@article{1998164082831 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {New design and performance-test strategy for sigma-delta modulators},
journal = {Transactions of the Institute of Measurement and Control},
author = {Zikic, A.M. and Cheshmehdoost, R.},
volume = {19},
number = {3},
year = {1997},
pages = {155 - 165},
issn = {01423312},
abstract = {The paper proposes a new approach to sigma-delta modulator design based on linear and non-linear control theories combined with a number of digital signal processing techniques. The limitations of single-stage high-order designs are analyzed as a compatibility problem between the linear filtering and non-linear quantizer requirements. The complexity versus performance-improvements of other strategies are also discussed. In addition to the new approach to component-compatibility analysis, the paper proposes a more rigorous analyses of the system performance by using, for the first time, groups of harmonic-rich test signals. Based on this new approach and the extensive analysis of how jointly and severally the linear and non-linear parameters influence the modulator's performance, a new design strategy is proposed and results demonstrated on a single-stage second-order modulator. The results are compared with those of an already-published second-order design for low over-sampling ratio of 64. It is shown that under the same conditions the new modulator exhibits a significantly improved signal-to-noise ratio `response' over a wide dynamic range of input signals. Finally, the conclusion discusses how this approach can be extended to other designs as well as used as a framework to completely new adaptive strategies.},
key = {Modulators},
keywords = {Analog to digital conversion;Delta modulation;Digital signal processing;Linear control systems;Nonlinear control systems;Signal to noise ratio;},
note = {Sigma delta modulators;},
} 


@article{20181705061275 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Standard Test Methods for Tire Performance Testing on Snow and Ice Surfaces},
year = {1999},
abstract = {Scope: These test methods cover the evaluation of tire performance on snow and ice surfaces utilizing passenger car or light truck vehicles. Since the tires are evaluated as part of a tire/vehicle system, the conclusions reached may not be applicable to the same tires tested on a different vehicle. These test methods do not purport to identify every maneuver useful for determining tire performance in a winter environment. These test methods are not meant to evaluate vehicle performance. Allowing for the variability of test results with different vehicles, these procedures have been developed and selected to evaluate relative tire-snow performance. These test methods are suitable for research and development purposes, where tires are compared during a single series of tests. They may not be suitable for regulatory statutes or specification acceptance because the values obtained may not necessarily agree or correlate either in rank order or absolute traction performance level with those obtained under other environmental conditions on other surfaces or the same surface after additional use. The values stated in SI units are to be regarded as the standard. The values given in parentheses are for information only. This standard does not purport to address all of the safety concerns, if any, associated with its use. It is the responsibility of the user of this standard to establish appropriate safety and health practices and determine the applicability of regulatory limitations prior to use.<br/> &copy;1999 ASTM International. All rights reserved.},
key = {Vehicle performance},
keywords = {Automobile testing;Snow;Tires;},
note = {Environmental conditions;Research and development;Safety and healths;Safety concerns;Snow and ice;Standard test method;Tire performance;Traction performance;},
URL = {http://dx.doi.org/10.1520/F1572-99},
versions = {4},
} 


@inproceedings{20133116568266 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Thermal performance testing of the bepicolombo hightemperature MLI},
journal = {40th International Conference on Environmental Systems, ICES 2010},
author = {Ranzenberger, Christian and Moser, Martin and Varewijck, George and Lehmann, Bernd and Ritter, Heiko and Battaglia, Domenico and Schilke, Jurgen},
year = {2010},
pages = {American Institute for Aeronautics and Astronautics (AIAA) - },
address = {Barcelona, Spain},
abstract = {The performance of multi-layer insulation (MLI) is commonly tested with a flat circular double sided hot plate calorimeter with a temperature limitation of +100&deg;C maximum. The BepiColombo mission demands insulation performance at considerably higher temperatures (up to +450&deg;C), which requires different test set-ups and facilities to obtain thermal performance data on ideal flat blankets as an extrapolation of test data obtained from the standard calorimeter would not be suitable for this extended temperature range. Real MLI has disturbances causing a loss of MLI performance due to edge effects, overlapping areas, slits and cut-outs, attachments or simply due to bending to follow the 3-dimensional (3D) shape of a spacecraft. To account for the elevated temperatures and losses due to real MLI shapes different calorimetric test setups were developed to produce performance data, which support the system thermal analysis for the spacecraft. Both ideal flat circular and 3D cubic-box MLI samples of varying sizes with the two BepiColombo HT-MLI compositions have been tested at elevated temperatures for this purpose. Thermocouples have been placed at various locations within the MLI packages to determine temperature gradients over and through the blankets. This paper describes the tested MLI compositions, the test setups used and correlates the performance and test results of 2D- and 3D- MLI samples for both compositions. The increase in the heat transfer coefficient (HTC) between ideal 2D blankets and box-shaped 3D blankets of different sizes is discussed. It is shown that the measured performance data for both MLI types are well within the design requirements set for the system analyses. The calorimetric tests prove that MLI insulation was developed which can cope with the severe thermal environment of the BepiColombo mission. &copy; 2010 by RUAG Space GmbH.},
key = {Three dimensional},
keywords = {Calorimeters;Calorimetry;Spacecraft;Testing;Thermal insulation;Thermoanalysis;Thermocouples;},
note = {Bepicolombo mission;Elevated temperature;Heat transfer coefficient (HTC);Insulation performance;Multi-layer insulation;Temperature limitation;Thermal Performance;Thermal performance testing;},
} 


@inproceedings{20122815236725 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Off-highway truck wheel bearing performance testing},
journal = {SAE Technical Papers},
author = {Browner, Rich},
year = {2002},
issn = {01487191},
address = {Las Vegas, NV, United states},
abstract = {Large mining truck manufacturers have achieved enhanced performance of the wheel bearings on their off-highway construction equipment vehicles using a unique Transducer Bearing from the Torrington Company to measure loads during truck operations. They have increased the life of the bearings by optimizing operating preload, and have gained an in-depth knowledge of bearing loading during the various portions of the truck duty cycle. This will increase the mean time between failure (MTBF) for these vehicles, improving uptime during mine operation and reducing failure costs for its users. This procedure can be used to identify inadequate bearing support structure, validate any required redesigns, and provide insights to optimize the life of the bearing in the measured load conditions. This paper provides results from the first testing of bearing loads in trucks using an instrumented bearing and a Torrington Co. patented data analysis algorithm. The instrumented bearing and data analysis algorithm form a valuable tool for determining applied loads in-situ, and can be utilized on any equipment or processes where bearing loads need to be measured. In fact, this technology could help users gain insight into the operating conditions in many kinds of rotating equipment by using the bearing as a transducer to measure critical system operating parameters. Copyright &copy; 2002 Society of Automotive Engineers, Inc.<br/>},
key = {Off road vehicles},
keywords = {Automobile manufacture;Construction equipment;Data handling;Highway engineering;Information analysis;Mine trucks;Transducers;Wheels;},
note = {Critical systems;Data analysis algorithms;In-depth knowledge;Mean time between failures;Off-highway trucks;Operating condition;Operating parameters;Rotating equipment;},
URL = {http://dx.doi.org/10.4271/2002-01-1370},
} 


@inproceedings{1990096110040 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {High performance test generation for accurate defect models in CMOS gate array technology},
author = {Sucar, Hector and Chandra, Susheel J. and Wharton, David J.},
year = {1989},
pages = {166 - 169},
address = {Santa Clara, CA, USA},
abstract = {A brief description is given of the CrossCheck test technology which provides the fundamental basis for this work. The authors present a practical analysis of transistor-level defects which result in accurate defect models in comparison to conventional fault models. The embedded test technology and accurate defect models are combined to form a high-quality test environment which is used to implement a high-performance test generation system. Finally, the authors present results on five ISCAS sequential benchmark circuits and two real designs. These results indicate that, in the presence of the embedded test electronics, test generation and fault simulation are considerably faster and test quality is substantially improved.},
key = {Integrated Circuit Testing},
keywords = {Failure Analysis;Logic Circuits, Sequential;Semiconductor Devices, MOS;},
note = {Accurate Defect Models;CMOS Gate Array;Fault Simulation;Sequential Benchmark Circuits;Test Generation;Transistor-Level Defects;},
URL = {http://dx.doi.org/10.1109/ICCAD.1989.76928},
} 


@inproceedings{2003227482240 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {SIRTF-CTA optical performance test},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Schwenker, J.P. and Brandi, B.R. and Burmester, W.L. and Hora, J.L. and Mainzer, A.K. and Quigley, P.C. and Van Cleve, J.E.},
volume = {4850},
number = {1},
year = {2002},
pages = {304 - 317},
issn = {0277786X},
address = {Waikoloa, HI, United states},
abstract = {This paper describes the "End to End" optical test conducted on the Space InfraRed Telescope Facility (SIRTF) Cryogenic Telescope Assembly (CTA) in 2001. It was critical to verify SIRTF's optical functionality and quality under optical and thermal conditions that as much as possible simulated the flight environment. The Liquid Nitrogen cooled "Brutus" chamber at Ball Aerospace was the test facility. Flight-like self cooling, thermal blanketing, and auxiliary cooling loops allowed the assembly to reach temperatures close to orbital conditions. (25-5 K) Introducing optical sources at the SIRTF focal plane allowed the telescope to perform as the collimating source. A motorized and cryogenically characterized reflection flat was used to direct the refocused images of test sources to visible and IR focal planes in SIRTF's Multi-Instrument Chamber. A sequence of tests was performed to gather data on system focus position, image stability, telescope wavefront and instrument assembly confocality.},
key = {Optical testing},
keywords = {Cryogenics;Infrared instruments;Space telescopes;Superfluid helium;},
note = {Cryogenic telescope assembly (CTA);},
URL = {http://dx.doi.org/10.1117/12.461918},
} 


@article{2000415305247 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Accelerated stress testing in a time-driven product development process},
journal = {International Journal of Production Economics},
author = {Lu, Yuan and Loh, Han Tong and Brombacher, Aarnout Cornelis and Ouden, Elke Den},
volume = {67},
number = {1},
year = {2000},
pages = {17 - 26},
issn = {09255273},
abstract = {In order to compete in the market, companies have to produce the right products with a shorter time to market and at lower costs than before. Shorter time to market requires the product development process (PDP) to change the way of working from the classical `wait and react' to anticipating and preventing problems as early as possible in the development process. This requires a new, and different role for the quality and reliability tests used. While in a classical PDP products could be tested when available from (pilot) production, a modern, time-driven development process requires optimization long before larger series of products are available. Accelerated stress testing (AST) is a classical solution for the implementation of tests where product failures need to be activated faster (and cheaper) in a well-controlled environment at the early stage of the PDP. This paper reviews the classical AST strategy and some most recent AST strategies. It demonstrates that these accelerated test strategies are mainly based on generic lists of failure mechanisms and have only very limited relation with the actual failure rate curve of products. The theoretical background of the four-phase roller coaster failure rate curve is addressed and from this an alternative AST strategy is developed based on the relevant phases of the roller coaster curve using a concept called stressor-susceptibility analysis. A discussion, on the application of the proposed AST strategies and their impacts on the four-phase roller-coaster curves, is given at the end.},
key = {Product development},
keywords = {Costs;Process engineering;Product design;Quality assurance;Quality control;Reliability;Stress analysis;},
note = {Accelerated stress testing (AST);Stressor-susceptibility analysis;Time-driven product development process;},
URL = {http://dx.doi.org/10.1016/S0925-5273(00)00006-2},
} 


@inproceedings{1986050074725 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {PERFORMANCE TESTING - THE WAY AHEAD.},
author = {Childs, Brian},
year = {1984},
pages = {295 - 298},
address = {Berlin, West Ger},
abstract = {The evolution of new VSLI/Microprocess and Complex Support Chips is causing a revolution in test techniques for electronic manufacturing. The new high performance sub-systems have proved to be far more complex to test and diagnose than previous designs and require a new look at traditional testing approaches. The paper discusses a combination of techniques for solving these problems using a proprietary technique of memory emulation, along with a sophisticated system of high speed sensors and qualifiers. This technique enables the identification and diagnosis of faults on PCBs which manifest themselves only when the PCB is in its final environment running at normal operating speed. The use of sensors and data collectors running at speeds up to 32 MHz enable the speedy location of dynamic faults on even the most complex circuits.},
key = {INTEGRATED CIRCUITS, VLSI},
keywords = {PRINTED CIRCUITS - Testing;},
note = {ELECTRONIC MANUFACTURING;},
} 


@inproceedings{20160902036900 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Randomized stress-testing of link-time optimizers},
journal = {2015 International Symposium on Software Testing and Analysis, ISSTA 2015 - Proceedings},
author = {Le, Vu and Sun, Chengnian and Su, Zhendong},
year = {2015},
pages = {327 - 337},
address = {Baltimore, MD, United states},
abstract = {Link-time optimization (LTO) is an increasingly important and adopted modern optimization technology. It is currently supported by many production compilers, including GCC, LLVM, and Microsoft Visual C/C++. Despite its complexity, but because it is more recent, LTO is relatively less tested compared to the more mature, traditional optimizations. To evaluate and help improve the quality of LTO, we present the first extensive effort to stress-test the LTO components of GCC and LLVM, the two most widely-used production C compilers. In 11 months, we have discovered and reported 37 bugs (12 in GCC; 25 in LLVM). Developers have confirmed 21 of our bugs, and fixed 11 of them. Our core technique is differential testing and realized in the tool Proteus. We leverage existing compiler testing tools (Csmith and Orion) to generate single-file test programs and address two important challenges specific for LTO testing. First, to thoroughly exercise LTO, Proteus automatically transforms a single-file program into multiple compilation units and stochastically assigns each an optimization level. Second, for effective bug reporting, we develop a practical mechanism to reduce LTO bugs involving multiple files. Our results clearly demonstrate Proteus's utility; we plan to make ours a continuous effort in validating link-time optimizers. &copy; 2015 ACM.},
key = {Software testing},
keywords = {C (programming language);Program compilers;Quality control;},
note = {Automated testing;Compiler testing;Differential testing;Link-time optimization;Optimization levels;Optimization technology;Optimizers;Stress Testing;},
URL = {http://dx.doi.org/10.1145/2771783.2771785},
} 


@inproceedings{20122715190837 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of the extended-range (hybrid) electric G van},
journal = {SAE Technical Papers},
author = {Scott Keller, A. and Whitehead, Gerald D.},
year = {1992},
issn = {01487191},
address = {Detroit, MI, United states},
abstract = {This paper presents the results of performance characterization testing of the extended-range Conceptor G Van electric vehicle (EV). Testing was performed at the Electrotek Electric Vehicle Test Facility (EVTF) as part of the Electric Power Research Institute (EPRI)/Electrotek EV Program. This extended-range EV (XREV) is based on the electric G Van, which is a GMC full-sized van converted to electric propulsion by Conceptor Industries of Newmarket (Toronto), Ontario. A 7-kW Onan gasoline engine/generator (E/G) set was retrofitted into the vehicle by McKee Engineering of Lake Zurich, Illinois. The XREV utilizes tubular-plate lead-acid batteries and dc powertrain components furnished by Chloride EV Systems of Redditch, England. Testing was conducted according to the EPRI/Electrotek EV Test Plan and included measurement of driving range on the SAE J227a C Cycle, on the Electrotek-defined Chattanooga City Cycle (CCC), and at four constant speeds from 56 km/h to 80 km/h. The C Cycle and CCC tests were performed with the E/G switched on at different battery states of charge (SOC) from 100% to 25% to determine the effects of the E/G on driving range and battery behavior. Limp-home tests were also conducted over these cycles by driving the XREV on pure-electric power to 0% SOC, turning on the E/G for a one-hour battery charge, and then continuing the cycle under both battery and E/G power. It was found that use of the E/G increased driving range significantly for all cases. Additional tests were performed to determine the dc energy consumption of the XREV over the C cycle and at various constant speeds. Data is presented which includes driving test results as well as calculated costs for different combinations of electric and gasoline operation. &copy; Copyright 1992 Society of Automotive Engineers, Inc.<br/>},
key = {Software testing},
keywords = {Charging (batteries);Chlorine compounds;Energy utilization;Gasoline;Lead acid batteries;Vehicles;},
note = {Constant speed;Electric Power Research Institute;Gasoline engines;Gasoline operations;Performance characterization;Performance testing;Powertrain components;States of charges;},
URL = {http://dx.doi.org/10.4271/920439},
} 


@inproceedings{2003147424235 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Non-invasive assessment of hemodynamics in adolescents with arterial tonometry and doppler ultrasound during a conventional stress test},
journal = {Computers in Cardiology},
author = {Matthys, Koen and Vanhercke, D. and Van Aken, S. and De Groote, K. and Coomans, I. and Verdonck, P.},
volume = {29},
year = {2002},
pages = {517 - 520},
issn = {02766574},
address = {Memphis, TN, United states},
abstract = {Aiming to improve early diagnosis of people at cardiovascular risk, we are developing a custom set-up to allow an adequate hemodynamic analysis of heart function and arterial circulation properties, based on non-invasive acquisition of pressure (arterial tonometry) and flow (Doppler ultrasound techniques) waveforms. In an experimental setting 15 healthy volunteers were examined on a custom made supine bicycle. Able to record usable data throughout the bicycle test and automatically analyse derived hemodynamic parameters such as compliance, peripheral resistance, etc., we also applied the set-up in a real clinical environment. This research contributes to a more complete cardiovascular examination without significant additional discomfort for the patient or prolongation of the test protocol.},
key = {Cardiovascular system},
keywords = {Biomedical engineering;Blood vessels;Computer aided diagnosis;Hemodynamics;Noninvasive medical procedures;},
note = {Mental stresses;Tonometers;},
URL = {http://dx.doi.org/10.1109/CIC.2002.1166823},
} 


@article{20072010604779 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Incorporating performance testing in test-driven development},
journal = {IEEE Software},
author = {Johnson, Michael J. and Maximilien, E. Michael and Ho, Chih-Wei and Williams, Laurie},
volume = {24},
number = {3},
year = {2007},
pages = {67 - 73},
issn = {07407459},
abstract = {Performance design and performance testing are necessarily different from functional test case design. A rigorous test-driven design methodology isn't practical for all performance measurement. A test-first approach to performance provides some advantages in a TDD environment. Experience with applying early performance testing in a TDD framework for a device-driver development project provides insight into the test-first approach. The results show a trend of performance improvement throughout the development life cycle, and better performance compared to an earlier release. Lessons learned include the benefit of having a performance architect on the development team and of tracking performance measurements throughout the development life cycle.This article is part of a special issue on test-driven development. &copy; 2007 IEEE.},
key = {Software engineering},
keywords = {Software design;Software testing;},
note = {Test execution;Test-driven design;Test-driven development;},
URL = {http://dx.doi.org/10.1109/MS.2007.77},
} 


@inproceedings{20120214675019 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Reusing functional testing in order to decrease performance and stress testing costs},
journal = {SEKE 2011 - Proceedings of the 23rd International Conference on Software Engineering and Knowledge Engineering},
author = {De Sousa Santos, Ismayle and Santos, Alcemir Rodrigues and Neto, Pedro De Alcantara Dos S.},
year = {2011},
pages = {470 - 474},
address = {Miami, FL, United states},
abstract = {This work presents an experimental study of an idea related to the automatic generation of performance and stress testing by reusing functional testing. The idea was implemented in a tool named FERRARE GT. This tool is able to generate both test scripts as well as the data required for their execution. In this study we verified that the use of the method can generate benefits related to cost reduction, from the reduction of test effort and, at the same time, benefits related to test quality, from the improvement of the test relevance for the software development.<br/>},
key = {Software testing},
keywords = {Cost reduction;Knowledge engineering;Software design;},
note = {Automatic Generation;Data generation;Experimental study;Functional testing;Non-functional requirements;Stress Testing;Test efforts;Test quality;},
} 


@inproceedings{20094612442839 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Fuse and load testing with Mid-sized, high energy density flux compression generators},
journal = {PPPS-2007 - Pulsed Power Plasma Science 2007},
author = {Young, A. and Holt, T. and Elsayed, M. and Neuber, A. and Kristiansen, M. and Altgilbers, L.L. and Stults, A.H.},
volume = {2},
year = {2007},
pages = {1165 - 1168},
address = {Albuquerque, NM, United states},
abstract = {Compact Pulsed Power Systems (CPPSs) require power sources that are small in size yet can produce the necessary electrical energy required to drive a given load. Helical Flux Compression Generators (HFCGs) are attractive for single shot applications due to their rapid conversion of chemical energy to electrical energy. Midsized generators occupy little total volume (&tilde;4,000-cm<inf>3</inf>total with a compressible volume of &tilde;300-cm<inf>3</inf>in the present generator design), while the high explosives used in an HFCG provide an energy density of &tilde;8,000 MJ/m<inf>3</inf>. Consistent output current and energy gain from shot to shot are key variables in the ability of an HFCG to drive CPPSs effectively. An investigation into the practicality of using mid-sized HFCGs as the driver for single shot CPPSs is presented. Data and waveforms from generators fired into 3&mu;H inductive loads are shown, with results measuring the generator's performance as a driver for an inductive energy storage (IES) system. Results are also shown from adding a power conditioning system to the output of the HFCG, where the measurements demonstrate the ability of an HFCG to drive high impedance loads. The effectiveness of a mid-sized HFCG as drivers for these systems will be evaluated. &copy; 2007 IEEE.<br/>},
key = {Digital storage},
keywords = {Electric power systems;Load testing;},
note = {Compact pulsed power;Electrical energy;Generator design;Helical flux compression generators;High energy densities;Inductive energy storage;Power conditioning systems;Rapid conversion;},
URL = {http://dx.doi.org/10.1109/PPPS.2007.4652394},
} 


@inproceedings{20155101697731 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Robot-assisted smartphone performance testing},
journal = {IEEE Conference on Technologies for Practical Robot Applications, TePRA},
author = {Kanstren, Teemu and Aho, Pekka and Lamsa, Arttu and Martin, Henar and Liikka, Jussi and Seppanen, Miska},
volume = {2015-August},
year = {2015},
issn = {23250526},
address = {15 Middlesex Canal Park, Woburn, MA, United states},
abstract = {This paper describes experiences and lessons learned in applying an approach of using a physical robot for testing overall smartphone device performance based on user profiles. The process consists of capturing user actions, abstracting them to usage profiles, transforming these into test models, and generating test cases from the models. The goal is to support performance testing of touch screen devices and applications in a realistic test environment. To achieve this, the tests are based on real-world generated user profiles and executed using a real physical robot, simulating the actual user. Our performance testing targets different attributes of performance such as response times, power and resource usage, and software/hardware aging. Use of different hardware and software configurations in the test scenarios is considered. This work has been performed in close collaboration with industry partners in robotics provider and user industries. &copy; 2015 IEEE.},
key = {Software testing},
keywords = {Electronic mail;Human computer interaction;Markov processes;Robot applications;Robots;Signal encoding;Smartphones;Testing;Touch screens;},
note = {Collaboration with industries;Device performance;Hardware and software;Performance evaluation;Performance testing;Robot kinematics;Service robots;Software/hardware;},
URL = {http://dx.doi.org/10.1109/TePRA.2015.7219669},
} 


@article{20170703341550 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Measurable Augmented Reality for Prototyping Cyberphysical Systems: A Robotics Platform to Aid the Hardware Prototyping and Performance Testing of Algorithms},
journal = {IEEE Control Systems},
author = {Omidshafiei, Shayegan and Agha-Mohammadi, Ali-Akbar and Chen, Yu Fan and Ure, Nazim Kemal and Liu, Shih-Yuan and Lopez, Brett T. and Surati, Rajeev and How, Jonathan P. and Vian, John},
volume = {36},
number = {6},
year = {2016},
pages = {65 - 87},
issn = {1066033X},
abstract = {Planning, control, perception, and learning are current research challenges in multirobot systems. The transition dynamics of the robots may be unknown or stochastic, making it difficult to select the best action each robot must take at a given time. The observation model, a function of the robots' sensor systems, may be noisy or partial, meaning that deterministic knowledge of the team's state is often impossible to attain. Moreover, the actions each robot can take may have an associated success rate and/or a probabilistic completion time. Robots designed for real-world applications require careful consideration of such sources of uncertainty, regardless of the control scheme or planning or learning algorithms used for a specific problem. Understanding the underlying mechanisms of planning algorithms can be challenging due to the latent variables they often operate on. When performance testing such algorithms on hardware, the simultaneous use of the debugging and visualization tools available on a workstation can be difficult. This transition from experimentation to implementation becomes especially challenging when the experiments need to replicate some feature of the software tool set in hardware, such as simulation of visually complex environments. This article details a robotics prototyping platform, called measurable augmented reality for prototyping cyberphysical systems (MAR-CPS), that directly addresses this problem, allowing for the real-time visualization of latent state information to aid hardware prototyping and performance testing of algorithms. &copy; 2016 IEEE.},
key = {Robot programming},
keywords = {Augmented reality;Computer aided software engineering;Computer debugging;Computer software;Embedded systems;Hardware;Learning algorithms;Program debugging;Real time systems;Robotics;Robots;Stochastic systems;Visualization;},
note = {Complex environments;Cyber physical systems (CPSs);Hardware prototyping;Prototyping platform;Real time visualization;Research challenges;Sources of uncertainty;Visualization tools;},
URL = {http://dx.doi.org/10.1109/MCS.2016.2602090},
} 


@inproceedings{20103813240047 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test of multiplatform real time processing of biomedical signals},
journal = {IEEE International Conference on Industrial Informatics (INDIN)},
author = {Krejcar, Ondrej and Penhaker, Marek and Janckulik, Dalibor and Motalova, Leona},
year = {2010},
pages = {825 - 830},
issn = {19354576},
address = {Osaka, Japan},
abstract = {The paper deal with a problem of a data collecting and visualization of several biomedical signals from patients by mobile embedded monitoring stations. Measurement devices were used in real tests. Due to a problem of real time processing a 12 channels ECG from ECG device by Bluetooth to mobile stations, packet parsing as the one problem part of data processing chain, is presented and solved by two possible solutions. Mobile embedded monitoring stations are based on Microsoft Windows Mobile operating system. The whole system is based on the architecture of .NET Framework, .NET Compact Framework, .NET Micro Framework and Microsoft SQL Server. &copy; 2010 IEEE.<br/>},
key = {Windows operating system},
keywords = {Bioelectric phenomena;Biomedical signal processing;Biotelemetry;Data handling;Data visualization;Electrocardiography;Processing;},
note = {Data processing chains;Measurement device;Microsoft SQL Server;Mobile;Monitoring stations;NET compact framework;Performance tests;Realtime processing;},
URL = {http://dx.doi.org/10.1109/INDIN.2010.5549635},
} 


@article{20140517243353 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Comprehensive load test on prestressed concrete piles in alluvial clays and marl in Savannah, Georgia},
journal = {Journal of Performance of Constructed Facilities},
author = {Tan, Yong and Lin, Guoming},
volume = {28},
number = {1},
year = {2014},
pages = {178 - 190},
issn = {08873828},
abstract = {This paper introduces a comprehensive full-scale pile load test program on 457-mm (18-in.) square prestressed concrete (PSC) piles in Savannah, Georgia. The program consisted of pile driving analyzer testing during initial pile driving and restrikes, Statnamic tests, static axial compression load tests, and reciprocal lateral load tests. On the basis of the interpretation of the test data, some important findings were obtained: (1) the alluvial clays in Savannah can only provide very limited resistance; (2) the time-dependent pile capacity gain after pile driving (i.e., setup effect) was approximately proportional to the pile embedment length into the Marl formation; (3) the estimated equivalent static pile capacities from the Statnamic tests were comparable to those from the static axial load tests; (4) the Marl formation is a competent bearing stratum for piles; (5) the potential degradation of pile concrete stiffness caused by pile driving should be accounted for in pile capacity analysis; and (6) the piles exhibited stiffer response under the monotonic lateral loading condition than the cyclic lateral loading condition. Finally, predictions on both axial and lateral pile capacities, using the soil parameters derived from the instrumentation data and back-analysis of the pile load tests, were compared with the corresponding pile load test results. The comparisons demonstrate that in combination of the static-bearing capacity formulas and the LPILE program, the developed soil models can make reliable predictions on both the vertical and lateral behaviors of the PSC piles driven through the soft alluvial clays to end bearing in the Marl formation. &copy; 2014 American Society of Civil Engineers.<br/>},
key = {Piles},
keywords = {Axial loads;Concrete beams and girders;Fertilizers;Load testing;Pile driving;Prestressed concrete;Software testing;},
note = {Alluvial clay;Axial compression load;Bearing capacity formulas;Cyclic lateral loading;Lateral load tests;Lateral loading conditions;Marl formation;Pile driving analyzers;},
URL = {http://dx.doi.org/10.1061/(ASCE)CF.1943-5509.0000305},
} 


@inproceedings{20163502750372 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of the EU/QU MMRTG},
journal = {14th International Energy Conversion Engineering Conference, 2016},
author = {Barklay, Chadwick and Tolson, Boyd and Bolotin, Gary and Keyawa, Nicholas and Woerner, David},
year = {2016},
address = {Salt Lake City, UT, United states},
abstract = {The Multi-Mission Radioisotope Thermoelectric Generator (MMRTG) Lifecycle Testing Laboratory is operated by the University of Dayton Research Institute (UDRI), which is dedicated to conducting life-cycle testing of electrically heated versions of the MMRTG. Since there are only two MMRTG electrically-heated thermoelectric generators (ETG) available for testing, a Test Plan Development Working Group was established to determine and prioritize the performance testing that is being conducted with the Engineering Unit (EU) and Qualification Unit (QU) ETGs. This working group is comprised of subject matter experts from the U.S. Department of Energy (DOE), the National Aeronautics and Space Administration (NASA) Glenn Research Center (GRC), NASA Jet Propulsion Laboratory (JPL), Idaho National Laboratory (INL), Oak Ridge National Laboratory (ORNL), UDRI, Aerojet Rocketdyne, and Teledyne Energy Systems. The highest priority testing was concluded by the working group to be: 1) To determine the impact of thermal cycling on thermoelectric components by characterizing the evolution of the thermoelectric/electrical properties of the EU as a result of thermal cycling the ETG through a Martian Sol repeatedly; 2) to characterize the effect of a simulated cruise-phase environment on the QU by evaluating the change in performance of the ETG before and after a cruise-phase simulation; and 3) characterize and clear any potential MMRTG internal shorts to chassis by integrating the JPL derived active short technique between the internal electrical power circuit and chassis frame of the MMRTG. The data and risk mitigation techniques derived from this testing can potentially be incorporated into future missions that would employ the MMRTG or successor thermoelectric radioisotope power systems. &copy; 2016, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved.},
key = {Integration testing},
keywords = {Chassis;Electronic equipment;Energy conversion;Fighter aircraft;Laboratories;Life cycle;NASA;Nuclear batteries;Radioisotopes;Sols;Thermal cycling;Thermoelectric energy conversion;Thermoelectric equipment;},
note = {Glenn Research Center;Idaho national laboratories;Multi mission radioisotope thermoelectric generators;Oak ridge national laboratories;Radioisotope Power System;Subject matter experts;Thermoelectric generators;U.S. Department of Energy;},
} 


@article{20150600497023 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stress test for a technology credit guarantee fund based on survival analysis},
journal = {Journal of the Operational Research Society},
author = {Ju, Yonghan and Young Sohn, So},
volume = {66},
number = {3},
year = {2015},
pages = {463 - 475},
issn = {01605682},
abstract = {A technology credit guarantee policy has been established to provide financial support to technology-based SMEs with a limited asset base. For an effective technology credit guarantee policy, risk management is essential. In this paper, we investigate a survival model that predicts start-up SMEs' loan default probability at a given time based on technology attributes along with the economic environment and the firm's characteristics at the time of the technology credit guarantee fund application. This, in turn, is used for the estimation of the technology fund risk along with a stress test. Our work is expected to contribute to reducing the risks associated with technology financing.<br/> &copy; 2015 Operational Research Society Ltd.},
key = {Risk assessment},
keywords = {Bioinformatics;Risk management;Risk perception;},
note = {Economic environment;Financial support;Loan default;Stress test;Survival analysis;Survival model;Technology credit guarantee funds;Technology-based;},
URL = {http://dx.doi.org/10.1057/jors.2014.10},
} 


@inproceedings{20131016092664 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {An improved wavelet denoising method used in electrical throttle performance testing},
journal = {Proceedings of 2012 International Conference on Image Analysis and Signal Processing, IASP 2012},
author = {Yang, Xiaomin and Chen, Zailiang},
year = {2012},
pages = {171 - 174},
address = {Hangzhou, China},
abstract = {In this paper, an electrical throttle performance test system is designed mainly focusing on its potentiometer and function tests. An improved denoising algorithm based upon the wavelet transform is proposed in non-stationary testing environment. In the experiment, the virtual instrument is used to call the denoising module and processes the acquiring signals. It is proved that its effect is obviously more excellent than conventional algorithms. This test system is then used in actual assembly line. Good parts can be sorted out efficiently and the quality of assembly line is improved. &copy; 2012 IEEE.},
key = {Image analysis},
keywords = {Algorithms;Assembly;Assembly machines;Signal processing;Voltage dividers;},
note = {Assembly line;Conventional algorithms;De-noising;De-noising algorithm;electrical throttle;Function tests;Nonstationary;Performance testing;Performance tests;Test systems;Testing environment;Virtual instrument;Wavelet denoising;Wavelet denoising method;},
URL = {http://dx.doi.org/10.1109/IASP.2012.6425016},
} 


@inproceedings{20133516663550 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Influence of advancements in gas turbine control systems on gas turbine and combined-cycle performance test correction curves},
journal = {American Society of Mechanical Engineers, Power Division (Publication) POWER},
author = {Schmitt, Thomas P. and Banares, Christopher R. and Morlang, Benjamin D. and Michael, Matthew C.},
volume = {2},
number = {1},
year = {2011},
pages = {661 - 668},
address = {Denver, CO, United states},
abstract = {Many modern power plants feature gas turbines with advanced control systems that allow a greater level of performance enhancements, over a broader range of the combined-cycle plant's operating environment, compared to conventional systems. Control system advancements tend to outpace a plant's construction and commissioning timescale. Often, the control algorithms and settings in place at the final guarantee performance test will differ significantly from those envisioned during the contract agreement phase. As such, the gas turbine's actual performance response to changes in boundary conditions, such as air temperature and air humidity, will be considerably different than the response illustrated on the initial correction curves. For the sake of technical accuracy, the performance correction curves should be updated to reflect the as-built, as-left behavior of the plant. By providing the most technically accurate curves, the needs of the new plant performance test are satisfied. Also, plant operators receive an accurate means to trend performance over time. The performance correction curves are intended to provide the most technically accurate assurance that the corrected test results are independent of boundary conditions that persist during the performance test. Therefore, after the gas turbine control algorithms and/or settings have been adjusted, the performance correction curves - whether specific to gas turbines or overall combined-cycle plants - should be updated to reflect any change in turbine response. This best practice maintains the highest level of technical accuracy. Failure to employ the available advanced gas turbine control system upgrades can limit the plant performance over the ambient operating regime. Failure to make a corresponding update to the correction curves can cause additional inaccuracy in the performance test's corrected results. This paper presents a high-level discussion of GE's recent gas turbine control system advancements, and emphasizes the need to update performance correction curves based on their impact. Copyright &copy; 2011 by ASME.},
key = {Gas turbines},
keywords = {Algorithms;Boundary conditions;Combined cycle power plants;Control systems;},
note = {Advanced control systems;Combined-cycle plants;Contract agreements;Conventional systems;Correction curves;Gas turbine control;Operating environment;Performance enhancements;},
URL = {http://dx.doi.org/10.1115/POWER2011-55123},
} 


@inproceedings{20162902613010 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {CAN bus performance test technology},
journal = {2015 IEEE 12th International Conference on Electronic Measurement and Instruments, ICEMI 2015},
author = {Shengbing, Shi and Chunyan, Song and Yanlin, Wu},
volume = {3},
year = {2016},
pages = {1395 - 1399},
address = {Qingdao, China},
abstract = {With the development of high and new technology, the degree of weapon equipments' integration, digitization and information became more and more higher. CAN bus technology is also used more and more widely. The self-performance of CAN bus effects weapon equipments' information interaction such as instructs convey, default detection and so on. It also has vital influence on weapon equipments to carry out fight tasks. In this paper, through analyzing CAN bus architecture of certain weapon and data transmission characteristic on CAN bus, analyses several problems on CAN bus performance test, including test system structure, test data capacity analysis and data processing. Through constructing one test environment, proves this method is scientific and logical, lays the technological foundation of implementing CAN bus performance test. &copy; 2015 IEEE.},
key = {Data communication systems},
keywords = {Data handling;Equipment;Testing;},
note = {CAN bus;CAN-bus technology;Information interaction;Performance tests;Test data;Test Environment;Test systems;Weapon equipment;},
URL = {http://dx.doi.org/10.1109/ICEMI.2015.7494507},
} 


@inproceedings{20142017708609 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing: A guide to successful real world performance testing november 2013},
journal = {Annual International Conference of the Computer Measurement Group, CMG 2013},
author = {Verma, Mohit},
volume = {2},
year = {2013},
pages = {1090 - 1131},
address = {London, United kingdom},
abstract = {In this paper, we present benefits of performance testing, forms of performance testing, key success factors and provider a framework to build a business case for Performance Testing and Application Performance Monitoring. It will be beneficial for beginner Performance Engineers and help close gaps for existing engineers by illustrating some best practices and guidelines for Successful Performance testing, and building a Performance Testing Center of Excellence.<br/>},
key = {Measurement},
keywords = {Computer science;Computers;},
note = {Application performance;Best practices;Business case;Key success factors;Performance testing;Real-world performance;},
} 


@article{20160801986563 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A three-stage scenario based operational performance test approaches for production capacity enhancement: Case study on the 5th refinery of South Pars Gas Complex in Iran},
journal = {Journal of Natural Gas Science and Engineering},
author = {Fahimirad, Mahdi and Farzad, Somayeh and Moghaddam, Siamak Nourin and Saremi, Homayoun Shokuh},
volume = {27},
year = {2015},
pages = {1758 - 1770},
issn = {18755100},
abstract = {In this work, the possibility of capacity enhancement in the South Pars Gas Complex of Iran has been studied. Mass balance is studied and data validation and reconciliation have been carried out in 5<sup>th</sup>refinery of South Pars Gas Complex in order to achieve the reliable data of the plant. Then the possibility of capacity increase has been studied, taking into account the important parameters such as alteration of the plant pressure profile. Calculation of the key parameters for different equipment at higher feed rate, specified the unit of operations which may have trouble during the capacity enhancement. The performance of export gas compressors, dehydration unit and High-Integrity Pressure Protection System (HIPPS) has been anticipated to be the obstacle of this project according to the results of design basis review. In order to increase the feed rate the operation at constant inlet pressure is considered while the final stage pressure decreases as it is safe procedure for the plant. Then performance test has been carried out to monitor the changes in the plant. Three methodologies were designed and evaluated for implementing the performance test, and the stepwise procedure has been carried out successfully. During the performance test, the feed rate has been increased in three consecutive steps by 4.5%, 3% and 2.5% respectively. The operation of key equipment such as turbo expanders, exports and refrigerant compressors, dehydration beds, columns and filters, have been examined by taking samples from inlet-outlet streams such as feed gas, acid gas, lean and rich amine, LPG product. Following the step wised feed rate increase, the performance test was operationally successful and the production capacity of sweet gas in South Pars has been increased about 10%. &copy; 2015 Elsevier B.V.},
key = {Offshore gas fields},
keywords = {Compressibility of gases;Dehydration;Gas compressors;Gases;Refining;Testing;},
note = {Capacity enhancement;Gas refineries;High integrity pressure protection system;Operational performance;Performance tests;Production capacity;Refrigerant compressors;South Pars Gas Complex;},
URL = {http://dx.doi.org/10.1016/j.jngse.2015.10.042},
} 


@inproceedings{20130315907895 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Load testing on a budget, Part II},
journal = {35th International Conference Computer Measurement Group},
author = {Johnson, Peter},
year = {2009},
address = {Dallas, TX, United states},
abstract = {An earlier paper provided a introductory tutorial on using the open-source tool JMeter to load test a web application. But that paper just scratched the surface of what JMeter is capable of. This paper continues where that paper left off, describing how you can make use of some of the other capabilities of JMeter to load test applications. This paper is provided as a tutorial giving specific steps to accomplish various tasks. Copyright &copy; 2009, Unisys Corporation. All rights reserved.},
key = {Measurements},
note = {Load test;Open source tools;WEB application;},
} 


@inproceedings{20144600190944 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Diversified stress testing of RDF data management systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Aluc, Gune and Hartig, Olaf and Tamer Ozsu, M. and Daudjee, Khuzaima},
volume = {8796},
year = {2014},
pages = {197 - 212},
issn = {03029743},
address = {Riva del Garda, Italy},
abstract = {The Resource Description Framework (RDF) is a standard for conceptually describing data on the Web, and SPARQL is the query language for RDF. As RDF data continue to be published across heterogeneous domains and integrated at Web-scale such as in the Linked Open Data (LOD) cloud, RDF data management systems are being exposed to queries that are far more diverse and workloads that are far more varied. The first contribution of our work is an indepth experimental analysis that shows existing SPARQL benchmarks are not suitable for testing systems for diverse queries and varied workloads. To address these shortcomings, our second contribution is the Waterloo SPARQL Diversity Test Suite (WatDiv) that provides stress testing tools for RDF data management systems. Using WatDiv, we have been able to reveal issues with existing systems that went unnoticed in evaluations using earlier benchmarks. Specifically, our experiments with five popular RDF data management systems show that they cannot deliver good performance uniformly across workloads. For some queries, there can be as much as five orders of magnitude difference between the query execution time of the fastest and the slowest system while the fastest system on one query may unexpectedly time out on another query. By performing a detailed analysis, we pinpoint these problems to specific types of queries and workloads. &copy; Springer International Publishing Switzerland 2014.},
URL = {http://dx.doi.org/10.1007/978-3-319-11964-9},
} 


@inproceedings{20124415628251 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {An innovative approach to smart automation testing at National Grid},
journal = {Proceedings of the IEEE Power Engineering Society Transmission and Distribution Conference},
author = {Knauss, John-Paul H. and Warren, Cheri and Kearns, Dave},
year = {2012},
issn = {21608555},
address = {Orlando, FL, United states},
abstract = {Upon completion of a successful Distribution Automation (DA) Pilot Project centered in National Grid's upstate New York service territory, it was determined that the reliability improvements delivered by the pilot demonstration justified a much more comprehensive effort to further evaluate additional Smart Grid technologies. The vision was to conduct experiments with a full suite of Smart Grid technologies including: AMI; Home Area Network and energy management systems; Automatic Fault Isolation &amp; System Restoration; advanced feeder monitoring; distribution transformer monitoring; single pole tripping and Pulse Closing technology on distribution line reclosers; advanced capacitor control with independent pole operation; faulted circuit indicators with 2-way communication capability; and distribution fault locating capability. This vision came to be known as National Grid's Smart Grid Pilot proposal. Many challenges exist with such a comprehensive approach from public and personnel safety, to ensuring interoperability between devices and systems of different manufacture. In order to determine which technologies would provide the most benefit to National Grid's customer base, a means was needed to prequalify the various types of products available before large scale deployments were initiated. Looking at the large number of Smart Grid device suppliers, architectures and products available, we realized that the optimum solution would be to build a facility wherein a wide range of Smart Grid technologies could be installed and systematically put through their paces; i.e. actually tested in as near a real-world atmosphere as practical. Thus was born the National Grid Smart Technology Centre or STC. Soon thereafter, National Grid's Utility of the Future engineering team designed, engineered, and constructed a truly innovative test fixture that enabled system level testing on complex distribution networks to ensure process safety during field deployment. One of only a few known organizations in the U.S., National Grid has in-house capability to truly test and evaluate an end-to-end Smart distribution system architecture where systems such as automated fault isolation and system restoration can be evaluated. This paper will discuss interoperability testing that National Grid embarked upon to prepare for its proposed Smart Grid Pilot demonstration and will detail the lengths that were taken in creating a test site where medium voltage Smart Grid technologies could be fully evaluated to ensure that the various applications would play well with each other prior to actually being deployed in the field. Furthermore, this paper will focus on providing an overview of the system level testing and technical evaluation of distribution protection and control equipment with automated fault isolation and system restoration capabilities. It will also detail a number of lessons learned from this effort and discuss future plans for smart technology evaluation as a basis for an educational platform and workforce training tool. &copy; 2012 IEEE.<br/>},
key = {Smart power grids},
keywords = {Automation;Control equipment;Electric equipment protection;Electric power transmission networks;Electric transformers;Energy management systems;Home networks;Interoperability;Network architecture;Plant shutdowns;Poles;Restoration;Safety engineering;Safety testing;},
note = {Communication capabilities;Distribution automation;Distribution protection;Distribution transformer;Faulted circuit indicators;Interoperability testing;Smart distribution systems;Smart Grid technologies;},
URL = {http://dx.doi.org/10.1109/TDC.2012.6281507},
} 


@inproceedings{20082911374282 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research on universal network performance testing model},
journal = {ISCIT 2007 - 2007 International Symposium on Communications and Information Technologies Proceedings},
author = {Xing, Changyou and Zhang, Guomin and Chen, Ming},
year = {2007},
pages = {780 - 784},
address = {Sydney, Australia},
abstract = {Network performance testing is one of the key components in optimizing network resource configuration and improving network performance. Existing performance testing tools usually focus on single performance parameters, and lack of the ability to satisfy integrated testing demands of network administrators. In this paper, a universal network performance testing model based on policy scheduling is proposed, which integrates many kinds of performance testing tools into a single system, and provides a uniform testing interface to network administrators. Universal Probe (UP) is the key component of such a model, thus a detailed study is given on UP, which includes UP architecture, policy-based UP cooperation, mobility, and UP deployment under resource constraints. At last, a practical Network Monitor and Measurement System that designed based on the discussed concepts is presented. &copy; 2007 IEEE.<br/>},
key = {Ability testing},
keywords = {Network performance;},
note = {Measurement system;Network administrator;Network resource;Performance parameters;Performance testing;Practical networks;Resource Constraint;Universal network;},
URL = {http://dx.doi.org/10.1109/ISCIT.2007.4392122},
} 


@inproceedings{20170903400732 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Results from performance testing of transportable gasifier for on-farm disposal of animal mortalities},
journal = {International Conference on Thermal Treatment Technologies and Hazardous Waste Combustors 2016, IT3 2016},
author = {Lemieux, Paul and Serre, Shannon},
year = {2016},
pages = {56 - 70},
address = {Baton Rouge, LA, United states},
abstract = {A prototype transportable gasifier intended to process 25 tons per day of animal mortalities (scalable to 200 tons per day) was built as part of an interagency effort involving several federal agencies as well as the State of North Carolina. This effort is intended to demonstrate the feasibility of gasification for contaminated carcass disposal and to identify technical challenges and improvements that will simplify, improve, and enhance the gasifier system as a mobile response tool. Past testing of the prototype demonstrated partial success, in that the transportability and rapid deployment requirements were met, however, the throughput of animal carcasses was approximately 1/3 of the intended design capacity. Significant modifications were made to various gasifier components, including the burner system, feed system, control system, power distribution, and ash handling system in order to increase its operating capacity to the rated design throughput. A series of tests were performed in September 2015 to evaluate the effectiveness of the design modifications at increasing the system's throughput, as well as to demonstrate the unit's ability to operate around the clock for an extended period of time. These tests, once again, were partially successful, with the new burner system, feed system, control system, and power distribution systems all functioning in an acceptable manner. However, the ash removal system and the system to move material across the bed failed during the tests due to material issues. This paper summarizes the results of the test.},
key = {Animals},
keywords = {Ash handling;Combustors;Control systems;Hazardous materials;Hazards;Heat treatment;Power control;Throughput;Waste treatment;},
note = {Ash handling systems;Design modifications;Operating capacity;Performance testing;Power distribution system;Power distributions;Rapid deployments;Technical challenges;},
} 


@article{20091912076008 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Investigation of shear resistance of steel bridge girders by load testing and monitoring of load response data under highway traffic conditions},
journal = {Canadian Journal of Civil Engineering},
author = {Au, Alexander and Lam, Clifford and Tharmabala, Bala},
volume = {36},
number = {3},
year = {2009},
pages = {449 - 462},
issn = {03151468},
abstract = {A recent strength evaluation of the Hogg's Hollow Bridge on Highway 401 in Ontario revealed a significant deficiency in the shear resistance of the existing girders at support locations. This was attributed to the absence of transverse stiffeners at the extreme ends of the girders. However, none of the bridge girders showed any signs of distress. The Ontario Ministry of Transportation recently conducted a field study to investigate this shear issue in greater detail. To that end, a test program was devised to (a) monitor the real stresses in the end panels of two selected girders in the Hogg's Hollow Bridge when subjected to (i) a test truck with known axle loads and (&laquo;) normal highway traffic loading, and (b) calibrate the observed stresses against theoretically expected responses in the girders and calculate the live load capacity factor using the shear data derived from the field measurements.<br/>},
key = {Highway bridges},
keywords = {Automobile testing;Load testing;Plate girder bridges;Software testing;Steel bridges;Steel testing;Traffic surveys;},
note = {Bridge testing;Field measurement;Live-load capacity;Shear resistances;Steel bridge girders;Strength evaluation;Traffic loads;Transverse stiffener;},
URL = {http://dx.doi.org/10.1139/L09-009},
} 


@inproceedings{20110613643890 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Session-based performance test case generation for web applications},
journal = {SCMIS 2010 - Proceedings of 2010 8th International Conference on Supply Chain Management and Information Systems: Logistics Systems and Engineering},
author = {Quan, Xiuxia and Lu, Lu},
year = {2010},
abstract = {There are many techniques and tools for Web application testing, but few of these address the procedure for gathering user session data accessed in a production environment to assist in testing Web application performance. In this paper, we present a session-based approach to automatically generate performance test cases by exploiting user session information taken from server logs. Such test cases are used for generating synthetic workload to evaluate performance. This paper illustrates the prototype implementation of our session-based performance test case generation approach.<br/>},
key = {Testing},
keywords = {Decision trees;Information management;Logistics;Supply chain management;},
note = {Performance tests;Production environments;Prototype implementations;Synthetic workloads;Techniques and tools;User sessions;WEB application;Web application testing;},
} 


@inproceedings{20121114854651 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test specification for passenger car in low temperature},
journal = {Advanced Materials Research},
author = {Mi, Chen and Han, DaMing},
volume = {418-420},
year = {2012},
pages = {2272 - 2277},
issn = {10226680},
address = {Guilin, China},
abstract = {The study of this article focus on the standards on the working limit of the passenger car. The standards for passenger cars at low temperature were studied and proposed by combination of the technical content in cold regions' environments and the development trend in the domestic and international situation. The proposed standards can improve the service life of mechanical parts, reduce wear and failure of passenger cars and improve the passenger's power, economy and security. In the industry standardization and the objective requirements of relevant standards, this proposed standards are the basis to ensure fair competition in international trade, maintain the normal order of market and make up a communication bridge among the international economic cooperations. Maintain maximum benifit of the China's auto industry in the internationality. The emphases of the standards is to establish standards for low temperature environment laboratory, draw our own standards on product characteristics and screening standards system in line with China's actual conditions. &copy; (2012) Trans Tech Publications, Switzerland.},
key = {Standardization},
keywords = {Automobiles;Competition;Diagnosis;International trade;Passenger cars;Temperature;},
note = {Auto industry;Cold regions;Development trends;In-line;International economics;Low temperature environment;Low temperatures;Mechanical parts;Performance of low temperatures;Performance tests;Product characteristics;Reduce wear;Technical content;Test method;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMR.418-420.2272},
} 


@inproceedings{20163302710912 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Overloaded!   A model-based approach to database stress testing},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Meira, Jorge Augusto and de Almeida, Eduardo Cunha and Kim, Dongsun and Filho, Edson Ramiro Lucas and Le Traon, Yves},
volume = {9827 LNCS},
year = {2016},
pages = {207 - 222},
issn = {03029743},
address = {Porto, Portugal},
abstract = {As a new era of &ldquo;Big Data&rdquo; comes, contemporary database management systems (DBMS) introduced new functions to satisfy new requirements for big volume and velocity applications. Although the development agenda goes at full pace, the current testing agenda does not keep up, especially to validate non-functional requirements, such as: performance and scalability. The testing approaches strongly rely on the combination of unit testing tools and benchmarks. There is still a testing methodology missing, in which testers can model the runtime environment of the DBMS under test, defining the testing goals and the harness support for executing test cases. The major contribution of this paper is the MoDaST (Model-based Database Stress Testing) approach that leverages a state transition model to reproduce a runtime DBMS with dynamically shifting workload volumes and velocity. Each state in the model represents the possible running states of the DBMS. Therefore, testers can define state goals or specific state transitions that revealed bugs. Testers can also use MoDaST to pinpoint the conditions of performance loss and thrashing states. We put MoDaST to practical application testing two popular DBMS: PostgreSQL and VoltDB. The results show that MoDaST can reach portions of source code that are only possible with non-functional testing. Among the defects revealed by MoDaST, when increasing the code coverage, we highlight a defect confirmed by the developers of VoltDB as a major bug and promptly fixed. &copy; Springer International Publishing Switzerland 2016.},
key = {Database systems},
keywords = {Big data;Defects;Expert systems;Information management;},
note = {Application testing;Model based approach;Non-functional requirements;Performance and scalabilities;Performance loss;Runtime environments;State transition models;Testing methodology;},
URL = {http://dx.doi.org/10.1007/978-3-319-44403-1_13},
} 


@inproceedings{20145100346340 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Review of NoSQL databases and performance testing on HBase},
journal = {Proceedings - 2013 International Conference on Mechatronic Sciences, Electric Engineering and Computer, MEC 2013},
author = {Naheman, Wumuti and Wei, Jianxin},
year = {2013},
pages = {2304 - 2309},
address = {Shenyang, China},
abstract = {NoSQL (Not Only SQL) is the generic term of a kind of non-relational database products. This paper, firstly, lists the disadvantages of traditional relational databases, introduces NoSQL databases including their advantages, disadvantages and their application status. Then, a comparison is made between NoSQL databases and SQL database, also another comparison between different NoSQL products. Finally, we introduce the architecture and data model of HBase database, which is a representative of NoSQL databases, and did some performance tests on HBase database, including the column family test, the sort test, the random read/write test and the query test. Test results show that written and query speed of HBase is slow under a single machine environment, but can be significantly improved in multi machine cluster environment.<br/> &copy; 2013 IEEE.},
key = {Query processing},
keywords = {Testing;},
note = {Application status;Cluster environments;H Base;Non-Relational Databases;Nosql database;Performance testing;Performance tests;Relational Database;},
URL = {http://dx.doi.org/10.1109/MEC.2013.6885425},
} 


@article{1997010407857 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Effect of crack blunting in liquid metal environments on KIEAC determined by the rising load test},
journal = {Engineering Failure Analysis},
author = {Fernandes, P.J.L. and Jones, D.R.H.},
volume = {3},
number = {3},
year = {1996},
pages = {227 - 230},
issn = {13506307},
abstract = {An accelerated testing method to determine the threshold stress intensity is proposed. The method involves the application of a monotonically increasing load to a pre-cracked fracture mechanics type specimen exposed to the environment of interest. The stress intensity for crack initiation is calculated from the initiation load, as determined from the point of deviation from the linear load-displacement record, and the corresponding crack length. This stress intensity value is assumed to be equivalent to K<inf>IEAC</inf>.},
key = {Stress analysis},
keywords = {Brass;Crack initiation;Crack propagation;Dissolution;Embrittlement;Fatigue testing;Fracture mechanics;Gallium;Liquid metals;Load testing;Stress intensity factors;},
note = {Crack blunting;Crack length;Crack tip;Linear load displacement record;Load ratio;Loading rates;Molten gallium environment;Rising load tests;Threshold stress intensity;},
URL = {http://dx.doi.org/10.1016/1350-6307(96)00009-X},
} 


@inproceedings{20102312980212 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Development and in-sea performance testing of a single point mooring supported contra-rotating tidal turbine},
journal = {Proceedings of the International Conference on Offshore Mechanics and Arctic Engineering - OMAE},
author = {Clarke, Joe and Grant, Andrew and Connor, Gary and Johnstone, Cameron},
volume = {4},
number = {PART B},
year = {2009},
pages = {1065 - 1073},
address = {Honolulu, HI, United states},
abstract = {A 2<sup>nd</sup>generation, contra-rotating marine current turbine has been developed by the Energy Systems. Research Unit at the University of Strathclyde. This system can be tuned to extract energy over a wide range of water depths by "flying" a neutrally-buoyant device from a flexible, tensioned mooring. After successful proof of concept turbine trials, the development programme has moved on to investigate the performance of a scaled prototype system comprising of a dual rotor, contra-rotating turbine directly coupled to a submersible contra-rotating generator; and held on station via a gravity based tensioned mooring system. The turbine/generator assembly was initially tested in a towing tank, before the entire system underwent sea trials initially at the Kyles of Bute in the River Clyde Estuary before being deployed in eth Sound of Islay of eth West Coast of Scotland. An investigation into turbine wake development (an area in which it is hoped that the contra-rotating turbine will have uniquely beneficial properties) has recently begun. Small single-rotor model turbines have been deployed in a flume. Trends observed so far are in accordance with those observed by other researchers. Copyright &copy; 2009 by ASME.<br/>},
key = {Turbine components},
keywords = {Arctic engineering;Arctic vehicles;Mooring;},
note = {Contra rotating turbine;Contra-rotating;Development programmes;Marine current turbines;Performance testing;Proof of concept;Prototype system;University of Strathclyde;},
URL = {http://dx.doi.org/10.1115/OMAE2009-79995},
} 


@article{20103313154568 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Session-based user behavior meta-model of web applications for user-level QoS load testing},
journal = {International Journal of Digital Content Technology and its Applications},
author = {Lu, Lu and Quan, Xiuxia},
volume = {4},
number = {4},
year = {2010},
pages = {28 - 42},
issn = {19759339},
abstract = {With the rapid development of Service-Oriented Architecture (SOA) and Service-Oriented Computing (SOC), the Quality of Service (QoS) is more and more essential than before. There are a number of tools and techniques for Web application testing, but few of these have addressed the procedure to gather user session data accessed in the production environment to assist testing SOA and SOC Web application performance, so as to apply appropriate user-level quality of service policy (user-level QoS) according to the test result. In this paper, we present a session-based user behavior meta-model (SUBM) to automatically generate test cases for user-level QoS load testing. SUBM represents realistic user behavior by exploiting user session information taken from server logs. The major contribution of this paper is the fundamental role of user behavioral authenticity in load testing. This paper also illustrates the prototype implementation of our session-based user behavior meta-model.<br/>},
key = {Quality of service},
keywords = {Behavioral research;Decision trees;Information services;Load testing;Service oriented architecture (SOA);},
note = {Production environments;Prototype implementations;Service-oriented computing;Tools and techniques;User behaviors;User sessions;WEB application;Web application testing;},
URL = {http://dx.doi.org/10.4156/jdcta.vol4.issue4.3},
} 


@inproceedings{20164803076440 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research and analysis of GNSS performance test methods},
journal = {Proceedings of the 2016 IEEE 11th Conference on Industrial Electronics and Applications, ICIEA 2016},
author = {He, He and Wang, Ershen and Pang, Tao},
year = {2016},
pages = {2096 - 2100},
address = {Hefei, China},
abstract = {GNSS performance test is necessary at various stages such as initial design, full operational capability and system modernization, and is also the important guarantee of GNSS continuous and reliable operation. At present, China's BeiDou navigation satellite system (BDS) is in the construction stage of developing from the regional navigation system to the global navigation system, which is quite vital to carry out the study on relevant performance test methods. Firstly, this paper systematically studies the GNSS performance test projects carried out in the different stages of development in view of GPS, Galileo and some augmentation systems including WAAS, GBAS, EGNOS. And the test purpose, test content, test method, the experimental reference and test results are analyzed in detailed. Then, based on the status of China's BeiDou navigation satellite system, the related suggestions for performance test methods of BDS are put forward. The study is of great reference value to establishing BDS performance test environment and developing test methods. &copy; 2016 IEEE.},
key = {Global positioning system},
keywords = {Airport ground equipment;Communication satellites;Industrial electronics;Navigation systems;Radio navigation;Satellites;Testing;Tracking (position);},
note = {Augmentation systems;Beidou navigation satellite systems;Full operational capabilities;Global Navigation Satellite Systems;Global navigation system;Performance tests;Research and analysis;Test method;},
URL = {http://dx.doi.org/10.1109/ICIEA.2016.7603935},
} 


@inproceedings{20090311864290 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Ultrasonic diagnostic load testing of steel highway bridges},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Mandracchia, Efrain A.},
volume = {2946},
year = {1996},
pages = {17 - 25},
issn = {0277786X},
address = {Scottsdale, AZ, United states},
abstract = {This paper presents a new product, the SonicForce&trade; Acoustic Strain Gauge (ASG), that utilizes a non-contact ultrasonic technology to measure applied strain requiring no paint removal and minimal surface preparation. After an overview of the ultrasonic technology is presented the results of a diagnostic test utilizing a prototype of the ASG will be discussed. The purpose of this test was to validate the Acoustic Strain Gauge as being functionally equivalent to the resistance strain gauge, and to demonstrate a cost effective enabling technology to the civil and structural engineering communities. The diagnostic tests program was supervised by Dr. Abba Lichtenstein in accordance with accepted guidelines contained in the manual for "Rating Bridges Through Testing" For the purpose of this study the bridge superstructure was modeled and structural loading profiles were determined using both resistive and acoustic strain measurement techniques. Measured strains as determined by the ASG (correlation between the ASG and the resistance strain gauge was 0.998) were compared to theoretical loads in order to determine if the Rodeo Gulch superstructure was operating in a safe and reliable manner. Additionally, under the direction of Phil Fish (Wisconsin DOT), two pre-production ASGs were used to monitor accumulated cyclic loading. These test data presented as a time series strip chart and rainflow histogram. &copy;2005 Copyright SPIE - The International Society for Optical Engineering.<br/>},
key = {Ultrasonic testing},
keywords = {Cost effectiveness;Cost engineering;Highway bridges;Load testing;Nondestructive examination;Program diagnostics;Software testing;Steel testing;Strain;Strain gages;Ultrasonics;},
note = {Applied strain;Bridge diagnostics;Civil and structural engineerings;EMAT;Measurement techniques;Rainflow;Resistance strain gauges;Ultrasonic diagnostics;},
URL = {http://dx.doi.org/10.1117/12.259142},
} 


@article{20142017721083 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Method to prevent the malfunction caused by the Transformer Magnetizing Inrush Current using IEC 61850-based IEDs and dynamic performance test using RTDS test-bed},
journal = {Journal of Electrical Engineering and Technology},
author = {Kang, Hae-Gweon and Song, Un-Sig and Kim, Jin-Ho and Kim, Se-Chang and Park, Jong-Soo and Park, Jong-Eun},
volume = {9},
number = {3},
year = {2014},
pages = {1104 - 1111},
issn = {19750102},
abstract = {The digital substations are being built based on the IEC 61850 network. The cooperation and protection of power system are becoming more intelligent and reliable in the environment of digital substation. This paper proposes a novel method to prevent the malfunction caused by the Transformer Magnetizing Inrush Current(TMIC) using the IEC 61850 based data sharing between the IEDs. To protect a main transformer, the current differential protection(87T) and over-current protection(50/51) are used generally. The 87T IED applies to the second harmonic blocking method to prevent the malfunction caused by the TMIC. However, the 50/51 IED may malfunction caused by the TMIC. To solve that problem, the proposed method uses a GOOSE inter-lock signal between two IEDs. The 87T IED transmits a blocking GOOSE signal to the 50/51 IED, when the TMIC is detected. The proposed method can make a cooperation of digital substation protection system more intelligent. To verify the performance of proposed method, this paper performs the real time test using the RTDS (Real Time Digital Simulator) test-bed. Using the RTDS, the power system transients are simulated, and the TMIC is generated. The performance of proposed method is verified in real-time using that actual current signals. The reaction of simulated power system responding to the operation of IEDs can be also confirmed.<br/>},
key = {Transformer protection},
keywords = {Electric fault currents;Electric power system protection;Electric substations;Electric transformer testing;},
note = {Current differential protection;GOOSE;IEC 61850;Real time digital simulator;Transformer magnetizing;},
URL = {http://dx.doi.org/10.5370/JEET.2014.9.3.1104},
} 


@article{2003127400794 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Dynamic performance test and improvement of static excitation systems for synchronous generators suffering voltage flicker disturbances},
journal = {Journal of the Chinese Institute of Electrical Engineering, Transactions of the Chinese Institute of Engineers, Series E/Chung KuoTien Chi Kung Chieng Hsueh K'an},
author = {Chuang, Yung-Sung and Wu, Chi-Jui and Yen, Shih-Shong and Guo, Tzong-Yih},
volume = {10},
number = {1},
year = {2003},
pages = {83 - 90},
issn = {10234462},
abstract = {In this paper, the dynamic performances of. static excitation systems are examined and improved for synchronous generators suffering disturbances due to voltage flickering. The disturbances to the 161kV bus of the Tong-Shiao Generation Station are caused by the fluctuating reactive power from nearby electric arc furnaces. This also demonstrates the low frequency active power oscillations of generators. It is required that the generators provide enough damping to suppress active power oscillations, in addition to having a fast reactive power response. A field test method with a small step-changing signal was used to reveal the dynamic performance indexes of the generators with static excitation systems at no-load and full-load. Computer time domain simulations and eigenvalue analysis are also employed to explore the effects of loop-gains. The results show that when the loop-gain of an excitation system is higher, there is faster response of reactive power to improve voltage flicker, but also1 more serious low frequency oscillations of active power. Hence, installing a power system stabilizer is evaluated to improve the damping of the electromechanical mode (local mode). This arrangement not only lets the generator acquire damping of active power oscillations but also gives a fast reactive power response to improve voltage flicker.},
key = {Electric excitation},
keywords = {Computer simulation;Damping;Eigenvalues and eigenfunctions;Electric arcs;Electric distortion;Electronic equipment testing;Oscillations;Reactive power;Synchronous generators;Time domain analysis;},
note = {Active power oscillation;Electric arc furnace;Electromechanical mode;Static excitation system;Voltage flickering;},
} 


@inproceedings{20093512276726 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research on dry resistance load test of diesel locomotive for energy saving},
journal = {Asia-Pacific Power and Energy Engineering Conference, APPEEC},
author = {Xiao, Jun and Jiang, Hongxia and Tang, Chunqiu and Mo, Yimin and Xie, Jinfang},
year = {2009},
pages = {Chinese Society for Electrical Engineering; IEEE Power and Energy Society; Scientific Research Publishing; Wuhan University - },
issn = {21574839},
address = {Wuhan, China},
abstract = {A method of dry resistance load test of diesel locomotive is introduced. The electric power generated by a dynamotor, which is driven by the diesel, is converted to DC and consumed on the dry resistances. AS the heat dissipation of the resistances is about several thousand kilowatts, DC motor fans are used for air cooling the resistances. In order to save energy, the energy for driven the motor fans is come from the electric power of the DC power. A constant current speed regulating system for the motor fans is presented, which bases on a kind of high-power switch component (IGBT). The experimental results are discussed. &copy; 2009 IEEE.<br/>},
key = {DC motors},
keywords = {Diesel locomotives;Electric motor generator sets;Energy conservation;Heat resistance;Insulated gate bipolar transistors (IGBT);Pulse width modulation;},
note = {Air cooling;Constant current;Dc power;Electric power;High power switch;Resistance load;Save energy;},
URL = {http://dx.doi.org/10.1109/APPEEC.2009.4918682},
} 


@inproceedings{20133716718139 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A case study of automating user experience-oriented performance testing on smartphones},
journal = {Proceedings - IEEE 6th International Conference on Software Testing, Verification and Validation, ICST 2013},
author = {Canfora, Gerardo and Mercaldo, Francesco and Visaggio, Corrado Aaron and D'Angelo, Mauro and Furno, Antonio and Manganelli, Carminantonio},
year = {2013},
pages = {66 - 69},
address = {Luxembourg, Luxembourg},
abstract = {We have developed a platform named Advanced Test Environment (ATE) for supporting the design and the automatic execution of UX tests for applications running on Android smart phones. The platform collects objective metrics used to estimate the UX. In this paper, we investigate the extent that the metrics captured by ATE are able to approximate the results that are obtained from UX testing with real human users. Our findings suggest that ATE produces UX estimations that are comparable to those reported by human users. We have also compared ATE with three widespread benchmark tools that are commonly used in the industry, and the results show that ATE outperforms these tools. &copy; 2013 IEEE.},
key = {Smartphones},
keywords = {Design;Robots;Software testing;Tools;},
note = {Advanced tests;android;Android smart phones;Mobile applications;Objective metrics;Performance testing;usability;User experience;},
URL = {http://dx.doi.org/10.1109/ICST.2013.16},
} 


@inproceedings{20175104549679 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The design of shield tunnelling machine cutter headers cutting performance test bed},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Zhu, Zongming and Xia, Yimin and Luo, Dezhi and Teng, Tao},
volume = {6424 LNAI},
year = {2010},
pages = {356 - 362},
issn = {03029743},
address = {Shanghai, China},
abstract = {In order to solve the problems of data access and low accuracy on the shield tunnelling machine construction site, a test bed that can simulate the shield tunnelling machine cutter head&rsquo;s cutting performance is designed. The test bed&rsquo;s box uses a fixed cutter head and a turning material bin. The whole configuration is designed to a welding framework. The cutter head is designed to a spoke form. The fixing angle and the distance between different cutters can be adjusted at random. The propelling and loading system of the test bed are controlled in an electro-hydraulic proportional control manner. It can be used to test the single factor and multiple factors that influence the cutter head&rsquo;s cutting performance.<br/> &copy; Springer-Verlag Berlin Heidelberg 2010.},
key = {Tunnels},
keywords = {Cutting tools;Equipment testing;Hydraulic equipment;Hydraulic machinery;Robotics;Testing;Tunneling machines;},
note = {Cutter heads;Cutting performance;Data access;Electro-hydraulic proportional control;Hydraulic system;Loading system;Multiple factors;Shield tunnelling machines;},
URL = {http://dx.doi.org/10.1007/978-3-642-16584-9_34},
} 


@inproceedings{20105213526075 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The design of shield tunnelling machine cutter header's cutting performance test bed},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Zhu, Zongming and Xia, Yimin and Luo, Dezhi and Teng, Tao},
volume = {6424 LNAI},
number = {PART 1},
year = {2010},
pages = {356 - 362},
issn = {03029743},
abstract = {In order to solve the problems of data access and low accuracy on the shield tunnelling machine construction site, a test bed that can simulate the shield tunnelling machine cutter head's cutting performance is designed. The test bed's box uses a fixed cutter head and a turning material bin. The whole configuration is designed to a welding framework. The cutter head is designed to a spoke form. The fixing angle and the distance between different cutters can be adjusted at random. The propelling and loading system of the test bed are controlled in an electro-hydraulic proportional control manner. It can be used to test the single factor and multiple factors that influence the cutter head's cutting performance. &copy; 2010 Springer-Verlag.<br/>},
key = {Tunnels},
keywords = {Cutting tools;Equipment testing;Hydraulic equipment;Hydraulic machinery;Tunneling machines;},
note = {Cutter heads;Cutting performance;Data access;Electro-hydraulic proportional control;Hydraulic system;Loading system;Multiple factors;Shield tunnelling machines;},
URL = {http://dx.doi.org/10.1007/978-3-642-16584-9_34},
} 


@inproceedings{20144400131449 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Partial load test protocol, a way to move ahead for efficiency measurement in transport refrigeration},
journal = {Refrigeration Science and Technology},
author = {Stumpf, A. and Chakiachvili, B.},
year = {2014},
pages = {590 - 597},
issn = {01511637},
address = {London, United kingdom},
abstract = {Fuel burn, or energy consumption, impacts the environment as well as the profitability of the European road transport refrigeration sector and is of significant importance. Several approaches to establish regulations in this area demonstrate that there is a lack of necessary test data. In this paper we will address the relationship between the energy efficiency and the energy consumption of the transport refrigeration unit. At present for these types of systems, the use of official ATP test data established under controlled ambient temperature according to the ATP rules (an international agreement for transport of perishable foodstuffs supported by the United Nations), can give only a partial answer regarding the energy efficiency of the marketed products. This test protocol measures the fuel burn of the refrigeration unit in steady state conditions, which are considered very close to full load data. But full load test data appears only when the refrigeration unit is pulling down the inside air temperature of the trailer or box, or during the delivery cycle, when the refrigeration unit has to cool down the ambient air that entered into the trailer body during multiple door openings. The temperature recorded in actual usage demonstrates that for most of the time, the transport refrigeration system operates in partial load to compensate only for the thermal losses of the trailer body. Based on new standards already in development in Europe, this paper will explain how partial load tests can be performed in standard calorimeter tests rooms, and will present data obtained from independent and dependent refrigeration units. The limits of the usage of this data for modeling the global energy consumption of the refrigerated truck or trailer will be highlighted.<br/>},
key = {Energy efficiency},
keywords = {Chains;Energy utilization;IIR filters;Refrigeration;Sustainable development;Testing;Truck transportation;Trucks;},
note = {Air temperature;Efficiency measurement;Perishable foodstuffs;Refrigeration system;Road transports;Steady-state condition;Test protocols;United Nations;},
} 


@inproceedings{1987010014236 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {OVERVIEW OF THE NEW ASME PERFORMANCE TEST CODE FOR WIND TURBINES.},
journal = {American Society of Mechanical Engineers (Paper)},
author = {Spera, David A.},
year = {1986},
pages = {ASME, New York, NY, USA; IEEE, New York, NY, USA - },
issn = {04021215},
address = {Portland, OR, USA},
abstract = {This paper presents the principal technical features of the code and discusses the various issues which the committee was required to resolve, such as what sizes and types of wind turbines should be included, what the principal measure of performance should be, and how wind speed should be measured. Test measurement requirements are given, and a sample performance test is used to illustrate the application of recommended testing and data analysis procedures.},
key = {WIND TURBINES},
keywords = {ANEMOMETERS;TURBOMACHINERY - Performance;},
note = {AIR DENSITY DIFFERENCES EFFECT;ANEMOMETER CORRELATION TEST;ASME PERFORMANCE TEST CODE;GENERATOR OUTPUT POWER;WIND SPEED MEASUREMENTS;},
} 


@article{20081711209748 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing: Evaluating an RFID library inventory reader},
journal = {International Journal of Internet Protocol Technology},
author = {Golding, Paul and Tennant, Vanesa},
volume = {2},
number = {3-4},
year = {2007},
pages = {240 - 251},
issn = {17438209},
abstract = {Numerous studies have been performed in supply chain environments to determine the performance requirement to achieve a near 100% read rate. However the literature on testing in the library environment is sparse. This study examines the operational efficiencies of a RFID library reader. The factors examined included angle directionality sensitivity, read distance and tag location. The findings suggested that the performance of the inventory system degrades significantly as the angle directionality moves from 0 to 60 degrees. The read distance varied from vendor specification. The findings provide empirical insight into the performance of an RFID reader in an operating environment. &copy; 2007, Inderscience Publishers.},
key = {Libraries},
keywords = {Data warehouses;Inventory control;Radio frequency identification (RFID);Sensitivity analysis;},
note = {Library inventory reader;Library system;},
URL = {http://dx.doi.org/10.1504/IJIPT.2007.016224},
} 


@inproceedings{1995122539885 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Condenser and feedwater heater computerized performance testing and diagnostic programs},
journal = {American Society of Mechanical Engineers, Power Division (Publication) PWR},
author = {Diaz-Tous, I.A. and Mateos, M.A.},
volume = {25},
year = {1994},
pages = {165 - 172},
address = {Phoenix, AZ, USA},
abstract = {Accurate interpretation of performance-test results can lead to improved unit heat-rate and reduced equipment failure or damage when appropriate and timely corrective actions are taken. Aware of the difficulties inherent in performance testing as well as the need for a PC-based tool to support performance engineers in power plant problem diagnosis, NYSEG and ENCOR commenced developing (in 1990) the Computerized Performance Test Program (CPTP). CPTP is designed to ease performance testing, enhance the quality of performance-test results and provide correct diagnostics and recommendations for actions to the performance-test engineer and power-operations management. To accomplish these goals, CPTP utilizes expert algorithms based on the years of experience accumulated by the engineering staffs at NYSEG and ENCOR. Such experience is demonstrated by the extensive guidance provided by CPTP regarding the prioritization of equipment testing and the preparation and execution of the proper test procedures. Equally insightful are the interpretation of the test results and the corrective actions prescribed to solve diagnosed problems. For all these reasons, CPTP is an effective training tool for plant personnel to improve the performance of the condenser and feedwater heaters and plan the maintenance of any power plant. Currently, NYSEG and Portland General Electric (PGE) are using CPTP modules for performance testing, diagnostic and training purposes.},
key = {Feedwater heaters},
keywords = {Algorithms;Computer aided analysis;Computer software;Condensers (liquefiers);Performance;},
note = {Computerized performance test program (CTCP);Diagnostic programs;},
} 


@inproceedings{20130215873091 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A thermal stress test of the depth-graded Pt/C Re ectors used in the ASTRO-H hard x-ray telescope (HXT)},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Maeda, Yoshitomo and Ichihara, Kou and Shionome, Yu and Sato, Takuro and Hayashi, Takayuki and Ishida, Manabu and Kan, Hiroaki and Namba, Yoshiharu and Takahashi, HIdeaki and Miyazawa, Takuya and Ishibashi, Kazunori and Sakai, MIchito and Sugita, Satoshi and Haba, Yoshito and Matsumoto, Hironori and Mori, Hideyuki},
volume = {8443},
year = {2012},
pages = {The Society of Photo-Optical Instrumentation Engineers (SPIE) - },
issn = {0277786X},
address = {Amsterdam, Netherlands},
abstract = {The ASTRO-H Hard X-ray Telescope (HXT) to cover hard X-rays up to 80 keV is thin-foil, multi-nested conical optics with depth-graded Pt/C multilayer. The reflectors are made of heat-formed aluminum substrate of the thickness gauged of 200 m of the alloy 5052, followed by epoxy replication on Pt/C-sputtered smooth Pyrex cylindrical mandrels to acquire the X-ray reflective surface. The epoxy layer is 20 m depth. In this paper, we report a thermal stress test of the reflectors of the HXT. The reflectors can experience in various temperature environment either in ground or in space. The temperature range can be as wide as several tens degrees in space dependently on the thermal design of the telescope system. We kept the reflectors in the three different temperatures at 5, 50 and 60 degrees, respectively, for a week. It is found that the surface of the reflectors at 60 degrees or higher temperature were significantly changed. The change appears as wrinkles with a typical scale length of a few tens micron meters. It is noticed that the scale length is equivalent to the depth of the epoxy layer, suggesting the existence of the epoxy layer causes the change in the scale length. No changes on the surface were observed from the 5 and 50 degree samples. No change on X-ray reflectivity was also detected from them. &copy; 2012 SPIE.},
key = {X rays},
keywords = {Aluminum;Gamma rays;Platinum alloys;Reflection;Space telescopes;Thermal stress;},
note = {Aluminum substrate;ASTRO-H;Cylindrical mandrel;Epoxy layers;Hard X ray;Hard X-ray telescope;Scale length;Telescope system;Temperature range;Thermal designs;Typical scale;X ray reflectivity;X-ray reflective;},
URL = {http://dx.doi.org/10.1117/12.925847},
} 


@inproceedings{20105013478813 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Scenario-based approach for blackbox load testing of online game servers},
journal = {Proceedings - 2010 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery, CyberC 2010},
author = {Cho, Chang-Sik and Lee, Dong-Chun and Sohn, Kang-Min and Park, Chang-Joon and Kang, Ji-Hoon},
year = {2010},
pages = {259 - 265},
abstract = {Simply having a large beta test cannot consistently provide stability and performance to game servers, which are major issues in online game development. Therefore, test automations have been used in order to reduce the testing time of online games by simulating highly repetitive tasks and emulating server loads. However, in previous approaches, blackbox testing and scenario-based testing are not supported because they use prerecorded packets of real players as templates, or reuse a subset of the main game client for the test client. In this paper, we propose blackbox testing and scenario-based testing of online games as well as simple load testing. Instead of rewriting the virtual client dummy code, only the game description language and virtual game map are redefined when a new game is to be tested. In addition, an actual testing environment can be mimicked more closely, because complex and various scenarios such as attack, party play, and waypoint movement can be tested through combining actions. We have applied our tools on several online games to verify the effectiveness of our method. &copy; 2010 IEEE.<br/>},
key = {Black-box testing},
keywords = {Computer aided software engineering;Distributed computer systems;Load testing;Social networking (online);Software design;},
note = {Description languages;On-line games;Scenario-based testing;Virtual games;Virtual users;},
URL = {http://dx.doi.org/10.1109/CyberC.2010.54},
} 


@inproceedings{20153401193532 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing program design and assessment methods of small arms},
journal = {2015 5th International Workshop on Computer Science and Engineering: Information Processing and Control Engineering, WCSE 2015-IPCE},
author = {Zhang, Junbin and Huang, Xueying and Ma, Li and Xu, Youliang and Li, Hongkui},
year = {2015},
address = {Moscow, Russia},
abstract = {In this paper, a comprehensive identification on the overall performance of light weapons is as a starting point, and it proposed simulated combat background, operational performance testing program of light weapons with a typical combat mission, and to build simulated battlefield environment and simulate human testing apparatus to establish methods are discussed, proposed the construction methods and technical approach. On the basis of analysis of the various performance evaluation methods, mathematical model of light weapons and tactical performance test evaluation is established.},
key = {Software testing},
keywords = {Testing;},
note = {Battlefield environments;Construction method;Environment simulation;Evaluation methods;Operational performance;Performance testing;Performance tests;Small arms;},
} 


@inproceedings{2004278245939 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Hierarchical extreme-voltage stress test of analog CMOS ICs for gate-oxide reliability enhancement},
journal = {Proceedings of the ACM Great Lakes Symposium on VLSI},
author = {Wey, Chin-Long and Khalil, M.A. and Liu, Jim and Wierzba, Gregory},
year = {2004},
pages = {322 - 327},
address = {Boston, MA, United states},
abstract = {Yield and reliability are two factors affecting the profitability of semiconductor manufacturing. High-temperature burn-in and extreme-voltage stress tests are two current industrial standard methods to speed up the deterioration of electronic devices and weed-out infant mortality. Extreme-voltage stress test aims at enhancing both quality and reliability without performance the high-cost burn-in test process. Our recent stress tests of analog/mixed-signal CMOS ICs for gate-oxide reliability enhance. This paper presents a control flow model for analog CMOS circuits and uses it to develop a circuit partition scheme. A practically large analog circuit can be partitioned into many smaller sub-circuits so that the developed stress vector generator and stressability analyzer can conformably handle in term of computational complexity. In addition, a structure-based stress vector generation process is also developed. Stress vectors are generated based on the circuit topological structure without performing circuit simulations. The performance improvement proposed in this study can significantly reduce the computational complexity so that the developed stress test system can handle practically large analog CMOS circuits.},
key = {CMOS integrated circuits},
keywords = {Built-in self test;Computer simulation;Deterioration;Electric potential;High temperature effects;Reliability;Semiconductor materials;Stress analysis;Topology;Vector quantization;},
note = {Extreme-voltage;Gate-oxide;IC reliability;Stress test;},
URL = {http://dx.doi.org/10.1145/988952.989030},
} 


@inproceedings{1994091352646 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Formulation to optimize stress testing},
journal = {Proceedings - Electronic Components and Technology Conference},
author = {Chan, H.Anthony},
year = {1994},
pages = {1020 - 1027},
issn = {05695503},
address = {Washington, DC, USA},
abstract = {Although hard-defects may be detectable in factory tests, weak products may exhibit failures or degrade only under certain stress conditions. Without stress testing, these weak products may often be shipped to customers causing early failures in the field. A candidate product for stress testing needs to get more business benefits to more than pay off the cost of stress testing. A business measure of the success of the stress testing program is the net benefit, which is the total benefit minus the total cost of the program. The optimum stress testing program maximizes this net benefit. A given unit of a product has a probability of encountering a maximum stress X during its product life. It also has a probability of possessing a product yield strength Y, which is the maximum stress the unit can survive without failure. While the strength distribution depends on the design and manufacture processes, the distribution of the maximum stress is determined by the customers' environment. A convenient picture is to construct the contour map of the joint probability distribution of X and Y. In this contour map, a unit falling in the Y &lt; X region will fail during its product life, whereas one falling in the Y &gt; X region will not result in field failure. The effects of stress testing at a given maximum stress level, X<sup>ST</sup>, are shown by a dividing line on the product strength into stress test failure and stress test pass. The units in the contour map are then divided into four regions by the Y = X line and the X<sup>ST</sup> line. The cost and benefits may now be evaluated for each region. Now the value of X<sup>ST</sup> is a free parameter that determines the relative size of each region. The second free parameter is the fraction of units going through stress testing. These two parameters may be adjusted to maximize the net benefit of the stress testing program.},
key = {Stress analysis},
keywords = {Computer software;Electron device testing;Failure (mechanical);Mathematical models;Optimization;Product design;Reliability;Robustness (control systems);},
note = {Contour maps;Operator model;Product reliability;Product robustness;Product yield strength;Stress testing;},
} 


@inproceedings{20071310512266 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Results of the MACT comprehensive performance test of the DOE Oak Ridge TSCA incinerator},
journal = {A and WM, Annual International Conference on Incineration and Thermal Treatment Technologies, IT3},
author = {Perez, Fidel and Dunn, Jim and Jackson, Kevin and Swientoniewski, Mark},
volume = {1},
year = {2006},
pages = {62 - 76},
address = {Savannah, GA, United states},
abstract = {A Maximum Achievable Control Technology (MACT) Comprehensive Performance Test (CPT) was performed at the dual-purpose Resource Conservation and Recovery Act (RCRA) and Toxic Substances Control Act (TSCA) Incinerator (TSCAI), located at the U.S. Department of Energy (DOE) East Tennessee Technology Park (ETTP) in Oak Ridge, Tennessee. Bechtel Jacobs Company, LLC (BJC) is the environmental management contractor for the DOE Oak Ridge Operations Office. The Shaw Group operates and maintains the incinerator under subcontract to BJC. The TSCAI is designed and permitted to thermally treat radioactively contaminated TSCA (polychlorinated biphenyls (PCBs)) and RCRA hazardous wastes. The incinerator consists of a rotary kiln and a secondary combustion chamber followed by a wet off-gas cleaning system. The off-gas cleaning system includes a; quench chamber, venturi scrubber, packed bed scrubber, dual ionizing wet scrubbers (IWS) in series, induced draft fan, and exhaust stack. Pre-testing was conducted in December 2004, and the CPT was conducted in March 2005. The Shaw Group performed sampling, analysis, and reporting of the CPT results. Emissions were sampled and analyzed for semi-volatile metals (SVM) (Cadmium [Cd] and Lead [Pb]), low volatile metals (LVM) (Arsenic [As], Beryllium [Be], and Chromium [Cr]), Principal Organic Hazardous Constituents (POHCs) (1, 2, 4-trichlorobenzene [TCB] and carbon tetrachloride [CCl<inf>4</inf>]), particulate matter (PM), and total hydrocarbons (THC). Based on the results of the 2001 RCRA Trial Burn Report, a data-in-lieu-of approval was obtained for dioxins/furans, mercury, and hydrogen chloride / chlorine (HCl/Cl<inf>2</inf>). Carbon monoxide (CO), oxygen (O <inf>2</inf>), and carbon dioxide were analyzed using permanent continuous emissions monitors (CEMS), with THC analyzed using a temporary CEMS analyzer. During the test program, materials were spiked into containerized solid waste feeds and directly into the liquid waste feed lines and included TCB, CCl <inf>4</inf>, ash (titanium dioxide [TiO<inf>2</inf>]), arsenic, cadmium, chromium, and lead. Incinerator feed consisted of solids, organic liquids, and aqueous waste streams. All CPT performance objectives were met. In addition, a permanent continuous particulate emission monitoring system was utilized as a process indicator and tool for the real time adjustment of process conditions. Data were obtained and are presented comparing the Method 5 particulate emission results with the output from the particulate emission monitoring system.},
key = {Refuse incinerators},
keywords = {Cadmium;Hazardous materials;Heat treatment;Lead;Particulate emissions;Polychlorinated biphenyls;},
note = {Liquid waste feed lines;Particulate emission monitoring;Process indicator;},
} 


@inproceedings{20162302469145 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Cloud-based load testing method for web services with VMs management},
journal = {Conference Proceedings of 2015 2nd International Conference on Knowledge-Based Engineering and Innovation, KBEI 2015},
author = {Shojaee, Aida and Agheli, Nafiseh and Hosseini, Bahareh},
year = {2015},
pages = {170 - 176},
address = {Tehran, Iran},
abstract = {Due to the increased loading the large number of users connected to pervasive web services during the past decade, their load testing and providing the needed resources in low time and cost, requires more attention. In this context cloud computing technology offers new ideas to solve such problems and has reduced the concern of large and complex testing systems. In this research in order to improve the quality and performance of web applications load testing, we proposed a method for web applications load testing based on cloud computing. The proposed method uses the existing facilities in the cloud including pool of computing resources without initial cost, unlimited data storage and cloud computing managerial procedures, containing the actual load generating and multi-user concurrency testing, that lead to improved load testing flexibility, time and operational costs. Moreover, in this load testing method, in order to manage resources and virtual machines, significant improvement is achieved by use of appropriate allocation, reducing performance and unnecessary migration avoiding methods. Through evaluation section of the proposed method through a simulated test environment, it is shown that cloud-based load testing in comparison with traditional methods of load testing, improves factors such as effort, cost and time. &copy; 2015 IEEE.},
key = {Load testing},
keywords = {Cloud computing;Costs;Digital storage;Distributed computer systems;Engineering research;Knowledge based systems;Testing;Web services;Websites;World Wide Web;},
note = {Cloud computing technologies;Complex testing;Computing resource;Load generating;Simulated tests;Testing method;Virtual machines;WEB application;},
URL = {http://dx.doi.org/10.1109/KBEI.2015.7436040},
} 


@article{20152200892997 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Field-to-fuel performance testing of lignocellulosic feedstocks: An integrated study of the fast pyrolysis-hydrotreating pathway},
journal = {Energy and Fuels},
author = {Howe, Daniel and Westover, Tyler and Carpenter, Daniel and Santosa, Daniel and Emerson, Rachel and Deutch, Steve and Starace, Anne and Kutnyakov, Igor and Lukins, Craig},
volume = {29},
number = {5},
year = {2015},
pages = {3188 - 3197},
issn = {08870624},
abstract = {Feedstock composition can affect final fuel yields and quality for the fast pyrolysis and hydrotreatment upgrading pathway. However, previous studies have focused on individual unit operations rather than the integrated system. In this study, a suite of six pure lignocellulosic feedstocks (clean (no bark) pine, whole-tree (including bark) pine, tulip poplar, hybrid poplar, switchgrass, and corn stover) and two blends (equal weight percentages whole-tree pine/tulip poplar/switchgrass and whole-tree pine/clean pine/hybrid poplar) were prepared and characterized. These materials then underwent fast pyrolysis and hydrotreatment. Although some feedstocks showed a high fast pyrolysis bio-oil yield, such as tulip poplar at 60%, high yields in the hydrotreater were not always observed. Results showed overall fuel yields of 17% (switchgrass), 20% (corn stover), 24% (tulip poplar, blend 1, blend 2), 25% (whole-tree pine, hybrid poplar), and 27% (clean pine). Simulated distillation of the upgraded oils indicated that the gasoline fraction varied from 39% (clean pine) to 51% (corn stover), while the diesel fraction ranged from 40% (corn stover) to 46% (tulip poplar). Little variation was seen in the jet fuel fraction at 11-12%. Hydrogen consumption during hydrotreating, a major factor in the economic feasibility of the integrated process, ranged from 0.051 g/g dry feed (tulip poplar) to 0.070 g/g dry feed (clean pine). &copy; 2015 American Chemical Society.},
key = {Fuels},
keywords = {Distillation;Feedstocks;Forestry;Plants (botany);},
note = {Economic feasibilities;Fast pyrolysis bio-oil;Gasoline fractions;Hydrogen consumption;Integrated systems;Lignocellulosic feedstocks;Simulated distillation;Weight percentages;},
URL = {http://dx.doi.org/10.1021/acs.energyfuels.5b00304},
} 


@inproceedings{20141217470396 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The performance test of heat exchanger under low-temperature frosting conditions},
journal = {International Conference on Advanced Mechatronic Systems, ICAMechS},
author = {Wang, Zhiyuan and Tong, Zhiwen},
year = {2013},
pages = {286 - 289},
issn = {23250682},
address = {Luoyang, China},
abstract = {The heat exchanger performance test bench under the frosting condition has been designed and structured, and the various parameters measuring instrument and sensor have been installed. The test bench consists of refrigeration cycle and air duct cycle which can simulate low temperature condition. With the assistance of C# programming language and.NET Framework, a multi-function remote measurement and control system is developed, which can be used for environmental simulation, data acquisition, display and data processing, real-time curve and video display. The performance test of heat exchanger under different conditions could be completed by the test system. The influence of external environment factors on the heat exchanger under frosting condition can be studied. This test system could provide more experimental reference and calculation basis for the study of heat exchanger under frosting condition at low temperature. &copy; 2013 IEEE.<br/>},
key = {Temperature},
keywords = {Data acquisition;Data handling;Heat exchangers;Refrigeration;},
note = {Environmental simulation;External environments;Heat exchanger performance;Low temperature conditions;Low temperatures;Measuring instruments;Performance tests;Refrigeration cycles;},
URL = {http://dx.doi.org/10.1109/ICAMechS.2013.6681795},
} 


@article{20154401479049 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Development of a performance test protocol for corrosion prevention compounds for aircraft},
journal = {ProQuest Dissertations and Theses Global},
author = {Gui, Feng},
year = {2006},
abstract = {In the application of corrosion prevention compounds (CPCs), two prime challenges are the lack of a means of performance evaluation and the understanding of the critical properties for the effective protection. This research attempted to investigate those key properties and their influence on CPCs' performance. One result was the development of a suite of test methods to assess performance and key properties. CPCs' performance on AA7075-T6 was assessed with electrochemical impedance spectroscopy (EIS). Excellent protection was exhibited by CPC-coated surfaces with interfacial impedances above 0.1 Mohms-cm2 or double layer capacitances below 7.6 x 10-8 F/cm 2. In addition, a prediction method was demonstrated based on impedance parameters that showed the feasibility of using data from less than 50 days of exposure to predict the performance after 180 days of exposure. CPCs provided protection mainly through the formation and maintenance of barrier film. The failure of CPCs is mainly driven by the defects present in the film and at the film/substrate interface. The free energies for the water displacement process indicated that all CPCs could displace water from both pristine and mildly corroded surfaces. However, severely corroded surfaces were found to be more compatible with water so that CPCs cannot displace water from such surfaces. Wicking rates were determined in-situ using fiber optic sensors assembled into simulated lap joints. All tested CPCs demonstrated the ability to wick into occluded regions albeit at varied rates. The wicking rates were substantially smaller when water was present in the occluded regions. The gap of the joint had a strong effect on the wicking kinetics of water and CPCs. For vertically-oriented samples, wicking was slower in tight lap structures and increased with increasing gap to a maximum and then decreased with further increases in gap. No maximum was observed for horizontally-oriented crevices. A simulation of the wicking kinetics was presented. The simulation reproduced the trend of the changes of wicking kinetics with crevice gap that was obtained from experiment. Among the properties that were investigated through the simulation, the viscosity had the dominant effect on wicking kinetics. CPCs with smaller viscosity have faster wicking rates. ProQuest Subject Headings: Materials science.  &copy; Citation reproduced with permission of ProQuest LLC.},
key = {Fighter aircraft},
keywords = {Corrosion;Corrosion prevention;Electrochemical corrosion;Electrochemical impedance spectroscopy;Fiber optic sensors;Interfaces (materials);Kinetics;Viscosity;},
note = {Corrosion prevention compounds;Critical properties;Double-layer capacitance;Film/substrate interface;Impedance parameters;Interfacial impedance;Prediction methods;Water displacement process;},
} 


@inproceedings{20134616964617 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A formal passive performance testing approach for distributed communication systems},
journal = {ENASE 2013 - Proceedings of the 8th International Conference on Evaluation of Novel Approaches to Software Engineering},
author = {Che, Xiaoping and Maag, Stephane},
year = {2013},
pages = {74 - 84},
address = {Angers, France},
abstract = {Conformance testing of communicating protocols is a functional test which verifies whether the behaviors of the protocol satisfy defined requirements, while the performance testing of communicating protocols is a qualitative and quantitative test, aiming at checking whether the performance requirements of the protocol have been satisfied under certain conditions. It raises the interesting issue of converging these two kinds of tests by using the same formal approach. In this paper, we present a novel logic-based approach to test the protocol performance through real execution traces and formally specified properties. In order to evaluate and assess our methodology, we have developed a prototype and present experiments with a set of IMS/SIP properties. Finally, the relevant verdicts and discussions are provided. Copyright &copy; 2013 SCITEPRESS.},
key = {Software engineering},
keywords = {Engineering;Formal methods;Industrial engineering;},
note = {Communicating protocols;Conformance testing;Distributed communication systems;Distributed framework;Logic-based approach;Performance requirements;Performance testing;Protocol performance;},
} 


@inproceedings{20091412001064 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Thermal performance testing of cryogenic insulation systems},
journal = {Proceedings of the 29th International Thermal Conductivity Conference, ITCC29 and the Proceedings of the 17th International Thermal Expansion Symposium, ITES17},
author = {Fesmire, J.E. and Augustynowicz, S.D. and Scholtens, B.E. and Heckle, K.W.},
year = {2008},
pages = {387 - 396},
address = {Birmingham, AL, United states},
abstract = {Efficient ways to characterize thermal performance of materials under cryogenic and vacuum conditions have been developed. These methods provide thermal conductivity data on materials under actual-use conditions and complement established methods. The actual-use environment of a large temperature difference across the insulation in combination with vacuum pressure is essential for understanding how insulation systems perform. Test articles include solids, foams, powders, layered blankets, and composite panels. Test methodology and apparatus design for several insulation test cryostats are discussed. The measurement principle is liquid nitrogen boiloff calorimetry. Heat flux capability ranges from about 0.5 to 500 W/m2; corresponding apparent thermal conductivity values range from below 0.01 up to about 60 mW/m-K. Example data for different insulation materials are also presented. After further work to standardize test methods, these patented insulation test cryostats can be used in a wide range of industrial applications.<br/>},
key = {Thermal conductivity},
keywords = {Cryostats;Foams;Heat flux;Tapes;Testing;Thermal expansion;Thermal insulation;Vacuum applications;},
note = {Apparent thermal conductivity;Boil-off calorimetries;Cryogenic insulations;Insulation materials;Insulation system;Temperature differences;Thermal Performance;Thermal performance testing;},
} 


@article{20081911237490 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Virtual stress testing machine and the cyber-infrastructure},
journal = {Engineering with Computers},
author = {Harris, R. and Impelluso, T.},
volume = {24},
number = {2},
year = {2008},
pages = {107 - 117},
issn = {01770667},
abstract = {The virtual stress testing machine (VSTM) project demonstrates the use of the cyber-infrastructure to integrate the algorithms of computational mechanics and supplement virtual environments with physics. The VSTM is not a tool, nor is it intended to be; rather it is a pedagogical presentation of new research paradigms that should be comprehensible to mechanical engineers. VSTM encompasses a real stress testing machine, a virtual stress-testing machine, and a server that initiates and regulates all component physics and visualization processes the server also controls the real Instron. A series of benchmark tests were conducted for analysis of reliability and to demonstrate how such tests can and should be conducted so as to foster communication between mechanical engineers and their colleagues across disciplines. These tests have demonstrated the concept of creating a physics-based virtual environment by revealing both the accuracy and real-time functionality of the simulation. The tests also exposed some system vulnerabilities in network communication and remote memory access processes. VSTM provides a description for mechanical engineers, of the necessary core network technologies needed to solve mechanics problems in new ways and join the community of computer scientists already at work in this arena. &copy; Springer-Verlag London Limited 2007.},
key = {Virtual reality},
keywords = {Client server computer systems;Computational mechanics;Computer simulation;Visualization;},
note = {Cyber infrastructure;Virtual stress testing machine;},
URL = {http://dx.doi.org/10.1007/s00366-007-0077-7},
} 


@inproceedings{20144900288082 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Green propellant infusion mission thruster performance testing for plume diagnostics},
journal = {50th AIAA/ASME/SAE/ASEE Joint Propulsion Conference 2014},
author = {Deans, Matthew C. and Reed, Brian D. and Arrington, Lynn A. and Williams, George J. and Kojima, Jun J. and Kinzbach, McKenzie I. and McLean, Christopher H.},
year = {2014},
address = {Cleveland, OH, United states},
abstract = {The Green Propellant Infusion Mission (GPIM) is sponsored by NASA&rsquo;s Space Technology Mission Directorate (STMD) Technology Demonstration Mission (TDM) office. The goal of GPIM is to advance the technology readiness level of a green propulsion system, specifically, one using the monopropellant, AF-M315E, by demonstrating ground handling, spacecraft processing, and on-orbit operations. One of the risks identified for GPIM is potential contamination of sensitive spacecraft surfaces from the effluents in the plumes of AF-M315E thrusters. NASA Glenn Research Center (GRC) is conducting activities to characterize the effects of AF-M315E plume impingement and deposition. GRC has established individual plume models of the 22-N and 1-N thrusters that will be used on the GPIM spacecraft. The model simulations will be correlated with plume measurement data from Laboratory and Engineering Model 22-N, AF-M315E thrusters. The thrusters are currently being tested in a small rocket, altitude facility at NASA GRC. A suite of diagnostics, including Raman spectroscopy, Rayleigh spectroscopy, and Schlieren imaging are being used to acquire plume measurements of AF-M315E thrusters. Plume data will include temperature, velocity, relative density, and species concentration. The plume measurement data will be compared to the corresponding simulations of the plume model. The GRC effort will establish a data set of AF-M315E plume measurements and a plume model that can be used for future AF-M315E applications.<br/> &copy; 2014 by the American Institute of Aeronautics and Astronautics, Inc. All rights reserved.},
key = {Spacecraft propulsion},
keywords = {NASA;Orbits;Propellants;Rockets;Space flight;},
note = {Engineering modeling;Green propellants;Rayleigh spectroscopy;Space technologies;Spacecraft surfaces;Species concentration;Technology readiness levels;Thruster performance;},
URL = {http://dx.doi.org/10.2514/6.2014-3483},
} 


@article{1997303679105 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Modern technique of transportation simulation for package performance testing},
journal = {Packaging Technology and Science},
author = {Sek, Michael A.},
volume = {9},
number = {6},
year = {1996},
pages = {327 - 343},
issn = {08943214},
abstract = {The paper reviews some of the current methods and proposes a new concept of assessment of hazards in road transportation and their physical simulation in the laboratory. In contrast to the standard approach in which acceleration is the primary data, the new method depends on a knowledge of road profile (roughness) and a numerical simulation model of the interactions between road and vehicle. Monitoring the transportation environment will consist of sampling the vehicle speed and simultaneously tracking its route by means of a GPS device.},
key = {Packaging},
keywords = {Computer simulation;Freight transportation;Global positioning system;Roads and streets;Surface roughness;Tracking (position);Vehicles;},
note = {Package testing;Road roughness;Road transportation simulation;},
URL = {http://dx.doi.org/10.1002/(SICI)1099-1522(199612)9:6<327::AID-PTS375>3.0.CO;2-U},
} 


@inproceedings{1987070116869 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {ASPECTS OF SEAL PERFORMANCE TESTING.},
author = {Herraty, A.G. and De Blic, E.},
year = {1984},
pages = {15 - 21},
address = {London, Engl},
abstract = {Rolling bearings function correctly only when they operate with an adequate and clean lubricant supply. Sealing of a bearing from the environment is thus essential in many applications to avoid contamination of the lubricant and resulting premature failure. This paper describes the specific performance parameters which are normally studied in the development of seals for greased rolling bearings. Particular attention is given to integral seals for deep groove ball bearing units. The test and monitoring equipment used is also described.},
key = {SEALS},
keywords = {BEARINGS - Seals;LUBRICATION - Monitoring;},
note = {CRITICAL ENVIRONMENTAL CONDITIONS;FAILURE DETECTION SYSTEM;INTEGRAL SEALS;},
} 


@inproceedings{20181705041224 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Discussion of the quality control and performance testing of ultrasound diagnostic equipment},
journal = {IOP Conference Series: Earth and Environmental Science},
author = {Jiang, Junjie},
volume = {128},
number = {1},
year = {2018},
issn = {17551307},
address = {Beijing, China},
abstract = {In recent years, with the rapid development of ultrasonography, the application and popularization of new technology used in ultrasound equipment, the level of providing diagnostic information for doctors enhances unceasingly, which has become the indispensable diagnostic tool for medical institutions. The performance of equipment is directly related to the doctor's diagnosis and the patient's health, therefore, it is very important to choose a good method for quality control and performance testing.<br/> &copy; Published under licence by IOP Publishing Ltd.},
key = {Quality control},
keywords = {Diagnosis;Ultrasonics;},
note = {Diagnostic equipment;Diagnostic tools;Good methods;Medical institutions;New technologies;Performance testing;},
URL = {http://dx.doi.org/10.1088/1755-1315/128/1/012118},
} 


@inproceedings{20121915009843 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Configuration and performance testing of IEC 61850 GOOSE},
journal = {APAP 2011 - Proceedings: 2011 International Conference on Advanced Power System Automation and Protection},
author = {Sidhu, Tarlochan and Kanabar, Mitalkumar and Parikh, Palak},
volume = {2},
year = {2011},
pages = {1384 - 1389},
address = {Beijing, China},
abstract = {The IEC 61850 standard part 8-1 proposes Generic Object Oriented Substation Event (GOOSE) message for time critical applications over the Ethernet network. In order to cover the wide range of applications and achieve flexibility in implementation, GOOSE messages are kept generic in the standard. However, this flexibility leads to configuration problem achieving multi-vendor interoperability. Therefore, some efforts have been carried out in this work to present a systematic GOOSE configuration approach, as well as, verification and performance testing of the GOOSE. First part of this paper configuration of Ethernet switched network, including IEEE 1588 based time synchronization, Rapid Spanning Tree Protocol (RSTP), and IEEE 802.1Q based Quality of Services (QoS). In the second part, the paper leads to step-by-step configuration process comprising IEC 61850 data modeling, datasets of GOOSE within individual IEDs, and system integration of GOOSE. Finally, the verification of configured GOOSE messages is presented using network analyzer tools, and performance testing time delay) over the network is carried out for various network scenarios. &copy; 2011 IEEE.<br/>},
key = {Electric power system protection},
keywords = {Electric substations;Ethernet;IEEE Standards;Network protocols;Office automation;Switching networks;},
note = {Configuration process;Ethernet switched networks;Generic object oriented sub-station events;GOOSE;IEC 61850;Rapid spanning tree protocol;Substation Automation Systems;Time-critical applications;},
URL = {http://dx.doi.org/10.1109/APAP.2011.6180593},
} 


@article{20162802580371 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and performance testing of an avalanche photodiode receiver with multiplication gain control algorithm for intersatellite laser communication},
journal = {Optical Engineering},
author = {Yu, Xiaonan and Tong, Shoufeng and Dong, Yan and Song, Yansong and Hao, Shicong and Lu, Jing},
volume = {55},
number = {6},
year = {2016},
issn = {00913286},
abstract = {An avalanche photodiode (APD) receiver for intersatellite laser communication links is proposed and its performance is experimentally demonstrated. In the proposed system, a series of analog circuits are used not only to adjust the temperature and control the bias voltage but also to monitor the current and recover the clock from the communication data. In addition, the temperature compensation and multiplication gain control algorithm are embedded in the microcontroller to improve the performance of the receiver. As shown in the experiment, with the change of communication rate from 10 to 2000 Mbps, the detection sensitivity of the APD receiver varies from -47 to -34 dBm. Moreover, due to the existence of the multiplication gain control algorithm, the dynamic range of the APD receiver is effectively improved, while the dynamic range at 10, 100, and 1000 Mbps is 38.7, 37.7, and 32.8 dB, respectively. As a result, the experimental results agree well with the theoretical predictions, and the receiver will improve the flexibility of the intersatellite links without increasing the cost. &copy; 2016 Society of Photo-Optical Instrumentation Engineers (SPIE).},
key = {Algorithms},
keywords = {Avalanche photodiodes;Gain control;Photodiodes;},
note = {Avalanche Photo Diode (APD);Communication data;Communication rate;Detection sensitivity;Inter-satellite laser communications;Inter-satellite link;Performance testing;Temperature compensation;},
URL = {http://dx.doi.org/10.1117/1.OE.55.6.067109},
} 


@article{20152901043743 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A global integrity parameter with acoustic emission for load testing of prestressed concrete girders},
journal = {ACI Structural Journal},
author = {Barrios, Francisco A. and Ziehl, Paul H.},
volume = {112},
number = {1},
year = {2015},
pages = {3 - 12},
issn = {08893241},
abstract = {Structural evaluation of existing infrastructure has become a critical subject in civil engineering. In recent years, significant efforts have been placed on developing nondestructive techniques such as acoustic emission to monitor and effectively assess the integrity of a structure without causing significant damage. However, acoustic emission methods face challenges regarding the subjectivity of associated performance evaluation criteria and a lack of measurable parameters directly related to the mechanical response of the system. It has been previously suggested that an integrated approach of the cyclic load testing method with acoustic emission techniques may overcome these difficulties and constitute a more effective, nondestructive load testing methodology. The current investigation analyzes experimental data gathered from flexural testing of six full-scale prestressed girder specimens (lightweight and normalweight) and presents a potential approach for damage detection and assessment within the minor to intermediate damage zones based on acoustic emission data. Copyright &copy; 2015, American Concrete Institute. All rights reserved.},
key = {Acoustic emission testing},
keywords = {Beams and girders;Concrete beams and girders;Concrete testing;Damage detection;Load testing;Prestressed concrete;Prestressing;Structural loads;},
note = {Acoustic emission data;Acoustic emission method;Acoustic emission techniques;Measurable parameters;Mechanical response;Non-destructive technique;Performance evaluation criteria;Structural evaluation;},
URL = {http://dx.doi.org/10.14359/51687294},
} 


@article{1982110141832 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Vibration and performance testing with small digital test systems},
journal = {S V Sound and Vibration},
author = {Smiley, R.G.},
volume = {16},
number = {4},
year = {1982},
pages = {8 - 15},
issn = {00381810},
abstract = {Recent advances in electronics and testing techniques have made the smaller Fourier analyzer test system much more attractive as a portable, flexible alternative to large, rack-mounted minicomputer-based test systems. In this article, a review of numerous experimental tests used by mechanical engineers in the areas of structural dynamics and operating performance evaluation are presented.},
key = {VIBRATIONS},
} 


@inproceedings{20162002376580 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Real-time quality monitoring and result verification by static and dynamic pile load testing in marine clay},
journal = {Geotechnical Engineering for Infrastructure and Development - Proceedings of the XVI European Conference on Soil Mechanics and Geotechnical Engineering, ECSMGE 2015},
author = {Wehr, Jimmy and Andreas, Mario and Bohle, BjSrn and Schallert, Matthias and Klingmiiller, Oswald},
volume = {3},
year = {2015},
pages = {1339 - 1343},
address = {Edinburgh, United kingdom},
abstract = {A construction project in the city of Constanze, Germany, Konstanz, on Lake Constance, provided a rare opportunity to install several test piles of different types and test these with regard to their bearing capacity. This opportunity was used to investigate full- displacement bored piles (FDP), vibro-concrete columns (VCC) and vibro-mortar columns (VMC). During pile installation, an on-line quality monitoring and verification system was used to monitor productivity. The results of this installation process were verified by static and dynamic axial load tests, with which it was hoped to show to what extent these agree with the results of the quality monitoring and the static tests and are therefore suitable for these foundation elements. The difficult foundation soil including very soft lacustrine clay presented a particularly interesting challenge. Despite the very unfavourable conditions, unexpectedly high individual loads were measured for the floating-installed columns. For the vibro-concrete column, the limit settlement was not achieved until an axial load of 1,000 kN had been reached. The full-displacement bored pile "failed" at a load of 720 kN, and the 4 m-shorter vibro-mortar column still required a load of 680 kN to reach its limit settlement. In comparison, the dynamic-loading tests confirmed the limit load-bearing capacities thus determined with a deviation of only about 5 %. However, a deviation of about 33 % from the statically determined bearing capacity of the full-displacement pile was less than satisfactory, and this remains to be investigated in detail with the results of future loading tests. &copy; The authors and ICE Publishing: All rights reserved, 2015.},
key = {Piles},
keywords = {Axial loads;Bearing capacity;Concrete construction;Concretes;Dynamic loads;Dynamics;Geotechnical engineering;Load testing;Monitoring;Mortar;Soil mechanics;Soils;Testing;},
note = {Construction projects;Dynamic loading test;Full displacement piles;Pile installation;Quality monitoring;Result verifications;Verification systems;Vibro concrete columns;},
} 


@article{20120214670866 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {An accelerated stress test method for electrostatically driven MEMS devices},
journal = {IEEE Transactions on Instrumentation and Measurement},
author = {Ruan, Jinyu J. and Monnereau, Nicolas and Tremouilles, David and Mauran, Nicolas and Coccetti, Fabio and Nolhier, Nicolas and Plana, Robert},
volume = {61},
number = {2},
year = {2012},
pages = {456 - 461},
issn = {00189456},
abstract = {This paper addresses an innovative solution to develop a circuit to perform accelerated stress tests of capacitive microelectromechanical-system (MEMS) switches and shows the use of instruments and equipment to monitor physical aging phenomena. A dedicated test circuit was designed and fabricated in order to meet the need for accelerated techniques for those structures. It integrated an in-house miniaturized circuit connected to additional test equipment (e.g., oscilloscopes and capacitance meters) that enabled the reliability characterization of capacitive switches. The accelerated stress test (AST) circuit generated an electrostatic-discharge-like impulse that stressed the device. This setup allowed the simultaneous measurement of the current and voltage waveforms, and the capacitance variation of the device under test after each stress. The results obtained using the miniature AST circuit were discussed and were correlated with results obtained using a commercial human-body-model tester as well as data from a cycling benchmark. The scope of this paper encompasses the theory, methodology, and practice of measurement; the development of a testing miniaturized board; and the analysis and representation of the information obtained from a set of measurements. As a result, it may contribute to the scientific and technical standards in the field of instrumentation and measurement of electrostactically actuated devices having insulating layers. &copy; 2006 IEEE.<br/>},
key = {Electronic equipment testing},
keywords = {Capacitance;Charging (furnace);Electric breakdown;Electrostatic devices;Electrostatics;Laser optics;MEMS;Microelectromechanical devices;Switches;},
note = {Accelerated testing;Capacitive microelectromechanical systems (MEMS);Electrostatically driven;Instrumentation and measurements;Instruments and equipments;Reliability characterization;Reliability testing;Simultaneous measurement;},
URL = {http://dx.doi.org/10.1109/TIM.2011.2161937},
} 


@inproceedings{20163502742688 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Effect study of silicone amount on the lumen maintenance of high power LED under accelerated stress test},
journal = {Proceedings of the 15th InterSociety Conference on Thermal and Thermomechanical Phenomena in Electronic Systems, ITherm 2016},
author = {Chen, Qi and Hu, Run and Xie, Bin and Yu, Xingjian and Cheng, Jingjing and Luo, Xiaobing},
year = {2016},
pages = {836 - 840},
address = {Las Vegas, NV, United states},
abstract = {In our previous study, we investigated the effects of different packaging materials (silicone and phosphor layer) on the reliability of high power light-emitting diodes (HPLEDs) by highly accelerated stress test (HAST). The experimental results showed that the LED samples' lumen maintenance property might have dependence on the silicone amount in the package. In this paper, we further studied the effect of silicone amount on the lumen maintenance under HAST. Five categories of LED specimens specified by silicone amount were prepared and subjected to an isothermal chamber whose temperature was set at 125 &deg;C. An online testing system was used to monitor and record the light outputs in real time during the experimental process. After 400 hours of aging, the largest attenuating range reached 6.17% and different groups display different degradation behaviors. An exponential decay model was adopted to calculate the decay rate of each lumen maintenance curve. The decay rate differs as the silicone amount inside the package modules changes. This phenomenon is well explained and Monte Carlo ray-tracing simulations are carried out to validate the explanation. The interaction effect of both silicone amount and temperature is also found and more researches need to be done for further study. &copy; 2016 IEEE.},
key = {Light emitting diodes},
keywords = {Decay (organic);Maintenance;Monte Carlo methods;Packaging materials;Ray tracing;Reliability;Silicones;},
note = {Accelerated stress;Degradation behavior;Exponential decay models;High power light emitting diodes;Highly accelerated stress tests;Isothermal chamber;Monte-Carlo ray tracing;Online testing systems;},
URL = {http://dx.doi.org/10.1109/ITHERM.2016.7517633},
} 


@inproceedings{20122615140709 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Vibration and performance testing with small digital test systems},
journal = {SAE Technical Papers},
author = {Smiley, R. Gene},
year = {1981},
issn = {01487191},
address = {Peoria, IL, United states},
abstract = {Recent advances in electronics and technical advances in testing techniques have made the smaller Fourier Analyzer test systems much more attractive as a more portable, more flexible alternative to large, rack-mounted minicomputer-based test systems. This paper will review numerous experimental tests performed in structural dynamics and operating performance by mechanical engineers in terms of their speed, data base size, calculation complexity, and transducer interface requirements in an attempt to clarify the position of the smaller test system in the mechanical engineering test profession. &copy; 1981 Society of Automotive Engineers, Inc.<br/>},
key = {Test facilities},
keywords = {Flexible electronics;Professional aspects;Structural dynamics;},
note = {Digital test systems;Experimental test;Fourier;Operating performance;Performance testing;Technical advances;Test systems;Testing technique;},
URL = {http://dx.doi.org/10.4271/810693},
} 


@inproceedings{20064210171453 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Rapid-to-deploy wireless monitoring systems for static and dynamic load testing of bridges: Validation on the grove street bridge},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Hou, Tsung-Chin and Lynch, Jerome P.},
volume = {6178},
year = {2006},
pages = {SPIE; ASME - },
issn = {0277786X},
address = {San Diego, CA, United states},
abstract = {Bridge management officials have expressed a keen interest in the use of low-cost and easy-to-install wireless sensors to record bridge responses during short-term load testing. To illustrate the suitability of wireless sensors for short-term monitoring of highway bridges, a wireless monitoring system is installed upon the Grove Street Bridge to monitor structural responses during static and dynamic load testing. Specifically, load testing of the Grove Street Bridge is conducted after its construction to validate the behavior of a novel jointless bridge deck constructed from a high-performance fiber reinforced cementations composite (HPFRCC) material. A heterogeneous array of sensing transducers are installed in the bridge including metal foil strain gages, accelerometers and linear variable differential transducers (LVDTs). First, the acceleration response of the bridge is monitored by the wireless system during routine traffic loading. Modal parameters (modal frequencies and mode shapes) are calculated by the wireless sensors so that an analytical model of the bridge constructed in a standard commercial finite element package can be updated off-line. Next, the bridge is closed to traffic and trucks of known weight are parked on the bridge to induce static deformations. The installation strategy of the wireless monitoring system during static load testing is optimized to monitor the strain and rotation response of the HPFRCC deck. The measured static response of the deck is compared to that predicted by the updated analytical model.},
key = {Bridges},
keywords = {Condition monitoring;Deformation;Identification (control systems);Load testing;Mathematical models;Wireless telecommunication systems;},
note = {Rotation response;Static deformations;Structural monitoring;Wireless sensors;},
URL = {http://dx.doi.org/10.1117/12.658902},
} 


@article{20180404678429 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {High density emulation platform for Wi-Fi performance testing},
journal = {Ad Hoc Networks},
author = {Capdehourat, German and alvarez, German and alvarez, Martin and Porteiro, Pedro and Bagalciague, Fernando},
volume = {70},
year = {2018},
pages = {1 - 13},
issn = {15708705},
abstract = {The IEEE 802.11 standard has become the basis of one of the most successful wireless communication technologies of all time. Originally created to provide wireless connectivity for a few devices, a couple of decades later it may support thousands of users in a single wireless LAN. This fact has made 802.11 a relevant research topic, and as it happens with other wireless technologies, many of the work carried out is based on simulations. In particular, studies for scenarios with high user density are usually performed this way, in many cases leading to conclusions which do not apply to real world situations. This mismatch can be due to multiple factors, such as the specific protocol implementations or the hardware and drivers used. In this article we present a novel 802.11-based testing platform, which aims to bridge the gap between simulations and the real world, in order to carry out research work for typical high density scenarios. The platform is compatible with standard 802.11-based wireless cards on the market and it was tested with two different radios, The validation metrics considered were the TCP throughput, the airtime utilization and the effective data rate, with relative errors ranging from 0 up to 15%. The potential of the tool is illustrated with real world measurements from two example use cases in education facilities: a school classroom and a conference room. The results indicate this might be the first step towards an open platform to enable active Wi-Fi performance testing for large scale scenarios. Further emulation capabilities are shown with different application tests already integrated to the platform, such as QoE tests for YouTube video playback or e-learning platforms.<br/> &copy; 2017 Elsevier B.V.},
key = {Wireless local area networks (WLAN)},
keywords = {E-learning;Education;Standards;Wireless telecommunication systems;},
note = {Client emulation;Emulation capabilities;IEEE 802.11 standards;IEEE 802.11s;Performance testing;Wireless communication technology;Wireless connectivities;Wireless technologies;},
URL = {http://dx.doi.org/10.1016/j.adhoc.2017.11.007},
} 


@inproceedings{20122315082695 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test and data acquisition of voltage regulator for automotive alternator},
journal = {Proceedings 2011 International Conference on Transportation, Mechanical, and Electrical Engineering, TMEE 2011},
author = {Zhang, Xiaoqin and Li, Zhihong and Wang, Baoliang and Wang, Lianchuan},
year = {2011},
pages = {707 - 710},
address = {Changchun, China},
abstract = {The dynamic testing system of voltage regulator must be assembled with the automotive alternator, so it's large, expensive, power consumption and operation complexity. A static testing system was developed by using electronic analog generator in place of automotive alternator sets. The system communicated with the computer can carry out performance test and data acquisition, in turn to analysis performance for large quantities of products. The paper described the methods of static testing and the principles of data acquisition. By comparison, it's proved that the static testing system is simple, reliable, easy to operate, cheap and accurate. Its accuracy came to 0.1 relative to dynamic testing system. &copy; 2011 IEEE.<br/>},
key = {Data acquisition},
keywords = {Dynamics;Synchronous generators;Voltage regulators;},
note = {Automotive alternators;Dynamic testing;Electrical performance;Performance tests;Static testing;Static tests;},
URL = {http://dx.doi.org/10.1109/TMEE.2011.6199300},
} 


@inproceedings{20113914365538 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Jet performance testing of high-pressure waterjet descaling nozzles},
journal = {Advanced Materials Research},
author = {Ma, Fei and Li, Yong and Song, Zhiming},
volume = {314-316},
year = {2011},
pages = {2408 - 2413},
issn = {10226680},
address = {Guangzhou, China},
abstract = {Descaling nozzles, generator of high-speed waterjets, are key components in high-pressure waterjet descaling system. Jet performance of the nozzle has great effect on hot-rolling steel billet descaling. Most domestic manufactures provide nozzle structural data and impact force scale with rated pressure, such as orifice diameter, injecting angle and scattering angle. However, jet distribution shape and jet impact force distribution and strength, which are major parameters affecting steel billet descaling quality, are not available from manufactures. A jet performance test device for nozzles was developed in this paper. Two and three dimensional graphs of jet impact force distribution with different standoff distance were obtained. Shape of jet distribution area was indicated in two dimensional graphs while jet impact strength and distribution were given in three dimensional graphs, providing evidence for jet performance judgement. Injecting angle, scattering angle and flow volume coefficient could also be measured with the device. A fan-type nozzle used for scale removal was tested. Results obtained were presented and discussed. &copy; (2011) Trans Tech Publications.},
key = {High pressure engineering},
keywords = {Billets (metal bars);Descaling;Design;Hot rolling;Impact strength;Jets;Manufacture;Metal cleaning;Nozzle design;Nozzles;Scattering;Three dimensional;},
note = {Descaling systems;Distribution area;Flow volumes;High-speed;Impact force;Key component;Orifice diameters;Performance testing;Performance tests;Scattering angles;Standoff distance;Steel billets;Structural data;Three dimensional graphs;Two-dimensional graphs;Water jets;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMR.314-316.2408},
} 


@article{20062910008639 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {An in vitro oxidative stress test for determining pollutant tolerance in algae},
journal = {Ecological Indicators},
author = {Johnstone, C. and Day, J.G. and Staines, H. and Benson, E.E.},
volume = {6},
number = {4},
year = {2006},
pages = {770 - 779},
issn = {1470160X},
abstract = {An in vitro oxidative stress test has been developed to assess pollutant tolerance in freshwater algae using Euglena gracilis as the test organism and FeSO<inf>4</inf> and NaCl as the pollutants. The test evaluates free radical-mediated oxidative stress through the concomitant application of three biochemical assays: (1) the non-invasive, gas chromatographic-volatile headspace analysis of hydroxyl radicals ({radical dot}OH) using dimethyl-sulphoxide as a radical trap; (2) the spectroscopic determination of total antioxidant activity; (3) a fluorescent microscopy viability test. In vitro pollutant testing was devised to simulate contaminant loadings that impact urban retention ponds. E. gracilis was found to be tolerant to FeSO<inf>4</inf> (2-10% (w/v)) and NaCl (10-5000 ppm) as indicated by high positive viabilities (ca. 100%) and low, or no {radical dot}OH production, as compared to controls. Total antioxidant activity increased with increasing pollutant loading suggesting that the organism has the capacity to enhance antioxidant defence in response to pollutant stress. This in vitro test provides a new approach to monitor the effects of water quality on the biological components of urban and/or polluted aquatic ecosystems. It also has a potential application in the identification of putative algal phytoremediators. &copy; 2005 Elsevier Ltd. All rights reserved.},
key = {Algae},
keywords = {Antioxidants;Bioassay;Free radicals;Oxidation;Sodium chloride;Stress analysis;},
note = {Algal stress;Aquatic pollution indicators;Phytoremediators;Pollutant tolerance;Xenobiotics;},
URL = {http://dx.doi.org/10.1016/j.ecolind.2005.09.002},
} 


@inproceedings{20111313884834 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing and control of a small wind energy converter},
journal = {Proceedings - 2011 6th IEEE International Symposium on Electronic Design, Test and Application, DELTA 2011},
author = {Habash, Riadh W. Y. and Groza, Voicu and Yang, Yeu and Blouin, Charles and Guillemette, Pierre},
year = {2011},
pages = {263 - 268},
address = {Queenstown, New zealand},
abstract = {Responding to more demand in coming years, the task of the small wind energy industry requires progress on several fronts - from public policy initiatives, to technology development, to market growth. Enhanced technologies such as contra-rotating blades, transmission systems, lubrication, airfoils, generators, and power electronics will lower cost and increase energy production. This paper mainly considers two key technological points of a small wind energy converter (SWEC) namely, the performance of the rotor system and induction generator. Small-scale prototypes have been built to experimentally verify the performance of the SWEC. Wind tunnel tests of the power output, power coefficient, and turbine speed were carried out to ascertain the aerodynamic power conversion and the operation capability at lower wind speeds. The results demonstrated a significant increase in performance compared to a single-rotor system of the same type. Another aspect of development and test is to present a comparative performance evaluation between a standard induction generator and an efficient but with modified design (TRIAS Generator) as a realistic solution of clean power for grid-connected SWECs. The paper also discusses issues related to control and monitoring of SWEC. &copy; 2011 IEEE.<br/>},
key = {Asynchronous generators},
keywords = {Aerodynamics;Electric generators;Electric power transmission;Rotating machinery;Wind power;Wind tunnels;},
note = {Comparative performance;Contra-rotating;Control and monitoring;Small wind generators;Technology development;Transmission systems;Wind energy converters;Wind energy industry;},
URL = {http://dx.doi.org/10.1109/DELTA.2011.55},
} 


@inproceedings{20145000304380 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research of performance test technology for big data applications},
journal = {2014 IEEE International Conference on Information and Automation, ICIA 2014},
author = {Liu, Zhenyu},
year = {2014},
pages = {53 - 58},
address = {Hailar, Hulunbuir, China},
abstract = {This paper studies the performance test in big data application. The existing performance testing technology is not suitable for the big data application. The paper proposed test technology for performance testing. The technology provided test goal analysis, test design, load design for big data application. The character for different application could be supported to consider specific multiple test data design method under this framework. The performance technology is used to test some applications and proved effective.},
URL = {http://dx.doi.org/10.1109/ICInfA.2014.6932625},
} 


@article{20181605015017 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stress-testing the ALFRED design - Part III: Safety margins evaluation},
journal = {Progress in Nuclear Energy},
author = {Lodi, F. and Grasso, G.},
volume = {106},
year = {2018},
pages = {433 - 439},
issn = {01491970},
abstract = {The advancement of the design of the Advanced Lead-cooled Fast Reactor European Demonstrator (ALFRED) beyond the conceptual phase, passes through the analysis of the impact of uncertainties, notably to what concerns safety-related conditions. Compliancy of plant safety to Design Extension Conditions is, according to IAEA and in line with the meaning itself of these beyond-design conditions, usually investigated by best estimates only. Due however to the demonstration nature of ALFRED, it was decided to assess the actual safety performances of this system even in ultimate conditions. To this regard, the emphasis was put on unprotected events like the UTOP (unprotected transient of over-power) and ULOOP (unprotected loss of offsite power, resulting from the combination of a loss of flow and loss of heat sink under unprotected conditions), pinpointed as the most challenging situations sought for the plant. The purpose of the present work, which has been divided in three parts, was then to assess the ultimate ALFRED safety margins against failure of the key core components and systems (Part III). To target this objective, the evaluation of uncertainties coming, on one hand, from nuclear data was performed at first, to retrieve their impact on the reactivity coefficients, thereby on the transient behavior driven by the latter (Part I); then, uncertainties from material properties, fabrication procedures, operation and measurement, and computational tools were propagated to assess their influence on the thermal-hydraulics of the system (Part II). In this work the efforts of Parts I and II are merged together and the effect of uncertainties on safety margins and salient parameters assessed. The retrieved uncertainties are propagated to the expected number of pins experiencing fuel melting during an UTOP and to the clad time-to-failure during an ULOOP. The former has been found to be quite affected by uncertainties, but still under limits not directly posing hazards to the people and the environment, even when extremely conservative assumptions are put forward; the latter shows a milder response to uncertainties, but always guaranteeing more than an order of magnitude of safety margin relative to WENRA recommendations.<br/> &copy; 2018 Elsevier Ltd},
key = {Uncertainty analysis},
keywords = {Fast reactors;Outages;Safety testing;Transients;},
note = {ALFRED;Computational tools;Fabrication procedure;Lead cooled fast reactor;Reactivity coefficients;Safety analysis;Safety performance;Thermal hydraulics;},
URL = {http://dx.doi.org/10.1016/j.pnucene.2018.04.003},
} 


@inproceedings{1987120200178 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {GUIDANCE FOR PERFORMANCE MONITORING: A NEW ASME PERFORMANCE TEST CODE CONCEPT.},
journal = {American Society of Mechanical Engineers (Paper)},
author = {Case, Robert C. and Deming, Norman R.},
year = {1987},
pages = {ASME, New York, NY, USA; IEEE, New York, NY, USA - },
issn = {04021215},
address = {Miami Beach, FL, USA},
abstract = {The ASME Board on Performance Test Codes chartered a new PTC Committee entitled, 'Guidance for Performance Monitoring'. 'Guidance for Performance Monitoring' will be oriented toward steam power plants. It seeks to advise plant operators on how to effectively monitor the efficiency and mechanical condition of their equipment throughout its lifetime. It also seeks to extend beyond monitoring itself into the arenas of information evaluation and application toward corrective action. This paper explains the Committee's background and its anticipated directions in approaching the task.},
key = {STEAM POWER PLANTS},
keywords = {POWER PLANTS - Testing;},
note = {ASME PERFORMANCE TEST CODE;GUIDANCE FOR PERFORMANCE TESTING;PERFORMANCE MONITORING;},
} 


@inproceedings{1990080427461 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Combined load testing of prestressed concrete cylinder pipe},
author = {Tremblay, Armand W.},
year = {1990},
pages = {310 - 322},
address = {Las Vegas, NV, USA},
abstract = {A series of combined load tests were run on prestressed concrete cylinder pipe in order to evaluate a proposed new method of design for pipe made to AWWA Standard C301. These tests involved the simultaneous application of external loads and internal pressures in various combinations. The test apparatus was designed and constructed with several unique features, which permitted visual observation of the interior pipe surface at the invert and measurement of vertical deflection during the test. In addition, strain gauges were used to monitor strain levels in the concrete core, the mortar coating, the steel cylinder, and the prestress wire.},
key = {Pipe, Concrete},
keywords = {Concrete Construction - Prestressing;},
note = {Combined Load Testing;Pipe Test AWWA Standard C301;Prestressed Concrete Cylinder Pipe;},
} 


@inproceedings{20172503792186 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stainless Steel Heat Pipe Fabrication, Performance Testing and Modeling},
journal = {Energy Procedia},
author = {Lee, How-Ming and Tsai, Meng-Chang and Chen, Hsin-Liang and Li, Heng-Yi},
volume = {105},
year = {2017},
pages = {4745 - 4750},
issn = {18766102},
address = {Beijing, China},
abstract = {A set of stainless steel tabular heat pipes are successfully fabricated, for the purpose of the low-grade heat recovery applications in a corrosion exhaust environment. The fabrication, the thermal performance testing systems, and modeling are presented in the paper. Experimental results show that the water filling ratio plays a significant role in the thermal performance of heat pipes. A numerical model is developed and the model prediction is trustworthy in comparison with experimental data. The model reveals that a better heat pipe thermal performance could be achieved by selecting a material with higher thermal conductivity coefficient. However, it should be compromised in terms of the thermal performance and the application concerns like corrosion. &copy; 2017 The Authors.},
key = {Heat pipes},
keywords = {Corrosion;Fabrication;Stainless steel;Steel heat treatment;Steel testing;Thermal conductivity;Waste heat;Waste heat utilization;},
note = {Low grade heat;Model prediction;Performance testing;Thermal conductivity coefficient;Thermal Performance;Thermal performance testing;Water filling;},
URL = {http://dx.doi.org/10.1016/j.egypro.2017.03.1032},
} 


@inproceedings{2004208158147 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Live-Load Test Results of Missouri's First High-Performance Concrete Superstructure Bridge},
journal = {Transportation Research Record},
author = {Yang, Yumin and Myers, John J.},
number = {1845},
year = {2003},
pages = {96 - 103},
issn = {03611981},
abstract = {For its significant economical savings and greater design flexibility, high-performance concrete (HPC) is becoming more widely used in high-way bridge structures. High-performance bridges with HPC and large-diameter prestressed strands are becoming attractive to designers. Bridge A6130 is the first fully HPC superstructure bridge in Missouri. The bridge has HPC cast-in-place deck and high-strength concrete girders reinforced with 15.2-mm (0.6-in.) diameter strands. The bridge was instrumented with embedded strain gauges and thermocouples to monitor the early-age and later-age behavior of the structures from construction through service. To investigate the overall behavior of the bridge under live load, a static live-load test was developed and carried out. During the live-load test, 64 embedded vibrating wire strain gauges and 14 embedded electrical-resistance strain gauges were used to acquire the changing strain rate in the bridge caused by the varying live-load conditions. Girder deflections and rotations were also recorded with external sensors and a data acquisition system. Based on the test results, the load distribution to the girders was studied. The AASHTO specifications live-load distribution factor recommended for design was compared with the measured value and found to be overly conservative. The AASHTO load and resistance factor design live-load distribution factors recommended for design were found to be comparable to measured values. Two finite element models were developed with ANSYS and compared with measured values to investigate the continuity level of the Missouri Department of Transportation interior bent detail.},
key = {Highway bridges},
keywords = {Boundary conditions;Concrete bridges;Deflection (structures);Electric resistance;Load testing;Reinforced concrete;Strain gages;Stress analysis;Structural design;Thermocouples;},
note = {Electrical-resistance strain gauges (ERSG);High performance concrete (HPC);Live-load distribution;},
} 


@article{20153101083733 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Accelerated stress test procedures for PEM fuel cells under actual load constraints: State-of-art and proposals},
journal = {International Journal of Hydrogen Energy},
author = {Petrone, R. and Hissel, D. and Pera, M.C. and Chamagne, D. and Gouriveau, R.},
volume = {40},
number = {36},
year = {2015},
pages = {12489 - 12505},
issn = {03603199},
abstract = {Research activities concerning proton exchange membrane fuel cells (PEMFC) are mainly aimed to reach lifespan objective. To this purpose numerous experimental tests are usually scheduled. In this framework, the studies involved in system aging and lifetime prediction can be extremely time consuming and costly. Thus, introducing accelerated aging methodologies to reduce test duration and costs becomes now an open question at an international level. This article aims to raise awareness on this topic, analysing the accelerated stress test (AST) applications proposed in PEMFC domain. An overview on the main protocols reported in literature is then presented focusing on PEMFC lifetime prediction applications. The open issues related to the protocols' development and to the AST coupling with natural aging are also evaluated. Finally, new proposals are presented. In the last part of the article the fundamentals to develop a new approach for lifetime prediction based on adaptable load cycling are introduced. &copy; 2015, Hydrogen Energy Publications, LLC.},
key = {Proton exchange membrane fuel cells (PEMFC)},
keywords = {Forecasting;Fuel cells;Testing;},
note = {Accelerated aging;Accelerated stress;Experimental test;Lifetime prediction;Load constraints;Load cycling;New approaches;Research activities;},
URL = {http://dx.doi.org/10.1016/j.ijhydene.2015.07.026},
} 


@inproceedings{20120414716802 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Benchmarking embedded devices for broadband performance testing},
journal = {Proceedings - IEEE 9th International Conference on Dependable, Autonomic and Secure Computing, DASC 2011},
author = {Tangadpalliwar, Snehal and Sandrasegaran, Kumbesan and Raymond, Malcolm and Moitra, Ajanta and Madani, Faisal},
year = {2011},
pages = {321 - 327},
address = {Sydney, NSW, Australia},
abstract = {Real time monitoring of broadband performance parameters is critical for estimating the user experience of new broadband services like VoIP, IPTV, Gaming and Video. This information is of interest to service providers themselves for efficient network design and maintenance and government regulatory bodies for analyzing ISPs, regions and national benchmarking. A web-based system TRUEE (Tool for Real-time User Experience Estimation) is a distributed system that incorporates independent modules such as standalone measurement devices installed at customer premises, data centers, test servers and web-clients for remote monitoring and management of the system. The focus of this paper is to discuss the process of benchmarking three commercial embedded devices with PC as reference device representing an end user system for accessing broadband services. This work is part of the ongoing development process of TRUEE. This benchmarking process is of significant importance for making an informed decision on the suitability of an embedded device capable of providing desired accuracy and consistency in estimation of the broadband performance parameters. Based on literature review, online forum reviews and cost analysis three devices based on ARM viz. SheevaPlug, Texas Instrument's BeagleBoard-xM and Gumstix Overo are selected for benchmarking. Results show that Marvell's SheevaPlug outperforms the other two devices in accurately measuring the broadband parameters on its network interface. &copy; 2011 IEEE.<br/>},
key = {Benchmarking},
keywords = {Green computing;Information management;IPTV;Parameter estimation;},
note = {Benchmarking process;Broadband;Broadband performance;Distributed systems;Embedded device;Network Monitoring;Performance testing;Real time monitoring;},
URL = {http://dx.doi.org/10.1109/DASC.2011.71},
} 


@article{20173504097545 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Hybrid vehicular fuel cell/battery powertrain test bench: design, construction, and performance testing},
journal = {Transactions of the Institute of Measurement and Control},
author = {Salah, Mohammad and Abu Mallouh, Mohammed and Youssef, Mohamed and Abdelhafez, Eman and Hamdan, Mohammed and Surgenor, Brian},
volume = {39},
number = {9},
year = {2017},
pages = {1431 - 1440},
issn = {01423312},
abstract = {The development of hybrid vehicular power systems has been conducted for decades to improve transportation quality mainly in terms of environment pollution and fuel economy. Hence, hybrid electric vehicular systems are considered an attractive and potential solution in the long run to replace conventional combustion engine vehicles. In this paper, a scaled-down vehicular powertrain test bench is designed and constructed utilizing a hybrid fuel cell/battery energy sources. The performance of the proposed test bench is also investigated experimentally to explore the modes of operation for system components under various road conditions. Load-following energy management strategy is implemented experimentally in this hybrid configuration. The concepts that can be learned from such test bench are certainly essential for any future implementation on real full-size vehicles. In this study, it is shown that even though fuel cells have a good energy-to-weight ratio, they have a slow response and that is why they must be combined with other fast-response energy sources like a battery or supercapacitor. The test bench is mainly built to explore the implementation of various energy management strategies and control algorithms without the need to have a real vehicle and an automotive test track. In addition, it is an excellent platform for training highly qualified automotive engineers and university undergraduate students as well as automotive researchers. &copy; 2017, &copy; The Author(s) 2017.},
key = {Testing},
keywords = {Education;Energy management;Fuel cells;Fuel economy;Load testing;Personnel training;Powertrains;Students;Vehicles;},
note = {Conventional combustions;Energy management strategies;Energy-to-weight ratio;Load following;Performance testing;Test benches;Undergraduate students;Vehicular systems;},
URL = {http://dx.doi.org/10.1177/0142331216642835},
} 


@inproceedings{1995382803917 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {BIST/DFT for performance testing of bare dies and MCMs},
journal = {Electro International, Conference Proceedings},
author = {Chen, Chih-Ang and Gupta, Sandeep K.},
year = {1994},
pages = {803 - 812},
address = {Boston, MA, USA},
abstract = {High emphasis on performance and high cost of MCM repair necessitate a framework for performance testing of dies, substrates, and final MCMs. Application of performance tests to bare dies is very expensive due to the need for small and high speed probes and ATE. BIST, scan, and boundary scan can provide a framework to accomplish performance testing in a cost effective manner. It has been shown that traditional BIST, scan, and boundary scan techniques do not provide the framework for performance testing. Special BIST and scan design techniques that can be employed to guarantee high coverage of delay faults are described. Typically, these techniques produce BIST test pattern generators and scan chain designs that require sightly increased hardware overhead over conventional BIST/scan. However, they can drastically decrease the complexity of bare die performance testing. Furthermore, when used in combination with the proposed enhanced boundary scan design, they provide a framework for detection and diagnosis of dynamic failures.},
key = {Multichip modules},
keywords = {Costs;Error detection;Performance;Quality control;Reliability;Repair;Semiconductor materials;Substrates;},
note = {Bare dies;Built in self test;Delay faults;Hardware overhead;Performance testing;Scan chain designs;Test pattern generators;},
} 


@inproceedings{20163802827932 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Assets overlapping networks and stress testing on stability of financial systems},
journal = {Chinese Control Conference, CCC},
author = {Zhou, Changli and Du, Donglei and Cao, Zhigang and Wang, Yingli and Yang, Xiaoguang},
volume = {2016-August},
year = {2016},
pages = {10385 - 10389},
issn = {19341768},
address = {Chengdu, China},
abstract = {Financial networks, creating potential propagation channels for shocks in crises, are widely viewed as a key factor to systemic stability. In this paper, we develop a dynamic model of deleveraging in an overlapping network of assets. We study the deleveraging spirals driven by the interaction between fire sales and confidence effects, and show how distress is amplified and propagated throughout the network. Using the regulatory data from the Peoples Bank of China (PBC), we construct the assets overlapping network and then apply the model to the system. The result suggests that: (1) the mutually reinforcing effects of fire sales and confidence can contribute to contagion significantly; (2) The vulnerability of the system are largely dependant on the distribution of large illiquid assets. Our model provides a ready-to-use yet powerful stress testing tool for macro-prudential regulation. &copy; 2016 TCCT.},
URL = {http://dx.doi.org/10.1109/ChiCC.2016.7555000},
} 


@inproceedings{20160101765216 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Power minimization technique for induction motor load test},
journal = {Proceedings - IPEMC 2000: 3rd International Power Electronics and Motion Control Conference},
author = {Lumyong, Pichit and Chat-Uthai, Chaiwut},
volume = {2},
year = {2000},
pages = {570 - 573},
address = {Beijing, China},
abstract = {This paper presents the technique of how to minimize power from the supply when a three-phase induction motor is under the load test. The load test enables the determination of the value of load power, current and power factor of the induction motor. In practice, a DC generator or eddy current brake is applied for the mechanical test. The objective of this paper is to propose a load test method using two pulleys for changing speed of an induction motor. The second induction machine is controlled to operate as an induction generator in order to transfer the energy to the supply, therefore the power required during the test is obviously reduced. The study of how to control the induction motor operated as generator will be the useful information for developing the induction generator system (IG) to work with variable speed and load, and to make it work as a stand alone generator. &copy; 2000 Int. Acad. Publ., World Publ. Corp.},
key = {Induction motors},
keywords = {Asynchronous generators;Asynchronous machinery;Electric power factor;Motion control;Power control;Power electronics;Pulleys;},
note = {Eddy current brakes;Induction machines;Induction motor loads;Power minimization;Stand-alone generators;Three phase induction motor;Variable speed;Variable speed pulleys;},
URL = {http://dx.doi.org/10.1109/IPEMC.2000.884551},
} 


@inproceedings{20151400702836 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Operating experience and site performance testing of the CW251B12 gas turbine engine},
journal = {ASME 1992 International Gas Turbine and Aeroengine Congress and Exposition, GT 1992},
author = {Diakunchak, Ihor S.},
volume = {4},
year = {1992},
pages = {International Gas Turbine Institute - },
address = {Cologne, Germany},
abstract = {The first CW251B12 engine has been operating for about a year at a paper mill in a cogeneration application. The engine generates electricity, and the exhaust heat is used in a supplementary fired Heat Recovery Steam Generator (HRSG) to produce steam. The steam generated in the HRSG plus additional process steam is used to produce electrical power in a condensing steam turbine. Steam extracted from the steam turbine is in turn used in the paper mill. This paper describes the operating experience of the gas turbine and provides some details of the site performance test. Copyright &copy; 1992 by ASME.},
key = {Gas turbines},
keywords = {Engines;Heat transfer;Paper and pulp mills;Papermaking machinery;Steam;Steam generators;Steam turbines;Waste heat;},
note = {Condensing steam turbine;Electrical power;Exhaust heat;Heat recovery steam generators;Operating experience;Paper mill;Performance testing;Performance tests;},
URL = {http://dx.doi.org/10.1115/92-GT-236},
} 


@inproceedings{20133416627414 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test of electricity generation utilizing vortex induced vibration},
journal = {ASME-JSME-KSME 2011 Joint Fluids Engineering Conference, AJK 2011},
author = {Iiyoshi, Ryota and Kamijyo, Masahiro and Yamada, Shuichi and Koide, Mizuyasu and Takahashi, Tsutomu and Shirakashi, Masataka},
volume = {1},
number = {PARTS A, B, C, D},
year = {2011},
pages = {3557 - 3565},
address = {Hamamatsu, Japan},
abstract = {The Karman vortex induced vibration (KVIV) is observed over a wide range of conditions, and has been regarded as a negative phenomenon until now since it has caused many accidents. Therefore a lot of researches have been conducted to predict and to avoid it. Recently, however, KVIV is regarded as a process to convert energy of natural flows into mechanical energy, and techniques for electricity generation utilizing it are proposed. The electric power of this method is smaller than that of wind and water turbine generations, but this method has possibility to become a smaller and more maintenance-free apparatus than rotary machines. In earlier works, we found that the trailing vortex shed periodically from a cruciform two-circular-cylinder system, and that it induces a cross flow vibration on the upstream cylinder (TVIV) over a wide velocity range, which becomes broader by replacing the downstream cylinder by a strip-plate. Because of this character, an electricity generator utilizing TVIV should be effectively applied to rivers of which velocity usually varies largely. The purpose of this work is to develop a technique to generate electricity utilizing TVIV in water flow. Experiments using a water tunnel and an open-surface water channel are conducted to know conditions of the maximum electric power and to test the performance in a river. The optimum gap-to-diameter ratio is 0.22 since the cylinder vibration amplitude is largest. The optimum resistance of the circuit is the value which makes the virtual damping due to electricity generation nearly equal to the structure damping. The performance test in the water channel shows that the open surface and the turbulence in flow have little influences on the cylinder vibration amplitude and the synchronization velocity range of KVIV. However, TVIV is not observed, maybe because of the large aspect ratio. Copyright &copy; 2011 by ASME.},
key = {Vibrations (mechanical)},
keywords = {Aspect ratio;Cylinders (shapes);Damping;Electric generators;Electricity;Rivers;Vortex flow;},
note = {Cross-flow vibrations;Downstream cylinders;Electricity generation;Electricity generators;Generate electricity;Mechanical energies;Vibration amplitude;Vortex induced vibration;},
URL = {http://dx.doi.org/10.1115/AJK2011-17011},
} 


@inproceedings{20134416932115 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Introducing FIRESTARTER: A processor stress test utility},
journal = {2013 International Green Computing Conference Proceedings, IGCC 2013},
author = {Hackenberg, Daniel and Oldenburg, Roland and Molka, Daniel and Schone, Robert},
year = {2013},
address = {Arlington, VA, United states},
abstract = {Processor stress test utilities are important tools for a number of different use cases. In particular, cooling systems need to be tested at maximum load in order to ensure that they fulfill their specifications. Additionally, a test system characterization in terms of idle and maximum power consumption is often a prerequisite for energy efficiency research. This creates the need for a simple yet versatile tool that generates near-peak power consumption of compute nodes. While in different research areas tools such as LINPACK and Prime95 are commonly used, these tools are just highly optimized and compute intense routines that solve specific computational problems. As stress test utilities they are unnecessarily hard to use and in many cases unreliable in terms of power consumption maximization. We propose FIRESTARTER, an Open Source tool that is specifically designed to create near-peak power consumption. Our experiments show that this task cannot be achieved with generic high-level language code. We therefore use highly optimized assembly routines that take the specific properties of a given processor microarchitecture into account. A study on four compute nodes with current or last generation x86-64 processors shows that we reliably exceed the power consumption of other stress tests and create very steady power consumption patterns. &copy; 2013 IEEE.},
key = {Testing},
keywords = {Computer architecture;Computer programming languages;Energy efficiency;Optimization;Tools;},
note = {Computational problem;Consumption patterns;FIRESTARTER;Linpack;Micro architectures;Open source tools;Prime95;Specific properties;},
URL = {http://dx.doi.org/10.1109/IGCC.2013.6604507},
} 


@article{20174204286387 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Solid oxide fuel cell short stack performance testing - Part A: Experimental analysis and -combined heat and power unit comparison},
journal = {Journal of Power Sources},
author = {Mastropasqua, L. and Campanari, S. and Brouwer, J.},
volume = {371},
year = {2017},
pages = {225 - 237},
issn = {03787753},
abstract = {The need to experimentally understand the detailed performance of SOFC stacks under operating conditions typical of commercial SOFC systems has prompted this two-part study. The steady state performance of a 6-cell short stack of yttria (Y<inf>2</inf>O<inf>3</inf>) stabilised zirconia (YSZ) with Ni/YSZ anodes and composite Sr-doped lanthanum manganite (LaMnO<inf>3</inf>, LSM)/YSZ cathodes is experimentally evaluated. In Part A, the stack characterisation is carried out by means of sensitivity analyses on the fuel utilisation factor and the steam-to-carbon ratio. Electrical and environmental performances are assessed and the results are compared with a commercial full-scale micro-CHP system, which comprises the same cells. The results show that the measured temperature dynamics of the short stack in a test stand environment are on the order of many minutes; therefore, one cannot neglect temperature dynamics for a precise measurement of the steady state polarisation behaviour. The overall polarisation performance is comparable to that of the full stack employed in the micro-CHP system, confirming the good representation that short-stack analyses can give of the entire SOFC module. The environmental performance is measured verifying the negligible values of NO emissions (&lt;10 ppb) across the whole polarisation curve.<br/> &copy; 2017 Elsevier B.V.},
key = {Solid oxide fuel cells (SOFC)},
keywords = {Atmospheric thermodynamics;Carbon;Electrodes;Emission control;Environmental management;Fuel cells;Neutron emission;Polarization;Sensitivity analysis;Zirconia;},
note = {Combined heat and power units;Environmental performance;Experimental;Micro-CHP;Polarisation curves;Short stack;Sr-doped lanthanum manganites;Steady state performance;},
URL = {http://dx.doi.org/10.1016/j.jpowsour.2017.10.028},
} 


@inproceedings{20112414063942 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Proactive performance testing using SQL performance assurance services (SQL-PASS)},
journal = {International Conference and Workshop on Emerging Trends in Technology 2011, ICWET 2011 - Conference Proceedings},
author = {Tendulkar, D.M. and Phalak, C.},
year = {2011},
pages = {541 - 547},
abstract = {The information systems are becoming more and more complex and it is very common these days where database sizes are in hundreds of GBs. Handling of such large data volumes is creating challenges for assuring the performance of end-user applications. Applications involving database transactions are worst hit as there is no clue about the time required to fetch the relevant data from the huge database. The tools available in the market and the existing methodologies are suitable for the production environment but not effective in the development environment. This creates a gap between database application development and its deployment in the production environment. Therefore assuring the performance against high volume is an indisputable problem faced by the application developer and tester. In this paper, we discuss the work done in industry to tackle the SQL performance problem arising because of large data volumes and present SQL-PASS (SQL Performance Assurance Services), a web based service developed by TCS innovation Lab - Performance engineering, which helps to validate the SQL performance against high volumes without using actual data. We will also discuss how this service has been used in the development project to assure the performance. Copyright &copy; 2011 ACM.<br/>},
key = {Query processing},
keywords = {Database systems;},
note = {Database statistics;Explain plan;Query execution time;Query optimization;SQL performance;},
URL = {http://dx.doi.org/10.1145/1980022.1980138},
} 


@inproceedings{2006079707647 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stress testing real-time systems with genetic algorithms},
journal = {GECCO 2005 - Genetic and Evolutionary Computation Conference},
author = {Briand, Lionel C. and Labiche, Yvan and Shousha, Marwa},
year = {2005},
pages = {1021 - 1028},
address = {Washington, D.C., United states},
abstract = {Reactive real-time systems have to react to external events within time constraints: Triggered tasks must execute within deadlines. The goal of this article is to automate, based on the system task architecture, the derivation of test cases that maximize the chances of critical deadline misses within the system. We refer to that testing activity as stress testing. We have developed a method based on genetic algorithms and implemented it in a tool. Case studies were run and results show that the tool may actually help testers identify test cases that will likely stress the system to such an extent that some tasks may miss deadlines. Copyright 2005 ACM.},
key = {Real time systems},
keywords = {Genetic algorithms;Optimization;Scheduling;Stress analysis;Testing;},
note = {Reactive real-time systems;Schedulability theory;Stress testing;},
URL = {http://dx.doi.org/10.1145/1068009.1068183},
} 


@article{20181905157039 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Standard Practice for Performance Testing of Packages for Single Parcel Delivery Systems},
journal = {Standard Practice for Performance Testing of Packages for Single Parcel Delivery Systems},
year = {2016},
abstract = {Scope: This practice provides a uniform basis of evaluating, in a laboratory, the ability of shipping units, weighing up to but not exceeding 150 lb (68 kg), intended for the single parcel delivery system to withstand the hazards associated with the distribution environment. This is accomplished by subjecting them to a test plan consisting of a sequence of anticipated hazard elements encountered in the distribution cycles. This practice is not intended to supplant material specifications or existing pre-shipment test procedures. The suitability of this practice for use with hazardous materials has not been determined. The values stated in inch-pound units are to be regarded as standard. The values given in parentheses are mathematical conversions to SI units that are provided for information only and are not considered standard. This standard does not purport to address all of the safety concerns, if any, associated with its use. It is the responsibility of the user of this standard to establish appropriate safety and health practices and determine the applicability of regulatory limitations prior to use. Specific precautionary statements are given in 1.1.<br/> &copy;2016 ASTM International. All rights reserved.},
key = {Hazards},
keywords = {Ships;Testing;},
note = {Distribution cycle;Material specification;Mathematical conversion;Performance testing;Safety and healths;Safety concerns;Standard practices;Test procedures;},
URL = {http://dx.doi.org/10.1520/D7386-16},
versions = {3},
} 


@inproceedings{1987010014238 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {ALTBACH UNIT NO. 5 - PERFORMANCE TEST EVALUATION USING GENERALIZED CORRECTION METHODS.},
journal = {American Society of Mechanical Engineers (Paper)},
author = {Herbig, H. and Keller, H. and Schaefer, K.H. and Gartner, G.},
year = {1986},
pages = {ASME, New York, NY, USA; IEEE, New York, NY, USA - },
issn = {04021215},
address = {Portland, OR, USA},
abstract = {General information is given on the Altbach-Deizisau Unit No. 5 and its initial start-up. The plant features a tandem-compound, double-flow, reheat steam turbine-generator. The subsequent acceptance tests serve as an example for the application of generalized correction methods. The intent of this paper is to give the reader further information on this comprehensive evaluation method. It is applicable for the same type of corrections as the correction curves provided by the manufacturers for the Group 2 corrections, as well as the feedwater cycle and generator-related Group 1 corrections of ASME PTC-6. A computer program was used to evaluate the examples given in this paper. Its algorithms are consistent with those given in the Generalized Correction Curves. Since this evaluation method also covers nuclear steam turbines, the recent acceptance test at the Grohnde Nuclear Power Plant is also presented as an additional example.},
key = {STEAM TURBINES},
keywords = {ELECTRIC POWER PLANTS - Federal Republic of Germany;NUCLEAR POWER PLANTS - Steam Turbines;STEAM POWER PLANTS - Reheat Cycle;TURBOMACHINERY - Testing;},
note = {ALTBACH-DEIZISAU UNIT 5;GENERALIZED CORRECTION METHODS;PERFORMANCE TEST EVALUATION;THERMAL ACCEPTANCE TESTS;},
} 


@article{20181905153810 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Standard Test Methods for Tire Performance Testing on Snow and Ice Surfaces},
journal = {Standard Test Methods for Tire Performance Testing on Snow and Ice Surfaces},
year = {2015},
abstract = {Scope: These test methods cover the evaluation of tire performance on snow and ice surfaces utilizing passenger car or light truck vehicles. Since the tires are evaluated as part of a tire/vehicle system, the conclusions reached may not be applicable to the same tires tested on a different vehicle. These test methods do not purport to identify every maneuver useful for determining tire performance in a winter environment. These test methods are not meant to evaluate vehicle performance. Allowing for the variability of test results with different vehicles, these procedures have been developed and selected to evaluate relative tire-snow performance. These test methods are suitable for research and development purposes, where tires are compared during a single series of tests. They may not be suitable for regulatory statutes or specification acceptance because the values obtained may not necessarily agree or correlate either in rank order or absolute traction performance level with those obtained under other environmental conditions on other surfaces or the same surface after additional use. The values stated in SI units are to be regarded as the standard. The values given in parentheses are for information only. This standard does not purport to address all of the safety concerns, if any, associated with its use. It is the responsibility of the user of this standard to establish appropriate safety and health practices and determine the applicability of regulatory limitations prior to use.<br/> &copy;2015 ASTM International. All rights reserved.},
key = {Vehicle performance},
keywords = {Automobile testing;Snow;Tires;},
note = {Environmental conditions;Research and development;Safety and healths;Safety concerns;Snow and ice;Standard test method;Tire performance;Traction performance;},
URL = {http://dx.doi.org/10.1520/F1572-08R15},
versions = {4},
} 


@inproceedings{20113614307645 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Macro stress testing with a macroeconomic credit risk model for China},
journal = {Communications in Computer and Information Science},
author = {Fang-Ying, Yuan},
volume = {227 CCIS},
number = {PART 4},
year = {2011},
pages = {25 - 31},
issn = {18650929},
abstract = {In order to test the overall credit risk of loans of China's banking system, a macroeconomic credit risk model is designed, including a multiple linear regression model describing default probability, and a set of regression models describing macroeconomic environment. Studies show that bank loan default rates and key macroeconomic factors are related. Then stress tests are implemented one by one according to different shocks. The results showed that most banks continue to profit even at 95% confidence level when estimated risk of loss, reflecting a moderate credit risk in the banking system. However, if confidence level rises to 99% when estimated risk of loss, the banking system will face significant losses. The results show that it is necessary to prevent the credit risk of real estate loans and government debt. &copy; 2011 Springer-Verlag.<br/>},
key = {Risk perception},
keywords = {Linear regression;Monte Carlo methods;Online systems;Risk assessment;},
note = {Confidence levels;Credit risk modeling;Credit risks;Default probabilities;Macroeconomic environments;Multiple linear regression models;Real estate loans;Stress Testing;},
URL = {http://dx.doi.org/10.1007/978-3-642-23226-8_4},
} 


@inproceedings{20083111420903 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Fourier spectrum-based signature test: A genetic CAD toolbox for reliable RF testing using low-performance test resources},
journal = {Proceedings of the Asian Test Symposium},
author = {Srinivasan, G. and Chatterjee, A. and Natarajan, V.},
year = {2007},
pages = {139 - 142},
issn = {10817735},
address = {Beijing, China},
abstract = {At the present time, coordinated EDA tools for RF/mixed-signal pin test do not exist In this paper, a CAD tool for efficient production testing of high-performance RF systems using low-cost baseband ATE is presented The CAD tool consists of a custom developed genetic ATPG for spectral (Fourier spectrum) signature-based alternate (to full specification-based tests) test of RF systems and involves co-simulation of scalable behavioral-level models of the RF System-Under-Test, baseband ATE test instrumentation, loadboard resources, and DfT resources for fast test vector optimization/generation. The CAD tool also enables the evaluation of various low-cost ATE architectures on the impact of the generated tests to provide a cost-effective solution. &copy; 2007 IEEE.<br/>},
key = {Computer aided design},
keywords = {Cost effectiveness;Costs;Multiobjective optimization;},
note = {Behavioral level;Co-simulations;Cost-effective solutions;Fourier spectra;Performance tests;Production testing;Signature tests;Test instrumentation;},
URL = {http://dx.doi.org/10.1109/ATS.2007.4387999},
} 


@article{2005369351319 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Sensor fusion of a railway bridge load test using neural networks},
journal = {Expert Systems with Applications},
author = {Ataei, Sh. and Aghakouchak, A.A. and Marefat, M.S. and Mohammadzadeh, S.},
volume = {29},
number = {3},
year = {2005},
pages = {678 - 683},
issn = {09574174},
abstract = {Field testing of bridge vibrations induced by passage of vehicle is an economic and practical form of bridge load testing. Data processing of this type of tests are usually carried out in a system identification framework using output measurements techniques which are categorized as parametric or nonparametric methods. These methods are based on the theory of probability. Learning theory which stems its origin from two separate disciplines of statistical learning theory and neural networks, presents an efficient and robust framework for data processing of such tests. In this article, the linear two layer feed forward neural network (NN) with back propagation learning rule has been adapted for strain and displacement sensors fusion of a railway bridge load test. The trained NN has been used for structural analysis and finite element (FE) model updating. &copy; 2005 Elsevier Ltd. All rights reserved.},
key = {Sensor data fusion},
keywords = {Data processing;Finite element method;Learning systems;Mathematical models;Mechanical testing;Neural networks;Railroad bridges;Sensors;Statistical methods;Strain;Vibrations (mechanical);},
note = {Lad test;Learning theory;Model updating;Railway bridges;Sensor fusion;},
URL = {http://dx.doi.org/10.1016/j.eswa.2005.04.038},
} 


@inproceedings{20142717907966 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Implementation of wheelchair motion control based on electrooculography using simulation and experimental performance testing},
journal = {Applied Mechanics and Materials},
author = {Mohd Noor, Nurul Muthmainnah and Ahmad, Salmiah and Sidek, Shahrul Naim},
volume = {554},
year = {2014},
pages = {551 - 555},
issn = {16609336},
abstract = {The aim of this study is to perform the experimental verification on the fuzzy-based control designed for wheelchair motion. This motion control based on the eye movement signals using electrooculograhphy (EOG) technique. The EOG is a technique to acquire the eye movement data from a person, i.e tetraplegia, which the data obtained, can be used as a main communication tool. This study is about the implementation of the designed controller using PD-type fuzzy controller and tested on the hardware of the wheelchair system using the eye movement signal obtained through EOG technique as the motion input references. The results obtained show that the PD-type fuzzy logic controller designed has successfully managed to track the input reference for linear motion set (forward and backward direction) by the EOG signal. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Eye movements},
keywords = {Controllers;Fuzzy logic;Motion control;Wheelchairs;},
note = {Communication tools;EOG;Experimental verification;Eye movement datum;Forward-and-backward;Fuzzy logic controllers;Performance testing;Tetraplegia;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.554.551},
} 


@inproceedings{1985020025205 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {ASME PERFORMANCE TEST ON TVA SEQUOYAH UNIT 1.},
journal = {American Society of Mechanical Engineers (Paper)},
author = {Deming, N.R. and Moradian, M.A. and Arnold, G.I. and Hurt, K.T.},
year = {1984},
pages = {IEEE, New York, NY, USA; ASME, New York, NY, USA; ASCE, New York, NY, USA - },
issn = {04021215},
address = {Toronto, Ont, Can},
abstract = {In April 1983 an ASME Performance Test was conducted on the Sequoyah 1 nuclear turbine-generator unit. Test data were collected using a mobile computer-controlled data-acquisition system. Consistent test results were achieved which showed that the unit performed better than expected. Earlier calorimetric analysis had indicated that the unit was not generating the expected electrical output. These earlier results were based on final feedwater flow measurement using permanently-installed station venturis. The ASME tests, which employed calibrated ASME throat-tap nozzles to measure feedwater flow, showed that the permanently-installed venturis had been indicating high, thereby causing the unit to be operated at less than 100 percent thermal power prior to the ASME test. The causes of this discrepancy are discussed. This paper includes a description of the test program and testing procedures and the performance of the major components of the heat cycle.},
key = {NUCLEAR POWER PLANTS},
note = {ASME PERFORMANCE TESTS;CALORIMETRIC ANALYSIS;STATION VENTURIS;THROAT-TAP NOZZLES;TVA SEQUOYAH UNIT 1;},
} 


@article{20154301420685 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Optical performance test  analysis of intraocular lenses},
journal = {ProQuest Dissertations and Theses Global},
author = {Choi, Junoh},
year = {2008},
abstract = {Cataract is a condition in the eye that if left untreated, could lead to blindness. One of the effective ways to treat cataract is the removal of the cataractous natural crystalline lens and implantation of an artificial lens called an intraocular lens(IOL). The designs of the IOLs have shown improvements over the years to further imitate natural human vision. A need for an objective testing and analysis tool for the latest IOLs grow with the advancements of the IOLs. In this dissertation, I present a system capable of objective test and analysis of the advanced IOLs. The system consists of (1) Model eye into which an IOL can be inserted to mimic conditions of the human eye. (2) Modulation Transfer Function measurement setup capable of through-focus test for depth of field studies and polychromatic test for study of effects of chromatization. (3) Use of Defocus Transfer Function to simulate depth of field characteristic of rotationally symmetric multifocal designs and extension of the function to polychromatic conditions. (4) Several target imaging experiments for comparison of stray light artifacts and simulation using a non-sequential ray trace package. ProQuest Subject Headings: Optics, Ophthalmology.  &copy; Citation reproduced with permission of ProQuest LLC.},
key = {Intraocular lenses},
keywords = {Lenses;Ophthalmology;Stray light;Transfer functions;},
note = {Analysis tools;Crystalline lens;Depth of field;Health science;Modulation transfer function measurements;Optical performance;Target imaging;Test and analysis;},
} 


@inproceedings{20110413612293 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Real-time performance test of an vision-based inertial SLAM},
journal = {ICCAS 2010 - International Conference on Control, Automation and Systems},
author = {Yun, Sukchang and Lee, Byoung-Jin and Lee, Young Jae and Sung, Sangkyung},
year = {2010},
pages = {2423 - 2426},
abstract = {Despite its precise positioning performance, a GPS based navigation system may require the reference or augmentation station in close boundaries and is liable to be affected by satellite observation environments. Thus, this paper presents a vision-based inertial SLAM navigation system which can operate in a real-time manner and uses purely unknown feature points in order to cope with the limited GPS/INS integration environment. And real-time performance of the presented system is verified via indoor test. &copy;ICROS.<br/>},
key = {Global positioning system},
keywords = {Indoor positioning systems;},
note = {GPS-based navigation systems;Heterogeneous sensors;Precise positioning;Real time;Real time performance;Relative positioning;Satellite observations;Vision sensors;},
} 


@inproceedings{20141117443366 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling based on T-S model for thermal process in metallurgical performance testing},
journal = {Advanced Materials Research},
author = {Xie, Dong and Wang, Min and Shi, Jing Liang and Xu, Di Jian and Wang, Hua Bing},
volume = {889-890},
year = {2014},
pages = {699 - 702},
issn = {10226680},
address = {Kunming, China},
abstract = {Most of metallurgical performance testing devices use small high-temperature furnace to simulate physical environment for the sample testing. Since the controlled object has the dynamic characteristics of nonlinear, time-varying, large delay and large inertia during heating process, it is difficult to establish an accurate models to control thermal processes and optimize. This paper presents an adaptive neural fuzzy modeling approach based on T-S model for the heating process. Using the fuzzy system structure identification and parameter identification, the more accurate nonlinear model can be obtained. Duo to the fuzzy neural network has the capability of autonomous, quickly and effectively converging to the required relations of the input and output, the modeling accuracy has been improved. The simulation results demonstrate the effectiveness of the proposed algorithm, and the method can provide a reference for obtaining accurate nonlinear model. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Process control},
keywords = {Fuzzy neural networks;Nonlinear systems;Pyrometallurgy;},
note = {Adaptive neural networks;Dynamic characteristics;Heating process;High temperature furnaces;Metallurgical performance;Nonlinear;Physical environments;T S models;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMR.889-890.699},
} 


@inproceedings{20101712874755 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and performance test of relative navigation of a low cost inertial SLAM},
journal = {ICCAS-SICE 2009 - ICROS-SICE International Joint Conference 2009, Proceedings},
author = {Yun, Sukchang and Sung, Sangkyung and Lee, Young Jae},
year = {2009},
pages = {4217 - 4221},
address = {Fukuoka, Japan},
abstract = {Despite its precise positioning performance, a GPS based navigation system may require the reference or augmentation station in close boundaries and is liable to be affected by satellite observation environments. Thus, this paper presents an INS/vision sensor integrated system, which in principle uses purely unknown feature points in previous epochs in order to cope with the limited GPS/INS integration environment. For the implementation of three-dimensional navigation using feature points, the presented system takes advantage of a robust image extraction and tracking algorithm, data association, and inertial SLAM filter algorithm. Finally, experimental results verified the performance of integrated navigation system, through which the performance enhancement in estimating relative position of the vehicle is demonstrated effectively. &copy; 2009 SICE.<br/>},
key = {Global positioning system},
keywords = {Air navigation;},
note = {GPS/INS;Integrated navigation;Positioning;SLAM;Vision sensors;},
} 


@article{20133316616981 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Load settlement response of footing placed over buried flexible pipe through a model plate load test},
journal = {International Journal of Geomechanics},
author = {Srivastava, Amit and Goyal, Chaitanya R. and Raghuvanshi, Abhishek},
volume = {13},
number = {4},
year = {2013},
pages = {477 - 481},
issn = {15323641},
abstract = {This paper presents the load-settlement response of a surface footing placed over buried flexible pipe through model plate load tests. Experiments are conducted in a rectangular box after placing a model footing on the surface of sand placed at two different relative densities. Combination of tests were performed, such as, (1) model footing placed over sand compacted at low relative density (RD = 50%) and model buried flexible pipe (PVC pipe) placed at 0.5 B and 1.0 B depth, and (2) model footing placed over sand compacted at high relative density (RD = 88%) and model buried flexible pipe (PVC pipe) placed at 0.5 B &amp; 1.0 B depth; where B = diameter of the model footing. The results of the model plate load test provide useful interpretation about the combined behavior of buried flexible pipe-soil system in terms of load-settlement response. The influence on the bearing capacity of sand in different relative densities and that caused by the presence of a buried flexible pipe beneath the footing is also discussed. Experimental results are also verified numerically using the two-dimensional finite-element tool PLAXIS, and results are discussed in light of the experimental findings. Furthermore, a soil nailing technique is also explored experimentally and numerically to establish its usefulness in terms of improving the bearing capacity of the buried flexible pipe soil system in a given sand medium. &copy; 2013 American Society of Civil Engineers.},
key = {Pipe},
keywords = {Bearing capacity;Finite element method;Polyvinyl chlorides;Sand;Soils;Structural analysis;},
note = {Buried flexible pipes;High relative densities;Load settlement;Plate load tests;Rectangular box;Relative density;Soil systems;Soil-nailing;},
URL = {http://dx.doi.org/10.1061/(ASCE)GM.1943-5622.0000228},
} 


@inproceedings{20141117443232 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {3D parametric design and performance test of precision cam divider},
journal = {Advanced Materials Research},
author = {Xu, Nian Fu and He, Wei},
volume = {889-890},
year = {2014},
pages = {22 - 27},
issn = {10226680},
address = {Kunming, China},
abstract = {The precision cam divider is mainly used for intermittent motion, such as transmission of mechanisms of various automatic production lines. It exhibits properties of high speed, high precision, high stability and accurate indexing, however, design and manufacture of globoidal indexing cam is cumbersome. In consideration of convenience for design, this paper develops CAD/CAM system for globoidal indexing cam mechanism in Pro/E environment for the second time. Main ideas of the paper are reflected in parametric design of globoidal indexing cam and transposition disc by means of Pro/E secondary development system, dynamic assembly, simulation and performance test so that the properties of product can achieve satisfactory result. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Indexing (of information)},
keywords = {Cams;Manufacture;Product design;Testing;},
note = {3D parametric designs;Automatic production line;Design and manufactures;Globoidal indexing cam;Parametric;Precision cam divider;Pro/E;Pro/e secondary development;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMR.889-890.22},
} 


@inproceedings{20102613036424 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and performance test of relative navigation of a low cost inertial SLAM},
journal = {ICCAS-SICE 2009 - ICROS-SICE International Joint Conference 2009},
author = {Yun, Sukchang and Sung, Sangkyung and Lee, Young Jae},
year = {2009},
pages = {4217 - 4221},
address = {Fukuoka, Japan},
abstract = {Despite its precise positioning performance, a GPS based navigation system may require the reference or augmentation station in close boundaries and is liable to be affected by satellite observation environments. Thus, this paper presents an INS/vision sensor integrated system, which in principle uses purely unknown feature points in previous epochs in order to cope with the limited GPS/INS integration environment. For the implementation of three-dimensional navigation using feature points, the presented system takes advantage of a robust image extraction and tracking algorithm, data association, and inertial SLAM filter algorithm. Finally, experimental results verified the performance of integrated navigation system, through which the performance enhancement in estimating relative position of the vehicle is demonstrated effectively. &copy; 2009 SICE.},
key = {Global positioning system},
keywords = {Air navigation;Navigation systems;Tracking (position);},
note = {GPS/INS;Integrated navigation;Positioning;SLAM;Vision sensors;},
} 


@article{20181705071041 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Standard Practice for Performance Testing of Packages for Single Parcel Delivery Systems},
year = {2012},
abstract = {Scope: This practice provides a uniform basis of evaluating, in a laboratory, the ability of shipping units, weighing up to but not exceeding 150 lb (68 kg), intended for the single parcel delivery system to withstand the hazards associated with the distribution environment. This is accomplished by subjecting them to a test plan consisting of a sequence of anticipated hazard elements encountered in the distribution cycles. This practice is not intended to supplant material specifications or existing pre-shipment test procedures. The suitability of this practice for use with hazardous materials has not been determined. The values stated in inch-pound units are to be regarded as standard. The values given in parentheses are mathematical conversions to SI units that are provided for information only and are not considered standard. This standard does not purport to address all of the safety concerns, if any, associated with its use. It is the responsibility of the user of this standard to establish appropriate safety and health practices and determine the applicability of regulatory limitations prior to use. Specific precautionary statements are given in 1.1.<br/> &copy;2012 ASTM International. All rights reserved.},
key = {Hazards},
keywords = {Ships;Testing;},
note = {Distribution cycle;Material specification;Mathematical conversion;Performance testing;Safety and healths;Safety concerns;Standard practices;Test procedures;},
URL = {http://dx.doi.org/10.1520/D7386-12},
versions = {3},
} 


@inproceedings{20071310512295 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Comprehensive performance test strategies for liquid-fuel fired boilers under the HWC MACT phase II standards},
journal = {A and WM, Annual International Conference on Incineration and Thermal Treatment Technologies, IT3},
author = {McBride, Chris E. and Schomer, Terry L.},
volume = {2},
year = {2006},
pages = {423 - 454},
address = {Savannah, GA, United states},
abstract = {The October 12, 2005 HWC MACT Phase II provisions for liquid-fuel fired boilers (LFBs, inclusive of process heaters) considerably altered the regulatory framework for performance testing and establishing final operating limits as compared to the RCRA boiler and industrial furnace (BIF) standards, especially as they apply to compliance with metals and HCl/Cl<inf>2</inf> emission standards. Additionally, the HWC MACT rule introduces a fundamentally different approach compared to RCRA for establishing operating limits by prescribing specific types of limits within the body of the rule based on the individual features of the combustor system and emissions control devices. Previously, the RCRA BIF delineated only a few specific limits leaving the bases for establishment of those and most of the other operating limits via related guidance and unit/site-specific considerations. Due to the prescriptive aspect of the HWC MACT provisions, personnel involved in test planning activities are faced with a more arduous task in evaluating the various compliance scenarios and options available to them, and then making very important and often immutable compliance decisions in an informed manner. This paper focuses on key aspects of the HWC MACT Phase II provisions that impact the initial evaluation of compliance, performance testing and subsequent ongoing compliance for LFBs. Topics include: Comparison of thermal concentration approach versus the mass concentration approach to metals and HCl/Cl<inf>2</inf> emissions compliance Identification of prescribed operating limits, and options that exist within the rule Delineation of a general test strategy for demonstrating the three most critical operating limits, and Opportunities to utilize the broadly applicable alternative monitoring provisions in 63.1209(g) to substitute more appropriate, unit-specific methods of compliance demonstration to those prescribed by the HWC MACT rule. Time sensitive and interrelated aspects of these issues and decisions are addressed. How these decisions could impact the methodology for complying with future operating limits is also examined. A number of example cases are provided to help illustrate the benefits of making informed, strategic decisions early on in the HWC MACT compliance process.},
key = {Oil fired boilers},
keywords = {Combustors;Emission control;Hydrochloric acid;Industrial furnaces;Liquid fuels;Standards;},
note = {Mass concentration;Process heaters;Regulatory frameworks;},
} 


@inproceedings{20100212618399 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Advanced load-testing techniques for a science archive},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Legassie, Mark and Bennett, Lee and Comeau, Susan and Dodd, Suzanne},
volume = {7016},
year = {2008},
pages = {SPIE Europe; The International Society for Optical Engineering (SPIE) - },
issn = {0277786X},
address = {Marseille, France},
abstract = {Performance goals for data archive systems need to be established early in the design process to ensure stability and acceptable response throughput. Load testing is one technique used to measure the progress towards these performance goals. Providing resources for load-test planning is critical, and this planning must include feasibility studies, tool analyses, and generation of an overall load-test strategy. This strategy is much different for science data archives than other systems, including commercial websites and high-volume data centers. This paper will provide an overview of the load testing performed on the Spitzer Space Telescope's science archive, which is part of Science Operations System at the Spitzer Science Center (SSC). Methods used for planning and conducting SSC load tests will be presented, and advanced load-testing techniques will be provided to address runtime issues and enhance verification results. This work was performed at the California Institute of Technology under contract to the National Aeronautics and Space Administration. &copy; 2008 Copyright SPIE - The International Society for Optical Engineering.<br/>},
key = {Load testing},
keywords = {NASA;Observatories;Space telescopes;Testing;},
note = {California Institute of Technology;Commercial websites;Feasibility studies;Performance testing;Science archive;Science operations;Spitzer space telescope;Verification results;},
URL = {http://dx.doi.org/10.1117/12.788045},
} 


@inproceedings{20163302705612 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Mechanical design and initial performance testing of an apple-picking end-effector},
journal = {ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE)},
author = {Davidson, Joseph R. and Mo, Changki},
volume = {4A-2015},
year = {2015},
pages = {American Society of Mechanical Engineers (ASME) - },
address = {Houston, TX, United states},
abstract = {The fresh market apple industry currently relies on manual labor for all harvesting activities. The lack of mechanical harvesting technologies is a serious concern because of rising labor costs and increasingly uncertain labor availability. Researchers have been working for several decades to develop mechanical harvesters for tree fruit. The two fruit removal methods considered include mass mechanical harvesters and selective harvesting with robotics technology. Whereas mass mechanical harvesters have demonstrated unacceptable damage rates, robotic systems have been limited by insufficient speed and robustness. This paper describes the design and analysis of a novel underactuated end-effector fabricated for the robotic harvesting of tree fruit. The device has been optimized around a set of target tasks, the most critical being speed, low complexity, suitability for a highly variable field environment, and the replication of hand picking so as to minimize fruit damage. Development of the end-effector has been facilitated by a thorough study of the dynamic forces involved during the manual harvesting of apples. The end-effector produces a spherical power grasp with a normal force distribution and picking sequence replicating selected human patterns. An underactuated, tendon-driven device with compliant flexure joints has been adopted to improve system performance in the presence of position errors as well as enhance robustness to variable fruit size, shape, and orientation. The prototype end-effector also uses minimal sensors and incorporates open-loop control to reduce complexity and improve picking speed. This paper presents the theoretical analysis of the end-effector kinematics and discusses the selection of key geometric parameters. Experiments have been conducted to determine the normal forces developed during grasping of the apple. Results indicate that open-loop, feedforward control can be used to produce optimal normal force patterns. Copyright &copy; 2015 by ASME.},
key = {Robotics},
keywords = {Compensation (personnel);End effectors;Forestry;Fruits;Harvesters;Harvesting;Robustness (control systems);Wages;},
note = {Design and analysis;Harvesting activities;Mechanical design;Normal force distribution;Open loop control;Performance testing;Robotics technology;Selective harvesting;},
URL = {http://dx.doi.org/10.1115/IMECE2015-50482},
} 


@inproceedings{1994031229773 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Volumetric performance testing using laser diagonals and telescoping ball bar},
journal = {SME Technical Paper (Series) IQ},
author = {Denomme, Michael E. and Callaghan, Robert},
year = {1993},
pages = {1 - 13},
abstract = {History and objectives of volumetric performance testing of machine tools in accordance with ANSI/ASME B5.54 laser diagonals and telescoping ball bars will be presented. Test equipment, methods of data acquisition and analysis will be reviewed. Case studies will be presented in support of the technical application of this type of machine tool performance evaluation.},
} 


@inproceedings{2002246979163 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Study using position silicon detectors for performance testing of computer numerically controlled machine tools},
journal = {Proceedings of the Institution of Mechanical Engineers, Part B: Journal of Engineering Manufacture},
author = {Jywe, W.},
volume = {216},
number = {5},
year = {2002},
pages = {725 - 733},
issn = {09544054},
abstract = {In this paper, various contouring test systems for computer numerically controlled (CNC) machine tools are reviewed. It is the first time a laser diode and a quadrant sensor have been employed to build a simple contouring measuring system for testing dynamic performance of a CNC machine tool. The experimental work on a CNC machine tool with a Fanuc OM controller for various contouring paths under specified feed rates is carried out. Then, the compensation work is executed with the assistance of this developed contouring system. After the compensation, the contouring error, especially at a high feed rate and small radius, is reduced significantly.},
key = {Machine tools},
keywords = {Computer control systems;Control equipment;Cutting;Error analysis;Machining;Numerical control systems;Semiconductor lasers;Silicon sensors;},
note = {Computer numerically controlled (CNC) machine tools;},
URL = {http://dx.doi.org/10.1243/0954405021520418},
} 


@inproceedings{20124015535305 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A DOE to assess PCB fabrication material design and process using IST (Interconnect Stress Testing) to improve fine pitch BGA via reliability},
journal = {IPC - IPC Printed Circuits Expo, APEX and the Designers Summit 2007},
author = {Narayanaswamy, Mahesh and Gonzalez, Reinaldo},
volume = {3},
year = {2007},
pages = {1530 - 1561},
address = {Los Angeles, CA, United states},
abstract = {During the development of a new medical imaging system, via quality was identified as a potentially source of infantile failures. Premature via failures were precipitated in a critical 14 layer board, specifically in the 0.8 mm BGA vias with an aspect ratio of approximately 9:1. Failure analysis indicated two dominant failure mechanisms: dry film lock-in, and drill debris in the via barrel causing insufficient plating of the via sidewall. Dry-film lock-in was corrected by process control improvements at the fab supplier. The fab material was identified as a major driver in the presence of drill debris in the via barrel. To address these infant mortality issues and to demonstrate long term via reliability, IST testing was identified as an industry recognized tool to quickly assess fab reliability. Three parameters were identified as key variables in fine-pitch via quality and reliability: fab resin material, inclusion of non-functional pads (NFP), and type of drill machine at the fab supplier. A DOE was developed to understand the influence of these factors on overall via reliability. The following conclusions were observed. The lower CTE fab material outperformed the other fab materials in mean cycles to failure (CTF). In addition, an interesting result with NFPs was found. Contradictory to industry recommendations, the presence of NFPs actually improved the mean CTF for the same material and process. The drill machine had little to no influence on CTF for the same material and design. In addition, at the lead-free preconditioning temperature, separation of the glass fiber bundles was observed in most of the materials tested. An understanding of this phenomenon and the other failure modes is critical to developing a robust lead-free fab.<br/>},
key = {Printed circuit boards},
keywords = {Aspect ratio;Ball grid arrays;Debris;Drills;Locks (fasteners);Medical imaging;Reliability;},
note = {Control improvements;Failure mechanism;Glass fiber bundles;Infant mortality;PCB fabrication;Resin materials;Stress Testing;Three parameters;},
} 


@inproceedings{20140617284108 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A mechatronic load testing equipment},
journal = {20th Annual International Conference on Mechatronics and Machine Vision in Practice, M2VIP 2013},
author = {Yildiran, H. Orhan and Gurel, Cahit},
year = {2013},
pages = {17 - 25},
address = {Ankara, Turkey},
abstract = {In a Project given to 2<sup>nd</sup>year students in Engineering Mechanics I (Statics) course the students are required to make calculations and prototype of a spring link- rigid body link weight carrying body with concurrent forces in 2D. Unfortunately the student had problems in visualization of the problem and also the solution. In this paper a prototype is shown (manufactured) which have an output of the results so as to use these results in checking calculation and visualization of the system in a lab environment study. Results are given to the students as: Theoretical, mechanical, through potentiometric device readings and by image processing. By this test apparatus, students change connection points and the weights and make the calculations to find forces in elements, displacement of spring and the angles that links make with horizontal. They see the results as; change in length of spring, the forces in each member visually on LCD (PC) and compare their results. The main object of this equipment, is to make Mechatronics Engineering students understand the problem better, check their results, meet with future mechatronic devices they will see in their following semesters and have an understanding of what mechatronic systems are.<br/>},
key = {Load testing},
keywords = {Computer vision;Image processing;Measurement;Potentiometers (electric measuring instruments);Potentiometers (resistors);Students;Visualization;Voltage dividers;},
note = {Connection points;Engineering mechanics;Force systems;Mechatronic devices;Mechatronic systems;Mechatronics engineerings;Statics;Testing equipment;},
} 


@article{20074310886669 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test data analysis of scintillation cameras},
journal = {IEEE Transactions on Nuclear Science},
author = {Demirkaya, Omer and Al Mazrou, Refaat},
volume = {54},
number = {5},
year = {2007},
pages = {1506 - 1515},
issn = {00189499},
abstract = {In this paper, we present a set of image analysis tools to calculate the performance parameters of gamma camera systems from test data acquired according to the National Electrical Manufacturers Association NU 1-2001 guidelines. The calculation methods are either completely automated or require minimal user interaction; minimizing potential human errors. The developed methods are robust with respect to varying conditions under which these tests may be performed. The core algorithms have been validated for accuracy. They have been extensively tested on images acquired by the gamma cameras from different vendors. All the algorithms are incorporated into a graphical user interface that provides a convenient way to process the data and report the results. The entire application has been developed in MATLAB programming environment and is compiled to run as a stand-alone program. The developed image analysis tools provide an automated, convenient and accurate means to calculate the performance parameters of gamma cameras and SPECT systems. The developed application is available upon request for personal or non-commercial uses. The results of this study have been partially presented in Society of Nuclear Medicine Annual meeting as an InfoSNM presentation. &copy; 2007 IEEE.},
key = {Scintillation counters},
keywords = {Algorithms;Data reduction;Error analysis;Image analysis;MATLAB;Robust control;Single photon emission computed tomography;},
note = {Gamma camera systems;Performance measurement;Scintillation cameras;},
URL = {http://dx.doi.org/10.1109/TNS.2007.906162},
} 


@inproceedings{20135117091334 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Noise and vibration reduction performance test of rubber damping pad under slab track in high speed railway},
journal = {2013 Joint Rail Conference, JRC 2013},
author = {Rong, Chen and Ping, Wang and Likang, Guo},
year = {2013},
address = {Knoxville, TN, United states},
abstract = {Rubber damping pad under ballastless slab track can isolate structure vibration and noise so as to reduce stress and wear of railway track components. In order to make scientific evaluation on the influence of rubber damping pad on the dynamic response of the track structure, focusing on the engineering practice of Chengdu-GuanDujiangyan high-speed railway, comparative test of slab track with and without rubber damping pad is carried out by using acceleration sensors, acoustic sensors, and dynamic data acquisition system. Spectrum analysis of vibration acceleration and noise test results shows that rubber damping pad under track slab can greatly isolate the substructure vibration of the track, the bridge vibration and ground vibration; vibration level of the base slab under the pad is reduced by about 20.1dB; the rubber damping pad can reduce some of the structure noise caused by the bridge structure vibration, but it has no significant effect on noise reduction of the whole system due to the influences of EMU pantograph's arc noise, severe air turbulence noise and field test environment. Copyright &copy; 2013 by ASME.},
key = {Damping},
keywords = {Dynamic response;Noise abatement;Railroad plant and structures;Railroad transportation;Rubber;Spectrum analysis;},
note = {Ballastless slab tracks;Engineering practices;Noise;Noise and vibration reductions;Scientific evaluations;Slab tracks;Vibration;Vibration acceleration;},
URL = {http://dx.doi.org/10.1115/JRC2013-2569},
} 


@article{1991100294507 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {SMT resin performance testing},
journal = {Connector Specifier},
author = {Podesta, Gerry},
volume = {7},
number = {3},
year = {1991},
pages = {42 - 45},
issn = {87564076},
abstract = {Connector tests under actual end-use testing are the most definitive approach to determining a resin's suitability for a connector application, but also is time-consuming and costly. While the performance of an end-use product actual is dependent upon a number of variables such as part design, molding conditions and end-use environment, non-traditional ASTM testing may assist in more accurately predicting resin performance. Specifically, ductility measurements that focus on elongation appear to be the best indicators of performance. A flexural strain test provides some indication of ductility, while the more exact instrumented impact test provides in-depth information.},
key = {Electric Connectors},
keywords = {Plastics, Reinforced - Glass Fiber;Polyethylene Terephthalates;Thermoplastics;},
note = {Connector Housing;Polybutylene Terephthalate (PBT);Polycyclohexane Terephthalate;Surface Mount Technology (SMT);Thermoplastic Resins;},
} 


@article{20091612039475 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Models for optimization of production environmental stress testing on electronic circuit packs},
journal = {International Journal of Reliability, Quality and Safety Engineering},
author = {Joyce, Toby and Honari, Bahman and Wilson, Simon and Donovan, John and Gaffney, Oonagh},
volume = {15},
number = {6},
year = {2008},
pages = {555 - 579},
issn = {02185393},
abstract = {The problem of optimizing accelerated production testing is a pressing one in most electronic manufacturing facilities. Yet, practical models are scarce in the literature, especially for testing high volumes of electronic circuit packs in failure-accelerating environments. In this paper, we develop both a log-linear and linear model, based initially on the Weibull distribution. The models developed are suitable for modeling accelerated production testing data from a temperature-cycled environment. The model is "piecewise" in that the failures in each discrete "piece" of the temperature cycle are modeled as if the testing was in parallel rather than sequential mode. An extra covariate is introduced to indicate age at the start of each piece. The failures in a piece then depend on the stress in the piece itself and the time elapsed to the start of the piece. This last dependence captures the influence of reliability growth and has the result of providing an alternative linear model to the log-linear one. The paper demonstrates a simpler use of Poisson regression. An application, using actual production data, is described. Uses of the Loglogistic, Logistic, Lognormal and Normal distributions are also illustrated. &copy; 2008 World Scientific Publishing Company.<br/>},
key = {Weibull distribution},
keywords = {Maximum likelihood;Normal distribution;Poisson distribution;Regression analysis;Timing circuits;},
note = {Accelerated stress testing;Environmental stress;Generalized linear model;Poisson regression;Weibull;},
URL = {http://dx.doi.org/10.1142/S0218539308003222},
} 


@article{20181705100969 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Standard Practice for Performance Testing of Packages for Single Parcel Delivery Systems},
year = {2008},
abstract = {Scope: This practice provides a uniform basis of evaluating, in a laboratory, the ability of shipping units, weighing up to but not exceeding 150 lb (68 kg), intended for the single parcel delivery system to withstand the hazards associated with the distribution environment. This is accomplished by subjecting them to a test plan consisting of a sequence of anticipated hazard elements encountered in the distribution cycles. This practice is not intended to supplant material specifications or existing pre-shipment test procedures. The suitability of this practice for use with hazardous materials has not been determined. The values stated in inch-pound units are to be regarded as standard. The values given in parentheses are mathematical conversions to SI units that are provided for information only and are not considered standard. This standard does not purport to address all of the safety concerns, if any, associated with its use. It is the responsibility of the user of this standard to establish appropriate safety and health practices and determine the applicability of regulatory limitations prior to use. Specific precautionary statements are given in 1.1.<br/> &copy;2008 ASTM International. All rights reserved.},
key = {Hazards},
keywords = {Ships;Testing;},
note = {Distribution cycle;Material specification;Mathematical conversion;Performance testing;Safety and healths;Safety concerns;Standard practices;Test procedures;},
URL = {http://dx.doi.org/10.1520/D7386-08},
versions = {3},
} 


@article{2004268234607 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing architecture for communication protocols},
journal = {Periodica Polytechnica Electrical Engineering},
author = {Szabo, Janos Zoltan},
volume = {47},
number = {1-2},
year = {2003},
pages = {101 - 113},
issn = {03246000},
abstract = {This paper presents a new model for distributed and parallel performance testing. The model has been designed to support testing based on language Testing and Test Control Notation version 3 (TTCN-3). Our test environment is capable of generating a realistic load towards the tested implementation with a large number of distributed parallel tester processes. The architecture is also able to operate on test systems with heterogeneous hardware and operating systems. We show the components of our model in details and demonstrate their operation and internal communication on examples. The practical issues of the test system implementation are also discussed. Some results from real life performance testing applications conclude the paper.},
key = {Network protocols},
keywords = {Computer hardware;Computer operating systems;Decoding;Encoding (symbols);Hierarchical systems;Mathematical models;Parallel processing systems;Synchronization;},
note = {Distributed testing;Performance testing;Test architecture;TTCN-3;},
} 


@inproceedings{20074610920951 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Web services wind tunnel: On performance testing large-scale stateful web services},
journal = {Proceedings of the International Conference on Dependable Systems and Networks},
author = {De Barros, Marcelo and Shiau, Jing and Shang, Chen and Gidewall, Kenton and Shi, Hui and Forsmann, Joe},
year = {2007},
pages = {612 - 617},
address = {Edinburgh, United kingdom},
abstract = {New versions of existing large-scale web services such as Passport.com&copy;have to go through rigorous performance evaluations in order to ensure a high degree of availability. Performance testing (such as benchmarking, scalability, and capacity tests) of large-scale stateful systems in managed test environments has many different challenges, mainly related to the reproducibility of production conditions in live data centers. One of these challenges is creating a dataset in a test environment that mimics the actual dataset in production. Other challenges involve the characterization of load patterns in production based on log analysis and proper load simulation via reutilization of data from the existing dataset. The intent of this paper is to describe practical approaches to address some of the aforementioned challenges through the use of various novel techniques. For example, this paper discusses data sanitization, which is the alteration of large dataseis in a controlled manner to obfuscate sensitive information, preserving data integrity, relationships, and data equivalence classes. This paper also provides techniques for load pattern characterization via the application of Markov Chains to custom and generic logs, as well as general guidelines for the development of cache-based load simulation tools tailored for the performance evaluation of stateful systems. &copy; 2007 IEEE.},
key = {Web services},
keywords = {Benchmarking;Computer simulation;Data acquisition;Information retrieval;Markov processes;},
note = {Capacity tests;Log analysis;Performance testing;Web services wind tunnels;},
URL = {http://dx.doi.org/10.1109/DSN.2007.102},
} 


@article{1998214152038 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Experimental approach characterizing rear bicycle derailleur systems Part I: Performance test},
journal = {International Journal of Vehicle Design},
author = {Lin, T.Y. and Tseng, C.H.},
volume = {19},
number = {3},
year = {1998},
pages = {356 - 370},
issn = {01433369},
abstract = {The derailleur system on a bicycle serves the same purpose as transmissions in motor vehicles: they provide different speed ratios for different situations. Cyclists can choose between speed and labour-saving by moving shift levers to complete a series of mechanical motions that change gears. Therefore, the shifting performance of the derailleur system is very important in designing derailleur system components. This paper proposes a systematic procedure for arranging the design steps for the derailleur system. It promises that the derailleur system components will integrate well and operate effectively. The performance test indices in the present paper can be used to judge the shifting performance during the period of shifting gears. Many design and manufacturing imperfections in products can also be found using the experimental results from performance test. Experimental procedures provide an environment that replaces subjective human `feel' tests used in the past.},
key = {Bicycles},
keywords = {Equipment testing;Gears;Nonmotorized transportation;},
note = {Rear bicycle derailleur systems;Shifting gear characteristic graph (SCG);},
} 


@inproceedings{20174404344908 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {PCLOS: Stress testing CLOS experiencing the metaobject protocol},
journal = {Proceedings of the European Conference on Object-Oriented Programming on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA/ECOOP 1990},
author = {Paepcke, Andreas},
year = {1990},
pages = {194 - 211},
address = {Ottawa, ON, Canada},
abstract = {This paper demonstrates that the CLOS metaobject protocol approach to defining and implementing an object model is very powerful. CLOS is an object-oriented language that is based on Common Lisp and is in the process of being standardized. Implementations of CLOS are themselves object-oriented with all major building blocks of the language being instances of system classes. A metaobject protocol provides a framework for CLOS implementations by specifying the hierarchy of these classes and the order and contents of the communication among their instances. This design has made CLOS both flexible and portable, two design goals that traditionally conflict. In support of this suggestion we present a detailed account of how we added object persistence to CLOS without modifying any of the language's implementation code. &copy; 1990 ACM.},
key = {Object oriented programming},
keywords = {Computer systems programming;LISP (programming language);},
note = {Building blockes;Design goal;Metaobject protocol;Object model;Object oriented;Stress Testing;},
URL = {http://dx.doi.org/10.1145/97945.97969},
} 


@article{20181705086141 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Standard Test Methods for Tire Performance Testing on Snow and Ice Surfaces},
year = {2005},
abstract = {Scope: These test methods cover the evaluation of tire performance on snow and ice surfaces utilizing passenger car or light truck vehicles. Since the tires are evaluated as part of a tire/vehicle system, the conclusions reached may not be applicable to the same tires tested on a different vehicle. These test methods do not purport to identify every maneuver useful for determining tire performance in a winter environment. These test methods are not meant to evaluate vehicle performance. Allowing for the variability of test results with different vehicles, these procedures have been developed and selected to evaluate relative tire-snow performance. These test methods are suitable for research and development purposes, where tires are compared during a single series of tests. They may not be suitable for regulatory statutes or specification acceptance because the values obtained may not necessarily agree or correlate either in rank order or absolute traction performance level with those obtained under other environmental conditions on other surfaces or the same surface after additional use. The values stated in SI units are to be regarded as the standard. The values given in parentheses are for information only. This standard does not purport to address all of the safety concerns, if any, associated with its use. It is the responsibility of the user of this standard to establish appropriate safety and health practices and determine the applicability of regulatory limitations prior to use.<br/> &copy;2005 ASTM International. All rights reserved.},
key = {Vehicle performance},
keywords = {Automobile testing;Snow;Tires;},
note = {Environmental conditions;Research and development;Safety and healths;Safety concerns;Snow and ice;Standard test method;Tire performance;Traction performance;},
URL = {http://dx.doi.org/10.1520/F1572-99R05},
versions = {4},
} 


@article{20181705102422 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Standard Test Methods for Tire Performance Testing on Snow and Ice Surfaces},
year = {2008},
abstract = {Scope: These test methods cover the evaluation of tire performance on snow and ice surfaces utilizing passenger car or light truck vehicles. Since the tires are evaluated as part of a tire/vehicle system, the conclusions reached may not be applicable to the same tires tested on a different vehicle. These test methods do not purport to identify every maneuver useful for determining tire performance in a winter environment. These test methods are not meant to evaluate vehicle performance. Allowing for the variability of test results with different vehicles, these procedures have been developed and selected to evaluate relative tire-snow performance. These test methods are suitable for research and development purposes, where tires are compared during a single series of tests. They may not be suitable for regulatory statutes or specification acceptance because the values obtained may not necessarily agree or correlate either in rank order or absolute traction performance level with those obtained under other environmental conditions on other surfaces or the same surface after additional use. The values stated in SI units are to be regarded as the standard. The values given in parentheses are for information only. This standard does not purport to address all of the safety concerns, if any, associated with its use. It is the responsibility of the user of this standard to establish appropriate safety and health practices and determine the applicability of regulatory limitations prior to use.<br/> &copy;2008 ASTM International. All rights reserved.},
key = {Vehicle performance},
keywords = {Automobile testing;Snow;Tires;},
note = {Environmental conditions;Research and development;Safety and healths;Safety concerns;Snow and ice;Standard test method;Tire performance;Traction performance;},
URL = {http://dx.doi.org/10.1520/F1572-08},
versions = {4},
} 


@inproceedings{1988010010235 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {ISDN PROTOCOL AND SERVICE VERIFICATION AND PERFORMANCE TESTING.},
journal = {Conference Record - International Conference on Communications},
author = {Kuzyszyn, Steven M. and Park, Kun I.},
year = {1987},
pages = {1356 - 1360},
issn = {05361486},
address = {Seattle, WA, USA},
abstract = {The multimanufacturer, multinetwork environment in the United States and the complicated protocols and novel technologies involved in ISDN (integrated services digital networks) make comprehensive, carefully planned testing a critical element in making ISDN implementation successful. A description is given of a microcomputer-based, field-deployable, sophisticated ISDN network test system that has been developed to meet this need. The discussion focuses on protocol, service, and network integration verification testing, performance testing, and the design and operation of the system.},
key = {COMPUTER NETWORKS},
keywords = {COMPUTERS, MICROCOMPUTER - Data Communication Systems;DIGITAL COMMUNICATION SYSTEMS - Voice/Data Integrated Services;TELECOMMUNICATION SYSTEMS - Testing;},
note = {CUSTOMER EMULATION MODULE (CEM);INTEGRATED SERVICES DIGITAL NETWORKS (ISDN);PROTOCOL, SERVICE &amp; NETWORK INTEGRATION VERIFICATION TESTING;},
} 


@article{1992090308747 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Method to determine the chatter threshold in the dynamic performance test of engine lathes},
journal = {Chung-Kuo Chi Hsueh Kung Ch'eng Hsueh Pao/Journal of the Chinese Society of Mechanical Engineers},
author = {Liao, Yunn-Shiuan and Ling, Yu-Liang},
volume = {9},
number = {4},
year = {1988},
pages = {303 - 310},
abstract = {This paper proposed a Variance-Control Chart for the detection of the onset of chatter during the dynamic performance test of engine lathes. The acceleration signal measured during the cutting test is passed through a low pass filter to retrieve the signal that is close to the chatter frequency before sampling. The variance in a pre-specified sampling period during the stable cutting conditions is estimated. The statistical quality control concept is then applied to set up the upper control limit. By comparing the sample variance of the coming filtered acceleration data with this value as cutting test proceeds, the onset of chatter is detected. It is found that this approach is objective and reliable. It can be employed for the performance test of other type of machine tools. The method also has a great potential in the application of machine tool chatter control.},
key = {Lathes},
keywords = {Machine Tools--Vibrations;Vibrations--Calculations;},
note = {Chatter Threshold;Control Chart;Dynamic Performance Test;Engine Lathes;},
} 


@inproceedings{1987070113855 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {PERFORMANCE TESTING OF REAL TIME COMPUTER NETWORKS.},
journal = {IEE Colloquium (Digest)},
author = {Collier, D.},
number = {1986 /28},
year = {1986},
pages = {5. 1 - 5. 6},
issn = {09633308},
address = {London, Engl},
abstract = {This paper is concerned with the verification of the performance of a high speed interprocessor communication network operating in a real time environment. The network forms a key element in a multiprocessor system which will be required to carry out plant control and monitoring operations. A program of testing has been implemented in a power station environment to assess the performance of a particular local area network technology for use real time process control and monitoring applications. The tests were proceeded by approximate theoretical and labatory studies to give baseline performance figures for this environment.},
key = {COMPUTER SYSTEMS, DIGITAL},
keywords = {COMPUTER NETWORKS - Performance;INDUSTRIAL PLANTS - Control;},
note = {INTERPROCESSOR COMMUNICATION NETWORKS;REAL-TIME COMPUTER NETWORKS;},
} 


@article{20070310377959 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of two-coat zinc-rich systems on steel bridges},
journal = {Journal of Protective Coatings and Linings},
author = {Chong, Shuang-Ling and Yao, Yuan},
volume = {23},
number = {11},
year = {2006},
pages = {72 - 83},
issn = {87551985},
abstract = {The Federal Highway Administration conducted a study to compare the performance the two-coat fast-dry systems with the conventional three-coat systems used for protecting steel bridges from corrosion. All of the coating systems were applied on steel surfaces that were abrasive blast-cleaned to SSPC SP-10 in accordance the manufacturer's specifications. The zinc content was determined by a combined scanning electron microscopy/energy dispersive X-ray spectrometry analysis (SEM/EDS) of an isolated pigment fraction. The surface failures such as blistering, rusting, and other imperfections were measured for scribe creepage at 500-hour laboratory test intervals. It was found that two-coat zinc rich primer/ fast-dry topcoat systems exhibited no rust creepage and scribe after the 500-hour accelerated laboratory test and the two-year outdoor exposure in salt-rich environment. Result shows that two-coat zinc-rich coating system can be used to protect steel structures from corrosion.},
key = {Protective coatings},
keywords = {Creep;Energy dispersive spectroscopy;Scanning electron microscopy;Steel bridges;Steel corrosion;},
note = {Performance testing;Pigment fraction;Three-coat systems;},
} 


@inproceedings{1998013925960 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Qualification program for DC-DC converters using accelerated stress testing},
journal = {Institute of Environmental Sciences - Proceedings, Annual Technical Meeting},
author = {Ellacott, Ken D. and Stone, Kevin P.},
year = {1996},
pages = {149 - 157},
issn = {00739227},
address = {Orlando, FL, USA},
abstract = {Printed circuit board mounted DC-DC power converters, also referred to as Point-of-Use Power Supplies (PUPS), are an integral and critical component of products developed and manufactured by Nortel. PUPS are the key interface between the incoming battery. feed voltage and the complex electronics that make up today's telecommunication products. Reliable power converters are necessary to ensure the lowest cost of system maintenance and the least possible customer service impact in the telecommunications environment. Many of the converters utilized in Nortel products are standard commercial units, available from a wide variety of manufacturers. With the recent proliferation of products using these devices, traditional qualification test methods had begun to prove incapable of assuring the high degree of reliability required by a demanding and competitive telecom equipment environment. This paper will describe an improved process used by Nortel to evaluate DC-DC power converter design quality and reliability.},
key = {Power converters},
keywords = {Printed circuit boards;Printed circuit testing;Stress analysis;},
note = {Point of use power supplies (PUPS);},
} 


@inproceedings{1997033427312 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Dynamic load testing of roller screw EMA's},
journal = {Proceedings of the Intersociety Energy Conversion Engineering Conference},
author = {Schinstock, Dale E. and Haskew, Tim A.},
volume = {1},
year = {1996},
pages = {221 - 226},
issn = {0146955X},
address = {Washington, DC, USA},
abstract = {In the Electromechanical Actuators (EMA) Laboratory at The University of Alabama a dynamic load test stand has been designed and built. This test stand uses large load, high bandwidth, hydraulic actuation to generate load profiles under force control. The test stand can accommodate EMA's up to six feet in length. It can generate dynamic loads of up to 100,000 lb at fundamental frequencies of up to 12 Hz against a stiff environment. This test stand has been used to generate severe loading conditions on a large roller screw in an attempt qualify the effects of large, high frequency loads on roller screw. During the tests performed in the EMA Laboratory the screw was fixed at one end and axial loads were applied to the roller nut at the other end. Since the end opposite the nut was fixed, only a small amount of relative rotation between the nut and screw was achieved. This rotation was the result of elastic deformation (wind up) of the screw along the length between the fixed end and the nut. This simulates a severe, but likely, application of the roller screw. The results of the tests performed demonstrate that roller screws may be damaged by dynamic loading with load magnitudes that are well within the static load rating of the screw. While the damage that was observed is not catastrophic, it would be expected to substantially decrease the life of the screw.},
key = {Electromechanical devices},
keywords = {Actuators;Deformation;Mechanical testing;Screws;},
note = {Axial loads;Dynamic load testing;Elastic deformation;Load profiles;Static load ratings;},
} 


@inproceedings{20131816286062 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {AUDIT: Stress testing the automatic way},
journal = {Proceedings - 2012 IEEE/ACM 45th International Symposium on Microarchitecture, MICRO 2012},
author = {Kim, Youngtaek and John, Lizy Kurian and Pant, Sanjay and Manne, Srilatha and Schulte, Michael and Bircher, W. Lloyd and Govindan, Madhu S. Sibi},
year = {2012},
pages = {212 - 223},
address = {Vancouver, BC, Canada},
abstract = {Sudden variations in current (large di/dt) can lead to significant power supply voltage droops and timing errors in modern microprocessors. Several papers discuss the complexity involved with developing test programs, also known as stress marks, to stress the system. Authors of these papers produced tools and methodologies to generate stress marks automatically using techniques such as integer linear programming or genetic algorithms. However, nearly all of the previous work took place in the context of single-core systems, and results were collected and analyzed using cycle-level simulators. In this paper, we measure and analyze di/dt issues on state-of-the-art multi-core x86 systems using real hardware rather than simulators. We build on an existing single-core stress mark generation tool to develop an Automated DI/dT stress mark generation framework, referred to as AUDIT, to generate di/dt stress marks quickly and effectively for multicore systems. We showcase AUDIT's capabilities to adjust to micro architectural and architectural changes. We also present a dithering algorithm to address thread alignment issues on multi-core processors. We compare standard benchmarks, existing di/dt stress marks, and AUDIT-generated stress marks executing on multi-threaded, multi-core systems with complex out-of-order pipelines. Finally, we show how stress analysis using simulators may lead to flawed insights about di/dt issues. &copy; 2012 IEEE.},
key = {Management},
keywords = {Computer architecture;Genetic algorithms;Hardware;Integer programming;Low power electronics;Microprocessor chips;Simulators;Stress analysis;},
note = {di/dt;Inductive noise;Low Power;Power distribution network;stressmark generation;Voltage droop;},
URL = {http://dx.doi.org/10.1109/MICRO.2012.28},
} 


@inproceedings{20161602247501 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic extraction of probabilistic workload specifications for load testing session-based application systems},
journal = {Proceedings of the 8th International Conference on Performance Evaluation Methodologies and Tools, VALUETOOLS 2014},
author = {Van Hoorn, Andre and Vogele, Christian and Schulz, Eike and Hasselbring, Wilhelm and Krcmar, Helmut},
year = {2014},
pages = {139 - 146},
address = {Bratislava, Slovakia},
abstract = {Workload generation is essential to systematically evaluate performance properties of application systems under controlled conditions, e.g., in load tests or benchmarks. The definition of workload specifications that represent the real workload as accurately as possible is one of the biggest challenges in this area. This paper presents our approach for the modeling and automatic extraction of probabilistic workload specifications for load testing session-based application systems. The approach, called Wessbas, comprises (i.) a domain-specific language (DSL) enabling layered modeling of workload specifications as well as support for (ii.) automatically extracting instances of the DSL from recorded sessions logs and (iii.) transforming instances of the DSL to workload specifications of existing load testing tools. During the extraction process, different groups of customers with similar navigational patterns are identified using clustering techniques. We developed corresponding tool support including a transformation to probabilistic test scripts for the Apache JMeter load testing tool. The evaluation of the proposed approach using the industry standard benchmark SPECjEnterprise2010 demonstrates its applicability and the representativeness of the extracted workloads. &copy; Copyright 2015 ICST.},
key = {Load testing},
keywords = {Benchmarking;Computer programming languages;Extraction;Modeling languages;Problem oriented languages;Specifications;},
note = {Application systems;Clustering;Clustering techniques;Controlled conditions;Domain specific languages;Industry-standard benchmarks;Navigational patterns;Performance properties;},
URL = {http://dx.doi.org/10.4108/icst.valuetools.2014.258171},
} 


@inproceedings{20104313329116 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design of BDI agent for adaptive performance testing of Web services},
journal = {Proceedings - International Conference on Quality Software},
author = {Ma, Bo and Chen, Bin and Bai, Xiaoying and Huang, Junfei},
year = {2010},
pages = {435 - 440},
issn = {15506002},
abstract = {As services are dynamic discovered and bound in the open Internet environment, testing has to be exercised continuously and online to verify and validate the continuous changes and to ensure the quality of the integrated service-based system. During this process, testing strategies have to be adapted in accordance to the changes in the environment and target systems. Software agents are characterized by context awareness, autonomous decision making and social collaboration capabilities. The paper introduces the design of BDI (Believe-Decision-Intention) agents to facilitate adaptive performance testing of Web Services. The BDI model specifies the necessary test knowledge, test goal and action plan to carry out test and adaptive schedule. Performance testing is defined as a scheduling problem to select the workload and test cases in order to achieve the goal of performance abnormal detection. A two-level control architecture is built. At the TR (Test Runner) level, the BDI agents control the workload of concurrent requests. At the TC (Test Coordinator) level, the BDI agents control the complexity of test cases. Agents communicate and collaborate with each other to share knowledge and test plan. The paper introduces the design of the BDI model, the adaptation rules and the control architecture. Case study is exercised to illustrate the adaptive testing process based on the design of BDI agents. &copy; 2010 IEEE.},
key = {Web services},
keywords = {Autonomous agents;Concurrency control;Decision making;Intelligent agents;Software agents;Web crawler;Websites;},
note = {Adaptive testing;Autonomous decision;BDI Agent;Collaboration capabilities;Concurrent requests;Control architecture;Internet environment;Performance testing;},
URL = {http://dx.doi.org/10.1109/QSIC.2010.69},
} 


@inproceedings{20095312600275 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of mobile applications at the unit test level},
journal = {SSIRI 2009 - 3rd IEEE International Conference on Secure Software Integration Reliability Improvement},
author = {Kim, Heejin and Choi, Byoungju and Wong, W. Eric},
year = {2009},
pages = {171 - 180},
address = {Shanghai, China},
abstract = {With the rapid growth of the wireless market and the development of various mobile devices, innovative methods and technologies to produce high-quality mobile applications and reduce time to market have been emerging. Mobile applications are often characterized by an array of limitations such as the short development lifecycle to gain a competitive advantage and difficulties to update once released. Hence, rigorous testing on the applications is required before distribution to the market, including structural white-box, functional black-box, integration and system testing. Although recently performance testing at the system test level has become crucial given its direct connection with the product quality improvement, most such tests are confined to the areas of load, usability, and stress testing. Moreover, the implementation itself is insufficient due to the limitations of the development environment. This paper proposes a method to support performance testing utilizing a database established through benchmark testing in emulator-based test environment at the unit test level. It also presents the tool that supports the proposed method of performance testing and verifies the reliability of performance test results through experiments. &copy; 2009 IEEE.<br/>},
key = {Integration testing},
keywords = {Benchmarking;Black-box testing;Commerce;Competition;Integration;Load testing;Mobile computing;Software reliability;Testing;},
note = {Benchmark testing;Competitive advantage;Development environment;Innovative method;Mobile applications;Performance testing;Performance tests;Quality improvement;},
URL = {http://dx.doi.org/10.1109/SSIRI.2009.28},
} 


@inproceedings{20172903964706 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Simulating user interactions: A model and tool for semi-realistic load testing of social app backend web services},
journal = {WEBIST 2017 - Proceedings of the 13th International Conference on Web Information Systems and Technologies},
author = {Brune, Philipp},
year = {2017},
pages = {235 - 242},
address = {Porto, Portugal},
abstract = {Many mobile apps today support interactions between their users and/or the provider within the app. Therefore, these apps commonly call a web service backend system hosted by the app provider. For the implementation of such service backends, load tests are required to ensure their performance and scalability. However, existing tools like JMeter are not able to simulate "out of the box" a load distribution with the complex time evolution of heterogeneous, real and interacting users of a social app, which e.g. would be necessary to detect critical performance bottlenecks. Therefore, in this paper a probabilistic model for simulating interacting users of a social app is proposed and evaluated by implementing it in a prototype load testing tool and using it to test a backend of new real-world social app currently under development. Copyright &copy; 2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
key = {Web services},
keywords = {Complex networks;Information systems;Load testing;Websites;},
note = {Mobile app;Mobile social networks;Model based testing;Performance and scalabilities;Performance bottlenecks;Probabilistic modeling;Support interaction;User simulation;},
} 


@inproceedings{2006169828455 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Bridge load rating using an integrated load testing and finite element analysis approach: A case study},
journal = {Proceedings, Annual Conference - Canadian Society for Civil Engineering},
author = {Halfawy, M.R. and Wipf, T. and Wood, D. and Abu-Hawash, A. and Phares, B.},
volume = {2002},
year = {2002},
pages = {1371 - 1379},
address = {Montreal, QB, Canada},
abstract = {Bridge load rating is the primary decision tool that is currently in use to evaluate and predict bridge performance under various loading conditions. Traditional bridge rating calculations involve calculating the load carrying capacity of the structural elements based on design plans, field inspection reports, and engineering judgment. Experience shows that bridge performance is always under-estimated using this simplified approach and in many cases results in placing unnecessary load restrictions on bridges. Bridge diagnostic load testing has been widely recognized as a more reliable and accurate method for bridge rating. However, the time and cost involved in conducting bridge load testing has been a major impediment to employing this valuable tool on a large scale. Bridge owners can typically only afford to perform load testing for major bridges and under critical circumstances. The need for more cost-effective and easy-to-implement methods to perform bridge load testing and rating analysis is well evident. In this paper, the use of an integrated system to conduct bridge load testing, finite element analysis, and rating is demonstrated. The system consists of load testing instrumentation and data acquisition hardware as well as four software components to perform structural analysis and rating calculations. A case study of a prestressed concrete bridge is presented to demonstrate the seamless integration of the load testing and analysis processes.},
key = {Load testing},
keywords = {Bridges;Data acquisition;Finite element method;Loading;Prestressed concrete;},
note = {Bridge load rating;Bridge performance;Decision tool;Instrumentation;},
} 


@inproceedings{20133716732140 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {WSCLT: A tool for WS-BPEL compositions load testing},
journal = {Proceedings of the Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises, WETICE},
author = {Maalej, Afef Jmal and Hamza, Manel and Krichen, Moez},
year = {2013},
pages = {272 - 277},
issn = {15244547},
address = {Hammamet, Tunisia},
abstract = {This paper addresses the load testing of WS-BPEL compositions. For that, we developed WSCLT tool, which takes as input a specification of the composition under test, expressed as a Timed Automaton, and considers various parameters such as the number of requests to handle simultaneously. Our WSCLT tool injects this load in the application and monitors the sequence of requests, invocations and responses between the components. This log is then analyzed by the tool to separate the actions corresponding to each instance and to check that they follow legitimate paths. A global report is then issued regarding all concurrent instances. We illustrate how to use our prototype tool by means of a case study. &copy; 2013 IEEE.},
key = {Tools},
keywords = {Automata theory;Load testing;},
note = {Log analysis;Prototype tools;Timed Automata;WS-BPEL;},
URL = {http://dx.doi.org/10.1109/WETICE.2013.71},
} 


@inproceedings{20163702805346 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The NRC human performance test facility: An approach to data collection using novices and a simplified environment},
journal = {Advances in Intelligent Systems and Computing},
author = {Hughes, Niav and DAgostino, Amy and Reinerman-Jones, Lauren},
volume = {495},
year = {2017},
pages = {183 - 192},
issn = {21945357},
address = {Walt Disney World, FL, United states},
abstract = {In the spring of 2012, as part of a &lsquo;hub and spoke&rsquo; model of research to address the human performance concerns related to current as well as new and advanced control room designs and operations, the U.S. Nuclear Regulatory Commission (NRC) sponsored a project to procure a low cost simulator to empirically measure and study human performance aspects of control room operations. Using this simulator, the Human Factors and Reliability Branch (HFRB) in the Office of Nuclear Regulatory Commission (NRC) began a program of research known as the NRC Human Performance Test Facility (HPTF) to collect empirical human performance data with the purpose of measuring and ultimately better understanding the various cognitive and physical elements that support safe control room operation. To accomplish this, HFRB first procured two 3-loop Westinghouse pressurized water reactor simulators with the capability to run a full range of power operation scenarios. HFRB staff work as co-investigators along with a team of researchers at the University of Central Florida (UCF) to design and carry-out a series of experiments aimed at measuring and understanding the human performance aspects of common control room tasks through the use of a variety of physiological and self-report metrics. The intent was to design experiments that balanced domain realism and laboratory control sufficiently to collect systematic, yet meaningful human performance data related to execution of common main control room (MCR) tasks. Investigators identified and defined three types of tasks that are examined in the present project: Checking, Detection, and Response Implementation. Task type presentation was partially counterbalanced to maintain ecologic validity with experimental control. A variety of subjective and physiological measures were used to understand performance of those tasks in terms ofworkload. The simulator used to collect these data was a digital representation of a generic analog NPP MCR interface. The data resulting from this experimentation enhances the current information gathering process, allowing for more robust technical bases to support regulatory guidance development and decision making. The present paper describes the approach behind this research effort. &copy; Springer International Publishing Switzerland 2017.},
key = {Data acquisition},
keywords = {Decision making;Design;Electric industry;Human computer interaction;Human engineering;Nuclear energy;Physiology;Pressurized water reactors;Simulators;Software testing;Test facilities;},
note = {Digital representations;Human performance;Information gathering;Main control room;Nuclear regulatory commission;Physiological measures;U.S. Nuclear Regulatory Commission;University of Central Florida;},
URL = {http://dx.doi.org/10.1007/978-3-319-41950-3_16},
} 


@inproceedings{20081111149955 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of the desdemona motion system},
journal = {Collection of Technical Papers - 2007 AIAA Modeling and Simulation Technologies Conference},
author = {Roza, Manfred and Wentink, Mark and Feenstra, Philippus},
volume = {1},
year = {2007},
pages = {275 - 288},
address = {Hilton Head, SC, United states},
abstract = {In the spring of 2007 TNO Human Factors together with AMST Systemtechnik GmbH have completed the development of their newest research simulator, the Desdemona, in The Netherlands. The Desdemona research simulator features a unique motion system not seen elsewhere in the world. Its serial design and geometrical dimensions give the motion system a large cylindrical motion space and a broad range of dynamic performance capabilities, which go beyond those of a classical Stewart platform. Like any other motion-base simulator the Desdemona motion system is driven by motion filters that transform the various simulation model outputs into safe and optimal motion cues. For the development of these motion filters it is necessary to exactly determine the dynamic performance characteristics of Desdemona and check whether these characteristics meet the specified motion system requirements. This paper describes the test protocol to measure, specify and verify the dynamic performance characteristics of the Desdemona motion system. The performance test protocol builds upon and extends the classical synergistic motion system test approaches, like the AGARD standard, to suite the specific Desdemona motion system capabilities.},
key = {Flight simulators},
keywords = {Computational geometry;Dynamic models;Motion control;Requirements engineering;},
note = {Motion filters;Motion systems;Synergistic motion system;},
} 


@inproceedings{20170503290813 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {GP-GPU based high-performance test equipment for debugging radar digital units},
journal = {Proceedings of 2016 International Conference on Data Mining and Advanced Computing, SAPIENCE 2016},
author = {Badarinath, R. and Abhilash, M.T.},
year = {2016},
pages = {387 - 391},
address = {Ernakulam, India},
abstract = {Modern active phased array radars are made to optimize the size, weight and power without compromising its capability to combat with advanced electronic warfare. To accomplish this task, the signal is digitized at element level or at sub-array level and processed with the help of advanced digital signal processor. Proving the capabilities of this firmware at bench level helps to reduce the overall development time. Hence, it is necessary to have a built-in test unit or test vector generator to verify the optimal performance of digital modules. The best way to accomplish this goal is to use a high speed baseband I &amp; Q radar data generator which helps in testing, identifying and segregating the problems at various stages. In this paper we have explored the capability of latest general purpose graphical processing unit (GP-GPU) as software defined built in test vector generator with high throughput for active array radar applications. &copy; 2016 IEEE.},
key = {Digital signal processors},
keywords = {Application programs;Data mining;Electronic warfare;Equipment testing;Firmware;Program processors;Radar;Radar signal processing;Signal processing;Software testing;},
note = {Active phased array radar;Built in tests;Development time;Digital beam forming;Graphical processing unit (GPUs);High throughput;Optimal performance;Performance tests;},
URL = {http://dx.doi.org/10.1109/SAPIENCE.2016.7684173},
} 


@inproceedings{20132716464670 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stress testing with a wireline tool using a drilled hole sealed with a compression pad},
journal = {Society of Petroleum Engineers - Abu Dhabi International Petroleum Exhibition and Conference 2012, ADIPEC 2012 - Sustainable Energy Growth: People, Responsibility, and Innovation},
author = {Edwards, John and Rodriguez, Adrian and Judd, Tobias and Kristensen, Morten and Tevis, Chris and Harrigan, Edward and Al Rashdi, Yaqoob and Hindriks, Cornelius},
volume = {2},
year = {2012},
pages = {819 - 827},
address = {Abu Dhabi, United arab emirates},
abstract = {A new method of stress testing with a wireline tool uses a drilled hole sealed with a compression pad to apply hydraulic pressure to the reservoir. Geomechanics modeling shows why this reduces the fracture initiation pressure and avoids intersecting the borehole with the induced fracture. The superposition of two induced stresses, mechanical and hydraulic, causes the tensile failure to initiate towards the end of the drilled hole as the hydraulic pressure is increased. The 9-mm-diameter hole is drilled from the center of the sealing compression pad to a depth of up to 15 cm. A fracture initiating some distance from the wellbore will be located part way through the near-wellbore perturbed stress field and will propagate away from the wellbore to the far field in the direction of reduced minimum stress. Reservoir simulation shows that the leakage rate of injected fluid around the compression pad is insignificant. The first jobs using this technique are described, including procedures for passive tool orientation so that the drilled hole is aligned with the maximum horizontal stress. Information revealed about breakdown pressures in tight dolomite explained why drilling-induced fractures were affecting resistivity logs and well test interpretation. The current procedure for stress testing is the pumping of drilling mud between inflated packers. The new technique described here solves two problems associated with the inflated packer method. The pumped fluid volumes are much smaller, so clean fracture fluid from a sample chamber can be used instead of mud. And the system compressibility is reduced, so the pressure transients are more responsive to the formation. The ability to induce a fracture in the formation with a pad tool using dedicated fluid with a low dead volume creates a new way of connecting to the reservoir, an alternative to connecting via the borehole wall surface. This large, undamaged contact area due to the induced fracture beyond the drilling-damaged zone will facilitate sampling low-permeability formations or high-viscosity oils. Copyright 2012, Society of Petroleum Engineers.},
key = {Horizontal drilling},
keywords = {Boreholes;Boring;Electric logging;Energy conservation;Fracture;Hydraulic fluids;Oil field equipment;Oil well drilling;Oil wells;Packers;Petroleum engineering;Stresses;Well testing;},
note = {Breakdown pressure;Fracture initiation pressures;High-viscosity oil;Horizontal stress;Hydraulic pressure;Pressure transient;Reservoir simulation;Well test interpretation;},
} 


@inproceedings{20143218026079 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Application research on distributed optical fiber monitoring technology in static load test of large diameter and post-grouting filling pile},
journal = {Applied Mechanics and Materials},
author = {Chen, Jia Xing and Zhou, Tong He and Guo, Yuan Cheng},
volume = {580-583},
year = {2014},
pages = {572 - 578},
issn = {16609336},
address = {Haikou, China},
abstract = {The Static load test of the post-grouting filling pile in Zhengzhou city's third ring road rapidness project, uses strain gauge and distributed optical fiber to track and monitor the evolution rule of load-settlement, pile body stress, pile side resistance, etc., interprets bearing properties of large diameter post-grouting filling pile, contrasts and analyzes the monitoring data obtained by optical fiber and strain gauge at the same time. The result shows that, the monitoring effect of the pile body stress obtained by distributed optical fiber technology is superior to the strain gauge, but the data of them still needs to verify each other. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Piles},
keywords = {Load testing;Optical fibers;Strain gages;},
note = {Application research;Bearing properties;Distributed optical fiber;Filling pile;Monitoring effect;Monitoring technologies;Side resistance;Static load tests;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.580-583.572},
} 


@article{20175204586748 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Exploiting load testing and profiling for Performance Antipattern Detection},
journal = {Information and Software Technology},
author = {Trubiani, Catia and Bran, Alexander and van Hoorn, Andre and Avritzer, Alberto and Knoche, Holger},
volume = {95},
year = {2018},
pages = {329 - 345},
issn = {09505849},
abstract = {Context: The performance assessment of complex software systems is not a trivial task since it depends on the design, code, and execution environment. All these factors may affect the system quality and generate negative consequences, such as delays and system failures. The identification of bad practices leading to performance flaws is of key relevance to avoid expensive rework in redesign, reimplementation, and redeployment. Objective: The goal of this manuscript is to provide a systematic process, based on load testing and profiling data, to identify performance issues with runtime data. These performance issues represent an important source of knowledge as they are used to trigger the software refactoring process. Software characteristics and performance measurements are matched with well-known performance antipatterns to document common performance issues and their solutions. Method: We execute load testing based on the characteristics of collected operational profile, thus to produce representative workloads. Performance data from the system under test is collected using a profiler tool to create profiler snapshots and get performance hotspot reports. From such data, performance issues are identified and matched with the specification of antipatterns. Software refactorings are then applied to solve these performance antipatterns. Results: The approach has been applied to a real-world industrial case study and to a representative laboratory study. Experimental results demonstrate the effectiveness of our tool-supported approach that is able to automatically detect two performance antipatterns by exploiting the knowledge of domain experts. In addition, the software refactoring process achieves a significant performance gain at the operational stage in both case studies. Conclusion: Performance antipatterns can be used to effectively support the identification of performance issues from load testing and profiling data. The detection process triggers an antipattern-based software refactoring that in our two case studies results in a substantial performance improvement.<br/> &copy; 2017 Elsevier B.V.},
key = {Software testing},
keywords = {Load testing;Systems engineering;},
note = {Anti-patterns;Complex software systems;Empirical data;Execution environments;Performance assessment;Performance measurements;Software characteristic;Software performance engineerings;},
URL = {http://dx.doi.org/10.1016/j.infsof.2017.11.016},
} 


@inproceedings{20102312986028 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing and optimization of J2EE-based web applications},
journal = {2nd International Workshop on Education Technology and Computer Science, ETCS 2010},
author = {Wu, Qinglin and Wang, Yan},
volume = {2},
year = {2010},
pages = {681 - 683},
address = {Wuhan, Hubei, China},
abstract = {J2EE-based Web applications are becoming increasingly ubiquitous and with their increasing adoption, the performance is the attention focus and the most important factor of evaluating the system by users. In this paper, we present a systematic solution for performance testing and optimization of J2EE-based Web applications. The solution helps to identify and eliminate bottlenecks in the application design and ensures that systems are designed to meet their quality of service requirements. This paper firstly analyses the architecture of J2EE-based Web applications and performance testing principle, and then improves the JMeter testing framework for meeting the more concurrent users. Lastly, performance testing for J2EE-based Web applications is done; it finds performance bottlenecks and puts forward optimum measures, and compares the performance with the former one. &copy; 2010 IEEE.<br/>},
key = {Engineering education},
keywords = {Education computing;Optimization;Quality of service;},
note = {Application design;Distributed;JMeter;Performance;Performance bottlenecks;Performance testing;Testing framework;WEB application;},
URL = {http://dx.doi.org/10.1109/ETCS.2010.583},
} 


@inproceedings{20113314230815 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Study on the establishment of dynamic performance test environment for the digital protective relay using RTDS},
journal = {IFAC Proceedings Volumes (IFAC-PapersOnline)},
author = {Jang, Byung Tae and Choe, Chang Youl and Jung, Gil Jo},
volume = {5},
number = {PART 1},
year = {2006},
pages = {143 - 146},
issn = {14746670},
abstract = {A performance test of digital protective relay is divided into three parts ; a static test, a dynamic test, a EMC test. Among these, a dynamic test is increasingly important, but it is not easy to diffuse a technique for dynamic test because of the intricate approach to real time digital simulator. In order to solve these problems, KEPRI(Korea Electric Power Research Institute) has established environments for performance test, which consist of a system model and a performance test procedure for the dynamic test. Copyright &copy; 2006 IFAC.<br/>},
key = {Relay protection},
keywords = {Electric fault currents;Electromagnetic compatibility;},
note = {Digital protective relay;Dynamic performance tests;Dynamic tests;Korea electric power research institutes;Performance tests;Real time digital simulator;Static tests;System modeling;},
} 


@inproceedings{20182005202831 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and performance test of NIRS-based spinal cord lesion detector},
journal = {Progress in Biomedical Optics and Imaging - Proceedings of SPIE},
author = {Li, Nanxi and Li, Ting},
volume = {10484},
year = {2018},
pages = {The Society of Photo-Optical Instrumentation Engineers (SPIE) - },
issn = {16057422},
address = {San Francisco, CA, United states},
abstract = {Spinal cord lesions can cause a series of severe complications, which can even lead to paralysis with high mortality. However, the traditional diagnosis of spinal cord lesion relies on complicated imaging modalities and other invasive and dangerous methods. Here, we have designed a small monitor based on NIRS technology for noninvasive monitoring for spinal cord lesions. The development of the instrument system includes the design of hardware circuits and the program of software. In terms of hardware, OPT101<sup>1</sup>is selected as the light detector, and the appropriate probe distribution structure is selected according to the simulation result of Monte Carlo Simulation. At the same time, the powerful controller is selected as our system's central processing chip for the circuit design, and the data is transmitted by serial port to the host computer for post processing. Finally, we verify the stability and feasibility of the instrument system. It is found that the spinal signal could be obviously detected in the system, which indicates that our monitor based on NIRS technology has the potential to monitor the spinal lesion.<br/> &copy; 2018 SPIE.},
key = {Monte Carlo methods},
keywords = {Computer hardware;Convergence of numerical methods;Detectors;Hardware;Integrated circuit manufacture;Intelligent systems;Printed circuit design;Remote control;Surgery;},
note = {Design of hardwares;feasibility;Imaging modality;Instrument systems;NIRS;Non-invasive monitoring;Performance tests;Spinal cords;},
URL = {http://dx.doi.org/10.1117/12.2287071},
} 


@inproceedings{20114414464663 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and implementation of OLED optical performance test system},
journal = {Proceedings - IEEE 2011 10th International Conference on Electronic Measurement and Instruments, ICEMI 2011},
author = {Zhang, Yujie and Zhang, Yuanyuan},
volume = {2},
year = {2011},
pages = {38 - 41},
address = {Chengdu, China},
abstract = {For the defects of the manual measurement of OLED optical performance by using discrete devices, this paper presented a platform which can measure the optical and electrical property of the light-emitting device of the OLED at the same time. It drew the real-time curve via the host computer to monitor and compare the performance data. It implemented a rapid, accurate and reliable automatic measurement system. And it improved the measure efficiency and accuracy greatly. It plays an important role in the study of the optical carriers transport properties, luminescence properties, luminous efficiency of OELD devices. &copy; 2011 IEEE.<br/>},
key = {Optical properties},
keywords = {Efficiency;Luminescence;Organic light emitting diodes (OLED);},
note = {Automatic measurement system;Design and implementations;Light emitting devices;Luminescence properties;Luminous efficiency;OLED;Optical and electrical properties;Optical performance;},
URL = {http://dx.doi.org/10.1109/ICEMI.2011.6037760},
} 


@inproceedings{20180504690749 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Extending the stress-testing deployment envelope to highly deviated wells},
journal = {Society of Petroleum Engineers - SPE Russian Petroleum Technology Conference 2017},
author = {Rylance, M. and Naidu, R. and Hoq, A. and Mossop, K. and Smithells, S. and Ronald, A. and Masson, L.},
year = {2017},
address = {Moscow, Russia},
abstract = {Open-hole in-situ stress measurements have gained increasing significance in recent years, from front end loading of major hydraulic fracturing campaigns, as well as cap-rock integrity assurance and management of Out Of Zone Injection (OOZI) for pressure maintenance or secondary recovery purposes. The latter has become particularly important in recent years, with an increasing scrutiny of injection operations and their containment assurance. In response to this requirement, wireline deployed dual-packer micro-fracturing has been the most commonplace approach taken to obtain such data. However, such Wire-line Formation Tester (WFT) measurements have their own technical limitations, particularly with respect to the wellbore deviation, hole-size and pressure differential limits that can be applied. Just such a scenario was faced where a number of planned development wells were being drilled and were radiating from a suite of fixed drill centres, resulting in extensive and large sail angle sections in the zones within and across the cap-rock of interest. The use of conventional WFT micro-fracturing operations was considered to be too challenging under this scenario; due to the wellbore inclinations, the pressure limits, the probability of failure, the timings, the costs and the operational complexity in such a difficult environment. The proposed solution was to resurrect a technique that had been used on just very few occasions some 30 years ago, prior to the availability of the WFT approach, which was the use of drill-string deployed dualpacker tools for stress measurements. Due to the lack of recent industry experience with this type of application, the tool and equipment selection, the Bottom Hole Assembly (BHA) design and operational considerations were of paramount importance and required considerable planning. This paper describes the technology selection, planning, contingency options, risk mitigation, operational aspects and the outcome of the first operation from the initial concept to its final execution. It includes how the tools were successfully selected, tested and deployed, the packers inflated and set, and injection tests made within the target formation; with a number of lessons learned on the tool behaviour, the injection and the test approaches taken. The downhole data was efficiently retrieved and a suite of recommendations have resulted from the operations in general. Accurate in-situ stress measurements have been successfully made in a cap-rock formation from an open-hole section of a well at high-angle, using a pipe-deployed dual-packer approach. While the often used WFT micro-fracturing technique can address the majority of scenarios, situations can arise where a pipe-deployed approach offers the only effective and economic means of obtaining such data. The data that can be obtained is helpful for designing wells and defining the operational envelope for increasing the reliability and efficiency of injector wells to achieve field development objectives.<br/> Copyright 2017, Society of Petroleum Engineers.},
key = {Stress measurement},
keywords = {Bottom-hole assembly;Deflected boreholes;Drill strings;Drills;Hydraulic fracturing;Hydraulic machinery;Oil field equipment;Oil wells;Packers;Petroleum engineering;Secondary recovery;Stress analysis;Stresses;Well testing;},
note = {Highly deviated wells;In-situ stress measurement;Operational complexity;Planned development wells;Pressure differential;Pressure maintenance;Probability of failure;Technical limitations;},
} 


@inproceedings{20134717004713 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test method of the mixed-mode interface of an integrated-sensor RFID system},
journal = {Applied Mechanics and Materials},
author = {Qi, Shu Zhe and Zhou, Song Bin},
volume = {457-458},
year = {2014},
pages = {755 - 760},
issn = {16609336},
address = {Hong kong},
abstract = {Aiming at the performance evaluation of mixed-mode sensing interface of the integrated-sensor RFID system, an integrated-sensor RFID system was constructed. Then the mechanism of performance evaluation of mixed-mode interface was analyzed. According to the validity and reliability principle, a mixed-mode interface performance testing model was established. Moreover, a Plug-and-Play performance testing method was presented. Finally, the physical platform was set up to test the reading speed and the recognition rate indicator in Plug-and-Play process. Results showed the reading speeds of two STIM maintained at around 656.56ms and 645.24ms steadily during Plug-and-Play process whose Bit Error Rate was 10<sup>-9</sup> Experiments indicate that effective transverse comparison of performance of similar products could be implemented by the proposed method in static environment as well as dynamic environment. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Sensors},
keywords = {Mechanical engineering;Radio frequency identification (RFID);},
note = {Comparison of performance;Dynamic environments;IEEE 1451.4;Intelligent sensors;Mixed-mode interface;Performance testing;Reliability principles;Static environment;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.457-458.755},
} 


@article{20141817649369 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test of solar-assisted ejector cooling system},
journal = {International Journal of Refrigeration},
author = {Huang, Bin-Juine and Ton, Wei-Zhe and Wu, Chen-Chun and Ko, Hua-Wei and Chang, Hsien-Shun and Hsu, Hang-Yuen and Liu, Jen-Hao and Wu, Jia-Hung and Yen, Rue-Her},
volume = {39},
year = {2014},
pages = {172 - 182},
issn = {01407007},
abstract = {A solar-assisted ejector cooling/heating system (SACH-2k) is built and test result is reported. The solar-driven ejector cooling system (ECS) is connected in series with an inverter-type air conditioner (IAC). Several advanced technologies are developed in SACH-k2, including generator liquid level control in ECS, the ECS evaporator temperature control, and optimal control of fan power in cooling tower of ECS. From the field test results, the generator liquid level control performs quite well and keeps stable performance of ejector. The ECS evaporator temperature control also performs satisfactorily to keep ejector performance normally under low or fluctuating solar radiation. The fan power control system cooling tower performs stably and reduces the power consumption dramatically without affecting the ECS performance. The test results show that the overall system COP<inf>o</inf>including power consumptions of peripheral increases from 2.94-3.3 (IAC alone) to 4.06-4.5 (SACH-k2), about 33-43%. The highest COP<inf>o</inf>is 4.5. &copy; 2013 Elsevier Ltd and IIR. All rights reserved.<br/>},
key = {Power control},
keywords = {Air conditioning;Air ejectors;Cooling;Cooling systems;Cooling towers;Ejectors (pumps);Electric power utilization;Energy conservation;Evaporators;Fluidized bed combustion;Hand held computers;Level control;Polonium compounds;Solar energy;Solar refrigeration;Temperature control;Thermoelectric equipment;},
note = {Advanced technology;Ejector cooling system;Evaporator temperature;Liquid level control;Optimal controls;Performance tests;Solar assisted;Stable performance;},
URL = {http://dx.doi.org/10.1016/j.ijrefrig.2013.06.009},
} 


@inproceedings{20124815738641 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {CaPTIF: Comprehensive performance testing framework},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Mayer, Daniel A. and Steele, Orie and Wetzel, Susanne and Meyer, Ulrike},
volume = {7641 LNCS},
year = {2012},
pages = {55 - 70},
issn = {03029743},
address = {Aalborg, Denmark},
abstract = {In this paper we present the design and implementation of a framework for comprehensive performance evaluation of algorithms, modules, and libraries. Our framework allows for the definition of well-defined test inputs and the subsequent scheduling and execution of structured tests. In addition, the framework provides a web-based interface for user interaction and allows for the convenient browsing, plotting, and statistical analysis of test results. We furthermore report on our experience in using the new framework in the development of cryptographic protocols and algorithms-specifically in the context of secure multi-party computation. &copy; 2012 IFIP International Federation for Information Processing.},
key = {Software testing},
keywords = {Algorithms;Multimedia systems;},
note = {Comprehensive performance;Comprehensive performance evaluation;Cryptographic protocols;Secure multi-party computation;Test inputs;User interaction;Web-based interface;},
URL = {http://dx.doi.org/10.1007/978-3-642-34691-0_6},
} 


@inproceedings{20170903388965 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Task performance test on grasping the bolt by a power distribution line maintenance experimental robot system},
journal = {2016 International Symposium on Micro-NanoMechatronics and Human Science, MHS 2016},
author = {Kato, Yukiko and Koike, Motoki and Kurabe, Koichi and Jinno, Koji and Yamashita, Kyohei and Tatsuno, Kyoichi},
year = {2016},
address = {Nagoya, Japan},
abstract = {We have been developing a power distribution line maintenance robot system. This system will autonomously carry out basic tasks in the maintenance work. For examples, 'Grasping a bolt', 'Inserting a bolt', 'Tightening a nut' and so on. We perform a task performance test 'Grasp the bolt on the tool box'. The system grasps the bolt on tool box under visual feedback from the hand-eye camera. Applied visual feedback control does not require camera calibration and arm calibration because this visual feedback adjusts the bolt and the gripper in one image plane using the hand-eye camera. &copy; 2016 IEEE.},
key = {Bolt tightening},
keywords = {Bolts;Calibration;Cameras;Feedback;Grounding electrodes;Maintenance;Social sciences;Visual communication;Visual servoing;},
note = {Camera calibration;Image plane;Maintenance work;Power distribution lines;Robot system;Task performance;Visual feedback;Visual feedback control;},
URL = {http://dx.doi.org/10.1109/MHS.2016.7824232},
} 


@inproceedings{20073510787985 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A lower bound on effective performance testing for digital forensic tools},
journal = {Proceedings - SADFE 2007: Second International Workshop on Systematic Approaches to Digital Forensic Engineering},
author = {Pan, Lei and Batten, Lynn M.},
year = {2007},
pages = {117 - 130},
address = {Bell Harbor, WA, United states},
abstract = {The increasing complexity and number of digital forensic tasks required in criminal investigations demand the development of an effective and efficient testing methodology, enabling tools of similar functionalities to be compared based on their performance. Assuming that the tool tester is familiar with the underlying testing platform and has the ability to use the tools correctly, we provide a numerical solution for the lower bound on the number of testing cases needed to determine comparative capabilities of any set of digital forensic tools. We also present a case study on the performance testing of password cracking tools, which allows us to confirm that the lower bound on the number of testing runs needed is closely related to the row size of certain orthogonal arrays. We show how to reduce the number of test runs by using knowledge of the underlying system. &copy; 2007 IEEE.},
key = {Software testing},
keywords = {Computational complexity;Computer aided software engineering;Data reduction;Parallel processing systems;},
note = {Abstraction layer model;Orthogonal arrays;Partition testing;SADFE;Software performance;},
URL = {http://dx.doi.org/10.1109/SADFE.2007.2},
} 


@inproceedings{20142017708611 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing approach for services and applications using MQ-Series},
journal = {Annual International Conference of the Computer Measurement Group, CMG 2013},
author = {Srinivasa, Lakshmi N. and Anbalagan, Jagadeesh and Meenakshisundaram, Sriganesh},
volume = {2},
year = {2013},
pages = {1151 - 1162},
address = {London, United kingdom},
abstract = {Performance Testing of web-based applications in general is accomplished with the help of standard load testing tools and their methodology is well established and adopted by the Software Industry. With the advent of distributed Service Oriented Architecture (SOA) applications, load testing of services poses its own challenge to performance Testers and Engineers. In particular, this paper presents an approach and a tool by which the challenges for performance testing a messaging service (services using SOAP over MQ) can be overcome. Further, the paper illustrates how the existing tools can be adapted or new tools can be used to test them. In addition, it also specifies the testing, monitoring and tuning aspects of Messaging services.<br/>},
key = {Software testing},
keywords = {Application programs;Information services;Load testing;Service oriented architecture (SOA);},
note = {Distributed service;Messaging services;Performance testing;Services and applications;Software industry;Standard loads;Testing tools;Web-based applications;},
} 


@article{1990080510160 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Computerised performance testing of data acquisition facilities},
journal = {Measurement Science and Technology},
author = {Abdel-Aal, R.E.},
volume = {1},
number = {3},
year = {1990},
pages = {216 - 219},
issn = {09570233},
abstract = {This paper describes a low-cost approach to performing automatic performance measurements on data acquisition modules and systems employed in physics research. A versatile programmable CAMAC pulse generator is described which produces accurately timed repetitive logic pulses whose width and repetition rate are set by software. The variable rate is useful in determining the performance of data acquisition systems over a wide range of data rates, while the variable width may be used in the automatic measurement of the characteristics of modules such as time-to-digital converters (TDCS). Using a time-to-amplitude converter (TAC), this width can be converted into a variable amplitude for testing analogue-to-digital converter (ADC) modules. Hardware and software aspects are described. Typical applications are discussed including automated performance measurements on a VAX 11/785 data acquisition system and on a TAC/ADC combination.},
key = {Data Processing},
keywords = {Data Conversion, Analog to Digital;Physics--Research;Pulse Generators;},
note = {CAMAC Pulse Generator;Performance Testing;Time-to-Digital Converters;},
URL = {http://dx.doi.org/10.1088/0957-0233/1/3/002},
} 


@inproceedings{20134616967793 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Laser tracking system design performance test},
journal = {Advanced Materials Research},
author = {Wang, Chunyan and Wang, Yibo},
volume = {823},
year = {2013},
pages = {392 - 395},
issn = {10226680},
address = {Wuhan, Hubei, China},
abstract = {To simulate the real field environment far field, to obtain the best performance of the laser measurements of the turntable tracking system to be developed, can be locked by means of the tracking of the target, the turntable adjusting the rotational angular velocity tracking system size and rotation means, so as to simulate different motion state space moving target effect on the laser irradiation to test the performance targets to achieve the targeting system performance evaluation. &copy; (2013) Trans Tech Publications, Switzerland.},
key = {Target tracking},
keywords = {Industrial engineering;Phonographs;},
note = {Design performance;Laser measurements;Laser tracking system;Moving targets;Performance targets;Targeting Systems;Tracking system;Velocity tracking;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMR.823.392},
} 


@inproceedings{20121915005112 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of open laboratory management system based on LoadRunner},
journal = {Proceedings - 2011 International Conference on Instrumentation, Measurement, Computer, Communication and Control, IMCCC 2011},
author = {Yan, Xiaojiao and Wen, Fuan and Fan, Chunmei and Wang, Xiao},
year = {2011},
pages = {164 - 167},
address = {Beijing, China},
abstract = {Open Laboratory Management System provides an open virtual experiment environment for students, so that its system performance immediately impacts the quality of students learning. According to analyze the performance requirements of Open Laboratory Management System, the author discovers performance testing points, implements automated performance testing for performance testing points of the system based on Load Runner. In this paper, taking the students login for example, it elaborates testing process and provides the reference for system optimization. &copy; 2011 IEEE.<br/>},
key = {Load testing},
keywords = {Laboratories;Students;Virtual reality;},
note = {Loadrunner;Open laboratory management systems;Performance requirements;Performance testing;Students learning;System optimizations;Testing process;Virtual experiment environments;},
URL = {http://dx.doi.org/10.1109/IMCCC.2011.50},
} 


@article{20070810438668 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Objective performance testing and quality assurance of medical ultrasound equipment},
journal = {Ultrasound in Medicine and Biology},
author = {Thijssen, Johan M. and Weijers, Gert and de Korte, Chris L.},
volume = {33},
number = {3},
year = {2007},
pages = {460 - 471},
issn = {03015629},
abstract = {There is an urgent need for a measurement protocol and software analysis for objective testing of the imaging performance of medical ultrasound equipment from a user's point of view. Methods for testing of imaging performance were developed. Simple test objects were used, which have a long life expectancy. First, the elevational focus (slice thickness) of the transducer was estimated and the in-plane transmit focus was positioned at the same depth. Next, the postprocessing look-up-table (LUT) was measured and linearized. The tests performed were echo level dynamic range (dB), contrast resolution (i.e., gamma of display, number of gray levels/dB) and sensitivity, overall system sensitivity, lateral sensitivity profile, dead zone, spatial resolution and geometric conformity of display. The concept of a computational observer was used to define the lesion signal-to-noise ratio, SNR<inf>L</inf> (or Mahalanobis distance), as a measure for contrast sensitivity. All the measurements were made using digitized images and quantified by objective means, i.e., by image analysis. The whole performance measurement protocol, as well as the quantitative measurements, have been implemented in software. An extensive data-base browser was implemented from which analysis of the images can be started and reports generated. These reports contain all the information about the measurements, such as graphs, images and numbers. The approach of calibrating the gamma by using a linearized LUT was validated by processing simultaneously acquired rf data. The contrast resolution and echo level of the rf data had to be compressed by a factor of two and amplified by a gain factor corresponding to 12 dB. This resulted in contrast curves that were practically identical to those obtained from DICOM image data. The effects of changing the transducer center frequency on the spatial resolution and contrast sensitivity were estimated to illustrate the practical usefulness of the developed approach of quality assurance by measuring objective performance characteristics. The developed methods might be considered as a minimum set of objective quality assurance measures. This set might be used to predict clinical performance of medical ultrasound equipment, taking into account the performance at a unique point in space i.e., the coinciding depths of the elevation and in-plane (azimuth) foci. Furthermore, it should be investigated whether the approach might be used to compare objectively various brands of equipment and to evaluate the performance specifications given by the manufacturer. Last but not least, the developed approach can be used to monitor, in a hospital environment, the medical ultrasound equipment during its life cycle. The software package may be viewed and downloaded at the website http://www.qa4us.eu. (E-mail: j.thijssen@cukz.umcn.nl). &copy; 2007 World Federation for Ultrasound in Medicine &amp; Biology.},
key = {Ultrasonic equipment},
keywords = {Computer software;Database systems;Image analysis;Medical imaging;Quality assurance;Signal to noise ratio;Ultrasonic transducers;},
note = {Computational observer;Contrast resolution;Objective assessment;Performance testing;Spatial resolution;},
URL = {http://dx.doi.org/10.1016/j.ultrasmedbio.2006.09.006},
} 


@inproceedings{20062810000774 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Distributed architecture system for computer performance testing},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Herruzo, Ezequiel and Mesones, Andres J. and Benavides, Jose I. and Plata, Oscar and Zapata, Emilo L.},
volume = {3911 LNCS},
year = {2006},
pages = {140 - 147},
issn = {03029743},
address = {Poznan, Poland},
abstract = {This article presents a system which is based on a distributed network architecture, The system defines a "double" Client-Server structure which permits to incorporate new client systems in real-time using the Internet. We have used this distributed architecture system to develop a tool to measure the computer performance characteristics of several computer architecture systems. The computer performance is tested by a free library called PAPI (Performance API), which allows us to access to internal status registers of several CPU families in several Operating Systems. As this testing has to be done in real CPUs, we have to create a new system to provide this functionality. The structure proposed has only one entry point to the whole system, the Master Server, and several different Architecture Client Servers. We present the network system description and the usage of PAPI for performance testing. &copy; Springer-Verlag Berlin Heidelberg 2006.},
key = {Computer architecture},
keywords = {Client server computer systems;Computer systems programming;Distributed computer systems;Information retrieval systems;Internet;Real time systems;},
note = {Computer performance;Distributed architecture system;Network systems;},
URL = {http://dx.doi.org/10.1007/11752578_18},
} 


@article{20133516668969 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Modern statistical and philosophical framework for uncertainty assessment in biometric performance testing},
journal = {IET Biometrics},
author = {Wayman, James L. and Possolo, Antonio and Mansfield, Anthony J.},
volume = {2},
number = {3},
year = {2013},
pages = {85 - 96},
issn = {20474938},
abstract = {The question of estimating uncertainty in measurement is fundamental to all scientific fields. In the field of automated human recognition, lack of repeatability and reproducibility of measurements has been noted since at least the 1970s. This study discusses current approaches to estimation of measurement uncertainty within the broader context of scientific philosophy and measurement science. The authors discuss the Duhem-Quine thesis on testing holism and international standards on estimating and reporting uncertainty in laboratory measurements, then apply these concepts to the estimation of uncertainty in technology, scenario and operational testing in biometrics. The authors advocate for moving beyond the calculation of application of the concepts of uncertainty assessment. &copy; The Institution of Engineering and Technology 2013.},
key = {Uncertainty analysis},
keywords = {Biometrics;Estimation;Philosophical aspects;Standards;},
note = {International standards;Laboratory measurements;Measurement science;Measurement uncertainty;Operational testing;Performance testing;Uncertainty assessment;Uncertainty in measurement;},
URL = {http://dx.doi.org/10.1049/iet-bmt.2013.0009},
} 


@inproceedings{20174304307160 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The STIG: Framework for the stress-test for infrastructures of geographic information},
journal = {Lecture Notes in Geoinformation and Cartography},
author = {Nushi, Bujar and Van Loenen, Bastiaan},
number = {199609},
year = {2013},
pages = {289 - 298},
issn = {18632351},
address = {Enschede, Netherlands},
abstract = {Spatial data infrastructure (SDI) facilitates the collection, maintenance, dissemination and use of spatial information. To stimulate SDI development effectively and efficiently, it is key to assess the progress and benefits of the SDI. SDI is difficult to assess because of its complex, dynamic, multi-faceted and constantly evolving nature. Several SDI assessment methods exist. However, these are still in an infancy stage and none of these appear to meet the requirements of practitioners. As a result, SDI decision makers are still without any guidance on the success of their SDI. In this paper we propose a new method for SDI assessment: The STIG, a Stress-test for Infrastructures of Geographical information. The development and application of the Stress-test methodology will provide new valuable information for decision-makers about the aspects of SDIs that need to be improved in order to take full advantage of the potential benefit of the SDIs, especially in the instance of disaster management. &copy; Springer-Verlag Berlin Heidelberg 2013.},
key = {Decision making},
keywords = {Disaster prevention;Disasters;},
note = {Development and applications;Disaster management;Geographic information;Geographical information;SDI assessment;Spatial data infrastructure;Stress test;The STIG;},
URL = {http://dx.doi.org/10.1007/978-3-642-33218-0_20},
} 


@inproceedings{20134416937199 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research on DB2 performance testing automation},
journal = {Advanced Materials Research},
author = {Zhuang, Lei and Gao, Zhen and Wu, Hao and Yang, Chun Xin and Zheng, Miao},
volume = {756-759},
year = {2013},
pages = {2204 - 2208},
issn = {10226680},
address = {Nanjing, Jiangsu, China},
abstract = {Software testing play a significant role in modern software development and maintenance process, which is also an important means to ensure software reliability and improve software quality. With the continuous improvement of quality requirements of the software products and software engineering technology become more sophisticated, software testing has been participating into every phase of software lift cycle, become more and more important in software development and maintenance. DB2 Performance testing consists of four parts, which are environment setup, workload run, data measurement and environment clean up. Before all the operations are done manually and need about two hours' continuous attention. What's worse, even three times a day. This mechanical and complicated procedure is clearly unacceptable. This paper put forward a reusable automated testing framework based on IBM automated testing tools RFT to achieve the whole testing procedure automation. It reduces the count of human-computer interaction and greatly improves the efficiency of DB2 performance testing. &copy; (2013) Trans Tech Publications, Switzerland.},
key = {Information technology},
keywords = {Computer software selection and evaluation;Maintenance;Materials science;Software design;Software testing;},
note = {Automated testing;Automated testing tools;Continuous improvements;Performance testing;Quality requirements;RFT;Software development and maintenances;Testing framework;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMR.756-759.2204},
} 


@inproceedings{20165003113912 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test and image correction of CMOS image sensor in radiation environment},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Wang, Congzheng and Hu, Song and Gao, Chunming and Feng, Chang},
volume = {9684},
year = {2016},
pages = {Chinese Academy of Sciences, Institute of Optics and Electronics (IOE); The Chinese Optical Society (COS) - },
issn = {0277786X},
address = {Suzhou, China},
abstract = {CMOS image sensors rival CCDs in domains that include strong radiation resistance as well as simple drive signals, so it is widely applied in the high-energy radiation environment, such as space optical imaging application and video monitoring of nuclear power equipment. However, the silicon material of CMOS image sensors has the ionizing dose effect in the high-energy rays, and then the indicators of image sensors, such as signal noise ratio (SNR), non-uniformity (NU) and bad point (BP) are degraded because of the radiation. The radiation environment of test experiments was generated by the<sup>60</sup>Co &gamma;-rays source. The camera module based on image sensor CMV2000 from CMOSIS Inc. was chosen as the research object. The ray dose used for the experiments was with a dose rate of 20krad/h. In the test experiences, the output signals of the pixels of image sensor were measured on the different total dose. The results of data analysis showed that with the accumulation of irradiation dose, SNR of image sensors decreased, NU of sensors was enhanced, and the number of BP increased. The indicators correction of image sensors was necessary, as it was the main factors to image quality. The image processing arithmetic was adopt to the data from the experiences in the work, which combined local threshold method with NU correction based on non-local means (NLM) method. The results from image processing showed that image correction can effectively inhibit the BP, improve the SNR, and reduce the NU. &copy; 2016 SPIE.},
key = {Image processing},
keywords = {CMOS integrated circuits;Digital cameras;Digital storage;Equipment;Gamma rays;Image reconstruction;Image sensors;Ionizing radiation;Manufacture;Optical data processing;Optical testing;Pixels;Radiation;Signal to noise ratio;},
note = {CMOS image sensor;High energy radiation;Non local means (NLM);Nuclear power equipments;Performance tests;Radiation environments;Radiation resistance;Ray radiation;},
URL = {http://dx.doi.org/10.1117/12.2243427},
} 


@inproceedings{1993030668798 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {System evaluation and performance testing of the easton dual-shaft electric propulsion system},
journal = {Proceedings - Society of Automotive Engineers},
author = {MacDowall, R.D.},
number = {P-256},
year = {1992},
pages = {349 - 366},
issn = {87568470},
address = {Dearborn, MI, USA},
abstract = {The Eaton Corporation, under a shared-cost contract to the United States Department of Energy (DOE), developed the Dual-Shaft Electric Propulsion (DSEP) System. Engineering evaluation testing has been conducted by the Idaho National Engineering Laboratory (INEL) in order to determine the overall system performance of the TB-2 and NVH vehicles within the systems environment. The DSEP vehicles were teted on a chasis dynamometer in the INEL Electric Vehicle Test Laboratory and on the track at the Chrysler Proving Grounds in Phoenix, Arizona. The operation of the DSEP vehicles was also simulated on the computer using the INEL SIMPLEV computer program. The computer predictions were compared with the test data and used to project the range of the DSEP vehicles for a NIF-170 battery having rated capacity.},
key = {Propulsion},
keywords = {Computer simulation;Electric batteries;Electric power transmission;Electric variables measurement;Electric vehicles;Secondary batteries;Testing;},
note = {Dual shaft electric propulsion system;Energy comsumption;Performance testing;Power trains;System evaluation;},
} 


@inproceedings{20171403534674 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and performance test in an interconnected TD-LTE train-ground communication for urban rail transit system},
journal = {Proceedings of 2016 IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference, IMCEC 2016},
author = {Si, Chaogang and Changmin, Teng and Li, Wang},
year = {2016},
pages = {1734 - 1737},
address = {Xi'an, China},
abstract = {In existing urban rail transit system, because of long construction period, train-ground communication system for different rail lines may use equipment from different manufacturer, that will bring challenges for management of metro company, even, it may result in emergency brake of train or traffic safety when a train is going across different lines. In this paper, we first study relevant demands of TD-LTE train-ground communication interconnection, an interconnected TD-LTE train-ground communication system for the urban rail transit system is designed next, in order to test the interconnected TD-LTE based train-ground communication system performance, an indoor testing environment is set up. The programmable attenuators and EIT-Monitor are used to simulate the real urban rail transit environment and monitor signal from different network equipment. Final test results prove that the designed interconnected TD-LTE train-ground communication can be applied to current train control system, which completely satisfies the demand of subway operation in urban rail transit system. &copy; 2016 IEEE.},
key = {Light rail transit},
keywords = {Construction equipment;Environmental testing;Information management;Railroad traffic control;Subways;Testing;Vehicle performance;Wireless telecommunication systems;},
note = {Construction period;Interconnection;Programmable attenuators;TD-LTE;Train control systems;Train-ground communications;Urban rail transit;Urban rail transit systems;},
URL = {http://dx.doi.org/10.1109/IMCEC.2016.7867515},
} 


@inproceedings{20164202906327 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test of unmanned aerial systems communication links in a severe multipath environment},
journal = {IEEE International Symposium on Electromagnetic Compatibility},
author = {Dixon, Jacob and Rajamani, Vignesh and Bunting, Chuck},
volume = {2016-September},
year = {2016},
pages = {862 - 867},
issn = {10774076},
address = {Ottawa, ON, Canada},
abstract = {This paper discusses the results of exploratory research in analyzing the electromagnetic compatibility (EMC) of commercially available radio frequency transceivers co-located within the chassis of an Unmanned Air System (UAS). Tests were performed on a UAS with multiple communication systems onboard encompassing frequency bands with center frequencies of 915 MHz, 2.4 GHz, and 5.8 GHz. These tests were performed in a normal operational environment a.k.a free space and also inside a multipath environment where the UAS was subjected to performance evaluation i.e. the status of the communication systems of the UAS were monitored while there is no external EM threat and also while applying an external EM field. &copy; 2016 IEEE.},
key = {Electromagnetic compatibility},
keywords = {Drones;Electromagnetic pulse;Flight dynamics;Frequency bands;Multipath propagation;Radio transceivers;Signal interference;Unmanned aerial vehicles (UAV);},
note = {Exploratory research;Multi-path environments;Operational environments;Performance tests;Radio frequency transceiver;Unmanned aerial systems;Unmanned air systems;Unmanned air vehicles;},
URL = {http://dx.doi.org/10.1109/ISEMC.2016.7571763},
} 


@inproceedings{20153301164829 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Points of Load: Performance test in high-B environment},
journal = {Conference Record - IEEE Instrumentation and Measurement Technology Conference},
author = {Lazzaroni, M. and Citterio, M. and Latorre, S.},
volume = {2015-July},
year = {2015},
pages = {1320 - 1325},
issn = {10915281},
address = {Pisa, Italy},
abstract = {The performance in magnetic field (B-field) of a DC-DC converter ad hoc designed for LHC operation has been evaluated. The tests have been carried out at the Laboratorio Acceleratori e Superconduttivit Applicata (LASA), in Milan (Italy), in the first months of 2014 and the experimental results are here presented and discussed. The ability to operate in hostile environment of the tested DC-DC converter is very interesting in particular when used in measuring system for physics experiments. In this case, in fact, the presence of radiation and strong magnetic field make electronic devices challenged to function. In particular, in this paper the operation in high B-field environment has been investigated and discussed. &copy; 2015 IEEE.},
key = {DC-DC converters},
keywords = {Magnetic fields;Measurements;Reliability;},
note = {Dependability;Electronic device;Hostile environments;LHC;Measuring systems;Performance tests;Physics experiments;Strong magnetic fields;},
URL = {http://dx.doi.org/10.1109/I2MTC.2015.7151464},
} 


@inproceedings{1992095120373 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {How to treat transmission line effects when testing high speed devices with a high performance test system},
author = {Plitschka, Rainer},
year = {1989},
pages = {78 - 85},
address = {Paris, France},
abstract = {State-of-the-art digital ASICs have even faster clock rates and signal transition times; testing these devices may cause problems regarding delivering the signals to the device under test (DUT) and precisely measuring the response of the DUT. Transmission-line techniques have to be applied to the tester-to-DUT interconnection in order to maintain signal fidelity. The author illustrates how to implement this critical signal path in a high-speed test system to get high-precision timing and level measurements, particularly for CMOS devices. The solution suggested to embed a CMOS device in a transmission-line environment is the resistive divider. The operating principle of the resistive divider is to apply a defineable DC load to the DUT. This maintains signal fidelity, as the signal is fed into a parallel terminated system. Therefore no reflections occur.},
key = {Integrated Circuit Testing},
keywords = {Electric Networks--Transmission Line Theory;Semiconductor Devices, MOS--Testing;},
note = {ASIC Testing;CMOS Devices;High Speed Test System;Signal Path;Transmission Line Effects;},
} 


@inproceedings{20172903962261 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A novel on-die GHz AC stress test methodology for high speed IO application},
journal = {IEEE International Reliability Physics Symposium Proceedings},
author = {Kang, P.-Z. and Yew, T.-Y. and Shih, K.-W. and Hsieh, M.-H. and Chou, W.-S. and Fu, C.-M. and Huang, Y.-C. and Wang, W. and Peng, Y.-C. and Lee, Y.-H.},
year = {2017},
pages = {4C3.1 - 4C3.5},
issn = {15417026},
address = {Monterey, CA, United states},
abstract = {A new methodology and test circuit for evaluation of device reliability are presented. The stress conditions must emulate the real circuit operation, or similar to product-like environment. Existing methodology might not archive this purpose. In this paper, an on-die wave front generator was established in circuit level. Experiments in this study cover from mechanisms of off state, Bias Temperature Instability (BTI) and Hot Carrier Injection (HCI). Based on the extensive results, strong dependence of reliability to layout effect can be concluded. And the reliability guidelines and recommendations for high speed IO circuit design can be made. &copy; 2017 IEEE.},
key = {Hot carriers},
keywords = {Human computer interaction;Integrated circuit manufacture;Reliability;},
note = {AC stress;Bias temperature instability;Device reliability;High Speed;Hot carrier injection;Off state;Strong dependences;Wave-front generators;},
URL = {http://dx.doi.org/10.1109/IRPS.2017.7936314},
} 


@inproceedings{20161102086284 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test and analysis of vehicle equipments horizontal earth electrodes under lightning environment},
journal = {Environmental Protection and Sustainable Ecological Development - Proceedings of the Environmental Protection and Sustainable Ecological Development, EPSED 2014},
author = {Qu, Xin-Bo and Zhou, Bi-Hua and Fu, Ya-Peng and Liu, Bo and Chen, Jian-Ping},
year = {2015},
pages = {77 - 81},
address = {Wuhan, China},
abstract = {Under lightning environment, architecture safety gets more and more attention while vehicle equipment falls into neglect. In lightning protection, earth device plays an important role. But conventional earth electrode of vehicle equipment can&rsquo;t meet the needs of protection. In this paper, a new type of portable horizontal grid earth electrode has been designed for mobile equipment. With the impulse ground measurement system, the performance of horizontal earth electrodes are tested and analyzed. The responses to double exponential pulse current of four earth electrodes in different arrangements have been tested on cement floor, respectively. After filtering and calculating, the curves of Transient Grounding Resistance (TGR) in time domain can be gotten. The results show that the same numbers of electrodes have different stable value of TGR in different arrangements, and the lowest value is in a line arrangement. &copy; 2015 Taylor & Francis Group, London.},
key = {Sustainable development},
keywords = {Ecology;Electric grounding;Electrodes;Environmental protection;Equipment;Grounding electrodes;Lightning;Lightning protection;Vehicles;},
note = {Double exponential pulse;Ground measurements;Horizontal grid;Mobile equipments;Performance tests;Time domain;Transient grounding resistance (TGR);Vehicle equipments;},
} 


@inproceedings{20174904505624 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance Testing of Semantic Publish/Subscribe Systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Murth, Martin and Winkler, Dietmar and Biffl, Stefan and Kuhn, Eva and Moser, Thomas},
volume = {6428 LNCS},
year = {2010},
pages = {45 - 46},
issn = {03029743},
address = {Hersonissos, Greece},
abstract = {Publish/subscribe mechanisms support clients in observing knowledge represented in semantic repositories and responding to knowledge changes. Currently available implementations of semantic publish/subscribe systems differ significantly with respect to performance and functionality. In this paper we present an evaluation framework for systematically evaluating publish/subscribe systems and its application to identify performance bottlenecks and optimization approaches.<br/> &copy; 2010, Springer-Verlag Berlin Heidelberg.},
key = {Peer to peer networks},
keywords = {Message passing;Publishing;Semantics;},
note = {Evaluation framework;ITS applications;Optimization approach;Performance bottlenecks;Performance testing;Publish/subscribe mechanisms;Publish/Subscribe system;Semantic repository;},
URL = {http://dx.doi.org/10.1007/978-3-642-16961-8_14},
} 


@inproceedings{20104813446859 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of semantic publish/subscribe systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Murth, Martin and Winkler, Dietmar and Biffl, Stefan and Kuhn, Eva and Moser, Thomas},
volume = {6428 LNCS},
year = {2010},
pages = {45 - 46},
issn = {03029743},
abstract = {Publish/subscribe mechanisms support clients in observing knowledge represented in semantic repositories and responding to knowledge changes. Currently available implementations of semantic publish/subscribe systems differ significantly with respect to performance and functionality. In this paper we present an evaluation framework for systematically evaluating publish/subscribe systems and its application to identify performance bottlenecks and optimization approaches. &copy; 2010 Springer-Verlag Berlin Heidelberg.<br/>},
key = {Publishing},
keywords = {Message passing;Semantics;},
note = {Evaluation framework;ITS applications;Optimization approach;Performance bottlenecks;Performance testing;Publish/subscribe mechanisms;Publish/Subscribe system;Semantic repository;},
URL = {http://dx.doi.org/10.1007/978-3-642-16961-8_14},
} 


@inproceedings{20110113546098 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The design of the measuring and controlling system of the high power pump performance test-bed based on virtual instrument technique},
journal = {Advanced Materials Research},
author = {Chen, Shumei and Zhang, Wei},
volume = {139-141},
year = {2010},
pages = {1967 - 1972},
issn = {10226680},
address = {Guangzhou, China},
abstract = {To satisfy the performance test of the high power hydraulic pump, a test-bed is developed in this paper. The parameters, the sign of the control and the data of the state are concluded. The test-bed employs the virtual instrument technique and PXI bus structure as well as M series data acquisition apparatus, it can measure the important performance parameters, such as pressure, flow, torque, speed and temperature; then we deal with and analysis these data. During the testing procedure it can realize automatic control, such as regulating the flow, pressure and so on. During the measuring and controlling, we can also monitor the state of the test-bed and give an alarm, such as over temperature or pressure. &copy; (2010) Trans Tech Publications.},
key = {Testing},
keywords = {Automation;Control;Data flow analysis;Digital instruments;Industrial engineering;Manufacture;Pumps;Test facilities;},
note = {Automatic control;Bus structures;Controlling system;High-power;Hydraulic pump;Performance parameters;Performance tests;Testing procedure;Virtual instrument;Virtual instrument technique;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMR.139-141.1967},
} 


@inproceedings{20133316602571 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test on radio communication device for train control system},
journal = {Proceedings - 2012 7th International Conference on Computing and Convergence Technology (ICCIT, ICEI and ICACT), ICCCT 2012},
author = {Chae, Eunkyung and Lee, Kangmi and Kim, Kyung-Hee and Lee, Jaeho},
year = {2012},
pages = {462 - 465},
address = {Seoul, Korea, Republic of},
abstract = {Train control system controls the headway and train route to prevent collisions and derailment of train on the basis of the train location. Radio communication based train control system can enhance the headway and safety of train in the manner of using radio communications instead of the wayside equipment such as the track circuit installed in the track. Radio communication based train control system uses the standard of IEEE 802.11 which uses an unlicensed frequency band because there is no dedicated frequency for railways. Since there is the risk where the frequency interference and other interference problems can be occurred because the unlicensed band might be used by various wireless devices, we analyzed wireless environments of Daebul Line which was selected as the test section, and in this paper, we measured the performance of radio communication device to be applied to the radio communication network and selected a optimized location which has no shaded area. &copy; 2012 AICIT.},
key = {Radio communication},
keywords = {Control systems;Frequency bands;Radio;Risk assessment;Standards;},
note = {Communication device;Communication-based train control systems;Frequency interference;Interference problems;Performance tests;Train control systems;Wireless devices;Wireless environment;},
} 


@inproceedings{20125015792900 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design of performance testing bed for hydraulic products of engineering machinery},
journal = {Advanced Materials Research},
author = {Liu, Zhihai and Zeng, Qingliang and Kang, Hongxi and Wang, Chenglong},
volume = {590},
year = {2012},
pages = {427 - 430},
issn = {10226680},
address = {Qingdao, China},
abstract = {Hydraulic test platform is a very important testing tool for hydraulic products of engineering machinery. In this paper, a new type of hydraulic test bed is developed which can be used for performance testing of hydraulic valves, hydraulic motor and hydraulic pump. The composition structure diagram of hydraulic system, power supply system, and the signal flow diagram of data acquisition system were designed. The communication between sensors and computer via RS232 were researched. At last, the hydraulic test software is developed by using Labwindows/CVI and Simense PLC. &copy; (2012) Trans Tech Publications, Switzerland.},
key = {Hydraulic machinery},
keywords = {Communication;Electric power systems;Equipment testing;Hydraulic equipment;Hydraulic motors;Machine design;Mechatronics;Product design;Systems analysis;},
note = {Composition structure;Data acquisition system;Engineering machinery;Hydraulic pump;Hydraulic system;Hydraulic tests;Hydraulic valves;Labwindows;LabWindows/CVI;Performance testing;Signal flow;Structure design;Testing tools;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMR.590.427},
} 


@inproceedings{20081711224509 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Real- time measurement of friction coefficient in the frictional performance test of brake disk},
journal = {Key Engineering Materials},
author = {Huo, Xiao-Jing and Zhang, Rui-Qing and Wang, Hui and Qian, Dong-Ping and Teng, Jia-Xu},
volume = {373-374},
year = {2008},
pages = {484 - 487},
issn = {10139826},
abstract = {Development and optimizing of friction material formula, oriented to improve the service life and security of brake disk, is largely based on advanced measurement method to accurately provide the friction coefficient. In this study, virtual instrumentation technique was used to design an automation measurement system of friction coefficient. With proper sensors, data of four measured variables such as temperature, rotation speed, pressure and friction torque are acquired by the computer combined with a plug-in data acquisition board. The system work principle, selection of sensors, multi-channel sampling, signal processing and anti-jamming measures have been presented in detail. Those functions of the software such as real-time data acquisition, dynamic wave displaying, high-speed report saving and inquiry, and so on, have been realized by LabWindows/CVI 7.1. The system works safely with high accuracy and friendly user interface in practical operation.},
key = {Friction materials},
keywords = {Disks (machine components);Measurement theory;Optimization;Real time systems;},
note = {Brake disks;Friction coefficient;Virtual instrumentation;},
} 


@inproceedings{20162102423654 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Application of selected performance test scenarios on multi-channel UHF receivers},
journal = {GeMiC 2016 - 2016 German Microwave Conference},
author = {Trommer, Ralph and Quednau, Philipp and Schmidt, Lorenz-Peter},
year = {2016},
pages = {73 - 76},
address = {Bochum, Germany},
abstract = {In a preceding paper a multi-channel test signal generator for UHF radar applications was presented. The present contribution shows the application of this generator to test the performance of multi-channel receivers in selected scenarios. Exemplary measurement results are presented showing the usable dynamic range and the maximum packet reception rate for a secondary surveillance radar receiver and a smart meter data collector. Furthermore the direction-of-Arrival estimation precision and the source separation capabilities of the receivers are tested under various conditions. &copy; 2016 Institut fur Mikrowellen und Antennentechnik-IMA.},
key = {Direction of arrival},
keywords = {Radar;Radar measurement;Signal receivers;Smart meters;Source separation;Surveillance radar;},
note = {Data collectors;Direction of arrival estimation;Dynamic range;Multi channel receiver;Packet Reception Rate;Performance tests;Secondary surveillance radars;UHF receivers;},
URL = {http://dx.doi.org/10.1109/GEMIC.2016.7461559},
} 


@inproceedings{20151200655723 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Calibrate workload model for accurate performance testing},
journal = {40th International Conference on Performance and Capacity 2014 by CMG},
author = {Mao, Benjamin},
year = {2014},
address = {Atlanta, GA, United states},
abstract = {Web performance testing, in short, is to simulate real user access workload and web system behaviour in test environment. Performance engineers often spent significant time to build and validate performance test workload model with their best effort and knowledge. The reality is that the workload models in performance testing often missed their real-world scenario targets due to missing "significant non critical" web usages or lack of accurate workload model validation. The accuracy of workload model is directly reflected back into the understanding of web app usage pattern in production. Without an accurate workload model, not only performance test results could be incorrect, but also many following tasks, performance bottleneck recreating, server performance tuning, capacity planning, and application framework validation could be at wrong targets. I will walk you through a practical way of building accurate workload model that will be matching to the targeted prod workload much closer comparing to the workload model created in current performance testing practice. The high accurate workload model and followed performance test results will bring high confidence on web app performance of new releases to project team.},
key = {Social networking (online)},
note = {Accurate performance;Application frameworks;Current performance testing;Model calibration;Performance bottlenecks;Performance testing;Web usage;Work-load models;},
} 


@inproceedings{20174904486358 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {No-load performance testing of an arduino-primed hybrid solar-electric crop dryer},
journal = {2017 ASABE Annual International Meeting},
author = {Nwakuba, Nnaemeka R. and Chukwuezie, Collins O. and Asoegwu, Sabbas N. and Nwaigwe, Kevin N.},
year = {2017},
pages = {ASABE - },
address = {Spokane, WA, United states},
abstract = {This work presents the performance testing of an arduino-controlled hybrid solar-electric cabinet dryer under no-load condition. The integral hybrid system mainly consists of solar and electric heat components which are connected to a programmable circuit board (micro-controller) with a piece of software (integrated development environment, IDE) known as arduino micro-processor which controls and automates the overall operation of the dryer system through its relay and receives signals from transducer sensors (a capacitive humidity and thermistor sensors) placed at different locations on the dryer. Through the use of a 4 X 4 matrix keypad, preset chamber temperature threshold and chamber air flow rates were inputted; relative humidities of the different locations, tray and chamber temperatures and energy consumption from both solar and electric energy sources were measured, recorded, displayed on the liquid crystal display (LCD) and transferred to a microcomputer via a universal serial board (USB) cord. With the arduino platform, the quantity of moisture loss per given time and energy required for drying as well as other basic drying parameters can be effectively measured with minimum human supervision, thus making the entire operation automated and efficient. No-load tests were conducted to evaluate the thermal profile of the dryer, which involved running the dryer at five different air velocities (0.1, 0.5, 1.0, 1.5, and 2.0 m/s) in order to determine the required time to reach the preset optimum drying temperatures of 50, 55, 60, 65, 70oC. Results obtained show that an average minimum drying chamber heat-up times of 9.8 and 6.2 minutes were required by the electrical and hybrid heat sources at a temperature and air velocity of 70oC and 2 m/s respectively. Ambient air temperature, relative humidity and air velocity were observed to have significant influence on the dryer heat-up time and tray temperatures. Drying time had significant effect on the energy consumption of the dryer mainly due to hourly solar heat. The hybrid and electric heat sources developed a maximum chamber temperature of about 92.5 and 84oC respectively after 210 minutes. Peak energy of 1946 and 1485kW-hr were developed by the hybrid and electric heat units respectively and 784kW/m<sup>2</sup>was developed by the solar collector. The solar component contributed a maximum drying chamber temperature of 30 to 31.7oC which is about 50 to 55% of the required drying chamber temperature. Energy regression equation models were developed in terms of time for each heat source as well as the hybrid with an average R<sup>2</sup>-value of 0.99. The general performance of the dryer was attributed to the heat contribution of the solar collector and that of the electric heater as well as its negligible thermal losses. Good prospects for future applications as well as recommendations were stated.<br/>},
key = {Dryers (equipment)},
keywords = {Air;Atmospheric humidity;Capacitive sensors;Drying;Electric heating;Electric losses;Energy utilization;Humidity control;Hybrid systems;Liquid crystal displays;Load testing;Solar collectors;},
note = {Ambient air temperature;Arduino processor;Heat profiles;Heat-up time;Hybrid dryers;Integrated development environment;Liquid crystal display(LCD);Programmable circuits;},
URL = {http://dx.doi.org/10.13031/aim.201700079},
} 


@article{20141317518374 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Diagnostic load testing and assessment of existing bridges: examples of application},
journal = {Structure and Infrastructure Engineering},
author = {Olaszek, Piotr and Lagoda, Marek and Casas, Joan Ramon},
volume = {10},
number = {6},
year = {2014},
pages = {834 - 842},
issn = {15732479},
abstract = {Load testing method is a significant tool in the assessment of bridge safety. One type of load tests is diagnostic load testing, the aim of which is to establish a comparison between real bridge behaviour and analytical calculation. It can be used either as acceptance test of the structures or as an estimation tool for the load carrying capacity of the already existing structures that have been in service for some time. This article presents diagnostic load tests and three examples of their application to various bridge structures and emphasises their diagnostic potential for assessment. In the majority of cases of diagnostic load tests presented in the literature, the experimental results (deflections, strains, etc) are very close or lower than the predicted ones and for this reason, such tests are expected to validate the existing structure. However, in the cases presented here, it is shown how the experimental results differ considerably from the expected ones. Since the theoretical and the experimental results of all three examples did not match, it was highly recommended to keep the matter under close investigation. A deep insight into the bridges showed serviceability and safety concerns and in some cases a repair/strengthening was necessary. &copy; 2013 &copy; 2013 Taylor &amp; Francis.<br/>},
key = {Acceptance tests},
keywords = {Bridges;Load testing;Loading;Safety testing;},
note = {Analytical calculation;assessment;Bridge structures;Diagnostic load tests;Diagnostic potential;Existing structure;Field testing;Testing and assessments;},
URL = {http://dx.doi.org/10.1080/15732479.2013.772212},
} 


@inproceedings{20082811353983 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Realistic load testing of web applications},
journal = {Proceedings of the European Conference on Software Maintenance and Reengineering, CSMR},
author = {Draheim, Dirk and Grundy, John and Hosking, John and Lutteroth, Christof and Weber, Gerald},
year = {2006},
pages = {57 - 67},
issn = {15345351},
address = {Bari, Italy},
abstract = {We present a new approach for performing load testing of web applications by simulating realistic user behaviour with stochastic form-oriented analysis models. Realism in the simulation of user behaviour is necessary in order to achieve valid testing results. In contrast to many other user models, web site navigation and time delay are modelled stochastically. The models can be constructed from sample data and can take into account effects of session history on user behaviour and the existence of different categories of users. The approach is implemented in an existing architecture modelling and performance evaluation tool and is integrated with existing methods for forward and reverse engineering. &copy; 2006 IEEE.<br/>},
key = {Behavioral research},
keywords = {Computer software maintenance;Load testing;Reengineering;Reverse engineering;Stochastic models;Stochastic systems;Websites;},
note = {Existing architectures;Form-oriented analysis;New approaches;Performance evaluation tools;Sample data;User behaviour;WEB application;Web site navigation;},
URL = {http://dx.doi.org/10.1109/CSMR.2006.43},
} 


@inproceedings{1997373414495 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Optical system development and performance testing of the NEAR laser rangefinder},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Boies, Mark T. and Cole, Timothy D. and El-Dinary, Ashruf S. and Reiter, R.Alan},
volume = {2811},
year = {1996},
pages = {169 - 184},
address = {Denver, CO, USA},
abstract = {The near-earth asteroid rendezvous (NEAR) laser rangefinder (NLR) is a bistatic system using a diode-pumped Nd:YAG laser and a Dall-Kirkhamm telescope for a receiver. The NLR is one of a suite of five scientific data gathering instruments on the NEAR spacecraft. The NEAR mission is the first of NASA's Discovery Series of spacecraft. The NLR transmitter emits a 15.6 mJ, 15 ns pulse at 1064 nm. The receiver is capable of reliably detecting return signals from the asteroid as low as 1 fJ per pulse, which corresponds to an average power of 50 nW (20 ns pulse). The development and alignment approach of the bistatic system are discussed. The performance test results of the receiver, transmitter, and integrated rangefinder system are presented. Particular attention is given to the system alignment tests and an open air range verification test.},
key = {Range finders},
keywords = {Optical radar;Solid state lasers;Space applications;Telescopes;},
note = {Dall-Kirkhamm telescope;Near-earth asteroid rendezvous;},
} 


@article{20164803056277 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Development and performance testing of 'Comb Separator', a novel sewer overflow screening device},
journal = {International Journal of Environment and Waste Management},
author = {Aziz, Md. Abdul and Imteaz, Monzur A. and Rasel, H.M. and Phillips, Donald},
volume = {16},
number = {3},
year = {2015},
pages = {248 - 261},
issn = {14789876},
abstract = {Rivers and creeks receive a lot of sewer solids due to sewer overflow. This overflow causes a serious concern for the environment, aesthetics and public health. To manage such sewer overflow, different types of screening device were developed. The initial expense, maintenance costs, poor sewer capture efficiency and blinding on the screen were discussed as the limitations of these overflow devices. Most screens had electro-mechanical systems that were expensive, complex and caused concern for possible malfunctions in unstaffed remote locations. Consequently, a novel sewerage overflow device 'Comb Separator' was conceived, developed and tested. Optimum criteria were achieved for the device using trial and error method; robustness of the experimental set-up was tested to reproduce consistent results. There was minimal blockage on the screen and higher capture efficiency than Hydro-JET&trade;. The 'Comb Separator' has a good application potential to improve the sewer solids capture in the urban sewerage system. Copyright &copy; 2015 Inderscience Enterprises Ltd.},
key = {Sewers},
keywords = {Efficiency;Public health;Separators;},
note = {Capture efficiency;Electromechanical systems;Experimental set up;Maintenance cost;Performance testing;Screening devices;Sewer solids;Trial-and-error method;},
URL = {http://dx.doi.org/10.1504/IJEWM.2015.073033},
} 


@inproceedings{20130315904438 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Load testing on a budget},
journal = {34th International Conference Computer Measurement Group},
author = {Johnson, Peter},
year = {2008},
address = {Las Vegas, NV, United states},
abstract = {Load testing your application before placing it into production is always a good idea. Load testing during development is an even better idea. But commercial load testing software tends to be expensive and thus placing copies into the hands of every developer might not be feasible. This paper examines JMeter, a popular free, open source load testing tool. This paper is written as a tutorial showing how to use JMeter to load test an example application.},
key = {Measurements},
note = {Load test;Open sources;Testing software;},
} 


@article{20154401488855 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test of new near-ambient-pressure XPS at Korean Basic Science Institute and its application to CO oxidation study on Pt3Ti polycrystalline surface},
journal = {Current Applied Physics},
author = {Jeong, Changkil and Yun, Hyungjoong and Lee, Hyungcheol and Muller, Sebastian and Lee, Jouhahn and Mun, Bongjin Simon},
volume = {16},
number = {1},
year = {2016},
pages = {73 - 78},
issn = {15671739},
abstract = {A performance test of near-ambient pressure X-ray photoelectron spectroscopy (NAP-XPS) at Korean Basic Science Institute (KBSI) in Daejeon, Korea is carried out. The NAP-XPS at KBSI is equipped with SPECS PHOIBOS 150 analyzer and 2-dimensional-delay line detector, which provides improved detection efficiency with 1-dimensional chemical imaging mode. The in-situ gas-pressure cell is designed to operate at pressure up to 25 mbar with differential pumping scheme. A micro-focused Al<inf>K&alpha;</inf>X-ray source is utilized as photon excitation source. The NAP-XPS is composed of two separate chambers, e.g. a main preparation chamber and a measurement chamber, which hold a low energy electron diffraction, a high pressure cell, an ion sputter gun, a multi-cell E-beam evaporators, and a four-axis manipulator with heating and cooling capability. As a test run of NAP-XPS, a CO oxidation experiment is carried out on Pt<inf>3</inf>Ti polycrystalline surface. During the active phase of CO oxidation, a clear formation of Ti oxide is found on surface, revealing the intriguing role of surface metal oxide in surface chemical reaction. &copy; 2015 Elsevier B.V.},
key = {X ray photoelectron spectroscopy},
keywords = {Chemical detection;Electrons;Metals;Oxidation;Phase interfaces;Photoelectrons;Photons;Platinum;Platinum alloys;Surface reactions;Titanium;Titanium oxides;},
note = {Ambient pressure xps;Ambient-pressure x-ray photoelectron spectroscopies;Co oxidation;Differential pumping;Polycrystalline surface;Pt alloy;Surface chemical reactions;X-ray photoemissions;},
URL = {http://dx.doi.org/10.1016/j.cap.2015.10.010},
} 


@inproceedings{1998023935263 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of communication protocols for three-tier computing: Results for ICA and X Window protocols},
journal = {Proceedings of the International Conference on Computer Communications and Networks, ICCCN},
author = {Roberts, David C. and Grossman, David A. and Frieder, Ophir and Bernstein, Robert and Bishop, Eric},
year = {1997},
pages = {450 - 455},
address = {Las Vegas, NV, USA},
abstract = {We present the results of performance tests to compare two protocols for three-tier computing using the Windows NT operating system. Three-tier computing features a data server for stored databases (Tier 1), an application server that runs applications (Tier 2), and a simple client program that runs on desktop machines that presents the user interface (Tier 3). Three protocols are available to communicate between Tier 2 and 3: Intelligence Computer Architecture (ICA) with and without data compression, and X Window. We measured the performance of the three protocols in a multi-user environment in which we simulated the workload imposed by typical users. We found that, for Microsoft Office 97 and Lotus Notes applications, the X Window protocol uses approximately twice the network bandwidth of ICA, without compression. We also found that compressed ICA generates roughly one third less network traffic than uncompressed ICA at a cost of 20% of additional processor utilization.},
key = {Network protocols},
keywords = {Bandwidth;Computer architecture;Computer simulation;Data compression;Database systems;Telecommunication traffic;User interfaces;Wide area networks;},
note = {Intelligence computer architecture (ICA);Three tier computing;},
} 


@inproceedings{20103013100705 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Automating performance testing of interactive Java applications},
journal = {Proceedings - International Conference on Software Engineering},
author = {Jovic, Milan and Adamoli, Andrea and Zaparanuks, Dmitrijs and Hauswirth, Matthias},
year = {2010},
pages = {8 - 15},
issn = {02705257},
address = {Cape Town, South africa},
abstract = {Interactive applications with graphical user interfaces are prevalent in today's environment: Everybody with access to any kind of computer constantly uses them. A significant body of prior work has devised approaches for automating the functional testing of such applications. However, no such work exists for automatically testing their performance. Performance testing imposes additional requirements upon GUI test automation tools: the tools have to be able to replay complex interactive sessions, and they have to avoid perturbing the application's performance. We study the feasibility of using five Java GUI capture &amp; replay tools for GUI performance test automation. Besides confirming the severity of the previously known GUI element identification problem, we also identify a related problem, the temporal synchronization problem, which is of increasing importance for GUI applications that use timer-driven activity. We find that most of the tools we study have severe limitations when used for recording and replaying realistic sessions of real-world Java applications, and that all of them suffer from the temporal synchronization problem. However, we find that the most reliable tool, Pounder, causes only limited perturbation, and thus can be used to automate performance testing. Besides the significance of our findings to GUI performance testing, the results are also relevant to capture &amp; replay-based functional GUI test automation approaches. Copyright 2010 ACM.<br/>},
key = {Software testing},
keywords = {Automation;Graphical user interfaces;Java programming language;Testing;},
note = {Functional testing;Identification problem;Interactive applications;Interactive Java applications;Interactive session;Performance testing;Temporal synchronization;Test automation tool;},
URL = {http://dx.doi.org/10.1145/1808266.1808268},
} 


@article{2006079700075 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stochastic re-entrant line modeling for an environment stress testing in a semiconductor assembly industry},
journal = {Applied Mathematics and Computation (New York)},
author = {Kumar, Suresh and Omar, Mohamed Khaled},
volume = {173},
number = {1},
year = {2006},
pages = {603 - 615},
issn = {00963003},
abstract = {Environmental stress testing (EST) is a reliability test for the semiconductor products that is concerned with how products perform its intended functions under some environmental conditions. Planning, implementation and delivery schedules are affected by the outcome of these tests and it is crucial to determine the throughput of the EST process. In this paper we present an efficient modified analytical model based on approximate mean value analysis (MVA) with probabilistic re-entrant line to predict the total mean waiting time and subsequently the mean throughput rate for the EST process. Using the analytical and simulation method, we analyse a five-stage queuing system with re-entrant to the second stage under various stochastic routing. The MVA algorithm has been modified to deal with this situation. Results show that the modified algorithm can deal with situations involving small and large number of lots respectively. &copy; 2005 Elsevier Inc. All rights reserved.},
key = {Environmental testing},
keywords = {Algorithms;Approximation theory;Probabilistic logics;Semiconductor materials;Strategic planning;Stress analysis;},
note = {Approximate mean value analysis;Environmental stress testing;Mean throughput rate;Mean waiting time;Stochastic re-entrant;},
URL = {http://dx.doi.org/10.1016/j.amc.2005.04.050},
} 


@inproceedings{20114414470542 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Dynamic performance testing study of micro-turbine based distributed energy system},
journal = {Applied Mechanics and Materials},
author = {Zhang, Xuemei and Shen, Cen and Zhong, Yingjie and Qin, Chaokui and Zhou, Dahan},
volume = {71-78},
year = {2011},
pages = {2534 - 2542},
issn = {16609336},
address = {Shangri-La, China},
abstract = {The gas intake system, micro-turbine (MT) system and the absorption chiller within MT based Distributed Energy System (DES) demonstration project in Shanghai wer experimentally modified. An Computer Aided Testing(CAT) system, including exhaust gas flow rat metering, gas temperature, gas pressure and gas composition testing instruments, together with th data acquisition module of MT, was added to continually monitor and record the real-time data o DES, which is the foundation for further MT based DES energy management, optima operation and control strategies research. &copy; (2011) Trans Tech Publications.},
key = {Distributed computer systems},
keywords = {Civil engineering;Computer control systems;Computer testing;Energy management;Gases;Information management;Instrument testing;Materials testing;Rat control;Turbines;},
note = {Absorption chillers;Acquisition modules;Computer aided testing;Demonstration project;Distributed energy systems;Dynamic Performance;Gas compositions;Gas pressures;Gas temperature;Micro turbine;Operation and control;Real-time data;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.71-78.2534},
} 


@inproceedings{1999034471460 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Navajo scrubber project - start up and performance testing of the largest FGD system in the USA},
journal = {International Exhibition &amp; Conference for the Power Generation Industries - Power-Gen},
author = {Lusko, John and Massion, Richard and Sekhar, Net},
year = {1998},
pages = {53 - },
address = {Dallas, TX, USA},
abstract = {The Navajo Scrubber Project located in Page, Arizona is the largest Flue Gas Desulfurization (FGD) system in the USA. The start-up sequence/operation and performance test of Unit 3 of the FGD system is described. Performance tests include removal efficiency at 0.6 and 0.8% sulfur coal at normal and 60,000 PPM chloride in the slurry, particulate carry over determination under normal as well as upset ESP conditions, and determination of mist eliminator carry-over Video Droplet Analyzer.},
key = {Scrubbers},
keywords = {Desulfurization;Electric power plants;Flue gases;Performance;Plant startup;Project management;Sulfur dioxide;Testing;},
note = {Flue gas desulfurization;United States of America;},
} 


@inproceedings{20083211436764 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test of an environmental radiation monitoring system},
journal = {IEEE Nuclear Science Symposium Conference Record},
author = {Hong, S.B. and Han, S.H. and Chung, C.E.},
volume = {1},
year = {2007},
pages = {754 - 755},
issn = {10957863},
address = {Honolulu, HI, United states},
abstract = {A Portable environmental radiation monitoring system which is able to monitor both a scintillation detector and a high pressure ion chamber was developed. We applied Mourich's spectrum-dose rate conversion(G(E) method) for measurement of dose rate and Beck's energy band for natural radiation dose rate of NaI(TI) Detector. Also man-made radiation dos rate against nuclear power plant such as Cs-137, Mn-54, C0-58, Co-60, Ir-192 was measured. &copy; 2007 IEEE.<br/>},
key = {Monitoring},
keywords = {Medical imaging;Microwave integrated circuits;Nuclear fuels;Nuclear power plants;Nuclear reactors;Sodium Iodide;},
note = {Dose rate;Environmental radiation;High pressure ion chamber;NaI detector;Natural radiation;Performance tests;},
URL = {http://dx.doi.org/10.1109/NSSMIC.2007.4436438},
} 


@inproceedings{20172903961802 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of an internet of things platform},
journal = {IoTBDS 2017 - Proceedings of the 2nd International Conference on Internet of Things, Big Data and Security},
author = {Esquiagola, John and Costa, Laisa and Calcina, Pablo and Fedrecheski, Geovane and Zuffo, Marcelo},
year = {2017},
pages = {309 - 314},
address = {Porto, Portugal},
abstract = {The Internet of Things (IoT) is a network of physical objects, or things, with embedded electronics, software, sensors, and connectivity. The connection of all these things leverages value generation, by offering new services and strategic information. In order to make the Internet of Things possible, the integration of many technologies is necessary, such as machine-To-machine and cyber-physical systems. The process of testing IoT applications introduces new challenges because it does not only includes typical test strategies and methodologies. Testing an IoT system depends on its the specific configuration, and it also needs to consider the hardware platform and the network environment. Currently, industry and academy efforts are focusing on usability and connectivity tests, such as: simulating the environment where the device is to be used, and ensuring information is exchanged in a secure manner. In this paper, we use the current version of our IoT platform to perform stress testing of our IoT platform under different conditions. Our test methodology for IoT applications is also presented. Three different hardware platforms have been used for performing the stress testing of our platform. Copyright &copy; 2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
key = {Internet of things},
keywords = {Big data;Cyber Physical System;Embedded systems;Hardware;Testing;},
note = {Embedded electronics;Hardware platform;Internet of thing (IOT);IOT applications;Machine to machines;Network environments;Performance;Performance testing;},
} 


@inproceedings{20125215834376 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Dynamic performance test and analysis of spindle system of high speed grinding machine tools},
journal = {Applied Mechanics and Materials},
author = {Guo, Miao Xian and Li, Bei Zhi and Yang, Jian Guo},
volume = {226-228},
year = {2012},
pages = {720 - 724},
issn = {16609336},
address = {Shanghai, China},
abstract = {The high speed machine tool spindle plays an important role in machining operations. Based on modal test techniques and rotating machinery signature techniques, the research focused on the test and analysis of the dynamic characteristics of spindle system of high speed grinder. First, an experimental modal analysis (EMA) is performed in the spindle system; then, the frequency response characteristics and the FRFs of the system should be considered. Furthermore, rotating machinery signature techniques are used to analyze the dynamic behavior of the spindle system in process due to the limitation of modal test techniques, and the theoretical proof is given to explain the spindle system order. The results show that it requires the machine tool to avoid the use of vibration-sensitive speed in the production process and the machine production process, especially bearing manufacturing to improve its accuracy. &copy; (2012) Trans Tech Publications, Switzerland.},
key = {Grinding machines},
keywords = {Frequency response;Grinding (machining);Grinding wheels;Modal analysis;Production engineering;Rotating machinery;Structural dynamics;},
note = {Dynamic behaviors;Dynamic characteristics;Dynamic performance;Experimental modal analysis;Frequency response characteristic;High-speed grinding machine;High-speed machine tools;In-process;Machine production;Machining operations;Modal test;Order analysis;Production process;Spindle systems;Test and analysis;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.226-228.720},
} 


@inproceedings{20161602247507 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {PerfCenterLite: Extrapolating load test results for performance prediction of multi-tier applications},
journal = {Proceedings of the 8th International Conference on Performance Evaluation Methodologies and Tools, VALUETOOLS 2014},
author = {Apte, Varsha and Nadeesh, T.V.},
year = {2014},
pages = {181 - 186},
address = {Bratislava, Slovakia},
abstract = {Performance modeling is an important step in the lifecycle of a typical Web-based multi-tier application. However, while most practitioners are comfortable carrying out load tests on a Web application on a testbed, they find sophisticated performance modeling tools difficult to use because many inputs required by them are difficult to obtain. Chief among these is the service times of various types of requests at various resources in the multi-tier system (e.g. CPU execution time required at the Web server by a \Login" request). In this paper, we present PerfCenterLite, a tool focused on ease of use for practitioners of performance analysis. The tool (a) provides a spread-sheet template for describing the application architecture and (b) accepts standard performance metrics obtained from load testing of the application. PerfCenterLite then uses mathematical estimation techniques and transforms this input into a full-edged performance model as required by a sophisticated performance modeling tool. Validation experiments show that performance metrics predicted using PerfCenterLite match well with measured values. &copy; Copyright 2015 ICST.},
key = {Load testing},
keywords = {Mathematical transformations;World Wide Web;},
note = {Application architecture;Mathematical estimation;Multi-tier applications;Performance analysis;Performance metrics;Performance Model;Performance prediction;Standard performance;},
URL = {http://dx.doi.org/10.4108/icst.valuetools.2014.258208},
} 


@inproceedings{20164002875527 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test of Taurus HPC system},
journal = {Proceedings of 2016 IEEE International Conference of Online Analysis and Computing Science, ICOACS 2016},
author = {Zhang, Hailong and Nie, Jun},
year = {2016},
pages = {185 - 188},
address = {Chongqing, China},
abstract = {High performance computing system has become the strong support of scientific research due to the good cost performance ratio and scalability after pure science and experimental science, the performance tests help to find out the performance bottlenecks of HPC systems. How to evaluate the performance of a HPC system is the main purpose of this paper. A high-performance computing system with 16 CPU+GPU compute nodes has been constructed. HPL benchmark was used to evaluate the performance of CPU, GPU under different matrix scale Ns, computational nodes, block size NB of matrix etc, and an empirical formula of Ns value calculation was presented through lots of testings. A comprehensive storage I/O performance was tested with IOZone which is a professional file system's standard testing tool. The performance of CPU cluster reaches 93.5% of the system theoretical value and GPU cluster gets 80% of the theoretical value. &copy; 2016 IEEE.},
key = {Benchmarking},
keywords = {Matrix algebra;Program processors;},
note = {Computational nodes;Cost-Performance ratio;Experimental science;High performance computing systems;IOZone;Linpack;Performance bottlenecks;Scientific researches;},
URL = {http://dx.doi.org/10.1109/ICOACS.2016.7563076},
} 


@article{20071710564432 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Developing a tapping and drilling measurement system for a performance test using a laser diode, position-sensing detector, and laser interferometer},
journal = {Proceedings of the Institution of Mechanical Engineers, Part B: Journal of Engineering Manufacture},
author = {Jywe, Wenyuh and Chen, Chun-Jen},
volume = {220},
number = {12},
year = {2006},
pages = {2077 - 2086},
issn = {09544054},
abstract = {Tapping and drilling are frequently used in mechanical working. Previous research on tapping and drilling has mainly focused on cutting force variations, drill and tap wearing, and drill and tap design: machine tool performance has seldom been dealt with. A novel performance test system of tapping and drilling for a computer numerical control (CNC) machine tool is established in the current paper. This system includes a two-dimensional position sensing detector, a laser source, and a laser interferometer. The laser source was fixed on the spindle of the machine tool by the cutter, and the position sensing detector was mounted on the machine tool table. The reflecting mirror of the interferometer was fixed on the z axis of the machine tool, and the laser source of the laser interferometer was mounted on the machine tool table. Therefore, the spindle errors and the z axis position of the machine tool could be recorded by the position-sensing detector and laser interferometer respectively. Consequently the spindle error and z axis motion of the machine tool in the tapping/drilling test could be measured simultaneously. The accuracy of this system in the x-, y-, and z-directions was about 1 &mu;m in each case. The present paper describes the experiments of the position-sensing detector calibration, stability test, tapping test, and drilling test. The findings are discussed below. &copy; IMechE 2006.},
key = {Tapping (threads)},
keywords = {Computer control systems;Detectors;Drilling;Laser interferometry;Machine tools;Numerical control systems;Semiconductor lasers;},
note = {Drilling test;Performance test;Position sensing detectors;Spindle errors;Tapping test;},
URL = {http://dx.doi.org/10.1243/09544054JEM264},
} 


@inproceedings{20121915005594 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Application of wireline stress testing for SAGD caprock integrity},
journal = {Society of Petroleum Engineers - Canadian Unconventional Resources Conference 2011, CURC 2011},
author = {Mishra, Vinay K. and Lywood, Peter and Ayan, Cosan},
volume = {3},
year = {2011},
pages = {2184 - 2195},
address = {Calgary, AB, Canada},
abstract = {Measuring geomechanical properties of the caprock and shale gas reservoirs for enhanced oil recovery (EOR) or storage reservoirs has become an integral part of asset evaluation services. The steam-assisted gravity drainage (SAGD) process, as well as other EOR and storage applications (gas, nuclear waste, CO<inf>2</inf>), requires caprock integrity testing. Measuring in-situ stresses is an important input to caprock integrity solutions not only for the technical management of projects but also for environmental reasons. A Wireline Formation Testing (WFT) tool is one of the commonly used techniques used for direct measurement of the minimum in-situ stress at different depths. The process is commonly called a mini-frac or micro-frac and is typically performed in an openhole wellbore. A suitable tool string includes a straddle packer arrangement, downhole pump, gamma ray sonde for depth correlation, motorized valves, and pressure gauges. To perform a stress test, an interval of the wellbore is isolated by inflating me straddle packer arrangement. The interval is then pressurized by pumping fluid until a tensile fracture is initiated. In an open hole, the fracture initiates and propagates normal to the minimum stress. Multiple injection and fall-off cycles are performed to ensure fracture growth beyond the hoop stress regime. The data is analyzed to determine fracture initiation pressure, fracture propagation, and closure pressure. This paper describes the process of minimum in-situ stress measurement using a WFT. Lessons leamt over the years and best practices are highlighted along with their importance for proper job planning. Case studies of WFT testing including SAGD caprock stress testing from Canadian fields are presented and discussed. Copyright 2011, Society of Petroleum Engineers.<br/>},
key = {Enhanced recovery},
keywords = {Digital storage;Fracture;Gamma rays;Oil well flooding;Oil wells;Packers;Petroleum reservoir evaluation;Petroleum reservoirs;Resource valuation;Shale;Shale oil;Stresses;},
note = {Enhanced oil recovery;Environmental reasons;Fracture initiation pressures;Geomechanical properties;In-situ stress measurement;Steam-assisted gravity drainages;Technical management;Wireline formation testing;},
} 


@inproceedings{1996463339652 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Compact, low-cost, high-performance test fixture for electrical test and control of smart pixel integrated circuits},
journal = {LEOS Summer Topical Meeting},
author = {Kiamilev, Fouad and Rozier, Richard and Rieve, James},
year = {1996},
pages = {2pp - 2pp},
issn = {10994742},
address = {Keystone, CO, USA},
abstract = {A low-cost, compact test fixture that can supply and monitor high-speed electrical signals for smart pixel ICs packaged in an 84-pin PGA chip carrier has been developed. Each of the 84 pins on the smart pixel IC can be strapped to power, ground, or configured as an I/O pin. A Xilinx FPGA chip is used to provide the test program for the smart pixel IC, with each pin having a dedicated connection to an FPGA signal pin. The test program resides in an EPROM chip and the system clock is derived from a 100MHz (or slower) clock generation chip thus facilitating stand-alone operation. The fixture also includes a 7-segment display chip and several LED's that are controlled by the FPGA and can be programmed to display the operating status of the fixture.},
key = {Integrated circuit testing},
keywords = {CMOS integrated circuits;Computer hardware description languages;Computer simulation;Electronics packaging;Integrated optoelectronics;Logic design;Logic devices;Microprocessor chips;Performance;Printed circuit boards;Real time systems;ROM;},
note = {Clock generator chip;Electrical testing;Erasable programmable read only memory;Field programmable gate arrays;High speed electrical signals;Photonic demonstrator systems;Real time control;Smart pixel integrated circuits;Zero insertion force sockets;},
} 


@article{20132816481317 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Resistance factors calibration and its application using static load test data for driven steel pipe piles},
journal = {KSCE Journal of Civil Engineering},
author = {Park, Jae Hyun and Huh, Jungwon and Kim, Kyung Jun and Chung, Moonkyung and Lee, Ju Hyung and Kim, Dongwook and Kwak, Kiseok},
volume = {17},
number = {5},
year = {2013},
pages = {929 - 938},
issn = {12267988},
abstract = {This paper presents the reliability-based resistance factor calibration of driven steel pipe piles and the implementation of Load and Resistance Factor Design (LRFD) on practical design cases. Resistance factors of driven steel pipe piles were calibrated in the framework based on reliability theory using static pile load test results. The results of fifty seven load tests conducted to failure were compiled and these 57 data were divided into three different groups based on their data quality. For the three groups, reliability analyses were performed for two static bearing capacity equations and for different target reliability indices (2.0 and 2.33 for group piles and 2.5 for single piles) following the First-Order Reliability Method (FORM) and using the Monte Carlo Simulation (MCS). It is noted that the resistance factors were highly dependent on the quality of load test data. To implement the calibrated resistance factors, a case study on an actual bridge foundation design was performed. The case study result showed that, for the given target reliability index, the developed LRFD method using the resistance factors calibrated in this study could contribute to cost savings when it is compared with Allowable Stress Design (ASD) case using a safety factor of 3.0. &copy; 2013 Korean Society of Civil Engineers and Springer-Verlag Berlin Heidelberg.},
key = {Load testing},
keywords = {Bearing capacity;Bridge decks;Bridges;Calibration;Monte Carlo methods;Piles;Reliability analysis;Reliability theory;Safety factor;Steel pipe;Structural design;},
note = {Allowable stress design;First order reliability methods;Load and resistance factor designs;Monte-Carlo simulations;Resistance factors;Static load tests;Steel pipe pile;Target reliability index;},
URL = {http://dx.doi.org/10.1007/s12205-013-1038-x},
} 


@inproceedings{2004228186568 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test results of mock-up test facility of HTTR hydrogen production system},
journal = {Journal of Nuclear Science and Technology},
author = {Ohashi, Hirofumi and Inaba, Yoshitomo and Nishihara, Tetsuo and Inagaki, Yoshiyuki and Takeda, Tetsuaki and Hayashi, Koji and Katanishi, Shoji and Takada, Shoji and Ogawa, Masuro and Shiozawa, Shusaku},
volume = {41},
number = {3},
year = {2004},
pages = {385 - 392},
issn = {00223131},
abstract = {For the purpose to demonstrate effectiveness of high-temperature nuclear heat utilization, Japan Atomic Energy Research Institute has been developing a hydrogen production system and has planned to connect the hydrogen production system to High Temperature Engineering Test Reactor (HTTR). Prior to construction of a HTTR hydrogen production system, a mock-up test facility was constructed to investigate transient behavior of the hydrogen production system and to establish system controllability. The Mock-up test facility with a full-scale reaction tube is an approximately 1/30-scale model of the HTTR hydrogen production system and an electric heater is used as a heat source instead of a reactor. After its construction, a performance test of the test facility was carried out in the same pressure and temperature conditions as those of the HTTR hydrogen production system to investigate its performance such as hydrogen production ability, controllability and so on. It was confirmed that hydrogen was stably produced with a hot helium gas about 120m <sup>3</sup>/h, which satisfy the design value, and thermal disturbance of helium gas during the start-up could be mitigated within the design value by using a steam generator. The mock-up test of the HTTR hydrogen production system using this facility will continue until 2004.},
key = {Nuclear energy},
keywords = {Carbon dioxide;Control systems;Energy utilization;Hydrogen;Mockups;Nuclear reactors;Performance;Steam generators;},
note = {Hydrogen production;Nuclear heat utilization;Performance tests;},
} 


@inproceedings{20113714317731 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The acceleration stress test of the brake system on an airplane},
journal = {ICRMS'2011 - Safety First, Reliability Primary: Proceedings of 2011 9th International Conference on Reliability, Maintainability and Safety},
author = {Qiao, Jianjun},
year = {2011},
pages = {1067 - 1072},
abstract = {The test method is discussed which increases the environment stress and the working stress to stimulate failures in products without damage, besides, the method which converts the acceleration stress test time to working time is put forward to evaluate the MTBF and first overhaul period of the product. In order to stimulate potential failures, the technology of colligating reliability test and life test is studied in the brake system of a certain aircraft, in which the environment stress is not statistical stress but its kind and magnitude are established in allusion to the weak links. Rated working stress which corresponds to antiskid brake rule is brought into the test profile and the contamination tolerance test of hydraulic system is conducted. As a result, latent failures of the break system are activated in a short time; the test which needs 5200 working hours to finish is ended in 200 hours; reliability growth rate achieves 0.65; the MTBF of the brake system increases to 848h from 28h in the beginning, and the first overhaul period of new developed products in the break system attains 1250 takeoff-landing times. &copy; 2011 IEEE.<br/>},
key = {Occupational risks},
keywords = {Brakes;Hydraulic equipment;Product design;Reliability;Testing;},
note = {Design improvements;Life evaluation;Reliability Evaluation;Reliability growth;Test method;},
URL = {http://dx.doi.org/10.1109/ICRMS.2011.5979426},
} 


@inproceedings{20174404358482 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test and simulation study on the air path of CAP1400 passive containment cooling system},
journal = {International Conference on Nuclear Engineering, Proceedings, ICONE},
author = {Xinxin, Pan and Jingyu, Huang and Chunjing, Song},
volume = {8},
year = {2017},
pages = {Nuclear Engineering Division - },
address = {Shanghai, China},
abstract = {As a large scale passive pressurized water reactor nuclear power plant, CAP1400 can remove the reactor decay heat to outside containment with the air cooling in the air flow path of passive containment cooling system (PCS) during the longterm period following an accident. Flow resistance characteristic and wind neutrality characteristic are the main performances of PCS air flow path. In order to study the performance of PCS air flow path, it is necessary to carry out the PCS wind tunnel test and computational fluid dynamics (CFD) analysis to establish a suitable method for the analysis of the performance of the air flow path. This paper comes up simulating the internal pressure and velocity distribution in the air flow path under different wind speed through CAP1400 PCS 1:100 scaled air flow path wind tunnel test to research the air flow resistance and internal flow pattern. The test shows that local uneven flow phenomenon exists in the outer annulus of the air flow path, but the wind pressure distribution of inner annulus is not affected by environment wind speed, wind direction angle, landforms and the surrounding buildings. The wind pressure is uniform at different heights on the cross section and shows the neutrality feature. Combining with CAP1400 PCS wind tunnel test, the CFD model is built. The measured inlet wind speed, turbulent kinetic energy and turbulent dissipation rate distribution parameters are inputs and the uniform wind conditions and gradient wind conditions of simulation analysis are developed. Simulation results show that: 1) In uniform wind condition, simulation result of pressure coefficient distribution trend at each cross section is consistent with the test trend and the deviation is very small, which basically can be controlled below 5%. The simulated differential pressures between inner annulus and outer annulus at different elevation are basically identical with the test results, which increase as the elevation arises. The simulated velocity distribution is basically identical with the test. The wind velocity at the upwind and central area of the flow path outlet is larger than other area, and a large swirling region comes on the leeward side near the wall 15cm, but simulated swirling region size at leeward side is slightly smaller. 2) In gradient wind condition, the pressure coefficient distribution trends are basically identical, and the deviation between the test and CFD analysis is 5-10% approximately. Considering the stability of gradient wind condition in wind tunnel is worse than that of uniform wind conditions, and more prone to wind speed fluctuations, therefore, the deviation is slightly greater than the uniform wind condition. According to the CFD simulation and wind tunnel test, it can be found that the simulation of air flow inside and outside annulus has a high precision though the test results are slightly affected by the instrument tubes along the two sides of test model. In general, CFD simulation and wind tunnel test results are basically identical. Therefore, CFD analysis method is well verified by PCS wind tunnel test, which can be applied to the analysis of the actual power plant. Key words: air flow path, wind tunnel test, uniform wind, gradient wind; neutrality, pressure coefficient, CFD. &copy; Copyright 2017 ASME.},
key = {Wind tunnels},
keywords = {Air;Computational fluid dynamics;Cooling;Cooling systems;Flow patterns;Fluid dynamics;Kinetic energy;Kinetics;Nuclear engineering;Nuclear fuels;Nuclear power plants;Nuclear reactor accidents;Pressurized water reactors;Steam condensate;Structural dynamics;Thermoelectric equipment;Velocity distribution;Wind;Wind effects;Wind stress;},
note = {Computational fluid dynamics analysis;Flow resistance characteristic;Passive containment cooling systems;Pressure and velocity distributions;Pressure coefficient distribution;Turbulent dissipation rates;Turbulent kinetic energy;Wind pressure distribution;},
URL = {http://dx.doi.org/10.1115/ICONE25-66321},
} 


@inproceedings{20081011132573 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {State machine based CDMA stress testing service system},
journal = {Proceedings of 2006 IEEE Asia-Pacific Conference on Services Computing, APSCC},
author = {Liu, Lan and Lin, Jun and Li, Zhitang and Li, Jiachun},
year = {2006},
pages = {625 - 628},
address = {Guangzhou, Guangdong, China},
abstract = {This paper introduces a system model of CDMA stress testing service platform based on state machine technology. This system provides an efficient service oriented solution on protocol and stress testing of CDMA system. with high performance and automatic capability. The concurrent multitask mechanism and the state machine framework enable the high performance and automatic capability of this system. And the scalable distributed architecture offers the maximum flexibility of deployment. &copy; 2006 IEEE.},
key = {Code division multiple access},
keywords = {Automation;Concurrent engineering;Scalability;Stress analysis;},
note = {Automatic capability;State machine;Stress testing;},
URL = {http://dx.doi.org/10.1109/APSCC.2006.93},
} 


@inproceedings{20121314908071 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design of radar ECCM performance testing system and its semi-physical simulation experiment},
journal = {Proceedings of 2011 IEEE CIE International Conference on Radar, RADAR 2011},
author = {Ren, Mingqiu and Cai, Jinyan and Zhu, Yuanqing and Han, Zhuangzhi},
volume = {2},
year = {2011},
pages = {1058 - 1062},
address = {Chengdu, China},
abstract = {This paper describes the theory, design, implementation, simulation and testing of a radar ECCM performance testing system capable of generating target echo, clutter and jamming signal for radar ECM/ECCM experiment. With the help of the proposed testing system, the jamming styles and parameters can be smartly intercalated with a variety of simulation scenarios. The rubs are resolved such as radar states data acquisition, echo real time simulation and display &amp; control terminals setup of signal environment. Then a radar ECM semi-physical simulation experiment is applied to measure six typical ECCM performance indexes in the signal environment generated by the testing system. Experiment and data processing results show the testing platform is valid and practical. The testing system can be used to solve problems such as radar ECCM performance evaluation, radar advanced design and ECCM strategies when the equipment is relatively small in tracking and guidance phase. &copy; 2011 IEEE.<br/>},
key = {Radar},
keywords = {Data acquisition;Data handling;Jamming;},
note = {Active jamming;Evaluation index;Performance evaluations;Performance testing;Real time simulations;Semi-physical simulations;Simulation and testing;Testing systems;},
URL = {http://dx.doi.org/10.1109/CIE-Radar.2011.6159734},
} 


@inproceedings{20104713399462 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Application of downhole injection stress testing in the Barnett Shale formation},
journal = {Proceedings - SPE Annual Technical Conference and Exhibition},
author = {Ramakrishnan, H. and Waters, G. and Boratko, E. and Latifzai, A. and Bentley, D. and Kelley, J.},
volume = {2},
year = {2009},
pages = {1107 - 1119},
address = {New Orleans, LA, United states},
abstract = {Knowledge about minimum in-situ stress gradient of various intervals is essential to accurately predict stimulation treatment pressures, net pressure development and fracture height growth. Though several techniques are available to estimate this stress value, often times the analysis is performed in cased holes using surface measurements of rate and pressure which decreases the accuracy of the estimated stress values due to near wellbore storage effects, perforation to fracture misalignment, etc. Commonly employed pump rates and volumes also result in relatively large fractures which could break out of zone if the formation of interest is thin. Additionally, in vertically complex, low permeability intervals such as shales this can result in long decline periods that evidence multiple closure signatures making interpretation quite difficult. In addition, if reservoirs are being developed with horizontal wells, testing in uncased pilot holes is the only option to derive this information. This paper discusses the use of downhole injection stress testing to quantify fracture closure stress. Using this technique the injection and measurement of pressure is done downhole at the zone of interest thereby minimizing near wellbore effects and increasing the accuracy of the measurements. Stress testing is possible over very small intervals isolated with openhole packers using a wireline conveyed tool string. The intervals to be tested are determined from open hole logs run prior to testing. Multiple intervals can be stress tested on a single trip into the hole and several injection-decline cycles can be performed at each depth to bracket the range of closure stress for each of the tested intervals. Validation of the interpretation is enhanced via post-injection formation image logging which identifies the fractures created. Downhole injection stress testing has been performed on multiple wells in the Fort Worth Basin Barnett Shale. Closure stress in various facies within the Barnett Shale and in bounding intervals has been measured. From these tests a better understanding of hydraulic fracture height growth has been acquired. Optimum landing points of horizontal laterals to best control fracture height growth and minimize fracture initiation issues have also been identified. This paper reviews the tool string utilized in this procedure, the methodology for selecting the intervals to be tested, the testing technique, and the data interpretation procedure. Copyright 2009, Society of Petroleum Engineers.<br/>},
key = {Fracture testing},
keywords = {Boreholes;Digital storage;Fracture;Horizontal wells;Hydraulic fracturing;Image enhancement;Oil field equipment;Oil wells;Petroleum reservoir evaluation;Shale;Surface measurement;Well testing;},
note = {Data interpretation;Fracture closure stress;Fracture height;Fracture initiation;Low permeability;Stimulation treatments;Testing technique;Zone of interest;},
} 


@inproceedings{20113614294857 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The credit risk macro stress testing of the Chinese banking system},
journal = {Proceedings of the 2011 Chinese Control and Decision Conference, CCDC 2011},
author = {Fang-Ying, Yuan},
year = {2011},
pages = {1198 - 1203},
abstract = {In order to test the overall credit risk of loans of China's banking system, a macroeconomic credit risk model is designed, including a multiple linear regression model describing default probability, and a set of regression models describing macroeconomic environment. Studies show that bank loan default rates and key macroeconomic factors are related. Then stress tests are implemented one by one according to different shocks. The results showed that most banks continue to profit even at 90% confidence level when estimated risk of loss, reflecting a moderate credit risk in the banking system. However, if confidence level rises to 99% when estimated risk of loss, the banking system will face significant losses. The results show that it is necessary to prevent the credit risk of real estate loans and government debt. Key words: macro stress-testing; credit risk; SUR; Monte Carlo method &copy; 2011 IEEE.<br/>},
key = {Risk perception},
keywords = {Linear regression;Monte Carlo methods;Online systems;Risk assessment;},
note = {Banking systems;Confidence levels;Credit risk modeling;Default probabilities;Macroeconomic environments;Multiple linear regression models;Real estate loans;Regression model;},
URL = {http://dx.doi.org/10.1109/CCDC.2011.5968369},
} 


@article{20133016537289 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of an optimal photocatalytic mop fan air cleaning system},
journal = {International Journal of Energy Research},
author = {Riffat, S.B. and Ma, Xiaoli},
volume = {37},
number = {11},
year = {2013},
pages = {1389 - 1396},
issn = {0363907X},
abstract = {A novel photocatalytic mop fan air cleaning system has been developed. The novel mop fan system is optimized in terms of the pollutant degradation efficiency, energy consumption, appearance and cost reduction based on previous research. The fluid dynamic characteristic and energy consumption of the novel mop fan system has been identified by experimental testing. Pollutant degradation effect of the mop fan on a typical industry pollutant, diesel fume, has also been tested. It was found that the system has very low energy consumption and is very effective to destroy the diesel fume, a microparticulate pollutant. The system is suitable for any indoor environment to clean the air by removing the particulates, odors, virus, bacteria and volatile organic pollutants. &copy; 2012 John Wiley &amp; Sons, Ltd.},
key = {Air pollution},
keywords = {Degradation;Energy utilization;Optimization;Viruses;},
note = {Air cleaning;Air cleaning systems;Dynamic characteristics;Experimental testing;Low energy consumption;Performance testing;Photo-catalytic;Pollutant degradation;},
URL = {http://dx.doi.org/10.1002/er.2925},
} 


@article{20120614750197 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Development of a packet simulator for performance test of information security system},
journal = {International Journal of Multimedia and Ubiquitous Engineering},
author = {Kim, Wankyung and Soh, Wooyoung and Sigfred, Jason},
volume = {1},
number = {1},
year = {2006},
pages = {1 - 4},
issn = {19750080},
abstract = {Development of information security system is brought by problem by the development of network environment, and the need of equipment for performance test, but performance test equipments are expensive and difficult to use. Therefore, we need an environment which can develop a performance test for an information security system. In this paper, the design and implementation of an APS (Attack Packet Simulator) extracts the attack information from Snort rule and creates an attack information in the Database using the extracted information. Stored information in the database creates and transmits the packets which are analyzed for comparing the results to other systems.},
key = {Security of data},
keywords = {Information use;Security systems;Simulators;},
note = {Attack packets;Network environments;Performance tests;Security;},
} 


@inproceedings{20170303247253 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {An accelerometer based system to measure myocardial performance index during stress testing},
journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
author = {Dinh, Anh and Bui, Francis M. and Nguyen, Tam},
volume = {2016-October},
year = {2016},
pages = {4877 - 4880},
issn = {1557170X},
address = {Orlando, FL, United states},
abstract = {Stress testing is used to measure the performance of the heart in an elevated stress state, in order to monitor or diagnose certain heart problems. Many measurements can be used to determine the performance of the heart, with the Tei index being the measurement of interest in this work. The Tei index has been used as a reliable method to evaluate systolic and diastolic performance, as it overcomes some limitations of the classical echocardiographic indices. It is calculated based on the time intervals derived from echocardiography. This paper presents an exploratory study, which uses an accelerometer to record mechanical events occurring in each cardiac cycle, also known as the seismocardiogram (SCG). From timing measurements corresponding to various events in the heart, a metric for myocardial performance is calculated based on the Tei index. The use of SCG in addition to ECG has the potential to provide further insights about the heart during stress testing, since the SCG quantifies mechanical actions of the heart. &copy; 2016 IEEE.},
URL = {http://dx.doi.org/10.1109/EMBC.2016.7591820},
} 


@article{20133416647212 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design, modeling and performance testing of end-effector for sweet pepper harvesting robot hand},
journal = {Journal of Robotics and Mechatronics},
author = {Bachche, Shivaji and Oka, Koichi},
volume = {25},
number = {4},
year = {2013},
pages = {705 - 717},
issn = {09153942},
abstract = {This paper presents a new design and modeling fundamentals of gripper and cutting system for 5 degree of freedom robotic arm, designed to harvest sweet peppers in horticultural green house. The design consists of two parallel jaws mounted on gears and operated with the help of servo motor. The same servo motor was used to operate the cutting system which was composed of scissors. The complete system was designed to operate by using one servo motor only. The system model was developed in SolidWorks and tested for different kinematic and dynamic performances. The performance of the gripper and cutting tool system has been evaluated through simulation to determine the design parameters of practical prototype. Based on the design concept, practical prototype of the gripper and cutting system was developed by considering the results obtained by model developed in SolidWorks. The developed prototype was tested to verify the feasibility and reliability of the model developed in Solid- Works. The performance and practical application of the developed prototype was verified and validated by conducting experiments in the lab and greenhouse and comparing the results with simulation results.},
key = {Grippers},
keywords = {Computer simulation;Cutting tools;Design;Harvesting;Range finding;Robotic arms;},
note = {Complete system;Degree of freedom;Design and modeling;Design concept;Design parameters;Dynamic performance;Harvesting robot;Performance testing;},
} 


@inproceedings{2006019629151 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of ammonia scrubbing system},
journal = {Proceedings of the ASME Summer Heat Transfer Conference},
author = {Yanagi, H. and Khong, M. and Ng, K.C.},
volume = {4},
year = {2005},
pages = {405 - 411},
address = {San Francisco, CA, United states},
abstract = {Accidental massive release of ammonia is extremely dangerous for both the environment and the health of those residing or working close to the release especially in a crowded city. Therefore means of mitigating or in the best case scenario containment of a release shall be a priority. A mobile ammonia scrubber was developed. The scrubbing system installed on a vehicle for easy access to the release site allows the recovery of all liquid and gas up to a 4MT storage tank. In this report, we discuss the ammonia effect on the characteristics of impregnated adsorbent. Its heat generation through the process of adsorption as well as its mass transfer during operation, which simulates an actual accident release. Copyright &copy; 2005 by ASME.},
key = {Ammonia},
keywords = {Adsorption;Calcium compounds;Carbon fibers;Mass transfer;},
note = {Active Carbon Fiber (ACF);Ammonia Scrubber;Safety for Release Accident;},
URL = {http://dx.doi.org/10.1115/HT2005-72474},
} 


@inproceedings{20092912203529 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Application of generalized linear models for optimizing production stress testing},
journal = {Proceedings - Annual Reliability and Maintainability Symposium},
author = {Honari, Bahman and Donovan, John and Joyce, Toby and Wilson, Simon},
year = {2008},
issn = {0149144X},
address = {Las Vegas, NV, United states},
abstract = {Accelerated environmental stress tests (EST) are applied during the manufacturing process to improve reliability by precipitating and detecting latent defects. This test represents an in-process manufacturing screen and the objective of performing it is to avoid early field failures that reduce the customer satisfaction level and increase warranty and compensation costs. Temperature cycling during EST is one of the most commonly used test procedures. Although it is an expensive and energy intensive procedure, usually a lengthy test is initially recommended for a new product. Based on the product test performance or a possible manufacturing process modification, the test duration and regime may be changed after some period. Even if the number of test cycles is reduced, EST continues to be an expensive test and a major process bottleneck. This paper uses Generalized Linear Modeling (GLM) to investigate the effects of the production and EST test variables on the population under test. Both the number of units rejected and the time to failure can be modeled as a regression function of covariates representative of the test environment. The field reliability function is written as a product of the unconditional reliability in each segment of the test profile such as dwell, ramp, etc. The next step is to apply the result of the temperature cycle EST GLM to a mathematical cost model. This cost model includes both the test cost and the warranty and compensation costs of the early field failures. The optimum test regime and number of cycles, which minimizes the total cost is determined by combining the GLM and the cost model. In this way the production test regime can be optimized in terms of field reliability/test cost trade-off. &copy; 2008 IEEE.<br/>},
key = {Costs},
keywords = {Customer satisfaction;Economic and social effects;Functions;Maintainability;Manufacture;Maximum likelihood;Reliability;},
note = {Compensation costs;Environmental stress;Generalized linear model;Manufacturing process;Regression function;Temperature cycles;Temperature cycling;Test optimization;},
URL = {http://dx.doi.org/10.1109/RAMS.2008.4925806},
} 


@inproceedings{20073210748226 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of a multi-component powder coating system},
journal = {Proceedings of the Biennial International Pipeline Conference, IPC},
author = {Been, Jenny and Given, Russ and Worthingham, Robert},
volume = {2},
year = {2007},
pages = {669 - 676},
address = {Calgary, AB, Canada},
abstract = {A number of new coatings offer the possibility for cost savings and/or improved performance. As a shielding coating, the resistance of a high-integrity three-layer coating to disbondment in damaged areas and as a function of applied cathodic potential is of interest with regard to the creation of an environment on the pipe that will support corrosion and/or cracking. The cathodic disbondment (CD) behavior of a multi-component powder coating system has been characterized under simulated field conditions (restrictive mass transport using soils), rather than the standard CSA protocol. The asreceived coating displayed excellent impedance properties and minimal disbondment under normal operating conditions. Coated panels were furthermore subjected to impact damage and a hot water soak prior to the CD tests. Results showed minimal disbondment of the multi-component powder coating system over 3 to 6 months regardless of impact damage or temperature. There was some evidence that more negative potentials may increase the disbondment area over longer periods of time. However, mechanistic considerations, literature information, experimental observations and field experiences would suggest that coating disbondment might be limited when the coating is properly applied and otherwise in good condition. Longer-term experiments are required to confirm the presence of a maximum size disbondment. Copyright &copy; 2006 by ASME.},
key = {Tape coatings},
keywords = {Bond (masonry);Computer simulation;Damage detection;Impact strength;Pipelines;Shielding;},
note = {Cathodic disbondment (CD);Fusion bonded epoxy;Layer coatings;Multi-component powder coating systems;},
URL = {http://dx.doi.org/10.1115/IPC2006-10443},
} 


@inproceedings{1991110328839 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of a floor-based, occupant-controlled office ventilation system},
journal = {ASHRAE Transactions},
author = {Bauman, F.S. and Johnston, L.P. and Zhang, H. and Arens, E.A.},
number = {pt 1},
year = {1991},
pages = {553 - 565},
issn = {00012505},
address = {New York, NY, USA},
abstract = {Measurements were made of the thermal performance of a floor-based, occupant-controlled ventilation system. The experiments were performed in a controlled environment chamber configured to resemble an interior zone of a modern office building with modular workstation furniture and partitions. Velocity and temperature distributions were measured at six heights throughout the test chamber for each test configuration. Tests were conducted to investigate the effects of supply volume, supply location, supply direction, supply/return temperature difference, heat load density, and workstation size and layout. Temperature differences in the range of 1&deg;C to 2.5&deg;C between adjacent workstations were observed, and stratification in the room was strongly dependent on the supply air volume. The jet flow characteristics of the floor supply outlets produced high velocities in their immediate vicinity, increasing the risk of draft discomfort in these regions. However, by controlling the volume and trajectory of the supply air entering the space, office workers were able to control their local environment over a wide range, giving them the opportunity to fine-tune the thermal conditions in their workstation to their personal comfort preferences.},
key = {Ventilation},
keywords = {Flow of Fluids - Jets;Heat Transfer - Measurements;Office Buildings - Ventilation;},
note = {Floor Based Ventilation Systems;Ventilative Cooling;},
} 


@inproceedings{20162802575970 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing for an active/passive vibration isolation and steering system},
journal = {AIAA Dynamics Specialists Conference},
author = {Sullivan, Jeanne M. and Goodding, James C. and Idle, Michelle K. and Das, Alok and Hoffman, Terance J. and Davis, L. Porter},
year = {1996},
pages = {87 - 97},
address = {Salt Lake City, UT, United states},
abstract = {Active and passive vibration isolation mounts which can be used to locally isolate vibration generating mechanisms from the rest of the satellite have been addressed by many researchers. However, with few exceptions, only passive isolation technology has been accepted by satellite designers as mature for space applications. This paper describes the testing of an active/passive vibration isolation and steering system (VISS) which can be used to isolate a precision payload from spacecraft borne disturbances. VISS is a complicated device which is designed to work in a zerog environment. Because of its high mechanical compliance, testing on the ground in a one-g field is a serious concern. The VISS payload will therefore be off-loaded during the ground performance testing. The base of VISS is attached to a composite structure which is, in turn, attached to the host satellite. The flexible body dynamics of the composite structure will be approximated as will the rigid body dynamics of the entire satellite. This paper will discuss the design of the ground test hardware to be used in the VISS performance testing as well as some initial test results. &copy; American Institute of Aeronautics and Astronautics, Inc., 1996. All rights reserved.},
key = {Rigid structures},
keywords = {Satellites;Space applications;Structure (composition);},
note = {Flexible body dynamics;Generating mechanism;Mechanical compliance;Passive vibration isolations;Performance testing;Rigidbody dynamics;Vibration isolations;Zero-g environments;},
URL = {http://dx.doi.org/10.2514/6.1996-1210},
} 


@inproceedings{20142717899524 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Preliminary performance test of mechanical pump for a STELLA-1},
journal = {ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE)},
author = {Han, Ji-Woong and Ko, Bock Seong and Park, Sang-Jun and Lee, Yoon Sang and Jeong, Ji-Young and Lee, Yong Bum},
volume = {15},
year = {2013},
pages = {ASME - },
address = {San Diego, CA, United states},
abstract = {In the process of sodium-cooled fast reactor (SFR) design, it is very important to verify thermo-hydraulic performance of each component in the sodium environment. In KAERI (Korea Atomic Energy Research Institute) STELLA (Sodium Integral Effect Test Loop for Safety Simulation and Assessment) project is under a Mid- and Long-term Nuclear R&amp;D Program. The STELLA project is composed of two stages. In the 1st stage the performance for heat exchangers such as DHX (Decay heat exchanger) and AHX (Air heat exchanger) and for PHTS (Primary heat transport system) mechanical pump will be evaluated. The detailed design of each component is based on that of a 600MWe demonstration reactor. Since full-scale components could not be installed in STELLA-1 [1], the model pump is designed to be scaled-down based on the scaling law. Various pump tests have been done in water environment by using model pump. In this study the design features of model pump were described and the scaling parameters were examined. The results of pump performance tests have been also introduced which is essential to perform safety analysis. Copyright &copy; 2013 by ASME.<br/>},
key = {Pumps},
keywords = {Heat exchangers;Safety engineering;Sodium-cooled fast reactors;Software testing;},
note = {Demonstration reactor;Korea Atomic Energy Research Institute;Performance tests;Primary heat transport systems;Scaling parameter;Sodium cooled fast reactors (SFR);Thermo-hydraulic performance;Water environments;},
URL = {http://dx.doi.org/10.1115/IMECE2013-65654},
} 


@article{1986030036849 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {PERFORMANCE TEST OF LASER VELOCIMETER SYSTEM FOR THE LANGLEY 16-FOOT TRANSONIC TUNNEL.},
journal = {NASA Technical Paper},
author = {Meyers, James F. and Hunter Jr., William W. and Reubush, David E. and Nichols Jr., Cecil E. and Hepner, Timothy E. and Lee, Joseph W.},
year = {1985},
issn = {01488341},
abstract = {An investigation in the Langley 16-Foot Transonic Tunnel has been conducted in which a laser velocimeter was used to measure free-stream velocities from Mach 0. 1 to 1. 0 and the flow velocities along the stagnating streamline of a hemisphere-cylinder model at Mach 0. 8 and 1. 0. The flow velocity was also measured at Mach 1. 0 along the line 0. 533 model diameters below the model. These tests determined the performance characteristics of the dedicated two-component laser velocimeter at flow velocities up to Mach 1. 0 and the effects of the wind tunnel environment on the particle-generating system and on the resulting size of the generated particles. To determine these characteristics, the measured particle velocities along the stagnating streamline at the two Mach numbers were compared with the theoretically predicted gas and particle velocities calculated lusing a transonic potential flow method.},
key = {WIND TUNNELS},
keywords = {FLOW OF FLUIDS - Velocity Measurement;VELOCIMETERS - Laser Doppler;},
note = {LASER VELOCIMETRY;PARTICLE SIZING;},
} 


@inproceedings{20100712710119 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Apply automation testing in enterprises},
journal = {Applied Mechanics and Materials},
author = {Ding, Yan and Qi, Feng},
volume = {20-23},
year = {2010},
pages = {337 - 341},
issn = {16609336},
address = {Macao, China},
abstract = {In order to keep pace of product development and delivery, it is essential to implement an effective and reusable automation test framework. The traditional capture/replay framework is not only out of date but hard to use. Much more robust automation framework must be found otherwise automation test will only end up with failure forever. Success comes when clear concept of automation test is in managers' mind and full preparation is made. The paper first make it clear what is test automation and how it should be used and then list some approaches and tools popular in automation test. Then, it describes details of a framework. A model is given after it. It has been proved that this flow is reliable and greatly improves test efficiency in a company. &copy; (2010) Trans Tech Publications.},
key = {Testing},
keywords = {Automation;Computer software;Information technology;Product development;},
note = {Automation testing;Capture/replay;Software test;Test Automation;Test automation frameworks;Test efficiency;Test framework;},
} 


@inproceedings{20170403283736 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Traction inverter performance testing using mathematical and real-time controller-in-the-loop Permanent Magnet Synchronous Motor emulator},
journal = {IECON Proceedings (Industrial Electronics Conference)},
author = {Kadam, Arvind H. and Menon, Rishi and Williamson, Sheldon S.},
year = {2016},
pages = {6651 - 6656},
address = {Florence, Italy},
abstract = {In the development stage of electric vehicle drive, simulation plays a vital role. It's a powerful tool which allows the developer to investigate various control strategies and test hardware systems in harmless work environment. The software simulations platform does have constraints. In that the complex mathematical operations take longer time to solve and eventually increases the overall simulation time and cannot perform the real-time operation. This simulation further needs to be converted to the target processor's language, either assembly or C-language, which will operate in the drive system. However, if a real-time simulation environment could be comprehended, then the real processor used in the system could be incorporated in the simulation. This eventually will eliminate the chance of introducing error during code translation as well as reduce simulation time. Also, the target controller could be tested within the simulation before introducing it the actual system. This paper discuss a concept of controller-in-loop simulation, which can be used to simulate the entire system in real-time. A simple dynamic model of Permanent Magnet Synchronous Motor is simulated with MATLAB/Simulink as well as on a TMS320F28069 digital signal processor from Texas Instruments Inc. Comparative study of simulation results of both the platforms, demonstrate that although MATLAB/Simulink provides excellent GUI and functionality, it fails to performs real-time simulation which can be accomplished with controller-in-simulation. &copy; 2016 IEEE.},
URL = {http://dx.doi.org/10.1109/IECON.2016.7793156},
} 


@inproceedings{20120214674980 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Generation of scripts for performance testing based on UML models},
journal = {SEKE 2011 - Proceedings of the 23rd International Conference on Software Engineering and Knowledge Engineering},
author = {Da Silveira, Maicon B. and Rodrigues, Elder M. and Zorzo, Avelino F. and Costa, Leandro T. and Vieira, Hugo V. and De Oliveira, Flavio M.},
year = {2011},
pages = {258 - 263},
address = {Miami, FL, United states},
abstract = {Software testing process has a high cost when compared to the other stages of software development. Automation of software testing through reuse of software artifacts (e.g. models) is a good alternative for mitigating these costs and making the process much more efficient and efficacious. Model-Based Testing (MBT) is a technique to automatic generation of testing artifacts based on software models. For software development, the most spread modeling language in either the industrial or academic environments is UML. In such environments, it is desirable to reuse UML models also for MBT. avoiding re-building a different model exclusively for testing automation. These are the main reasons that make these semi-formal models an alternative to implementing MBT. Even though there are a lot of testing tools available commercially, to the best of our knowledge, none of them fully uses MBT. Therefore, this paper describes a case study showing how to implement the MBT process to automate test scripts generation and execution in a real-world, context. Furthermore, our solution is generated automatically by a Software Product Line (SPL).<br/>},
key = {Software testing},
keywords = {Computer software reusability;Formal methods;Knowledge engineering;Model checking;Software design;Unified Modeling Language;},
note = {Academic environment;Automatic Generation;Model based testing;Performance testing;Software artifacts;Software Product Line;Software product line (SPL);Testing automation;},
} 


@inproceedings{20142017722866 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {On the limits and possibilities of stress testing for assessing system safety performance in the oil and gas industry},
journal = {Safety, Reliability and Risk Analysis: Beyond the Horizon - Proceedings of the European Safety and Reliability Conference, ESREL 2013},
author = {Khorsandi, J.D. and Aven, T. and Skogdalen, J.E.},
year = {2014},
pages = {1721 - 1729},
address = {Amsterdam, Netherlands},
abstract = {Recent events in the oil and gas industry have raised concerns regarding the level of safety of petroleum activities, in particular in relation to offshore drilling operations. We examine whether stress testing, suitably implemented, can be a useful tool to further enhance the safety level of these activities. Analogously, following the 2011 earthquake in Japan the European Commission requested all nuclear power plants in Europe to undergo a stress test to verify that they comply with the highest safety standards. Such tests were also applied in the financial sector following the recent economic crisis to test the robustness of banks in the event of an extreme adverse economic scenario. Drawing on some lessons from other industries, this paper examines some of the challenges and limitations of stress testing, and discusses some of the potential benefits, and how these tests could be related to existing risk assessment and management practices in the oil and gas industry. &copy; 2014 Taylor &amp; Francis Group, London.<br/>},
key = {Accident prevention},
keywords = {Gas industry;Nuclear fuels;Nuclear power plants;Offshore drilling;Offshore oil wells;Petroleum industry;Reliability analysis;Risk analysis;Risk assessment;Safety testing;},
note = {European Commission;Financial sectors;Level of safeties;Offshore drilling operations;Oil and Gas Industry;Potential benefits;Risk assessment and managements;Safety standard;},
} 


@inproceedings{1997353722121 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test of Viterbi decoder for wideband CDMA system},
journal = {Proceedings of the Asia and South Pacific Design Automation Conference, ASP-DAC},
author = {Park, Jang-Hyun and Rho, Yea-Chul},
year = {1997},
pages = {19 - 23},
address = {Chiba, Jpn},
abstract = {This paper describes the design, the implementation, and the performance test of the Serial Viterbi decoder (SVD) using VHDL and FPGAs. The decoding scheme assumes the transmitted symbols were coded with a K = 9, 32 Kbps, and rate 1/2 convolutional encoder with generator function g<inf>0</inf> = (753)<inf>8</inf> and g<inf>1</inf> = (561)<inf>8</inf> as defined JTC TAG-7 W-CDMA PCS standard. The SVD is designed using VHDL and implemented using FPGAs. Main algorithm except memories is implemented in two Altera FLEX81500 FPGAs. And the performance test results with 3DB Gaussian noises show that the function of SVD works well.},
key = {Decoding},
keywords = {Algorithms;Broadband networks;Convolutional codes;High level languages;Spread spectrum communication;Spurious signal noise;Standards;},
note = {Field programmable gate arrays (FPGA);Serial Viterbi decoders (SVD);},
} 


@inproceedings{1993081001702 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {DB2 Version 2 Release 3 multi-user performance test results},
journal = {CMG Proceedings},
author = {Battersby, Glynis and De Rossett, Margaret},
year = {1992},
pages = {542 - 549},
address = {Reno, NV, USA},
abstract = {A series of tests designed to determine the performance and resource consumption characteristics of DB2 Version 2 Release 3 as compared with DB2 Version 2 Release 2 was executed in a multi-user environment. The purpose of this paper is to describe the results of experiences using DB2 2.3 and DB2 2.2. The workload presented in the paper is synthetic and does not represent any known workload deployed at any site. No endorsement of IBM of its products is expressed, and none should be implied. No recommendation is made regarding the purchase DB2 or any other IBM products. A network of 300 terminals was simulated using IBM's Teleprocessing Network Simulator (TPNS), and test scripts were executed at various transaction rates to measure the system performance under both peak and non-peak conditions. The basic workload was then restructured to take advantage of DB2 2.3's new package feature and additional volume testing was conducted. The reader of this paper is assumed to have a basic knowledge of DB2 principles and MVS performance terminology and concepts. The reader may wish to read the provided glossary before proceeding, or may reference it as needed.},
key = {Database systems},
keywords = {Computer software selection and evaluation;Performance;},
note = {DB2;},
} 


@inproceedings{20152500951528 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Automated model-based performance testing for PaaS cloud services},
journal = {Proceedings - IEEE 38th Annual International Computers, Software and Applications Conference Workshops, COMPSACW 2014},
author = {Zhou, Junzan and Zhou, Bo and Li, Shanping},
year = {2014},
pages = {644 - 649},
address = {Vasteras, Sweden},
abstract = {Recently, cloud computing has become popular for its unique advantages. Many applications have been migrated to cloud as web services. However, evaluating the performance of cloud services is non-trivial. Performance testing is one of the dominant techniques for evaluating system performance. In this paper, we present a model and template-based approach that automatically generates test scripts and test cases to measure service performance in an enterprise private cloud. We describe how load is generated automatically from our tool. Our empirical study shows the proposed approach can significantly decrease the cost of performance testing and help reveal potential performance issues. &copy; 2014 IEEE.},
key = {Web services},
keywords = {Application programs;Clouds;Distributed database systems;Social networking (online);Websites;},
note = {automated;Automated modeling;Empirical studies;Evaluating systems;Performance issues;Performance testing;Service performance;Template-based approaches;},
URL = {http://dx.doi.org/10.1109/COMPSACW.2014.108},
} 


@inproceedings{20144600195389 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Implementing TaaS-based stress testing by MapReduce computing model},
journal = {Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS},
author = {Hwang, Gwan-Hwan and Wu-Lee, Chi and Tung, Yuan-Hsin and Chuang, Chih-Ju and Wu, Syz-Feng},
year = {2014},
pages = {137 - 140},
issn = {23270586},
address = {Beijing, China},
abstract = {In this paper we propose to employ the MapReduce computing model to implement a Testing as a Service (TaaS) for stress testing. We focus on stress testing for heavy-weight network transactions. The computation power of MapReduce computing system is used to simulate concurrent network transactions issued by a lot of users. The user first describes the testing scenario which he wants to be simulate in a testing script. The TaaS platform analyzes the testing script and then automatically distributes required testing data including details of transactions and files into a MapReduce computing system. We propose three different schemes to distribute testing data and measure their performances. We compare them with the popular stress testing tool JMeter and find out that our scheme can always have the tested system deliver higher error rate during the stress testing.<br/> &copy; 2014 IEEE.},
key = {Software engineering},
keywords = {Electrical engineering;Engineering;Industrial engineering;},
note = {Computation power;Computing model;Computing system;Hadoop;Map-reduce;Network transactions;Stress Testing;Testing as a services;},
URL = {http://dx.doi.org/10.1109/ICSESS.2014.6933530},
} 


@inproceedings{20130615981548 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Study on performance test of storage structure base on state scene performance},
journal = {Proceedings - 2012 International Conference on Computer Science and Service System, CSSS 2012},
author = {Li, Li and Zhu, Lei-Lei and Zhai, Hongyu and Liu, Dan and Wang, Hai-Fang},
year = {2012},
pages = {570 - 573},
address = {Nanjing, China},
abstract = {This paper is an introduction to software performance automated testing and theory. It introduces the features of Open Xml storage and SQL Server storage. Then this paper sets three state scenes and chooses different test automated tools respectively. Finally, it uses tools to monitor software performance index from these two data storage systems. Results are then analyzed, comparing the quality performance of different storage systems to the same state scene. &copy; 2012 IEEE.},
key = {Computer science},
keywords = {Data storage equipment;},
note = {Automated testing;Automated tools;Data storage systems;Monitor software;Performance tests;Quality performance;Software performance;SQL servers;Storage structures;Storage systems;XML storage;},
URL = {http://dx.doi.org/10.1109/CSSS.2012.148},
} 


@inproceedings{20171903654986 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {An exploratory study of the state of practice of performance testing in Java-based open source projects},
journal = {ICPE 2017 - Proceedings of the 2017 ACM/SPEC International Conference on Performance Engineering},
author = {Leitner, Philipp and Bezemer, Cor-Paul},
year = {2017},
pages = {373 - 384},
address = {L'Aquila, Italy},
abstract = {The usage of open source (OS) software is wide-spread across many industries. While the functional quality of OS projects is considered to be similar to closed-source software, much is unknown about the quality in terms of performance. One challenge for OS developers is that, unlike for functional testing, there is a lack of accepted best practices for performance testing. To reveal the state of practice of performance testing in OS projects, we conduct an exploratory study on 111 Java-based OS projects from GitHub. We study the performance tests of these projects from five perspectives: (1) developers, (2) size, (3) test organization, (4) types of performance tests and (5) used tooling. We show that writing performance tests is not a popular task in OS projects: performance tests form only a small portion of the test suite, are rarely updated, and are usually maintained by a small group of core project developers. Further, even though many projects are aware that they need performance tests, developers appear to struggle implementing them. We argue that future performance testing frameworks should provider better support for low-friction testing, for instance via non-parameterized methods or performance test generation, as well as focus on a tight integration with standard continuous integration tooling. &copy; 2017 Copyright held by the owner/author(s).},
key = {Software testing},
keywords = {Integration testing;Java programming language;Open source software;Open systems;Software engineering;},
note = {Empirical Software Engineering;Mining software repositories;Open sources;Performance engineering;Performance testing;},
URL = {http://dx.doi.org/10.1145/3030207.3030213},
} 


@inproceedings{20181705057996 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Modelling and characterisation of a grease pump-out test stand and its use for accelerated stress testing of thermal greases},
journal = {THERMINIC 2017 - 23rd International Workshop on Thermal Investigations of ICs and Systems},
author = {Wunderle, B. and Heilmann, J. and May, D. and Arnold, J. and Hirscheider, J. and Bauer, J. and Schacht, R. and Vogel, J. and Ras, M. Abo},
volume = {2017-January},
year = {2017},
pages = {1 - 6},
address = {Amsterdam, Netherlands},
abstract = {Thermal greases allow a low stress bond at low bond line thicknesses (BLT) at medium thermal conductivities and simple application, all of which make it an alternative to solders, thermal adhesives or pads. It is widely used in power and microprocessor applications, most of which involve large areas to be used for heat transfer. However, for years thermal overload failure of power modules and chips has been a pressing problem due to pump-out of thermal grease as die or module thermal interface material (TIM): Most thermal greases are Bingham fluids and thus no solids, so they can be squeezed out from in between the gap, driven by thermo-mechanical action of the adjacent layers as e.g. DCB substrate or silicon chip with the heat sink. Today, thermal greases have to be qualified in lengthy stress tests in a product relevant environment which consumes substantial resources as often a system test is required. Therefore, a fast test is necessary which accelerates testing and thus allows a fast screening of market-available greases on one hand, and guidelines for material development on the other. For that purpose this paper addresses this topic in a combined simulative and experimental manner, where at the same time a novel test procedure is proposed for accelerated grease pump-out testing (GPOT) in the framework of a completely new approach, combining loading with in-situ failure analytical techniques and decoupling thermal from mechanical loading.<br/> &copy; IEEE / Therminic 2017.},
key = {Thermal conductivity},
keywords = {Failure (mechanical);Heat transfer;Integrated circuits;Interfaces (materials);Lubricating greases;Outages;Pumps;},
note = {Accelerated stress testing;Material development;Mechanical loading;Microprocessor applications;Thermal adhesives;Thermal interface materials;Thermal overloads;Thermo-mechanical;},
URL = {http://dx.doi.org/10.1109/THERMINIC.2017.8233806},
} 


@article{1998434363424 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Results of the performance testing of purpose-built and PC-based electrocardiographs using a simple evaluation procedure},
journal = {Journal of Medical Engineering and Technology},
author = {Kahlmeyer, H. and Haucler, C. and Lyngsmo, K.O. and Berg, S. and Schipper, K.P.},
volume = {22},
number = {2},
year = {1998},
pages = {73 - 81},
issn = {03091902},
abstract = {This paper presents the results of the evaluation testing of six 12-lead electrocardiographs, three purpose-built instruments and three of the recently introduced personal computer-based type (PC-based). As for PC-based electrocardiographs, three examples of the MRT systems, two examples of the 300 Hz CardioScope model and one prototype of the 1200 Hz CardioScope were examined but only results for one representative example of each are given here. It was of particular interest to compare the performance advantages and limitations of the PC-based electrocardiographs with that of instruments currently in use. A test procedure was developed that can be used by a medical technical department to evaluate an electrocardiograph before making a purchase decision. The procedure includes tests of frequency response, sampling rate, 50 Hz filter attenuation, gain and common mode rejection ratio (CMRR) plus tests based upon simulated electrocardiograms (ECGs). The procedure takes account of the AHA and ECRI recommendations for electrocardiograph checks and can be completed in less than two hours. The only equipment required being an ECG simulator and a signal generator. The results of this work show that purpose-built electrocardiographs meet all normal performance requirements, whereas the PC-based types, whilst having the potential to at least equal these requirements, currently exhibit software and hardware related problems.},
key = {Electrocardiography},
keywords = {Cardiovascular system;Computer aided diagnosis;Electrophysiology;Equipment testing;Personal computers;},
note = {Electrocardiographs;},
URL = {http://dx.doi.org/10.3109/03091909809010002},
} 


@inproceedings{20111013714902 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Assessment of bridge capacity through proof load testing},
journal = {Life-Cycle Civil Engineering - Proceedings of the 1st International Symposium on Life-Cycle Civil Engineering, IALCCE '08},
author = {Gomez, J.D. and Casas, J.R.},
year = {2008},
pages = {559 - 564},
abstract = {Aging is a matter of increasing concern for most bridges that are part of the road and railway systems of the European Union. Many of these bridges are very old bridges without documentation. A possible way to assess their capacity is by means of a proof load test. Two main questions should be solved when facing the execution of such a test: a) Which is the load level that the bridge should resist during the proof test to guarantee a predetermined service load with a required and appropriate safety level? and b) When the increase of loading should stop in order to not damage the structure? The answer to these questions is part of the task of the EC 6th Framework Programme European Project ARCHES (Assessment and Rehabilitation of Central European Highway Structures). In the project a methodology of proof load testing for existing bridges in new member states will be proposed. The paper shows the basis of the method as well as the application to an existing bridge located in Barcza (Poland). The bridge should be removed in the next future and therefore the proposed methodology can be fully checked. &copy; 2008 Taylor &amp; Francis Group, London.<br/>},
key = {Arch bridges},
keywords = {Life cycle;Load testing;Railroad transportation;},
note = {Bridge capacity;European project;European union;Existing bridge;Highway structures;New Member States;Railway system;Service loads;},
} 


@inproceedings{20142817910404 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing web applications on the cloud},
journal = {Proceedings - IEEE 7th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2014},
author = {Mukherjee, Joydeep and Wang, Mea and Krishnamurthy, Diwakar},
year = {2014},
pages = {363 - 369},
address = {Cleveland, OH, United states},
abstract = {Web applications are increasingly resorting to public cloud platforms such as the Amazon Web Services (AWS) Elastic Compute Cloud (EC2). However, previous studies have shown that the virtualized infrastructures used in a cloud environment can introduce performance issues. Hence, it is crucial to test the performance of the cloud to support Web applications. This is challenging because the performance effect of the cloud platform cannot be easily isolated from other extraneous factors. In this paper, we present a systematic experimental process to address this challenge. Following our proposed process, we test the performance of Web applications running on different types of AWS EC2 instances. Results suggest that Web server response times can fluctuate up to 1000% for the same workload under certain circumstances such as instance type, time-of-the-day, and day-of-the-week. &copy; 2014 IEEE.<br/>},
key = {Software testing},
keywords = {Verification;Web services;},
note = {Amazon web services;Cloud environments;Cloud platforms;Elastic compute clouds;Performance effect;Performance issues;Performance testing;WEB application;},
URL = {http://dx.doi.org/10.1109/ICSTW.2014.57},
} 


@article{20144500152713 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {An empirical comparison of model-based and capture and replay approaches for performance testing},
journal = {Empirical Software Engineering},
author = {Macedo Rodrigues, Elder and Moreira de Oliveira, Flavio and Teodoro Costa, Leandro and Bernardino, Maicon and Zorzo, Avelino Francisco and do Rocio Senger Souza, Simone and Saad, Rodrigo},
volume = {20},
number = {6},
year = {2015},
pages = {1831 - 1860},
issn = {13823256},
abstract = {A variety of testing tools has been developed to support and automate the software testing activity. Some of them may use different techniques such as Model-based Testing (MBT) or Capture and Replay (CR). Model-based Testing is a technique for automatic generation of testing artifacts based on software models. One of the main benefits of using MBT is related to the easiness of maintaining models over code; hence, it is likely that using models as a source for automatic generation of scripts requires less effort and reduces the number of faults. Otherwise, CR-based tools basically record the user interaction with the System Under Test (SUT) and then playback the recorded test. This paper presents our effort on setting up and running an experimental study performed in order to evaluate the effort to use MBT and CR-based tools to generate performance scripts. Thus, we apply an MBT and a CR approaches for the purpose of evaluation with respect to the effort to generate scripts and scenarios from the perspective of the performance testers and the performance test engineers in the context of undergraduates, M.Sc. and Ph.D. students, performance testers and performance test engineers for the generation of performance test scripts and scenarios. Our results indicate that, for simple testing tasks, the effort of using a CR-based tool was lower than using an MBT tool, but as the complexity or size of the activities of the testing tasks increases, the advantage of using MBT increased significantly.<br/> &copy; 2014, Springer Science+Business Media New York.},
key = {Software testing},
keywords = {Automatic programming;Model checking;},
note = {Empirical studies;Experimental study;Model based testing;Performance testing;Script generation;Testing automation;},
URL = {http://dx.doi.org/10.1007/s10664-014-9337-5},
} 


@inproceedings{20083811570022 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Study on CAN communication of EBS and braking performance test for commercial vehicle},
journal = {VPPC 2007 - Proceedings of the 2007 IEEE Vehicle Power and Propulsion Conference},
author = {Chu, Liang and Gu, Jiayun and Liu, Minghui and Li, Jun and Gao, Yimin and Ehsani, Mehrdad},
year = {2007},
pages = {849 - 852},
address = {Arlington, TX, United states},
abstract = {EBS (Electronic Brake System) can effectively control and adjust braking force acting on every wheel, reduce braking response time and braking distance, and make vehicle achieve much more braking stability. It is featured with CAN (Controller Area Network) communication by which the sensor signals and control command signals can be transmitted and received. In the braking performance test of EBS, conventional test methods have some inconvenience in existence. For example, the fixing of pressure sensors and wheel speed sensors is restrained by the installation position, and the precision of measuring is prone to be affected by the environment conditions. But based on CAN communication technology, the special testing instrument can be connected with CAN bus, monitoring and recording signals on the bus. Thus signals representing braking performance can be acquired through CAN bus. &copy;2007 IEEE.<br/>},
key = {Braking performance},
keywords = {Brakes;Braking;Commercial vehicles;Control system synthesis;Controllers;Instrument testing;Propulsion;Wheels;},
note = {Braking stabilities;CAN communications;Cans (controller area network);Electronic brake system;Environment conditions;Installation position;Testing instrument;Wheel speed sensors;},
URL = {http://dx.doi.org/10.1109/VPPC.2007.4544242},
} 


@article{20145000316869 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stress test for quantum dynamics approximations: Deep tunneling in the muonium exchange reaction D + HMu  DMu + H},
journal = {Journal of Physical Chemistry Letters},
author = {Perez De Tudela, Ricardo and Suleimanov, Yury V. and Richardson, Jeremy O. and Saez Rabanos, Vicente and Green, William H. and Aoiz, F.J.},
volume = {5},
number = {23},
year = {2014},
pages = {4219 - 4224},
issn = {19487185},
abstract = {Quantum effects play a crucial role in chemical reactions involving light atoms at low temperatures, especially when a light particle is exchanged between two heavier partners. Different theoretical methodologies have been developed in the last decades attempting to describe zero-point energy and tunneling effects without abandoning a classical or semiclassical framework. In this work, we have chosen the D + HMu &rarr; DMu + H reaction as a stress test system for three well-established methods: two representative versions of transition state theory (TST), canonical variational theory and semiclassical instanton, and ring polymer molecular dynamics (RPMD). These calculations will be compared with accurate quantum mechanical results. Despite its apparent simplicity, the exchange of the extremely light muonium atom (0.114 u) becomes a most challenging reaction for conventional methods. The main result of this work is that RPMD provides an overall better performance than TST-based methods for such a demanding reaction. RPMD might well turn out to be a useful tool beyond TST applicability.<br/> &copy; 2014 American Chemical Society.},
key = {Reaction kinetics},
keywords = {Molecular dynamics;Phase interfaces;Quantum electronics;},
note = {Canonical variational theories;Conventional methods;Gas-phase reactions;Isotope effect;Molecular simulations;Reaction dynamics;Transition state theories;Zero-point energies;},
URL = {http://dx.doi.org/10.1021/jz502216g},
} 


@inproceedings{20173504084277 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Lab performance testing on corrosion inhibitors under supercritical carbon dioxide conditions},
journal = {NACE - International Corrosion Conference Series},
author = {Chen, Larry and Obeyesekere, Nihal and Wylde, Jonathan},
volume = {4},
year = {2017},
pages = {2773 - 2786},
issn = {03614409},
address = {New Orleans, LA, United states},
abstract = {For the foreseeable future, fossil fuels will continue to be the dominant source of the world's primary energy production. There has been growing concern that the use of the carbon-based fuels produces greenhouse gases, principally carbon dioxide (CO<inf>2</inf>), which may adversely affect the global climate and environment. One way to mitigate the problem is to use carbon capture, transportation, and storage (CCTS) techniques and systems. As such, there is an increasing demand on corrosion inhibitors for CCTS application and also a need to understand the corrosion inhibitor performance above CO<inf>2</inf>critical point (30.98 &deg;C, 73.77 bar) as a single phase in the system which is a pre-condition for continuous operation at the so-called quasi-steady (QSSA) state. Therefore, the corrosion inhibitors for CCTS applications need to be specially formulated and evaluated under supercritical conditions of CO<inf>2</inf>. This paper discusses the design philosophy for corrosion inhibitors used for CCTS and the performance testing using rotating cylinder autoclave (RCA) and electrochemical impedance spectroscopy (EIS) methods under CO<inf>2</inf>supercritical conditions with or without water and SO<inf>2</inf>as the major impurity in the system. &copy; 2017 by NACE International.},
key = {Corrosion inhibitors},
keywords = {Carbon capture;Carbon dioxide;Corrosion;Electrochemical corrosion;Electrochemical impedance spectroscopy;Fossil fuels;Greenhouse gases;Supercritical fluid extraction;},
note = {AC-impedance;CCTS;Corrosion testing;Electrochemical;Supercritical condition;},
} 


@inproceedings{20170403289953 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research and comparative analysis of performance test on SDN controller},
journal = {2016 1st IEEE International Conference on Computer Communication and the Internet, ICCCI 2016},
author = {Fan, Yamei and Qing, Liao and Qi, He},
year = {2016},
pages = {207 - 210},
address = {Wuhan, China},
abstract = {The emergence of Software Defined Network(SDN) gives the demand of big data and network management a chance. SDN separates the control and forwarding in traditional network through OpenFlow protocol. In the software-defined network, SDN controller is an important integral part that is the core of SDN. In this paper, firstly we summarize the common SDN controller, and choose two popular, wider using open-source controllers(OpenDaylight and ONOS), analyze the implementation architecture and model framework of the two controllers. Then build the controller platform, simulate the underlying topology using IXIA test instruments, Cbench and Mininet to get the performance parameters and furthermore analyze the data. &copy; 2016 IEEE.},
key = {Information management},
keywords = {Big data;Controllers;Open source software;Testing;},
note = {Comparative analysis;Implementation architecture;Model framework;ONOS;OpenDaylight;Performance parameters;Performance tests;Test instruments;},
URL = {http://dx.doi.org/10.1109/CCI.2016.7778909},
} 


@inproceedings{1997393773570 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Static dynamometer for load testing large variable frequency motor drives},
journal = {IEEE International Electric Machines and Drives Conference Record, IEMDC},
author = {Sueker, Keith H.},
year = {1997},
pages = {WB1 9.1 - 9.3},
address = {Milwaukee, WI, USA},
abstract = {The static dynamometer, an apparent oxymoron, is a system which allows full load testing of variable frequency motor drives with no rotating equipment and only minimal demand from the power line. By inserting a reactor between the drive output and the line from which it is powered, the drive can be made to appear as a synchronous generator. This arrangement offers a practical alternative to the motor-generator sets usually employed for load testing. The required equipment consists of a set of power reactors approximating 10% of the drive rating, a contactor and a phase locked loop circuit for regulating the drive phase relative to the line. The static dynamometer is in production use on variable speed drives from 20 to 5000 hp and 480 to 4160 V. There are no intrinsic limits to either power or voltage for its application.},
key = {Electric drives},
keywords = {Dynamometers;Electric contactors;Electric loads;Electric motors;Electric reactors;Phase locked loops;},
note = {Electric load testing;Variable frequency drives (VFD);},
} 


@inproceedings{20124215566560 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Site resonance frequency assessment through dynamic load testing (DLT): Early results of a test carried out in the experimental site of fivizzano (MS, Italy)},
journal = {Proceedings of the Symposium on the Application of Geophyics to Engineering and Environmental Problems, SAGEEP},
author = {Rainone, Mario Luigi and Di Benedetto, Sara and Greco, Pasquale and Signanini, Patrizio and Torrese, Patrizio},
year = {2011},
pages = {625 - 639},
issn = {15548015},
address = {Charleston, SC, United states},
abstract = {The assessment of the local seismic response is one of the fundamental phases when it comes to defining the levels of seismic hazard at a detailed scale. These are typically known as seismic zonation studies. The estimation of the site specific resonance frequency is a parameter of relevant interest within such studies as it is associated with the maximum seismic amplification which has to be related to the frequency of resonance of buildings. The ambient noise based methods and other experimental methods for measuring this parameter are not always applicable because they are strongly influenced by contrasts of impedence and by lateral subsurface heterogeneities. Furthermore, they sometimes present limits that are not always clearly known. On the other hand, the classic analytical approach that makes use of integrated and multidisciplinary investigation methods, which estimate the local amplification parameters, mainly in terms of amplification factors and response spectrums, currently presents uncertainties and limitations. These are essentially associated with the difficulty of modelling the mechanisms of propagation of the seismic waves within a 3D system. The authors of this paper propose the experimental measurement of the site resonance frequency by means of Dynamic Load Testing (DLT). This is done by presenting the operative procedures, the data processing and the results obtained from a test undertaken at the experimental site of Fivizzano (Massa-Carrara, Italy) where a detailed study of the local seismic response was also undertaken. The test involved the delivery of sinusoidal forces with maximum amplitude of 20 kN and a range of frequencies between 0 and 15 Hz by means of an electro-mechanical generator. Simultaneous seismic monitoring was undertaken through a multichannel acquisition system. Velocimeters were placed on the ground and in a nearby strategic building. The measured frequency of resonance was compared to the predicted value obtained from empirical-analytical solutions and application of horizontal to vertical spectral ratios (HVSR) method and to the value measured by a seismic station equiped with two coupled accelerometers, one at the surface and one at depth; these sensors allowed an accurate analysis of the effects of the drift deposits overlying the bedrock, that is the transfer function of the stratigraphic column at the site.<br/>},
key = {Load testing},
keywords = {Amplification;Data handling;Dynamic loads;Dynamics;Frequency estimation;Natural frequencies;Seismic response;Stratigraphy;Uncertainty analysis;},
note = {Amplification factors;Horizontal-to-vertical spectral ratios;Investigation methods;Local seismic response;Multi-channel acquisition;Resonance frequencies;Stratigraphic columns;Subsurface heterogeneity;},
} 


@inproceedings{20152000839672 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Construction and load rating of a large capacity reaction floor-wall assembly for lateral load testing at IIT Kanpur},
journal = {NCEE 2014 - 10th U.S. National Conference on Earthquake Engineering: Frontiers of Earthquake Engineering},
author = {Rai, Durgesh C. and Jain, Sudhir K. and Murty, C.V.R. and Bansal, Dipanshu},
year = {2014},
pages = {Computers and Structures Inc. (CSI); ConocoPhillips; et al.; Federal Emergency Management Agency (FEMA); Golder Associates; State of Alaska, Division of Geological and Geophysical Surveys (DGGS) - },
address = {Anchorage, AK, United states},
abstract = {The earthquake simulation on full-scale civil engineering structures under quasi-static lateral loading environment provides an affordable and practical means to understand the nonlinear behavior of structures and their seismic energy dissipation potential. The required experimental facility consists of a large capacity strong floor and wall reaction assembly along with servo-controlled electro-hydraulic actuators for the load application. One such testing facility is nearing completion at IIT Kanpur, which has 15 m&times;10 m L-shaped and 10.5 m high reaction wall and 1.2 m thick top slab of the box girder for the strong floor. The anchor points are located in the wall and floor in a square grid of 0.6 m with each point has load capacity of 1.7 MN in tension and 1.0 MN in shear. The 2 m thick post-tensioned wall using Freyssinet 12K15 cable system in a novel configuration can resist an overturning moment of 12.7 MNm per meter of the wall. The capacity of the reaction assembly depends upon number of loads applied, combination of loads, and interaction between different components of the reaction assembly structure. A methodology based on "influence coefficients" was developed to estimate the worst load combination for describing the load rating of the reaction structure. Finite element analyses in Abaqus environment was conducted to compute the influence coefficients matrix whose elements can be added linearly to find out the maximum loading effect on the structure which can be used to determine the limiting load for a particular case of load application.},
key = {Load testing},
keywords = {ABAQUS;Box girder bridges;Earthquakes;Energy dissipation;Engineering geology;Finite element method;Floors;Hydraulic actuators;},
note = {Assembly structures;Civil engineering structures;Earthquake simulation;Electro-hydraulic actuator;Experimental facilities;Influence coefficient;Influence coefficients matrix;Seismic energy dissipation;},
URL = {http://dx.doi.org/10.4231/D3VH5CJ6K},
} 


@inproceedings{2003427677875 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Multi-function Window and Its Performance Test},
journal = {Proceedings of the International Symposium on Test and Measurement},
author = {Guo, Youxiong and Chen, Rong and Wan, Anhua and Huang, Baisheng},
volume = {6},
year = {2003},
pages = {4925 - 4928},
abstract = {This paper focuses on a new type of multi-function window (MFW). Firstly the principle and construction of the MFW is described, and then the engineering application is concerned. For the first time, a kind of double-layer-sash MFW with specialized ventilators is used in a residential building with bad sound and heat environment, In the building the MFWs are combined with a natural air conditioning, and a non-pipe central air conditioning system is formed, which allows air convection to occur in all rooms at any time and provides a comfortable, stable indoor heat environment. The performance test for MFWs is then introduced in the paper. Test results and the engineering application show that the MFW not only has the function of lighting, ventilating and enclosing, but also has satisfactory performance on heat insulation, sound insulation, dust-preventing, keeping mosquito and theft out, and improving the air quality indoors.},
key = {Ventilation},
keywords = {Air conditioning;Intelligent buildings;Sound insulation;Thermal insulation;},
note = {Multi-function windows;},
} 


@article{1991040113668 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of the OSIRIS dust monitoring sytem},
journal = {Annals of Occupational Hygiene},
author = {Roebuck, B. and Vaughan, N.P. and Chung, K.Y.K.},
volume = {34},
number = {3},
year = {1990},
pages = {263 - 279},
issn = {00034878},
abstract = {OSIRIS is a monitoring system for non-fibrous dusts based on optical scattering methods. It was developed by HSE's Safety Engineering Laboratory primarily for use in the coal-mining industry as an alternative to gravimetric sampling. Up to eight dust monitors can be controlled by a microcomputer via a two-wire telemetry link at distances of up to 8 km. The paper reports the results of comparative tests between OSIRIS and the MRE 113A gravimetric sampler in a calm air dust box, in a wind tunnel and in field trials at two collieries. Results show that OSIRIS can be calibrated against the MRE 113A for a given dust and that the calibration is maintained over the normal working range of 0-40 mg m<sup>-3</sup>. Results of tests against a variety of available test dusts show that the physical and optical properties of the dust particles have a significant effect on the response of the instrument. OSIRIS therefore needs to be calibrated against a gravimetric sampler for each dust which it will be used to monitor. Once calibrated, OSIRIS would be useful in monitoring respirable dust concentrations in a wide range of industrial or laboratory situations.},
key = {Dust},
keywords = {Coal Mines and Mining - Dust Problems;Industrial Hygiene;Miners - Health;},
note = {Dust Monitor;Non-Fibrous Dusts;Optical Scattering Instantaneous Respirable Dust Indicating System (OSIRIS);OSIRIS Dust Monitoring System;},
} 


@inproceedings{2005058812297 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {An effective performance testing approach for Java Enterprise applications},
journal = {Proceedings of the International Conference on Parallel and Distributed Processing Techniques and Applications, PDPTA'04},
author = {Alameldin, Tarek and Sinha, Amitesh},
volume = {1},
year = {2004},
pages = {90 - 96},
address = {Las Vegas, NV, United states},
abstract = {Java has proved its wide acceptance by its efficient implementation of object oriented programming concepts and its unique memory management model. This paper describes features that quickly test the ability of J2EE applications to keep up with an increasing number of users or requests and other general performance factors. This paper helps the user in avoiding costly and embarrassing failures when the enterprise application is needed most. An enterprise application is constituted by a number of interlinked components. Any of the components can work as a bottleneck, or failure point, slowing down or hampering the mission-critical business processes. Testing strategy recommended here can help the user quickly right-size their application infrastructure as new functionalities are enhanced and deployed. This paper emphasizes the key issues that affect application performance for Java enterprise development environment. This paper also describes techniques for designing correct steps and processes to address these issues successfully through the adoption of a formal testing process. This paper recommends techniques for selecting performance benchmarks that achieve the optimized output from the J2EE application. These benchmarks must be quantifiable, representing and must be reproducible, in order to get the most realistic representation of the system.},
key = {Java programming language},
keywords = {Computer hardware;Information technology;Mathematical models;Object oriented programming;Optimization;Parameter estimation;Storage allocation (computer);},
note = {Automatic memory management;Factors impacting performance and scalability;Java performance testing;Performance optimization;},
} 


@inproceedings{20102312986747 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and implementation of performance testing model for web services},
journal = {CAR 2010 - 2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics},
author = {Guo, Xiao-Yang and Qiu, Xue-Song and Chen, Ying-Hui and Tang, Fan},
volume = {1},
year = {2010},
pages = {353 - 356},
address = {Wuhan, China},
abstract = {The performance testing model for Web Services is proposed. Aiming to enhance testing efficiency and automation, the model provides a multi-machine joint testing model and strategy model. The former is used to share the heavy load to multiple units, which could also be called load balance model, and the latter is used to simulate a realistic Web Services running environment. The model has been applied to an original web services testing software, and proved to be a feasible way for performance testing for web services. &copy;2010 IEEE.<br/>},
key = {Web services},
keywords = {Automation;Load testing;Robotics;Software testing;Websites;},
note = {Design and implementations;Load balance;Multi-machines;Performance testing;Strategy modeling;Testing efficiency;Testing modeling;Testing software;},
URL = {http://dx.doi.org/10.1109/CAR.2010.5456825},
} 


@article{2002146904877 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {User query interface for the deep-foundations load-test database},
journal = {Transportation Research Record},
author = {Satyanarayana, Raghavendra and Ealy, Carl D. and Dimillio, Albert F. and Kalavar, Shesh R.},
number = {1755},
year = {2001},
pages = {3 - 14},
issn = {03611981},
abstract = {The deep-foundation load-test database is a result of research quality data collection over the past 15 years. The database consists of soils data along with the deep-foundations load-test data gathered from prototype tests conducted all over the world. The soils data include general site information, stratigraphy, laboratory, and in situ test details. The foundations data consist of general foundations information including foundation construction, and load-settlement information to failure. Over 1,000 foundations are currently in the database, and more are being added. The database is checked for its validity and correctness both before and after the data are added to the database to make sure that the data integrity is preserved. Also, the data are periodically backed up and the data input is strictly administered by providing controlled access to the designated individuals. The database is structured to follow the rules of relational database management system (RDBMS). The database resides in a Unix-based Sun Solaris server, and the database engine is Sybase RDBMS. The database front-end query application is under development for the Internet using Java as the programming language and will run under any Internet-capable browser (e.g., Netscape, Microsoft Internet Explorer) environment. The application will use Java applets to communicate with the database server. The user community includes state highway engineers, geotechnical researchers, students, and practicing engineers. Interested users can access the database using the interface to view, download, and chart the data at run-time.},
key = {Load testing},
keywords = {Data acquisition;Failure (mechanical);Java programming language;Pile foundations;Query languages;Relational database systems;Road construction;Settlement of structures;Soil mechanics;Soil testing;Stratigraphy;User interfaces;},
note = {Deep foundations load test database;Relational database management systems;Sun Solaris server;User query interface;},
} 


@inproceedings{20100312647310 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Bridging the gap between manufacturing reality and design assumptions: Chaining manufacturing analyses and defects with performance testing},
journal = {Proceedings from the 12th International Conference on Modeling of Casting, Welding, and Advanced Solidification Processes},
author = {Sholapurwalla, Adi and Scott, Sam},
year = {2009},
pages = {101 - 109},
address = {Vancouver, BC, Canada},
abstract = {In today's competitive environment it has become commonplace for foundries to incorporate capabilities such as component design, part assembly and other non-traditional foundry operations. To predict the behavior of a casting component under service conditions, value-added functionality has also been integrated into engineering software by linking solutions together and adding multi-physics analyses into the design cycle. The structural simulation of safety components made of die cast alloys is frequently based on the assumption of a homogenous distribution of mechanical properties. In reality defects caused by the production process like porosity is one of the most degrading factors leading to non-homogenous mechanical properties. In order to predict the behavior of the part under service conditions, it is necessary to take into account the influence of the porosity distribution resulting from the casting process into the structural simulation. This production part is then used in a performance analysis, such as crash or impact, to observe how the as-cast part will perform in its actual usage. This paper describes a methodology to model the complete High Pressure Die Casting (HPDC) process, determine macro and micro porosity results and then map these porosity results onto a geometry which can be used for a crash/impact analysis. The porosity map leads to a more correct description of the mechanical strength of the component, which then leads to more accurate virtual component testing. These results will be compared to the experimentally measured porosity distribution in the actual part, as well as actual loading cases to observe the deflection and failure of the component. This type of advanced technology and predictive engineering is the next giant step in the software industry.<br/>},
key = {Porosity},
keywords = {Casting;Defects;Die casting;Foundries;Manufacture;Mechanical properties;Software engineering;Solidification;Welding;},
note = {Chaining casting and impact;Competitive environment;High pressure die casting;Impact;Porosity distributions;Predictive engineering;Strength;Structural simulations;},
} 


@inproceedings{20120814786830 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Lateral load testing of the Advanced Stirling Convertor (ASC-E2) heater head},
journal = {8th Annual International Energy Conversion Engineering Conference},
author = {Cornell, Peggy A. and Krause, David L. and Davis, Glen and Robbie, Malcolm G. and Gubics, David A.},
year = {2010},
address = {Nashville, TN, United states},
abstract = {Free-piston Stirling convertors are fundamental to the development of NASA's next generation of radioisotope power system, the Advanced Stirling Radioisotope Generator (ASRG). The ASRG will use General Purpose Heat Source (GPHS) modules as the energy source and Advanced Stirling Convertors (ASCs) to convert heat into electrical energy, and is being developed by Lockheed Martin under contract to the Department of Energy. Achieving flight status mandates that the ASCs satisfy design as well as flight requirements to ensure reliable operation during launch. To meet these launch requirements, GRC performed a series of quasi-static mechanical tests simulating the pressure, thermal, and external loading conditions that will be experienced by an ASC-E2 heater head assembly. These mechanical tests were collectively referred to as "lateral load tests" since a primary external load lateral to the heater head longitudinal axis was applied in combination with the other loading conditions. The heater head was subjected to the operational pressure, axial mounting force, thermal conditions, and axial and lateral launch vehicle acceleration loadings. To permit reliable prediction of the heater head's structural performance, GRC completed Finite Element Analysis (FEA) computer modeling for the stress, strain, and deformation that will result during launch. The heater head lateral load test directly supported evaluation of the analysis and validation of the design to meet launch requirements. This paper provides an overview of each element within the test and presents assessment of the modeling as well as experimental results of this task.<br/>},
key = {Loads (forces)},
keywords = {Energy conversion;Finite element method;Load testing;NASA;Nuclear batteries;Radioisotopes;Stirling cycle;},
note = {Advanced stirling convertors;Department of Energy;General-purpose heat sources;Radioisotope Power System;Stirling convertors;Stirling Radioisotope Generator;Structural performance;Vehicle acceleration;},
} 


@inproceedings{20143118006642 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Automated Generation of Performance Test Cases from Functional Tests for Web Applications},
journal = {Communications in Computer and Information Science},
author = {Toledo Rodriguez, Federico and Reina, Matias and Baptista, Fabian and Polo Usaola, Macario and Perez Lamancha, Beatriz},
volume = {417 CCIS},
year = {2013},
pages = {164 - 173},
issn = {18650929},
address = {Angers, France},
abstract = {When modernizing systems there are big risks concerning functional and non-functional properties. It is expected that the functionality, the performance and the dependability are the same (or better) in the new version. Therefore, the preventive workload simulation (to verify non-functional properties) is crucial to guarantee the success of the modernization project. Since tools for load simulation work at protocol level, the automation of tasks for workload simulation demand much more effort than functional testing, whose test cases are designed using record and playback techniques on the GUI: these tools are more intuitive and they have to handle less variables and technical issues. In this article we present a tool to automatically generate workload simulation scripts from automated functional tests. The tool has been used in several projects in the industry, achieving important cost savings and improving flexibility when verifying non-functional properties of a migrated system. &copy; Springer-Verlag Berlin Heidelberg 2013.<br/>},
key = {Software testing},
keywords = {Automation;Load testing;},
note = {Automated generation;Functional testing;Modernization projects;Non functional properties;Non-functional;Performance tests;Record and playback;Testing automation;},
URL = {http://dx.doi.org/10.1007/978-3-642-54092-9_12},
} 


@inproceedings{20151200665216 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Impact of proof load test programs on the reliability of foundations},
journal = {Geotechnical Special Publication},
author = {Abdallah, Youmna and Najjar, Shadi and Saad, George},
volume = {GSP 256},
year = {2015},
pages = {1850 - 1860},
issn = {08950563},
address = {San Antonio, TX, United states},
abstract = {Traditionally, proof-load tests have been utilized to validate design methods and construction procedures. There is currently an inconsistency in the recommendations that are available in pile design codes and practices regarding the required number of proof-load tests and the level of the proof loads. Recently, and in the framework of reliability-based design, researchers have shown that information from pile load tests may have a considerable impact on reducing the probability of failure of piles at a site, thus allowing for the use of lower factors of safety for the piles. This paper presents the results of a thorough investigation that is conducted to study the effect of choosing different proof-load test programs on the reliability of piles. This is achieved by utilizing a Bayesian approach to update the capacity distributions of piles at a site given the results of the proof-load test program. In the updating exercise, an effort is made to update both the mean and the lower-bound capacity to maximize the benefit of the collected proof load data. The significance of the results presented lies in the fact that these results constitute necessary input to any practical decision framework for choosing the number and the magnitude of the proof load test that would maximize the value of information of the test program. &copy; ASCE 2015.},
key = {Piles},
keywords = {Bayesian networks;Design;Reliability;Software testing;Statistical tests;Test facilities;},
note = {Bayesian approaches;Capacity distribution;Construction procedures;Decision framework;Factors of safeties;Probability of failure;Reliability based design;Value of information;},
URL = {http://dx.doi.org/10.1061/9780784479087.169},
} 


@inproceedings{20130115850854 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Grid interconnection and performance testing procedures for vehicle-to-grid (V2G) power electronics},
journal = {World Renewable Energy Forum, WREF 2012, Including World Renewable Energy Congress XII and Colorado Renewable Energy Society (CRES) Annual Conferen},
author = {Kramer, William and Chakraborty, Sudipta and Kroposki, Benjamin and Hoke, Andy and Martin, Greg and Markel, Tony},
volume = {3},
year = {2012},
pages = {2280 - 2287},
address = {Denver, CO, United states},
abstract = {Bidirectional power electronics can add vehicle-to-grid (V2G) capability in a plug-in vehicle, which then allows the vehicle to operate as a distributed resource (DR). The uniqueness of the battery-based V2G power electronics requires a test procedure that will not only maintain IEEE interconnection standards, but can also evaluate the electrical performance of the vehicle working as a DR. The objective of this paper is to discuss a recently published NREL technical report that provides interim test procedures for V2G vehicles for their integration into the electrical distribution systems and for their performance in terms of continuous output power, efficiency, and losses. Additionally, some other test procedures are discussed that are applicable to a V2G vehicle that desires to provide power reserve functions. A few sample test results are provided based on testing of prototype V2G vehicles at NREL.},
key = {Vehicle performance},
keywords = {Power electronics;Testing;},
note = {Distributed resources;Electrical distribution system;Electrical performance;Grid interconnections;Interconnection standards;Output power;Performance testing;Plug-ins;Power reserves;Test procedures;Vehicle to grids;},
} 


@article{20152300919393 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Reliability-based design of proof load test programs for foundations},
journal = {Geotechnical Engineering},
author = {Abdallah, Y. and Najjar, S.S. and Saad, G.},
volume = {46},
number = {2},
year = {2015},
pages = {94 - 101},
issn = {00465828},
abstract = {There is currently an inconsistency in the recommendations that are available in pile design codes and practices regarding the required number of proof-load tests and the level of the proof loads. This paper presents the results of a comprehensive investigation that is conducted to study the effect of choosing different proof-load test programs on the reliability of piles. This is achieved by utilizing a Bayesian approach to update the capacity distribution of piles at a site given the results of the proof-load test program. In the updating exercise, an effort is made to update both the mean and the lower-bound capacity to maximize the benefit of the collected proof load data. The significance of the results presented lies in the fact that these results constitute necessary input to any practical decision framework for choosing the number and the magnitude of the proof load test that would maximize the value of information of the test program.},
key = {Statistical tests},
keywords = {Bayesian networks;Piles;Reliability;Software testing;Test facilities;Testing;},
note = {Bayesian approaches;Bayesian updating;Capacity distribution;Decision framework;Lower bounds;Reliability based design;Test program;Value of information;},
} 


@inproceedings{20122615166184 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Space constructible radiator (SCR) life test heat pipe performance testing and evaluation},
journal = {SAE Technical Papers},
author = {Mai, T.D. and Sifuentes, R.T. and Chen, A.L. and Cornwell, J.D.},
year = {1994},
issn = {01487191},
address = {Friedrichshafen, Germany},
abstract = {The Space Constructible Radiator (SCR) Life Test heat pipe performance testing is currently conducted at NASA/Johnson Space Center as part of the Advanced Technology Development Program. The SCR is a dual passage, monogroove heat pipe radiator designed and manufactured by Grumman Aerospace for NASA. The heat pipe has many aerospace applications since it can transport a large amount of heat with a compact lightweight design. As the micro-meteoroid/orbital debris environment worsens, it may be advantageous to add the heat pipe radiator to the Space Station's thermal control system. The SCR Life Test has been operating over the last 10 years and will continue until the year 2000. The overall heat transfer coefficient has decreased from 792 W/K (1500 Btu/Hr-&deg;F) to 475 W/K (900 Btu/Hr-&deg;F) but appears to have stabilized. This paper summarizes the SCR Life Test setup and the test results to date. &copy; Copyright 1994 Society of Automotive Engineers, Inc.<br/>},
key = {Heat pipes},
keywords = {Aerospace applications;Control systems;Environmental management;Heat transfer;NASA;Radiators;Slip forming;Software testing;Space debris;Space platforms;Space stations;Testing;},
note = {Advanced technology development;Large amounts;Life-tests;Lightweight design;Overall heat transfer coefficient;Pipe performance;Space centers;Thermal control systems;},
URL = {http://dx.doi.org/10.4271/941437},
} 


@article{20155101703361 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test of wireless technologies for personnel and equipment proximity sensing in work zones},
journal = {Journal of Construction Engineering and Management},
author = {Park, Jeewoong and Marks, Eric and Cho, Yong K. and Suryanto, Willy},
volume = {142},
number = {1},
year = {2016},
issn = {07339364},
abstract = {The dynamic nature and limited work space of roadway work zones contribute to dangerous working environments for construction workers. This environment can result in hazardous proximity situations because pedestrian workers are required to operate in close proximity to heavy construction equipment. A total of 609 work zone personnel fatalities were reported in 2012. Previous analysis of work zone fatality data found that the majority of the pedestrian worker and mobile object struck-by fatalities resulted when pedestrian workers were struck by construction equipment. These statistics indicate that current safety practices for pedestrian workers and equipment operators are inadequate. The objective of this study was to create and evaluate a proximity detection and alert system using Bluetooth sensing technology. The scope included hazardous proximity situations between pedestrian workers and construction equipment in roadway work zones at grade. Evaluation metrics were implemented to assess the tested proximity sensing systems including the cost, time and ease of calibration, required hardware, system capabilities, and many others. Commercially available radio frequency identification (RFID) and magnetic field proximity sensing systems were also evaluated to provide a basis for comparison. Various interaction scenarios between pedestrian workers and construction equipment were used in the evaluation of the system. The performance evaluation based on the statistical results showed that all the tested systems were considered reliable with minimal false alarm rates. However, the magnetic system showed a significant drop in its coverage range, while still providing reliable coverage measures, with a set of tests that were more dynamic than other sets of tests. The created Bluetooth system provided the highest level of simplicity with its minimized infrastructure, ease of calibration, and ease of installation. In sum, experimental results demonstrate that the created proximity detection and alert system (1) requires minimal infrastructure; (2) provides adequate alerts to equipment operators and pedestrian workers; and (3) provides, through an alert, an additional layer of hazard avoidance in real time during hazardous-proximity situations in roadway work zones. &copy; 2015 American Society of Civil Engineers.},
key = {Construction equipment},
keywords = {Alarm systems;Bluetooth;Calibration;Equipment;Hazards;Highway accidents;Information technology;Machinery;Pedestrian safety;Radio frequency identification (RFID);Wireless telecommunication systems;},
note = {Bluetooth technology;Construction safety;Construction workers;Hazardous proximity situations;Highway work zones;System capabilities;Wireless technologies;Working environment;},
URL = {http://dx.doi.org/10.1061/(ASCE)CO.1943-7862.0001031},
} 


@inproceedings{20113114198049 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Advanced stirling convertor (ASC-E2) performance testing at NASA Glenn Research Center},
journal = {Nuclear and Emerging Technologies for Space 2011, NETS-2011},
author = {Oriti, Sal and Wilson, Scott},
year = {2011},
pages = {562 - 575},
abstract = {The National Aeronautics and Space Administration (NASA) Glenn Research Center (GRC) has been supporting development of the Advanced Stirling Radioisotope Generator (ASRG) since 2006. A key element of the ASRG Project is providing life, reliability, and performance testing of the Advanced Stirling Convertor (ASC). For this purpose, four pairs of ASCs capable of operating to 850&deg;C and designated with the model number ASC-E2, were delivered by Sunpower of Athens, OH, to GRC in 2010. The ASC-E2s underwent a series of tests that included workmanship vibration testing, performance mapping, and extended operation. Workmanship vibration testing was performed following fabrication of each convertor to verify proper hardware build. Performance mapping consisted of operating each convertor at various conditions representing the range expected during a mission. Included were conditions representing beginning-of-mission (BOM), end-of-mission (EOM), and fueling. This same series of tests was performed by Sunpower prior to ASC-E2 delivery. The data generated during the GRC test were compared to performance before delivery. Extended operation consisted of a 500-hour period of operation with conditions maintained at the BOM point. This was performed to demonstrate steady convertor performance following performance mapping. Following this initial 500-hour period, the ASC-E2s will continue extended operation, controller development and special durability testing, during which the goal is to accumulate tens of thousands of hours of operation. Data collected during extended operation will support reliability analysis. Performance data from these tests is summarized in this paper.<br/>},
key = {Durability},
keywords = {Mapping;NASA;Nuclear batteries;Radioisotopes;Reliability analysis;Stirling cycle;Vibration analysis;},
note = {Advanced stirling convertors;Controller development;Durability testing;Extended operations;Glenn Research Center;Performance testing;Radioisotope Power System;Stirling Radioisotope Generator;},
} 


@inproceedings{20114814565045 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of RFID systems with RF-harsh materials},
journal = {2011 IEEE International Conference on RFID-Technologies and Applications, RFID-TA 2011},
author = {Mercer, Allison J. and James, Ryan K. and Bennett, Gisele and Patel, Priyank and Johnston, Chase and Cai, James},
year = {2011},
pages = {537 - 543},
address = {Sitges, Spain},
abstract = {Radio Frequency Identification (RFID) has been adopted to track items in supply chain, healthcare, and manufacturing applications. Hospitals and factories, however, are difficult environments for radiowave propagation. Cinder block walls with steel rebar, metal obstructions, and RF noise present significant obstacles to RFID system performance. Tagging lossy materials in these environments, such as metals and liquids, can also degrade the performance of RFID systems. In a previous paper [1] we simulated the RF-harsh conditions prevalent in these environments to evaluate UHF RFID system performance. In this paper, we utilize the same laboratory environment to measure RFID system performance when RF-harsh materials are tagged. These tests serve to examine the effect of water and plastic car parts on RFID system performance in an RF harsh environment. We show that the problems posed when tagging RF-harsh materials can be mitigated with either the strategic placement of tags on the item, or the careful choice of tags. While UHF RFID systems can be used in the presence of RF-harsh circumstances, the system architecture must be carefully tested in order to minimize the effects of performance-hindering RF obstacles. &copy; 2011 IEEE.<br/>},
key = {Radio frequency identification (RFID)},
keywords = {Liquids;Manufacture;Materials testing;Millimeter waves;Radio;Radio transmission;Strategic materials;Supply chains;},
note = {Automotive materials;Laboratory environment;Manufacturing applications;Multipath;Performance evaluations;Performance testing;System architectures;Ultra-high frequency;},
URL = {http://dx.doi.org/10.1109/RFID-TA.2011.6068597},
} 


@inproceedings{20104013270963 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Fiber-optic gyrocompass performance test and combined dead reckoning (DR) navigation scheme design},
journal = {ICSPS 2010 - Proceedings of the 2010 2nd International Conference on Signal Processing Systems},
author = {Chen, Mu-Qing and Xu, Jiang-Ning and Rui, Liu and Ping, Li},
volume = {3},
year = {2010},
pages = {V3594 - V3596},
abstract = {Different test schemes are designed in the paper, which fully aware of the characteristics and important indicators of fiber-optic gyro compass OCTANS. After analysis the towed system working environment, this paper propose the towed system to use part of OCTANS heave compensation outputs for combined DR navigation system<sup>[1]</sup>. &copy; 2010 IEEE.<br/>},
key = {Signal processing},
keywords = {Fiber optics;Gyroscopes;Navigation systems;},
note = {Combined navigation;Dead reckoning;Fiber optic gyro;Heave compensations;Performance tests;Scheme design;Towd system;Working environment;},
URL = {http://dx.doi.org/10.1109/ICSPS.2010.5555842},
} 


@inproceedings{20161702286069 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Low temperature ablatives thermal performance testing},
journal = {37th Aerospace Sciences Meeting and Exhibit},
author = {Wong, J.L. and Jovanovic, V. and Tang, I. and Johnson, G. and Koo, Joseph H.},
year = {1999},
address = {Reno, NV, United states},
abstract = {A number of existing and developmental advanced heatshield materials were screen-tested at Boeing's Space System Laboratory (SSL) Graphite Heater Test Facility to evaluate their thermal performance. The simulated thermal environment was 60 BTU/ft<sup>2</sup>-sec for 90 seconds at ambient pressure followed by 160 seconds of thermal soaking. Based on the primary constituents, these low temperature ablative (LTA) materials were grouped into cork-based and silicone foam materials. The cork-based materials with epoxy or phenolic resin smoked and combusted during the high heat environment and swelled significantly as they charred. The combustion of cork and resin to form weakened char was the single most important degradation path of such heatshield materials. The finely cracked top surface is a characteristic of all cork based materials and was observed on most posttest samples. One of our new cork phenolic materials produced rigid char and ablated smooth. Replacing the epoxy and phenolic resins with silicone also minimized the combustion issues. Additionally, the silicone foam material produced smooth rigid char and the ablation rate was approximately equal to the swelling rate, resulting in minimal shape change. The main disadvantages of silicone-based thermal protection system (TPS) materials are the relatively high cost and more involved installation process. &copy; 1997 The American Institute of Aeronautics and Astronautics Inc. All rights reserved.},
key = {Swelling},
keywords = {Ablative materials;Aerospace engineering;Combustion;Low temperature testing;Phenolic resins;Resins;Silicones;Temperature;},
note = {Ablation rates;Ambient pressures;Low temperatures;Swelling rates;Thermal environment;Thermal Performance;Thermal performance testing;Thermal Protection System;},
} 


@inproceedings{20171003426184 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {How to emulate web traffic using standard load testing tools},
journal = {imPACt 2016 - Internet, Mobile, Performance and Capacity, Cloud and Technology},
author = {Brady, James F. and Gunther, Neil J.},
year = {2016},
pages = {ASG Technologies; et al.; IntelliMagic; Metron; TeamQuest; Winthrop - },
address = {La Jolla, CA, United states},
abstract = {Conventional load-testing tools are based on a fifty-year old time-share computer paradigm where a finite number of users submit requests and respond in a synchronized fashion. Con- versely, modern web traffic is essentially asynchronous and driven by an unknown number of users. This difference presents a conundrum for testing the performance of modern web applications. Even when the difference is recognized, performance engineers often introduce modifications to their test scripts based on folklore or hearsay published in various Internet fora, much of which can lead to wrong results. We present a coherent methodology, based on two fundamental principles, for emulating web traffic using a standard load-test environment.},
key = {Load testing},
note = {Finite number;Fundamental principles;Standard loads;Test Environment;Test scripts;Testing tools;WEB application;Web traffic;},
} 


@inproceedings{20140517258577 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design of a new air winch performance test platform and analysis on its bracket},
journal = {ICPTT 2013: Trenchless Technology - The Best Choice for Underground Pipeline Construction and Renewal, Proceedings of the International Conference on Pipelines and Trenchless Technology},
author = {Chen, Yingchun and Zhang, Shimin and Chuan, Jungang and Wang, Wenming and Zhang, Hang and Li, Hengtao},
year = {2013},
pages = {545 - 553},
address = {Xi'an, China},
abstract = {Due to the complex working environment and relatively backward manufacturing technology, an important industrial tool, the air winch, faces lots of problems such as wire rope breaking and brake instability. This paper presents a new mechanical loading tower type air winch performance test platform designed to test air winch after it is manufactured. In order to ensure security during the test, this paper proceeded with numerical analysis for the bracket. Results of the analysis showed: the maximum stress of the bracket when loadedwas10tat 156MPa which was far below its yield stress, and its maximum displacement was0.527mm,which would not produce large deformation. The natural frequencies of the bracket's free mode are smooth sequential which do not exist in local breakpoint, and the interval of each frequency is large, thus it can avoid the close mode. Because the first mode frequency is 37.255Hz, so the bracket can avoid resonance caused by the vibration of the system due to the instability of the gas source during the test. This paper also analyzed the stress of the bracket during the test to help the operator predict the danger point and prevent the occurrence of overload. In addition to introducing a new mechanical loading tower type air winch performance test platform, the authors also present a detailed analysis of the bracket. The new test platform can effectively compensate for the lack of air winch performance testing in domestic manufacturing. &copy; ASCE 2013.<br/>},
key = {Trenching},
keywords = {Manufacture;Pipelines;Stress analysis;Winches;Yield stress;},
note = {Bracket;Domestic manufacturing;Manufacturing technologies;Maximum displacement;Mode analysis;Performance testing;Performance tests;Working environment;},
URL = {http://dx.doi.org/10.1061/9780784413142.056},
} 


@inproceedings{20161202114783 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Object driven performance testing of Web applications},
journal = {Proceedings - 1st Asia-Pacific Conference on Quality Software, APAQS 2000},
author = {Subraya, B.M. and Subrahmanya, S.V.},
year = {2000},
pages = {17 - 26},
address = {Hong Kong, China},
abstract = {Performance of many Web sites depends on the load on the site at peak time under varying conditions. Performance testing is normally conducted in reasonably simulated environment with the help of performance testing tools. However, performance of a Web site depends on various parameters and each parameter must be tested under varying stress levels. It is not possible to draw a common denominator for performance parameters to test the Web site due to complexity of Web sites. Different parts of the Web site must be tested with different parameters under varying condition and stress level. In such circumstances, it is necessary to decompose the Web site into many components, which represents the behavior of various business components. These business components are mapped to various objects that truly represent the behavior and structure of the part of the web site. These objects are subjected to performance testing with different parameters and stress levels. This paper addresses the new testing process, which uses the concept of decomposing the behavior of the Web site into testable components, which are mapped onto testable objects. These testable objects are subjected to performance testing under varied performance parameters and stress levels. &copy; 2000 IEEE.},
key = {Websites},
note = {Business component;Common denominators;Performance parameters;Performance testing;Simulated environment;Testing process;Varying stress;WEB application;},
URL = {http://dx.doi.org/10.1109/APAQ.2000.883774},
} 


@inproceedings{20113914381487 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research of virtual reality in industrial design manufacture and performance testing},
journal = {Proceedings of the 2nd International Conference on Intelligent Control and Information Processing, ICICIP 2011},
author = {Wu, Xu and Chunfeng, Lv},
number = {PART 1},
year = {2011},
pages = {403 - 405},
abstract = {Virtual reality (VR) is a new method of visual operating and interacting of complex data can be realized by computers, in which one would have an immersed sense to observe and operate objects in three dimensions timely and unboundedly. VR is a new developing technique and a complex simulation tool for industry, it builds a simulated environment in which researchers can do many things such as driving, operating, designing and performance test in a unaffected way. Performance test plays an important role in vehicle design. Most of interactive processing in virtual vehicle manufacturing is perfect, but many deep interactive functions are under emphasis such as performance test after manufacturing, variation and recording of performance parameters. Research of VRML combining with JavaScript is presented in this paper, and vehicle designing and manufacturing, testing system are built based on it, in which we can real-time and dynamic control the car through keyboard and mouse, and get the real-time performance parameters. &copy; 2011 IEEE.<br/>},
key = {Vehicle performance},
keywords = {Automobile manufacture;Industrial research;Product design;Virtual reality;},
note = {Complex simulation;Dynamic controls;Interactive functions;Performance parameters;Performance testing;Performance tests;Real time performance;Simulated environment;},
URL = {http://dx.doi.org/10.1109/ICICIP.2011.6008274},
} 


@inproceedings{20133616691209 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {When load testing large user population web applications the devil is in the (virtual) user details},
journal = {CMG 2012 International Conference},
author = {Brady, James F.},
year = {2012},
pages = {BMC Software - },
address = {Las Vegas, NV, United states},
abstract = {Many times load testing is dismissed as a waste of time and money because past results didn't conform to real world experience when the application went live. Sometimes it's because the test suite is too narrow but often it is due to the approach used to produce traffic and the way results are interpreted. This discussion focuses on the latter situation because a lack of testing scope is an obvious limitation but poor quality traffic and improper analysis techniques are subtle shortcomings that impact test credibility in ways that aren't always clear until the live application reveals them.},
note = {Analysis techniques;Large users;Real-world experience;WEB application;},
} 


@inproceedings{20133516663581 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Marine alternative fuel performance testing},
journal = {Proceedings of the Spring Technical Conference of the ASME Internal Combustion Engine Division},
author = {Ghosh, Sujit and Risley, Tom and Sobolewski, David and Welch, William and Williams, Sherry},
year = {2012},
pages = {203 - 213},
issn = {15296598},
address = {Torino, Piemonte, Italy},
abstract = {As part of the U.S. Maritime Administration (MARAD) marine application of alternative fuel initiative, the U.S. Navy provided neat hydrotreated renewable diesel (HRD), derived from the hydroprocessing of algal oils, for operational and exhaust emission testing onboard the T/S STATE OF MICHIGAN. This vessel has diesel-electric propulsion with four caterpillar D-398 compression ignition engines; one of these ship service diesel engines was selected as the test engine. The diesel generator sets power both the propulsion motors propelling the ship and provide the electrical power for the hotel loads of the ship. Ultra-low sulfur diesel (ULSD) was blended with the neat HRD fuel in a 50/50-by-volume blend and tested for over 440 hours on the vessel. Exhaust emissions testing was performed while underway on Lake Michigan using the baseline ULSD assessed earlier. A similar profile was run using the blended test fuel. Emission testing was conducted using the ISO 8178 (D2) test cycle. When emissions testing was completed a series of underway and pierside test runs were conducted to accumulate the remaining engine hours, After all testing, the engine conditions were assessed again using a combination of visual inspection and oil analysis. The remainder of the test fuel will be used to conduct a long-term stability test. The setup, test, and results of this testing, currently underway, are reported here with a discussion of MARAD's alternative fuels test initiative. Copyright &copy; 2012 by ASME.},
key = {Ship propulsion},
keywords = {Alternative fuels;Diesel engines;Engines;Marine engines;Ships;},
note = {Compression ignition engine;Diesel generator sets;Diesel-electric propulsion;Engine conditions;Long-term stability test;Maritime administrations;Propulsion motors;Ultra-low sulfur diesel;},
URL = {http://dx.doi.org/10.1115/ICES2012-81239},
} 


@article{20142817930030 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research on GUI-based automation test technology driven by separated definition data},
journal = {International Journal of Control and Automation},
author = {Liu, Zhenyu and Chen, Qiang and Cai, Lizhi},
volume = {7},
number = {6},
year = {2014},
pages = {421 - 432},
issn = {20054297},
abstract = {GUI-based software is often developed a complicated test script with existing traditional automation software testing tools. The software automated test development technology consequently carried out some study of existing automated testing with current automated testing tools to simplify the script. The paper proposed a novel test automation technology with separated definition data, which replaced by script development or modification. The definition data are depicted for script driven, page description and test data separately. The test automation technology provided completed function and interface between this method and actual test tool. The test engineers is not need to write the any test script, but modify the definition files for test developing to some extent. The automation functional test technology has support the typical test tool and proved effective in the specific cases. &copy; 2014 SERSC.},
key = {Software testing},
keywords = {Automation;Graphical user interfaces;Testing;},
note = {Automated test;Automated testing;Automated testing tools;Automation software;Automation tests;Definition data;Functional test;Test Automation;},
URL = {http://dx.doi.org/10.14257/ijca.2014.7.6.39},
} 


@inproceedings{20121214869057 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and implementation of cloud-based performance testing system for web services},
journal = {Proceedings of the 2011 6th International ICST Conference on Communications and Networking in China, CHINACOM 2011},
author = {Zhang, Li and Chen, Yinghui and Tang, Fan and Ao, Xiong},
year = {2011},
pages = {875 - 880},
address = {Harbin, China},
abstract = {Nowadays testing plays an important role in software development process. While software testing is expensive and time-consuming, sufficient testing is hard, especially for a distributed system using web services technique in the real circumstance. The development of cloud computing provides us new ideas to solve these testing problems. To address these issues, we propose a framework which integrates cloud computing and performance testing technologies. In this paper, first we present the architecture of the cloud-based performance testing system for web services (CPTS), which is a portable, extensible and easy-to-use framework for generating and submitting test workloads to computing clouds. Then, we show the process how to use CPTS to run a performance test and present the concept of dynamic migration in CPTS. Finally, we present our experiences with CPTS in Amazon EC2. We found that the CPTS allows a user to easily set up and test a web services system on the cloud and improve test effectively. &copy; 2011 IEEE.<br/>},
key = {Web services},
keywords = {Cloud computing;Software design;Software testing;Testing;Virtual machine;Websites;},
note = {Cloud-based;Computing clouds;Design and implementations;Distributed systems;Dynamic migration;Performance testing;Performance tests;Software development process;},
URL = {http://dx.doi.org/10.1109/ChinaCom.2011.6158278},
} 


@inproceedings{20174304292977 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Comparative study of N-tier and cloud-based web application using automated load testing tool},
journal = {Advances in Intelligent Systems and Computing},
author = {Jailia, Manisha and Agarwal, Manisha and Kumar, Ashok},
volume = {625},
year = {2018},
pages = {239 - 250},
issn = {21945357},
address = {Bangkok, Thailand},
abstract = {These days people cannot think a single day without online world. In online world, Web applications play very important role in all sectors, let it be for searching, shopping, and education too. Too many Web sites are launched daily. But what matters a lot for a user is all about performance. In this paper, we have discussed the comparison between N-tier-based Web application and cloud-based Web application, so that while designing of Web site one can efficiently select Web architecture. At last with the help of loadcomplete tool, performance is to be evaluated on various metrics. &copy; Springer Nature Singapore Pte Ltd. 2018.},
key = {Computer architecture},
keywords = {Architecture;Clouds;Load testing;Websites;},
note = {Cloud-based;Comparative studies;Loadcomplete;WEB application;Web architecture;},
URL = {http://dx.doi.org/10.1007/978-981-10-5508-9_23},
} 


@article{20143600057828 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Towards virtualized and automated software performance test architecture},
journal = {Multimedia Tools and Applications},
author = {Kim, Gwang-Hun and Kim, Yeon-Gyun and Chung, Kyung-Yong},
volume = {74},
number = {20},
year = {2015},
pages = {8745 - 8759},
issn = {13807501},
abstract = {In this paper, we propose the towards virtualized and automated software performance test architecture. In general, test engineers use the public performance testwares such as Load Runner, Silk Performer to validate the performance efficiency of their own systems. In case that they do not allowed to use the performance testwares due to the technical limitations in the testwares, most testers should perform the testing in manually. According to the waste of computer and human resources resulted from the situation, we need to propose the test automation scheme by using the virtualization technology to prevent the dissipation in the test environment which has limited resources. The system architecture considered efficient usage of computer resources and test automation to reduce human acts are addressed mainly in this paper. we describe our proposed method which deals with the system architecture and test automation procedures. In our system architecture, we will show how to use the virtual machines and the types of the virtual machines for performance measurement. In addition, the six steps of the test automation are introduced for the automated testing procedures. Finally, a number of experiments show that the proposed schemes allow offering the possibility for automated software performance testing by using the virtualization.<br/> &copy; 2013, Springer Science+Business Media New York.},
key = {Software testing},
keywords = {Automation;Computer architecture;Network security;Virtual machine;Virtual reality;Virtualization;},
note = {Performance efficiency;Performance measurements;Performance testing;Software performance engineerings;Software performance testing;Technical limitations;Test Automation;Virtualization technologies;},
URL = {http://dx.doi.org/10.1007/s11042-013-1536-3},
} 


@inproceedings{20143718153940 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing open source products for the TMT event service},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Gillies, K. and Bhate, Yogesh},
volume = {9152},
year = {2014},
pages = {The Society of Photo-Optical Instrumentation Engineers (SPIE) - },
issn = {0277786X},
address = {Montreal, QC, Canada},
abstract = {The software system for TMT is a distributed system with many components on many computers. Each component integrates with the overall system using a set of software services. The Event Service is a publish-subscribe message system that allows the distribution of demands and other events. The performance requirements for the Event Service are demanding with a goal of over 60 thousand events/second. This service is critical to the success of the TMT software architecture; therefore, a project was started to survey the open source and commercial market for viable software products. A trade study led to the selection of five products for thorough testing using a specially constructed computer/network configuration and test suite. The best performing product was chosen as the basis of a prototype Event Service implementation. This paper describes the process and performance tests conducted by Persistent Systems that led to the selection of the product for the prototype Event Service. &copy; 2014 SPIE.<br/>},
key = {Open systems},
keywords = {Commerce;Middleware;Open source software;Software design;Software testing;},
note = {Commercial market;Distributed systems;Open source products;Performance requirements;Performance testing;Performance tests;Software products;Software services;},
URL = {http://dx.doi.org/10.1117/12.2057148},
} 


@inproceedings{20174804450705 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Comparative analysis of automated load testing tools: Apache JMeter, Microsoft Visual Studio (TFS), LoadRunner, Siege},
journal = {International Conference on Communication Technologies, ComTech 2017},
author = {Abbas, Rabiya and Sultan, Zainab and Bhatti, Shahid Nazir},
year = {2017},
pages = {39 - 44},
address = {Rawalpindi, Pakistan},
abstract = {Software testing is the process of testing, verifying and validating the user's requirements. During whole software development, testing is an ongoing process. Black Box, White Box testing and grey box testing are the three main types of software testing. In Black box testing, user doesn't know intrinsic logics and design of system. In white box testing, Tester knows the intrinsic logic of code. In Grey box testing, Tester has little bit knowledge about the internal structure, code and working of the system. It is commonly used in case of Integration testing. Load testing is the type of testing which helps us to analyze the performance of the system under heavy load or under Zero load. With the help of a automated load Testing Tools, we can do it in better way. The intention for writing this research is to carry out a comparison of four automated load testing tools i.e. Apache JMeter, HP LoadRunner, Microsoft Visual Studio (TFS), Siege based on certain criteria i.e. test scripts generation, plug-in support, result reports, application support and cost. The main focus is to study and analyze these load testing tools and identify which tool is best and more efficient [10]. We assume this comparative analysis can help in selecting the most appropriate tool and motivates the use of open source load testing tools.<br/> &copy; 2017 IEEE.},
key = {Black-box testing},
keywords = {Automation;Integration testing;Load testing;Open source software;Software design;Software engineering;Software testing;Studios;Testing;},
note = {Automated testing;Comparative analysis;Grey-box testing;Internal structure;Manual testing;Stress test;Testing tools;White-box testing;},
URL = {http://dx.doi.org/10.1109/COMTECH.2017.8065747},
} 


@inproceedings{20151600754435 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research on performance test method of lane departure warning system with PreScan},
journal = {Lecture Notes in Electrical Engineering},
author = {Zhang, Qiang and Chen, Daxing and Li, Yusheng and Li, Keqiang},
volume = {328},
year = {2015},
pages = {445 - 453},
issn = {18761100},
address = {Opole, Poland},
abstract = {A performance test method of lane departure warning system (LDWS) with PreScan software is proposed. In the process of virtual integration, the LDWS camera is located in the front of a computer monitor displaying virtual environment so as to capture pictures including lane marks and other information. Vehicle dynamic model and maneuver model run on a real-time computer, which represents a virtual vehicle and communicates with LDWS controller with CAN bus. The results show that the method will make it easier to create various test scenarios, which can save time and cost by transferring complex testing catalogues to the laboratory. The dangers presented in vehicle experiments in some critical scenarios can also be reduced. The repeatable model-based method makes it more convenient to locate the problem, which would make it easier to compare and assess the performance of LDWS produced by different companies objectively. &copy; Springer-Verlag Berlin Heidelberg 2015.},
key = {Software testing},
keywords = {Testing;Vehicles;Virtual reality;},
note = {Lane-departure-warning systems;Model-based method;Real time simulations;Real-time computer;Test scenario;Vehicle dynamic model;Vehicle experiment;Virtual integration;},
URL = {http://dx.doi.org/10.1007/978-3-662-45043-7_45},
} 


@inproceedings{20150800554202 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing framework: Evaluating the impact on the system speed},
journal = {WATeR 2014 - Proceedings of the 2014 2nd Workshop on Anti-Malware Testing Research},
author = {Bot, Paul and Vatamanu, Cristina and Gavrilut, Dragos and Benchea, Razvan-Mihai},
year = {2015},
pages = {Virus Bulletin - },
address = {Canterbury, United kingdom},
abstract = {The world we live in now is defined by the word 'speed' and any device, technology, or system that doesn't keep up is rejected or replaced immediately. Because of this, one of the biggest concerns today is 'optimization'. Its purpose is to reduce the impact on the user's device. The Anti-Virus industry is also confronting with this challenge. Although the first concern is to keep the user safe, providing a flawless protection, it is crucial to reduce the impact brought on the user's system, preventing him to disable or uninstall the AV solution and thus remaining unprotected. The increased number of malware types/families as well as their complexity generated the need for complicated detection methods, which means a constant evaluation is needed. Because of these reasons, our antimalware laboratory has developed a generic framework for measuring the impact that the AV solutions have on the system they are installed on. This system was designed to be easily configurable, managing the big number of changes that occur every day and fast so that every update released to the users can be tested. Also, this framework is used to test and develop new technologies that improve the performance of our AV product.<br/> &copy; 2014 IEEE.},
key = {Computer crime},
keywords = {Malware;Viruses;},
note = {Anti-malware;Detection methods;Generic frameworks;impact;New technologies;performance;Performance testing framework;User interaction;},
URL = {http://dx.doi.org/10.1109/WATeR.2014.7015753},
} 


@article{20111813948297 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and performance test of spacecraft test and operation software},
journal = {Acta Astronautica},
author = {Wang, Guohua and Cui, Yan and Wang, Shuo and Meng, Xiaofeng},
volume = {68},
number = {11-12},
year = {2011},
pages = {1774 - 1781},
issn = {00945765},
abstract = {Main test processor (MTP) software is the key element of Electrical Ground Support Equipment (EGSE) for spacecraft test and operation used in the Chinese Academy of Space Technology (CAST) for years without innovation. With the increasing demand for a more efficient and agile MTP software, the new MTP software was developed. It adopts layered and plug-in based software architecture, whose core runtime server provides message queue management, share memory management and process management services and forms the framework for a configurable and open architecture system. To investigate the MTP softwares performance, the test case of network response time, test sequence management capability and data-processing capability was introduced in detail. Test results show that the MTP software is common and has higher performance than the legacy one. &copy; 2011 Elsevier Ltd. All rights reserved.<br/>},
key = {Software testing},
keywords = {Aerospace ground support;Computer architecture;Data handling;Ground supports;Information management;Network architecture;Spacecraft equipment;},
note = {Electrical ground support equipments;Main test processor;Management capabilities;Open architecture systems;Performance tests;Process management;Processing capability;Space technologies;},
URL = {http://dx.doi.org/10.1016/j.actaastro.2011.02.002},
} 


@inproceedings{20083111416216 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A tool for automated performance testing of Java3D applications in agile environments},
journal = {2nd International Conference on Software Engineering Advances - ICSEA 2007},
author = {Xueling, Shu and Maurer, Frank},
year = {2007},
address = {Cap Esterel, France},
abstract = {Following the agile philosophy that all core features of a system need an automated test harness, performance requirements also need such a check when they are essential for the success of a project. The purpose of this paper is to describe a tool, J3DPerfUnit, which supports automated performance testing for Java3D applications in agile environments. We elicited tool requirements from domain experts through a survey and evaluated J3DPerfUnit using code from our partner's bioinformatics project and Java3D official tutorials. The evaluation pointed out that the tool is effective in detecting performance problems and in identifying where they come from when loading/unloading a 3D object. &copy; 2007 IEEE.<br/>},
key = {Software engineering},
keywords = {Automation;},
note = {Agile environment;Automated test;Core features;Domain experts;Performance problems;Performance requirements;Performance testing;Tool requirements;},
URL = {http://dx.doi.org/10.1109/ICSEA.2007.11},
} 


@article{20105113507563 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Steady state performance test analysis of actively cooled extractor grids for SST-1 neutral beam injector},
journal = {Review of Scientific Instruments},
author = {Jana, M.R. and Mattoo, S.K. and Khan, M.},
volume = {81},
number = {11},
year = {2010},
issn = {00346748},
abstract = {Neutral beam injection (NBI) system is a workhorse to heat magnetically confined tokamak fusion plasma. The heart of any NBI system is an ion extractor system. Steady State Superconducting Tokamak-1 (SST-1) needs 0.5 MW of hydrogen beam power at 30 kV to raise the plasma ion temperature to &sim;1 keV and 1.7 MW of hydrogen beam power at 55 kV for future upgradation. To meet this requirement, an ion extractor system consisting of three actively cooled grids has been designed, fabricated, and its performance test has been done at MARION test stand, IPP, Julich, Germany. During long pulse (14 s) operation, hydrogen ion beam of energy 31 MJ has been extracted at 41 kV. In this paper, we have presented detailed analysis of calorimetric data of actively cooled extractor grids and showed that by monitoring outlet water temperature, grid material temperature can be monitored for safe steady state operation of a NBI system. Steady state operation of NBI is the present day interest of fusion research. In the present experimental case, performance test analysis indicates that the actively cooled grids attain steady state heat removal condition and the grid material temperature rise is &sim;18&deg;C and saturates after 10 s of beam pulse. &copy; 2010 American Institute of Physics.<br/>},
key = {Oceanography},
keywords = {Calorimetry;Ion beams;Ions;Magnetoplasma;Particle beam injection;Tokamak devices;},
note = {Neutral beam injection system;Neutral beam injectors;Outlet-water temperatures;Performance tests;Plasma ion temperature;Steady state performance;Steady state superconducting tokamaks;Steady-state operation;},
URL = {http://dx.doi.org/10.1063/1.3499257},
} 


@inproceedings{20171703591122 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {PHOEBE: an automation framework for the effective usage of diagnosis tools in the performance testing of clustered systems},
journal = {Software - Practice and Experience},
author = {Portillo-Dominguez, A. Omar and Perry, Philip and Magoni, Damien and Murphy, John},
volume = {47},
number = {11},
year = {2017},
pages = {1837 - 1874},
issn = {00380644},
abstract = {The identification of performance issues and the diagnosis of their root causes are time-consuming and complex tasks, especially in clustered environments. To simplify these tasks, researchers have been developing tools with built-in expertise for practitioners. However, various limitations exist in these tools that prevent their efficient usage in the performance testing of clusters (e.g. the need of manually analysing huge volumes of distributed results). In a previous work, we introduced a policy-based adaptive framework (PHOEBE) that automates the usage of diagnosis tools in the performance testing of clustered systems, in order to improve a tester's productivity, by decreasing the effort and expertise needed to effectively use such tools. This paper extends that work by broadening the set of policies available in PHOEBE, as well as by performing a comprehensive assessment of PHOEBE in terms of its benefits, costs and generality (with respect to the used diagnosis tool). The performed evaluation involved a set of experiments in assessing the different trade-offs commonly experienced by a tester when using a performance diagnosis tool, as well as the time savings that PHOEBE can bring to the performance testing and analysis processes. Our results have shown that PHOEBE can drastically reduce the effort required by a tester to do performance testing and analysis in a cluster. PHOEBE also exhibited consistent behaviour (i.e. similar time-savings and resource utilisations), when applied to a set of commonly used diagnosis tools, demonstrating its generality. Finally, PHOEBE proved to be capable of simplifying the configuration of a diagnosis tool. This was achieved by addressing the identified trade-offs without the need for manual intervention from the tester. Copyright &copy; 2017 John Wiley &amp; Sons, Ltd. Copyright &copy; 2017 John Wiley & Sons, Ltd.},
key = {Cluster computing},
keywords = {Commerce;Economic and social effects;},
note = {Adaptive framework;Comprehensive assessment;Manual intervention;Performance analysis;Performance diagnosis;Performance issues;Performance testing;System performance;},
URL = {http://dx.doi.org/10.1002/spe.2500},
} 


@inproceedings{20094812516448 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and implementation of a web application automation testing framework},
journal = {Proceedings - 2009 9th International Conference on Hybrid Intelligent Systems, HIS 2009},
author = {Wandan, Zeng and Ningkang, Jiang and Xubo, Zhou},
volume = {2},
year = {2009},
pages = {316 - 318},
address = {Shenyang, China},
abstract = {In this paper the problems in the automation testing of GUI based Web applications are discussed. A new automation testing framework based on the concept of object feature set and dynamic searching policy is proposed. The design and implementation of it are both given. The framework working using result shows that it makes the testing more convenient and efficient with less resources and time cost but higher testing coverage. The ability of maintenance and stability are both improved. &copy; 2009 IEEE.<br/>},
key = {Automation},
keywords = {Intelligent systems;},
note = {Automation testing;Design and implementations;Dynamic searching;Feature sets;Time cost;WEB application;Web application testing;},
URL = {http://dx.doi.org/10.1109/HIS.2009.175},
} 


@article{20091011939177 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {CLIF, a framework based on Fractal for flexible, distributed load testing},
journal = {Annales des Telecommunications/Annals of Telecommunications},
author = {Dillenseger, Bruno},
volume = {64},
number = {1-2},
year = {2009},
pages = {101 - 120},
issn = {00034347},
abstract = {The context of this work is performance evaluation of IT systems based on load testing. It typically consists in generating a flow of requests on a system under test, and to measure response times, request throughput, or computing resource usage. A quick overview of available load testing platforms shows that there exist hundreds of such platforms, including in the open source domain. However, many testers still tend to develop their own ad hoc load testing tooling. Why? This paper starts by looking for possible answers to this question, in order to introduce the CLIF load injection framework, which intends not to be yet another load testing platform. Based on the Fractal component model, the CLIF open source project aims at addressing key issues such as flexibility, adaptation, and scalability. We give here details about CLIF's architecture and associated tools as well as some feedback from a bunch of practical utilizations. &copy; 2008 Institut TELECOM and Springer-Verlag.<br/>},
key = {Load testing},
keywords = {Fractals;Open source software;Software testing;},
note = {Component-based software engineering;Computing resource;Distributed systems;Fractal component models;IS performance evaluation;Open source projects;Performance evaluations;Testing platforms;},
URL = {http://dx.doi.org/10.1007/s12243-008-0067-9},
} 


@inproceedings{20161302168818 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Sparkbench  A spark performance testing suite},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Agrawal, Dakshi and Butt, Ali and Doshi, Kshitij and Larriba-Pey, Josep-L. and Li, Min and Reiss, Frederick R. and Raab, Francois and Schiefer, Berni and Suzumura, Toyotaro and Xia, Yinglong},
volume = {9508},
year = {2016},
pages = {26 - 44},
issn = {03029743},
address = {Kohala Coast, HI, United states},
abstract = {Spark has emerged as an easy to use, scalable, robust and fast system for analytics with a rapidly growing and vibrant community of users and contributors. It is multipurpose&mdash;with extensive and modular infrastructure for machine learning, graph processing, SQL, streaming, statistical processing, and more. Its rapid adoption therefore calls for a performance assessment suite that supports agile development, measurement, validation, optimization, configuration, and deployment decisions across a broad range of platform environments and test cases. Recognizing the need for such comprehensive and agile testing, this paper proposes going beyond existing performance tests for Spark and creating an expanded Spark performance testing suite. This proposal describes several desirable properties flowing from the larger scale, greater and evolving variety, and nuanced requirements of different applications of Spark. The paper identifies the major areas of performance characterization, and the key methodological aspects that should be factored into the design of the proposed suite. The objective is to capture insights from industry and academia on how to best characterize capabilities of Spark-based analytic platforms and provide cost-effective assessment of optimization opportunities in a timely manner. &copy; Springer International Publishing Switzerland 2016.},
key = {Benchmarking},
keywords = {Artificial intelligence;Big data;Cost effectiveness;Learning systems;},
note = {Agile development;Graph processing;Methodological aspects;Performance assessment;Performance characterization;Performance testing;Performance tests;Statistical processing;},
URL = {http://dx.doi.org/10.1007/978-3-319-31409-9_3},
} 


@inproceedings{20112714122900 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Model-based performance testing (NIER track)},
journal = {Proceedings - International Conference on Software Engineering},
author = {Barna, Cornel and Litoiu, Marin and Ghanbari, Hamoun},
year = {2011},
pages = {872 - 875},
issn = {02705257},
abstract = {In this paper, we present a method for performance testing of transactional systems. The methods models the system under test, finds the software and hardware bottlenecks and generate the workloads that saturate them. The framework is adaptive, the model and workloads are determined during the performance test execution by measuring the system performance, fitting a performance model and by analytically computing the number and mix of users that will saturate the bottlenecks. We model the software system using a two layers queuing model and use analytical techniques to find the workload mixes that change the bottlenecks in the system. Those workload mixes become stress vectors and initial starting points for the stress test cases. The rest of test cases are generated based on a feedback loop that drives the software system towards the worst case behaviour. &copy; 2011 ACM.<br/>},
key = {Software testing},
keywords = {Adaptive systems;Queueing theory;},
note = {Performance Model;Performance testing;Performance tests;Software and hardwares;Software systems;Stress Testing;System under test;Transactional systems;},
URL = {http://dx.doi.org/10.1145/1985793.1985930},
} 


@inproceedings{20105013472951 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Practical end-to-end performance testing tool for high speed 3G-based networks},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Shinbo, Hiroyuki and Tagami, Atsushi and Ano, Shigehiro and Hasegawa, Toru and Suzuki, Kenji},
volume = {6435 LNCS},
year = {2010},
pages = {205 - 220},
issn = {03029743},
abstract = {High speed IP communication is a killer application for 3rd generation (3G) mobile systems. Thus 3G network operators should perform extensive tests to check whether expected end-to-end performances are provided to customers under various environments. An important objective of such tests is to check whether network nodes fulfill requirements to durations of processing packets because a long duration of such processing causes performance degradation. This requires testers (persons who do tests) to precisely know how long a packet is hold by various network nodes. Without any tool's help, this task is time-consuming and error prone. Thus we propose a multi-point packet header analysis tool which extracts and records packet headers with synchronized timestamps at multiple observation points. Such recorded packet headers enable testers to calculate such holding durations. The notable feature of this tool is that it is implemented on off-the shelf hardware platforms, i.e., lap-top personal computers. The key challenges of the implementation are precise clock synchronization without any special hardware and a sophisticated header extraction algorithm without any drop. &copy; 2010 IFIP International Federation for Information Processing.<br/>},
key = {3G mobile communication systems},
keywords = {Computer hardware;Hardware;Mechanical clocks;Personal computers;Software testing;Synchronization;Technology transfer;},
note = {Clock Synchronization;End-to-end performance;Header extraction;IP communications;Killer-application;Off-the-shelf hardwares;Packet header;Performance degradation;},
URL = {http://dx.doi.org/10.1007/978-3-642-16573-3_15},
} 


@inproceedings{20152500949640 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Practical end-to-end performance testing tool for high speed 3G-based networks},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Shinbo, Hiroyuki and Tagami, Atsushi and Ano, Shigehiro and Hasegawa, Toru and Suzuki, Kenji},
volume = {6435},
year = {2010},
pages = {205 - 220},
issn = {03029743},
address = {Natal, Brazil},
abstract = {High speed IP communication is a killer application for 3rd generation (3G) mobile systems. Thus 3G network operators should perform extensive tests to check whether expected end-to-end performances are provided to customers under various environments. An important objective of such tests is to check whether network nodes fulfill requirements to durations of processing packets because a long duration of such processing causes performance degradation. This requires testers (persons who do tests) to precisely know how long a packet is hold by various network nodes. Without any tool&rsquo;s help, this task is time-consuming and error prone. Thus we propose a multi-point packet header analysis tool which extracts and records packet headers with synchronized timestamps at multiple observation points. Such recorded packet headers enable testers to calculate such holding durations. The notable feature of this tool is that it is implemented on off-the shelf hardware platforms, i.e., lap-top personal computers. The key challenges of the implementation are precise clock synchronization without any special hardware and a sophisticated header extraction algorithm without any drop &copy; IFIP International Federation for Information Processing 2010.},
key = {3G mobile communication systems},
keywords = {Clocks;Computer hardware;Hardware;Mechanical clocks;Personal computers;Software testing;Synchronization;Technology transfer;},
note = {Clock Synchronization;End-to-end performance;Header extraction;IP communications;Killer-application;Off-the-shelf hardwares;Packet header;Performance degradation;},
} 


@inproceedings{1983040057378 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {MONITOR AND PERFORMANCE TEST EQUIPMENT IN COMBINATION WITH A CONTROL SYSTEM.},
author = {Nordmann, Th and Guebeli, H. and Vuilleumier, U.},
volume = {1},
year = {1982},
pages = {840 - 844},
address = {Brighton, Engl},
key = {DATA PROCESSING},
note = {ALUMINUM CASE;CONTROL SYSTEMS;FEEDBACK;HEAT BALANCE;PERFORMANCE TEST EQUIPMENT;SENSORS;},
} 


@inproceedings{20140917370063 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test and bottle analysis based on scientific research management platform},
journal = {2013 10th International Computer Conference on Wavelet Active Media Technology and Information Processing, ICCWAMTIP 2013},
author = {Li, Ping and Shi, Dong and Li, Jianping},
year = {2013},
pages = {218 - 221},
address = {Chengdu, Sichuan, China},
abstract = {The performance and service quality of a Web system become more and more important along with the development of Web application technology and popularization of Web application rapidly. There are many particularities and difficulties in the testing of web applications as to traditional application, especially in performance testing, such as unpredictable load, reality of designing scenario and veracity of analysis bottleneck. This paper which based on traditional Web system performance testing theory and used the testing tool named LoadRunner to analyze how to detect the shortage of Web system performance precisely. The method has been implemented in System of scientific research management platform, and has been obtained anticipative result. This paper has divide the web system method into six processes based on the Web system performance testing: Making performance testing plan, build performance testing environment, record and develop testing script, foundation testing scene, play the monitor scene and analysis testing result. And also gives Web performance test the general step. &copy; 2013 IEEE.<br/>},
key = {Load testing},
keywords = {Bottles;Websites;},
note = {Bottleneck analysis;Foundation testing;Loadrunner;Performance testing;Performance tests;Scientific researches;WEB application;Web performance;},
URL = {http://dx.doi.org/10.1109/ICCWAMTIP.2013.6716635},
} 


@inproceedings{20083211434602 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Software realization and performance testing of des cryptographic algorithm on the .NET platform},
journal = {The Experience of Designing and Application of CAD Systems in Microelectronics - Proceedings of the 9th International Conference, CADSM 2007},
author = {Yakovyna, Vitaly and Fedasyuk, Dmytro and Seniv, Maxym},
year = {2007},
pages = {386 - 388},
address = {Lviv-Polyana, Ukraine},
abstract = {The software realization of DES symmetric encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested and it was shown, that the encryption rate is 11.1 Mb/sec on the Intel Celeron D 351 3.2GHz processor, while the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.<br/>},
key = {Cryptography},
keywords = {Computer aided design;Microelectronics;Software testing;},
note = {.NET;CryptoAPI;Cryptographic algorithms;Cryptographic software;DES algorithms;Development environment;Software implementation;Symmetric cryptography;},
URL = {http://dx.doi.org/10.1109/CADSM.2007.4297591},
} 


@inproceedings{20083211434604 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The Performance testing of RSA algorithm software realization},
journal = {The Experience of Designing and Application of CAD Systems in Microelectronics - Proceedings of the 9th International Conference, CADSM 2007},
author = {Yakovyna, Vitaly and Fedasyuk, Dmytro and Seniv, Maxym and Bilas, Orest},
year = {2007},
pages = {390 - 392},
address = {Lviv-Polyana, Ukraine},
abstract = {The software realization of RSA public key encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested. The present paper shows, that the encryption rate is 306.4&plusmn;0.6 kbytes/sec, while the coefficient of encryption time increasing with file size increasing is 3.299. It is concluded that the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.<br/>},
key = {Computer aided design},
keywords = {Microelectronics;Public key cryptography;Software testing;},
note = {.NET;Cryptographic software;Development environment;Flexible architectures;Operation performance;Public key encryption algorithms;RSA algorithms;Software implementation;},
URL = {http://dx.doi.org/10.1109/CADSM.2007.4297593},
} 


@inproceedings{1986060027550 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {APPLICATION OF ELECTROMAGNETIC ENVIRONMENT SIMULATION TO RADAR PERFORMANCE TESTING, OPERABILITY ASSESSMENT AND TRAINING.},
author = {Michaels, John F.},
year = {1985},
pages = {125 - 129},
address = {Arlington, VA, USA},
abstract = {A description is given of the applicability of radar environment simulator systems (RESSs) to the shipboard, ground, and air environment in regard to radar testing, operability assessment, and operator/combat team training. A representative technical description of a delivered RESS is presented.},
key = {RADAR},
keywords = {RADAR SYSTEMS - Testing;},
note = {RADAR ENVIRONMENT SIMULATORS;TEAM TRAINING;},
} 


@inproceedings{20114014404035 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Designing approach analysis on small-scale software performance testing tools},
journal = {Proceedings of 2011 International Conference on Electronic and Mechanical Engineering and Information Technology, EMEIT 2011},
author = {Meng, Xiangfeng},
volume = {8},
year = {2011},
pages = {4254 - 4257},
address = {Harbin, China},
abstract = {Currently, most software performance testing tools in the market are large ones designated for enterprises. Aiming at the demand of small-sized and individual customers' conduction of software performance testing, the paper proposes an approach for designing and realizing a small tool for testing. Core design refers to simulating multi-user concurrent operation by simultaneous execution of multithreading and measuring performance of the system tested through whether each threading responses in a correct manner as well as testing data such as period of responding. Testing tool, which is realized by Java language, consists of three modules of case management, test implementation and test report. Multiple designing modes are utilized in a combined manner during designing, which makes the designing scheme a simple one with high efficiency and easy to expand. The market of performance testing is developing in a rapid manner and researching software performance test is gaining increasingly significance. &copy; 2011 IEEE.<br/>},
key = {Software testing},
keywords = {Commerce;Multitasking;},
note = {Concurrent operations;designing approach;designing mode;Individual customers;Measuring performance;Software performance;Software performance testing;Testing tools;},
URL = {http://dx.doi.org/10.1109/EMEIT.2011.6023983},
} 


@inproceedings{20135017083200 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven generative framework for automated OMG DDS performance testing in the cloud},
journal = {SPLASH Indianapolis 2013; GPCE 2013 - Proceedings of the 12th International Conference on Generative Programming: Concepts and Experiences},
author = {An, Kyoungho and Kuroda, Takayuki and Gokhale, Aniroddha and Tambe, Sumant and Sorbini, Andrea},
year = {2013},
pages = {179 - 182},
address = {Indianapolis, IN, United states},
abstract = {The Object Management Group's (OMG) Data Distribution Service (DDS) provides many configurable policies which determine end-to-end quality of service (QoS) of applications. It is challenging to predict the system's performance in terms of latencies, throughput, and resource usage because diverse combinations of QoS configurations influence QoS of applications in different ways. To overcome this problem, design-time formal methods have been applied with mixed success, but lack of sufficient accuracy in prediction, tool support, and understanding of formalism has prevented wider adoption of the formal techniques. A promising approach to address this challenge is to emulate system behavior and gather data on the QoS parameters of interest by experimentation. To realize this approach, which is preferred over formal methods due to their limitations in accurately predicting QoS, we have developed a model-based automatic performance testing framework with generative capabilities to reduce manual efforts in generating a large number of relevant QoS configurations that can be deployed and tested on a cloud platform. This paper describes our initial efforts in developing and using this technology. &copy; 2013 ACM.},
key = {Quality of service},
keywords = {Distributed computer systems;Forecasting;},
note = {Data distribution services;End-to-end quality of service;Generative programming;Model-driven Engineering;Object management groups;Performance testing;Performance testing framework;Publish/subscribe;},
URL = {http://dx.doi.org/10.1145/2517208.2517216},
} 


@inproceedings{20181104908213 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {VST: A virtual stress testing framework for discovering bugs in SSD flash-translation layers},
journal = {IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD},
author = {Liu, Ren-Shuo and Chang, Yun-Sheng and Hung, Chih-Wen},
volume = {2017-November},
year = {2017},
pages = {283 - 290},
issn = {10923152},
address = {Irvine, CA, United states},
abstract = {Flash translation layers (FTLs) are the core embedded software (also known as firmware) of NAND flash-based solid-state drives (SSDs). The relentless pursuit of high-performance SSDs renders FTLs increasingly complex and intricate. Therefore, testing and validating FTLs are crucial and challenging tasks. Directly testing and validating FTLs on SSD hardware are common practices though, they are time-consuming and cumbersome because 1) the testing speed is limited by the hardware speed of SSDs and 2) just reproducing bugs can be challenging, let alone locating and root causing the bugs. This work presents virtual stress testing (VST), a simulation framework to enable executing SSD FTLs on PCs or servers against virtual SRAM, DRAM, and flash emulated by host-side main memory. FTL function calls, such as moving data from flash to DRAM, are served by the VST framework. Therefore, VST can test FTLs without SSD hardware requirements nor SSD speed limitations, and root causing bugs becomes manageable tasks. We apply VST to representative SSD design, OpenSSD, which is actively utilized and maintained by SSD and FTL communities. Experimental results show that VST can test FTLs at a speed up to 375 GB/s, which is several hundred times faster than directly testing FTLs on SSD hardware. Moreover, we successfully discover seven new FTL bugs in the OpenSSD design using VST, which is a solid evidence of VST's bug-discovering effectiveness.<br/> &copy; 2017 IEEE.},
key = {Flash-based SSDs},
keywords = {Computer aided design;Computer hardware;Computer software;Data storage equipment;Digital storage;Dynamic random access storage;Embedded software;Embedded systems;Firmware;Flash memory;Hardware;Integrated circuit design;Program debugging;Software testing;Static random access storage;},
note = {Common practices;Data storage systems;Disk drive;Flash translation layer;Function calls;Simulation framework;Software debugging;Systems simulation;},
URL = {http://dx.doi.org/10.1109/ICCAD.2017.8203790},
} 


@inproceedings{2005028788142 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Architecture and performance testing of a software GPS receiver for space-based applications},
journal = {IEEE Aerospace Conference Proceedings},
author = {Gold, Kenn and Brown, Alison},
volume = {4},
year = {2004},
pages = {2404 - 2415},
issn = {1095323X},
address = {Big Sky, MT, United states},
abstract = {Space-based GPS technology presents significant challenges over Earth-based systems. These include visibility issues for rotating platforms and tracking of GPS satellites from spacecraft that are in higher orbits than the GPS, realtime resolution of carrier phase ambiguities, and different dynamics during various mission phases. NAVSYS has developed a software GPS receiver that makes use of 3-dimensional Digital Beam Steering technology and inertial aiding to address these issues. This approach offers several advantages including all around visibility for spinning satellites, tracking of weak GPS signals, reduction of multipath, and reprogrammability to accommodate different mission phases. Additionally, a suite of simulation tools based around the NAVSYS Matlab Toolbox and Advanced GPS Hybrid Simulation products have been built to allow testing for simulated space environments. The receiver architecture and test tools are described in this paper.},
key = {Global positioning system},
keywords = {Computer architecture;Computer simulation;Computer software;Orbits;Satellites;Signal processing;Signal to noise ratio;Space applications;},
note = {Digital beam steering technology;Goddard space flight center (GSFC);Precision applications;Satellite signals;},
URL = {http://dx.doi.org/10.1109/AERO.2004.1368035},
} 


@inproceedings{20114114421459 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stress test model of cascading failures in power grids},
journal = {NAPS 2011 - 43rd North American Power Symposium},
author = {Liao, Huaiwei and Ilic, Marija},
year = {2011},
pages = {Northeastern University College of Engineering; Power and Energy Society (IEEE PES) - },
address = {Boston, MA, United states},
abstract = {Cascading failures in electric power systems are one of the major causes of large power blackouts. The operators in control centers of electric power systems need an online tool to monitor the risk of cascading failures when transferring large quantities of power over long distances. In this paper, we propose a two-stage stress test model of cascading failures. The stress test model is intended to emulate the effect of security-constrained economic dispatch (SCED) in support of the required power transfer level, and at the same time, to account for relay actions in response to a given set of severe disturbances, called maximum credible disturbances. The model includes an inner stage, which simulates cascading outages due to relay actions in the system at a given state under disturbances, and an outer stage, which moves the operating point of the system as the power transfer increases as a result of SCED. We use the stress test model to simulate cascading failures in a real 3000-bus power system when increasing its power transfer level in different directions. &copy; 2011 IEEE.<br/>},
key = {Outages},
keywords = {Electric fault currents;Electric load dispatching;Electric power system control;Electric power systems;Electric power transmission networks;Energy transfer;Online systems;Scheduling;},
note = {Cascading failures;Cascading outages;On-line tools;Operating points;Power grids;Power System;Power transfers;Security-constrained economic dispatch;},
URL = {http://dx.doi.org/10.1109/NAPS.2011.6025200},
} 


@inproceedings{20114314452937 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Application of fuzzy and binary algorithm to regulation of load in locomotive load test},
journal = {2011 2nd International Conference on Mechanic Automation and Control Engineering, MACE 2011 - Proceedings},
author = {Tang, Chunqiu and Mo, Yimin and Wen, Zhou},
year = {2011},
pages = {96 - 99},
address = {Inner Mongolia, China},
abstract = {The purpose of locomotive load test is to examine and adjust the capability of locomotive often in its non-driving state, and it is a kind of important standard and means to estimate the quality of repairing locomotive in railway locomotive depot. There are two ways of load test at present. One is the water-resistor load test, the other is the dry resistor load test. Because the dry resistor-load test means does not pollute the environment and needs area less, its developing foreground is immense. To solve the difficulty that the current cannot be freely regulated continuously, for the first time, the model of weightier resistor network in digital circuit is applied to the locomotive dry resistor-load test system, which solves the problem of dry resistor-load test theoretically. It is proved by theory and test that the precision of dry resistor means can meet the request of locomotives constant power load test and reach the standard of water-resistor, so it can serve the application of the dry resistor-load test system. During the locomotive load test, the load of locomotive may be regulated so that the locomotive can be adapted run on all kinds of actual work state. According to the characteristic of weightier resistor, the control arithmetic, which is made up of fuzzy algorithm and binary algorithm, realizes the fast and exact regulation on locomotive load. This paperintroduces how to apply fuzzy and binary algorithm to regulate the dry resistor-load and explains the realization of the fuzzy and binary algorithm. &copy; 2011 IEEE.<br/>},
key = {Testing},
keywords = {Control theory;Engines;Fuzzy sets;Locomotives;Resistors;},
note = {Binary algorithms;Constant power load;Control arithmetic;Fuzzy algorithms;Railway locomotives;Regulation;Resistor load;Resistor network;},
URL = {http://dx.doi.org/10.1109/MACE.2011.5986866},
} 


@inproceedings{20103713223214 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Load testing and performance monitoring tools in use with AJAX based web applications},
journal = {MIPRO 2010 - 33rd International Convention on Information and Communication Technology, Electronics and Microelectronics, Proceedings},
author = {Krizanic, J. and Grguric, A. and Momondor, M. and Lazarevski, P.},
year = {2010},
pages = {428 - 434},
address = {Opatija, Croatia},
abstract = {In order to deliver quality assured software and avoid potential costs caused by unstable software, software testing is essential in software lifecycle. Load testing is one of the testing types with high importance. It is usually accompanied by performance monitoring of the hosting environment. In the case of web applications which are today widely used, one fact is obvious: most of web applications are public and used by vast number of users, which are making a considerable traffic load on hosting environments and web applications. Load testing and performance monitoring become facilitated with existing tools aimed for load testing and performance monitoring. In the paper we analyze and compare several existing tools which facilitate load testing and performance monitoring, in order to find the most appropriate tools by criteria such as ease of use, supported features, and license. Selected tools were put in action in the real environment, through several web applications. For the case study one of the web applications is used in order to introduce different capabilities of tools, including distributed testing, assembling of test scenario from previously recorded usage scenarios, security support, results analysis, monitoring of key parameters, and reporting and alerting about changes of these parameters.<br/>},
key = {Load testing},
keywords = {Microelectronics;Monitoring;Software testing;},
note = {AJAX;Distributed testing;Performance monitoring;Real environments;Security support;Software life cycles;Usage scenarios;WEB application;},
} 


@inproceedings{20132416416305 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Radiation Belt Storm Probes (RBSP) Flight Software stress testing: Case study and lessons learned},
journal = {IEEE Aerospace Conference Proceedings},
author = {Finnigan, Jeremiah},
year = {2013},
issn = {1095323X},
address = {Big Sky, MT, United states},
abstract = {This paper presents a case study of the Radiation Belt Storm Probes (RBSP) mission Command and Data Handling (C&amp;DH) Flight Software stress testing program. Background information on the motivation for stress testing embedded software, and the general principles and goals of a stress test are provided as an introduction. Details of the stress test program that was implemented for the RBSP C&amp;DH Flight Software are presented and discussed. This discussion includes the design and development of a test framework that was implemented to incrementally build the test scenarios, increase the productivity of the RBSP stress test team, and facilitate reuse for regression testing. Results of the RBSP stress test program are summarized, and lessons learned that may be useful for future embedded software test programs are documented. &copy; 2013 IEEE.},
key = {Software testing},
keywords = {C (programming language);Data handling;Embedded software;Probes;Radiation belts;Storms;Test facilities;Testing;},
note = {Background information;Design and Development;Flight Software;Lessons learned;Mission command;Regression testing;Stress Testing;Test framework;},
URL = {http://dx.doi.org/10.1109/AERO.2013.6496814},
} 


@inproceedings{20134817032605 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven generative framework for automated OMG DDS performance testing in the cloud},
journal = {SPLASH 2013 - Proceedings of the 2013 Companion Publication for Conference on Systems, Programming, and Applications: Software for Humanity},
author = {An, Youngho and Kuroda, Takayuki and Gokhale, Aniruddha and Tambe, Sumant and Sorbini, Andrea},
year = {2013},
pages = {93 - 94},
address = {Indianapolis, IN, United states},
abstract = {The Object Management Group's (OMG) Data Distribution Service (DDS) provides many configurable policies which determine end-to-end quality of service (QoS) delivered to the applications. It is challenging, however, to predict the application's performance in terms of latencies, throughput, and resource usage because diverse combinations of QoS configurations influence QoS of applications in different ways. To overcome this problem, design-time formal methods have been applied with mixed success, but a lack of sufficient accuracy in prediction, tool support, and understanding of formalism has prevented wider adoption of the formal techniques. A promising approach to address this challenge is to emulate application behavior and gather data on the QoS parameters of interest by experimentation. To realize this approach, we have developed a middleware framework that uses model-driven generative mechanisms to automate performance testing of a large number of DDS QoS configuration combinations that can be deployed and tested on a cloud platform. Copyright &copy; 2013 by the Association for Computing Machinery, Inc. (ACM).},
key = {Quality of service},
keywords = {Application programs;Computer systems programming;},
note = {Data distribution services;End-to-end quality of service;Generative programming;Middleware frameworks;Model-driven Engineering;Object management groups;Performance testing;Publish/subscribe;},
URL = {http://dx.doi.org/10.1145/2508075.2508096},
} 


@inproceedings{20085211804750 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Scheduling in performance test environment},
journal = {SoftCom 2008: 16th International Conference on Software, Telecommuncations and Computer Networks},
author = {Bozoki, Ferenc and Csondes, Tibor},
year = {2008},
pages = {404 - 408},
address = {Split-Dubrovnik, Croatia},
abstract = {Nowadays automatic testing is getting more and more important in the telecommunication world. The sooner a fault is discovered the cheaper it is to correct it. If a fault is discovered during the development process the cost of the correction is significantly smaller. There are different test strategies, with different approaches like, Conformance Test, System Test and Performance Test. The System Test takes place after a successful Conformance Test. Performance Test is analyzing the load characteristics of the System Under Test (SUT). In this article we describe the main attributes of performance testing, where the main challenge is to generate the expected load without having as complex hardware as the SUT is itself. Most of the papers, presented in this subject are focusing on the characteristics of the generated load, but not the way how to achieve it. These papers usually have the assumption that the load can be generated by deploying more hardware resources. Other papers propose new extensions for test description languages such SDL or TTCN-3 [4]. In this article we intend to describe a Finite State Machine (FSM) based model and an algorithm which improves the efficiency of Scheduling in this Performance Test environment. We present an architecture based on the so called Virtual Threads, an algorithm to optimize the scheduling between these threads, and an example to demonstrate the algorithm.<br/>},
key = {Load testing},
keywords = {Automatic testing;Computer hardware;Computer networks;Hardware;Scheduling;Software testing;},
note = {Architecture-based;Description languages;Development process;Hardware resources;Load characteristics;Performance testing;Performance tests;System under test;},
URL = {http://dx.doi.org/10.1109/SOFTCOM.2008.4669519},
} 


@inproceedings{20084811743376 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Towards adaptive framework of keyword driven automation testing},
journal = {Proceedings of the IEEE International Conference on Automation and Logistics, ICAL 2008},
author = {Tang, Jingfan and Cao, Xiaohua and Ma, Albert},
year = {2008},
pages = {1631 - 1636},
address = {Qingdao, China},
abstract = {This paper presents an adaptive framework of keyword-driven automation testing to support the conversion of the keyword-based test cases into different kinds of test scripts automatically to be executed by different test applications under different test environments (such as GUI environment, Database environment, etc.). XML is used to describe the keyword-based commands for the test case. An engine is provided in this framework to parse the XML file and dispatch the command sequences to the different test drivers according to the driver type pre-defined in the command. The test driver is responsible for dispatching the commands to the corresponding test applications to generate the test scripts automatically according to the keywords in the commands. The test scripts will be executed by the test applications on the system-under-test under different test environments. All the test results will be recorded into a log repository for generating all kinds of the test reports. &copy; 2008 IEEE.<br/>},
key = {Testing},
keywords = {Automation;XML;},
note = {Adaptive;Adaptive framework;Automation testing;Command sequences;Keyword driven;System under test;Test applications;Test Environment;},
URL = {http://dx.doi.org/10.1109/ICAL.2008.4636415},
} 


@inproceedings{20120114656330 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The research and design of NSL-oriented automation testing framework},
journal = {Advances in Intelligent and Soft Computing},
author = {Wang, Chongwen},
volume = {128},
year = {2011},
pages = {367 - 373},
issn = {18675662},
abstract = {By analyzing the Selenium and other open source testing tool, the lack of Selenium and the design of testing scripts are given to discuss and try to improve to resolve problems of NLS. These improvements include the using of page elements, enhancement of the response of the heavyweight component, optimization of testing scripts for multi-language versions. The parallel execution strategy for multilingual test cases has been provided, through which the users can execute test cases of multi-language in a great number of test servers at the same time, greatly improving the overall testing efficiency. The testing framework proposed has been applied to the actual web product globalization testing, and achieved very good results. &copy; Springer-Verlag Berlin Heidelberg 2011.<br/>},
key = {Open source software},
keywords = {Selenium;},
note = {Automation testing;Multi languages;Open sources;Parallel executions;Test case;Testing efficiency;Testing framework;Testing tools;},
URL = {http://dx.doi.org/10.1007/978-3-642-25989-0_60},
} 


@inproceedings{20171603585111 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Directed automated memory performance testing},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Chattopadhyay, Sudipta},
volume = {10206 LNCS},
year = {2017},
pages = {38 - 55},
issn = {03029743},
address = {Uppsala, Sweden},
abstract = {Understanding software non-functional properties (e.g. time, energy and security) requires deep understanding of the execution platform. The design of caches plays a crucial role in impacting software performance (for low latency of caches) and software security (for cache being used as a side channel). We present CATAPULT, a novel test generation framework to systematically explore the cache behaviour of an arbitrary program. Our framework leverages dynamic symbolic execution and satisfiability modulo theory (SMT) solvers for generating test inputs. We show the application of CATAPULT in testing timing-related properties and testing cache side-channel vulnerabilities in several open-source programs, including applications from OpenSSL and Linux GDK libraries. &copy; Springer-Verlag GmbH Germany 2017.},
key = {Software testing},
keywords = {Application programs;Computer operating systems;Open source software;},
note = {Dynamic symbolic executions;Execution platforms;Memory performance;Non functional properties;Open source projects;Satisfiability modulo Theories;Software performance;Software security;},
URL = {http://dx.doi.org/10.1007/978-3-662-54580-5_3},
} 


@article{1995242672792 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Environmental stress testing experiment using the Taguchi method},
journal = {IEEE transactions on components, packaging, and manufacturing technology. Part A},
author = {Pachucki, Dennis E.},
volume = {18},
number = {1},
year = {1995},
pages = {3 - 9},
issn = {10709886},
abstract = {An environmental stress screening (ESS), a method for improving manufacturing process by applying stress beyond product specification detect latent defects in the product, was performed to find out the relevant stress used in the production of printed wiring boards. Three types of stress - random vibration, temperature cycling and power cycling - were emphasized. Experimental results were statistically obtained using the Taguchi design method.},
key = {Printed circuit manufacture},
keywords = {Application specific integrated circuits;Computer software;Data acquisition;Data storage equipment;Environmental testing;Microprocessor chips;Random processes;Statistical methods;Stresses;Thermal cycling;Vibrations (mechanical);},
note = {Analysis of variance;Environmental stress testing;Functional diagnostic test suite;Power cycling;Power on self test;Printed wiring board;Programmable memory chip;Random vibration;Taguchi method;Temperature cycling;},
URL = {http://dx.doi.org/10.1109/95.370727},
} 


@inproceedings{20141717624803 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Downhole tools oil-immersion automation test system design},
journal = {Applied Mechanics and Materials},
author = {Shang, Chun Min and Zhang, Dong Mei and Zhang, Xin Ming},
volume = {543-547},
year = {2014},
pages = {930 - 933},
issn = {16609336},
address = {Beijing, China},
abstract = {According to the relationship of pressure and volume of the downhole tool oil-immersion test system during the pressuring process, the mathematical models of the pressure control was deduced about the downhole tool experiment system, based on the model, a test system of the multi function, high precision, high index, intelligent automation was designed and manufactured. The control system has friendly interface, manual/automatic and scene/remote control function, the test parameters and test process is free to set according to the actual needs of test tool, reports and graphs can be produce automatically, the test site achieve unattended operation that improving testing process safety. Test and application show that pressure control capacity of 150Mpa, pressure control accuracy of 0.35%FS. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Tools},
keywords = {Automation;Automobile manufacture;Information technology;Mathematical models;Packers;Pressure control;Safety testing;},
note = {Automation controls;Automation tests;Control functions;Down-hole tool;Experiment system;Intelligent automation;Multi-functions;Oil-immersion;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.543-547.930},
} 


@inproceedings{20080311027892 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Wireless communication system automation testing framework},
journal = {2007 International Conference on Wireless Communications, Networking and Mobile Computing, WiCOM 2007},
author = {Liu, Lan and Wei, Wenguo and Li, Jiachun},
year = {2007},
pages = {2981 - 2984},
address = {Shanghai, China},
abstract = {This article intends to introduce a leading next generation wireless protocol oriented automation testing framework-WiCAT system. This framework supports multiple protocol messaging testing by simulating the wireless equipments and implementing the telecommunication system logic. WiCAT provides high-efficiency and low-cost performance basing on a distributed, expandable and extensible architecture. &copy; 2007 IEEE.},
key = {Wireless telecommunication systems},
keywords = {Automation;Message passing;Mobile devices;Network protocols;},
note = {Automation testing;Wireless equipments;Wireless protocols;},
URL = {http://dx.doi.org/10.1109/WICOM.2007.740},
} 


@article{1996363246637 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Deriving workloads for performance testing},
journal = {Software - Practice and Experience},
author = {Avritzer, Alberto and Weyuker, Elaine J.},
volume = {26},
number = {6},
year = {1996},
pages = {613 - 633},
issn = {00380644},
abstract = {An approach is presented to compare the performance of an existing production platform and a proposed replacement architecture. The traditional approach to such a comparison is to develop software for the proposed platform, build the new architecture, and collect performance measurements on both the existing system in production and the new system in the development environment. In this paper we propose a new way to design an application-independent workload for doing such a performance evaluation. We demonstrate the applicability of our approach by describing our experience using it to help an industrial organization determine whether or not a proposed architecture would be adequate to meet their organization's performance requirements.},
key = {Computer software},
keywords = {Computer architecture;Computer software portability;Performance;Software engineering;},
note = {Benchmark tuning;Performance testing;Workloads;},
URL = {http://dx.doi.org/10.1002/(SICI)1097-024X(199606)26:6<613::AID-SPE23>3.0.CO;2-5},
} 


@article{20164302941951 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {WESSBAS: extraction of probabilistic workload specifications for load testing and performance predictiona model-driven approach for session-based application systems},
journal = {Software and Systems Modeling},
author = {Vogele, Christian and van Hoorn, Andre and Schulz, Eike and Hasselbring, Wilhelm and Krcmar, Helmut},
volume = {17},
number = {2},
year = {2018},
pages = {443 - 477},
issn = {16191366},
abstract = {The specification of workloads is required in order to evaluate performance characteristics of application systems using load testing and model-based performance prediction. Defining workload specifications that represent the real workload as accurately as possible is one of the biggest challenges in both areas. To overcome this challenge, this paper presents an approach that aims to automate the extraction and transformation of workload specifications for load testing and model-based performance prediction of session-based application systems. The approach (WESSBAS) comprises three main components. First, a system- and tool-agnostic domain-specific language (DSL) allows the layered modeling of workload specifications of session-based systems. Second, instances of this DSL are automatically extracted from recorded session logs of production systems. Third, these instances are transformed into executable workload specifications of load generation tools and model-based performance evaluation tools. We present transformations to the common load testing tool Apache JMeter and to the Palladio Component Model. Our approach is evaluated using the industry-standard benchmark SPECjEnterprise2010 and the World Cup 1998 access logs. Workload-specific characteristics (e.g., session lengths and arrival rates) and performance characteristics (e.g., response times and CPU utilizations) show that the extracted workloads match the measured workloads with high accuracy.<br/> &copy; 2016, The Author(s).},
key = {Load testing},
keywords = {Computer programming languages;Extraction;Forecasting;Modeling languages;Problem oriented languages;Specifications;},
note = {Domain specific languages;Industry-standard benchmarks;Model driven approach;Performance characteristics;Performance evaluation tools;Performance Model;Performance prediction;Testing and modeling;},
URL = {http://dx.doi.org/10.1007/s10270-016-0566-5},
} 


@inproceedings{2004528742400 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of a microturbine generator set with twin rotating disk regenerators},
journal = {Proceedings of the ASME Turbo Expo 2004},
author = {Chiang, Hsiao-Wei D. and Wang, Chun-Hao and Hsu, Chih-Neng},
volume = {6},
year = {2004},
pages = {37 - 44},
address = {Vienna, Austria},
abstract = {An investigation was conducted to study the performance of a 150 kW microturbine generator set with twin rotating disk regenerators, including testing and analyses. Originally designed as a vehicular microturbine engine, twin rotating ceramic disk regenerators were used to dramatically improve fuel consumption by transferring heat energy from the exhaust gas stream to compressor discharge. This microturbine engine consists of a gasifier assembly, a power turbine, a combustor, a regenerator system, a reduction and accessory drive gearbox, and a fuel management system. Because the microturbine engine did not come with the necessary start and control system (including electronic engine control unit), a start sequence was successfully developed and a manual control system installed. This paper reports on testing of the microturbine generator set at different load conditions using load banks. As a parallel effort, a software program was used to predict the performance of the microturbine generator set at different operating conditions in order to compare with the test results.},
key = {Turbines},
keywords = {Control systems;Disks (machine components);Gas generators;Mechanical testing;Performance;Regenerators;Rotors;Shafts (machine components);},
note = {Combined heat and power (CHP);Microturbine generators;Rotating disk regenerators;Vehicular microturbine engine;},
} 


@article{1999284675977 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Network application performance testing for lotus notes},
journal = {CMG Transactions},
author = {Williams, Andrew},
number = {95},
year = {1999},
pages = {49 - 64},
abstract = {As customers move toward network applications, the problem of acceptable performance and user load stresses have not evaporated. Increasingly, customers need to simulate large network user loads to measure end-to-end response time and identify potential bottlenecks. This paper presents a methodology to achieve this and details results from real applications evaluations on an OS/2 and AIX Lotus Notes 4.1 environment. In all, thirty client machines were setup in a laboratory and linked to an additional set of seventy virtual users all exercising Lotus Notes application test cases to create a user load of 100 active concurrent users. During the process the clients and servers were monitored with various tools. The paper details the process used, a sample of the results, problems found in the process, the metrics required and future directions for network performance test solutions. It will focus mostly on the method of creating large, realistic loads for Lotus Notes applications - a topic largely ignored by the testing community up to this point in time. The subject will be of interest to any owner interested in implementing a network application or client/server application or a test specialist involved in testing these type of applications.},
key = {Computer applications},
keywords = {Client server computer systems;Computer software;Computer testing;Internet;Performance;Response time (computer systems);},
note = {Lotus notes;Network application performance testing;},
} 


@inproceedings{20152701007652 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {PLeTsPerf - A Model-Based Performance Testing Tool},
journal = {2015 IEEE 8th International Conference on Software Testing, Verification and Validation, ICST 2015 - Proceedings},
author = {Rodrigues, Elder and Bernardino, Maicon and Costa, Leandro and Zorzo, Avelino and Oliveira, Flavio},
year = {2015},
pages = {Graz University of Technology (TU Graz); IEEE Computer Society - },
address = {Graz, Austria},
abstract = {Performance testing is a highly specialized task, since it requires that a performance engineer knows the application to be tested, its usage profile, and the infrastructure where it will execute. Moreover, it requires that testing teams expend a considerable effort and time on its automation. In this paper, we present the PLeTsPerf, a model-based performance testing tool to support the automatic generation of scenarios and scripts from application models. PLetsPerf is a mature tool, developed in collaboration with an IT company, which has been used in several works, experimental studies and pilot studies. We present an example of use to demonstrate the process of generating test scripts and scenarios from UML models to test a Web application. We also present the lessons learned and discuss our conclusions about the use of the tool. &copy; 2015 IEEE.},
key = {Software testing},
keywords = {Model checking;Unified Modeling Language;Verification;},
note = {Application models;Automatic Generation;Model based testing;Model-based OPC;Performance testing;Pilot studies;Testing tools;WEB application;},
URL = {http://dx.doi.org/10.1109/ICST.2015.7102628},
} 


@article{20130415938517 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Challenges on amazon cloud in load balancing, performance testing and upgrading},
journal = {Advances in Intelligent Systems and Computing},
author = {Shah, Himanshu and Wankhede, Paresh and Borkar, Anup},
volume = {203},
year = {2013},
pages = {31 - 40},
issn = {21945357},
abstract = {Web application hosting in a data centre is clouded with quite a few issues ranging from hardware provisioning, software installation and maintaining the servers. Traditional data-centre techniques need production grade hardware to test application's behavior/performance under expected peak load. This could be costly and procuring hardware could be very time consuming causing delays in software delivery. Cloud (Infrastructure-as-a- Service) can be an answer to this. Cloud Computing provides production grade server instances at very cheap rates. This whitepaper is divided into two sub parts: first part details out the typical web application setup on Amazon Web Services cloud (AWS) [Ref 2], challenges faced during the setup and resolution for the same, while the second part talks about the observations made during load testing using Apache JMeter performance testing tool on AWS cloud. Three different application setup topologies (single tier, two tier and three tier) are tested and findings and learning from it are discussed here. This whitepaper only highlights the pitfalls encountered and possible resolutions for each and is not a comment on performance of Amazon cloud. The whitepaper endeavors to find out the best architecture which would give maximum return on investment. &copy; Springer-Verlag Berlin Heidelberg 2013.},
key = {Computer hardware},
keywords = {Hardware;Profitability;Web services;},
note = {Amazon web services;Data centres;Peak load;Performance testing;Return on investments;Software installations;Test applications;WEB application;},
URL = {http://dx.doi.org/10.1007/978-3-642-35461-8},
} 


@inproceedings{1998094000254 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Simplifying motor performance testing in the production environment},
journal = {Proceedings of the Electrical/Electronics Insulation Conference},
author = {Leonard, Donald C.},
year = {1997},
pages = {185 - 190},
issn = {03622479},
address = {Rosemont, IL, USA},
abstract = {The objective of this paper is to illustrate how performance test systems on the factory floor can be enhanced by utilizing the power and speed of integral computer hardware and software to automate and simplify tasks typically performed in the production environment. The first part of this paper discusses why the test system is needed to perform additional tasks. The second section defines the relationships between various departments within the organization, and the test system. The third section discusses the benefits of integrating additional functions into the test system. The final sections of the paper discusses incorporating artificial intelligence and networking to simplify tasks associated with the production environment.},
key = {Electric motors},
keywords = {Artificial intelligence;Automatic testing;Computer hardware;Computer integrated manufacturing;Computer software;Decision making;Factory automation;Performance;},
note = {Factory floor;Performance testing;},
} 


@inproceedings{20141017429873 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {An evaluation of client-side dependencies of search engines by load testing},
journal = {5th International Conference on Advances in System Testing and Validation Lifecycle, VALID 2013, Held at SoftNet 2013},
author = {Sefer, Emine and Aykanat, Sinem},
year = {2013},
pages = {61 - 65},
address = {Venice, Italy},
abstract = {Nowadays, web based large-scale systems, such as search engines, are widely used. The popularity of search engines created a new environment in which the applications need to be highly scalable due to the data tsunami generated by a huge load of requests. In this context, the main problem is to validate how far the web applications especially search engines can deal with the load generated by the clients. Load testing, in general, refers to the practice of accessing the system behavior under load. In this paper, we study on search engine performances' dependencies related to network bandwidth and Internet browsers in aspect of load testing. We observed that search engines' speed is dependent on Internet browsers and network bandwidth.<br/>},
key = {Search engines},
keywords = {Bandwidth;Large scale systems;Life cycle;Load testing;System theory;},
note = {Client sides;Internet browsers;Network bandwidth;Search engine performance;System behaviors;Under loads;WEB application;Web based;},
} 


@inproceedings{20144200110472 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Evaluating capture and replay and model-based performance testing tools: An empirical comparison},
journal = {International Symposium on Empirical Software Engineering and Measurement},
author = {Rodrigues, Elder M. and Oliveira, Flavio M. and Bernardino, Maicon and Saad, Rodrigo S. and Costa, Leandro T. and Zorzo, Avelino F. and Guarienti, Priscila},
year = {2014},
pages = {IEEE Software; Microsoft Research; Politecnico di Torino; Telecom Italia JOL (Joint Open Lab); Telecom Italia Lab - },
issn = {19493770},
address = {Torino, Italy},
abstract = {[Context] A variety of testing tools have been developed to support and automate software performance testing activities. These tools may use different techniques, such as Model-Based Testing (MBT) or Capture and Replay (CR). [Goal] For software companies, it is important to evaluate such tools w.r.t. the effort required for creating test artifacts using them; despite its importance, there are few empirical studies comparing performance testing tools, specially tools developed with different approaches. [Method]We are conducting experimental studies to provide evidence about the required effort to use CR-based tools and MBT tools. In this paper, we present our first results, evaluating the effort (time spent) when using LoadRunner and Visual Studio CRbased tools, and the PLeTsPerf MBT tool to create performance test scripts and scenarios to test Web applications, in the context of a collaboration project between Software Engineering Research Center at PUCRS and a technological laboratory of a global IT company. [Results] Our results indicate that, for simple testing tasks, the effort of using a CR-based tool was lower than using an MBT tool, but as the testing complexity increases tasks, the advantage of using MBT grows significantly. [Conclusions] To conclude, we discuss the lessons we learned from the design, operation, and analysis of our empirical experiment. Copyright 2014 ACM.<br/>},
key = {Software testing},
keywords = {Application programs;Experiments;Model checking;},
note = {Collaboration projects;Empirical - comparisons;Empirical experiments;Model based testing;Performance testing;Software performance testing;Testing complexity;Testing tools;},
URL = {http://dx.doi.org/10.1145/2652524.2652587},
} 


@inproceedings{20140917393351 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Static analysis driven cache performance testing},
journal = {Proceedings - Real-Time Systems Symposium},
author = {Banerjee, Abhijeet and Chattopadhyay, Sudipta and Roychoudhury, Abhik},
year = {2013},
pages = {319 - 329},
issn = {10528725},
address = {Vancouver, BC, Canada},
abstract = {Real-time, embedded software are constrained by several non-functional requirements, such as timing. With the ever increasing performance gap between the processor and the main memory, the performance of memory subsystems often pose a significant bottleneck in achieving the desired performance for a real-time, embedded software. Cache memory plays a key role in reducing the performance gap between a processor and main memory. Therefore, analyzing the cache behaviour of a program is critical for validating the performance of an embedded software. In this paper, we propose a novel approach to automatically generate test inputs that expose the cache performance issues to the developer. Each such test scenario points to the specific parts of a program that exhibit anomalous cache behaviour along with a set of test inputs that lead to such undesirable cache behaviour. We build a framework that leverages the concepts of both static cache analysis and dynamic test generation to systematically compute the cache-performance stressing test inputs. Our framework computes a test-suite which does not contain any false positives. This means that each element in the test-suite points to a real cache performance issue. Moreover, our test generation framework provides an assurance of the test coverage via a well-formed coverage metric. We have implemented our entire framework using Chronos worst case execution time (WCET) analyzer and LLVM compiler infrastructure. Several experiments suggest that our test generation framework quickly converges towards generating cache-performance stressing test cases. We also show the application of our generated test-suite in design space exploration and cache performance optimization. &copy; 2013 IEEE.<br/>},
key = {Software testing},
keywords = {Cache memory;Embedded software;Interactive computer systems;Program compilers;Real time systems;Static analysis;},
note = {Cache performance;Design space exploration;Memory subsystems;Non-functional requirements;Performance testing;Static cache analysis;Test generations;Worst-case execution time;},
URL = {http://dx.doi.org/10.1109/RTSS.2013.39},
} 


@inproceedings{20143518112883 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and implementation of automation testing framework based on keyword driven},
journal = {Applied Mechanics and Materials},
author = {He, Zhong Hai and Zhang, Xiang and Zhu, Xiang Yin},
volume = {602-605},
year = {2014},
pages = {2142 - 2146},
issn = {16609336},
address = {Chongqing, China},
abstract = {For the purpose of settling problems in the present automated testing frameworks, the paper presents an automated testing framework based on keyword driven technology. At first, it summarized and analyzed the recent automated testing frameworks; and then it proposed the framework's system architecture, and also presented the key technology details of the framework. At last, this paper compared this paper's framework with the recent frameworks by the IP phone, which proved that this framework had superiority in reducing the scale of test scripts, raising the overall efficiency of testing and so on. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Software testing},
keywords = {Materials;Mechanics;},
note = {Automated testing;Automation testing;Design and implementations;Key technologies;Keyword driven;Overall efficiency;System architectures;Test scripts;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.602-605.2142},
} 


@inproceedings{20113614311923 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Wireless network performance test in hybrid wired/wireless network system},
journal = {Proceedings of the World Congress on Intelligent Control and Automation (WCICA)},
author = {Jiang, Dezhi and Fei, Minrui and Wang, Haikuan and Li, Tongtao},
year = {2011},
pages = {1029 - 1034},
abstract = {Recently, considerable researches on wireless networks have been carried in industrial automation. A great deal of wireless control and monitoring systems are introduced in certain problematic parts of the process industry to improve the productivity and efficiency. However, the control and monitor application requires high standard performances, such as reliability, real-timing and accuracy. Therefore a comprehensive performance assessment is needed to test the property of the wireless network so as to optimize the network protocol and improve the network communication quality. This paper studies the wireless network in the integrated wired/wireless fieldbus system and proposes a method to acquire a set of key indicators of wireless networks. Then, a test device is designed to acquire the performance indicators of the system. The wireless protocols are analysed according to the performance indicators. The results show that the test for the performance of wireless networks can be realized by the method mentioned. &copy; 2011 IEEE.<br/>},
key = {Wireless networks},
keywords = {Benchmarking;Internet protocols;Network protocols;},
note = {Comprehensive performance assessments;Control and monitor;IEEE 802.15.4a;Industrial automation;Network communications;Performance indicators;Process industries;Protocol conversion;},
URL = {http://dx.doi.org/10.1109/WCICA.2011.5970672},
} 


@inproceedings{20130315908070 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing challenges  solutions for asynchronous systems},
journal = {37th International Conference Computer Measurement Group},
author = {Mudujutla, Guru and Hampaiah, Uppara and Jandhyala, Srinivas},
year = {2011},
address = {Washington, DC, United states},
abstract = {This paper presents challenges faced in typical Asynchronous Systems Performance Testing (ASPT) and workaround solutions applied for them. An Enterprise Service Fulfillment (ESF) system consists of Business Gateways, Application Integrators Customer Relationship Management (CRM) Systems, Order Fulfillment Systems, Fault Resolution Systems and series of other back-end systems such as billing, revenue assurance, work order management, MIS etc. It uses web services, queue communications with high volumes of different business transactions. Stringent business Service Level Agreement (SLAs) (like individual component response times, throughputs, utilizations and End to End (E2E) response times), scaled down test environment and unavailability of back-end components in test environment poses some unique challenges during performance testing of asynchronous systems. This paper elaborates these challenges and presents suitable workaround solutions devised to handle asynchronous transactions for complete performance testing thus providing an assurance on the asynchronous SLAs before the business goes live.},
key = {Response time (computer systems)},
keywords = {Telecommunication systems;Web services;},
note = {Asynchronous system;Backend system;Business service;Business transaction;Customer relationship management systems;End to end;Enterprise services;Individual components;Order fulfillment;Performance testing;Resolution systems;Revenue assurance;Test Environment;Work order management;},
} 


@inproceedings{20124015495162 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Expertus: A generator approach to automate performance testing in IaaS clouds},
journal = {Proceedings - 2012 IEEE 5th International Conference on Cloud Computing, CLOUD 2012},
author = {Jayasinghe, Deepal and Swint, Galen and Malkowski, Simon and Li, Jack and Wang, Qingyang and Park, Junhee and Pu, Calton},
year = {2012},
pages = {115 - 122},
address = {Honolulu, HI, United states},
abstract = {Cloud computing is an emerging technology paradigm that revolutionizes the computing landscape by providing on-demand delivery of software, platform, and infrastructure over the Internet. Yet, architecting, deploying, and configuring enterprise applications to run well on modern clouds remains a challenge due to associated complexities and non-trivial implications. The natural and presumably unbiased approach to these questions is thorough testing before moving applications to production settings. However, thorough testing of enterprise applications on modern clouds is cumbersome and error-prone due to a large number of relevant scenarios and difficulties in testing process. We address some of these challenges through Expertus - -a flexible code generation framework for automated performance testing of distributed applications in Infrastructure as a Service (IaaS) clouds. Expertus uses a multi-pass compiler approach and leverages template-driven code generation to modularly incorporate different software applications on IaaS clouds. Expertus automatically handles complex configuration dependencies of software applications and significantly reduces human errors associated with manual approaches for software configuration and testing. To date, Expertus has been used to study three distributed applications on five IaaS clouds with over 10,000 different hardware, software, and virtualization configurations. The flexibility and extensibility of Expertus and our own experience on using it shows that new clouds, applications, and software packages can easily be incorporated. &copy; 2012 IEEE.<br/>},
key = {Infrastructure as a service (IaaS)},
keywords = {Application programs;Automation;Clouds;Codes (symbols);Program compilers;Scalability;Software testing;Testing;},
note = {Aspect;Code Generation;Datacenter;Emulab;IaaS;Multi-tier;Open Cirrus;Performance;Template;},
URL = {http://dx.doi.org/10.1109/CLOUD.2012.98},
} 


@inproceedings{20124315601080 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling and analysis of CPU usage in safety-critical embedded systems to support stress testing},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Nejati, Shiva and Di Alesio, Stefano and Sabetzadeh, Mehrdad and Briand, Lionel},
volume = {7590 LNCS},
year = {2012},
pages = {759 - 775},
issn = {03029743},
address = {Innsbruck, Austria},
abstract = {Software safety certification needs to address non-functional constraints with safety implications, e.g., deadlines, throughput, and CPU and memory usage. In this paper, we focus on CPU usage constraints and provide a framework to support the derivation of test cases that maximize the chances of violating CPU usage requirements. We develop a conceptual model specifying the generic abstractions required for analyzing CPU usage and provide a mapping between these abstractions and UML/MARTE. Using this model, we formulate CPU usage analysis as a constraint optimization problem and provide an implementation of our approach in a state-of-the-art optimization tool. We report an application of our approach to a case study from the maritime and energy domain. Through this case study, we argue that our approach (1) can be applied with a practically reasonable overhead in an industrial setting, and (2) is effective for identifying test cases that maximize CPU usage. &copy; 2012 Springer-Verlag.<br/>},
key = {Safety engineering},
keywords = {Abstracting;Computer software selection and evaluation;Constrained optimization;Embedded systems;Safety testing;},
note = {Conceptual model;Constraint optimization problems;Industrial settings;Model and analysis;Optimization tools;Safety-critical embedded systems;Software safety;State of the art;},
URL = {http://dx.doi.org/10.1007/978-3-642-33666-9_48},
} 


@inproceedings{20063010030632 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Using genetic algorithms for early schedulability analysis and stress testing in real-time systems},
journal = {Genetic Programming and Evolvable Machines},
author = {Briand, Lionel C. and Labiche, Yvan and Shousha, Marwa},
volume = {7},
number = {2},
year = {2006},
pages = {145 - 170},
issn = {13892576},
abstract = {Reactive real-time systems have to react to external events within time constraints: Triggered tasks must execute within deadlines. It is therefore important for the designers of such systems to analyze the schedulability of tasks during the design process, as well as to test the system's response time to events in an effective manner once it is implemented. This article explores the use of genetic algorithms to provide automated support for both tasks. Our main objective is then to automate, based on the system task architecture, the derivation of test cases that maximize the chances of critical deadline misses within the system; we refer to this testing activity as stress testing. A second objective is to enable an early but realistic analysis of tasks' schedulability at design time. We have developed a specific solution based on genetic algorithms and implemented it in a tool. Case studies were run and results show that the tool (1) is effective at identifying test cases that will likely stress the system to such an extent that some tasks may miss deadlines, (2) can identify situations that were deemed to be schedulable based on standard schedulability analysis but that, nevertheless, exhibit deadline misses.},
key = {Genetic algorithms},
keywords = {Real time systems;Scheduling;Stress analysis;Systems analysis;},
note = {Critical deadline;Schedulability theory;Software verification and validation;System task architecture;},
URL = {http://dx.doi.org/10.1007/s10710-006-9003-9},
} 


@inproceedings{20084811737731 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A configurable web service performance testing framework},
journal = {Proceedings - 10th IEEE International Conference on High Performance Computing and Communications, HPCC 2008},
author = {Jingmin, Xie and Xiaojun, Ye and Li, Bin and Feng, Xie},
year = {2008},
pages = {312 - 319},
address = {Dalian, China},
abstract = {More and more softwares based on web service technologies are developed. Before their releases on the Internet, it is necessary to evaluate these systems' performance, especially their response time under different workload pressures. However, existing performance testing benchmarks and tools for web service applications are difficult to adapt to various user-specific testing purposes. This paper proposes a configurable web service performance testing framework which contains client module, application server module and database module. Client module, by using the network cooperation method that one central client drives several other clients, adapts to a great number of concurrent customers to request web services. Application server module contains web services under testing and external supporting web services, each of which is configured as a plug-in. The process to realize mixed ratio of web service interactions is similar to dealing cards and adapts to different commercial application characteristics. In database module, the data model including table and attribute dependence can be customized, and the data scale initialization can be resized according to the topology of above dependence. As such, this framework allows testers to dynamically define their data model, customize their scale of database, configure their transaction characteristics, deploy their application strategies and confirm their performance metrics. &copy; 2008 IEEE.<br/>},
key = {Web services},
keywords = {Benchmarking;Database systems;Digital storage;Topology;Websites;},
note = {Application Servers;Application strategies;Commercial applications;Performance metrics;Service interaction;Service performance;Web service applications;Web service technology;},
URL = {http://dx.doi.org/10.1109/HPCC.2008.53},
} 


@inproceedings{20172103685017 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling expands value of performance testing for big data applications},
journal = {ICPE 2017 - Companion of the 2017 ACM/SPEC International Conference on Performance Engineering},
author = {Zibitsker, Boris and Lupersolsky, Alex},
year = {2017},
pages = {119 - 123},
address = {L'Aquila, Italy},
abstract = {Performance testing of Big Data applications is performed typically on small test environment with limited volume of data. The results of these types of tests do not take into consideration differences between test and production hardware and software environment and contention for resources with many applications in production environments. In this paper we will review application of the modeling for extending the results of performance testing, predicting how new application will perform in production environment. We will review how modeling results can be used to evaluate different options and justify decisions during design, development, implementation and performance management of the production environment. &copy; 2017 ACM.},
key = {Big data},
keywords = {Application programs;Benchmarking;Software testing;},
note = {Big data applications;Data infrastructure;Performance assurances;Performance engineering;Performance Model;Performance prediction;Performance testing;},
URL = {http://dx.doi.org/10.1145/3053600.3053624},
} 


@inproceedings{20162102421542 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Challenges with applying performance testing methods for systems deployed on shared environments with indeterminate competing workloads: Position paper},
journal = {ICPE 2016 Companion - Companion Publication for 7th ACM/SPEC International Conference on Performance Engineering},
author = {Bondi, Andre B.},
year = {2016},
pages = {41 - 44},
address = {Delft, Netherlands},
abstract = {There is a tendency to move production environments from corporate-owned data centers to cloud-based services. Users who do not maintain a private production environment might not wish to maintain a private performance test environment either. The application of performance engineering methods to the development and delivery of software systems is complicated when the form and or parameters of the target deployment environment cannot be controlled or determined. The difficulty of diagnosing the causes of performance issues during testing or production may be increased by the presence of highly variable workloads on the target platform that compete with the application of interest for resources in ways that might be hard to determine. In particular, performance tests might be conducted in virtualized environments that introduce factors influencing customer-affecting metrics (such as transaction response time) and observed resource usage. Observed resource usage metrics in virtualized environments can have different meanings from those in a native environment. Virtual machines may suffer delays in execution. We explore factors that exacerbate these complications. We argue that these complexities reinforce the case for rigorously using software performance engineering methods rather than diminishing it. We also explore possible performance testing methods for mitigating the risk associated with these complexities.},
key = {Software testing},
keywords = {Application programs;Testing;Virtual reality;},
note = {Cloud performance;Performance engineering;Performance issues;Performance measurements;Performance testing;Production environments;Software performance engineerings;Virtualized environment;},
URL = {http://dx.doi.org/10.1145/2859889.2859895},
} 


@inbook{20172403758303 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Study on the Establishment of Dynamic Performance Test Environment for the Digital Protective Relay using RTDS},
journal = {Power Plants and Power Systems Control 2006},
author = {Jang, ByungTae and Choe, ChangYoul and Jung, GilJo},
year = {2007},
pages = {143 - 146},
abstract = {This chapter presents a study on the establishment of dynamic performance test environment for the digital protective relay using real time digital simulator (RTDS). A performance test of digital protective relay is divided into three parts, which include a static test, a dynamic test, and EMC test. Among these, a dynamic test the most important, but it is not easy to diffuse a technique for dynamic test because of the intricate approach to real time digital simulator. To solve these problems, Korea Electric Power Research Institute (KEPRI) has established environments for performance test, which consist of a system model and a performance test procedure for the dynamic test. Differing from the general test equipment, RTDS has a strong point to examine real time close-loop test. Since users should articulately use both software (PSCAD) and hardware (RTDS), it is difficult for the users to access a dynamic performance test. The system modeling was performed by using equivalent impedance data of transmission line, equivalent impedance data of bus, and no load loss data of transformer. When carrying out performance test of the digital protective relay by using RTDS in domestic and overseas organizations, engineers can utilize this procedure for examining reliability and propriety in terms of the result of performance verification test. &copy; 2007 Elsevier Ltd All rights reserved.},
key = {Software testing},
keywords = {Electric fault currents;Electromagnetic compatibility;Equipment testing;Equivalent circuits;Mechanisms;Relay protection;},
note = {Digital protective relay;Dynamic performance tests;Equivalent impedance;Korea electric power research institutes;Performance tests;Performance verification;Real time digital simulator;Test equipments;},
URL = {http://dx.doi.org/10.1016/B978-008046620-0/50024-4},
} 


@inproceedings{20164102888346 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A search based approach for stress-testing integrated circuits},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Eljuse, Basil and Walkinshaw, Neil},
volume = {9962 LNCS},
year = {2016},
pages = {80 - 95},
issn = {03029743},
address = {Raleigh, NC, United states},
abstract = {In order to reduce software complexity and be power efficient, hardware platforms are increasingly incorporating functionality that was traditionally administered at a software-level (such as cache management). This functionality is often complex, incorporating multiple processors along with a multitude of design parameters. Such devices can only be reliably tested at a &lsquo;system&rsquo; level, which presents various testing challenges; behaviour is often non-deterministic (from a software perspective), and finding suitable test sets to &lsquo;stress&rsquo; the system adequately is often an inefficient, manual activity that yields fixed test sets that can rarely be reused. In this paper we investigate this problem with respect to ARM&rsquo;s Cache Coherent Interconnect (CCI) Unit. We present an automated search-based testing approach that combines a parameterised testgeneration framework with the hill-climbing heuristic to find test sets that maximally &lsquo;stress&rsquo; the CCI by producingmuch larger numbers of data stall cycles than the corresponding manual test sets. &copy; Springer International Publishing AG 2016.},
key = {Software testing},
keywords = {Integrated circuit interconnects;Integrated circuits;Reconfigurable hardware;Software engineering;},
note = {Automated searches;Cache coherent interconnect;Cache management;Design parameters;Hardware platform;Multiple processors;Software complexity;Stress Testing;},
URL = {http://dx.doi.org/10.1007/978-3-319-47106-8_6},
} 


@article{20165103138448 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Study on application of WSN in circuit design and performance test of energy management},
journal = {Romanian Review Precision Mechanics, Optics and Mechatronics},
author = {Ma, Yan-Li and Liu, Yu and Dong, Bei-Bei and Chen, Gui-Qiang and Zhang, Xiao},
volume = {2016},
number = {50},
year = {2016},
pages = {253 - 258},
issn = {15845982},
abstract = {In recent years, with the development of science and technology, wireless sensor network (WSN) technology, one of the most important technology in the world, has received considerable attention from both expert and scholar and enterprises. Energy consumption and supply of the node are the key problems to be solved in the development and application of WSN technology. Based on these issues, WSN was used in circuit design and performance test. Based on the main research background of solar energy and wind energy, energy management circuit is designed and its strategy is studied. Existing application technology is used to settle problems occurred during the application of WSN. Two-circuit ways to collect solar energy and different performances of lithium battery and super-capacitor are studied based on energy storage. Weak current test system is used as an effective means to debug low-power circuits. Star configuration of WSN test platform is established based on designed energy capture node of electric system. Independent charging efficiency test is used to conclude result that under the test environment, energy collection of node satisfies its continuous and effective work. Thus, this circuit is proved to be practical and feasible, and theoretical and technical support is provided for applying WSN. In conclusion, this circuit is worthy widely promotion. &copy; 2016, Editura Cefin. All rights reserved.},
key = {Wireless sensor networks},
keywords = {Energy management;Energy utilization;Integrated circuit manufacture;Lithium batteries;Low power electronics;Program debugging;Sensor nodes;Solar energy;Timing circuits;Wind power;},
note = {Application technologies;Charging efficiency;Development and applications;Development of science and technologies;Energy collection;Low-power circuit;Technical support;Weak currents;},
} 


@inproceedings{20165203175826 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Virtual instrumentation for no-load testing of induction motor},
journal = {Proceedings - 2016 IEEE International Power Electronics and Motion Control Conference, PEMC 2016},
author = {Subtirelu, Gheorghe-Eugen and Dobriceanu, Mircea and Linca, Mihaita},
year = {2016},
pages = {854 - 859},
address = {Varna, Bulgaria},
abstract = {The main objective of this paper is to solve a practical and current problem, by taking advantage of the virtual instrumentation in testing electrical machines. The abilities of virtual instrumentation are used to data acquisition, measurement and analyze the values of no-load testing's parameters for three-phase induction motor. The virtual measurement system bench is designed and consist from two principal components: the hardware components (six LEM transducers for measuring three voltages and three currents; elements for signal conditioning and power transducers; USB multifunction Input / Output module; a personal computer) and the software components (operating system for the computer; drivers for the acquisition and manipulation of data; virtual instrument for calculation and graphical presentation of results). The LabVIEW graphical programming environment is used for designing virtual instrument. This virtual measurement system bench is an easy to use device which can be used in engineering education laboratories from universities or in electrical machines testing workbenches; it is capable of data acquisition, storage or memorization on different media, visualization of different graphs or analysis on-line or off-line of the results obtained. The virtual measurement system described in the paper can work independently (in the Simulation mode or Real time Acquisition mode) or integrated as part of a future complex virtual system for measurement and analysis in the domain of electrical machines testing workbenches. &copy; 2016 IEEE.},
key = {Electric variables measurement},
keywords = {Automobile engines;Computer graphics;Computer hardware;Computer operating systems;Data acquisition;Data visualization;Digital instruments;Digital storage;Distance education;Electric machinery;Induction motors;Load testing;Motion control;Personal computers;Power control;Power electronics;Transducers;},
note = {Graphical presentations;Labview graphical programming;Measurement and analysis;Principal Components;Real time acquisition;Three phase induction motor;Virtual Instrumentation;Virtual measurement system;},
URL = {http://dx.doi.org/10.1109/EPEPEMC.2016.7752106},
} 


@inproceedings{1993081001700 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stress testing a non-existent application tools, methods, and results},
journal = {CMG Proceedings},
author = {Brey, Jack},
year = {1992},
pages = {520 - 529},
address = {Reno, NV, USA},
abstract = {How do you test an application that doesn't exist yet? How do you make an architectural decision when there are no similar applications in production anywhere? This case study covers the decision making process, the tools selected, the test plan, and the test results of an analysis used to choose between the use of a CASE tool and ACMS for a proposed application. The study involved use of both an analytic model and a benchmarking tool to establish the saturation point of a VAX 9000 under each alternative. The paper will discuss creation of the models, the results of the modeling activities, and the criteria that went into the actual decision.},
key = {Computer software},
keywords = {Decision theory;Testing;},
note = {Software development;},
} 


@article{20113614302583 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Application and performance test of a micro-machined unipolar charger for real-time measurements of exhaust particles from a diesel engine vehicle},
journal = {Journal of Aerosol Science},
author = {Lee, Sang-Gu and Hyun, Junho and Park, Dongho and Hwang, Jungho and Kim, Yong-Jun},
volume = {42},
number = {11},
year = {2011},
pages = {747 - 758},
issn = {00218502},
abstract = {Characterization of particulate matter (PM) emitted from diesel vehicle exhaust requires a real-time measurement sensor to record particle concentrations under transient tests. Recently, a micro-machined unipolar charger (MUC) based on a micro-electromechanical system (MEMS) was introduced and evaluated to test aerosol particles on a laboratory scale. We present the performance characteristics of the MUC for its potential use as a sensor for diesel PM emissions. A correlation equation was derived from particle loss experiments and tandem differential mobility analyzer (TDMA) measurements in the laboratory, which was used to convert the current measurement datum into a total particle number concentration. Under various idling and driving conditions of a diesel vehicle, the electrical signals from the MUC were verified to have followed the trend of the total number concentrations of diesel PM measured using a condensation particle counter (CPC). When the diesel PM concentrations measured using the CPC were within the range of 2&times;10<sup>4</sup>-2&times;10<sup>5</sup>#/cm<sup>3</sup>, the total number concentrations, estimated using a correlation equation, were in agreement with the CPC data. &copy; 2011 Elsevier Ltd.<br/>},
key = {Particles (particulate matter)},
keywords = {Diesel engines;Diesel locomotives;Electric corona;MEMS;Time division multiple access;Time measurement;Vehicles;},
note = {Condensation particle counters;Corona discharges;Micro electromechanical system (MEMS);Micro-machined;Particle number concentration;Tandem differential mobility analyzers;Total number concentrations;Unipolar charging;},
URL = {http://dx.doi.org/10.1016/j.jaerosci.2011.07.003},
} 


@inproceedings{20132216378712 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research of load testing and result application based on loadrunner},
journal = {Proceedings of the 2012 National Conference on Information Technology and Computer Science, CITCS 2012},
author = {Zhang, Hui-Li and Zhang, Shu and Li, Xiao-Jie and Zhang, Pei and Liu, Shao-Bo},
year = {2012},
pages = {1069 - 1072},
address = {Lanzhou, China},
abstract = {In this paper, we made the plan of a load testing, and got results by means of the LoadRunner which is an automatic testing tool. We fully considered the characteristics of the electronic commerce application, designed the reasonable test cases, and simulated the practical scenario. In the process of running LoadRunner, we arranged the appropriate transactions and rendezvous, and designed the truthful test network environment. The plan was applied to the load testing phase of the telecommunication equipment sales system of special products. We analyzed the load testing results, proposed the improving measures, and realized the optimization of the telecommunication equipment sales system. &copy; 2012. The authors - Published by Atlantis Press.},
key = {Information technology},
keywords = {Automatic testing;Computer science;Load testing;Telecommunication equipment;},
note = {Electronic commerce applications;Loadrunner;Test case;Test network;Test scripts;Testing phase;Transaction;},
} 


@article{20173804193684 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Rational decision framework for designing pile-load test programs},
journal = {Geotechnical Testing Journal},
author = {Najjar, S. and Saad, G. and Abdallah, Y.},
volume = {40},
number = {2},
year = {2017},
pages = {302 - 316},
issn = {01496115},
abstract = {There is currently an inconsistency in the recommendations that are available in pile-design codes and practices regarding the required number of proof-load tests and the level of the proof loads for piles. In this paper, a pre-posterior decision-making framework is proposed to allow for selecting the optimal pile-load test program that would result in the maximum expected benefit to a project, while maintaining a target level of reliability in the pile design at the site. This proposed methodology is original, practical, and is based on site-specific information that is unique to any given project. The proposed methodology is based on a robust Bayesian approach that allows for updating the capacity distribution of piles at a site, given the results of the proof-load test program. The efficiency of the proposed decision framework is demonstrated by applying it on a practical design example that involves piles that are driven in a site consisting of medium-dense sand. Results indicate that: (1) the optimum proof-load level that results in the maximum benefit to the example project is 1.5 times the design load, (2) the optimum number of tests is a function of the number of piles (superstructure load) and the costs of the pile construction and testing, (3) as the number of piles in the site increases, the optimal required number of proof-load tests also increase, with the optimum number of pile-load tests being around 1 % to 2 % of the total number of piles at the site, and (4) the optimal number of pile-load tests increases as the cost of pile construction and installation increases and as the cost of implementing the pile test program decreases. Copyright &copy; 2017 by ASTM International.},
key = {Piles},
keywords = {Bayesian networks;Costs;Decision making;Decision theory;Load testing;Reliability;Reliability analysis;Software testing;Statistical tests;Test facilities;Testing;},
note = {Bayesian approaches;Capacity distribution;Decision framework;Decision-making frameworks;Deep foundations;Field testing;Pile test program;Site-specific information;},
URL = {http://dx.doi.org/10.1520/GTJ20160088},
} 


@inproceedings{20114014398894 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Recent successes and changes of the HPCMP sustained systems performance test},
journal = {Proceedings - 2010 DoD High Performance Computing Modernization Program Users Group Conference, HPCMP UGC 2010},
author = {Bennett, Paul M. and Brown, Laura L.},
year = {2011},
pages = {453 - 462},
address = {Schaumburg, IL, United states},
abstract = {The sustained systems performance (SSP) test has been implemented on certain High Performance Computing Modernization Program (HPCMP) HPC systems in order to quantitatively evaluate updates to system software, hardware repairs, job queuing policy modifications, and revisions to the job scheduler as necessary. The test employs codes used in the system acquisition cycle with proven migration capability to HPCMP HPC systems and non-empirical tests for numerical accuracy. Metrics such as compilation time, queue wait time, benchmark execution time, and total test throughput time are gathered and compared against metric data from previous tests to monitor the systems under test while minimizing impact to the users. Jobs failing to execute properly or in anomalously short or long times are investigated, and the results are reported to system administrators and center directors at each center for appropriate actions. During the past year, the SSP test has been instrumental in surfacing configuration issues with the PBS scheduler and performance issues on several HPC systems. Additionally, the frequency of the SSP test on systems procured in Technology Insertion 2009 (TI-09) and thereafter has increased, with attendant changes in the test cases comprising the test. The SSP test continues to play an important role in monitoring the quality of service delivering HPC to HPCMP users at the system, DoD Supercomputing Resource Center, and vendor levels. &copy; 2011 IEEE.<br/>},
key = {Software testing},
keywords = {Modernization;Quality of service;Scheduling;},
note = {High performance computing modernization programs;Numerical accuracy;Performance issues;Sustained systems;System acquisition;System administrators;Systems under tests;Technology insertion;},
URL = {http://dx.doi.org/10.1109/HPCMP-UGC.2010.46},
} 


@inproceedings{20124415618550 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A novel approach of automation testing on mobile devices},
journal = {2012 International Conference on Computer and Information Science, ICCIS 2012 - A Conference of World Engineering, Science and Technology Congress, ESTCON 2012 - Conference Proceedings},
author = {Nagowah, Leckraj and Sowamber, Gayeree},
volume = {2},
year = {2012},
pages = {924 - 930},
address = {Kuala Lumpur, Malaysia},
abstract = {Mobile phones and mobile applications have now become an integral part of our everyday life. Mobile application testing plays a pivotal role in making the mobile applications more reliable and defect free. Existing test automation tools have been tailored to perform mobile test automation through mobile emulators. Other tools require the mobile device where the application is installed, to be connected to a computer so that the tests can be run. Obviously, the results obtained from emulators often differ from those obtained on actual mobile devices. To our best knowledge only a few solutions for creating automated tests of mobile applications exist and their functionality is very limited. In this paper, we introduce the idea of implementing a mobile test automation framework MobTAF which performs mobile test automation on the mobile device where connection to a computer is not required. The framework moves the testing infrastructure to the phone, to support test situations that cannot easily be replicated with an emulator. A prototype application was then implemented to test the mobile automation framework, MobTAF. The results prove that MobTAF framework is an efficient way of performing mobile application tests directly on the mobile devices. &copy; 2012 IEEE.<br/>},
key = {Software testing},
keywords = {Application programs;Automation;Mobile computing;Mobile devices;Telephone sets;},
note = {Automation testing;Mobile application testing;Mobile applications;Mobile device test automations;Mobile test automation frameworks;Mobile testing;Test automation tool;Testing infrastructure;},
URL = {http://dx.doi.org/10.1109/ICCISci.2012.6297158},
} 


@inproceedings{20082111274878 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {CROWNBench: A grid performance testing system using customizable synthetic workload},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Yang, Xing and Li, Xiang and Ji, Yipeng and Sha, Mo},
volume = {4976 LNCS},
year = {2008},
pages = {190 - 201},
issn = {03029743},
address = {Shenyang, China},
abstract = {The Grid middleware must be developed iteratively and incrementally, so Grid performance testing is critical for middleware developers of Grid system. Considering the special characters of Grid system, in order to gain meaningful and comprehensive results of performance testing, it is necessary to implement testing on real Grid environment with various types of workload. CROWNBench, as described in this paper, is a system for helping Grid middleware developers to evaluate middleware design and implement using customizable synthetic workload. Middleware developers can customize testing workload basing on the model of Grid workload derived from real workload traces, including its structure and parameters, and then workload is synthesized automatically and contained jobs will be submitted by CROWNBench in a distributed manner. CROWNBench defines several metrics for measuring Grid performance as automatic testing results. The experiment, which used CROWNBench to test the performance of Grid system with CROWN Grid middleware, shows that the system already finished have accomplished its prospective goal. It can implement Grid performance testing in an efficient, flexible, controllable, replayable and automatic way to help middleware developers evaluate and improve their products effectively. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Software testing},
keywords = {Grid computing;Middleware;Parameter estimation;Problem solving;Software design;},
note = {CROWNBench;Grid performance;Performance testing;Synthetic workloads;},
URL = {http://dx.doi.org/10.1007/978-3-540-78849-2_21},
} 


@inproceedings{20144900278479 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {LTF: A model-based load testing framework for web applications},
journal = {Proceedings - International Conference on Quality Software},
author = {Zhou, Junzan and Zhou, Bo and Li, Shanping},
year = {2014},
pages = {154 - 163},
issn = {15506002},
address = {Dallas, TX, United states},
abstract = {Performance evaluation is an important approach for various systems to guarantee the quality of their services. However, most performance evaluation tasks face a problem: how to model the system workload? Traditional workload models have limitations when it comes to modeling different workloads. In this paper, we propose a workload model for characterizing and generating synthetic web workloads. First, we introduce a Context-based Sequential Action Model to describe users that exhibit similar access patterns. Next, we present a Workload Parameter Specification Language to describe workload parameters for workload generation. Then, we introduce our load-testing framework based on the proposed model. The representativeness and features of our model are demonstrated by comparing it to other models. Experiments show that our framework can generate accurate and stable synthetic workloads.<br/> &copy; 2014 IEEE.},
key = {Load testing},
keywords = {Models;Quality control;Specification languages;},
note = {Parameter specification;performance;Performance evaluations;Synthetic workloads;System workloads;Testing framework;Workload characterization;Workload generation;},
URL = {http://dx.doi.org/10.1109/QSIC.2014.53},
} 


@inproceedings{20174004232566 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a structural load testing tool},
journal = {Proceedings of the 1996 ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 1996},
author = {Yang, Cheer-Sun D. and Pollock, Lori L.},
year = {1996},
pages = {201 - 208},
address = {San Diego, CA, United states},
abstract = {Load sensitive faults cause a program to fail when it is executed under a heavy load or over a long period of time, but may have no detrimental effect under small loads or short executions. In addition to testing the functionality of these programs, testing how well they perform under stress is very important. Current approaches to stress, or load, testing treat the system as a black box, generating test data based on parameters specified by the tester within an operational profile. In this paper, we advocate a structural approach to load testing. There exist many structural testing methods; however, their main goal is generating test data for executing all statements, branches, definition-use pairs, or paths of a program at least once, without consideration for executing any particular path extensively.Our initial work has focused on the identification of potentially load sensitive modules based on a static analysis of the module's code, and then limiting the stress testing to the regions of the modules that could be the potential causes of the load sensitivity. This analysis will be incorporated into a testing tool for structural load testing which takes a program as input, and automatically determines whether that program needs to be load tested, and if so, automatically generates test data for structural load testing of the program. &copy; 1996 ACM.},
key = {Software testing},
keywords = {Black-box testing;Load testing;Static analysis;Structural analysis;Structural loads;Test facilities;},
note = {Black boxes;Load sensitivities;Load-sensitive;Operational profile;Stress Testing;Structural approach;Structural testing;Testing tools;},
URL = {http://dx.doi.org/10.1145/229000.226318},
} 


@inproceedings{20142417826528 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A web automation testing framework over cloud},
journal = {Applied Mechanics and Materials},
author = {Chen, Min Gang and Zhong, Wen Bin and Chen, Wen Jie and Hu, Yun and Cai, Li Zhi},
volume = {556-562},
year = {2014},
pages = {6149 - 6153},
issn = {16609336},
address = {Shanghai, China},
abstract = {With the increasingly fast-paced software releasing or updating, research on the method of an efficient software automation testing framework based on cloud computing has become particularly important. In this paper, we propose an automation testing framework over cloud. We also describe some key technologies in the aspect of the design of hierarchical test case and automatic distribution of test cases in the cloud computing environment. Testing experiments show that our framework can take advantage of on-demand testing resources in the cloud to improve the efficiency of automation testing. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Software testing},
keywords = {Automation;Cloud computing;Computer systems;Information technology;},
note = {Automation testing;Cloud computing environments;Cloud testing;Key technologies;Software automation;TaaS;Testing resources;Web automation;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.556-562.6149},
} 


@inproceedings{20125015790116 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Building a TaaS platform for web service load testing},
journal = {Proceedings - 2012 IEEE International Conference on Cluster Computing, CLUSTER 2012},
author = {Yan, Minzhi and Sun, Hailong and Wang, Xu and Liu, Xudong},
year = {2012},
pages = {576 - 579},
address = {Beijing, China},
abstract = {Web services are widely known as the building blocks of typical service oriented applications. The performance of such an application system is mainly dependent on that of component web services. Thus the effective load testing of web services is of great importance to understand and improve the performance of a service oriented system. However, existing Web Service load testing tools ignore the real characteristics of the practical running environment of a web service, which leads to inaccurate test results. In this work, we present WS-TaaS, a load testing platform for web services, which enables load testing process to be as close as possible to the real running scenarios. In this way, we aim at providing testers with more accurate performance testing results than existing tools. WS-TaaS is developed on the basis of our existing Cloud PaaS platform: Service4All. First, we provide detailed analysis of the requirements of Web Service load testing and present the conceptual architecture and design of key components. Then we present the implementation details of WS-TaaS on the basis of Service4All. Finally, we perform a set of experiments based on the testing of real web services, and the experiments illustrate that WS-TaaS can efficiently facilitate the whole process of Web Service load testing. &copy; 2012 IEEE.},
key = {Websites},
keywords = {Cloud computing;Cluster computing;Experiments;Load testing;Web services;},
note = {Accurate performance;Application systems;Building blockes;Conceptual architecture;Service loads;Service oriented application;Service Oriented Systems;Testing platforms;Testing process;Testing tools;Whole process;},
URL = {http://dx.doi.org/10.1109/CLUSTER.2012.20},
} 


@inproceedings{20130916048097 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {WS-TaaS: A testing as a service platform for Web Service load testing},
journal = {Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS},
author = {Yan, Minzhi and Sun, Hailong and Wang, Xu and Liu, Xudong},
year = {2012},
pages = {456 - 463},
issn = {15219097},
address = {Singapore, Singapore},
abstract = {Web services are widely known as the building blocks of typical service oriented applications. The performance of such an application system is mainly dependent on that of component web services. Thus the effective load testing of web services is of great importance to understand and improve the performance of a service oriented system. However, existing Web Service load testing tools ignore the real characteristics of the practical running environment of a web service, which leads to inaccurate test results. In this work, we present WS-TaaS, a load testing platform for web services, which enables load testing process to be as close as possible to the real running scenarios. In this way, we aim at providing testers with more accurate performance testing results than existing tools. WS-TaaS is developed on the basis of our existing Cloud PaaS platform: Service4All. First, we briefly introduce the functionalities and main components of Service4All. Second, we provide detailed analysis of the requirements of Web Service load testing and present the conceptual architecture and design of key components. Third, we present the implementation details of WS-TaaS on the basis of Service4All. Finally, we perform a set of experiments based on the testing of real web services, and the experiments illustrate that WS-TaaS can efficiently facilitate the whole process of Web Service load testing. Especially, comparing with existing testing tools, WS-TaaS can obtain more effective and accurate test results. &copy; 2012 IEEE.},
key = {Web services},
keywords = {Cloud computing;Computer systems;Experiments;Load testing;Websites;},
note = {Accurate performance;Application systems;Building blockes;Conceptual architecture;Service oriented application;Service Oriented Systems;Testing as a services;Testing platforms;Testing process;Testing tools;Whole process;},
URL = {http://dx.doi.org/10.1109/ICPADS.2012.69},
} 


@article{20083611516113 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test of a 1 MW class HTS synchronous motor for industrial application},
journal = {Physica C: Superconductivity and its Applications},
author = {Kwon, Y.K. and Kim, H.M. and Baik, S.K. and Lee, E.Y. and Lee, J.D. and Kim, Y.C. and Lee, S.H. and Hong, J.P. and Jo, Y.S. and Ryu, K.S.},
volume = {468},
number = {15-20},
year = {2008},
pages = {2081 - 2086},
issn = {09214534},
abstract = {This paper deals with development activities of high temperature superconducting (HTS) synchronous motor at DOOSAN heavy industry and Korea Electrotechnology Research Institute (KERI) in Korea, and is sponsored by DAPAS program which is supported by Korean government. The final aim of the project is realization of HTS motor in the field of industry such as large driving pumps, fans and compressors for utility and industrial environments. At present time, 1 MW HTS motor is developed for the purpose to fully represent the design and manufacturing issues for the larger capacity machine. The number of pole and rotating speed of machine are 2 pole and 3600 rpm. The HTS field coil of the developed motor is cooled by way of neon thermosyphon mechanism and the stator coil is cooled by water through hollow copper conductor. This paper describes status of 1 MW HTS motor development, such as design, fabrication and performance test results, which was conducted at steady state in generator mode and motor mode. &copy; 2008 Elsevier B.V. All rights reserved.<br/>},
key = {Synchronous motors},
keywords = {Electric motors;High temperature superconductors;Poles;Stators;Superconducting coils;},
note = {Air-core stator;Development activity;High temperature superconducting;HTS field coil;Hts synchronous motors;Industrial environments;Manufacturing issue;Rotating cryogenic cooling system;},
URL = {http://dx.doi.org/10.1016/j.physc.2008.05.249},
} 


@inproceedings{20104413349348 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A reactivity-based framework of automated performance testing for web applications},
journal = {Proceedings - 9th International Symposium on Distributed Computing and Applications to Business, Engineering and Science, DCABES 2010},
author = {Gao, Tiantian and Ge, Yujia and Wu, Gongxin and Ni, Jinlong},
year = {2010},
pages = {593 - 597},
abstract = {To improve the reliability and feasibility of web applications, performance testing is very important for satisfying users. For reducing the cost and improve the efficiency of performance testing, we propose a new reactivity-based performance testing framework in this paper. We also provide a complete approach to generate test cases automatically from original web logs. First our approach retrieves user patterns through logs at the server side. Then, metrics derived from users' perspective are applied and usage pattern from client side are gained. At last test case can be generated automatically by solving an optimization problem through an evolutionary algorithm. &copy; 2010 IEEE.},
key = {Automatic test pattern generation},
keywords = {Distributed computer systems;Optimization;Web crawler;},
note = {Automated test case generation;Optimization problems;Performance testing;Performance testing framework;Server sides;Testing framework;Usage patterns;WEB application;},
URL = {http://dx.doi.org/10.1109/DCABES.2010.127},
} 


@inproceedings{20105013485991 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {XACML policy performance evaluation using a flexible load testing framework},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
author = {Butler, Bernard and Jennings, Brendan and Botvich, Dmitri},
year = {2010},
pages = {648 - 650},
issn = {15437221},
abstract = {The performance and scalability of access control systems is growing more important as organisations deploy ever more complex communications and content management systems. Fine-grained access control is becoming more pervasive, so decisions are more frequent and policy sets are larger. We outline a flexible performance testing framework that accepts XACML PDP implementations (in the server component) and submits representative access control requests (from the client component) in a representative temporal ordering. The framework includes instrumentation and analysis modules to support performance experiments. We describe an initial realization of the framework and report on initial experiments comparing the performance of the SunXACML and Enterprise XACML PDPs.<br/>},
key = {Access control},
keywords = {Distributed computer systems;Load testing;},
note = {Access control policies;Content management system;Performance and scalabilities;Performance evaluations;Performance experiment;Performance testing framework;Server components;Testing framework;},
URL = {http://dx.doi.org/10.1145/1866307.1866385},
} 


@inproceedings{20083911593688 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Load testing an AJAX application},
journal = {Proceedings of the International Conference on Information Technology Interfaces, ITI},
author = {Habul, Aida and Kurtovic, Ezudin},
year = {2008},
pages = {729 - 732},
issn = {13301012},
address = {Cavtat/Dubrovnik, Croatia},
abstract = {This paper presents a methodology for load testing an Ajax application. WebLOAD, an open source tool for performance testing, is used to simulate a huge number of client requests to the server. The load testing is used to evaluate and compare different scenarios on the system performance. In order to avoid misleading results, load testing of Ajax applications should incorporate not only server-side but also clientside code, because it can have a significant impact in determining the generated load.<br/>},
key = {Load testing},
note = {Ajax;Client request;Client sides;Open source tools;Performance testing;Server sides;Work-load models;},
URL = {http://dx.doi.org/10.1109/ITI.2008.4588501},
} 


@inproceedings{2005249153844 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {DiPerF: An automated distributed Performance testing framework},
journal = {Proceedings - IEEE/ACM International Workshop on Grid Computing},
author = {Dumitrescu, Catalin and Raicu, Ioan and Ripeanu, Matei and Foster, Ian},
year = {2004},
pages = {289 - 296},
issn = {15505510},
address = {Pittsburgh, PA, United states},
abstract = {We present DiPerF, a distributed performance-testing framework, aimed at simplifying and automating service performance evaluation. DiPerF coordinates a pool of machines that test a target service, collects and aggregates performance metrics, and generates performance statistics. The aggregate data collected provide information on service throughput, on service 'fairness' when serving multiple clients concurrently, and on the impact of network latency on service performance. Furthermore, using this data, it is possible to build predictive models that estimate a service performance given the service load. We have tested DiPerF on 100+ machines on two testbeds, Grid3 and PlanetLab, and explored the performance of job submission services (pre-WS GRAM and WS GRAM) included with Globus Toolkit&reg; 3.2. &copy; 2004 IEEE.},
key = {Distributed computer systems},
keywords = {Automation;Benchmarking;Data acquisition;Data reduction;HTTP;Local area networks;Mathematical models;Metric system;Quality of service;Synchronization;},
note = {DiPerF;Job submission services;Performance testing framework;Target services;},
URL = {http://dx.doi.org/10.1109/GRID.2004.21},
} 


@inproceedings{20130916048989 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Thermal performance testing of a high-temperature ESP motor for SAGD applications},
journal = {Proceedings - SPE Annual Technical Conference and Exhibition},
author = {Waldner, Leon and Wonitoy, Kelvin and Klaczek, Wayne and Noonan, Shauna},
volume = {6},
year = {2012},
pages = {4636 - 4644},
address = {San Antonio, TX, United states},
abstract = {During 2012, BakerHughes, ConocoPhillips and Nexen Inc. continued their research partnership [Waldner 2011] with a new experimental test program focused on the thermal performance of Electric Submersible Pump (ESP) systems for Steam Assisted Gravity Drainage (SAGD) applications, which was completed in the high-temperature flow loop at C-FER Technologies. Accurately monitoring the internal temperature of the ESP motor is a key consideration when trying to increase the operational longevity of an ESP system for any application; however, as the SAGD process develops, understanding this temperature profile has become more critical. This test program included several tests at various fluid temperatures and ESP operating conditions that helped determine the thermal performance of the ESP motor. Another unique aspect of this test program was the incorporation of two different temperature monitoring methods at approximately the same position on the internal and external base of the ESP motor: one internal probe positioned near the motor windings via a fiber optic sensor and one external skin temperature RTD positioned on the motor surface to monitor this important temperature differential. This paper presents the equipment and instrumentation used, and demonstrates some of the more interesting test results, thus providing further insight into the thermal performance of this ESP motor under representative SAGD conditions between 220&deg;C (428&deg;F) and 250&deg;C (482&deg;F). Copyright 2012, Society of Petroleum Engineers.},
key = {Mixed convection},
keywords = {Exhibitions;Temperature measuring instruments;Test facilities;},
note = {ConocoPhillips;Electric submersible pumps;Experimental test;Fluid temperatures;High temperature;High-temperature flows;Internal temperature;Motor windings;Operating condition;Skin temperatures;Steam-assisted gravity drainages;Temperature differential;Temperature monitoring;Temperature profiles;Test program;Thermal Performance;Thermal performance testing;},
} 


@article{1984070110764 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {'ASAP': A microcomputer-based automated safety and performance testing system},
journal = {Journal of clinical engineering},
author = {Eschelbach, R.E.},
volume = {9},
number = {1},
year = {1984},
pages = {21 - 27},
issn = {03638855},
abstract = {An HP-85 microcomputer programmed in BASIC was interfaced to a PEI 2000 safety analyzer via an HP-6942A Multiprogrammer and appropriate interface cards. This configuration allows automated safety and performance testing as well as report generation. The system is operated by means of a menu displayed on a built-in CRT and the keyboard. Data are displayed and then stored on the built-in cassette unit. Additional testing features are easily added with minimal software development, since all programming is in BASIC and all interface drivers are part of the hardware.},
key = {BIOMEDICAL EQUIPMENT},
keywords = {COMPUTER PROGRAMMING LANGUAGES - BASIC;COMPUTERS, MICROPROCESSOR - Medical Applications;DATA STORAGE, MAGNETIC - Tape;DISPLAY DEVICES - Medical Applications;MAINTENANCE - Computer Applications;},
note = {AUTOMATED PERFORMANCE TESTING;AUTOMATED SAFETY TESTING;MICROCOMPUTERS;},
} 


@inproceedings{20130916071124 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {New device design and performance test on gas generator in automobile airbag},
journal = {Proceedings - 2012 International Conference on Control Engineering and Communication Technology, ICCECT 2012},
author = {Tan, Yingxin and Yu, Cunjuan},
year = {2012},
pages = {484 - 487},
address = {Shenyang, Liaoning, China},
abstract = {An new test device to test gas generator performance in automobile airbag is built. It is made up of inflator jar, sliding track, lifting device and data acquisition system. This system can produce an analog signal which is similar to the impact signal of automobile crash. For get suitable data of acceleration and the duration of impact, lots of experiments have been done. When lifting height of inflator jar is 280mm, acceleration peak value is from 80.5g to 90.2g and dash duration is from 6ms to 8ms. They can meet require to detonate gas generator. There were five groups gas generators from SHANXI Jinheng auto-parts Co., LTD was tested and changing track of pressure and acceleration can be known clearly. Then forty-four gas generators contrast test were done separately in China and in USA. Test results from our designed device were very similar to USA device. It was confirmed that the device designed to test gas generator performance by ourselves was successful. &copy; 2012 IEEE.},
key = {Gas generators},
keywords = {Accidents;Automobiles;Communication;},
note = {airbag;Analog signals;Auto-parts;Contrast tests;Data acquisition system;Impact signals;Lifting devices;Lifting height;Mechanical design;New devices;Peak values;Performance tests;Pressure tests;Test device;},
URL = {http://dx.doi.org/10.1109/ICCECT.2012.77},
} 


@article{20174304293205 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Application and performance test of a small aerosol sensor for the measurement of aerosolized DNA strands},
journal = {Aerosol and Air Quality Research},
author = {Yang, Wenming and Zhu, Rong and Zhang, Chao and Li, Zheng},
volume = {17},
number = {10},
year = {2017},
pages = {2358 - 2366},
issn = {16808584},
abstract = {There is an immediate need for aerosol measuring sensors to monitor the size and concentration of DNA strand aerosols in PCR systems. We evaluate the performance of a previously developed small aerosol sensor for its potential use as a component in measuring DNA strand aerosols in PCR system chambers. A detailed derivation of the working principle is presented along with the principles used to determine the dimensions of the stages and the operational parameters. After characterizing the aerosolized DNA strands, experiments were conducted to identify their relationship with measured currents. The experimental results indicate that for aerosolized Escherichia coli DNA strands, the sensor is capable of measuring concentrations from 10<sup>2</sup>cm<sup>&ndash;3</sup>to 10<sup>5</sup>cm<sup>&ndash;3</sup>(from 10<sup>3</sup>cm<sup>&ndash;3</sup>to 10<sup>5</sup>cm<sup>&ndash;3</sup>for particles smaller than 102 nm) and sizes from 100 bp to 1000 bp. There was a slight difference between the results of the sensor and its theoretical model. The sensor exhibited good sensitivity to different concentrations and can detect every 150 bp of strands, indicating its effectiveness in monitoring ultrafine DNA strand aerosols for PCR systems and other applications. &copy; Taiwan Association for Aerosol Research.},
key = {Polymerase chain reaction},
keywords = {Aerosols;DNA;Escherichia coli;},
note = {Aerosol measurement;DNA strands;Measured currents;Operational parameters;Performance tests;Theoretical modeling;Ultrafine;},
URL = {http://dx.doi.org/10.4209/aaqr.2017.01.0054},
} 


@inproceedings{20140617272628 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Comparison of hardware based and software based stress testing of memory IO interface},
journal = {Midwest Symposium on Circuits and Systems},
author = {Querbach, Bruce and Puligundla, Sudeep and Becerra, Daniel and Schoenborn, Zale T. and Chiang, Patrick},
year = {2013},
pages = {637 - 640},
issn = {15483746},
address = {Columbus, OH, United states},
abstract = {In post-silicon testing and validation of circuit functionality, an effective IO stress pattern can identify bugs quickly and provide adequate test coverage. A lot of work has been done to identify the right stress patterns specific to each IO interface. While some patterns can be generic enough to apply to all IOs, other patterns are interface topology specific. In addition to identifying the worst-case pattern, tradeoffs between test-time and test coverage must be made depending on the test goals. Pseudo Random Bit Stream (PRBS) generators are commonly used to generate test patterns because of the adequate frequency content in the PRBS patterns, the ease of implementation, and minimal gate count. This paper introduces an Advanced Pattern Generator and Checker (APGC) based on PRBS that retains all the aforementioned advantages. The APGC was implemented for a DDR memory interface where different LFSRs beat against each other spatially on neighboring IO lanes while rotating this form of aggressor-victim pattern in time. The results of the APGC stress patterns are compared to a form of advanced software-based learning algorithm based patterns that exhaustively search this complete parameter space. The comparison of APGC to software showed that the measured bit error rate (BER) plotted on a Q-scale of both methods is similar for the Receiver side. On the Transmitter side, APGC showed less eye opening than the software. In addition to the margin comparison, on the test execution side, APGC can speed up the test and validation execution time compared to the software by 32 to 2048 times depending on aggressor victim lane width of 8 to 64 lanes. &copy; 2013 IEEE.<br/>},
key = {Software testing},
keywords = {Bit error rate;Testing;},
note = {Advanced softwares;Aggressor-victim;Circuit functionality;Frequency contents;Parameter spaces;Pattern generator;Pseudo random bit stream;Worst case pattern;},
URL = {http://dx.doi.org/10.1109/MWSCAS.2013.6674729},
} 


@inproceedings{20090111821844 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic identification of load testing problems},
journal = {IEEE International Conference on Software Maintenance, ICSM},
author = {Jiang, Zhen Ming and Hassan, Ahmed E. and Hamann, Gilbert and Flora, Parminder},
year = {2008},
pages = {307 - 316},
address = {Beijing, China},
abstract = {Many software applications must provide services to hundreds or thousands of users concurrently. These applications must be load tested to ensure that they can function correctly under high load. Problems in load testing are due to problems in the load environment, the load generators, and the application under test. It is important to identify and address these problems to ensure that load testing results are correct and these problems are resolved. It is difficult to detect problems in a load test due to the large amount of data which must be examined. Current industrial practice mainly involves time-consuming manual checks which, for example, grep the logs of the application for error messages. In this paper, we present an approach which mines the execution logs of an application to uncover the dominant behavior (i.e., execution sequences) for the application and flags anomalies (i.e., deviations) from the dominant behavior. Using a case study of two open source and two large enterprise software applications, we show that our approach can automatically identify problems in a load test. Our approach flags &lt; 0.01% of the log lines for closer analysis by domain experts. The flagged lines indicate load testing problems with a relatively small number of false alarms. Our approach scales well for large applications and is currently used daily in practice. &copy; 2008 IEEE.<br/>},
key = {Load testing},
keywords = {Automation;Computer software maintenance;Enterprise software;Open source software;Open systems;Software testing;},
note = {Application under tests;Automatic identification;Domain experts;Execution sequences;Industrial practices;Large enterprise;Number of false alarms;Software applications;},
URL = {http://dx.doi.org/10.1109/ICSM.2008.4658079},
} 


@article{20174004236999 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Empirical study on the discrepancy between performance testing results from virtual and physical environments},
journal = {Empirical Software Engineering},
author = {Arif, Muhammad Moiz and Shang, Weiyi and Shihab, Emad},
year = {2017},
pages = {1 - 29},
issn = {13823256},
abstract = {Large software systems often undergo performance tests to ensure their capability to handle expected loads. These performance tests often consume large amounts of computing resources and time since heavy loads need to be generated. Making it worse, the ever evolving field requires frequent updates to the performance testing environment. In practice, virtual machines (VMs) are widely exploited to provide flexible and less costly environments for performance tests. However, the use of VMs may introduce confounding overhead (e.g., a higher than expected memory utilization with unstable I/O traffic) to the testing environment and lead to unrealistic performance testing results. Yet, little research has studied the impact on test results of using VMs in performance testing activities. To evaluate the discrepancy between the performance testing results from virtual and physical environments, we perform a case study on two open source systems &ndash; namely Dell DVD Store (DS2) and CloudStore. We conduct the same performance tests in both virtual and physical environments and compare the performance testing results based on the three aspects that are typically examined for performance testing results: 1) single performance metric (e.g. CPU Time from virtual environment vs. CPU Time from physical environment), 2) the relationship among performance metrics (e.g. correlation between CPU and I/O) and 3) performance models that are built to predict system performance. Our results show that 1) A single metric from virtual and physical environments do not follow the same distribution, hence practitioners cannot simply use a scaling factor to compare the performance between environments, 2) correlations among performance metrics in virtual environments are different from those in physical environments 3) statistical models built based on the performance metrics from virtual environments are different from the models built from physical environments suggesting that practitioners cannot use the performance testing results across virtual and physical environments. In order to assist the practitioners leverage performance testing results in both environments, we investigate ways to reduce the discrepancy. We find that such discrepancy can be reduced by normalizing performance metrics based on deviance. Overall, we suggest that practitioners should not use the performance testing results from virtual environment with the simple assumption of straightforward performance overhead. Instead, practitioners should consider leveraging normalization techniques to reduce the discrepancy before examining performance testing results from virtual and physical environments. &copy; 2017 Springer Science+Business Media, LLC},
key = {Software testing},
keywords = {Open source software;Open systems;Virtual reality;},
note = {Large software systems;Performance metrices;Performance metrics;Performance testing;Physical environments;Software performance;Software performance engineerings;Testing environment;},
URL = {http://dx.doi.org/10.1007/s10664-017-9553-x},
} 


@article{1998164083460 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Fetal monitor for non-stress-test screening at home},
journal = {Biomedical Instrumentation and Technology},
author = {Horio, Hiroyuki and Murakami, Masayoshi and Chiba, Yoshihide and Inada, Hiroshi},
volume = {32},
number = {1},
year = {1998},
pages = {39 - 47},
issn = {08998205},
abstract = {A fetal monitoring device that works on battery power was developed for non-stress-test (NST) screening at home. It is small and lightweight that a pregnant woman can monitor fetal Doppler ultrasound and record fetal heart rate (FHR) and uterine contraction data on an attached memory integrated circuits at any time and in any place way from a hospital. The physician can evaluate these data, transmitted via public telephone line, using built-in modem in the monitor. Pregnant women participated in an evaluation of the fetal monitoring system. 648 NST data were transmitted and 6.7 Mbytes were the total amount of data received. The main cause of noise in the data was zero-count data; this noise rate accounted for 4.1% of the data abnormalities.},
key = {Fetal monitoring},
keywords = {Data communication systems;Electronic medical equipment;},
note = {Fetal Doppler ultrasound;Fetal heart rate;Non stress test (NST) screening;},
} 


@inproceedings{20151000615046 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Galileo test range: Performance test results},
journal = {ENC-GNSS 2008 - European Navigation Conference},
author = {Gottifredi, F. and Martinino, F. and Morante, Q. and Eleuteri, M. and Varriale, E. and Valle, V. and Pesci, G.},
year = {2008},
address = {Toulouse, France},
abstract = {The Galileo Test Range (GTR) project is an initiative of Regione Lazio in the frame of its support to the Italian technical research and innovation in satellite navigation. It is born as the Italian National permanent Laboratory for the experimentation and analysis of the Galileo Signal, for testing and certification of user terminals and support services for the development of application services. The development of the GTR is foreseen in two phases: - Phase A = Definition and Start up: implementation of the initial system, based on the generation on ground of navigation signals (GPS-like), using pseudolite technology (4 PSL), and to receive real signals coming from GPS, EGNOS and the new GIOVE-A Experimental Satellite. - Phase B = Full deployment and initialization of the GTR: implementation of the GTR final configuration, not only able to generate Galileo-like signals (from 9 PSL), but also to receive and process real signals coming from Galileo IOV satellites. The Phase A architecture is composed by the following macro segments: - The Analysis &amp; Control Centre composed by the Control Centre (CC) and all the specialized laboratories (i.e. Time, Orbitography, Synchronization, Integrity, R&amp;D); - The Experimental Area (covered by Differential Reference Stations) including the Test Area (covered by the Pseudolites - PSL) The 4 PSL deployed for the Phase A (2 fixed and 2 transportable) are equipped with the following main elements: &bull; an atomic reference clock composed by an OCXO locked to Rb oscillator in order to obtain good short and long term stability; &bull; a dual frequency GPS/SBAS Receiver Assembly; &bull; a GPS-like signal generator &bull; a directional antenna to disseminate the GPS-Like signal in the Test Area The PSL Receiver observables are sent to the GTR-CC and then to the Orbitography Laboratory Facility in charge of the Time Synchronization function of the GTR based on the SynchroNet product of TAS-I. The reference for this Synchronization is given by the Time Laboratory Facility, equipped with an Active Hydrogen Maser and 4 Caesium Clocks. The clock corrections are sent back to the PSL, uploaded in the Navigation Message and broadcasted to the Users in the Test Area. Users equipped with a GPS Receiver can connect it to a PC with a dedicated software (developed by TAS-I) that makes a data fusion between GPS satellites observables and PSL ones so as to compute a better 3D position. If required, the SW can compute a 2D solution using only the Pseudolite observables, Users can compute a 2D position. The PSLs guarantee in a flexible way, thanks to the transportable PSLs, an increased availability of GNSS-like signals in the Test Area that users can use to improve theirs navigation performances. The tests carried out show that the achievable performance in the Test Area with the 4 PSL of Phase A are in the order of 5 m in 3D and 3 m in 2D. With the upgrade foreseen in Phase B in number and type of signal, the performance achievable will improve and potential applications can be satisfied with the use of the PSL technology. The aims of this paper are to present the advantages of the availability of signals generated by PSLs (fixed and transportable) in a controlled area and to present the reached performances for the phase A of the GTR using PSLs. Furthermore it will be presented an overview on the potential applications for this technology that can be a good solution for all those environments that require augmentations in performance and availability (i.e. urban canyons, harbors, container movement, etc&mellip;).},
key = {Global positioning system},
keywords = {Clocks;Data fusion;Directive antennas;Geostationary satellites;Hydrogen masers;Laboratories;Navigation;Orbits;Satellites;Signal receivers;Synchronization;Testing;},
note = {Achievable performance;Application services;Laboratory facilities;Long term stability;Navigation messages;Navigation performance;Satellite navigation;Time synchronization;},
} 


@inproceedings{20150800559873 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research and implementation of a distributed performance testing execution system based on TTCN-3},
journal = {WMSCI 2014 - 18th World Multi-Conference on Systemics, Cybernetics and Informatics, Proceedings},
author = {Liu, Yongpo and Liu, Shuangmei},
volume = {1},
year = {2014},
pages = {108 - 112},
address = {Orlando, FL, United states},
abstract = {A distributed testing system is designed in this paper, which provides a mechanism of node communication, test script deployment, test scheduling, execution-driving and test result collection in distributed environment. A workload model is established, by which testers can describe the performance testing requirement. A performance testing framework is given, which simulates user behaviors in real environment based on virtual users so as to generate workload from the system under test (SUT). It can control the execution of virtual users by TTCN-3 standard interface. After executing the performance testing, test report is generated by extracting log. A method of generating performance test-case is studied by reusing functional test scripts. By executing performance testing on an online bookstore, this paper demonstrates the availability of the method of reusing TTCN-3 functional test scripts and the capability of distributed performance testing system established.<br/>},
key = {Testing},
keywords = {Behavioral research;Cybernetics;Distributed computer systems;},
note = {Distributed testing;Performance testing;System under test;Test suites;TTCN-3;},
} 


@inproceedings{20094512426132 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Ultraviolet through infrared imager performance testing},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Mazzetta, Jason A. and Scopatz, Stephen D.},
volume = {7481},
year = {2009},
pages = {SPIE Europe - },
issn = {0277786X},
address = {Berlin, Germany},
abstract = {The objective of any imaging system is to optimize the amount of pertinent information collected from a scene. Whether it is used for artistic reproduction, scientific research, or camouflage detection, a camera has the same ultimate requirement. In the era of broadband, multi-spectral, hyperspectral, and fused sensor systems, both spectral and spatial data continue to play battling roles in determining which is dominant in how well an imaging system meets its definitive objective. Typically sensor testing requires hardware and software exclusively designed for the spectral region of interest. Thus an imaging system with ultraviolet through infrared imaging capabilities could require three or more separate test benches for sensor characterization. Obviously this not only increases the complexity, and subsequently the cost of testing, but also more importantly tends to produce discontinuous results. This paper will outline the hardware and software developed by the authors that employ identical test methods and shared optics to complete infrared, visible, and ultraviolet sensor performance analysis. Challenges encompassing multiple emitting source switching, splitting, and combining will be addressed along with new single fused type source designs. Decisions related to specifying optics and targets of sufficient quality and construction to provide coverage of the full spectral region will be discussed along with sample performance specifications and data. Test methodology controlled by a single automated software suite will be summarized including modulation transfer function, signal to noise ratio, uniformity, focus, distortion, intrascene dynamic range, and sensitivity. Selected examples of results obtained by this test set will be presented. &copy; 2009 SPIE.<br/>},
key = {Signal to noise ratio},
keywords = {Hardware;Hyperspectral imaging;Image segmentation;Imaging systems;Infrared devices;Infrared radiation;Optics;Software testing;Testing;Thermography (imaging);},
note = {Blackbody;Integrating spheres;Multi-spectral;Ultraviolet;Visible;},
URL = {http://dx.doi.org/10.1117/12.830536},
} 


@article{20134817030778 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Automation testing software that aid in efficiency increase of regressionprocess},
journal = {Recent Patents on Computer Science},
author = {Bhatt, Alok N. and Babu Rajasekhara, M. and Bhatt, Anuja J.},
volume = {6},
number = {2},
year = {2013},
pages = {107 - 114},
issn = {18744796},
abstract = {Accuracy of any software release to the market depends on how efficiently it has been debugged. Debugging is a systematic procedure, used to identify and figure out the cause of defects or any anomaly that the software has and make the software behave as expected. The issues generated by the customer of any company are logged into a database, wherein issues are picked up selected, solved and reverted back to the customers. After solving an issue, it may happen that the issue affects other components which results into a greater number of bugs. The resultant issues are called regression issues. The objective of this paper is to propose and implement a client-server, object-oriented, multiple plat form supporting frame work called RATS Framework which automates the process of regression and thereby helps debug engineers to solve time-consuming regression issues at a faster rate. It automates the process with the help of web-scrapping algorithm (W-S-A) that includes HTML/XML parsing to extract the needed content in the form of GUI-Web Objects, than using Network-Binary Search Algorithm (N/W-BS-A) and Change Finder Algorithm, a variant of Binary Search method, RATS finds out the nearest pass/fail driver build and change in the driver build that cause the new defect in the driver respectively. Because the RATS Framework does this at runtime, client-server approach has to be followed making use of Remote Identification and Installation-Algorithm. Hence RATS framework is a cost effective and time efficient approach for regression issues. The present article has the discussion of few of the patents relevant to automation testing software. &copy; 2013 Bentham Science Publishers.},
key = {Program debugging},
keywords = {Algorithms;Cost effectiveness;Defects;Graphical user interfaces;Object oriented programming;Rats;Regression analysis;Software testing;},
note = {Client server;Cost effective;GUI-Web objects;Multiple platforms;Object oriented;Time-efficient;},
} 


@inproceedings{20101712879826 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Software performance testing scheme using virtualization technology},
journal = {Proceedings of the 4th International Conference on Ubiquitous Information Technologies and Applications, ICUT 2009},
author = {Kim, Gwang-Hun and Moon, Hui-Choun and Song, Gi-Pyeung and Shin, Seok-Kyu},
year = {2009},
address = {Fukuoka, Japan},
abstract = {In this paper, we propose software performance testing scheme using virtualization technology. Generally, people have used software performance testing tool such as load runner and silk performer. However, people should perform software performance testing manually in case of the situation that people cannot use testing tool. It needs a lot of resources such as human resource and computing resource. Therefore, we propose software performance testing scheme using virtualization technology to reduce resource consumption. Proposed scheme can reduce computer resource consumption because virtualization technology can make a number of virtual computers with a small number of physical computers. Also proposed scheme can reduce human resource consumption because, in proposed scheme, management computer can control keyboard and mouse of virtual computers automatically. Simulation result shows that proposed scheme has possibility to be used for software performance testing. &copy; 2009 IEEE.<br/>},
key = {Software testing},
keywords = {Computer resource management;Human resource management;Load testing;Virtual reality;Virtualization;},
note = {Computer resources;Computing resource;Performance testing;Resource consumption;Software performance engineerings;Software performance testing;Test Automation;Virtualization technologies;},
URL = {http://dx.doi.org/10.1109/ICUT.2009.5405721},
} 


@inproceedings{20171903655033 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {AutoPerf: Automated load testing and resource usage profiling of multi-tier internet applications},
journal = {ICPE 2017 - Proceedings of the 2017 ACM/SPEC International Conference on Performance Engineering},
author = {Apte, Varsha and Viswanath, T.V.S. and Gawali, Devidas and Kommireddy, Akhilesh and Gupta, Anshul},
year = {2017},
pages = {115 - 126},
address = {L'Aquila, Italy},
abstract = {A multi-tier Internet server application needs to be analyzed for its performance before it is released. Performance analysis is usually done by (a) load testing of the application on a testbed and (b) building a performance model of the application. While there are a plethora of Web load-generator tools available, there are two problems with these tools: one, the tests have to be configured manually, which can lead to a time-consuming trial-and-error process until the desired performance charts in the appropriate load ranges are obtained; and two, the load generator tools do not produce output that is directly useful for creating a performance model of the application. In this paper, we present AutoPerf, a load generator tool designed to meet two distinct goals, named capacity analysis and profiling. The goal of capacity analysis is to run a comprehensive load test on a Web application, in an appropriately chosen range, at a minimal number of load levels, while still producing an accurate graph of throughput and response time vs load levels. The goal of profiling is to generate a detailed server resource usage profile per request type, without instrumenting the application code. This data (e.g. CPU execution time by Web server for one request) is crucial for parameterizing performance models of the application. AutoPerf intelligently plans and configures its load tests by using analytical results from queuing theory along with some heuristics. Results show that AutoPerf is able to run performance tests very efficiently while still producing an accurate chart of performance metrics. &copy; 2017 ACM.},
key = {Load testing},
keywords = {Queueing theory;},
note = {Capacity analysis;Comprehensive loads;Multi-tier internets;Performance;Performance analysis;Performance metrics;Profilers;Trial-and-error process;},
URL = {http://dx.doi.org/10.1145/3030207.3030222},
} 


@inproceedings{1997483850455 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of the North American CDMA system, using an envelope simulator},
journal = {Annual Wireless Communications Conference, Proceedings},
author = {Mahmoudi, R. and Tauritz, J.L.},
year = {1997},
pages = {84 - 88},
address = {Boulder, CA, USA},
abstract = {The growing use of spread spectrum techniques for personal communications (PCS) in Japan and USA is proving to be an enormous stimulus for the study of system impact on component design. New and innovative techniques are required to translate system criteria into component specifications. In this paper we have studied the performance of the `North American Digital Cellular, IS-95' system proposed by QUALCOMM, under the influence of spurious signals using the new `Circuit Envelope Simulator' in HP-EESOF'S Microwave Design System, MDS. The implemented functional blocks facilitate the generation of proper (noisy) CDMA (Reverse and Forward) signals, which are then used to program an arbitrary wave generator in order to create actual test signals. Additionally, these functional blocks can be replaced with equivalent circuits, consisting of passive and active elements, etc. For illustrative purposes, we discuss the application of these signals to two real amplifiers, one linear and one non-linear. The measured results are critically compared with the simulation results.},
key = {Spread spectrum communication},
keywords = {Active networks;Amplifiers (electronic);Bandwidth;Cellular radio systems;Communication channels (information theory);Computer simulation;Digital communication systems;Equivalent circuits;Passive networks;Personal communication systems;Radio links;Spurious signal noise;},
note = {Circuit envelope simulator;Code division multiple access (CDMA);},
} 


@inproceedings{20142717896700 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Application of the OPC technology in the no-load test platform of the metro bogie},
journal = {Advanced Materials Research},
author = {Ren, Guang Sheng and Gai, Lei and Yin, Xiao Qing},
volume = {945-949},
year = {2014},
pages = {2062 - 2066},
issn = {10226680},
abstract = {The generation of the OPC technology makes each data source communicate flexibly in the industrial control environment. This paper takes the no-load test platform of the metro bogie as an example to design a lower and upper computer measurement and control system which is consist of IPC and PLC by the OPC technology. The OPC client is developed based on the platform of Visual Basic. By using the different communication mode, it is realized to access the OPC server data. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Technology},
keywords = {Bogies (railroad rolling stock);Data processing;Manufacture;},
note = {Communication mode;Industrial controls;Measurement and control systems;Metro;Opc technologies;Test platforms;Upper computer;VB;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMR.945-949.2062},
} 


@inproceedings{20102913088766 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A methodology to support load test analysis},
journal = {Proceedings - International Conference on Software Engineering},
author = {Malik, Haroon},
volume = {2},
year = {2010},
pages = {421 - 424},
issn = {02705257},
address = {Cape Town, South africa},
abstract = {Performance analysts rely heavily on load testing to measure the performance of their applications under a given load. During the load test, analyst strictly monitor and record thousands of performance counters to measure the run time system properties such as CPU utilization, Disk I/O, memory consumption, network traffic etc. The most frustrating problem faced by analysts is the time spent and complexity involved in analysing these huge counter logs and finding relevant information distributed across thousands of counters. We present our methodology to help analysts by automatically identifying important performance counters for load test and comparing them across tests to find performance gain/loss. Further, our methodology help analysts to understand the root cause of a load test failure by finding previously solved problems in test repositories. A case study on load test data of a large enterprise application shows that our methodology can effectively guide performance analysts to identify and compare top performance counters across tests in limited time thereby archiving 88% counter data reduction. &copy; 2010 ACM.<br/>},
key = {Principal component analysis},
keywords = {Automation;Load testing;Radiation counters;Software engineering;Testing;},
note = {CPU utilization;Large enterprise;Memory consumption;Network traffic;Performance counters;Performance Gain;Run time systems;Test analysis;},
URL = {http://dx.doi.org/10.1145/1810295.1810408},
} 


@inproceedings{20133216598213 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing framework for smart grid communication network},
journal = {IOP Conference Series: Earth and Environmental Science},
author = {Quang, D.N. and See, O.H. and Chee, L.L. and Xuen, C.Y. and Karuppiah, S.},
volume = {16},
number = {1},
year = {2013},
issn = {17551307},
address = {Beijing, China},
abstract = {Smart grid communication network is comprised of different communication mediums and technologies. Performance evaluation is one of the main concerns in smart grid communication system. In any smart grid communication implementation, to determine the performance factor of the network, a testing of an end-to-end process flow is required. Therefore, an effective and coordinated testing procedure plays a crucial role in evaluating the performance of smart grid communications. In this paper, a testing framework is proposed as a guideline to analyze and assess the performance of smart grid communication network. &copy; Published under licence by IOP Publishing Ltd.},
key = {Smart power grids},
keywords = {Communication;},
note = {Communication medium;End-to-end process;Performance factors;Performance testing framework;Smart Grid Communications;Testing framework;Testing procedure;},
URL = {http://dx.doi.org/10.1088/1755-1315/16/1/012147},
} 


@inproceedings{20132016337943 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The research of performance test method for Linux process scheduling},
journal = {Proceedings of the 2012 4th International Symposium on Information Science and Engineering, ISISE 2012},
author = {Lan, Yuqing and Xu, Hao and Liu, Xiaohui},
year = {2012},
pages = {216 - 219},
address = {Shanghai, China},
abstract = {Performance test plays a fundamental and irreplaceable role in the field of software test, especially in guaranteeing the quality and reliability of an operating system. The performance of the process scheduling subsystem directly affects the accuracy and stability of the whole operating system. Linux operating system vendors execute performance test almost in every period of the Linux operating system research and development to enhance their products' competitiveness. However, the lack of methods and tools for the Linux process scheduling performance test has caused great difficulties for Linux operating system vendors to evaluate and tune the Linux kernel performance. Therefore, in order to solve the issues mentioned above, this paper, based on the analysis of Linux process scheduling mechanism, proposes a Linux process scheduling performance test method, implements a Linux process scheduling performance test tool as well, and finally validates the tool experimentally. &copy; 2012 IEEE.},
key = {Computer operating systems},
keywords = {Benchmarking;Competition;Information science;Scheduling;Software reliability;Software testing;},
note = {Benchmark tests;linux;Performance analysis;Performance testing;Process scheduling;},
URL = {http://dx.doi.org/10.1109/ISISE.2012.54},
} 


@inproceedings{2005048809225 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {VSTM: Virtual stress testing machine},
journal = {Proceedings of the International Conference on Parallel and Distributed Processing Techniques and Applications, PDPTA'04},
author = {Harris, R. and Ausin, A.M. and Angulo, J.S. and Valafar, F. and Impelluso, T.},
volume = {3},
year = {2004},
pages = {1345 - 1351},
address = {Las Vegas, NV, United states},
abstract = {Virtual stress testing machine is a client-server software environment with a distributed memory system. VSTM encompasses a stress testing machine, a server component that initiates and controls all processes, a computational finite element component, and a number of visualization components. The goal of this design is to provide a virtual stress analysis environment, in which a specimen undergoes a series of stress applications. The finite element component calculates the displacement (deformation) of the specimen under stress. The visualization clients read the results of the finite element analysis, and construct an image of the deformed specimen color-coded to indicate varying levels of stress. A multitude of applications have been envisioned for this system, including studies in medicine.},
key = {Computer software},
keywords = {Animation;Client server computer systems;Data processing;Distributed computer systems;Finite element method;Fluid mechanics;Virtual reality;Visualization;},
note = {Distributed Memory;Finite element codes;Stress Testing;Virtual stress testing machines (VSTM);},
} 


@article{20181905163736 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Standard Guide for Thermal Performance Testing of Cryogenic Insulation Systems},
journal = {Standard Guide for Thermal Performance Testing of Cryogenic Insulation Systems},
year = {2013},
abstract = {Scope: This guide provides information for the laboratory measurement of the steady-state thermal transmission properties and heat flux of thermal insulation systems under cryogenic conditions. Thermal insulation systems may be composed of one or more materials that may be homogeneous or non-homogeneous; flat, cylindrical, or spherical; at boundary conditions from near absolute zero or 4 K up to 400 K; and in environments from high vacuum to an ambient pressure of air or residual gas. The testing approaches presented as part of this guide are distinct from, and yet complementary to, other ASTM thermal test methods including C177, C518, and C335. A key aspect of this guide is the notion of an insulation system, not an insulation material. Under the practical use environment of most cryogenic applications even a single-material system can still be a complex insulation system (1-3).<sup>2</sup>To determine the inherent thermal properties of insulation materials, the standard test methods as cited in this guide should be consulted. The function of most cryogenic thermal insulation systems used in these applications is to maintain large temperature differences thereby providing high levels of thermal insulating performance. The combination of warm and cold boundary temperatures can be any two temperatures in the range of near 0 K to 400 K. Cold boundary temperatures typically range from 4 K to 100 K, but can be much higher such as 300 K. Warm boundary temperatures typically range from 250 K to 400 K, but can be much lower such as 40 K. Large temperature differences up to 300 K are typical. Testing for thermal performance at large temperature differences with one boundary at cryogenic temperature is typical and representative of most applications. Thermal performance as a function of temperature can also be evaluated or calculated in accordance with Practices C1058 or C1045 when sufficient information on the temperature profile and physical modeling are available. The range of residual gas pressures for this Guide is from 10<sup>-7</sup>torr to 10<sup>+3</sup>torr (1.33<sup>-5</sup>Pa to 133 kPa) with different purge gases as required. Corresponding to the applications in cryogenic systems, three sub-ranges of vacuum are also defined: High Vacuum (HV) from &lt;10<sup>-6</sup>torr to 10<sup>-3</sup>torr (1.333<sup>-4</sup>Pa to 0.133 Pa) [free molecular regime], Soft Vacuum (SV) from 10<sup>-2</sup>torr to 10 torr (from 1.33 Pa to 1,333 Pa) [transition regime], No Vacuum (NV) from 100 torr to 1000 torr (13.3 kPa to 133 kPa) [continuum regime]. Thermal performance can vary by four orders of magnitude over the entire vacuum pressure range. Effective thermal conductivities can range from 0.010 mW/m-K to 100 mW/m-K. The primary governing factor in thermal performance is the pressure of the test environment. High vacuum insulation systems are often in the range from 0.05 mW/m-K to 2 mW/m-K while non-vacuum systems are typically in the range from 10 mW/m-K to 30 mW/m-K. Soft vacuum systems are generally between these two extremes (4). Of particular demand is the very low thermal conductivity (very high thermal resistance) range in sub-ambient temperature environments. For example, careful delineation of test results in the range of 0.01 mW/m-K to 1 mW/m-K (from R-value 14,400 to R-value 144) is required as a matter of normal engineering applications for many cryogenic insulation systems (5-7). The application of effective thermal conductivity values to multilayer insulation (MLI) systems and other combinations of diverse materials, because they are highly anisotropic and specialized, must be done with due caution and full provision of supporting technical information (8). The use of heat flux (W/m<sup>2</sup>) is, in general, more suitable for reporting the thermal performance of MLI systems (9-11). This guide covers different approaches for thermal performance measurement in sub-ambient temperature environments. The test apparatuses (apparatus) are divided into two categories: boiloff calorimetry and electrical power. Both absolute and comparative apparatuses are included. This guide sets forth the general design requirements necessary to construct and operate a satisfactory test apparatus. A wide variety of apparatus constructions, test conditions, and operating conditions are covered. Detailed designs are not given but must be developed within the constraints of the general requirements. Examples of different cryogenic test apparatuses are found in the literature (12). These apparatuses include boiloff types (13-17) as well as electrical types (18-21). These testing approaches are applicable to the measurement of a wide variety of specimens, ranging from opaque solids to porous or transparent materials, and a wide range of environmental conditions including measurements conducted at extremes of temperature and with various gases and over a range of pressures. Of particular importance is the ability to test highly anisotropic materials and systems such as multilayer insulation (MLI) systems (22-25). Other test methods are limited in this regard and do not cover the testing of MLI and other layered systems under the extreme cryogenic and vacuum conditions that are typical for these systems. In order to ensure the level of precision and accuracy expected, users applying this standard must possess a working knowledge of the requirements of thermal measurements and testing practice and of the practical application of heat transfer theory relating to thermal insulation materials and systems. Detailed operating procedures, including design schematics and electrical drawings, should be available for each apparatus to ensure that tests are in accordance with this Guide. In addition, automated data collecting and handling systems connected to the apparatus must be verified as to their accuracy. Verification can be done by calibration and comparing data sets, which have known results associated with them, using computer models. It is impractical to establish all details of design and construction of thermal insulation test equipment and to provide procedures covering all contingencies associated with the measurement of heat flow, extremely delicate thermal balances, high vacuum, temperature measurements, and general testing practices. The user may also find it necessary, when repairing or modifying the apparatus, to become a designer or builder, or both, on whom the demands for fundamental understanding and careful experimental technique are even greater. The test methodologies given here are for practical use and adaptation as well as to enable future development of improved equipment or procedures. This guide does not specify all details necessary for the operation of the apparatus. Decisions on sampling, specimen selection, preconditioning, specimen mounting and positioning, the choice of test conditions, and the evaluation of test data shall follow applicable ASTM Test Methods, Guides, Practices or Product Specifications or governmental regulations. If no applicable standard exists, sound engineering judgment that reflects accepted heat transfer principles must be used and documented. This guide allows a wide range of apparatus design and design accuracy to be used in order to satisfy the requirements of specific measurement problems. Compliance with a further specified test method should include a report with a discussion of the significant error factors involved as well the uncertainty of each reported variable. The values stated in SI units are to be regarded as the standard. The values given in parentheses are for information only. Either SI or Imperial units may be used in the report, unless otherwise specified. Safety precautions including normal handling and usage practices for the cryogen of use. Prior to operation of the apparatus with any potentially hazardous cryogen or fluid, a complete review of the design, construction, and installation of all systems shall be conducted. Safety practices and procedures regarding handling of hazardous fluids have been extensively developed and proven through many years of use. For systems containing hydrogen, particular attention shall be given to ensure the following precautions are addressed: (1) adequate ventilation in the test area, (2) prevention of leaks, (3) elimination of ignition sources, (4) fail safe design, and (5) redundancy provisions for fluid fill and vent lines. This standard does not purport to address all of the safety concerns, if any, associated with its use. It is the responsibility of the user of this standard to establish appropriate safety and health practices and determine the applicability of regulatory limitations prior to use. Major sections within this standard are arranged as follows: (Table Presented)<br/> &copy;2013 ASTM International. All rights reserved.},
key = {Thermal insulation},
keywords = {Anisotropy;Construction equipment;Cryogenics;Data handling;Equipment testing;Hazards;Heat flux;Heating equipment;Materials testing;Multilayers;Permafrost;Software testing;Tapes;Temperature;Temperature measurement;Thermal conductivity;Thermal insulating materials;Vacuum applications;},
note = {Effective thermal conductivity;Environmental conditions;Governmental regulations;Low thermal conductivity;Temperature environments;Thermal insulation materials;Thermal insulation systems;Thermal performance testing;},
URL = {http://dx.doi.org/10.1520/C1774},
versions = {1},
} 


@inproceedings{20124215564648 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance of cloud-based scalability and load with an automation testing tool in virtual world},
journal = {Proceedings - 2012 IEEE 8th World Congress on Services, SERVICES 2012},
author = {Kamra, Madhvi and Manna, Ratnamala},
year = {2012},
pages = {57 - 64},
address = {Honolulu, HI, United states},
abstract = {The development in cloud computing provides limitless capacity which provides opportunity to evaluate an application performance based on its nature to scale. This paper aims at the analysis of Performance using the Google App Engine(cloud computing paradigm). Virtual Office application is chosen as example to perform experiment of testing the scalability in turn maintaining the performance. An Automation Testing Tool - Test Harness has been used to perform the scale testing of the application while being deployed on the cloud. Results have seen shown in the form of request type and response times(Average time taken/request). Taken into account the consideration that when the application load goes up the Google Cloud expands(increases instance hours) without affecting the running application. &copy; 2012 IEEE.<br/>},
key = {Load testing},
keywords = {IEEE Standards;Mobile computing;Platform as a Service (PaaS);Program processors;Scalability;Virtual reality;},
note = {Analysis of performance;Application performance;Automation testing;Google app engines;Running applications;Test harness;Virtual office;Virtual worlds;},
URL = {http://dx.doi.org/10.1109/SERVICES.2012.54},
} 


@inproceedings{20095012542547 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Network performance testing on VM based autonomous web server},
journal = {2006 International Conference on Computing and Informatics, ICOCI '06},
author = {Mas'ud, M. Zaki and Yaacob, Asrul H. and Ahmad, Nazrul M.},
year = {2006},
address = {Kuala Lumpur, Malaysia},
abstract = {As online services increasingly play vital roles in modern society, the possibilities and opportunities offered are limitless, unfortunately, so too are the risks and chances of malicious intrusions. Intrusion Detection Systems (IDSs) has been widely used as an important component in protecting online service towards web attacks and evasions. Yet, today's architectures for intrusion detection force the IDS designer to make a difficult choice to place IDS, so that it can protect itself from a direct attack. To address these challenges, this paper introduces a novel framework to safeguard IDS from a direct attack. Simply called Zero Administrative Server (ZAS), the system incorporates IDS in a Virtual Machine (VM) environment. VM offers strong isolation for IDS from the monitored services and provides significant resistance to malicious attacks. Moreover, this VM based WWW server has the ability to monitor the network traffic to the running services; analyse the information obtained and detect the intrusion; alienate the intruder from the services; and reconstruct the corrupted data or damaged files caused by the evasion. In this paper, we demonstrate ZAS by exposing it to several attacking tools as well as to show the effects it takes on the network performance in terms of TCP throughput and application-to-application round trip time. &copy; 2006 IEEE.<br/>},
key = {Intrusion detection},
keywords = {Computer crime;Network performance;Network security;Online systems;Virtual machine;Web services;},
note = {Administrative servers;Check sums;Corrupted data;Intrusion Detection Systems;Malicious attack;Network traffic;On-line service;Round-trip time;},
URL = {http://dx.doi.org/10.1109/ICOCI.2006.5276470},
} 


@inproceedings{20094712463986 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Experience with training a remotely located performance test team in a quasi-agile global environment},
journal = {Proceedings - 2009 4th IEEE International Conference on Global Software Engineering, ICGSE 2009},
author = {Bondi, Andre B. and Ros, Johannes P.},
year = {2009},
pages = {254 - 261},
address = {Limerick, Ireland},
abstract = {We describe our experience of training a remotely located team of developers and testers to prepare and execute performance tests. The team is located in India. The lead performance engineer and the test project manager are based in New Jersey. The team members had little or no prior experience of performance testing. We describe how we overcame cultural differences and a large time difference to develop a performance testing team that is now functioning well with far less supervision than was required at its inception. Cultural differences included contrasting views on adherence to strict laboratory procedures and assumptions about the prior knowledge, experience, and expectations of working habits of the India-based and New Jersey-based teams. We show how these differences and organizational challenges were overcome with intensive on-site training, the use of twice-daily scrum meetings, the careful designation of team leaders and role players at the remote testing site, and, eventually, the development intensive use of automated tools to execute performance tests and track the results. &copy; 2009 IEEE.<br/>},
key = {Personnel training},
keywords = {Software engineering;},
note = {Cultural difference;Global environment;Laboratory procedures;On-site training;Performance testing;Performance tests;Prior experience;Time-differences;},
URL = {http://dx.doi.org/10.1109/ICGSE.2009.34},
} 


@inproceedings{20133416642799 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {MBPeT: A model-based performance testing tool},
journal = {VALID 2012 - 4th International Conference on Advances in System Testing and Validation Lifecycle},
author = {Abbors, Fredrik and Ahmad, Tanwir and Truscan, Dragos and Porres, Ivan},
year = {2012},
pages = {1 - 8},
address = {Lisbon, Portugal},
abstract = {In recent years, cloud computing has become increasingly common. Verifying that applications deployed in the cloud meet their performance requirements is not simple. There are three different techniques for performance evaluation: analytical modeling, simulation, and measurement. While analytical modeling and simulation are good techniques for getting an early performance estimation, they rely on an abstract representation of the system and leave out details related for instance to the system configuration. Such details are problematic to model or simulate, however they can be the source of the bottlenecks in the deployed system. In this paper, we present a model-based performance testing tool that measures the performance on web applications and services using the measurement technique. The tool uses models to generate workload which is then applied to the system in realtime and it measures different performance indicators. The models are defined using probabilistic timed automata and they describe how different user types interact with the system. We describe how load is generated from the models and the features of the tool. The utility of the tool is demonstrated by applying to a WebDav case study. Copyright &copy; (2012) by International Academy, Research, and Industry Association (IARIA).},
key = {Measurements},
keywords = {Analytical models;Automata theory;Computer simulation;Life cycle;Load testing;Models;Monitoring;System theory;Tools;},
note = {Abstract representation;Measurement techniques;Modeling and simulation;Performance estimation;Performance requirements;Performance testing;Probabilistic timed automata;Three different techniques;},
} 


@article{20160101744936 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Combining genetic algorithms and constraint programming to support stress testing of task deadlines},
journal = {ACM Transactions on Software Engineering and Methodology},
author = {Di Alesio, Stefano and Briand, Lionel C. and Nejati, Shiva and Gotlieb, Arnaud},
volume = {25},
number = {1},
year = {2015},
issn = {1049331X},
abstract = {Tasks in real-time embedded systems (RTES) are often subject to hard deadlines that constrain how quickly the system must react to external inputs. These inputs and their timing vary in a large domain depending on the environment state and can never be fully predicted prior to system execution. Therefore, approaches for stress testing must be developed to uncover possible deadline misses of tasks for different input arrival times. In this article, we describe stress-test case generation as a search problem over the space of task arrival times. Specifically, we search for worst-case scenarios maximizing deadline misses, where each scenario characterizes a test case. In order to scale our search to large industrial-size problems, we combine two state-of-the-art search strategies, namely, genetic algorithms (GA) and constraint programming (CP). Our experimental results show that, in comparison with GA and CP in isolation, GA+CP achieves nearly the same effectiveness as CP and the same efficiency and solution diversity as GA, thus combining the advantages of the two strategies. In light of these results, we conclude that a combined GA+CP approach to stress testing is more likely to scale to large and complex systems. 2015 Copyright is held by the owner/author(s).},
key = {Genetic algorithms},
keywords = {Algorithms;Computer programming;Constraint theory;Embedded systems;Interactive computer systems;Real time systems;Software testing;},
note = {Constraint programming;Environment state;Real-time embedded systems;Search strategies;Search-based software testing;Stress Testing;Task deadline;Worst case scenario;},
URL = {http://dx.doi.org/10.1145/2818640},
} 


@article{2005219112949 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A MSK performance testing/measuring tool sitwa},
journal = {Advances in Modelling and Analysis B},
author = {Izworski, Antoni and Skowronski, Slawomir and Lewoc, Jozef B.},
volume = {47},
number = {5-6},
year = {2004},
pages = {77 - 90},
issn = {12404543},
abstract = {It is rather difficult to find detailed and in-depth references concerning communication network performance testing/measuring tools. Therefore, the paper presents the solution developed earlier for the Interuniversity Computer Network in Poland. The structure and the functionality of the tool described are modified so that the description may be directly applied to TCP/IP networks. Some testing/measuring results are presented and benefits gained are discussed. The possible use of similar solution in present day communication networks is depicted.},
key = {Computer networks},
keywords = {Computer software;Data transfer;Measurement theory;Microcomputers;Network protocols;Telecommunication networks;Testing;},
note = {Internal tools;MSK performance testing;Network development;TCP/IP networks;},
} 


@inproceedings{20115214642763 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A study on the tag performance test for international standards using RFID emulator},
journal = {Lecture Notes in Electrical Engineering},
author = {Choi, Hae-Gill and Kim, Sang-Soo and Cho, Moon-Taek and Joo, Hae-Jong and Lee, Euy-Soo},
volume = {114 LNEE},
year = {2012},
pages = {621 - 632},
issn = {18761100},
address = {Jeju, Korea, Republic of},
abstract = {RFID technology uses communication through the use of radio waves to transfer data between a reader and an electronic tag attached to an object for the purpose of identification and tracking. RFID technology can be applied to the various service areas such as, position determination technology, remote processing management and information exchange between objects by collecting, storing, processing, and tracing their informations from the tag attached to the objects using electronic wave by recognizing the information and environment of those objects. However, to revitalize these various services, it is important to test the RFID tag performance. But there are few instructions which have and hold the RFID emulator technology for organizing the RFID international test environment. Also there are not many manufacturing companies which recognize about the exact RFID test standard and requirements for the International Standards. In this paper, a construction of Tag Performance test environments and test methods are suggested which are required by EPCglobal or ISO/IEC. Details about RFID Tag performance test items proposed by ISO/IEC FDIS 18046-3 are explained, performed RFID Tag performance test through the performing test against each measured item, and draw a result for the RFID Tag performance of International Standards. On the basis of this research, it is desired to contribute to develop a great performing RFID Tag product through the RFID Tag performance test which comes up to the International Standards and construct its application system and facilitate a revitalization of the RFID services. &copy; 2012 Springer Science+Business Media B.V.<br/>},
key = {Radio frequency identification (RFID)},
keywords = {ISO Standards;Testing;},
note = {EPCglobal;Identification and tracking;Information exchanges;International standards;ISO/IEC;Manufacturing companies;Position determination;RF-ID tags;},
URL = {http://dx.doi.org/10.1007/978-94-007-2792-2_60},
} 


@inproceedings{20130315907938 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Custom protocol load testing - The case of visual studio test edition},
journal = {35th International Conference Computer Measurement Group},
author = {Volkov, Oleksiy},
year = {2009},
address = {Dallas, TX, United states},
abstract = {While there is a large variety of load testing tools aimed at the general web/web services based application today, there is a surprising dearth of options for load testing complex, composite custom-built systems that use non-standard messaging protocols. The paper will focus on a real case of implementing a Visual Studio 2008-based performance testing solution for an in-house built bulk document processing application, the challenges and lessons learned, and the unique aspects of using a performance testing tool that is really a part of a well integrated development and testing framework.},
key = {Measurements},
note = {Document processing applications;Integrated development;Messaging protocols;Performance testing;Testing framework;Testing tools;Visual studios;},
} 


@inproceedings{1984010016197 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {PERFORMANCE TESTING OF A THREE-BED MOLECULAR SIEVE OXYGEN GENERATOR.},
journal = {Proceedings - Annual SAFE Symposium (Survival and Flight Equipment Association)},
author = {Tedor, J.B. and Horch, T.C. and Dangieri, T.J.},
year = {1982},
pages = {264 - 267},
address = {Las Vegas, NV, USA},
key = {AIRCRAFT, MILITARY},
note = {10-60 PSI GAUGE INPUT AIR PRESSURE;BREATHING GAS FLOW;MAXIMUM OXYGEN CONCENTRATION;MOLECULAR SIEVE OXYGEN ENRICHMENT SYSTEM;PERFORMANCE CURVES;TACTICAL AIRCRAFT USE;},
} 


@inproceedings{20083511490455 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Improved voltage disturbance generator for the performance test of the custom power devices},
journal = {Proceeding of International Conference on Electrical Machines and Systems, ICEMS 2007},
author = {Lee, Young-Ho and Park, Hae-Young and Nho, Eui-Cheol and Kim, In-Dong and Chun, Tae-Won and Kim, Heung-Geun and Choi, Nam-Sup},
year = {2007},
pages = {175 - 179},
address = {Seoul, Korea, Republic of},
abstract = {An improved voltage disturbance generator is proposed. To test the performance of the custom power devices such as DVR, SSTS, dynamic UPS, etc., a voltage disturbance generator is necessary. The proposed generator has good features of high reliability, low cost, simple structure, high efficiency, and reduced voltage drop. The main switching device is SCR thyristor, and all the thyristors have natural commutation characteristics, which provides reliable system. The circuit analysis and operating principle of the proposed scheme are described in each mode of voltage sag, swell, outage, and unbalance. Simulation and experimental results show the usefulness of the proposed scheme.<br/>},
key = {Electronic equipment testing},
keywords = {Electric machinery;Thyristors;Uninterruptible power systems;},
note = {Custom Power device;Natural commutation;Operating principles;Performance tests;Reduced voltage drops;Simple structures;Switching devices;Voltage disturbance generators;},
URL = {http://dx.doi.org/10.1109/ICEMS.2007.4412164},
} 


@article{1998104019864 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Development and performance testing of a 200 kVA damperless superconducting generator},
journal = {IEEE Transactions on Energy Conversion},
author = {Suryanarayana, T. and Bhattacharya, J.L. and Raju, K.S.N. and Prasad, K.A.Durga},
volume = {12},
number = {4},
year = {1997},
pages = {330 - 336},
issn = {08858969},
abstract = {A 200 kVA, 3000 RPM superconducting generator has been developed and tested. The rotor has been wound with superconducting wire of Nb-Ti alloy. A closed-circuit liquid helium system has been designed and installed for cooling the superconducting windings. The stator carries the air-gap type armature windings and a laminated-iron flux-shield. A new concept in the design of superconducting generators with high short-circuit ratio (more than 5) has been introduced. This eliminates the requirement of Electro-magnetic Damper (EMD) and Quick Response Excitation System (QRES). The generator has been comprehensively tested in superconducting state. Open-circuit and sustained short-circuit tests, 3-phase sudden short-circuit test, synchronization with grid and parallel operation with power system have been conducted. The synchronous machine was operated up to its rated kVA in the four quadrants - as generator and as condenser with leading and lagging power factors. A few special tests on superconducting generator, which were not reported earlier, such as direct-on-line starting of a 20 HP squirrel-cage induction motor and negative phase sequence tests have also been performed successfully. Test results and conclusions are given in the paper.},
key = {AC generators},
keywords = {Electric machinery testing;Electric power factor;Niobium alloys;Rotors (windings);Short circuit currents;Superconducting devices;Superconducting wire;Superconductivity;},
note = {Damperless superconducting generators;Electromagnetic dampers (EMD);Quick response excitation systems (QRES);},
URL = {http://dx.doi.org/10.1109/60.638869},
} 


@inproceedings{20171903645382 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Drop weight dynamic load testing for construction monitoring and quality control of offshore drilled foundations},
journal = {Geotechnical Special Publication},
author = {Robertson, Seth O. and Paikowsky, Samuel G.},
number = {GSP 279},
year = {2017},
pages = {143 - 153},
issn = {08950563},
address = {Orlando, FL, United states},
abstract = {High strain drop weight dynamic load testing is an effective tool when evaluating the construction quality and axial capacity of offshore drilled deep foundations. This is a result of the complexity and cost of the alternative conventional static load tests. Drop weight systems can be designed for project specific needs, providing sufficient energy to mobilize the required resistance while permitting ease in transporting the device. Test shafts/piles can be instrumented and analyzed using the same dynamic testing techniques used for driven pile foundations. A case study is presented where drop weight dynamic load tests were utilized for offshore drilled shaft foundations. The project includes the design, construction, and quality control for a cement unloading pier at the Tema port in Ghana, Africa. The foundations are unique, consisting of 0.8m outer diameter steel pipes embedded in 1.0m rock-socketed drilled shafts. Three dynamic load tests to failure and six load verification tests were performed offshore. The load verification tests were carried out due to construction difficulties and/or complex subsurface conditions. The piles' integrity and mobilized resistances were assessed using the signal matching analysis software CAPWAP. The underlying assumptions in the one-dimensional wave equation formulation on which CAPWAP is based are violated in these complex cases. Finite element analyses were therefore performed using the PLAXIS 2D software in order to examine the validity of the one-dimensional wave equation application under such conditions. This paper briefly describes the project, the associated difficulties, the unique foundations, example load tests and their analyses, as well as some initial processing in examining the validity of the one-dimensional wave equation analyses under the tested conditions. &copy; ASCE.},
key = {Load testing},
keywords = {Application programs;Drops;Dynamic loads;Finite element method;Foundations;Pile foundations;Piles;Quality control;Shaft sinking;Unloading;Wave equations;},
note = {Construction monitoring;Construction quality;Drilled foundations;One-dimensional wave equations;Signal matching analysis;Subsurface conditions;Three dynamic loads;Verification tests;},
URL = {http://dx.doi.org/10.1061/9780784480465.015},
} 


@article{20151800809616 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test of coordinated control of SMES and BESS in microgrid using the hardware-in-the-loop simulation system},
journal = {International Journal of Control and Automation},
author = {Ji, Hyeon-Kyun and Yoo, Hyeong-Jun and Kim, Hak-Man},
volume = {8},
number = {3},
year = {2015},
pages = {161 - 170},
issn = {20054297},
abstract = {Roles of energy storage systems (ESSs) in microgrid control are very important because a microgrid has uncontrollable energy sources such as the wind turbine and power trade with the utility grid. Especially, the ESSs have different characteristics - power density and energy density. The characteristics show a trade-off. For this reason, the coordinated control among ESSs considering their characteristics is required. In this paper, a coordinated control of SMES and BESS is tested with high reliability using the hardware-in-the-loop simulation (HILS) system in two grid-connected and islanded modes. &copy; 2015 SERSC.},
key = {Electric power system control},
keywords = {Economic and social effects;Electric energy storage;Electric power distribution;Electric power transmission networks;Energy storage;Hardware;Magnetic storage;Synthetic apertures;Traction (friction);Wind turbines;},
note = {Battery storage system;Co-ordinated control;Energy storage systems;Hardware in-the-loop simulation;Micro grid;Superconducting magnetic storage (SMES);Wind generator systems;},
URL = {http://dx.doi.org/10.14257/ijca.2015.8.3.18},
} 


@inproceedings{20180904844771 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {gRpas, a tool for performance testing and analysis},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Cucos, Laurentiu and de Doncker, Elise},
volume = {3514 LNCS},
year = {2005},
pages = {322 - 329},
issn = {03029743},
address = {Atlanta, GA, United states},
abstract = {This paper presents &ldquo;gRpas&rdquo;, a tool written in Java and designed to help analyzing test results from scientific computing applications. &ldquo;gRpas&rdquo; stands for &ldquo;gather Results/ plot, analyze, and store&rdquo;. As one of its main features, the tool is easy to interface with the user program. Furthermore it provides for one click data filtering and plot generation, effective graphical display of program output, and statistical report generation on algorithm results and performance. gRpas also has built-in functionality for comparison testing between two or more algorithms or algorithm versions. We will present examples of its use with parallel multivariate integration routines. However, its target applications cover a wide class of scientific computing programs.<br/> &copy; Springer-Verlag Berlin Heidelberg 2005.},
key = {Application programs},
keywords = {Artificial intelligence;Computer science;Computers;},
note = {Comparison testing;Data filtering;Graphical displays;Parallel multivariate integration;Performance testing;Scientific computing applications;Statistical report;Target application;},
URL = {http://dx.doi.org/10.1007/11428831_40},
} 


@article{20155101684562 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A comparative evaluation of state-of-the-art load and stress testing approaches},
journal = {International Journal of Computer Applications in Technology},
author = {Malej, Afef Jmal and Krichen, Moez and Jmaiel, Mohamed},
volume = {51},
number = {4},
year = {2015},
pages = {283 - 293},
issn = {09528091},
abstract = {In order to deliver quality assured software and avoid potential costs caused by unstable software, testing is essential in software life cycle. Load testing is one of the testing types with high importance. It is usually accompanied by performance monitoring of the hosting environment. The purpose of this paper is to present related solutions to both load and stress testing issues in different fields and emerging paradigms, and to evaluate them in order to identify their advantages and their shortcomings. Looking at the areas focused by existing researchers, gaps and untouched zones of different systems relatively to load testing can be discovered. This investigation will especially allow promoting future research in the context of load testing of web service compositions, considered as an arising concept in service-oriented architecture (SOA). &copy; 2015 Inderscience Enterprises Ltd.},
key = {Load testing},
keywords = {Application programs;Computer applications;Information services;Life cycle;Service oriented architecture (SOA);Software architecture;Software testing;Web services;Websites;},
note = {Comparative evaluations;Emerging paradigms;Performance monitoring;State of the art;Stress Testing;Web service composition;},
URL = {http://dx.doi.org/10.1504/IJCAT.2015.070491},
} 


@inproceedings{20104813421378 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Framework of MEMS high accelerated stress test},
journal = {2010 IEEE 5th International Conference on Nano/Micro Engineered and Molecular Systems, NEMS 2010},
author = {Wang, Zhen and Xu, Lixin and Wang, Zhao and Zhao, Heming and Song, Rongchang and Lou, Wenzhong},
year = {2010},
pages = {280 - 283},
abstract = {Given the reliability principles and failure mechanism of MEMS, this paper discussed the accelerated test from three aspects as follows: the connotation of the test including concept and meaning; the scope of application concerned with product levels for applicants in types of stress; test process includes the test objective determination, test stressing selection, the test profile designing, the implementation scheme determining, analysis and improvement measures. &copy;2010 IEEE.<br/>},
key = {Testing},
keywords = {MEMS;Product design;Reliability;Reliability analysis;},
note = {Accelerated tests;Failure mechanism;HAST;High-accelerated stress tests;Implementation scheme;Improvement measure;Reliability principles;Scope of application;},
URL = {http://dx.doi.org/10.1109/NEMS.2010.5592211},
} 


@article{1985070092684 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {ON-LOAD TEST OF THE 20KVA SUPERCONDUCTING GENERATOR.},
journal = {IEEE Transactions on Magnetics},
author = {Okada, T. and Nitta, T. and Shintani, T.},
volume = {MAG-21},
number = {2},
year = {1984},
issn = {00189464},
abstract = {The on-load tests are carried out on an experimental power system, where the 20 kVA superconducting synchronous generator is connected to the regional power system through reactors (artificial transmission lines). The cooling characteristics of the rotor, especially, the cold damper, are obtained. On the on-load tests, active power vs. reactive power, active power vs. load angle, field current vs. active power characteristics at the constant terminal voltage, and so on are obtained. The transient behavior of the generator for a small variation of the input power is obtained. A transient analysis for the above test was carried out. Good agreement between the measured and calculated values is confirmed. From the results, the characteristics of superconducting generators are compared with those of the conventional ones and discussed.},
key = {SUPERCONDUCTING DEVICES},
keywords = {ELECTRIC GENERATORS, SYNCHRONOUS;},
note = {ARMATURE CURRENT;ON-LOAD TEST;REACTIVE POWER;},
} 


@inproceedings{20124415632712 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing and system evaluation of the DOE ETV-1 electric vehicle},
journal = {SAE Technical Papers},
author = {Kurtz, Donald W. and Price, Theodore W. and Bryant, James A.},
year = {1981},
abstract = {The DOE ETV-1 represents one of most advanced vehicles in operation today. Engineering tests are now being conducted by the Jet Propulsion Laboratory in order to characterize its overall system performance and component efficiencies within the system environment. A chassis dynamometer is used in order to minimize the ambient effects and large uncertainties present in track testing. Extensive test requirements were defined and procedures were carefully controlled in order to maintain a high degree of credibility. Test results include an energy flow analysis through the major subsystems and incorporate the aerodynamic and rolling losses under cyclic and various steady speed conditions.},
key = {Electric vehicles},
keywords = {Dynamometers;},
note = {Advanced vehicle;Chassis dynamometers;Degree of credibility;Energy flow analysis;Engineering tests;Jet Propulsion Laboratory;Performance testing;System environment;System evaluation;Test requirements;},
URL = {http://dx.doi.org/10.4271/810418},
} 


@inproceedings{20162602543181 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {An adaptive Kalman filter for a range measurement based indoor positioning system: Algorithm adaptation and performance testing},
journal = {28th International Technical Meeting of the Satellite Division of the Institute of Navigation, ION GNSS 2015},
author = {Zhao, Sihao and Jiao, Yang and Mi, Haipeng and Ma, Tianyi and Lu, Mingquan},
volume = {3},
year = {2015},
pages = {2282 - 2290},
address = {Tampa, FL, United states},
abstract = {To overcome the positioning inaccuracy and discontinuity due to the signal errors and user dynamics in a wireless indoor navigation system, an adaptive Kalman filter positioning algorithm is proposed. This adaptive method automatically tune the elements in the process and measurement variance-covariance matrices according to the innovation values to enable a varying dependence on process or measurement model. The theory of the method is presented based on which the parameter settings are discussed. Both static and dynamic experiments under real indoor environment are conducted to verify the proposed method. Iterative least square (ILS) and standard Kalman filter (KF) are introduced to compare with the proposed adaptive filter. Results show that the proposed method outperforms the ILS and KF in both positioning accuracy and continuity.},
key = {Adaptive filters},
keywords = {Algorithms;Bandpass filters;Covariance matrix;Global positioning system;Indoor positioning systems;Iterative methods;Kalman filters;Navigation systems;},
note = {Adaptive kalman filter;Indoor navigation system;Iterative least squares;Performance testing;Positioning accuracy;Positioning algorithms;Standard Kalman filters;Variance-covariance matrices;},
} 


@inproceedings{20133116547699 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Validation and performance test of the reduction formaldehyde concentrations for indoor environment by sorptive building materials in Taiwan},
journal = {12th International Conference on Indoor Air Quality and Climate 2011},
author = {Huang, Kun Chih and Chiang, Che Ming and Lee, Ching Chang and Shao, Wen Cheng and Lin, Fang Ming},
volume = {3},
year = {2011},
pages = {2047 - 2052},
address = {Austin, TX, United states},
abstract = {With the high air-tightness and ventilation deficiencies of modern residential and energyefficient buildings, countries in the world gradually emphasize that the well-controlled of Indoor Air Quality (IAQ) and Indoor Environment Health (IEH) would reduce the hazards of human health. This study is based on the international standard, ISO 16000-23 and ISO 16000-24, to establish a Sorptive Building Materials Test System (SBMTS) in Taiwan. This research collected three Green Building Materials Label (GBML) products, which are wood core board, wood fiberboard and latex paint, to investigate the "adsorption properties" test for each material in small-scale chamber with 0.2ppm formaldehyde for 72hrs. The result indicates, air samples shall be ensure that the inlet/outlet has the same air flow rate during air sampling of recovery test and the error and uncertainty would be decrease to 5%. The wood fiberboard has higher sorption "phenomenon" in this study, which formaldehyde sorption flux (F<inf>m</inf>) is 210.47&mu;g/m<sup>2</sup>&middot h, equivalent ventilation rate (F<inf>v, eq</inf>) is 3.01m<sup>3</sup>/m <sup>2</sup>&middoth, and average sorption rate is 70.89%. This study demonstrates the formaldehyde could indeed reduce formaldehyde under 0.08ppm (based on the guideline of WHO) during 168 hrs.},
key = {Formaldehyde},
keywords = {Adsorption;Building materials;Desorption;Health hazards;Indoor air pollution;},
note = {Adsorption properties;Energy-efficient buildings;Formaldehyde concentrations;Green building materials;Indoor environment;International standards;Sorptive building materials;Test systems;},
} 


@inproceedings{20164002875524 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Program performance test based on different computing environment},
journal = {Proceedings of 2016 IEEE International Conference of Online Analysis and Computing Science, ICOACS 2016},
author = {Zhang, Hailong and Nie, Jun},
year = {2016},
pages = {174 - 177},
address = {Chongqing, China},
abstract = {To test the efficiency of different programming languages and find out the suitable one for solving the calculation problem of spherical distance between two points, we have developed serial and parallel calculate algorithms according C, Python programming languages, and tested the execution speed of all algorithms. As for the inefficiency of Python, we improved the performance by replacing some functions and variables of Python procedure with Cython. The experimental results show that Python programs can get the same execution efficiency as C language does with the same Large-scale computing environment. &copy; 2016 IEEE.},
key = {C (programming language)},
keywords = {Cesium;Computer software;Efficiency;High level languages;Software testing;},
note = {C language;Computing environments;Cython;Execution speed;Large-scale computing;Program performance;Python;Python programming language;},
URL = {http://dx.doi.org/10.1109/ICOACS.2016.7563073},
} 


@inproceedings{20093912331518 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing based on test-driven development for mobile applications},
journal = {Proceedings of the 3rd International Conference on Ubiquitous Information Management and Communication, ICUIMC'09},
author = {Kim, Heejin and Choi, Byoungju and Yoon, Seokjin},
year = {2009},
pages = {612 - 617},
address = {Suwon, Korea, Republic of},
abstract = {Due to the tight schedule of product development for mobile applications and lack of performance testing methods, the product-oriented performance testing that is mostly done in the end of the development shows problems such as identifying a cause of detected faults, tracking down and modifying the faults when faults occur. The importance of testing is emphasized in TDD and the automated test framework is supported for efficient software development with unit tests. In this paper, we propose the methods of performance testing based on test-driven development with regard to non-functional factors as well as functionality of software during the software development process by advancing performance testing to the development stage and introduce a testing tool that assists performance testing on software development phase. It provides automation of test case generation and test execution at unit test level. It will eventually improve the development productivity as well as the reliability and quality of mobile applications by reducing the time and cost to execute tests in the process of the entire mobile applications development and helping to detect faults. Copyright 2009 ACM.<br/>},
key = {Software testing},
keywords = {Computer programming;Information management;Mobile computing;Software design;},
note = {Development productivity;Development stages;Mobile applications;Mobile applications development;Performance testing;Software development process;Test case generation;Test driven development;},
URL = {http://dx.doi.org/10.1145/1516241.1516349},
} 


@inproceedings{20125015795037 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Continuous performance testing in virtual time},
journal = {Proceedings - 2012 9th International Conference on Quantitative Evaluation of Systems, QEST 2012},
author = {Baltas, Nikos and Field, Tony},
year = {2012},
pages = {13 - 22},
address = {London, United kingdom},
abstract = {In this paper we show how program code and performance models can be made to cooperateseamlessly to support continuous software performance testing throughout thedevelopment lifecycle. We achieve this by extending our existing VEXtool for executing programs in virtual time so that events that occurduring normal execution and those that occur during the simulation of a performance model can bescheduled on a single global virtual time line. The execution time of anincomplete component of an application is thus estimated by a performance model, whilstthat of existing code is measured by instrumentation that is added dynamicallyat program load time. A key challenge is to be able to map some or all of the resourcesin a performance model to the real resources of the host platform on which theapplication is running. We outline a continuous performance engineering methodologythat exploits our unified framework and illustrate the principles involved byway of a simple Java application development case study. &copy; 2012 IEEE.},
key = {Software testing},
keywords = {Computer simulation;},
note = {Execution time;Global virtual time;Java applications;Performance engineering;Performance Model;Performance testing;Program code;Software performance;Software performance testing;Unified framework;Virtual execution;Virtual-time;},
URL = {http://dx.doi.org/10.1109/QEST.2012.26},
} 


@inproceedings{20161102081160 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance Test of Various Types of Antenna Arrays in Real Propagation Environment},
journal = {IOP Conference Series: Materials Science and Engineering},
author = {Budiyanto, Setiyo and Nugraha, Beny and Widiastuti, Dian},
volume = {105},
number = {1},
year = {2016},
issn = {17578981},
address = {Yogyakarta, Indonesia},
abstract = {The research was conducted on various types of antenna arrays namely Uniform Array, Binomial Array, Dolph-Chebyshev Array, and Taylor Array. This research is done in the real propagation environment in order to define precisely the number of antenna elements, the distance between the elements, the angle of the antenna arrays, the side lobe level and the n-bar array distribution. The testing process is done by using Matlab and the Non-Uniform Array Simulation Program. The results obtained for various types of antenna arrays are as follows: On Uniform Array produces Half Power Beam Width (HPBW) of 10.152&deg; and directivity of l0 dB, on Binomial Array generates Half Power Beam Width (HPBW) of 20.245&deg; and directivity of 7.47 dB, on Dolph-Chebyshev Arrayproduces Half Power Beam Width (HPBW) of 20.304&deg; and directivity of 4.0185 dB, and on Taylor Arrayproduces Half Power Beam Width (HPBW) of 12.78&deg; and directivity of 8.9 dB.},
key = {Antenna arrays},
keywords = {Antenna lobes;Bins;MATLAB;Planning;Software testing;Sustainable development;},
note = {Binomial arrays;Chebyshev arrays;Real propagation;Taylor Array;Uniform array;},
URL = {http://dx.doi.org/10.1088/1757-899X/105/1/012015},
} 


@inproceedings{20164002862481 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stress testing ethernet switches for nectarcam in the cherenkov telescope array with a synchronous UDP frame generator},
journal = {Proceedings of Science},
author = {Hoffmann, D. and Houles, J. and Louis, F. and Moudden, Y. and Sizun, P. and Gu, W. and Raydo, B.},
volume = {30-July-2015},
year = {2015},
issn = {18248039},
address = {The Hague, Netherlands},
abstract = {The Cherenkov Telescope Array (CTA) will be the next generation ground-based gamma-ray instrument. It will be made up of approximately 100 telescopes of at least three different sizes, from 4 to 23 meters in diameter. The NectarCAM is a Cherenkov camera proposed for the Mid- Size Telescopes of CTA. Its characteristics make it one of the most challenging camera projects for a high speed data acquisition (DAQ) system in CTA has due to its average output rate of up to 40-Gbps on 265 Ethernet 1000baseT links, bundled to 4-10Gbps on four optical links and reduced to 10 Gbps after event-building. This paper presents results on characterisation and validation procedures carried out on several Ethernet switches, which have been considered as hardware for the camera-internal data traffic of NectarCAM. Two complementary types of data generators, one highly synchronous with up to 64 1-Gbps channels based on an FPGA core, the other with up to 320 1-Gbps channels working on 64 Scientific Linux boards, have been built and used to stimulate the DAQ system with six Ethernet switches and a standard Linux PC for IP packet reception.},
} 


@inproceedings{20063510088922 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {LCD display screen performance testing for handheld thermal imaging cameras},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Dinaburg, Joshua B. and Amon, Francine and Hamins, Anthony and Boynton, Paul},
volume = {6207},
year = {2006},
pages = {SPIE - },
issn = {0277786X},
address = {Kissimmee, FL, United states},
abstract = {Handheld thermal imaging cameras are an important tool for the first responder community. As their use becomes more prevalent, it will become important for a set of standard test metrics to be available to characterize the performance of these cameras. A major factor in the performance of the imagers is the quality of the image on a display screen. An imager may employ any type of display screen, but the results of this paper will focus on those using liquid crystal displays. First responders, especially firefighters, in the field rely on the performance of this screen to relay vital information during critical situations. Current research on thermal imaging camera performance metrics for first responder applications uses trained observer tests or camera composite output signal measurements. Trained observer tests are subjective and composite output tests do not evaluate the performance of the complete imaging system. It is the goal of this work to develop a non-, destructive, objective method that tests the performance of the entire thermal imaging camera system, from the infrared sensor to the display screen. Application of existing display screen performance metrics to thermal imaging cameras requires additional consideration. Most display screen test metrics require a well defined electronic input, with either full black or white pixel input, often encompassing detailed spatial patterns and resolution. Well characterized thermal inputs must be used to obtain accurate, repeatable, and non-destructive display screen measurements for infrared cameras. For this work, a thermal target is used to correlate the measured camera output with the actual display luminance. A test method was developed to determine display screen luminance. A well characterized CCD camera and digital recording device were used to determine an electro-optical transfer function for thermal imaging cameras. This value directly relates the composite output signal to the luminance of the display screen, providing a realistic characterization of system performance.},
key = {Cameras},
keywords = {Charge coupled devices;Electronic equipment testing;Infrared imaging;Liquid crystal displays;Nondestructive examination;},
note = {Display performance;Infrared cameras;Performance metrics;Thermal imagers;TIC;},
URL = {http://dx.doi.org/10.1117/12.666280},
} 


@inproceedings{20120714771402 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance extrapolation for load testing results of mixture of applications},
journal = {Proceedings - UKSim 5th European Modelling Symposium on Computer Modelling and Simulation, EMS 2011},
author = {Duttagupta, Subhasri and Nambiar, Manoj},
year = {2011},
pages = {424 - 429},
address = {Madrid, Spain},
abstract = {Load testing of IT applications faces the challenge of providing high quality test results that would represent the performance in production like scenarios, without incurring high cost of commercial load testing tools. It would help IT projects to be able to test with a small number of users and extrapolate to scenarios with much larger number of users. Such an extrapolation strategy when applied to mixture of application workloads running on a shared server environment must take into consideration application characteristics (CPU/IO intensive, memory bound) as well the server capabilities. The goal is to predict the performance of mixture workload, the maximum throughput offered by the application mix and the maximum number of users supported by the system before the throughput starts degrading. In this paper, we propose an extrapolation strategy that analyses a system workload mix based on its service demand on various resources and extrapolates its performance using simple empirical modeling techniques. Moreover, its ability to extrapolate throughput of an application mixture even if there is a change in the mixture, can help in capacity planning of the system. &copy; 2011 IEEE.<br/>},
key = {Load testing},
keywords = {Communication channels (information theory);Extrapolation;Mixtures;Throughput;},
note = {Capacity planning;High Quality Test;IT applications;Maximum through-put;multi-classes of job;Performance extrapolation;S Curve;System workloads;},
URL = {http://dx.doi.org/10.1109/EMS.2011.56},
} 


@article{20111413898728 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Construction and performance testing of small-scale wind power system},
journal = {World Academy of Science, Engineering and Technology},
author = {Soe, Aye Khaing and Swe, Wanna},
volume = {75},
year = {2011},
pages = {156 - 160},
issn = {2010376X},
abstract = {Most countries are trying electricity from many natural resources. Wind power system is one type of renewable energy and small-wind power system is widely used in home-use system. Therefore it can supply the nation's energy needs from one point. Small wind power system can be constructed with materials which can easily get within local market. This paper elaborates on the construction and testing of small-scale wind power system. This project produces an investigational exploration of the horizontal axis wind turbine. It also describes performance testing and results of wind generator model. This system is especially intended for home lighting system which directly uses DC power. And this system also intend for rural people to use easily and inexpensively. The site of this small wind turbine is selected in remote places so far from the national grids.<br/>},
key = {Electric power transmission networks},
keywords = {DC motors;Permanent magnets;Wind power;Wind turbines;},
note = {Blocking diodes;Horizontal axis wind turbines;Multimeter;Performance testing;Permanent magnet DC motors;Renewable energies;Small wind turbine;Wind generator systems;},
} 


@article{20125215844002 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Construction and performance testing of small-scale wind power system},
journal = {World Academy of Science, Engineering and Technology},
author = {Soe, Aye Khaing and Swe, Wanna},
volume = {51},
year = {2011},
pages = {156 - 160},
issn = {2010376X},
abstract = {Most countries are trying electricity from many natural resources. Wind power system is one type of renewable energy and small-wind power system is widely used in home-use system. Therefore it can supply the nation's energy needs from one point. Small wind power system can be constructed with materials which can easily get within local market. This paper elaborates on the construction and testing of small-scale wind power system. This project produces an investigational exploration of the horizontal axis wind turbine. It also describes performance testing and results of wind generator model. This system is especially intended for home lighting system which directly uses DC power. And this system also intend for rural people to use easily and inexpensively. The site of this small wind turbine is selected in remote places so far from the national grids.},
key = {Wind power},
keywords = {DC motors;Wind turbines;},
note = {Blocking diodes;Dc power;Energy needs;Horizontal axis wind turbines;Lighting systems;Local markets;Multimeter;National Grid;Performance testing;Permanent magnet DC motors;Remote places;Renewable energies;Rural people;Small wind power;Small wind turbine;Wind generator systems;},
} 


@inproceedings{20161502225478 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing and assessment of multi-vendor protection schemes using proprietary protocols and the IEC 61850 standard},
journal = {Proceedings of the Conference on the Industrial and Commercial Use of Energy, ICUE},
author = {Arnold, T. and Adewole, A.C. and Tzoneva, R.},
volume = {2015-September},
year = {2015},
pages = {284 - 290},
issn = {21660581},
address = {Cape Town, South africa},
abstract = {The International Electrotechnical Commission (IEC) developed a global standard for power system communication permitting Intelligent Electronic Devices (IEDs) to interoperate within the smart grid environment. However, in order for electric power utility companies to adopt IEC 61850 standard-based devices with confidence, it is necessary to carry out performance tests and evaluations to allay their fears. This paper presents an evaluation of the performance of IEC 61850 standard-based devices with respect to their speed, security, and dependability of operation. The study was implemented using multi-vendor IEDs configured for a Permissive Overreaching Transfer Trip (POTT) communication scheme with conventional proprietary protocols and the IEC 61850 Generic Object Oriented Substation Events (GOOSE) messages based on hardware-in-the-loop simulations with the Real-Time Digital Simulator (RTDS). RSCAD software was used in the modelling of a typical power system network protected by two multi-vendor distance protection IEDs using a lab-scale testbed designed and implemented for the investigations relating to this paper. Real-time simulations for various fault locations and fault resistances were carried out. The results obtained demonstrated the dependability and security of the operation of the IEC 61850-based POTT communication scheme with faster operating times compared with the conventional POTT communication scheme based on vendor-specific proprietary protocols. This paper could serve as a reference to electric power utility companies as they adopt IEC 61850 standard-based devices in their networks. &copy; 2015 CPUT.},
key = {Electric power system protection},
keywords = {Digital devices;Electric fault currents;Electric power systems;Electric power transmission networks;Electric substations;Electron devices;Electronic equipment;Object oriented programming;Smart power grids;Standards;Thermoelectric equipment;},
note = {Distance protection;GOOSE;IEC 61850;Intelligent electronic device;POTT;Real time digital simulation;},
URL = {http://dx.doi.org/10.1109/ICUE.2015.7280280},
} 


@article{20144700216949 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Axis geometrical errors analysis through a performance test to evaluate kinematic error in a five axis tilting-rotary table machine tool},
journal = {Precision Engineering},
author = {Alessandro, Velenosi and Gianni, Campatelli and Antonio, Scippa},
volume = {39},
year = {2015},
pages = {224 - 233},
issn = {01416359},
abstract = {Geometrical work piece errors in milling process are commonly generated by different error sources. Axis geometrical errors, such as the straightness error for linear axis and the offset location error of the origin of rotary axis, introduce kinematic error in the tool path. Direct measurement of kinematic error requires special devices such as laser interferometers, grid plate encoders or double ball bars, which impose production stop and specialized staff. These problems could be analyzed using indirect measurements obtained by means of a cutting performance test that is already a standard for three axis machine tools. Because of the different architectures of five-axis milling machines these tests are hardly standardizable, therefore this paper proposes a devised easy-to-use and time efficient cutting performance test to identify and quantify axis geometrical errors for a five axis tilting-rotary table machine tool. This test can be performed as a periodical checkup or, in case of production, as a re-start test. The main goal of this study is to develop a kinematic analytical model capable of correlating the work-piece geometrical errors to the axis geometrical errors of the machine tool. The model has been implemented on a multi-body software in order to simulate the axes motion sequence of the performance test and validated to decouple the kinematic error into the geometrical axis errors. The developed models have demonstrated to be capable of correcting a generic five axis tool path by predicting the tool-path error displacement. The overall validation of this approach has been carried out by comparing the simulated and experimentally measured profile of the NAS 979 standard five axis contouring cone frustum profile.<br/> &copy; 2014 Elsevier Inc.},
key = {Errors},
keywords = {Cutting tools;Geometry;Interferometers;Kinematics;Laser interferometry;Machine tools;Milling (machining);Milling machines;Software testing;Testing;},
note = {Accuracy;Cutting test;Different architectures;Five-axis machine tools;Indirect measurements;Kinematic error;Laser interferometer;Straightness errors;},
URL = {http://dx.doi.org/10.1016/j.precisioneng.2014.09.007},
} 


@inproceedings{20172503792353 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {ADVISOR Simulation and Performance Test of Split Plug-in Hybrid Electric Vehicle Conversion},
journal = {Energy Procedia},
author = {Rashid, Muhammad Ikram Mohd and Danial, Hamdan},
volume = {105},
year = {2017},
pages = {1408 - 1413},
issn = {18766102},
address = {Beijing, China},
abstract = {With increasing concern over the environment and ever stringent emissions regulations, the electric vehicle has been investigated as an alternative form of transportation. However, the electric vehicle suffers from relatively short range and long charging times and consequently has not become an acceptable solution to the automotive consumer. The addition of an internal combustion engine to extend the range of the electric vehicle is one method of exploiting the high efficiency and lack of emissions of the electric vehicle while retaining the range and convenient refuelling times of a conventional gasoline powered vehicle. The term that describes this type of vehicle is a hybrid electric vehicle. Many configurations of hybrid electric vehicles have been designed and implemented, namely the series, parallel and power-split configurations. This paper discusses the modelling and simulation of split plug-in hybrid electric vehicles. Modelling methods such as physics-based Resistive Companion Form technique and Bond Graph method are presented with powertrain component and system modelling examples. The modelling and simulation capability of existing tools such as ADvanced VehIcle SimulatOR (ADVISOR) is demonstrated through application examples. Hardware implementation has been done and tested on dyno and real road test. An experimental result has been compared to simulation results. Since power electronics is indispensable in hybrid vehicles, the issue of numerical oscillations in dynamic simulations involving power electronics is briefly addressed. &copy; 2017 The Authors.},
key = {Plug-in hybrid vehicles},
keywords = {Hardware;Hybrid vehicles;Internal combustion engines;Power electronics;Vehicles;},
note = {ADVISOR;Emissions regulations;Hardware implementations;Modelling and simulations;Plug in hybrid electric vehicles;Plug-in hybrids;Resistive Companion Form;Split-hybrid;},
URL = {http://dx.doi.org/10.1016/j.egypro.2017.03.524},
} 


@inproceedings{20153001060092 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Analysis and design of selenium webdriver automation testing framework},
journal = {Procedia Computer Science},
author = {Gojare, Satish and Joshi, Rahul and Gaigaware, Dhanashree},
volume = {50},
year = {2015},
pages = {341 - 346},
issn = {18770509},
address = {Chennai, India},
abstract = {Nowadays, number of software system has been implemented as web-based applications. These web applications are very complex. It is very difficult to test such complex web applications. Automation testing uses automation tools to reduce human intervention and repeatable tasks. In this paper we have designed and implemented automation testing framework for testing web applications. This new automation testing framework has been implemented using selenium WebDriver tool. Using this framework tester can easily write their test cases efficiently and in less time. Tester need not to study the selenium webdriver tool in detail. This framework is helpful to developer to analyze their code due to screen shot property of framework. This framework produces the customized test report to tester. It is very easy to maintain and repair the test suite for new release of the application using this framework. &copy; 2015 The Authors. Published by Elsevier B.V.},
key = {Big data},
keywords = {Application programs;Automation;Selenium;Social networking (online);World Wide Web;},
note = {Automation testing;Automation tools;Human intervention;Software systems;Test case;Test reports;WEB application;Web-based applications;},
URL = {http://dx.doi.org/10.1016/j.procs.2015.04.038},
} 


@inproceedings{20145000305850 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {An effective automation testing framework for OATS tool},
journal = {Advances in Intelligent Systems and Computing},
author = {Ramasamy, Gobi and Ramalingam, Sathishkumar},
volume = {324},
year = {2015},
pages = {543 - 550},
issn = {21945357},
address = {Kumaracoil, India},
abstract = {Oracle application test suite (OATS) is a test tool of Oracle. It is a very good integrated testing tool for Web applications, Web services, Oracle applications, and Oracle databases. The Oracle application testing suite is part of the Oracle Enterprise Manager product family and comprises the following tightly integrated products. They are Oracle load testing for scalability, performance and load testing, Oracle functional testing for automated functional and regression testing, and Oracle Test Manager for test process management, including test requirements management, test management, test execution, and defect tracking. OATS uses OpenScript platform. This paper discusses model-based test automation methods and tools referred to collectively as the Test Automation Framework that reduces the time and resources necessary to develop high-quality and high-assurance systems using OATS functional testing tool. Framework is named as Easy to Automate (Ez2Auto) framework. This OATS tool is newly available in market, and there is no established framework available in literature or ready to use in market.<br/> &copy; Springer India 2015.},
key = {Load testing},
keywords = {Artificial intelligence;Automation;Commerce;Evolutionary algorithms;Managers;Model checking;Software testing;Web services;},
note = {Automation tests;Ez2Auto;OATS;Open script;Test suites;},
URL = {http://dx.doi.org/10.1007/978-81-322-2126-5_59},
} 


@inproceedings{20155101691349 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Reverse Tracer: A software tool for generating realistic performance test programs},
journal = {Proceedings - International Symposium on High-Performance Computer Architecture},
author = {Sakamoto, M. and Brisson, L. and Katsuno, A. and Inoue, A. and Kimura, Y.},
volume = {2002-January},
year = {2002},
pages = {81 - 91},
issn = {15300897},
address = {Cambridge, MA, United states},
abstract = {During the development of high-performance processors, software performance models are used to obtain performance estimates. These models are not cycle-accurate, so their results can have significant errors, leading to performance surprises after the hardware is built. Some performance tests can run directly on the logic simulators, to get more accurate results, but those simulators cannot run large interactive workloads with I/O and much operating system code. So the accurate performance estimates from logic simulators are only available for application code, and are not adequate for the evaluation of powerful server systems that are primarily intended to run large interactive workloads. We discuss a software tool system, the "Reverse Tracer", that generates executable performance tests from an instruction trace of the workload. The generated performance tests retain the essential performance characteristics of multi-user I/O-intensive workloads without doing any real I/O, so they can run in logic simulation to measure performance accurately before the hardware is built. &copy; 2002 IEEE.},
key = {Computer software},
keywords = {Computer aided software engineering;Computer architecture;Computer hardware;Embedded systems;Hardware;Simulators;Software testing;Supercomputers;},
note = {Accurate performance;Application codes;Cycle accurate;High performance processors;Logic simulations;Performance characteristics;Performance tests;Software performance models;},
URL = {http://dx.doi.org/10.1109/HPCA.2002.995700},
} 


@inproceedings{20110413611893 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Proposal of automated performance testing tool for vital software in train control system},
journal = {ICCAS 2010 - International Conference on Control, Automation and Systems},
author = {Jo, Hyun-Jeong and Hwang, Jong-Gyu and Lee, Kang-Mi},
year = {2010},
pages = {1151 - 1155},
abstract = {In accordance with the development of recent computer technology, the dependency of train control system on the computer software is being increased further, and accordingly, the testing for the safety and reliability of train control system software became more important. Hence, the safety assurance of the vital software running on the train control system is very critical task and yet, not many works have been done. While much efforts have been reported to improve electronic hardware's safety, not so much systematic approaches to evaluate software's safety. In this paper, we suggested an automated tool for performance testing in train control system, and presented its result of implementation. The testing items in the implemented tool had referred to the international standards in relation to the software for train control system, such as IEC 61508 and IEC 62279. In these international standards, 'performance testing' for train control system S/W has to be recommended highly. &copy;ICROS.<br/>},
key = {Computer control systems},
keywords = {Automation;Computer control;Computer software selection and evaluation;Safety testing;Software reliability;Software testing;Vehicle performance;},
note = {Automated tools;Computer technology;Electronic hardwares;International standards;Performance testing;Safety assurance;Software safety;Train control systems;},
} 


@inproceedings{20131016093036 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Application stress testing: Achieving cyber security by testing cyber attacks},
journal = {2012 IEEE International Conference on Technologies for Homeland Security, HST 2012},
author = {Underbrink, Al and Potter, Andrew and Jaenisch, Holger and Reifer, Donald J.},
year = {2012},
pages = {556 - 561},
address = {Waltham, MA, United states},
abstract = {Application stress testing applies the concept of computer network penetration testing to software applications. Since software applications may be attacked - from inside or outside a protected network boundary - they are threatened by actions and conditions which cause delays, disruptions, or failures. Stress testing exposes software systems to simulated cyber attacks, revealing potential weaknesses and vulnerabilities in their implementation. By using such testing, these internal weaknesses and vulnerabilities can be discovered earlier in the software development life cycle, corrected prior to deployment, and lead to improved software quality. Application stress testing is a process and software prototype for verifying the quality of software applications under severe operating conditions. Since stress testing is rarely - if at all - performed today, the possibility of deploying critical software systems that have been stress tested provides a much stronger indication of their ability to withstand cyber attacks. Many possible attack vectors against critical software can be verified as true threats and mitigated prior to deployment. This improves software quality and serves as a tremendous risk reduction for critical software systems used in government and commercial enterprises. The software prototype models and verifies failure conditions of a system under test (SUT). The SUT is first executed in a virtual environment and its normal operational modes are observed. A normal behavior model is generated in order to predict failure conditions based on attack models and external SUT interfaces. Using off-the-shelf software tools, the predictions are verified in the virtual environment by stressing the executing SUT with attacks against the SUT. Results are presented to testers and system developers for dispensation or mitigation. &copy; 2012 IEEE.},
key = {Software testing},
keywords = {Ability testing;Application programs;Computer software selection and evaluation;Crime;National security;Security systems;Software design;Software prototyping;Virtual reality;},
note = {Application testing;attack;Attack model;Attack vector;Commercial enterprise;Critical software;Cyber security;Cyber-attacks;Failure conditions;Network penetration testing;Normal behavior;Operating condition;Operational modes;Penetration testing;Protected networks;Quality of softwares;Risk reductions;Software applications;Software assurance;Software development life cycle;Software prototypes;Software Quality;Software systems;Stress Testing;System developers;System under test;},
URL = {http://dx.doi.org/10.1109/THS.2012.6459909},
} 


@inproceedings{20180104610715 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and implementation of bank financial business automation testing framework based on QTP},
journal = {Proceedings of 2016 5th International Conference on Computer Science and Network Technology, ICCSNT 2016},
author = {Xie, Xianjie and Yang, Zhijun and Yu, Jiankun and Zhang, Weifeng},
year = {2016},
pages = {143 - 147},
address = {Changchun, China},
abstract = {The current software testing in the aspects of industrial benefits gradually causes the attention of the domestic financial bank. The innovation of software technology, the increase of software scale and the shortened developing period make the traditional manual testing meeting enormous challenges, while the development of automated testing technology has promoted the progress of the software testing industry. Because of the particularity of financial and banking services, the bank is under an obligation to ensure the quality and reliability of software. Therefore it's vital to test the software. In specific practice, although the powerful third-party testing tools can be used as a solution, it is hard to rely on certain tool to implement automated testing, hence a framework of automated test is required to be introduced for testing, which intends to handle high efficiency and high-quality testing for software automation. This paper proposes a kind of software automation testing framework based on QTP, mainly targeting on the core of the bank, credit, online banking to test the function of the three major operations. The framework is a secondary development based on QTP and mainly for regression testing of software, which integrates techniques including object recognition, data-driven, and keyword-driven technology, checkpoint technology, to proceed business-level testing. The paper expatiated on four issues, which were the test system design, the test standardization, the testing framework design and the testing of the implementation. The practical application shows that the framework can improve the operational efficiency, reduce the test cost, and guarantee the smooth progress of the software automation testing.<br/> &copy; 2016 IEEE.},
key = {Software testing},
keywords = {Application programs;Automation;Computer networks;Computer software;Efficiency;Finance;Object recognition;Software engineering;Software reliability;Testing;},
note = {Automated testing tools;Business automation;Design and implementations;Operational efficiencies;Secondary development;Software automation;Software technology;Test automation frameworks;},
URL = {http://dx.doi.org/10.1109/ICCSNT.2016.8070136},
} 


@inproceedings{20174104268960 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Based on the analysis of mobile terminal application software performance test},
journal = {Proceedings - 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing, SNPD 2017},
author = {Chunye, Du and Wei, Song and Jianhua, Wu},
year = {2017},
pages = {391 - 394},
address = {Kanazawa, Japan},
abstract = {With the rapid development of mobile terminal, mobile applications are gradually penetrated into all aspects of people's life and work. Mobile games, mobile streaming media, location services, mobile Internet news, instant messaging, mobile music and other rich and colorful information era are changing the social life. In view of this, we propose the application software performance test based on the mobile terminal, and analyze the performance test technology and method of the mobile application. Experimental results show that the performance test of the application system can predict the pressure in real environment, the system will be applied in the problems exposed, through the analysis of the data of the test, it will provide help for performance optimization of application system. &copy; 2017 IEEE.},
key = {Application programs},
keywords = {Artificial intelligence;Computer software;Computer terminals;Media streaming;Mobile computing;Mobile phones;Mobile telecommunication systems;Software engineering;Software testing;Testing;},
note = {Loadrunner;Mobile applications;Mobile terminal;Performance tests;Test method;Test technology;},
URL = {http://dx.doi.org/10.1109/SNPD.2017.8022751},
} 


@inproceedings{20174604403370 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Automation testing framework for web applications with selenium WebDriver: Opportunities and threats},
journal = {ACM International Conference Proceeding Series},
author = {Vila, Elior and Novakova, Galia and Todorova, Diana},
volume = {Part F131200},
year = {2017},
pages = {144 - 150},
address = {Bangkok, Thailand},
abstract = {The present paper discusses the need of automation testing in the process of software development, in order to provide high quality, robust and reliable software product. It answers the question why automation testing plays such a significant role in software development lifecycle as well as why not to use already existing automation testing tools when testing web applications and why it is better to create automation testing framework. Some reliable approaches how to build a testing framework are investigated. Selenium WebDriver tool is pointed out as appropriate solution when creating such framework and its wide use is outlined. Moreover, the paper provides analysis and detailed list of opportunities and threats of using Selenium WebDriver tool. The paper concludes by providing arguments for the value of the creation of automation framework for Web applications with Selenium WebDriver.<br/> &copy; 2017 Association for Computing Machinery.},
key = {Software testing},
keywords = {Application programs;Automation;Image processing;Network function virtualization;Selenium;Software design;Software engineering;},
note = {Automation testing;High quality;Software development life cycle;Software products;Testing framework;WEB application;},
URL = {http://dx.doi.org/10.1145/3133264.3133300},
} 


@inproceedings{20102713049591 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Webteste: A stress test tool},
journal = {WEBIST 2006 - 2nd International Conference on Web Information Systems and Technologies, Proceedings},
author = {Saba, Hugo and De Freitas Jorge, Eduardo Manuel and Costa, Victor Franco and De Barros Pereira, Hernane Borges},
volume = {IT/WIA},
year = {2006},
pages = {246 - 249},
address = {Setubal, Portugal},
abstract = {The usage of web applications has became a very common activity in the organizations' scope. From the software engineering perspective, the incessant search for production of more robust softwares, with better quality, is a continuous requirement. The main purpose of this paper is to present the WebTeste, which is a test tool used to verify the robustness of a web application. After comparison of several simulation's results, the use of distributed and ordered computers suggests more reliable tests. In addition, the analysis of the obtained results can suggest a new (re)design of a web system. The WebTeste could be used to perform stress test in order to verify the robustness of a web application more precisely. &copy; 2010.},
key = {Web crawler},
keywords = {Information systems;Software engineering;Testing;},
note = {Engineering perspective;Robust software;Stress test;Stress test tools;WEB application;Web servers;Web system;WebTeste;},
} 


@article{1996463344529 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing a large finance application},
journal = {IEEE Software},
author = {Grossman, David and McCabe, M.Catherine and Staton, Christopher and Bailey, Bret and Frieder, Ophir and Roberts, David C.},
volume = {13},
number = {5},
year = {1996},
pages = {50 - 54},
issn = {07407459},
abstract = {American Management System's Federal Financial System, a financial accounting application, was applied in a Customer Information Control System DB2 environment running on a large IBM mainframe. A test tool, TPNS (Teleprocessing Network Simulator), was used to verify if the software's performance is within acceptable standards. Detailed tuning was made after the development of the initial prototype. The test produced a fair approximation of the actual performance during the first two years of operation.},
key = {Computer software selection and evaluation},
keywords = {Computer aided software engineering;Computer operating systems;Computer simulation;Database systems;Financial data processing;Response time (computer systems);},
note = {Software package Federal financial system;Software package Teleprocessing network simulator;},
URL = {http://dx.doi.org/10.1109/52.536458},
} 


@article{20104913468013 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A genetic algorithm-based stress test requirements generator tool and its empirical evaluation},
journal = {IEEE Transactions on Software Engineering},
author = {Garousi, Vahid},
volume = {36},
number = {6},
year = {2010},
pages = {778 - 797},
issn = {00985589},
abstract = {Genetic algorithms (GAs) have been applied previously to UML-driven stress test requirements generation with the aim of increasing chances of discovering faults relating to network traffic in distributed real-time systems. However, since evolutionary algorithms are heuristic, their performance can vary across multiple executions, which may affect robustness and scalability. To address this, we present the design and technical detail of a UML-driven, GA-based stress test requirements generation tool, together with its empirical analysis. The main goal is to analyze and improve the applicability, efficiency, and effectiveness and also to validate the design choices of the GA used in the tool. Findings of the empirical evaluation reveal that the tool is robust and reasonably scalable when it is executed on large-scale experimental design models. The study also reveals the main bottlenecks and limitations of the tools, e.g., there is a performance bottleneck when the system under test has a large number of sequence diagrams which could be triggered independently from each other. In addition, issues specific to stress testing, e.g., the impact of variations in task arrival pattern types, reveal that the tool generally generates effective test requirements, although the features of those test requirements might be different in different runs (e.g., different stress times from the test start time might be chosen). While the use of evolutionary algorithms to generate software test cases has been widely reported, the extent, depth, and detail of the empirical findings presented in this paper are novel and suggest that the proposed approach is effective and efficient in generating stress test requirements. It is hoped that the findings of this empirical study will help other SBSE researchers with the empirical evaluation of their own techniques and tools. &copy; 2010 IEEE.<br/>},
key = {Software testing},
keywords = {Genetic algorithms;Heuristic algorithms;Interactive computer systems;Real time systems;},
note = {Distributed real time system;Empirical analysis;Empirical evaluations;Genetic algorithm (GAs);Performance bottlenecks;Stress Testing;Test Automation;Test tools;},
URL = {http://dx.doi.org/10.1109/TSE.2010.5},
} 


@inproceedings{2005159032294 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Experiences integrating and scaling a performance test bed generator with an open source CASE tool},
journal = {Proceedings - 19th International Conference on Automated Software Engineering, ASE 2004},
author = {Cai, Yuhong and Grundy, John and Hosking, John},
year = {2004},
pages = {36 - 45},
address = {Linz, Austria},
abstract = {We report on our experiences developing a performance test-bed generator for industrial usage by extending an open-source UML CASE tool. This tool generates client and server code, database configuration and deployment scripts from a high-level software architecture description. It automates the code generation, compilation, deployment and performance metric result collection processes. We identify a range of problems that arose from our previous research on performance test-bed generation that needed to be addressed to scale this automated software engineering technique. We describe a range of approaches we used to solve these problems in our new tool. We then report on industrial deployment and evaluation of our new tool and discuss the effectiveness of these solutions. &copy; 2004 IEEE.},
key = {Computer aided software engineering},
keywords = {Codes (symbols);Computer architecture;Computer programming languages;Computer simulation;Computer software;Database systems;Industrial applications;Mathematical models;Problem solving;Program compilers;},
note = {Architectural analysis;Experience report;Software performance testing;Software tool extension;},
} 


@inproceedings{20111213849200 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design of comprehensive performance test system for residual current fire monitoring detector based on virtual instrument technology},
journal = {Proceedings - 3rd International Conference on Measuring Technology and Mechatronics Automation, ICMTMA 2011},
author = {Xie, Qi and Xu, Wei and Gu, Qimin and Xu, Huigang},
volume = {1},
year = {2011},
pages = {950 - 953},
abstract = {Aiming at the need of detecting the residual current fire monitoring detector, an intelligent test system based on virtual instrument technology was designed. This system was composed of industrial computer, data acquisition card, signal conditioning circuit, three-phase great current generator and pneumatic fixture, etc. Using LabVIEW virtual instrument technology platform, the related test and data processing program codes were developed, and its high speed data acquisition and data processing satisfied the needs of ex-factory comprehensive performance test for residual current fire monitoring detector. The hardware design was given and the working principles of this generator were introduced, the module design of system software was also introduced in detail. Practical application shows that the intelligent test system features with stable and reliable, easy to operate and maintain, high precision and can improve the design and performance of products, which can be widely used.<br/>},
key = {Software testing},
keywords = {Data acquisition;Data handling;Digital instruments;Fires;Product design;Signal conditioning circuits;Signal processing;},
note = {Comprehensive performance;Data acquisition cards;Fire Monitoring;High speed data acquisition;Intelligent test;Intelligent test system;LabVIEW virtual instrument;Virtual instrument technology;},
URL = {http://dx.doi.org/10.1109/ICMTMA.2011.238},
} 


@inproceedings{1994031191086 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Load testing software using deterministic state testing},
journal = {Proceedings of the 1993 International Symposium on Software Testing and Analysis (ISSTA)},
author = {Avritzer, Alberto and Larson, Brian},
year = {1993},
pages = {82 - 88},
address = {Cambridge, MA, USA},
abstract = {In this paper we introduce a new load testing technique called Deterministic Markov State Testing and report on its application. Our approach is called 'deterministic' because the sequence of test case execution is set at planning time, and 'state testing' because each test case certifies a unique software state. There are four main advantages of Deterministic Markov State Testing for system testers: provision of precise software state information for root cause analysis in load test, accommodation for limitations of the system test lab configuration, higher acceleration ratios in system test, and simple management of distributed execution of test cases. System testers using the proposed method have great flexibility in dealing with common system test problems: limited access to the system test environment, unstable software, or changing operational conditions. Because each test case verifies correct execution on a path from the idle state to the software state under test, our method does not require the continuous execution of all test cases. Deterministic Markov State Testing is operational-profile-based, and allows for measurement of software reliability robustness when the operational profile changes.},
key = {Computer software},
keywords = {Computer system recovery;Distributed computer systems;Failure analysis;Probability;Random processes;Reliability;Robustness (control systems);Software engineering;Statistical tests;Telecommunication systems;},
note = {Deterministic Markov State Testing;Load testing software;Operational profile;Planning time;Software reliability robustness;System testers;},
} 


@inproceedings{20145000302487 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance evaluation of web based automation testing tools},
journal = {Proceedings of the 5th International Conference on Confluence 2014: The Next Generation Information Technology Summit},
author = {Angmo, Rigzin and Sharma, Monika},
year = {2014},
pages = {731 - 735},
address = {Noida, India},
abstract = {In today's 21<sup>st</sup> century era countless software applications are written as a web based application which runs in a web browsers. With new technologies and commercialization of I.T. sector, the web based system has undergoes frequent and rapid changes. Today Softwares are coded as a web based application, which help to access data from any part of the globe. Even the economic relevance of web based enhances the control and quality of software. The quality assurance of any system depends on its test. But to do manually testing in most of the cases is time consuming, expensive and hectic. For the better business purpose and to save time and money automation testing is required. There are variety of tools are available in the market for this. One of the best known tool is selenium suite which is a combination of different automation testing tool. In this paper we will discuss about the selenium suite. It provides testers with different framework for different test cases. The main objective of this paper is to find the best tool in selenium suite and then compare it with some other tool for same task. For this purpose, performance evaluation is done on the basis of some criteria.},
URL = {http://dx.doi.org/10.1109/CONFLUENCE.2014.6949287},
} 


@inproceedings{1994011191086 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Load testing software using deterministic state testing},
author = {Avritzer, Alberto and Larson, Brian},
year = {1993},
pages = {82 - 88},
address = {Cambridge, MA, United states},
abstract = {In this paper we introduce a new load testing technique called Deterministic Markov State Testing and report on its application. Our approach is called 'deterministic' because the sequence of test case execution is set at planning time, and 'state testing' because each test case certifies a unique software state. There are four main advantages of Deterministic Markov State Testing for system testers: provision of precise software state information for root cause analysis in load test, accommodation for limitations of the system test lab configuration, higher acceleration ratios in system test, and simple management of distributed execution of test cases. System testers using the proposed method have great flexibility in dealing with common system test problems: limited access to the system test environment, unstable software, or changing operational conditions. Because each test case verifies correct execution on a path from the idle state to the software state under test, our method does not require the continuous execution of all test cases. Deterministic Markov State Testing is operational-profile-based, and allows for measurement of software reliability robustness when the operational profile changes.},
key = {Computer software},
keywords = {Statistical tests;Software engineering;Robustness (control systems);Reliability;Distributed computer systems;Telecommunication systems;Random processes;Probability;Failure analysis;Computer system recovery;},
note = {Load testing software;Deterministic Markov State Testing;System testers;Software reliability robustness;Operational profile;Planning time;},
URL = {http://dx.doi.org/10.1145/154183.154244},
} 


@inproceedings{1991100274593 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Development of an economical, software-controlled battery load testing system},
journal = {INTELEC, International Telecommunications Energy Conference (Proceedings)},
author = {Hadfield, J.A.},
year = {1990},
pages = {553 - 555},
issn = {02750473},
address = {Orlando, FL, USA},
abstract = {Battery discharge capacity tests have traditionally been performed manually, although several mechanized systems are commercially available. A need was identified at the Manitoba Telephone System (MTS) to accurately and economically load test batteries in the field, to verify the capacity of new installations as well as to assist determining the true end-of-life of existing strings. The development of an economical, software-controlled system for testing -48-volt battery strings in the telephone environment is discussed.},
key = {Electric Batteries},
keywords = {Computer Software;Electric Discharges;Telephone Systems;},
note = {Battery Discharges;Battery Loads;Battery Strings;},
} 


@inproceedings{20171903655049 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Cloudperf: A performance test framework for distributed and dynamic multi-tenant environments},
journal = {ICPE 2017 - Proceedings of the 2017 ACM/SPEC International Conference on Performance Engineering},
author = {Michael, Nicolas and Ramannavar, Nitin and Shen, Yixiao and Patil, Sheetal and Sung, Jan-Lung},
year = {2017},
pages = {189 - 200},
address = {L'Aquila, Italy},
abstract = {The evolution of cloud-computing imposes many challenges on performance testing and requires not only a different approach and methodology of performance evaluation and analysis, but also specialized tools and frameworks to support such work. In traditional performance testing, typically a single workload was run against a static test configuration. The main metrics derived from such experiments included throughput, response times, and system utilization at steady-state. While this may have been sufficient in the past, where in many cases a single application was run on dedicated hardware, this approach is no longer suitable for cloud-based deployments. Whether private or public cloud, such environments typically host a variety of applications on distributed shared hardware resources, simultaneously accessed by a large number of tenants running heterogeneous workloads. The number of tenants as well as their activity and resource needs dynamically change over time, and the cloud infrastructure reacts to this by reallocating existing or provisioning new resources. Besides metrics such as the number of tenants and overall resource utilization, performance testing in the cloud must be able to answer many more questions: How is the quality of service of a tenant impacted by the constantly changing activity of other tenants? How long does it take the cloud infrastructure to react to changes in demand, and what is the effect on tenants while it does so? How well are service level agreements met? What is the resource consumption of individual tenants? How can global performance metrics on application- and system-level in a distributed system be correlated to an individual tenant's perceived performance? In this paper we present CloudPerf, a performance test framework specifically designed for distributed and dynamic multi-tenant environments, capable of answering all of the above questions, and more. CloudPerf consists of a distributed harness, a protocol-independent load generator and workload modeling framework, an extensible statistics framework with live-monitoring and post-analysis tools, interfaces for cloud deployment operations, and a rich set of both lowlevel as well as high-level workloads from different domains. &copy; 2017 Copyright held by the owner/author(s).},
key = {Network function virtualization},
keywords = {Clouds;Hardware;Load testing;Outsourcing;Quality of service;},
note = {Cloud infrastructures;Evaluation and analysis;Heterogeneous workloads;Multi tenancies;Perceived performance;Performance testing;Service Level Agreements;Work-load models;},
URL = {http://dx.doi.org/10.1145/3030207.3044530},
} 


@inproceedings{20105013486840 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design of automatic performance test system for CPS},
journal = {2010 International Conference on Computer, Mechatronics, Control and Electronic Engineering, CMCE 2010},
author = {Xu, Wei and Xu, Huigang and Xie, Qi and Yang, Yunfei and Dai, Mei},
volume = {4},
year = {2010},
pages = {206 - 209},
abstract = {In order to satisfy the needs of comprehensive and accurate performance test for CPS (Control and Protective Switching), an automatic performance test system was studied in this paper. The hardware structure and software was introduced in detail; the hardware system was made up of the industrial control computer, the three-phase current generator, adjustable single-phase power, pneumatic fixture, and so on. The test system software developed by LabVIEW was mainly used to achieve the functions of data acquisition, data processing and data display. The designed system is able to automatically test all functions of different types of CPS, including measurement function, communication function, multiple protection function, and so on. Practical application shows that the test system has following properties: high precision, low cost, strong anti-interference and convenient maintenance. &copy; 2010 IEEE.<br/>},
key = {Computer control systems},
keywords = {Automatic testing;Computer hardware;Computer programming languages;Data acquisition;Data handling;Electric equipment protection;Hardware;Software testing;},
note = {Accurate performance;Automatic test system;Communication functions;Industrial control computer;LabViEW;Measurement function;Performance tests;Three-phase currents;},
URL = {http://dx.doi.org/10.1109/CMCE.2010.5610188},
} 


@inproceedings{20115114614209 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Evaluating load generation in virtualized environments for software performance testing},
journal = {IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum},
author = {Netto, Marco A.S. and Menon, Suzane and Vieira, Hugo V. and Costa, Leandro T. and De Oliveira, Flavio M. and Saad, Rodrigo and Zorzo, Avelino},
year = {2011},
pages = {993 - 1000},
address = {Anchorage, AK, United states},
abstract = {Before placing a software system into production, it is necessary to guarantee it provides users with a certain level of Quality-of-Service. Intensive performance testing is then necessary to achieve such a level and the tests require an isolated computing environment. Virtualization can therefore play an important role for saving energy costs by reducing the number of servers required to run performance tests and for allowing performance isolation when executing multiple tests in the same computing infrastructure. Load generation is an important component in performance testing as it simulates users interacting with the target application. This paper presents our experience in using a virtualized environment for load generation aimed at performance testing. We measured several performance metrics and varied system load, number of virtual machines per physical resource, and the CPU pinning schema for comparison of virtual and physical machines. The two main findings from our experiments are that physical machines produced steadier and faster response times under heavy load and that the pinning schema is an important aspect when setting up a virtualized environment for load generation. &copy; 2011 IEEE.<br/>},
key = {Software testing},
keywords = {Computer architecture;Load testing;Quality of service;Virtual reality;Virtualization;},
note = {Computing environments;Computing infrastructures;Loadrunner;Multicore architectures;Performance isolations;Performance testing;Software performance testing;Virtualized environment;},
URL = {http://dx.doi.org/10.1109/IPDPS.2011.244},
} 


@inproceedings{20163502742304 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A Framework to Evaluate the Effectiveness of Different Load Testing Analysis Techniques},
journal = {Proceedings - 2016 IEEE International Conference on Software Testing, Verification and Validation, ICST 2016},
author = {Gao, Ruoyu and Jiang, Zhen Ming and Barna, Cornel and Litoiu, Marin},
year = {2016},
pages = {22 - 32},
address = {Chicago, IL, United states},
abstract = {Large-scale software systems like Amazon and eBay must be load tested to ensure they can handle hundreds and millions of current requests in the field. Load testing usually lasts for a few hours or even days and generates large volumes of system behavior data (execution logs and counters). This data must be properly analyzed to check whether there are any performance problems in a load test. However, the sheer size of the data prevents effective manual analysis. In addition, unlike functional tests, there is usually no test oracle associated with a load test. To cope with these challenges, there have been many analysis techniques proposed to automatically detect problems in a load test by comparing the behavior of the current test against previous test(s). Unfortunately, none of these techniques compare their performance against each other. In this paper, we have proposed a framework, which evaluates and compares the effectiveness of different test analysis techniques. We have evaluated a total of 23 test analysis techniques using load testing data from three open source systems. Based on our experiments, we have found that all the test analysis techniques can effectively build performance models using data from both buggy or non-buggy tests and flag the performance deviations between them. It is more cost-effective to compare the current test against two recent previous test(s), while using testing data collected under longer sampling intervals (&le; 180 seconds). Among all the test analysis techniques, Control Chart, Descriptive Statistics and Regression Tree yield the best performance. Our evaluation framework and findings can be very useful for load testing practitioners and researchers. To encourage further research on this topic, we have made our testing data publicity available to download. &copy; 2016 IEEE.},
key = {Software testing},
keywords = {Cost effectiveness;Internet;Load testing;Open source software;Open systems;Testing;Verification;},
note = {Analysis techniques;Descriptive statistics;Evaluation framework;Large-scale software systems;Open source system;Performance Model;Performance problems;Sampling interval;},
URL = {http://dx.doi.org/10.1109/ICST.2016.9},
} 


@inproceedings{20133016524771 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A distributed, cross-platform automation testing framework for GUI-driven applications},
journal = {Proceedings of 2nd International Conference on Computer Science and Network Technology, ICCSNT 2012},
author = {Yao, Yepeng and Wang, Xuren},
year = {2012},
pages = {723 - 726},
address = {Changchun, China},
abstract = {With the rapid development of computer technology, nowadays GUIs have been widely used in desktop applications and web applications. GUI-driven application testing is an emergent approach to software testing and plays a key role to assure software quality. This paper first discusses the various methods for testing GUI-driven applications, and then defines a GUI model and formally defines the test case and the test suite. Finally, it proposes a novel automated, distributed and cross-platform testing framework for GUI. Experiments conducted showed that the proposed testing architecture managed to use parallel cross-platform clusters to test heterogeneous applications whose technologies were incompatible with the testing framework. &copy; 2012 IEEE.},
key = {Graphical user interfaces},
keywords = {Automation;Computer science;Computer software selection and evaluation;Software testing;},
note = {Application testing;Automation testing;Computer technology;Cross-platform;Desktop applications;Distributed testing;Software Quality;Testing framework;},
URL = {http://dx.doi.org/10.1109/ICCSNT.2012.6526035},
} 


@inproceedings{20171403536765 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A framework for composing heterogeneous service tools involved in load testing lifecycle},
journal = {Applied System Innovation - Proceedings of the International Conference on Applied System Innovation, ICASI 2015},
author = {Lee, Shin-Jie and Lin, You-Chen and Lin, Kun-Hui and You, Jie-Lin},
year = {2016},
pages = {1075 - 1080},
address = {Osaka, Japan},
abstract = {Load testing is the process of applying ordinary stress to a software system to determine the system performance under normal conditions. In a typical load testing lifecycle, three kinds of service tools are involved: test case recording service tools that make testers easier to generate test cases through a web browsing-like behavior; test case execution service tools that exercise test cases with simulations of a large number of concurrent users; system resource monitoring service tools that provide information of system footprints during the test case executions. However, using these three kinds of service tools one by one to complete a load testing may require extra effort on operating and configuring each service. In this paper, we proposed a framework for composing the three types of service tools as an integrated service for load testing. A raw test case recorded by Badboy tool is automatically converted into an expanded test case that can be executed by JMeter. JMeter and Cacti are then automatically invoked by the framework. The execution time period of JMeter is automatically identified as the input to Cacti for resource monitoring of the system under test. The test report together with system footprints is also automatically generated. In the experimental evaluation, the result shows that the framework significantly save time on operating and configuring the load testing service tools than the traditional approach under a t-test. &copy; 2016 Taylor & Francis Group.},
key = {Software testing},
keywords = {Automatic test pattern generation;Life cycle;Load testing;Monitoring;Network function virtualization;},
note = {Automatically generated;Experimental evaluation;Heterogeneous services;Integrated service;Resource monitoring;System footprints;System under test;Traditional approaches;},
} 


@inproceedings{20112814145531 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Autonomic load-testing framework},
journal = {Proceedings of the 8th ACM International Conference on Autonomic Computing, ICAC 2011 and Co-located Workshops},
author = {Barna, Cornel and Litoiu, Marin and Ghanbari, Hamoun},
year = {2011},
pages = {91 - 100},
abstract = {In this paper, we present a method for performance testing of transactional systems. The methods models the system under test, finds the software and hardware bottlenecks and generate the workloads that saturate them. The framework is autonomic, the model and workloads are determined during the performance test execution by measuring the system performance, fitting a performance model and by analytically computing the number and mix of users that will saturate the bottlenecks. We model the software system using a two-layer queuing model and use analytical techniques to find the workload mixes that change the bottlenecks in the system. Those workload mixes become stress vectors and initial starting points for the stress test cases. The rest of test cases are generated based on a feedback loop that drives the software system towards the worst case behaviour. &copy; 2011 ACM.<br/>},
key = {Software testing},
keywords = {Load testing;Queueing theory;},
note = {Autonomic Systems;Performance Model;Performance testing;Software and hardwares;Stress Testing;System under test;Testing framework;Transactional systems;},
URL = {http://dx.doi.org/10.1145/1998582.1998598},
} 


@article{20111913969112 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Test component assignment and scheduling in a load testing environment},
journal = {Periodica Polytechnica Electrical Engineering},
author = {Eros, Levente and Bozoki, Ferenc},
volume = {52},
number = {3-4},
year = {2008},
pages = {145 - 152},
issn = {03246000},
abstract = {In this paper we introduce two major problems from the field of load (or performance) testing and our solutions for them. When testing the performance of a device (System Under Test - SUT), the test environment executes many software entities (the so-called test components) on the hosts of the test environment (testing hosts). Our goal is to maximize the load on the testing hosts by assigning the test components to them closely to optimal. The first problem to be solved is, thus, a special case of the task assignment problem for which many algorithms have been developed. Our solutions presented in this paper are, however, optimized for distributing load testing traffic in the case of which the possibilities and restrictions to be taken into account are very different from those of the classical task assignment case. The other problem we deal with is how to schedule test components running on the same testing host. Most of the papers written on scheduling focus on the characteristics of the generated load, but not on the way of generating it. These papers usually assume that the load can be generated by improving hardware resources. In this paper, however, we introduce a model and an algorithm which improves the efficiency of scheduling in a load testing environment with way less hardware resources. The algorithm is based on our novel concept of virtual threads. Our simulations have shown that by applying our solutions, the efficiency of load testing can be significantly increased. &copy; Periodica Polytechnica 2008.<br/>},
key = {Load testing},
keywords = {Combinatorial optimization;Computational complexity;Efficiency;Hardware;Scheduling;Software testing;Testing;},
note = {Distributing-load;Hardware resources;Software entities;System under test;Task assignment;Test components;Test Environment;Testing environment;},
URL = {http://dx.doi.org/10.3311/pp.ee.2008-3-4.03},
} 


@inproceedings{20134316874468 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing framework for rest-based web applications},
journal = {Proceedings of the International Symposium on the Physical and Failure Analysis of Integrated Circuits, IPFA},
author = {Kao, Chia Hung and Lin, Chun Cheng and Chen, Juei-Nan},
year = {2013},
pages = {349 - 354},
address = {Nanjing, Jiangsu, China},
abstract = {Recently, enterprises, organizations, and software companies are building more and more web applications to provide their services over the Internet. In order to fulfill various requirements, the complexity of web applications nowadays is increasing dramatically. As a result, the performance characteristics of web applications, including response time, throughput, etc, become more critical than before and should be taken into careful consideration. If the response time of a web application is poor, users may lose their interests even the function of the web application is correct. Therefore, how to execute performance testing on a complex web application systematically and efficiently will be an important issue. In this paper, a performance testing framework for REST-based web applications is introduced. The performance testing framework aims to provide software testers with an integrated process from test cases design, test scripts generation, to test execution. Based on the test cases designed by software testers and the appropriate software artifacts preserved by the framework (e.g., API document), the framework generates the corresponding performance test scripts, which can be executed by specific performance test tools. This helps software testers to focus more in the design of performance test cases. In addition, effort needed to understand the design and implementation of the application and to learn the operation of testing tools decrease. Thus, the efficiency of performance testing can be highly facilitated. &copy; 2013 IEEE.},
key = {Software testing},
keywords = {Applications;Design;Industry;World Wide Web;},
note = {Design and implementations;Performance characteristics;Performance testing;Performance testing framework;Performance tests;Software artifacts;Software company;WEB application;},
URL = {http://dx.doi.org/10.1109/QSIC.2013.32},
} 


@inproceedings{20132216381521 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Model-based performance testing in the cloud using the MBPeT tool},
journal = {ICPE 2013 - Proceedings of the 2013 ACM/SPEC International Conference on Performance Engineering},
author = {Abbors, Fredrik and Ahmad, Tanwir and Truscan, Dragos and Porres, Ivan},
year = {2013},
pages = {423 - 424},
address = {Prague, Czech republic},
abstract = {We present an approach for performance testing of software services. We use Probabilistic Timed Automata to model the workload of the system, by describing how different user types interact with the system. We use these models to generate load in real-time and we measure different performance indicators. An in-house developed tool, MBPeT, is used to support our approach. We exemplify with an auction web service case study and show how performance information about the system under test can be collected. &copy; 2013 Authors.},
key = {Load testing},
keywords = {Automata theory;Benchmarking;Software testing;Web services;},
note = {load generation;Model based testing;Performance indicators;Performance testing;Probabilistic timed automata;Software services;System under test;User type;},
URL = {http://dx.doi.org/10.1145/2479871.2479937},
} 


@inproceedings{20130916056163 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Software performance test automation by using the virtualization},
journal = {Lecture Notes in Electrical Engineering},
author = {Kim, Gwang-Hun and Kim, Yeon-Gyun and Shin, Seok-Kyu},
volume = {215 LNEE},
year = {2013},
pages = {1191 - 1199},
issn = {18761100},
address = {Pyeong Chang, Korea, Republic of},
abstract = {In this paper, we propose a method on software performance test automation by using the virtualization. In general, most test engineers use the public performance testwares such as Load Runner and Silk Performer to validate the performance efficiency of their own systems. In case that they cannot use the performance testwares due to some technical limitations in the testwares, the testers should perform the testing in manually. As waste of computer and human resources is resulted from the situation, we need to propose the test automation scheme by using the virtualization technology to prevent the dissipation in the test environment which has limited resources. The system architecture considered efficient usage of computer resources and test automation to reduce human acts are addressed mainly in this paper. Finally, a number of experiments show that the proposed schemes allow offering the possibility for automated software performance testing by using the virtualization. &copy; 2013 Springer Science+Business Media. automation*Virtualization.},
key = {Software testing},
keywords = {Automation;Virtual reality;},
note = {Computer resources;Performance efficiency;Performance testing;Software performance;Software performance engineerings;Software performance testing;System architectures;Technical limitations;Test Automation;Test engineers;Test Environment;Virtualization technologies;Virtualizations;},
URL = {http://dx.doi.org/10.1007/978-94-007-5860-5_143},
} 


@inproceedings{20151500728902 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {High-volume performance test framework using big data},
journal = {LT 2015 - Proceedings of the 4th ACM/SPEC International Workshop on Large-Scale Testing, in Conjunction with ICPE 2015},
author = {Yesudas, Michael and Girish Menon, S. and Nair, Satheesh K.},
year = {2015},
pages = {13 - 16},
address = {Austin, TX, United states},
abstract = {The inherent issues with handling large files and complex scenarios cause the data-driven approach [1] to be rarely used for performance tests. Volume and scalability testing of enterprise solutions typically requires custom-made test frameworks because of the complexity and uniqueness of data flow. The generation, transformation and transmission of large sets of data pose a unique challenge for testing a highly transactional back-end system like the IBM Sterling Order Management (OMS). This paper describes a test framework built on document-oriented NoSQL database, a design that helps validate the functionality and scalability of the solution simultaneously. This paper also describes various phases of planning, development, and testing of the OMS solution that was executed for a large retailer in Europe to test an extremely high online sales scenario. An out-of-the-box configuration of the OMS with the feature support for database sharding was used to drive scalability. The exercise was a success, and it is the world's largest IBM Sterling Order Management benchmark in terms of sales order volume, to date. Copyright &copy; 2015 ACM.},
key = {Big data},
keywords = {Digital storage;Information management;Load testing;Metadata;Rapid prototyping;Sales;Scalability;Testing;},
note = {Backend system;Data-driven approach;Nosql database;Order management;Performance tests;Test automation tool;Test framework;Test harness;},
URL = {http://dx.doi.org/10.1145/2693182.2693185},
} 


@article{20172903952609 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {OFBench: Performance Test Suite on OpenFlow Switches},
journal = {IEEE Systems Journal},
author = {Lin, Ying-Dar and Lai, Yu-Kuen and Wang, Chen-You and Lai, Yuan-Cheng},
year = {2017},
issn = {19328184},
abstract = {Performance issues of OpenFlow switches are attracting a lot of attention owing to the potential large-scale deployment of software-defined devices. This paper presents the OFBench which is an automatic test suite for evaluating the performance of OpenFlow switches. The design, as part of the Automation Control Test System (ACTS) development, is based on a controller-agent architecture which allows the development of test cases that are written in a high-level script language. In addition to the end-to-end measurement methodology, novel methods are proposed to further profile the internal performance metrics, which are difficult to get due to the black-box nature of the device under test. The prototype of this suite currently comprises five test cases to evaluate five performance metrics, which are action time, pipeline time, buffer size, pipeline efficiency, and timeout accuracy. OpenFlow switches are evaluated and three issues are observed associated with switches during the testing. First, some switches may not be well implemented in the design of apply-action instructions. Second, some switches suffer from random crashes with a high volume of bursty packet-in traffic. Finally, the timer of idle-timeout is often not reset properly with matching flow entry. IEEE},
key = {Computer network performance evaluation},
keywords = {Computer networks;High level languages;Pipelines;Software defined networking;Software testing;Testing;},
note = {Automation controls;End-to-end measurement;Internal performance;Large-scale deployment;Openflow;performance evaluation;Performance metrics;system performance;},
URL = {http://dx.doi.org/10.1109/JSYST.2017.2720758},
} 


@article{20114614512790 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Investigation on performance testing and evaluation of PReWebD: A.NET technique for implementing web application},
journal = {IET Software},
author = {Kalita, M. and Bezboruah, T.},
volume = {5},
number = {4},
year = {2011},
pages = {357 - 365},
issn = {17518806},
abstract = {A prototype research web application based on Visual Studio platform is developed with.NET as framework, Internet Information Server (IIS) (Version: 5.1) as web server and Microsoft Standard Query Language (SQL) Server (Version: 2005) as database server to study the performance and evaluation of the.NET technique used for developing the web application. The authors call it the PReWebD. As the performance is one of the most important features of a web application, to evaluate the performance, testing of PReWebD has been carried out using Mercury LoadRunner (Version 8.0) for validation and to study some other attributes like scalability, reliability etc. The performance depends on parameters such as hits/s, response time, throughput, errors/s etc. These parameters for PReWebD are tested with different stress levels. The statistical testing and analysis is done to assure the stability, reliability and quality of the application. Here the authors report in details the architecture, testing procedure, result of performance testing as well as the results of statistical analysis on recorded data of PReWebD. &copy; 2011 The Institution of Engineering and Technology.<br/>},
key = {Quality control},
keywords = {Query languages;Query processing;Reliability analysis;Software prototyping;Visual languages;Windows operating system;},
note = {Data-base servers;Important features;Internet information servers;Performance testing;Standard query languages;Statistical testing;Testing procedure;WEB application;},
URL = {http://dx.doi.org/10.1049/iet-sen.2010.0139},
} 


@inproceedings{20085211804749 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Test component assignment in a performance testing environment},
journal = {SoftCom 2008: 16th International Conference on Software, Telecommuncations and Computer Networks},
author = {Eros, Levente and Csondes, Tibor},
year = {2008},
pages = {399 - 403},
address = {Split-Dubrovnik, Croatia},
abstract = {In this paper we are going to introduce the problem of assigning test components to hosts of a performance (or load) testing environment, and its two novel solutions. When testing the performance of a device (System Under Test - SUT), the test environment simulates the latter real-life environment of the SUT. The number of hosts in the test environment is however way less than the number of hosts the SUT will have to serve in its real-life environment. Thus, real-life hosts are simulated by software entities, the so-called test components that have to be optimally assigned and then executed on the hosts of the test environment (testing hosts). Our goal is to emulate all the test components by as few testing hosts as possible, that is, to maximize the load on the testing hosts. The problem to be solved is a special case of the task assignment problem for which many solutions have been developed. Our solutions presented in this paper are, however, optimized for distributing load testing traffic. Thus the possibilities and restrictions we had to take into account are very different from those of the classical task assignment case. One of the solutions we present extends existing bin packing heuristics, while the other one solves a series of integer linear programs to make the assignments. Our simulations have shown that by applying our solutions, the average load level on testing hosts can be significantly increased.<br/>},
key = {Software testing},
keywords = {Combinatorial optimization;Computer networks;Integer programming;Load testing;Testing;},
note = {Distributing-load;Integer linear programs;Performance testing;Software entities;System under test;Task assignment;Test Environment;Testing environment;},
URL = {http://dx.doi.org/10.1109/SOFTCOM.2008.4669518},
} 


@inproceedings{20133516679859 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic load testing of web application in SaaS model},
journal = {Advances in Intelligent Systems and Computing},
author = {Stupiec, Emil and Walkowiak, Tomasz},
volume = {224},
year = {2013},
pages = {421 - 430},
issn = {21945357},
address = {Brunow, Poland},
abstract = {Necessity of monitoring in combination with the actual complexity of the e-services creates a need for constructing systems for active monitoring of various types of web services. Usually those systems are high-availability services, that require on one hand ingenious software solutions and on the other hand reliable hardware architecture. The created systems need to be flexible enough to satisfy customers requirements. This paper introduces an example solution of a system, that implement functional monitor of services provided in SaaS model. The provided system allows to check certain functionalities or whole service by running functional/load tests scenarios that are automatically generated, based on specially prepared user model. &copy; Springer International Publishing Switzerland 2013.},
key = {Software as a service (SaaS)},
keywords = {Automatic test pattern generation;Customer satisfaction;Web services;},
note = {Active monitoring;Automatically generated;E-services;Hardware architecture;High availability;Software solution;User Modeling;WEB application;},
URL = {http://dx.doi.org/10.1007/978-3-319-00945-2_38},
} 


@inproceedings{20121114864533 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {HammerCloud: A stress testing system for distributed analysis},
journal = {Journal of Physics: Conference Series},
author = {Van Der Ster, Daniel C. and Elmsheuser, Johannes and Garcia, Mario Ubeda and Paladin, Massimo},
volume = {331},
number = {PART 7},
year = {2011},
issn = {17426588},
address = {Taipei, Taiwan},
abstract = {Distributed analysis of LHC data is an I/O-intensive activity which places large demands on the internal network, storage, and local disks at remote computing facilities. Commissioning and maintaining a site to provide an efficient distributed analysis service is therefore a challenge which can be aided by tools to help evaluate a variety of infrastructure designs and configurations. HammerCloud is one such tool; it is a stress testing service which is used by central operations teams, regional coordinators, and local site admins to (a) submit arbitrary number of analysis jobs to a number of sites, (b) maintain at a steady-state a predefined number of jobs running at the sites under test, (c) produce web-based reports summarizing the efficiency and performance of the sites under test, and (d) present a web-interface for historical test results to both evaluate progress and compare sites. HammerCloud was built around the distributed analysis framework Ganga, exploiting its API for grid job management. HammerCloud has been employed by the ATLAS experiment for continuous testing of many sites worldwide, and also during large scale computing challenges such as STEP'09 and UAT'09, where the scale of the tests exceeded 10,000 concurrently running and 1,000,000 total jobs over multi-day periods. In addition, HammerCloud is being adopted by the CMS experiment; the plugin structure of HammerCloud allows the execution of CMS jobs using their official tool (CRAB).<br/>},
key = {Distributed computer systems},
keywords = {Digital storage;Interface states;},
note = {Continuous testing;Distributed analysis;Efficiency and performance;Grid job managements;Infrastructure design;Internal network;Large-scale computing;Plug-in structures;},
URL = {http://dx.doi.org/10.1088/1742-6596/331/7/072036},
} 


@article{20154201402194 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {To What Extent is Stress Testing of Android TV Applications Automated in Industrial Environments?},
journal = {IEEE Transactions on Reliability},
author = {Jiang, Bo and Chen, Peng and Chan, Wing Kwong and Zhang, Xinchao},
volume = {65},
number = {3},
year = {2016},
pages = {1223 - 1239},
issn = {00189529},
abstract = {An Android-based smart television (TV) must reliably run its applications in an embedded program environment under diverse hardware resource conditions. Owing to the diverse hardware components used to build numerous TV models, TV simulators are usually not sufficiently high in fidelity to simulate various TV models and thus are only regarded as unreliable alternatives when stress testing such applications. Therefore, even though stress testing on real TV sets is tedious, it is the de facto approach to ensure the reliability of these applications in the industry. In this paper, we study to what extent stress testing of smart TV applications can be fully automated in the industrial environments. To the best of our knowledge, no previous work has addressed this important question. We summarize the findings collected from ten industrial test engineers who have tested 20 such TV applications in a real production environment. Our study shows that the industry required test automation supports on high-level GUI object controls and status checking, setup of resource conditions, and the interplay between the two. With such supports, 87% of the industrial test specifications of one TV model can be fully automated, and 71.4% of them were found to be fully reusable to test a subsequent TV model with major upgrades of hardware, operating system, and application. It represents a significant improvement with margins of 28% and 38%, respectively, compared with stress testing without such supports. &copy; 2015 IEEE.},
key = {Application programs},
keywords = {Android (operating system);Automation;Computer software reusability;Drag reduction;Hardware;Television applications;},
note = {Hardware components;Hardware resources;Industrial environments;Industrial tests;ITS applications;Production environments;Resource conditions;Status checking;},
URL = {http://dx.doi.org/10.1109/TR.2015.2481601},
} 


@inproceedings{20130415918348 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Model-based load testing of web applications},
journal = {Journal of the Chinese Institute of Engineers, Transactions of the Chinese Institute of Engineers,Series A/Chung-kuo Kung Ch'eng Hsuch K'an},
author = {Wang, Xingen and Zhou, Bo and Li, Wei},
volume = {36},
number = {1},
year = {2013},
pages = {74 - 86},
issn = {02533839},
abstract = {In this article, a usage model is proposed to simulate users' behaviors realistically in load testing of web applications, and another relevant workload model is proposed to help generate realistic loads for load testing. It also demonstrates an eclipse-based load testing tool 'Load Testing Automation Framework' which is based on these two models and can perform load testing of web applications easily and automatically. Furthermore, these models and tools were successfully applied into a representative web-based system from a big corporation. &copy; 2013 The Chinese Institute of Engineers.},
key = {World Wide Web},
keywords = {Load testing;Markov processes;},
note = {Load models;Testing automation;Usage models;WEB application;Web-based system;Work-load models;},
URL = {http://dx.doi.org/10.1080/02533839.2012.726028},
} 


@inproceedings{20094712476045 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Mine pump comprehensive performance testing system based on labview},
journal = {2009 International Conference on Measuring Technology and Mechatronics Automation, ICMTMA 2009},
author = {Wang, Guimei and Jiao, Shanlin and Song, Hui},
volume = {1},
year = {2009},
pages = {300 - 303},
address = {Zhangjiajie, Hunan, China},
abstract = {The pump is one of the key equipments for the safety production of coal mine. It bears the important task to discharge all the underground water. However, the performance efficiency of the water pump will be declined, in the long run. Therefore, in order to ensure the safety production, users should check and test the pump performance regularly, to test if every target pump has live up to the "Coal Mine Safety Regulations". The ultimate goal in finding the fault in time, eliminating hidden dangers, reducing accidents, and saving maintenance costs can be attained. Virtual instrument is the production of modern computer and instrument technology combined in-depth, and is an important technology of computer-assisted testing area. The core idea is "software replacing hardware". The paper introduces the virtual instrument technology into the field of pump performance testing, and designs the mine pump comprehensive performance testing system based on Labview. The system takes software development environment-LabVIEW as platform and based on personal computer, and realizes the function that pump's import and export of water pressure, flow, speed, power, and other signals measured in real-time and dynamic displayed. It uses the polynomial fitting module of LabVIEW to fit the performance curve, and shows the performance curve by the waveform display. At the same time, it uses the Web Publishing Tool of LabVIEW to release the testing interface to the internet, and realizes its network communication function. Compared with traditional instruments, the pump performance testing system which based on Virtual instrument run stably, have strongly data analytical and processing functions, beautiful interface, easy operation, strongly visual function, highly testing precision. &copy; 2009 IEEE.<br/>},
key = {Instrument testing},
keywords = {Coal mines;Computer programming languages;Computer testing;Curve fitting;Data handling;Digital instruments;Groundwater;Mining machinery;Personal computers;Pumps;Software design;},
note = {Comprehensive performance;Computer assisted testing;LabViEW;Network communications;Performance efficiency;Software development environment;Testing systems;Virtual instrument technology;},
URL = {http://dx.doi.org/10.1109/ICMTMA.2009.179},
} 


@inproceedings{20110913713646 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Model based load testing of web applications},
journal = {Proceedings - International Symposium on Parallel and Distributed Processing with Applications, ISPA 2010},
author = {Wang, Xingen and Zhou, Bo and Li, Wei},
year = {2010},
pages = {483 - 490},
abstract = {In this paper, a usage model is proposed to simulate users' behaviors realistically in load testing of web applications, and another relevant workload model is proposed to help generate realistic load for load testing. It also demonstrates an eclipse-based load testing tool "Load Testing Automation Framework (LTAF)" which is based on these two models and can perform load testing of web applications easily and automatically. Furthermore, these models and tools were successfully applied into a representative web-based system from a big Corporation. &copy; 2010 IEEE.<br/>},
key = {Load testing},
keywords = {Distributed computer systems;Markov processes;},
note = {Load modeling;Model-based OPC;Performance engineering;Testing automation;Usage modeling;WEB application;Web-based system;Work-load models;},
URL = {http://dx.doi.org/10.1109/ISPA.2010.24},
} 


@inproceedings{1995012422340 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Prototype-driven approach to application-level performance testing: A case study of a large finance application},
journal = {Proceedings of the Symposium on Assessment of Quality Software Development Tools},
author = {Grossman, D. and Staton, C.J. and Bailey, B. and McCabe, M.C. and Latts, A. and Frieder, O. and Bock, C. and Roberts, D.},
year = {1994},
pages = {125 - 135},
address = {Washington, DC, USA},
abstract = {We present an approach to application-level performance testing. This uses a popular test tool, TPNS (Teleprocessing Network Simulator) to simulate performance of an application. Our approach hinges upon a simple prototype to verify that the system performance falls within acceptable bounds. Once the initial prototype is developed, detailed tuning may take place. We present a case study in which we tested the performance of a large finance application. This approach led to critical performance tuning improvement. Due to this improvement, the average user response time in our simulations was reduced from 30 seconds to under 1.5 seconds. This simulation has been verified by actual system usage during the first two months of live operation in which the average response time has indeed been under 1.5 seconds.},
key = {Database systems},
keywords = {Computer aided analysis;Computer networks;Computer operating systems;Computer simulation;Computer software selection and evaluation;Data processing;Product design;Program diagnostics;Response time (computer systems);Standards;Systems analysis;},
note = {Application level testing;Database management systems (DMBS);Initial production usage performance problems;Performance tuning;System level testing;Teleprocessing network simulator (TPNS);},
} 


@article{20131116116954 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of LiDAR exploitation software},
journal = {Computers and Geosciences},
author = {Varela-Gonzalez, M. and Gonzalez-Jorge, H. and Riveiro, B. and Arias, P.},
volume = {54},
year = {2013},
pages = {122 - 129},
issn = {00983004},
abstract = {Mobile LiDAR systems are being used widely in recent years for many applications in the field of geoscience. One of most important limitations of this technology is the large computational requirements involved in data processing. Several software solutions for data processing are available in the market, but users are often unknown about the methodologies to verify their performance accurately. In this work a methodology for LiDAR software performance testing is presented and six different suites are studied: QT Modeler, AutoCAD Civil 3D, Mars 7, Fledermaus, Carlson and TopoDOT (all of them in x64). Results depict as QTModeler, TopoDOT and AutoCAD Civil 3D allow the loading of large datasets, while Fledermaus, Mars7 and Carlson do not achieve these powerful performance. AutoCAD Civil 3D needs large loading time in comparison with the most powerful softwares such as QTModeler and TopoDOT. Carlson suite depicts the poorest results among all the softwares under study, where point clouds larger than 5 million points cannot be loaded and loading time is very large in comparison with the other suites even for the smaller datasets. AutoCAD Civil 3D, Carlson and TopoDOT show more threads than other softwares like QTModeler, Mars7 and Fledermaus. &copy; 2012 Elsevier Ltd.},
key = {Loading},
keywords = {Computer aided design;Data processing;Optical radar;Software testing;Three dimensional computer graphics;},
note = {AutoCad;Carlson;Computational requirements;Geosciences;Large datasets;Loading time;Mobile lidar;Mobile lidar system;Performance testing;Point cloud;Software performance testing;Software solution;Stress test;},
URL = {http://dx.doi.org/10.1016/j.cageo.2012.12.001},
} 


@inproceedings{20143218026187 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The application of getting RC value from point load test and rebound test by tunnel surrounding rock classification system},
journal = {Applied Mechanics and Materials},
author = {Wang, Ri Xu and Yuan, Zhong Chen},
volume = {580-583},
year = {2014},
pages = {1116 - 1121},
issn = {16609336},
address = {Haikou, China},
abstract = {The point load test and rebound tests were part of a simple rock testing methods, which together with a user-friendly, work environment characterized by less demanding test, so test the application of rock in the tunnel are very broad. Obtained by these two tests of rock uniaxial compressive strength Rc saturation level for the characterization of rock hard quantitative indicators, in the rock classification has a high status. With the computer technology in tunnel works in the field of application that can batch test data to establish the tunnel surrounding rock classification system. Article is based on two kinds of test in the same tunnel project in contrast to the use, through the rock classification system to analyze and evaluate both. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Classification (of information)},
keywords = {Compressive strength;Rocks;},
note = {Computer technology;Point load;Quantitative indicators;Rebound;Rock classification;Rock classification system;Tunnel surrounding rock;Uniaxial compressive strength;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.580-583.1116},
} 


@inproceedings{20181605011777 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Development of performance testing suite using apache JMeter},
journal = {Advances in Intelligent Systems and Computing},
author = {Agnihotri, Jidnyasa and Phalnikar, Rashmi},
volume = {673},
year = {2018},
pages = {317 - 326},
issn = {21945357},
address = {Pune, India},
abstract = {Testing a product has become one of the most important tasks for any organization (Be it small scale or large scale). Without testing the product, it is not delivered to the customer. Testing is an ongoing activity from the beginning of a product&rsquo;s development. A performance testing suite shall be developed using Apache JMeter for the purpose of testing a product. To perform performance testing on client- and server-type softwares, a 100% pure Java application named Apache JMeter is used. Apache JMeter is not a browser, it works at protocol level. Static and dynamic resources performance testing can be done using JMeter. A high level performance testing suite will be developed in capturing aspects of performance at UI and System level. Developing the testing suite helps in saving the time and cost of the organization. The discussion follows and describes benefits of performance testing and the performance testing suite.<br/> &copy; 2018, Springer Nature Singapore Pte Ltd.},
key = {Intelligent computing},
keywords = {Computer programming;Computer science;},
note = {Dynamic resources;Java applications;JMeter, etc;Performance testing;Protocol level;Small scale;System levels;},
URL = {http://dx.doi.org/10.1007/978-981-10-7245-1_32},
} 


@inproceedings{20083611505910 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Yet another performance testing framework},
journal = {Proceedings of the Australian Software Engineering Conference, ASWEC},
author = {Chen, Shiping and Moreland, David and Nepal, Surya and Zic, John},
year = {2008},
pages = {170 - 179},
address = {Perth, WA, Australia},
abstract = {Performance testing is one of the vital activities spanning the whole life cycle of software engineering. While there are a consideruble number of performance testing products and open source tools available, they are either too expensive and complicated for small projects, or too specific and simple for diverse performance tests. This paper presents a general-purpose testing framework for both simple and small, and complicated and large-scale performance testing. Our framework proposes an abstraction to facilitate performance testing by separating the application logic from the common performance testing functionalities. This leads to a set of general-purpose data models and components, which form the core of the framework. The framework has been prototyped on both.NET and Java platforms and was used for a number of performance-related projects. &copy; 2008 IEEE.<br/>},
key = {Software testing},
keywords = {Life cycle;Open source software;},
note = {Application logic;Java platforms;Open source tools;Performance testing;Performance testing framework;Performance tests;Testing framework;Whole life cycles;},
URL = {http://dx.doi.org/10.1109/ASWEC.2008.4483205},
} 


@inproceedings{20140817357128 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A performance testing tool for source code},
journal = {Applied Mechanics and Materials},
author = {Luo, Jun and Yang, Wei},
volume = {490-491},
year = {2014},
pages = {1553 - 1559},
issn = {16609336},
address = {Beijing, China},
abstract = {With the rapid development of the information age, computer software develops toward systematization and complication. In application areas such as commerce, finance and medical treatment, the performance of software is attracting more and more attention which even becomes one of the important factors to determine whether users are willing to use a piece of software. Currently, static checking tools are mostly designed to check the code errors but pay little attention to the performance problems. In order to detect the defects in source code that may cause performance problems, this paper designs and achieves a performance testing tool based on static analysis method. The experiments of detecting several open source projects using our testing tool demonstrate that it can quickly find the defects in source code with high accuracy rate. The result of defection removing shows that it can significantly reduce the memory consumption of software, and it can effectively improve software performance. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Static analysis},
keywords = {Application programs;Computer programming languages;Defects;Tools;},
note = {Code analysis;Memory consumption;Open source projects;Performance optimizations;Performance problems;Performance testing;Software performance;Static analysis method;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.490-491.1553},
} 


@inproceedings{20162902615084 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The power characteristic results according to the superconducting magnet coil load test of the motor generator system},
journal = {Proceedings - Symposium on Fusion Engineering},
author = {Eom, D.Y. and Hong, S.L. and Kim, C.H. and Roh, S.J. and Kong, J.D. and Park, K.R.},
volume = {2016-May},
year = {2016},
address = {Austin, TX, United states},
abstract = {When the poloidal field (PF) magnet power supplies (MPS) of 11 units are operated, max power of 200 MVA is required to achieve long pulse operation of Korea Superconducting Tokamak Advanced Research (KSTAR). Motor Generator (MG) system was installed to resolve power shortage because the available grid power is only 100 MVA at the National Fusion Research Institute (NFRI) site. MG system is composed of mechanical devices (stator, rotor, bearings, etc.), power control devices (VVVF, exciter), power facilities (transformers, switchboard, UPS, filter, dynamic brake, etc.), utilities (cooling water pump, heat exchangers, cooling fans, oil circulation pump, mechanical brake, etc.) and control system. MG system supplies power to the PF MPS of 11 units. And we configure the Reactive Power Compensator (RPC) &amp; Harmonic Filter (HF) system to stabilize the MG power system. After installing the MG system, individual tests and dummy coil tests were conducted to determine the safety and performance of MG system. And we completed the commissioning of the MG system by carrying out the superconducting magnet coil load test for 2014 KSTAR experiment. MG system was operated up to 150 MVA of PF MPS with RPC &amp; HF system. And the maximum operating duration was about 100 seconds. In this paper, we discuss about the power characteristic results of the MG system according to the superconducting magnet coil load test. &copy; 2015 IEEE.},
key = {Power control},
keywords = {AC generator motors;Bearings (machine parts);Brakes;Cooling water;Electric generators;Electric motor generator sets;Magnets;Power supply circuits;Superconducting magnets;Uninterruptible power systems;},
note = {Korea superconducting tokamak advanced researches;KSTAR;Long pulse operation;Magnet power supply;Motor generator;Power characteristic;power system;Reactive power compensator;},
URL = {http://dx.doi.org/10.1109/SOFE.2015.7482394},
} 


@inproceedings{20093412261037 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test of a 100 kW HTS generator operating at 67 K-77 K},
journal = {IEEE Transactions on Applied Superconductivity},
author = {Wen, Huaming and Bailey, Wendell and Goddard, Kevin and Al-Mosawi, Maitham and Beduz, Carlo and Yang, Yifeng},
volume = {19},
number = {3},
year = {2009},
pages = {1652 - 1655},
issn = {10518223},
abstract = {A systematic test program is in progress to fully characterize a 100 kW HTS synchronous generator which was successfully constructed in 2004. The machine was one of the first HTS synchronous generator/motors to operate at liquid nitrogen temperatures while achieving a power rating relevant to practical application. It has a conventional 3-phase stator and a cold rotor with a magnetic core and a superconducting winding consisting of 10 HTS Bi2223 pancake coils separated by magnetic flux diverters. The test program includes a series of tests at various speeds, field currents and temperatures (65 K-77 K) with the machine in open circuit to determine the critical currents of the HTS rotor, the waveform and harmonic characteristics of generated voltage at different levels of iron saturation. Stationary measurements of the rotor critical current are carried out using dc current in the stator windings to quantify the influence of stator field on the performance of the superconducting winding. The voltages and temperatures of the rotor are measured using a radio frequency telemetry system. &copy; 2009 IEEE.<br/>},
key = {Electric generators},
keywords = {AC generator motors;High temperature superconductors;Rotors (windings);Software testing;Stators;Superconducting coils;Superconducting devices;Synchronous generators;Winding;},
note = {Bscco coils;Harmonic characteristics;High temperature superconducting;HTS motors;Liquid nitrogen temperature;Performance tests;Rotating superconducting machines;Superconducting winding;},
URL = {http://dx.doi.org/10.1109/TASC.2009.2017832},
} 


@inproceedings{20130315908019 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A framework for automated system performance testing},
journal = {36th International Conference Computer Measurement Group},
author = {Khanapurkar, Amol and Malan, Suresh and Nambiar, Manoj},
year = {2010},
address = {Orlando, FL, United states},
abstract = {Single application performance testing methodologies are pretty mature in the industry today. However enterprises need to repeatedly deal with issues like accounting for differences between Test and Production environments, capturing knowledge and wisdom of load testing projects, performing extrapolation and validating results of load testing termed as Enterprise Performance Testing challenges. The paper presents a framework we developed to overcome them. The paper also highlights that even though the science behind load testing has advanced, tools are slow in incorporating these techniques. Copyright &copy; 2010, Unisys Corporation. All rights reserved.},
key = {Automation},
keywords = {Industry;},
note = {Application performance;Automated systems;Enterprise performance;Performance testing;Production environments;},
} 


@inproceedings{20173504089299 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Thermoelectric generator experimental performance testing for wireless sensor network application in smart buildings},
journal = {MATEC Web of Conferences},
author = {Al Musleh, Mohamed and Topriska, Evangelia and Jack, Lynne and Jenkins, David},
volume = {120},
year = {2017},
pages = {American Concrete Institute; et al.; International Society for Photogrammetry and Remote Sensing; Sharjah Electricity and Water Authority; Sharjah Research Academy; United Arab Emirates Ministry of Infrastructure Development - },
issn = {2261236X},
address = {Sharjah, United arab emirates},
abstract = {In order to make a conventional building more efficient or smarter, systems feedbacks are essential. Such feedbacks can include real-time or logged data from various systems, such as temperature, humidity, lighting and CO2 levels. This is only possible by the use of a network of sensors which report to the building management system. Conventional sensors are limited due to wiring and infrastructure requirements. Wireless Sensor Networks (WSN) however, eliminates the wiring limitations but still in certain cases require periodical battery changes and maintenance. A suitable solution for WSN limitations is to use different types of ambient energy harvesters to power battery-less sensors or alternatively to charge existing batteries so as to reduce their changing requirements. Such systems are already in place using various energy harvesting techniques. Thermoelectric Generators (TEG) are one of them where the temperature gradient is used to generate electricity which is conditioned and used for WSN powering applications. Researchers in this field often face difficulty in estimating the TEG output at the low-temperature difference as manufacturers' datasheets and performance data are not following the same standards and in most cases cover the high-temperature difference (more than 200C&deg;). This is sufficient for industrial applications but not for WSN systems in the built environment where the temperature difference is much smaller (1-20C&deg; is covered in this study). This paper presents a TEG experimental test setup using a temperature controlled hotplate in order to provide accurate TEG performance data at the low-temperature difference range. &copy; The Authors, published by EDP Sciences, 2017.},
key = {Wireless sensor networks},
keywords = {Building materials;Electric batteries;Electric generators;Electronic equipment;Energy harvesting;Intelligent buildings;Real time systems;Sustainable development;Temperature;Thermoelectric equipment;},
note = {Building management system;Conventional sensors;Generate electricity;Low-temperature difference;Performance testing;Temperature differences;Thermoelectric generators;Wireless sensor network applications;},
URL = {http://dx.doi.org/10.1051/matecconf/201712008003},
} 


@article{20143017976582 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Development of an integrated web-based system with a pile load test database and pre-analyzed data},
journal = {Geomechanics and Engineering},
author = {Chen, Yit-Jin and Liao, Ming-Ru and Lin, Shiu-Shin and Huang, Jen-Kai and Marcos, Maria Cecilia M.},
volume = {7},
number = {1},
year = {2014},
pages = {37 - 53},
issn = {2005307X},
abstract = {A Web-based pile load test (WBPLT) system was developed and implemented in this study. Object-oriented and concept-based software design techniques were adopted to integrate the pile load test database into the system. A total of 673 case histories of pile load test were included in the database. The data consisted of drilled shaft and driven precast concrete pile axial load tests in drained, undrained, and gravel loading conditions as well as pre-analyzed data and back-calculated design parameters. Unified modeling language, a standard software design tool, was utilized to design the WBPLT system architecture with five major concept-based components. These components provide the static structure and dynamic behavior of system message flows in a visualized manner. The open-source Apache Web server is the building block of the WBPLT system, and PHP Web programming language implements the operation of the WBPLT components, particularly the automatic translation of user query into structured query language. A simple search and inexpensive query can be implemented through the Internet browser. The pile load test database is helpful, and data can be easily retrieved and utilized worldwide for research and advanced applications. &copy; 2014 Techno-Press, Ltd.<br/>},
key = {Piles},
keywords = {Database systems;Internet;Load testing;Object oriented programming;Object-oriented databases;Open source software;Open systems;Precast concrete;Program translators;Query languages;Query processing;Software design;Software testing;Unified Modeling Language;Websites;},
note = {Advanced applications;Apache web server;Automatic translation;Design parameters;Software design techniques;Structured Query Language;System architectures;Web based;},
URL = {http://dx.doi.org/10.12989/gae.2014.7.1.037},
} 


@inproceedings{20162202446849 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing as a service for web applications},
journal = {2015 IEEE 7th International Conference on Intelligent Computing and Information Systems, ICICIS 2015},
author = {Ali, Amira and Badr, Nagwa},
year = {2015},
pages = {356 - 361},
address = {Cairo, Egypt},
abstract = {Software testing is a vital activity that is undertaken during software engineering life cycle to ensure software quality and reliability. Performance testing is a type of software testing that is done to shows how web application behaves under a certain workload. Cloud computing as an emerging technology can be used in the field of software engineering to provide cloud testing in order to overcome all deficiencies of conventional testing by leveraging cloud computing resources. As a result, testing-as-a-service (TaaS) is introduced as a service model that performs all testing activities in fully automated manner, on demand with a pay-for use basis. Moreover, TaaS increases testing efficiency and reduces time and cost required for testing. In this paper, performance TaaS framework for web applications is introduced which provides all performance testing activities including automatic test case generation and test execution. In addition, the proposed framework addresses many issues as: maximize resource utilization and continuous monitoring to ensure system reliability. &copy; 2015 IEEE.},
key = {Software testing},
keywords = {Application programs;Cloud computing;Computer software selection and evaluation;Information systems;Intelligent computing;Life cycle;Software engineering;Software reliability;World Wide Web;},
note = {Automatic test-case generations;Continuous monitoring;Emerging technologies;JMeter;Performance testing;Software engineering life-cycle;TaaS;Web application testing;},
URL = {http://dx.doi.org/10.1109/IntelCIS.2015.7397245},
} 


@inproceedings{20180604700217 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Software-defined network solutions for science scenarios: Performance testing framework and measurements},
journal = {ACM International Conference Proceeding Series},
author = {Rao, Nageswara S.V. and Liu, Qiang and Sen, Satyabrata and Kettimuthu, Raj and Boley, Josh and Settlemyer, Bradley W. and Chen, Hsing B. and Katramatos, Dimitrios and Yu, Dantong},
year = {2018},
pages = {ACM Special Interest Group on Mobility of Systems, Users, Data and Computing (SIGMOBILE); ACM Special Interest Group on Operating Systems (SIGOPS) - },
address = {Varanasi, India},
abstract = {High-performance scientific workflows utilize supercomputers, scientific instruments, and large storage systems. Their executions require fast setup of a small number of dedicated network connections across the geographically distributed facility sites.We present Software-Defined Network (SDN) solutions consisting of site daemons that use dpctl, Floodlight, ONOS, or OpenDaylight controllers to set up these connections. The development of these SDN solutions could be quite disruptive to the infrastructure, while requiring a close coordination among multiple sites; in addition, the large number of possible controller and device combinations to investigate could make the infrastructure unavailable to regular users for extended periods of time. In response, we develop a Virtual Science Network Environment (VSNE) using virtual machines, Mininet, and custom scripts that support the development, testing, and evaluation of SDN solutions, without the constraints and expenses of multi-site physical infrastructures; furthermore, the chosen solutions can be directly transferred to production deployments. By complementing VSNE with a physical testbed, we conduct targeted performance tests of various SDN solutions to help choose the best candidates. In addition, we propose a switching response method to assess the setup times and throughput performances of different SDN solutions, and present experimental results that show their advantages and limitations.<br/> &copy; 2018 ACM. 978-1-4503-6372-3/18/01. . . $15.00.},
key = {Distributed computer systems},
keywords = {Controllers;Data storage equipment;Electric lighting;Software defined networking;Software testing;Solution mining;Supercomputers;},
note = {Dedicated networks;Performance testing framework;Physical testbeds;Science scenarios;Scientific instrument;Scientific workflows;Switching response;Throughput performance;},
URL = {http://dx.doi.org/10.1145/3154273.3154336},
} 


@article{20130515969956 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Towards an interface-based automation testing framework for sirverlight applications},
journal = {Information Technology Journal},
author = {Tang, Jingfan and Zhu, Qin and Jiang, Ming},
volume = {12},
number = {4},
year = {2013},
pages = {829 - 834},
issn = {18125638},
abstract = {Nowadays software applications are increasingly becoming large in scale and complexity, thus, Graphical User Interface (GUI) testing plays a formal important role in ensuring the correctness and reliability of software applications. A variety of approaches in the area of GUI testing have emerged in recent years. One notable trend is Model-Based Testing (MBT) which creates an abstract test model that simulates the anticipated behavior of the System Under Testing (SUT) by using some software generated tools to generate model tests. This study highlights the designing as well as the presentation of a new automation testing framework for silverlight applications with particular focuses upon the integration of the Spec Explorer based MBT with a free web framework called WebAii. Both of the tools are available as open source. Spec Explorer can be used to generate the test cases automatically, while WebAii is used to simulate human action and operation processes to complete the test execution in an automated way. &copy; 2013 Asian Network for Scientific Information.},
key = {Software testing},
keywords = {Automation;Graphical user interfaces;Software reliability;Testing;},
note = {Automation testing;GUI testing;Human actions;Model based testing;Model tests;Open sources;Operation process;Software applications;Spec Explorer;Test case;Test execution;Test models;WebAii;},
URL = {http://dx.doi.org/10.3923/itj.2013.829.834},
} 


@article{20173904214075 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Methodological framework for heart rate variability analysis during exercise: application to running and cycling stress testing},
journal = {Medical and Biological Engineering and Computing},
author = {Hernando, David and Hernando, Alberto and Casajus, Jose A. and Laguna, Pablo and Garatachea, Nuria and Bailon, Raquel},
volume = {56},
number = {5},
year = {2018},
pages = {781 - 794},
issn = {01400118},
abstract = {Standard methodologies of heart rate variability analysis and physiological interpretation as a marker of autonomic nervous system condition have been largely published at rest, but not so much during exercise. A methodological framework for heart rate variability (HRV) analysis during exercise is proposed, which deals with the non-stationary nature of HRV during exercise, includes respiratory information, and identifies and corrects spectral components related to cardiolocomotor coupling (CC). This is applied to 23 male subjects who underwent different tests: maximal and submaximal, running and cycling; where the ECG, respiratory frequency and oxygen consumption were simultaneously recorded. High-frequency (HF) power results largely modified from estimations with the standard fixed band to those obtained with the proposed methodology. For medium and high levels of exercise and recovery, HF power results in a 20 to 40% increase. When cycling, HF power increases around 40% with respect to running, while CC power is around 20% stronger in running.<br/> &copy; 2017, International Federation for Medical and Biological Engineering.},
key = {Heart},
keywords = {Frequency estimation;},
note = {Autonomic nervous system;Heart rate variability;Heart rate variability analysis;Methodological frameworks;Non-stationary analysis;Pedalling cadence;Respiratory frequency;Stride cadence;},
URL = {http://dx.doi.org/10.1007/s11517-017-1724-9},
} 


@inproceedings{20104213294741 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Distributed agent-based performance testing framework on Web Services},
journal = {Proceedings 2010 IEEE International Conference on Software Engineering and Service Sciences, ICSESS 2010},
author = {Hao, Dan and Chen, Yinghui and Tang, Fan and Qi, Feng},
year = {2010},
pages = {90 - 94},
abstract = {Web Services are applied widely in the field of information technology, and performance testing for Web Services applications has become an important problem. This paper introduces the method of performance testing, and proposes a framework of agent-based performance testing on Web Services, which includes TestFlow Generator, Scenario Creator, Test Manager, Load Generation Agent and Test Analyzer. And the implementation of kernel modules in the framework is introduced especially. To realize the load allocation to distributed Load Generation Agents from Test Manager, a queue-based allocation strategy is given. &copy; 2010 IEEE.<br/>},
key = {Web services},
keywords = {Load testing;Managers;Software engineering;Websites;},
note = {Agent based;Allocation strategy;Distributed agents;Distributed loads;Kernel modules;Load allocation;Performance testing;Performance testing framework;},
URL = {http://dx.doi.org/10.1109/ICSESS.2010.5552290},
} 


@inproceedings{20073910823930 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of microturbine generator system fueled by biodiesel},
journal = {Proceedings of the ASME Turbo Expo},
author = {Chiang, Hsiao-Wei D. and Chiang, I-Che and Li, Hsin-Lung},
volume = {1},
year = {2007},
pages = {459 - 466},
address = {Montreal, Que., Canada},
abstract = {Using microturbine generator systems for distributed power generation has become the recent trend. To face the impact of the global energy crisis, one of the options is to use biofuels including biodiesel. To this end, this program is to perform study on biodiesel microturbine testing and analysis. A 150kW microturbine generator set with twin rotating disk regenerators was used. Designed as a vehicular microturbine engine, the twin rotating ceramic disk regenerators dramatically improve fuel consumption by transferring heat energy from the exhaust gas stream to compressor discharge. This paper involved testing of the microturbine generator set at different load conditions using 10%-30% biodiesel fuel. A software program was used to predict the performance of the microturbine generator set at different operating conditions in order to compare with the test results. Both biodiesel and petrodiesel fuels are used on the microturbine generator system in this study and the results will be compared. Copyright &copy; 2007 by ASME.},
key = {Turbines},
keywords = {Biodiesel;Compressors;Electric generators;Fuel consumption;Rotating disks;Thermal energy;Vehicles;},
note = {Compressor discharges;Global energy crisis;Rotating disk regenerators;},
URL = {http://dx.doi.org/10.1115/GT2007-28075},
} 


@inproceedings{20174404329102 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A Multi-objective Metaheuristic Approach to Search-Based Stress Testing},
journal = {IEEE CIT 2017 - 17th IEEE International Conference on Computer and Information Technology},
author = {Gois, Nauber and Porfirio, Pedro and Coelho, Andre},
year = {2017},
pages = {55 - 62},
address = {Helsinki, Finland},
abstract = {Nowadays applications need to deal with a large number of concurrent requests. These systems must be stress tested to ensure that they can function correctly under a load. In this context, a research field called Search-based Software Testing has become increasingly important. Most of the search-based test methods are based on single objective optimization. In the case of multi-objective optimization of tests, usually researchers assign different weight values to different objectives and combine them as a single objective. This research paper verifies the use of a multi-objective algorithm in search-based stress testing. The NSGA-II algorithm was implemented in the IAdapter tool using the jMetal framework. IAdapter is a JMeter plugin used for performing search-based stress tests. jMetal is an object-oriented Java-based framework for multi-objective optimization with metaheuristics. One experiment was conducted to validate the proposed approach. &copy; 2017 IEEE.},
key = {Multiobjective optimization},
keywords = {Heuristic methods;Object oriented programming;Optimization;Software testing;Testing;},
note = {Concurrent requests;Multi objective algorithm;Multi-objective metaheuristics;NSGA-II algorithm;Pareto frontiers;Search-based software testing;Single objective optimization;Stress test;},
URL = {http://dx.doi.org/10.1109/CIT.2017.19},
} 


@inproceedings{20095212580689 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stress testing the Logical Decision Making Server of a surveillance system},
journal = {1st International Conference on Advances in System Testing and Validation Lifecycle, VALID 2009},
author = {Nieminen, Mikko and Raty, Tomi and Palokangas, Jukka},
year = {2009},
pages = {98 - 103},
address = {Porto, Portugal},
abstract = {The current generation of distributed and automated physical location surveillance systems faces high demands for robustness and reliability. We present and evaluate the design of the Logical Decision Making Server (LDMS), a rule-based automated decision making component used in the Single Location Surveillance Point (SLSP) system. To validate the robustness of the LDMS design for operation in the SLSP environment, we design and conduct a stress test experiment in which large load of TCP/IP input messages is sent instantaneously to the LDMS prototype implementation using the Nethawk EAST software. The stress test results are compared to measurements obtained during a real-life scenario. The LDMS is observed to withstand a significant amount of load without crashing, and its performance is can be considered sufficient for the SLSP system needs. A detailed analysis of results however shows an increase in the latency resulting from an extreme temporal load. We identify potential areas in the design to be improved if demands for higher response rates arise. The research is based on the construction of the related publications and technologies, and the results are established from the testing and validation of the implemented LDMS within the SLSP system. &copy; 2009 IEEE.<br/>},
key = {Decision making},
keywords = {Life cycle;Monitoring;Security systems;Software testing;Space surveillance;System theory;},
note = {Automated decision making;Component;Current generation;Logical decisions;Physical locations;Prototype implementations;Stress Testing;Surveillance systems;},
URL = {http://dx.doi.org/10.1109/VALID.2009.16},
} 


@inproceedings{20141817656858 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A performance testing and optimization tool for system developed by python language},
journal = {IET Conference Publications},
author = {Fan, Haojie and Mu, Yongmin},
volume = {2013},
number = {637 CP},
year = {2013},
pages = {24 - 27},
address = {Beijing, China},
abstract = {With a wide range of Python language in developing programs, More and more programmers choose to use the Python language for systems development, it gradually becomes scientific computing, web and games' Choice Awards. However, the performance of python is always a headache for developers. For reasonable selection of functions in base library, the usage of third-party plug-ins functions and methods, and the design of custom functions, the problem whether they are the best choices for general developers is difficult to make a positive answer. After the systems performance bottleneck occurs, it is particularly important to determine where to tune and how to tune. Through the analysis and dynamic tracking of source code, with the built-in method in Python, we can get information about the system to be optimized, included: functions, grammatical structures, running time of each function, the relationship between function calls etc. This information provides an effective basis for further optimization of the system. Experimental results show that the system optimized by the tool has a significantly improvement.<br/>},
key = {Computer software},
keywords = {Computer games;Computers;High level languages;},
note = {Developing projects;Grammatical structure;Optimization tools;Performance testing;Python;System optimizations;Systems development;Systems performance;},
URL = {http://dx.doi.org/10.1049/cp.2013.2086},
} 


@inproceedings{20171703611671 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {LTTC: A load testing tool for cloud},
journal = {Advances in Intelligent Systems and Computing},
author = {Geetha Devasena, M.S. and Krishna Kumar, V. and Kingsy Grace, R.},
volume = {508},
year = {2017},
pages = {689 - 698},
issn = {21945357},
address = {Ahmedabad, India},
abstract = {Software testing is the process of software engineering to free the software from bugs. Load testing is one of the techniques in software testing and is used to find the maximum load that software can handle without affecting its performance. Load testing is used to test the cloud services that are running in a cloud. All the resources in a cloud are used by the cloud users based on their demand. Using cloud, it is easy to gather the required load for a particular application by forming clusters. If the required load is coming from different clusters and it is not known quantitatively then the problem of load balancing is raised. The proposed load testing tool avoids the problem of getting unequal loads coming from different clusters by distributing the same amount of load to all the clusters. Also the proposed load testing tool for cloud is used to find the maximum number of simultaneous users for a particular cloud system is to handle. &copy; Springer Nature Singapore Pte Ltd. 2017.},
key = {Load testing},
keywords = {Program debugging;Resource allocation;Software engineering;Software testing;},
note = {Cloud services;Cloud systems;Cloud testing;Maximum load;Running-in;},
URL = {http://dx.doi.org/10.1007/978-981-10-2750-5_70},
} 


@article{2005509546962 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stereo vision measurement system qualification and preliminary performance test results},
journal = {European Space Agency, (Special Publication) ESA SP},
author = {Finotello, R. and Losito, S. and Mondellini, C. and Rossi, G. and Zampato, M.},
number = {603},
year = {2005},
pages = {617 - 623},
issn = {03796566},
address = {Munich, Germany},
abstract = {The paper presents the Stereo Vision Measurement System. The system has been developed at proto-flight model level and features the stereo vision processing for in space measurement of the environment geometry. The SVMS subsystems and the relevant qualification tests are presented. Preliminary evaluations of the performances of the software system by using the laboratory prototype are included.},
key = {Computer software},
keywords = {Space research;Stereo vision;},
note = {Environment geometry;Space measurement;Stereo vision processing;},
} 


@inproceedings{1998254178939 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing in a client-server environment},
journal = {CMG Proceedings},
author = {Merton, Joseph K.},
volume = {1},
year = {1997},
pages = {594 - 601},
address = {Orlando, FL, USA},
abstract = {As an enterprise grows and adapts to changing business conditions, performance of client-server systems is affected by workload changes caused by growth, functional application changes, and configuration changes in hardware, software, or network topology. This paper presents a case study of the implementation of performance testing in a client-server environment. It describes performance testing objectives, evaluation and selection of performance testing software, construction of a performance testing environment, construction and execution of test cases, and evaluation of results.},
key = {Online systems},
keywords = {Computer aided software engineering;Computer networks;Computer software selection and evaluation;Response time (computer systems);Systems analysis;},
note = {Client/server environment;},
} 


@inproceedings{20145200358006 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {D-P2P-Sim+: A novel distributed framework for P2P protocols performance testing},
journal = {Journal of Systems and Software},
author = {Sioutas, S. and Sakkopoulos, E. and Panaretos, A. and Tsoumakos, D. and Gerolymatos, P. and Tzimas, G. and Manolopoulos, Y.},
volume = {100},
year = {2015},
pages = {211 - 232},
issn = {01641212},
abstract = {In recent technologies like IoT (Internet of Things) and Web 2.0, a critical problem arises with respect to storing and processing the large amount of collected data. In this paper we develop and evaluate distributed infrastructures for storing and processing large amount of such data. We present a distributed framework that supports customized deployment of a variety of indexing engines over million-node overlays. The proposed framework provides the appropriate integrated set of tools that allows applications processing large amount of data, to evaluate and test the performance of various application protocols for very large scale deployments (multi million nodes-billions of keys). The key aim is to provide the appropriate environment that contributes in taking decisions regarding the choice of the protocol in storage P2P systems for a variety of big data applications. Using lightweight and efficient collection mechanisms, our system enables real-time registration of multiple measures, integrating support for real-life parameters such as node failure models and recovery strategies. Experiments have been performed at the PlanetLab network and at a typical research laboratory in order to verify scalability and show maximum re-usability of our setup. D-P2P-Sim+ framework is publicly available at http://code.google.com/p/d-p2p-sim/downloads/list.<br/> &copy; 2014 Elsevier Inc.},
key = {Big data},
keywords = {Digital storage;Information management;Internet of things;Multiprocessing systems;Peer to peer networks;Research laboratories;},
note = {Application protocols;Big data applications;Distributed framework;Distributed infrastructure;Distributed storage system;Large-scale deployment;Real-time registration;Web 2.0 applications;},
URL = {http://dx.doi.org/10.1016/j.jss.2014.11.001},
} 


@inproceedings{20170503293412 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Study of performance testing of information system based on domestic CPU and OS},
journal = {Proceedings - 2016 3rd International Conference on Trustworthy Systems and Their Applications, TSA 2016},
author = {Li, Dong and Xiong, Jing and Yang, Chunhui},
year = {2016},
pages = {112 - 116},
address = {Wuhan, Hubei, China},
abstract = {In order to evaluate the performance of of information system based on domestic CPU and OS, through the introduction of the background of basic hardware and software based on domestic, we expound the domestic information system performance testing principle and method, according to the testing results of existing mature commercial performance testing tool LoadRunner can not reflect the user experience of time, and can not be directly used for testing the information system which based on domestic CPU/OS, this paper put forward the two kinds of testing schemes that base on user experience of LoadRunner and JMeter domestic information system performance test, and test two kinds of improved schemes, through the comparison of the test data and the user experience time of the two schemes, the variance of the test scheme based on JMeter is smaller than LoadRunner test scheme 70.49%. The results show that the test results of the JMeter scheme are more close to the user experience than LoadRunner. &copy; 2016 IEEE.},
key = {Software testing},
keywords = {Information systems;Testing;},
note = {Domistic Operating System(OS);Hardware and software;Improved scheme;Infrastructure software;Performance testing;Performance tests;Test tools;User experience;},
URL = {http://dx.doi.org/10.1109/TSA.2016.27},
} 


@inproceedings{20181504992142 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A new method for SSD black-box performance test},
journal = {Progress in Electromagnetics Research Symposium},
author = {Xie, Qiyou},
year = {2017},
pages = {1116 - 1122},
issn = {15599450},
address = {St. Petersburg, Russia},
abstract = {In the past decade, NAND Flash has stood out from numerous non-volatile storage mediums. The NAND Flash based Solid State Disk (SSD) has been widely used in many storing required fields such as embedded applications and data center. A new and efficient SSD black-box performance test method is revising in this paper. The designed test system contains time parameter getter, excitation signal generator, buffer unit, write/read controller and SSD. With the application of the proposed method, not only the influence of TRIM mechanism could been analyzed, but also the test precision is increased significantly. To verify the validity and performance of our test system, the IOPS, response time and write/read bandwidth of the universal testing software (IOMETER, HDTUNE, etc.) and SATA protocol analyzer are presented and compared with our method in detail.<br/> &copy; 2018 Electromagnetics Academy. All rights reserved.},
key = {Software testing},
keywords = {Flash-based SSDs;Memory architecture;NAND circuits;Testing;},
note = {Embedded application;Excitation signals;Performance tests;Protocol analyzers;Solid state disks (SSD);Testing software;Time parameter;Trim mechanisms;},
URL = {http://dx.doi.org/10.1109/PIERS.2017.8261912},
} 


@inproceedings{20064610243750 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test tool for RFID middleware: Parameters, design, implementation, and features},
journal = {8th International Conference Advanced Communication Technology, ICACT 2006 - Proceedings},
author = {Lee, Jongyoung and Kim, Naesoo},
volume = {1},
year = {2006},
pages = {149 - 152},
address = {Phoenix Park, Korea, Republic of},
abstract = {Recently, Major software vendors(such as Sun, IBM, Oracle) introduce RFID middleware product which process RFID tag data cause of extending RFID related technology and application. RFID middleware which receives tag data from reader, internal process receiving data, and transmit result to application acts key role of applying RFID technology to application. In this paper, we define parameters for RFID middleware performance and introduce design of performance test tool of RFID middleware.},
key = {Middleware},
keywords = {Computer software;Data reduction;Identification (control systems);Parameter estimation;},
note = {Performance test tool;RFID technology;Software testing;},
} 


@inproceedings{20133516681315 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The design of comprehensive performance test-bed of automobile electric power steering system},
journal = {Applied Mechanics and Materials},
author = {He, Ze Gang and Tai, Xiao Hong and Shen, Rong Wei and Han, Jiong Gang},
volume = {333-335},
year = {2013},
pages = {2301 - 2304},
issn = {16609336},
address = {Guilin, China},
abstract = {A kind of comprehensive performance test-bed of automobile electric power steering system was designed. IPC was applied to the main control system. Testing software was developed based on Visual Basic. AC servo system was assembled to respectively simulate input torque and load torque, the manual input torque can also be realized by operating steering wheel. The motion control card MPC08 is used to control the motion of Servo motor. Test data is collected by using multi-function data collection card. The lifting gears were assembled to install input/output shaft servo motor and EPS. Test results show that the test-bed can verify the control strategies and accurately detect the assist characteristic of EPS. &copy; (2013) Trans Tech Publications, Switzerland.},
key = {Software testing},
keywords = {AC generator motors;Servomechanisms;Visual BASIC;},
note = {AC servo systems;Assist characteristic;Automobile electric;Comprehensive performance;Data collection card;Designed;Electric power steering system;Motion control card;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.333-335.2301},
} 


@inproceedings{20083111421965 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Action-driven automation test framework for Graphical User Interface (GUI) software testing},
journal = {AUTOTESTCON (Proceedings)},
author = {Feng, Li and Zhuang, Sheng},
year = {2007},
pages = {22 - 27},
address = {Baltimore, MD, United states},
abstract = {In this paper we describe the design and implementation of an action-driven automation test framework especially for GUI software testing. The idea of action-driven automation test framework comes from the core concept of "Quality Assurance (QA)". Better quality can be ensured by increasing the coverage of test cases on the software but the process of creating large number of test cases has to be optimized. With this goal the framework was designed to primarily increase the efficiency and flexibility in composing test cases and simplify the process of learning the test cases. This paper describes the background, features, and implementation details of the framework.<br/>},
key = {Software testing},
keywords = {Automation;Graphical user interfaces;Quality assurance;Testing;},
note = {Automation tests;Design and implementations;Graphical user interfaces (GUI);GUI software;Process of learning;Test case;},
URL = {http://dx.doi.org/10.1109/AUTEST.2007.4374197},
} 


@inproceedings{20122515136087 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Peer-to-peer load testing},
journal = {Proceedings - IEEE 5th International Conference on Software Testing, Verification and Validation, ICST 2012},
author = {Meira, Jorge Augusto and Almeida, Eduardo Cunha De and Le Traon, Yves and Sunye, Gerson},
year = {2012},
pages = {642 - 647},
address = {Montreal, QC, Canada},
abstract = {Nowadays the large-scale systems are common-place in any kind of applications. The popularity of the web created a new environment in which the applications need to be highly scalable due to the data tsunami generated by a huge load of requests (i.e., connections and business operations). In this context, the main question is to validate how far the web applications can deal with the load generated by the clients. Load testing is a technique to analyze the behavior of the system under test upon normal and heavy load conditions. In this work we present a peer-to-peer load testing approach to isolate bottleneck problems related to centralized testing drivers and to scale up the load. Our approach was tested in a DBMS as study case and presents satisfactory results. &copy; 2012 IEEE.<br/>},
key = {Load testing},
keywords = {Large scale systems;Peer to peer networks;Software testing;Verification;},
note = {Bottleneck problem;Business operation;Heavy load conditions;Peer to peer;Scale-up;Study case;System under test;WEB application;},
URL = {http://dx.doi.org/10.1109/ICST.2012.153},
} 


@inproceedings{20182105218919 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Enhancement of automation testing system using Yocto project},
journal = {Proceedings of the International Conference on Electronics, Communication and Aerospace Technology, ICECA 2017},
author = {Khandelwal, Harita and Mankodi, Parthesh and Prajapati, Ritesh},
volume = {2017-January},
year = {2017},
pages = {697 - 700},
address = {Coimbatore, India},
abstract = {Nowadays, in industries, Testing has become one of the important tasks. Testing is necessary for an effective performance of product and software applications. When companies having a mass production of hardware boards, it is necessary to do testing of each and every module of hardware like SPI, UART, GPIO, PWM, ADC, USB, Ethernet. If we do testing manually then it will significantly take more time, which we can be reduced by automation testing. But the solution is not an automation testing because automation testing also requires the same amount of system, for example for 300 boards 300 system is required. The only difference in manual and automation testing is that in automation testing it will require less human effort. Now we are focusing more on developing a solution in which many tests can be done on one single system i.e. for 300 boards only one system is required for testing hence this problem can be solved by Yocto Project. Yocto project have build the tool named Bitbake which is written in Python language, which works on multithreading and scheduling so that simultaneously you can test more boards on a single system. In this paper we did automation testing of GPIO pins using Yocto project.<br/> &copy; 2017 IEEE.},
key = {Software testing},
keywords = {Application programs;Automation;Hardware;},
note = {Automation testing;Bitbake;Effective performance;Mass production;Open embedded;PYTHON language;Software applications;Yocto project;},
URL = {http://dx.doi.org/10.1109/ICECA.2017.8203630},
} 


@inproceedings{20072610680510 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Patterns and tools for performance testing},
journal = {2006 IEEE International Conference on Electro Information Technology},
author = {Stankovic, Nenad},
year = {2006},
pages = {152 - 157},
address = {East Lansing, MI, United states},
abstract = {The growth of software applications in size and complexity is being followed by a number of specific nonfunctional requirements such as portability, interoperability, and availability on various platforms. Most often, these have been addressed by middleware or programming environment. In addition, easy customizability, adaptability, and sharing of components facilitates the development cycle. These should be understood and applied in a broader sense, i.e. to byproducts created during the development process such as programs for functional and performance testing. Much time is spent on developing test programs but their quality and quality of thus obtained results varies largely if the process is not standardized and automated. In this paper we present our experience with performance testing of a large scale suite of gateways that are used for the seamless integration of heterogeneous communication networks. We analyze the commercial and public domain tools for load generation and motivate our decision to define an in-house framework and build a distributed tool for performance, testing that is also not restricted by licensing issues and is readily available to everyone involved. Our tool is built on Visper, the object-oriented distributed programming middleware. The suitability and adaptability of the Visper model for rapid application development and the quality of produced result have proven our decision correct.},
key = {Software testing},
keywords = {Computer aided software engineering;Data transfer rates;Gateways (computer networks);Interoperability;Middleware;Object oriented programming;Process control;},
note = {Distributed tools;Heterogeneous communication networks;Object oriented distributed programming;},
URL = {http://dx.doi.org/10.1109/EIT.2006.252109},
} 


@inproceedings{20110713665094 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Development of an improved GUI automation test system based on Event-flow graph},
journal = {Proceedings - International Conference on Computer Science and Software Engineering, CSSE 2008},
author = {Yongzhong, Lu and Danping, Yan and Songlin, Nie and Chun, Wang},
volume = {2},
year = {2008},
pages = {712 - 715},
address = {Wuhan, Hubei, China},
abstract = {A more highly automated graphic user interface (GUI) test model, which is based on the event-flow graph, is proposed. In the model, an automation tool is first used to carry out reverse engineering for a GUI test sample so as to obtain the event-flow graph. Then an improved ant colony optimization algorithm and a goal-directed searching approach are adopted to create GUI test sample cases. Moreover, a corresponding prototype system based on Microsoft UI automation framework is developed. &copy; 2008 IEEE.<br/>},
key = {Flow graphs},
keywords = {Ant colony optimization;Automation;Graphic methods;Graphical user interfaces;Reverse engineering;Software engineering;},
note = {Automation tests;Automation tools;Event-flow graph;Goal directed;Graphic user interface (GUI);Improved ant colony optimization;Prototype system;Test Modeling;},
URL = {http://dx.doi.org/10.1109/CSSE.2008.1336},
} 


@inproceedings{20101312803729 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Using TTCN-3 in performance test for service application},
journal = {Proceedings - 7th ACIS International Conference on Software Engineering Research, Management and Applications, SERA09},
author = {Shan, Min and Wang, Xianrong and Zhao, Lijun and Guo, Lili},
year = {2009},
pages = {253 - 258},
address = {Haikou, China},
abstract = {Service applications are applicable to provide services for requests of users from network. Due to the fact that they have to endure a big number of concurrent requests, the performance of service applications running under specific arrival rate of requests should be assessed. To measure the performance of a service application, Multi-party testing context is needed to simulate a number of concurrent requests and collect the responses. TTCN-3 is a test description language; it provides basic language elements for multi-party testing context that can be used in performance tests. This paper proposes a general approach of using TTCN-3 in multiparty performance testing service application. To this aim, a model of service application is presented, and performance testing framework for service applications is discussed. This testing framework is realized for a typical application by developing a reusable TTCN-3 abstract test suite. &copy; 2009 IEEE.<br/>},
key = {Application programs},
keywords = {Computer software reusability;Engineering research;Testing;},
note = {Concurrent requests;Description languages;Performance testing;Performance testing framework;Service applications;Testing framework;TTCN-3;Typical application;},
URL = {http://dx.doi.org/10.1109/SERA.2009.18},
} 


@article{2001045438158 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of a multimetals continuous emissions monitor},
journal = {Journal of the Air and Waste Management Association},
author = {Seltzer, M.D.},
volume = {50},
number = {6},
year = {2000},
pages = {1010 - 1016},
issn = {10962247},
address = {Charleston, SC, USA},
abstract = {A prototype instrument, designed for continuous monitoring of hazardous air pollutant metal emissions in the stack gases of waste incinerators and industrial furnaces, has undergone a performance evaluation that included a relative accuracy test audit. The test results confirmed the instrument's ability to accurately measure stack gas metal concentrations and thus validate the applicability of the candidate technique for compliance assurance monitoring for the specific source involved. The analytical accuracy of the this system, documented during the recent test exercise, represents a significant improvement in performance relative to that previously achieved, and can be attributed with certainty to the recent implementation of a shrouded nozzle sampling system. By reducing deposition losses of particulate matter in the extracted stack gas stream to acceptable levels, presentation of a more representative sample stream to the elemental analyzer has been accomplished. The present paper discusses the design and operation of the multimetals continuous emissions monitor (MMCEM), the shrouded nozzle sampling system, and the results of recent performance testing.},
key = {Hazardous materials},
keywords = {Air pollution;Environmental protection;Monitoring;Particles (particulate matter);Refuse incinerators;Toxicity;},
note = {Elemental analyzer;Hazardous air pollutant metals;Multimetals continuous emissions monitor;},
} 


@inproceedings{2004488472493 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Architecture and performance testing of a software GPS receiver for space-based applications},
journal = {Proceedings of the National Technical Meeting, Institute of Navigation},
author = {Gold, Kenn and Brown, Alison},
volume = {2004},
year = {2004},
pages = {624 - 635},
address = {San Diego, CA, United states},
abstract = {NAVSYS has modified the design of its Software GPS Receiver to optimize performance for various space-based scenarios. These include capabilities to track GPS satellites from missions that are at altitudes higher than the GPS constellation. The approach is based on Digital Beam Steering, which also presents significant advantages for multipath mitigation, which will improve kinematic carrier phase tracking and GPS interferometric attitude determination for orbital applications. In addition, the composite signal formed from the beam steering algorithms lends itself to antenna placement around the spacecraft body, which will result in continuous visibility, even for spinning satellites. Inertial aiding with the SGR has also been adapted for space applications including high dynamic scenarios in which it is difficult to track GPS. In order to test the modifications required for the Space-Software GPS Receiver (SSGR), the NAVSYS simulation tools suite has been augmented to account for orbital scenarios. This involved adding an interface to the GPS Toolbox product to accept orbital trajectories generated with Satellite Tool Kit. The Toolbox in turn drives the hardware simulations with the Advanced GPS Hybrid Simulator.},
key = {Global positioning system},
keywords = {Acoustic receivers;Algorithms;Computer simulation;Computer software;Geostationary satellites;Kinematics;Orbits;Space applications;Testing;Tracking (position);},
note = {Constellations;GPS signals;Hybrid simulators;Space-software GPS receiver (SSGR);},
} 


@inproceedings{20120714762022 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Synthesizable verification IP to stress test system-on-chip emulation and prototyping platforms},
journal = {2011 International Symposium on Integrated Circuits, ISIC 2011},
author = {Shankar, Subramanian Shiva and Shankar, Jayaratnam Siva},
year = {2011},
pages = {609 - 612},
address = {SingaporeSingapore, Singapore},
abstract = {One of the biggest challenges today with Pre-silicon System-on-Chip verification is to stress out the SoC to uncover as many corner case design issues by injecting heavy real time data traffic into the system. The inherent efficiency and the performance of the Emulation and FPGA prototyping systems make them the ideal platforms to run these tests. A typical solution is to inject data traffic through protocol exercisers with proprietary hardware (vendor specific slow down solutions) which can bridge the emulated DUT with a real time device or use software API's with transaction based SCE-MI communication infrastructure. The need for a complex input output interface makes the former difficult to be used with all emulators / FPGA prototyping systems while SCE-MI communication infrastructure being protocol specific is a disadvantage. So, a synthesizable verification architecture compliant with SCE-MI 2.0 infrastructure through which the protocol specific traffic is injected through industry standard interfaces. i.e. PIPE (PCIe), UTMI (USB), MII (Ethernet) based on user configured stimuli has been designed and implemented. Being synthesizable, the verification environment can run in both emulation and prototyping platforms effectively stress testing the complete system. &copy; 2011 IEEE.<br/>},
key = {System-on-chip},
keywords = {Application specific integrated circuits;Design for testability;Network architecture;Pipe;Programmable logic controllers;},
note = {Communication infrastructure;FPGA prototyping;Industry standards;Prototyping platform;Prototyping systems;Stress Testing;UTMI;Verification environment;},
URL = {http://dx.doi.org/10.1109/ISICir.2011.6131936},
} 


@inproceedings{20113314234219 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Home care web services evaluation by stress testing},
journal = {Communications in Computer and Information Science},
author = {Krejcar, Ondrej and Motalova, Leona},
volume = {171 CCIS},
year = {2011},
pages = {238 - 248},
issn = {18650929},
abstract = {Development of software applications result in complete application or solution. The last phase of developing process is the final testing of developed solution. The goal of our paper has focused on this problem in case of web services. The developed testing application can be used for any other software solutions with web service interface. The developed test environment, including application developed for the stress testing is based on Microsoft .NET Framework technology. Our stress testing application allows testing of selected problem areas to find any limitations before the tested developing solution will be set up at customer. By the help of our test application, the hardware solution for the server was selected on the base of selected home care agency needs. &copy; 2011 Springer-Verlag.<br/>},
key = {Web services},
keywords = {Application programs;Hardware;Mobile devices;Response time (computer systems);Software testing;Websites;},
note = {Developing process;Developing solutions;Hardware solutions;Software applications;SQL servers;Stress Testing;Test applications;Web service interface;},
URL = {http://dx.doi.org/10.1007/978-3-642-22729-5_20},
} 


@inproceedings{20134416927580 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Keyword driven automation test},
journal = {Applied Mechanics and Materials},
author = {Wu, Zhong Qian and Li, Jin Zhe and Liao, Zeng Zeng},
volume = {427-429},
year = {2013},
pages = {652 - 655},
issn = {16609336},
address = {Chongqing, China},
abstract = {In order to improve software reusability of automated test scripts, presents a keyword-driven test automation framework (KDTFA). First, the current existing automated testing framework for inductive analysis; then raised KDTFA system architecture; finally, an example of the android interface application framework and the existing framework for KDTFA actual contrast verification results show that the framework has a reduced scale of test scripts to improve the overall test efficiency and other advantages. &copy; (2013) Trans Tech Publications, Switzerland.},
key = {Testing},
keywords = {Automation;Computer software reusability;Industrial electronics;Information technology;Mechanical engineering;},
note = {Automated testing;Interface applications;KDTFA;Keyword driven;Mobile;System architectures;Test automation frameworks;Verification results;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.427-429.652},
} 



