@INPROCEEDINGS{8070136, 
author={X. Xie and Z. Yang and J. Yu and W. Zhang}, 
booktitle={2016 5th International Conference on Computer Science and Network Technology (ICCSNT)}, 
title={Design and implementation of bank financial business automation testing framework based on QTP}, 
year={2016}, 
volume={}, 
number={}, 
pages={143-147}, 
abstract={The current software testing in the aspects of industrial benefits gradually causes the attention of the domestic financial bank. The innovation of software technology, the increase of software scale and the shortened developing period make the traditional manual testing meeting enormous challenges, while the development of automated testing technology has promoted the progress of the software testing industry. Because of the particularity of financial and banking services, the bank is under an obligation to ensure the quality and reliability of software. Therefore it's vital to test the software. In specific practice, although the powerful third-party testing tools can be used as a solution, it is hard to rely on certain tool to implement automated testing, hence a framework of automated test is required to be introduced for testing, which intends to handle high efficiency and high-quality testing for software automation. This paper proposes a kind of software automation testing framework based on QTP, mainly targeting on the core of the bank, credit, online banking to test the function of the three major operations. The framework is a secondary development based on QTP and mainly for regression testing of software, which integrates techniques including object recognition, data-driven, and keyword-driven technology, checkpoint technology, to proceed business-level testing. The paper expatiated on four issues, which were the test system design, the test standardization, the testing framework design and the testing of the implementation. The practical application shows that the framework can improve the operational efficiency, reduce the test cost, and guarantee the smooth progress of the software automation testing.}, 
keywords={bank data processing;object recognition;program testing;software quality;software reliability;QTP;automated testing technology;bank financial business automation testing framework;banking service;business-level testing;domestic financial bank;financial services;keyword-driven technology;object recognition;online banking;regression testing;software automation testing;software quality;software reliability;software scale;software technology;software testing industry;test cost;test standardization;test system design;testing framework design;third-party testing tools;Automation;Libraries;Object recognition;Software;Standardization;Testing;Tools;QTP automated testing tool;software testing;test automation framework}, 
doi={10.1109/ICCSNT.2016.8070136}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{623350, 
author={D. C. Roberts and D. A. Grossman and O. Frieder and R. Bernstein and E. Bisfiop}, 
booktitle={Proceedings of Sixth International Conference on Computer Communications and Networks}, 
title={Performance testing of communication protocols for three-tier computing: results for ICA and X window protocols}, 
year={1997}, 
volume={}, 
number={}, 
pages={450-455}, 
abstract={We present the results of performance tests to compare two protocols for three-tier computing using the Windows NT operating system. Three-tier computing features a data server for stored databases (Tier 1), an application server that runs applications (Tier 2), and a simple client program that runs on desktop machines that presents the user interface (Tier 3). Three protocols are available to communicate between Tier 2 and 3: intelligence computer architecture (ICA) with and without data compression, and X Window. We measured the performance of the three protocols in a multi-user environment in which we simulated the workload imposed by typical users. We found that, for Microsoft Office 97 and Lotus Notes applications, the X Window protocol uses approximately twice the network bandwidth of ICA, without compression. We also found that compressed ICA generates roughly one third less network traffic than uncompressed ICA at a cost of 20% of additional processor utilization}, 
keywords={client-server systems;computer architecture;data compression;network servers;performance evaluation;program testing;protocols;testing;ICA protocols;Lotus Notes applications;Microsoft Office 97;Tier 1;Tier 2;Tier 3;Windows NT operating system;X window protocols;application server;client program;communication protocols;data compression;data server;desktop machines;intelligence computer architecture;multi-user environment;network bandwidth;network traffic;performance testing;stored databases;three-tier computing;user interface;Application software;Computer architecture;Computer interfaces;Independent component analysis;Machine intelligence;Operating systems;Protocols;Spatial databases;System testing;User interfaces}, 
doi={10.1109/ICCCN.1997.623350}, 
ISSN={1095-2055}, 
month={Sep},}
@INPROCEEDINGS{7359004, 
author={S. Kiran and A. Mohapatra and R. Swamy}, 
booktitle={2015 International Symposium on Technology Management and Emerging Technologies (ISTMET)}, 
title={Experiences in performance testing of web applications with Unified Authentication platform using Jmeter}, 
year={2015}, 
volume={}, 
number={}, 
pages={74-78}, 
abstract={Unified Authentication platform is a Single sign-on (SSO) mechanism which is integrated into Web applications to remove the necessity for multiple application-specific login credentials. Unified Authentication platform (UAP) is a unique platform developed by MIMOS with capability to support multiple authentication mechanism and can be integrated to any Web application to provide Single Sign On (SSO) solution. Performance testing of such web applications using UAP poses some unique challenges because the Jmeter script does not capture all the dynamic values, such as SAML Request, Relay State, Signature Algorithm, Authorization State, Cookie Time, Persistent ID (PID), JSession ID and Shibboleth, generated using single sign-on mechanism of Unified Authentication Platform. This paper explains some of the challenges & experiences to identify an appropriate solution for conducting performance testing on such web application.}, 
keywords={Internet;authorisation;program testing;software performance evaluation;Jmeter script;MIMOS;SSO mechanism;UAP;Web applications;performance testing;single sign-on mechanism;unified authentication platform;Authentication;Browsers;Computer architecture;Generators;MIMO;Servers;Testing;Jmeter;Performance Testing;Single Sign-On;Unified Authentication Platform}, 
doi={10.1109/ISTMET.2015.7359004}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{1602358, 
author={D. Draheim and J. Grundy and J. Hosking and C. Lutteroth and G. Weber}, 
booktitle={Conference on Software Maintenance and Reengineering (CSMR'06)}, 
title={Realistic load testing of Web applications}, 
year={2006}, 
volume={}, 
number={}, 
pages={11 pp.-70}, 
abstract={We present a new approach for performing load testing of Web applications by simulating realistic user behaviour with stochastic form-oriented analysis models. Realism in the simulation of user behaviour is necessary in order to achieve valid testing results. In contrast to many other user models, Web site navigation and time delay are modelled stochastically. The models can be constructed from sample data and can take into account effects of session history on user behaviour and the existence of different categories of users. The approach is implemented in an existing architecture modelling and performance evaluation tool and is integrated with existing methods for forward and reverse engineering}, 
keywords={Web sites;delays;human factors;resource allocation;reverse engineering;software architecture;software performance evaluation;stochastic processes;Web application;Web site navigation;architecture modelling;forward engineering;load testing;performance evaluation tool;reverse engineering;stochastic form-oriented analysis models;time delay;user behaviour;Analytical models;Application software;Computational modeling;Computer science;Delay effects;Navigation;Performance evaluation;Software testing;Software tools;Stochastic processes}, 
doi={10.1109/CSMR.2006.43}, 
ISSN={1534-5351}, 
month={March},}
@INPROCEEDINGS{6274032, 
author={M. Kamra and R. Manna}, 
booktitle={2012 IEEE Eighth World Congress on Services}, 
title={Performance of Cloud-Based Scalability and Load with an Automation Testing Tool in Virtual World}, 
year={2012}, 
volume={}, 
number={}, 
pages={57-64}, 
abstract={The development in cloud computing provides limitless capacity which provides opportunity to evaluate an application performance based on its nature to scale. This paper aims at the analysis of Performance using the Google App Engine(cloud computing paradigm). Virtual Office application is chosen as example to perform experiment of testing the scalability in turn maintaining the performance. An Automation Testing Tool - Test Harness has been used to perform the scale testing of the application while being deployed on the cloud. Results have seen shown in the form of request type and response times(Average time taken/request). Taken into account the consideration that when the application load goes up the Google Cloud expands(increases instance hours) without affecting the running application.}, 
keywords={Web sites;cloud computing;program testing;software performance evaluation;Google App Engine;application performance;automation testing tool;cloud computing;cloud-based scalability;scale testing;test harness;virtual office application;virtual world;Automation;Cloud computing;Google;Scalability;Servers;Teleworking;Testing;API;CPU;GAE;QPS}, 
doi={10.1109/SERVICES.2012.54}, 
ISSN={2378-3818}, 
month={June},}
@INPROCEEDINGS{4636415, 
author={Jingfan Tang and Xiaohua Cao and A. Ma}, 
booktitle={2008 IEEE International Conference on Automation and Logistics}, 
title={Towards adaptive framework of keyword driven automation testing}, 
year={2008}, 
volume={}, 
number={}, 
pages={1631-1636}, 
abstract={This paper presents an adaptive framework of keyword-driven automation testing to support the conversion of the keyword-based test cases into different kinds of test scripts automatically to be executed by different test applications under different test environments (such as GUI environment, database environment, etc.). XML is used to describe the keyword-based commands for the test case. An engine is provided in this framework to parse the XML file and dispatch the command sequences to the different test drivers according to the driver type pre-defined in the command. The test driver is responsible for dispatching the commands to the corresponding test applications to generate the test scripts automatically according to the keywords in the commands. The test scripts will be executed by the test applications on the system-under-test under different test environments. All the test results will be recorded into a log repository for generating all kinds of the test reports.}, 
keywords={XML;program compilers;program testing;XML file parsing;adaptive framework;automation engine layer;keyword driven automation testing;keyword-based command sequence;keyword-based test case conversion;log repository;test driver layer;test execution layer;test report;test script;Application software;Automatic testing;Databases;Educational institutions;Graphical user interfaces;Logistics;Robotics and automation;Software testing;System testing;XML;Keyword Driven;adaptive;automation testing}, 
doi={10.1109/ICAL.2008.4636415}, 
ISSN={2161-8151}, 
month={Sept},}
@INPROCEEDINGS{8046559, 
author={B. Yan and D. Teng and L. Liu and G. Wang}, 
booktitle={2017 18th International Conference on Electronic Packaging Technology (ICEPT)}, 
title={The degradation behaviors of white LEDs under highly accelerated stress testing (HAST)}, 
year={2017}, 
volume={}, 
number={}, 
pages={759-763}, 
abstract={Reliability of GaN-based LEDs is attracting researchers to engage in actively. At present, evaluating the lifetime of GaN-based LEDs in a short testing duration is still open question. Thermal and humidity stresses are two main environmental stresses that LED products will suffer infield applications. At the level of devices, LEDs are non-sensitive to vibration. In order to evaluate the reliabilities (including the lifetime and failure rate)of white LED devices in a short period, highly accelerated stress testing (HAST) method is attempted boldly in the present paper. A series of HAST conditions are designing through different combinations of thermal, electrical and humidity stresses. The temperatures fixed at 120°C, the biased currents vary between 20mA-350mA, and the humidities vary between 65%RH-95%RH, which imply the pressure inside the furnace is high than 1atm. The forward voltage and light intensity are monitored in-situ with a time step of 1min. Preliminary results indicate that the white LED devices' lifetime of L70 obeys Gaussian distribution under HAST humidity conditions, while the L70 lifetime obeys Inverse power distribution with the injection current density variation. Based on the Arrhenius equation, Inverse power law equation and Gauss equation, the copula acceleration model equation is established with respect to thermal, electrical and humidity stresses. As an example, under the condition of 20mA&85%RH&120°C the accelerating factor is estimated as 118.0 and 109.2. The general lifetime of L70 for white LED devices are estimated as 16926.9h and 5722.5h, respectively.}, 
keywords={Gaussian distribution;III-V semiconductors;LED displays;gallium compounds;life testing;thermal stresses;wide band gap semiconductors;Arrhenius equation;GaN;Gauss equation;Gaussian distribution;HAST conditions;L70 lifetime;copula acceleration model equation;degradation behaviors;environmental stresses;failure rate;highly accelerated stress testing;humidity conditions;humidity stresses;injection current density variation;inverse power distribution;inverse power law equation;lifetime rate;temperature 120 degC;thermal stresses;white LED;Gallium;Humidity measurement;Ions;RNA;Stress;Urban areas;Vibrations;Accelerating factor;Copula acceleration model;HAST}, 
doi={10.1109/ICEPT.2017.8046559}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6253496, 
author={D. Jayasinghe and G. Swint and S. Malkowski and J. Li and Q. Wang and J. Park and C. Pu}, 
booktitle={2012 IEEE Fifth International Conference on Cloud Computing}, 
title={Expertus: A Generator Approach to Automate Performance Testing in IaaS Clouds}, 
year={2012}, 
volume={}, 
number={}, 
pages={115-122}, 
abstract={Cloud computing is an emerging technology paradigm that revolutionizes the computing landscape by providing on-demand delivery of software, platform, and infrastructure over the Internet. Yet, architecting, deploying, and configuring enterprise applications to run well on modern clouds remains a challenge due to associated complexities and non-trivial implications. The natural and presumably unbiased approach to these questions is thorough testing before moving applications to production settings. However, thorough testing of enterprise applications on modern clouds is cumbersome and error-prone due to a large number of relevant scenarios and difficulties in testing process. We address some of these challenges through Expertus---a flexible code generation framework for automated performance testing of distributed applications in Infrastructure as a Service (IaaS) clouds. Expertus uses a multi-pass compiler approach and leverages template-driven code generation to modularly incorporate different software applications on IaaS clouds. Expertus automatically handles complex configuration dependencies of software applications and significantly reduces human errors associated with manual approaches for software configuration and testing. To date, Expertus has been used to study three distributed applications on five IaaS clouds with over 10,000 different hardware, software, and virtualization configurations. The flexibility and extensibility of Expertus and our own experience on using it shows that new clouds, applications, and software packages can easily be incorporated.}, 
keywords={cloud computing;program compilers;program testing;software packages;Expertus;IaaS clouds;Infrastructure as a Service;Internet;automated performance testing;cloud computing;distributed applications;enterprise applications;generator approach;multipass compiler approach;software packages;template-driven code generation;Automation;Cloud computing;Clouds;Testing;Weaving;XML;Aspect;Automation;Clouds;Code Generation;Datacenter;EC2;Emulab;IaaS;Multi-Tier;Open Cirrus;Performance;Scalability;Template;Testing}, 
doi={10.1109/CLOUD.2012.98}, 
ISSN={2159-6182}, 
month={June},}
@INPROCEEDINGS{8257142, 
author={F. Z. Fahmi and M. Abdurohman}, 
booktitle={2017 3rd International Conference on Science in Information Technology (ICSITech)}, 
title={Performance testing of M2M middleware platform}, 
year={2017}, 
volume={}, 
number={}, 
pages={378-382}, 
abstract={Machine to Machine Communication (M2M) is an enabler of Internet of Things (IoT) ecosystem. One of representative implemetation of M2M middleware platform is OpenMTC based on 3gpp standard. OpenMTC is horisontal M2M Platform that connect sensors and devices to user application. It support scalability by providing gateway capability layer for connecting to sensors and devices and network capability layar for supporting user application. This platform will handle large data from hundreds to thousands of sensors and devices and send the data to the suitable application. This paper has tested OpenMTC platform performance regarding its capability to handle large data. Utility and response time are measured parameters of middleware server performance. The result shows that server utilization increases when the number of nodes is less than 30. The utilization of the server shows a constant value of 70% when the number of nodes over 30. Response time to increase in line with the increase of node number. Response time is still on target while the number of nodes is less than 30.}, 
keywords={3G mobile communication;Internet of Things;machine-to-machine communication;middleware;mobile computing;3gpp standard;Internet of Things ecosystem;IoT ecosystem;M2M middleware platform;OpenMTC platform performance;gateway capability layer;machine to machine communication;middleware server performance;network capability layar;response time;Machine-to-machine communications;Monitoring;Sensors;Servers;Stability criteria;Stress;Testing;M2M;middleware;openMTC;performance test;stability}, 
doi={10.1109/ICSITech.2017.8257142}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{8304099, 
author={M. A. Putri and H. N. Hadi and F. Ramdani}, 
booktitle={2017 International Conference on Sustainable Information Engineering and Technology (SIET)}, 
title={Performance testing analysis on web application: Study case student admission web system}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={Websites usage for universities selection entrance (admission) are most visited websites in daily activity, thus its performance is critical. The ability of web applications either to control or to process users' requests determines its reliability. Furthermore, those websites which process students admission in Universitas Brawijaya and Politeknik Negeri Malang certainly engage massive volume of data and information that requires the highest level of reliability. Therefore, there is absolutely needed appropriate testing performances to measure the level of a certain application based on reliability rate. This measurement is used to determine responses, throughput, capability, and system scalability upon workload given. This research has a contribution to present testing performance concepts, goals, targets, types, and tools of Apache JMeter which is engaged for web assessment including detects mistake and error that relates to application performance and helps to improve the level of application performance as expected.}, 
keywords={Internet;Web services;Web sites;educational institutions;Politeknik Negeri Malang;Universitas Brawijaya;application performance;appropriate testing performances;daily activity;performance testing analysis;process students admission;reliability rate;student admission web system;system scalability;testing performance concepts;universities selection entrance;users;web application;websites usage;Computer science;Reliability;Servers;Software;Stress;Testing;Tools;jmeter;performance testing;testing;website}, 
doi={10.1109/SIET.2017.8304099}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{8065747, 
author={R. Abbas and Z. Sultan and S. N. Bhatti}, 
booktitle={2017 International Conference on Communication Technologies (ComTech)}, 
title={Comparative analysis of automated load testing tools: Apache JMeter, Microsoft Visual Studio (TFS), LoadRunner, Siege}, 
year={2017}, 
volume={}, 
number={}, 
pages={39-44}, 
abstract={Software testing is the process of testing, verifying and validating the user's requirements. During whole software development, testing is an ongoing process. Black Box, White Box testing and grey box testing are the three main types of software testing. In Black box testing, user doesn't know intrinsic logics and design of system. In white box testing, Tester knows the intrinsic logic of code. In Grey box testing, Tester has little bit knowledge about the internal structure, code and working of the system. It is commonly used in case of Integration testing. Load testing is the type of testing which helps us to analyze the performance of the system under heavy load or under Zero load. With the help of a automated load Testing Tools, we can do it in better way. The intention for writing this research is to carry out a comparison of four automated load testing tools i.e. Apache JMeter, HP LoadRunner, Microsoft Visual Studio (TFS), Siege based on certain criteria i.e. test scripts generation, plug-in support, result reports, application support and cost. The main focus is to study and analyze these load testing tools and identify which tool is best and more efficient [10]. We assume this comparative analysis can help in selecting the most appropriate tool and motivates the use of open source load testing tools.}, 
keywords={program testing;public domain software;software tools;Black box testing;Integration testing;LoadRunner;Microsoft Visual Studio;Siege;TFS;Zero load;apache JMeter;application support;automated load testing tools;comparative analysis;grey box testing;heavy load;intrinsic logic;open source load testing tools;plug-in support;result reports;software testing;test scripts generation;white box testing;Automation;Manuals;Software;Software testing;Tools;Visualization;Testing;automated testing;load testing;manual testing;stress test;testing tools}, 
doi={10.1109/COMTECH.2017.8065747}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{5984849, 
author={S. Duttagupta and R. Mansharamani}, 
booktitle={2011 International Symposium on Performance Evaluation of Computer Telecommunication Systems}, 
title={Extrapolation tool for load testing results}, 
year={2011}, 
volume={}, 
number={}, 
pages={69-76}, 
abstract={Load testing of IT applications is fraught with the challenges of time to market, quality of results, high cost of commercial tools, and accurately representing production like scenarios. It would help IT projects to be able to test with a small number of users and extrapolate to scenarios with much larger number of users. This in turn will cut down cycle times and costs and allow for a variety of extrapolations closer to production. We present a simple extrapolation technique based on statistical empirical modeling, which we have found to be more than 90% accurate across a range of applications running across a number of hardware servers. The technique has currently been validated for scenarios where the hardware is the bottleneck and is extensible to a wider range of scenarios as well.}, 
keywords={extrapolation;program testing;statistical analysis;IT applications;IT projects;extrapolation tool;load testing results;statistical empirical modeling;Extrapolation;Linear regression;Load modeling;Servers;Testing;Throughput;Time factors;Extrapolation;S-Curves;load testing;regression}, 
doi={}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{6459909, 
author={A. Underbrink and A. Potter and H. Jaenisch and D. J. Reifer}, 
booktitle={2012 IEEE Conference on Technologies for Homeland Security (HST)}, 
title={Application stress testing Achieving cyber security by testing cyber attacks}, 
year={2012}, 
volume={}, 
number={}, 
pages={556-561}, 
abstract={Application stress testing applies the concept of computer network penetration testing to software applications. Since software applications may be attacked - from inside or outside a protected network boundary - they are threatened by actions and conditions which cause delays, disruptions, or failures. Stress testing exposes software systems to simulated cyber attacks, revealing potential weaknesses and vulnerabilities in their implementation. By using such testing, these internal weaknesses and vulnerabilities can be discovered earlier in the software development life cycle, corrected prior to deployment, and lead to improved software quality. Application stress testing is a process and software prototype for verifying the quality of software applications under severe operating conditions. Since stress testing is rarely - if at all - performed today, the possibility of deploying critical software systems that have been stress tested provides a much stronger indication of their ability to withstand cyber attacks. Many possible attack vectors against critical software can be verified as true threats and mitigated prior to deployment. This improves software quality and serves as a tremendous risk reduction for critical software systems used in government and commercial enterprises. The software prototype models and verifies failure conditions of a system under test (SUT). The SUT is first executed in a virtual environment and its normal operational modes are observed. A normal behavior model is generated in order to predict failure conditions based on attack models and external SUT interfaces. Using off-the-shelf software tools, the predictions are verified in the virtual environment by stressing the executing SUT with attacks against the SUT. Results are presented to testers and system developers for dispensation or mitigation.}, 
keywords={computer network security;program testing;program verification;risk analysis;safety-critical software;software prototyping;software quality;software tools;virtual reality;SUT;application stress testing;commercial enterprises;computer network penetration testing;critical software system;cyber attack testing;cyber security;delay;failure analysis;formal verification;government enterprises;off-the-shelf software tools;potential weaknesses revealing;protected network boundary;risk reduction;software application;software development life cycle;software prototype model;software quality;software systems;software vulnerability;system under test;virtual environment;Databases;Monitoring;Prototypes;Software systems;Stress;Testing;application testing;attack;penetration testing;softwaer quality;software assurance}, 
doi={10.1109/THS.2012.6459909}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{204204, 
author={T. P. Parker and C. W. Webb}, 
booktitle={1992 Proceedings 42nd Electronic Components Technology Conference}, 
title={A study of failures identified during board level environmental stress testing}, 
year={1992}, 
volume={}, 
number={}, 
pages={177-184}, 
abstract={AT&T has investigated and implemented environmental stress testing (EST) in the production of a variety of circuit board designs as a means of reducing the incidence of early life failures. EST techniques include thermal cycling, random vibration, and others. These techniques have proven more effective than traditional burn-in techniques. In addition, studies have revealed that functional monitoring during thermal stressing of circuit cards more than doubles the effectiveness of EST. Outgoing quality audits and customer first month failure rates have improved by factors of two to four since the implementation of EST}, 
keywords={environmental testing;failure analysis;life testing;printed circuit testing;production testing;EST techniques;board level environmental stress testing;circuit board designs;early life failures;first month failure rates;functional monitoring;random vibration;thermal cycling;Application software;Assembly;Circuit testing;Failure analysis;Life testing;Manufacturing processes;Printed circuits;Production;Thermal stresses;Total quality management}, 
doi={10.1109/ECTC.1992.204204}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{7286553, 
author={Xi Chen and Hao Guo and P. Crossley}, 
booktitle={2015 IEEE Power Energy Society General Meeting}, 
title={Performance testing of IEC 61850 based architecture for UK National Grid standardised Substation automation solutions}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={Traditional protection and control systems in many UK National Grid Substations are reaching the end of their asset design life. This provides an opportunity to investigate whether new architecture that deploys Intelligent Electronic Device (IED) technology can deliver a reliable solution that is economically appropriate and delivers long life. The application of IEDs that utilize the IEC61850 based process bus reduces the life-time cost of the secondary systems and improves flexibility and functionality by accommodating high-speed peer-to-peer communications. The interconnectivity of devices on a single network offers significant benefits including a plug and play approach to future system changes. However, it requires interoperability among multi-vendor protection relays and control devices over an operating life of many decades. The realisation of this requires significant and detailed testing to help National Grid gain confidence in the use of these technologies. In this paper the substation architecture and the associated Power Networks are modelled in RTDS with faults applied at different locations on the transmission lines. The paper presents the results of interoperability tests involving multi-vendor Merging Unit (MU) and IED devices, which are then used to evaluate the functional performance of distance protection schemes.}, 
keywords={open systems;power grids;relay protection;substation automation;substation protection;IEC61850 based process bus;IED technology;RTDS;UK National Grid Standardised Substation automation solutions;asset design life;control devices;distance protection schemes;high-speed peer-to-peer communications;intelligent electronic device technology;interoperability tests;lifetime cost;multi-vendor merging unit;multi-vendor protection relays;plug and play approach;power networks;secondary systems;transmission lines;Circuit faults;IEC Standards;Interoperability;Merging;Substations;Tagging;IEC61850;Interoperability;Power System Reliability;Substation Automation;Substation Protection}, 
doi={10.1109/PESGM.2015.7286553}, 
ISSN={1932-5517}, 
month={July},}
@INPROCEEDINGS{622253, 
author={R. Mahmoudi and J. L. Tauritz}, 
booktitle={Proceedings of 1997 Wireless Communications Conference}, 
title={Performance testing of the North American CDMA system, using an envelope simulator}, 
year={1997}, 
volume={}, 
number={}, 
pages={84-88}, 
abstract={The growing use of spread spectrum techniques for personal communications (PCS) in Japan and USA is proving to be an enormous stimulus for the study of system impact on component design. New and innovative techniques are required to translate system criteria into component specifications. In this paper we have studied the performance of the “North American Digital Cellular IS-95” system proposed by QUALCOMM, under the influence of spurious signals using the new “Circuit Envelope Simulator” in HP-EESOF's Microwave Design System, MDS. The implemented functional blocks facilitate the generation of proper (noisy) CDMA (reverse and forward) signals, which are then used to program an arbitrary wave generator in order to create actual test signals. Additionally, these functional blocks can be replaced with equivalent circuits, consisting of passive and active elements, etc. For illustrative purposes, we discuss the application of these signals to two real amplifiers, one linear and one nonlinear. The measured results are critically compared with the simulation results}, 
keywords={cellular radio;code division multiple access;digital radio;digital simulation;personal communication networks;spread spectrum communication;telecommunication equipment testing;Circuit Envelope Simulator;HP-EESOF's Microwave Design System;North American CDMA system;North American Digital Cellular IS-95;QUALCOMM;equivalent circuits;functional blocks;linear amplifiers;nonlinear amplifier;performance testing;personal communications;spread spectrum techniques;Circuit noise;Circuit simulation;Circuit testing;Multiaccess communication;Noise generators;Personal communication networks;Signal design;Signal generators;Spread spectrum communication;System testing}, 
doi={10.1109/WCC.1997.622253}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6337826, 
author={M. Yan and H. Sun and X. Wang and X. Liu}, 
booktitle={2012 IEEE International Conference on Cluster Computing}, 
title={Building a TaaS Platform for Web Service Load Testing}, 
year={2012}, 
volume={}, 
number={}, 
pages={576-579}, 
abstract={Web services are widely known as the building blocks of typical service oriented applications. The performance of such an application system is mainly dependent on that of component web services. Thus the effective load testing of web services is of great importance to understand and improve the performance of a service oriented system. However, existing Web Service load testing tools ignore the real characteristics of the practical running environment of a web service, which leads to inaccurate test results. In this work, we present WS-TaaS, a load testing platform for web services, which enables load testing process to be as close as possible to the real running scenarios. In this way, we aim at providing testers with more accurate performance testing results than existing tools. WS-TaaS is developed on the basis of our existing Cloud PaaS platform: Service4All. First, we provide detailed analysis of the requirements of Web Service load testing and present the conceptual architecture and design of key components. Then we present the implementation details of WS-TaaS on the basis of Service4All. Finally, we perform a set of experiments based on the testing of real web services, and the experiments illustrate that WS-TaaS can efficiently facilitate the whole process of Web Service load testing.}, 
keywords={Web services;cloud computing;program testing;software tools;Cloud PaaS platform;Service4All;TaaS platform;WS-TaaS;Web service load testing tools;load testing platform;service oriented system;typical service oriented applications;Cloud computing;Computer architecture;Monitoring;Testing;cloud computing;load testing;testing as a service;web services}, 
doi={10.1109/CLUSTER.2012.20}, 
ISSN={1552-5244}, 
month={Sept},}
@INPROCEEDINGS{5581372, 
author={L. Xu and W. Zhang and L. Chen}, 
booktitle={2010 Seventh Web Information Systems and Applications Conference}, 
title={Modeling Users' Visiting Behaviors for Web Load Testing by Continuous Time Markov Chain}, 
year={2010}, 
volume={}, 
number={}, 
pages={59-64}, 
abstract={Virtual users with high quality are the preconditions to ensure the effect of load testing for Web applications. The existed tools for load testing usually generate virtual users with randomly choosing user sessions, manually generating user sessions or mining Log files, which causing such problems as non-real workload, subjectivity or difficult to update. Therefore we set each virtual user with a corresponding configure file, and these files determine the visiting paths, visiting moments and stay time of virtual users based on the Continuous Time Markov Chain. So we firstly finish the pretreatment for Log files, then construct the user visiting model, and next generate the virtual users, lastly carry out the load testing. In this way, we can obtain more reliable results for Web application load testing than the existed methods.}, 
keywords={Markov processes;Web services;data mining;program testing;virtual reality;Web load testing;continuous time Markov chain;log files mining;user visiting model;virtual users;Electromagnetic compatibility;Load modeling;Markov processes;Testing;Time factors;Web pages;Continuous Time Markov Chain;load testing;virtual user}, 
doi={10.1109/WISA.2010.47}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6297158, 
author={L. Nagowah and G. Sowamber}, 
booktitle={2012 International Conference on Computer Information Science (ICCIS)}, 
title={A novel approach of automation testing on mobile devices}, 
year={2012}, 
volume={2}, 
number={}, 
pages={924-930}, 
abstract={Mobile phones and mobile applications have now become an integral part of our everyday life. Mobile application testing plays a pivotal role in making the mobile applications more reliable and defect free. Existing test automation tools have been tailored to perform mobile test automation through mobile emulators. Other tools require the mobile device where the application is installed, to be connected to a computer so that the tests can be run. Obviously, the results obtained from emulators often differ from those obtained on actual mobile devices. To our best knowledge only a few solutions for creating automated tests of mobile applications exist and their functionality is very limited. In this paper, we introduce the idea of implementing a mobile test automation framework MobTAF which performs mobile test automation on the mobile device where connection to a computer is not required. The framework moves the testing infrastructure to the phone, to support test situations that cannot easily be replicated with an emulator. A prototype application was then implemented to test the mobile automation framework, MobTAF. The results prove that MobTAF framework is an efficient way of performing mobile application tests directly on the mobile devices.}, 
keywords={mobile computing;mobile handsets;program testing;MobTAF framework;automated tests;automation testing;defect free;mobile application testing;mobile devices;mobile emulators;mobile phones;mobile test automation framework;prototype application;test automation tools;testing infrastructure;Automation;Generators;Layout;Mobile communication;Robustness;Testing;XML;mobile application testing;mobile device test automation;mobile test automation framework;mobile testing;software testing}, 
doi={10.1109/ICCISci.2012.6297158}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{5533420, 
author={J. Križanić and A. Grgurić and M. Mošmondor and P. Lazarevski}, 
booktitle={The 33rd International Convention MIPRO}, 
title={Load testing and performance monitoring tools in use with AJAX based web applications}, 
year={2010}, 
volume={}, 
number={}, 
pages={428-434}, 
abstract={In order to deliver quality assured software and avoid potential costs caused by unstable software, software testing is essential in software lifecycle. Load testing is one of the testing types with high importance. It is usually accompanied by performance monitoring of the hosting environment. In the case of web applications which are today widely used, one fact is obvious: most of web applications are public and used by vast number of users, which are making a considerable traffic load on hosting environments and web applications. Load testing and performance monitoring become facilitated with existing tools aimed for load testing and performance monitoring. In the paper we analyze and compare several existing tools which facilitate load testing and performance monitoring, in order to find the most appropriate tools by criteria such as ease of use, supported features, and license. Selected tools were put in action in the real environment, through several web applications. For the case study one of the web applications is used in order to introduce different capabilities of tools, including distributed testing, assembling of test scenario from previously recorded usage scenarios, security support, results analysis, monitoring of key parameters, and reporting and alerting about changes of these parameters.}, 
keywords={Application software;Assembly;Costs;Licenses;Monitoring;Performance analysis;Security;Software quality;Software testing;Telecommunication traffic;AJAX;load testing;performance monitoring;web applications}, 
doi={}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{7780247, 
author={A. Amirante and T. Castaldi and L. Miniero and S. P. Romano}, 
booktitle={2016 Principles, Systems and Applications of IP Telecommunications (IPTComm)}, 
title={Jattack: a WebRTC load testing tool}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={We present Jattack, an automated stressing tool for the analysis of the performance of WebRTC-enabled server-side components. Jattack has been initially conceived with the primary objective of performing a thorough scalability analysis of the well-known Janus WebRTC gateway. As such, it re-uses most of the Janus core stack components in order to reliably emulate the behavior of a dynamically adjustable number of WebRTC clients. The specific testing .scenario can indeed be programmatically reproduced by writing a small "controller" component, which takes on the responsibility of properly orchestrating the scenario itself. The general-purpose nature of the tool, together with its flexibility deriving from the controller-based programmable approach, makes Jattack also suitable for stress-testing other WebRTC-enabled servers.}, 
keywords={Internet;program testing;Jattack;WebRTC load testing tool;WebRTC-enabled server-side components;automated stressing tool;stress-testing;Browsers;Media;Scalability;Servers;Stress;Testing;WebRTC}, 
doi={}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6606651, 
author={H. Malik and H. Hemmati and A. E. Hassan}, 
booktitle={2013 35th International Conference on Software Engineering (ICSE)}, 
title={Automatic detection of performance deviations in the load testing of Large Scale Systems}, 
year={2013}, 
volume={}, 
number={}, 
pages={1012-1021}, 
abstract={Load testing is one of the means for evaluating the performance of Large Scale Systems (LSS). At the end of a load test, performance analysts must analyze thousands of performance counters from hundreds of machines under test. These performance counters are measures of run-time system properties such as CPU utilization, Disk I/O, memory consumption, and network traffic. Analysts observe counters to find out if the system is meeting its Service Level Agreements (SLAs). In this paper, we present and evaluate one supervised and three unsupervised approaches to help performance analysts to 1) more effectively compare load tests in order to detect performance deviations which may lead to SLA violations, and 2) to provide them with a smaller and manageable set of important performance counters to assist in root-cause analysis of the detected deviations. Our case study is based on load test data obtained from both a large scale industrial system and an open source benchmark application. The case study shows, that our wrapper-based supervised approach, which uses a search-based technique to find the best subset of performance counters and a logistic regression model for deviation prediction, can provide up to 89% reduction in the set of performance counters while detecting performance deviations with few false positives (i.e., 95% average precision). The study also shows that the supervised approach is more stable and effective than the unsupervised approaches but it has more overhead due to its semi-automated training phase.}, 
keywords={input-output programs;program testing;public domain software;regression analysis;software performance evaluation;unsupervised learning;CPU utilization;LSS;SLA violations;automatic performance deviation detection;deviation prediction;disk I-O;large scale systems;load testing;logistic regression model;machine learning;memory consumption;network traffic;open source benchmark application;performance counters;root-cause analysis;run-time system properties;search-based technique;service level agreements;wrapper-based supervised approach;Control charts;Large-scale systems;Logistics;Monitoring;Principal component analysis;Radiation detectors;Testing;Machine Learning;Performance;Signature}, 
doi={10.1109/ICSE.2013.6606651}, 
ISSN={0270-5257}, 
month={May},}
@INPROCEEDINGS{4273012, 
author={M. D. Barros and J. Shiau and C. Shang and K. Gidewall and H. Shi and J. Forsmann}, 
booktitle={37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)}, 
title={Web Services Wind Tunnel: On Performance Testing Large-Scale Stateful Web Services}, 
year={2007}, 
volume={}, 
number={}, 
pages={612-617}, 
abstract={New versions of existing large-scale web services such as Passport.comcopy have to go through rigorous performance evaluations in order to ensure a high degree of availability. Performance testing (such as benchmarking, scalability, and capacity tests) of large-scale stateful systems in managed test environments has many different challenges, mainly related to the reproducibility of production conditions in live data centers. One of these challenges is creating a dataset in a test environment that mimics the actual dataset in production. Other challenges involve the characterization of load patterns in production based on log analysis and proper load simulation via reutilization of data from the existing dataset. The intent of this paper is to describe practical approaches to address some of the aforementioned challenges through the use of various novel techniques. For example, this paper discusses data sanitization, which is the alteration of large datasets in a controlled manner to obfuscate sensitive information, preserving data integrity, relationships, and data equivalence classes. This paper also provides techniques for load pattern characterization via the application of Markov chains to custom and generic logs, as well as general guidelines for the development of cache-based load simulation tools tailored for the performance evaluation of stateful systems.}, 
keywords={Web services;program testing;security of data;software performance evaluation;Markov chains;Web services wind tunnel;cache-based load simulation tools;data integrity;data sanitization;log analysis;performance testing;Availability;Benchmark testing;Environmental management;Large-scale systems;Pattern analysis;Production systems;Reproducibility of results;Scalability;System testing;Web services}, 
doi={10.1109/DSN.2007.102}, 
ISSN={1530-0889}, 
month={June},}
@INPROCEEDINGS{7102628, 
author={E. Rodrigues and M. Bernardino and L. Costa and A. Zorzo and F. Oliveira}, 
booktitle={2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)}, 
title={PLeTsPerf - A Model-Based Performance Testing Tool}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={Performance testing is a highly specialized task, since it requires that a performance engineer knows the application to be tested, its usage profile, and the infrastructure where it will execute. Moreover, it requires that testing teams expend a considerable effort and time on its automation. In this paper, we present the PLeTsPerf, a model-based performance testing tool to support the automatic generation of scenarios and scripts from application models. PLetsPerf is a mature tool, developed in collaboration with an IT company, which has been used in several works, experimental studies and pilot studies. We present an example of use to demonstrate the process of generating test scripts and scenarios from UML models to test a Web application. We also present the lessons learned and discuss our conclusions about the use of the tool.}, 
keywords={Internet;program testing;PLeTsPerf tool;UML model;Unified Modeling Language;Web application;model-based performance testing tool;scenario generation;script generation;Companies;Generators;Load modeling;Software;Testing;Unified modeling language;Visualization}, 
doi={10.1109/ICST.2015.7102628}, 
ISSN={2159-4848}, 
month={April},}
@INPROCEEDINGS{6068597, 
author={A. J. Mercer and R. K. James and G. Bennett and P. Patel and C. Johnston and J. Cai}, 
booktitle={2011 IEEE International Conference on RFID-Technologies and Applications}, 
title={Performance testing of RFID systems with RF-harsh materials}, 
year={2011}, 
volume={}, 
number={}, 
pages={537-543}, 
abstract={Radio Frequency Identification (RFID) has been adopted to track items in supply chain, healthcare, and manufacturing applications. Hospitals and factories, however, are difficult environments for radiowave propagation. Cinder block walls with steel rebar, metal obstructions, and RF noise present significant obstacles to RFID system performance. Tagging lossy materials in these environments, such as metals and liquids, can also degrade the performance of RFID systems. In a previous paper [1] we simulated the RF-harsh conditions prevalent in these environments to evaluate UHF RFID system performance. In this paper, we utilize the same laboratory environment to measure RFID system performance when RF-harsh materials are tagged. These tests serve to examine the effect of water and plastic car parts on RFID system performance in an RF harsh environment. We show that the problems posed when tagging RF-harsh materials can be mitigated with either the strategic placement of tags on the item, or the careful choice of tags. While UHF RFID systems can be used in the presence of RF-harsh circumstances, the system architecture must be carefully tested in order to minimize the effects of performance-hindering RF obstacles.}, 
keywords={radiofrequency identification;radiowave propagation;RF-harsh materials;UHF RFID system;performance testing;radio frequency identification;radiowave propagation;Antennas;Belts;Materials;Metals;Radio frequency;Radiofrequency identification;RFID;UHF (Ultra High Frequency);automotive materials;liquids;manufacturing;materials testing;multipath;performance evaluation;radio;radiowave propagation}, 
doi={10.1109/RFID-TA.2011.6068597}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6180593, 
author={T. Sidhu and M. Kanabar and P. Parikh}, 
booktitle={2011 International Conference on Advanced Power System Automation and Protection}, 
title={Configuration and performance testing of IEC 61850 GOOSE}, 
year={2011}, 
volume={2}, 
number={}, 
pages={1384-1389}, 
abstract={The IEC 61850 standard part 8-1 proposes Generic Object Oriented Substation Event (GOOSE) message for time critical applications over the Ethernet network. In order to cover the wide range of applications and achieve flexibility in implementation, GOOSE messages are kept generic in the standard. However, this flexibility leads to configuration problem achieving multi-vendor interoperability. Therefore, some efforts have been carried out in this work to present a systematic GOOSE configuration approach, as well as, verification and performance testing of the GOOSE. First part of this paper configuration of Ethernet switched network, including IEEE 1588 based time synchronization, Rapid Spanning Tree Protocol (RSTP), and IEEE 802.1Q based Quality of Services (QoS). In the second part, the paper leads to step-by-step configuration process comprising IEC 61850 data modeling, datasets of GOOSE within individual IEDs, and system integration of GOOSE. Finally, the verification of configured GOOSE messages is presented using network analyzer tools, and performance testing time delay) over the network is carried out for various network scenarios.}, 
keywords={local area networks;object-oriented methods;open systems;power engineering computing;quality of service;substation automation;synchronisation;Ethernet switched network;IEC 61850 GOOSE performance testing;IEC 61850 data modeling;IEEE 1588 based time synchronization;IEEE 802.1Q based quality of services;QoS;RSTP;generic object oriented substation event message;multivendor interoperability;network analyzer tools;rapid spanning tree protocol;substation automation systems;systematic GOOSE configuration approach;Automation;Bridges;Data models;IEC standards;Power systems;Switches;Testing;Ethernet switched networks;GOOSE;IEC 61850;substation automation systems}, 
doi={10.1109/APAP.2011.6180593}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6526035, 
author={Y. Yao and X. Wang}, 
booktitle={Proceedings of 2012 2nd International Conference on Computer Science and Network Technology}, 
title={A distributed, cross-platform automation testing framework for GUI-driven applications}, 
year={2012}, 
volume={}, 
number={}, 
pages={723-726}, 
abstract={With the rapid development of computer technology, nowadays GUIs have been widely used in desktop applications and web applications. GUI-driven application testing is an emergent approach to software testing and plays a key role to assure software quality. This paper first discusses the various methods for testing GUI-driven applications, and then defines a GUI model and formally defines the test case and the test suite. Finally, it proposes a novel automated, distributed and cross-platform testing framework for GUI. Experiments conducted showed that the proposed testing architecture managed to use parallel cross-platform clusters to test heterogeneous applications whose technologies were incompatible with the testing framework.}, 
keywords={Internet;graphical user interfaces;program testing;software architecture;software quality;GUI model;GUI-driven application testing;Web applications;computer technology;cross-platform automation testing framework;desktop applications;distributed automation testing framework;graphical user interfaces;parallel cross-platform clusters;software quality assurance;software testing;test case;test suite;testing architecture;GUI-driven applications;automation testing;cross-platform testing;distributed testing framework}, 
doi={10.1109/ICCSNT.2012.6526035}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6885425, 
author={W. Naheman and Jianxin Wei}, 
booktitle={Proceedings 2013 International Conference on Mechatronic Sciences, Electric Engineering and Computer (MEC)}, 
title={Review of NoSQL databases and performance testing on HBase}, 
year={2013}, 
volume={}, 
number={}, 
pages={2304-2309}, 
abstract={NoSQL (Not Only SQL) is the generic term of a kind of non-relational database products. This paper, firstly, lists the disadvantages of traditional relational databases, introduces NoSQL databases including their advantages, disadvantages and their application status. Then, a comparison is made between NoSQL databases and SQL database, also another comparison between different NoSQL products. Finally, we introduce the architecture and data model of HBase database, which is a representative of NoSQL databases, and did some performance tests on HBase database, including the column family test, the sort test, the random read/write test and the query test. Test results show that written and query speed of HBase is slow under a single machine environment, but can be significantly improved in multimachine cluster environment.}, 
keywords={SQL;data models;relational databases;software performance evaluation;HBase database;HBase performance testing;NoSQL databases;Not Only SQL database;SQL database;column family test;data model;machine cluster environment;nonrelational database products;query test;random read-write test;single machine environment;sort test;Availability;Blogs;Computer architecture;Distributed databases;Manuals;HBase;NoSQL databases;performance testing;relational database}, 
doi={10.1109/MEC.2013.6885425}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{5632110, 
author={F. Kreit and G. Barberio and C. Subramanian and I. Kostanic and J. P. Pinelli}, 
booktitle={2010 First International Conference on Sensor Device Technologies and Applications}, 
title={Performance Testing of the Wireless Sensor Network System for Hurricane Monitoring}, 
year={2010}, 
volume={}, 
number={}, 
pages={63-72}, 
abstract={A wireless pressure monitoring system was developed by Florida Institute of Technology to measure wind induced pressure on low-rise structures during hurricanes. This study presents tests made to evaluate the performance of the sensors and their ability to measure accurate pressure variations. To test the reliability of the pressure sensors, a series of tests were designed. The resulting measurements were then compared to secondary references. The measurements were also compared to the basic Bernoulli theory. Further, the wind tunnel measurement allowed for the development of the first comparative computational fluid dynamics simulation and experimental results. Due to the components packaging in the remote, the sensor case cannot be completely streamlined. The resulting shape caused some aerodynamic disturbances. In order to study the sensor shape's influence on the pressure measurements, different experiments were set up. Specifically, by using a roof shaped ramp model mounted on a van, a highway test was performed, allowing examination of the error caused by the sensor's shape. Another test was performed at the University of Florida Hurricane Simulator to study the gust (unsteady) effects. This test revealed that the sensors were sensitive to mechanical vibrations. The paper addresses the sensor network systems topic of the conference.}, 
keywords={atmospheric measuring apparatus;atmospheric pressure;computational fluid dynamics;geophysical fluid dynamics;pressure measurement;pressure sensors;storms;wind;wireless sensor networks;Bernoulli theory;Florida Institute of Technology;University of Florida Hurricane Simulator;comparative CFD simulation;computational fluid dynamics;hurricane monitoring;low rise structures;pressure variation measurement;roof shaped ramp model;sensor case shape;sensor performance;wind induced pressure;wind tunnel measurement;wireless pressure monitoring system;wireless sensor network performance testing;Atmospheric measurements;Electron tubes;Fluid flow measurement;Pressure measurement;Sea measurements;Semiconductor device measurement;Wind speed;Multi-sensors;Performance testing;Wireless network}, 
doi={10.1109/SENSORDEVICES.2010.19}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{4588501, 
author={A. Habul and E. Kurtovic}, 
booktitle={ITI 2008 - 30th International Conference on Information Technology Interfaces}, 
title={Load testing an AJAX application}, 
year={2008}, 
volume={}, 
number={}, 
pages={729-732}, 
abstract={This paper presents a methodology for load testing an Ajax application. WebLOAD, an open source tool for performance testing, is used to simulate a huge number of client requests to the server. The load testing is used to evaluate and compare different scenarios on the system performance. In order to avoid misleading results, load testing of Ajax applications should incorporate not only server-side but also client-side code, because it can have a significant impact in determining the generated load.}, 
keywords={Java;XML;performance evaluation;program testing;public domain software;AJAX;WebLOAD;client- side code;load testing;open source tool;performance testing;server-side code;Databases;Delay;Frequency;HTML;Java;Load modeling;Network servers;System performance;System testing;XML;Ajax;load testing;workload model}, 
doi={10.1109/ITI.2008.4588501}, 
ISSN={1330-1012}, 
month={June},}
@ARTICLE{206935, 
author={T. P. Parker and C. W. Webb}, 
journal={IEEE Transactions on Components, Hybrids, and Manufacturing Technology}, 
title={A study of failures identified during board level environmental stress testing}, 
year={1992}, 
volume={15}, 
number={6}, 
pages={1086-1092}, 
abstract={AT&T has investigated and implemented environmental stress testing (EST) in the production of a variety of circuit board designs as a means of reducing the incidence of early life failures. EST techniques include thermal cycling (TC), random vibration, etc. These techniques have proven more effective than traditional burn-in techniques. In addition, studies have revealed that functional monitoring during thermal stressing of circuit cards more than doubles the effectiveness of EST. Outgoing quality audits and customer first month failure rates have improved by factors of two to four since the implementation of EST}, 
keywords={environmental testing;failure analysis;life testing;printed circuit testing;quality control;AT&T;EST;board level environmental stress testing;burn-in techniques;circuit board designs;customer first month failure rates;early life failures;environmental stress testing;functional monitoring;outgoing quality audits;random vibration;study of failures;temperature cycling;thermal cycling;thermal stressing;Application software;Assembly;Circuit testing;Failure analysis;Human factors;Life testing;Manufacturing processes;Production;Thermal stresses;Total quality management}, 
doi={10.1109/33.206935}, 
ISSN={0148-6411}, 
month={Dec},}
@INPROCEEDINGS{5571539, 
author={T. Gao and Y. Ge and G. Wu and J. Ni}, 
booktitle={2010 Ninth International Symposium on Distributed Computing and Applications to Business, Engineering and Science}, 
title={A Reactivity-based Framework of Automated Performance Testing for Web Applications}, 
year={2010}, 
volume={}, 
number={}, 
pages={593-597}, 
abstract={To improve the reliability and feasibility of web applications, performance testing is very important for satisfying users. For reducing the cost and improve the efficiency of performance testing, we propose a new reactivity-based performance testing framework in this paper. We also provide a complete approach to generate test cases automatically from original web logs. First our approach retrieves user patterns through logs at the server side. Then, metrics derived from users' perspective are applied and usage pattern from client side are gained. At last test case can be generated automatically by solving an optimization problem through an evolutionary algorithm.}, 
keywords={Internet;automatic test pattern generation;client-server systems;evolutionary computation;performance evaluation;Web application;Web logs;automated reactivity-based performance testing framework;evolutionary algorithm;optimization problem;test case generation;user pattern retrieval;Load modeling;Measurement;Servers;Software;Testing;Time factors;Unified modeling language;automated test case generation;performance testing;testing framework;web applications}, 
doi={10.1109/DCABES.2010.127}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{4017687, 
author={N. Stankovic}, 
booktitle={2006 IEEE International Conference on Electro/Information Technology}, 
title={Patterns and Tools for Performance Testing}, 
year={2006}, 
volume={}, 
number={}, 
pages={152-157}, 
abstract={The growth of software applications in size and complexity is being followed by a number of specific nonfunctional requirements such as portability, interoperability, and availability on various platforms. Most often, these have been addressed by middleware or programming environment. In addition, easy customizability, adaptability, and sharing of components facilitates the development cycle. These should be understood and applied in a broader sense, i.e. to byproducts created during the development process such as programs for functional and performance testing. Much time is spent on developing test programs but their quality and quality of thus obtained results varies largely if the process is not standardized and automated. In this paper we present our experience with performance testing of a large scale suite of gateways that are used for the seamless integration of heterogeneous communication networks. We analyze the commercial and public domain tools for load generation and motivate our decision to define an in-house framework and build a distributed tool for performance, testing that is also not restricted by licensing issues and is readily available to everyone involved. Our tool is built on Visper, the object-oriented distributed programming middleware. The suitability and adaptability of the Visper model for rapid application development and the quality of produced result have proven our decision correct}, 
keywords={distributed programming;middleware;object-oriented programming;program testing;software prototyping;Visper;distributed tool;heterogeneous communication networks;large scale gateways suite;load generation;nonfunctional requirements;object-oriented distributed programming middleware;software applications;software engineering;software testing;software tools;test programs;Application software;Automatic testing;Availability;Communication networks;Large scale integration;Licenses;Middleware;Object oriented programming;Performance analysis;Programming environments;Software testing;software engineering;software tools}, 
doi={10.1109/EIT.2006.252109}, 
ISSN={2154-0357}, 
month={May},}
@ARTICLE{6313588, 
author={M. R. Dhote and G. G. Sarate}, 
journal={IEEE Software}, 
title={Performance Testing Complexity Analysis on Ajax-Based Web Applications}, 
year={2013}, 
volume={30}, 
number={6}, 
pages={70-74}, 
abstract={The Ajax model of Web applications development has rapidly gained popularity because it promises to bring the richness and responsiveness of desktop applications to the Web. Ajax implementations differ fundamentally from other Web implementations - mainly in making asynchronous requests for parts of a Webpage. Techniques routinely used for performance testing traditional Web applications must be modified and enhanced to suit the needs of Ajax-based applications. Using a general example, the authors of this article examine the unique challenges of carrying out performance testing for Ajax-based applications and offer approaches and tools for overcoming them.}, 
keywords={Internet;program testing;software metrics;Ajax-based Web applications;Webpage;performance testing complexity analysis;Browsers;Complexity theory;Internet;Servers;Software measurement;Statistical analysis;Testing;Ajax;performance testing;performance testing and tools;software quality and testing;stress testing}, 
doi={10.1109/MS.2012.132}, 
ISSN={0740-7459}, 
month={Nov},}
@INBOOK{5270481, 
author={H. Anthony Chan}, 
booktitle={Accelerated Stress Testing Handbook:Guide for Achieving Quality Products}, 
title={Production AST with Computers Using the Taguchi Method - Reprinted from Environmental Stress Testing Experiment Using the Taguchi Method, IEEE Transactions on Components, Packaging, and Manufacturing Technology, Part A, Vol. 18, No.1, pp. 39, with permission from the author and the IEEE, 1995.}, 
year={2001}, 
volume={}, 
number={}, 
pages={372-}, 
abstract={
Manufacturing process improvements which increase productivity, decrease test process time, and improve customer satisfaction are highly desirable in today's marketplace. The application of environmental stress screening (ESS), i.e, Production AST, is a method of achieving these improvements. ESS is the application of stresses applied beyond product specification limits in order to find latent product defects. Utilizing ESS achieves increased robustness and lowers infant mortality.

An experiment was performed to identify the significance or relevancy of the selected stresses for application in the printed wiring assembly (PWA) production process by using a statistically significant controlled method. The design of experiments statistical approach (analysis of variance) is applied, combined with the Taguchi two-level, seven-factor design method.

This experiment concentrated on three stresses?-?temperature cycling, random vibration, and power cyling?-?and two diagnostic levels?-?a prom-based (programmable memory chip), power-on self test (POST), and a functional diagnostic test suite, contained on disk storage.

This was not an optimization experiment. Once the significance to the production process is identified, future optimizing of temperature cycling, power cycling, and vibration screens will be conducted. Also, voltage margining was not included to reduce the complexity of the experiment-treatment factors and interactions. Experimental results and conclusions on the effectiveness of different stress regimens are presented in this chapter.

Introduction

Objectives

Stress Overview

Stress Screen Designs

Experiment Overview

The Taguchi Method

Response Variable Results and Conclusions of the Taguchi Experiment

< LI>
Intra-Experiment Summary

Taguchi Method Conclusion

Terms

Acknowledgments

References

}, 
keywords={}, 
doi={10.1109/9780470544051.ch15}, 
ISSN={}, 
publisher={Wiley-IEEE Press}, 
isbn={9780470544051}, 
url={https://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5270481},}
@INPROCEEDINGS{7780234, 
author={L. Dong and X. Jing and Y. Chunhui}, 
booktitle={2016 Third International Conference on Trustworthy Systems and their Applications (TSA)}, 
title={Study of Performance Testing of Information System Based on Domestic CPU and OS}, 
year={2016}, 
volume={}, 
number={}, 
pages={112-116}, 
abstract={In order to evaluate the performance of of information system based on domestic CPU and OS, through the introduction of the background of basic hardware and software based on domestic, we expound the domestic information system performance testing principle and method, according to the testing results of existing mature commercial performance testing tool LoadRunner can not reflect the user experience of time, and can not be directly used for testing the information system which based on domestic CPU/OS, this paper put forward the two kinds of testing schemes that base on user experience of LoadRunner and JMeter domestic information system performance test, and test two kinds of improved schemes, through the comparison of the test data and the user experience time of the two schemes, the variance of the test scheme based on JMeter is smaller than LoadRunner test scheme 70.49%. The results show that the test results of the JMeter scheme are more close to the user experience than LoadRunner.}, 
keywords={information systems;microprocessor chips;operating systems (computers);performance evaluation;JMeter domestic information system performance test;LoadRunner domestic information system performance test;OS;domestic CPU;domestic information system performance testing method;domestic information system performance testing principle;performance evaluation;Browsers;Hardware;Information systems;Operating systems;Rendering (computer graphics);Servers;Testing;JMeter test tool;LoadRunner test tool;domestic CPU;domestic infrastructure software;domistic Operating System(OS);information system;performance test}, 
doi={10.1109/TSA.2016.27}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6413663, 
author={M. Yan and H. Sun and X. Wang and X. Liu}, 
booktitle={2012 IEEE 18th International Conference on Parallel and Distributed Systems}, 
title={WS-TaaS: A Testing as a Service Platform for Web Service Load Testing}, 
year={2012}, 
volume={}, 
number={}, 
pages={456-463}, 
abstract={Web services are widely known as the building blocks of typical service oriented applications. The performance of such an application system is mainly dependent on that of component web services. Thus the effective load testing of web services is of great importance to understand and improve the performance of a service oriented system. However, existing Web Service load testing tools ignore the real characteristics of the practical running environment of a web service, which leads to inaccurate test results. In this work, we present WS-TaaS, a load testing platform for web services, which enables load testing process to be as close as possible to the real running scenarios. In this way, we aim at providing testers with more accurate performance testing results than existing tools. WS-TaaS is developed on the basis of our existing Cloud PaaS platform: Service4All. First, we briefly introduce the functionalities and main components of Service4All. Second, we provide detailed analysis of the requirements of Web Service load testing and present the conceptual architecture and design of key components. Third, we present the implementation details of WS-TaaS on the basis of Service4All. Finally, we perform a set of experiments based on the testing of real web services, and the experiments illustrate that WS-TaaS can efficiently facilitate the whole process of Web Service load testing. Especially, comparing with existing testing tools, WS-TaaS can obtain more effective and accurate test results.}, 
keywords={Web services;cloud computing;performance evaluation;program testing;service-oriented architecture;Service4All;WS-TaaS;Web service load testing tools;building blocks;cloud PaaS platform;component Web services;service oriented applications;service oriented system performance;testing as a service platform;Cloud computing;Monitoring;Runtime;Testing;cloud computing;load testing;testing as a service;web services}, 
doi={10.1109/ICPADS.2012.69}, 
ISSN={1521-9097}, 
month={Dec},}
@ARTICLE{8085385, 
author={P. Fang and X. Ma and X. Li and X. Qiu and R. Gerhard and X. Zhang and G. Li}, 
journal={IEEE Sensors Journal}, 
title={Fabrication, Structure Characterization, and Performance Testing of Piezoelectret-Film Sensors for Recording Body Motion}, 
year={2018}, 
volume={18}, 
number={1}, 
pages={401-412}, 
abstract={During muscle contractions, radial-force distributions are generated on muscle surfaces due to muscle-volume changes, from which the corresponding body motions can be recorded by means of so-called force myography (FMG). Piezo-or ferroelectrets are flexible piezoelectric materials with attractive materials and sensing properties. In addition to several other applications, they are suitable for detecting force variations by means of wearable devices. In this paper, we prepared piezoelectrets from cellular polypropylene films by optimizing the fabrication procedures, and developed an FMG-recording system based on piezoelectret sensors. Different hand and wrist movements were successfully detected on able-bodied subjects with the FMG system. The FMG patterns were evaluated and identified by means of linear discriminant analysis and artificial neural network algorithms, and average motion-classification accuracies of 96.1% and 94.8%, respectively, were obtained. This paper demonstrates the feasibility of using piezoelectret-film sensors for FMG and may thus lead to alternative methods for detecting body motion and to related applications, e.g., in biomedical engineering or structural-health monitoring.}, 
keywords={biomedical measurement;biomedical transducers;cellular biophysics;computerised instrumentation;electrets;force measurement;force sensors;medical computing;motion measurement;muscle;neural nets;piezoelectric thin films;piezoelectric transducers;polymer films;polymer foams;recorders;thin film sensors;FMG-recording system;artificial neural network algorithm;biomedical engineering;body motion detection;body motion recording;cellular polypropylene film;ferroelectret;force myography;force sensor;linear discriminant analysis;muscle contraction;muscle surface generation;performance testing;piezoelectret-film sensor;piezoelectric material;radial-force distribution;structural-health monitoring;structure characterization;wearable device;Accelerometers;Dynamics;Electrodes;Films;Force;Muscles;Sensors;Forcemyography;film sensor;motion registration;piezoelectret;wearable}, 
doi={10.1109/JSEN.2017.2766663}, 
ISSN={1530-437X}, 
month={Jan},}
@INPROCEEDINGS{6281507, 
author={J. P. H. Knauss and C. Warren and D. Kearns}, 
booktitle={PES T D 2012}, 
title={An innovative approach to smart automation testing at National Grid}, 
year={2012}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={Upon completion of a successful Distribution Automation (DA) Pilot Project centered in National Grid's upstate New York service territory, it was determined that the reliability improvements delivered by the pilot demonstration justified a much more comprehensive effort to further evaluate additional Smart Grid technologies. The vision was to conduct experiments with a full suite of Smart Grid technologies including: AMI; Home Area Network and energy management systems; Automatic Fault Isolation & System Restoration; advanced feeder monitoring; distribution transformer monitoring; single pole tripping and Pulse Closing technology on distribution line reclosers; advanced capacitor control with independent pole operation; faulted circuit indicators with 2-way communication capability; and distribution fault locating capability. This vision came to be known as National Grid's Smart Grid Pilot proposal. Many challenges exist with such a comprehensive approach from public and personnel safety, to ensuring interoperability between devices and systems of different manufacture. In order to determine which technologies would provide the most benefit to National Grid's customer base, a means was needed to prequalify the various types of products available before large scale deployments were initiated. Looking at the large number of Smart Grid device suppliers, architectures and products available, we realized that the optimum solution would be to build a facility wherein a wide range of Smart Grid technologies could be installed and systematically put through their paces; i.e. actually tested in as near a real-world atmosphere as practical. Thus was born the National Grid “Smart Technology Centre” or STC. Soon thereafter, National Grid's Utility of the Future engineering team designed, engineered, and constructed a truly innovative test fixture that enabled system level testing on complex distribution networks to ensure process safety during field de- loyment. One of only a few known organizations in the U.S., National Grid has in-house capability to truly test and evaluate an end-to-end Smart distribution system architecture where systems such as automated fault isolation and system restoration can be evaluated. This paper will discuss interoperability testing that National Grid embarked upon to prepare for its proposed Smart Grid Pilot demonstration and will detail the lengths that were taken in creating a test site where medium voltage Smart Grid technologies could be fully evaluated to ensure that the various applications would play well with each other prior to actually being deployed in the field. Furthermore, this paper will focus on providing an overview of the system level testing and technical evaluation of distribution protection and control equipment with automated fault isolation and system restoration capabilities. It will also detail a number of lessons learned from this effort and discuss future plans for smart technology evaluation as a basis for an educational platform and workforce training tool.}, 
keywords={automatic testing;control equipment;electrical safety;fault location;open systems;power distribution control;power distribution protection;power distribution reliability;power engineering computing;power system restoration;smart power grids;2-way communication capability;AMI;DA Pilot Project;National Grid;New York service territory;STC;Smart Technology Centre;advanced capacitor control;advanced feeder monitoring;automatic fault isolation;automatic system restoration;complex distribution network testing;control equipment;distribution automation;distribution fault locating capability;distribution line reclosers;distribution protection;distribution transformer monitoring;educational platform;end-to-end smart distribution system architecture;energy management systems;faulty circuit indicators;home area network;interoperability;large scale deployments;medium voltage smart grid technologies;personnel safety;process safety;public safety;pulse closing technology;reliability improvements;single pole tripping;smart automation testing;smart grid device suppliers;smart grid pilot demonstration;smart technology evaluation;system level testing;workforce training tool;Automation;Circuit faults;Control systems;Monitoring;Safety;Smart grids;Testing}, 
doi={10.1109/TDC.2012.6281507}, 
ISSN={2160-8555}, 
month={May},}
@INPROCEEDINGS{5635852, 
author={Y. Liu and B. Du and S. Wang and H. Yang and X. Wang}, 
booktitle={2010 First International Conference on Pervasive Computing, Signal Processing and Applications}, 
title={Design and Implementation of Performance Testing Utility for RTSP Streaming Media Server}, 
year={2010}, 
volume={}, 
number={}, 
pages={193-196}, 
abstract={RTSP has been widely used in a variety of streaming media applications and streaming service providers hope to choose a high-performance streaming media server to meet their needs, so it is an important research topic about how to evaluate the serving performance of RTSP streaming media server. This paper analyzes the performance metric of streaming media applications comprehensively, and proposes an approach to design and implement a Performance Testing Utility for RTSP Streaming Server. According to different stress test, the utility mainly evaluates a streaming server's performance in the case of delivering a large number of concurrent streams and quantifies the statistics of various performance metrics. The tool utilizes multi-thread mechanism to create multiple pseudo-terminal instances to simulate a certain number of concurrent users for sending RTSP signals, receives media flow by a special IP address, analyzes RTP packets, and counts the related performance metrics value of the server. Experiments validate the efficiency and accuracy of the tool.}, 
keywords={media streaming;multi-threading;multimedia servers;performance evaluation;protocols;IP address;RTP packets;RTSP streaming media server;multiple pseudo-terminal instances;multithread mechanism;performance metric;performance testing utility;real-time streaming protocol;streaming server performance evaluation;streaming service providers;Measurement;Media;Protocols;Real time systems;Servers;Streaming media;Testing;Concurrent streams;Media flow;Performance metrics;Streaming media server;Testing utility}, 
doi={10.1109/PCSPA.2010.55}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{7793853, 
author={F. Schloegl and M. Buescher and K. Diwold and S. Lehnhoff and L. Fischer and F. Zeilinger and T. Gawron-Deutsch}, 
booktitle={IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society}, 
title={Performance testing Smart Grid applications using a distributed co-simulation approach}, 
year={2016}, 
volume={}, 
number={}, 
pages={6305-6310}, 
abstract={Co-simulation is an established approach for Smart Grid simulations as it allows to break down the very complex system into sub-systems. The modularity of co-simulation environments makes easy to distribute it across different sites. One reason for such a distribution may be, that this way confidential software can stay within its secure domain. However the transmission of data between the sites is time consuming. This paper demonstrates how Smart Grid applications can be tested using a co-simulation approach. It investigates the costs of such an approach by measuring the time required for data transmission in a case study.}, 
keywords={data communication;power system security;smart power grids;data transmission;distributed cosimulation;smart grid;Computational modeling;Data models;Hardware;Load modeling;Smart grids;Software;Topology}, 
doi={10.1109/IECON.2016.7793853}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6958400, 
author={J. Zhou and B. Zhou and S. Li}, 
booktitle={2014 14th International Conference on Quality Software}, 
title={LTF: A Model-Based Load Testing Framework for Web Applications}, 
year={2014}, 
volume={}, 
number={}, 
pages={154-163}, 
abstract={Performance evaluation is an important approach for various systems to guarantee the quality of their services. However, most performance evaluation tasks face a problem: how to model the system workload? Traditional workload models have limitations when it comes to modeling different workloads. In this paper, we propose a workload model for characterizing and generating synthetic web workloads. First, we introduce a Context-based Sequential Action Model to describe users that exhibit similar access patterns. Next, we present a Workload Parameter Specification Language to describe workload parameters for workload generation. Then, we introduce our load-testing framework based on the proposed model. The representativeness and features of our model are demonstrated by comparing it to other models. Experiments show that our framework can generate accurate and stable synthetic workloads.}, 
keywords={Internet;software performance evaluation;specification languages;LTF;Web applications;context-based sequential action model;model-based load testing framework;performance evaluation;synthetic Web workloads;workload generation;workload model;workload parameter specification language;Computational modeling;Context;Context modeling;Load modeling;Testing;Unified modeling language;load testing;model;performance;workload characterization}, 
doi={10.1109/QSIC.2014.53}, 
ISSN={1550-6002}, 
month={Oct},}
@INPROCEEDINGS{524640, 
author={K. Roy and R. K. Roy and A. Chatterjee}, 
booktitle={1995 International Symposium on VLSI Technology, Systems, and Applications. Proceedings of Technical Papers}, 
title={Stress testing of combinational VLSI circuits using existing test sets}, 
year={1995}, 
volume={}, 
number={}, 
pages={93-98}, 
abstract={We present a stress testing method which can provide an attractive low-cost alternative to burn-in. The technique is based on reordering of test vectors such that a desired circuit activity or electrical stress is generated across the VLSI chip while achieving a high coverage for stuck-at defects. The test methodology can also be used to generate localized electrical or thermal stress in a circuit. Such testing procedure can be important for weeding out circuits with infant mortality problems. Experimental results on benchmark circuits show that the stress requirements can be changed by more than a factor of 4 by reordering the stuck-at test vectors}, 
keywords={CMOS logic circuits;VLSI;combinational circuits;integrated circuit testing;integrated logic circuits;logic testing;combinational VLSI circuits;infant mortality problems;localized electrical stress;localized thermal stress;stress testing method;stuck-at defects;test vectors reordering;Circuit faults;Circuit testing;Costs;Current density;Monitoring;National electric code;Ovens;Temperature;Thermal stresses;Very large scale integration}, 
doi={10.1109/VTSA.1995.524640}, 
ISSN={1524-766X}, 
month={May},}
@INPROCEEDINGS{7436040, 
author={A. Shojaee and N. Agheli and B. Hosseini}, 
booktitle={2015 2nd International Conference on Knowledge-Based Engineering and Innovation (KBEI)}, 
title={Cloud-based load testing method for web services with VMs management}, 
year={2015}, 
volume={}, 
number={}, 
pages={170-176}, 
abstract={Due to the increased loading the large number of users connected to pervasive web services during the past decade, their load testing and providing the needed resources in low time and cost, requires more attention. In this context cloud computing technology offers new ideas to solve such problems and has reduced the concern of large and complex testing systems. In this research in order to improve the quality and performance of web applications load testing, we proposed a method for web applications load testing based on cloud computing. The proposed method uses the existing facilities in the cloud including pool of computing resources without initial cost, unlimited data storage and cloud computing managerial procedures, containing the actual load generating and multi-user concurrency testing, that lead to improved load testing flexibility, time and operational costs. Moreover, in this load testing method, in order to manage resources and virtual machines, significant improvement is achieved by use of appropriate allocation, reducing performance and unnecessary migration avoiding methods. Through evaluation section of the proposed method through a simulated test environment, it is shown that cloud-based load testing in comparison with traditional methods of load testing, improves factors such as effort, cost and time.}, 
keywords={Web services;cloud computing;program testing;resource allocation;ubiquitous computing;virtual machines;VM management;Web applications load testing performance;Web applications load testing quality;cloud computing technology;cloud-based load testing method;computing resources pool;load generation;multiuser concurrency testing;pervasive Web services;resource management;virtual machines;Cloud computing;Decision support systems;Handheld computers;Systems architecture;Testing;Virtual machining;Cloud Computing;Load Testing;VMs;Web Service}, 
doi={10.1109/KBEI.2015.7436040}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{5325380, 
author={H. Kim and B. Choi and W. E. Wong}, 
booktitle={2009 Third IEEE International Conference on Secure Software Integration and Reliability Improvement}, 
title={Performance Testing of Mobile Applications at the Unit Test Level}, 
year={2009}, 
volume={}, 
number={}, 
pages={171-180}, 
abstract={With the rapid growth of the wireless market and the development of various mobile devices, innovative methods and technologies to produce high-quality mobile applications and reduce time to market have been emerging. Mobile applications are often characterized by an array of limitations such as the short development lifecycle to gain a competitive advantage and difficulties to update once released. Hence, rigorous testing on the applications is required before distribution to the market, including structural white-box, functional black-box, integration and system testing. Although recently performance testing at the system test level has become crucial given its direct connection with the product quality improvement, most such tests are confined to the areas of load, usability, and stress testing. Moreover, the implementation itself is insufficient due to the limitations of the development environment. This paper proposes a method to support performance testing utilizing a database established through benchmark testing in emulator-based test environment at the unit test level. It also presents the tool that supports the proposed method of performance testing and verifies the reliability of performance test results through experiments.}, 
keywords={integrated software;program testing;emulator-based test environment;functional black-box;integration;mobile applications;performance testing;structural white-box;system testing;unit test level;wireless market;Application software;Benchmark testing;Computer science;Databases;Mobile computing;Process control;Software performance;Software testing;Stress;System testing;emulator-based test;mobile application;performance test;unit test}, 
doi={10.1109/SSIRI.2009.28}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{4297593, 
author={V. Yakovyna and D. Fedasyuk and M. Seniv and O. Bilas}, 
booktitle={2007 9th International Conference - The Experience of Designing and Applications of CAD Systems in Microelectronics}, 
title={The Performance Testing of RSA Algorithm Software Realization}, 
year={2007}, 
volume={}, 
number={}, 
pages={390-392}, 
abstract={The software realization of RSA public key encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested. The present paper shows, that the encryption rate is 306.4 plusmn 0.6 kbytes/sec, while the coefficient of encryption time increasing with file size increasing is 3.299. It is concluded that the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.}, 
keywords={application program interfaces;network operating systems;public key cryptography;.NET platform;CryptoAPI;RSA algorithm software realization;RSA public key encryption algorithm;coefficient-of-encryption time;cryptographic software;encryption rate;flexible architecture independent tool;public-key cryptography;secure implementation;Algorithm design and analysis;Application software;Costs;Hardware;Public key;Public key cryptography;Software algorithms;Software performance;Software quality;Software testing;.NET;Operation performance;Public-key cryptography;RSA algorithm;Software realization}, 
doi={10.1109/CADSM.2007.4297593}, 
ISSN={}, 
month={Feb},}
@INBOOK{5270486, 
author={H. Anthony Chan}, 
booktitle={Accelerated Stress Testing Handbook:Guide for Achieving Quality Products}, 
title={Manufacturing AST with Telecommunication Products - Reprinted from Quality Improvement Using Environmental Stress Testing, in the AT T Technical Journal, pp. 1023, with permission from the authors and the AT T Technical Journal 1992.}, 
year={2001}, 
volume={}, 
number={}, 
pages={372-}, 
abstract={
AT&T and other leading manufacturers have developed techniques that use environmental stress testing to enhance the quality and reliability of electronics assemblies. These techniques consist primarily of applying thermal, vibration, and voltage stresses to components or assemblies during design and manufacturing. Environmental stress testing is a tool that is used to accelerate the detection of product weaknesses. When coupled with corrective-action programs, this tool also enhances product quality and reliability. This chapter discusses applications of environmental stress testing in the electronics industry. It also reviews the results of environmental stress testing at AT&T's Little Rock Operations Center in Arkansas as applied primarily to the manufacture of circuit-card assemblies.

Introduction

EST During Product Design (Design AST)

Production EST (AST)

Production EST (AST) Studies at AT&T

Results of the Thermal Cycling Studies

Acknowledgments

References

}, 
keywords={}, 
doi={10.1109/9780470544051.ch20}, 
ISSN={}, 
publisher={Wiley-IEEE Press}, 
isbn={9780470544051}, 
url={https://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5270486},}
@INPROCEEDINGS{4297591, 
author={V. Yakovyna and D. Fedasyuk and M. Seniv}, 
booktitle={2007 9th International Conference - The Experience of Designing and Applications of CAD Systems in Microelectronics}, 
title={Software Realization and Performance Testing of DES Cryptographic Algorithm on the .NET Platform}, 
year={2007}, 
volume={}, 
number={}, 
pages={386-388}, 
abstract={The software realization of DES symmetric encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested and it was shown, that the encryption rate is 11.1 Mb/sec on the Intel Celeron D 351 3.2 GHz processor, while the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.}, 
keywords={computer software;cryptography;.NET platform;DES symmetric encryption algorithm;Intel Celeron D 351 3.2 GHz processor;data encryption standard;software implementation;software realization;Algorithm design and analysis;Application software;Cryptography;Hardware;Protection;Software algorithms;Software performance;Software quality;Software testing;Software tools;.NET;CryptoAPI;DES algorithm;Software realization;Symmetric cryptography}, 
doi={10.1109/CADSM.2007.4297591}, 
ISSN={}, 
month={Feb},}
@INPROCEEDINGS{7492562, 
author={C. Gavrilă and C. Z. Kertész}, 
booktitle={2016 International Conference on Development and Application Systems (DAS)}, 
title={Automated performance testing of end-to-end streaming solutions over HbbTV architecture}, 
year={2016}, 
volume={}, 
number={}, 
pages={135-138}, 
abstract={This paper presents an automated test execution environment designed to analyze the accessibility, reliability and streaming performance of an end-to-end Hybrid broadcast broadband TV (HbbTV) solution. Its purpose is to provide the means for the TV providers to test their HbbTV solution by simulating real-world scenarios and online functioning in a local, offline environment, before making it available for the end users. This way, common problems like server overload, poor streaming quality and HbbTV incorrect functionality can be foreseen and corrected.}, 
keywords={Computer architecture;Digital TV;Measurement;Servers;Simple object access protocol;Testing;Automated testing;HbbTV;Network conditions simulation;Streaming media;Web services}, 
doi={10.1109/DAAS.2016.7492562}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{472644, 
author={Chih-Ang Chen and S. K. Gupta}, 
booktitle={Electro/94 International. Conference Proceedings. Combined Volumes.}, 
title={BIST/DFT for performance testing of bare dies and MCMs}, 
year={1994}, 
volume={}, 
number={}, 
pages={803-812}, 
abstract={High emphasis on performance and high cost of MCM repairs necessitates a frame work for performance testing of dies, substrates, and final MCMs. Application of performance tests to bare dies is very expensive due to the need for small and high speed probes and ATE, BIST, scan, and boundary scan can provide a framework to accomplish performance testing in a cost effective manner. It has been shown that traditional BIST, scan, and boundary scan techniques do not provide the framework for performance testing. Special BIST and scan design techniques that can be employed to guarantee high coverage of delay faults are described. Typically, these techniques produce BIST test pattern generators and scan chain designs that require slightly increased hardware overhead over conventional BIST/scan. However, they can drastically decrease the complexity of bare die performance testing. Furthermore, when used in combination with the proposed enhanced boundary scan design, they provide a framework for detection and diagnosis of dynamic failures}, 
keywords={built-in self test;fault diagnosis;multichip modules;substrates;BIST;MCMs;bare dies;boundary scan;delay faults;dynamic failures;performance testing;scan;Built-in self-test;Circuit faults;Costs;Delay;Economic forecasting;Integrated circuit interconnections;Logic testing;Parasitic capacitance;Probes;System testing}, 
doi={10.1109/ELECTR.1994.472644}, 
ISSN={}, 
month={May},}
@ARTICLE{6582353, 
author={J. L. Wayman and A. Possolo and A. J. Mansfield}, 
journal={IET Biometrics}, 
title={Modern statistical and philosophical framework for uncertainty assessment in biometric performance testing}, 
year={2013}, 
volume={2}, 
number={3}, 
pages={85-96}, 
abstract={The question of estimating uncertainty in measurement is fundamental to all scientific fields. In the field of automated human recognition, lack of repeatability and reproducibility of measurements has been noted since at least the 1970s. This study discusses current approaches to estimation of measurement uncertainty within the broader context of scientific philosophy and measurement science. The authors discuss the Duhem-Quine thesis on testing holism and international standards on estimating and reporting uncertainty in laboratory measurements, then apply these concepts to the estimation of uncertainty in technology, scenario and operational testing in biometrics. The authors advocate for moving beyond the calculation of `coverage' intervals as defined in the ISO/IEC `guidelines for the expression of uncertainty in measurement' to full application of the concepts of uncertainty assessment.}, 
keywords={IEC standards;ISO standards;biometrics (access control);computerised instrumentation;measurement standards;measurement uncertainty;philosophical aspects;statistical analysis;Duhem-Quine thesis;ISO-IEC guidelines;biometric performance testing;coverage intervals;international standards;laboratory measurements;measurement science;measurement uncertainty estimation;operational testing;philosophical framework;scenario testing;scientific philosophy;statistical framework;technology testing}, 
doi={10.1049/iet-bmt.2013.0009}, 
ISSN={2047-4938}, 
month={September},}
@INPROCEEDINGS{6605950, 
author={C. H. Kao and C. C. Lin and J. N. Chen}, 
booktitle={2013 13th International Conference on Quality Software}, 
title={Performance Testing Framework for REST-Based Web Applications}, 
year={2013}, 
volume={}, 
number={}, 
pages={349-354}, 
abstract={Recently, enterprises, organizations, and software companies are building more and more web applications to provide their services over the Internet. In order to fulfill various requirements, the complexity of web applications nowadays is increasing dramatically. As a result, the performance characteristics of web applications, including response time, throughput, etc, become more critical than before and should be taken into careful consideration. If the response time of a web application is poor, users may lose their interests even the function of the web application is correct. Therefore, how to execute performance testing on a complex web application systematically and efficiently will be an important issue. In this paper, a performance testing framework for REST-based web applications is introduced. The performance testing framework aims to provide software testers with an integrated process from test cases design, test scripts generation, to test execution. Based on the test cases designed by software testers and the appropriate software artifacts preserved by the framework (e.g., API document), the framework generates the corresponding performance test scripts, which can be executed by specific performance test tools. This helps software testers to focus more in the design of performance test cases. In addition, effort needed to understand the design and implementation of the application and to learn the operation of testing tools decrease. Thus, the efficiency of performance testing can be highly facilitated.}, 
keywords={Internet;program testing;Internet;REST-based Web applications;performance test scripts;performance test tools;performance testing framework;representational state transfer;software artifacts;software companies;software testers;test cases design;test execution;test scripts generation;Complexity theory;Computer architecture;Engines;Software;Testing;Time factors;XML;Performance testing;software testing;web application}, 
doi={10.1109/QSIC.2013.32}, 
ISSN={1550-6002}, 
month={July},}
@INPROCEEDINGS{6974152, 
author={S. Lee and J. Y. Jo and Y. Kim}, 
booktitle={2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
title={Performance testing of web-based data visualization}, 
year={2014}, 
volume={}, 
number={}, 
pages={1648-1653}, 
abstract={Many scientific applications generate massive data that requires visualization. For example, the Nevada Solar Energy-Water-Environmental Nexus project has been generating a large amount of environmental monitoring data in textual format. As the data is available on the web, a web-based visualization tool is desirable for the project rather than a standalone tool. This research analyzes the processing mechanisms of four popular web-based data visualization tools, that is, Google Charts, Flex, OFC, D3, and compares their performances. A standalone visualization tool, JfreeChart, have been also used for comparison. The processing times have been divided into three segments, layout time, data transformation time, and rendering time, and separately measured. The actual temperature data from the Nevada Nexus project has been used for testing in different scales ranging from 100 to 100,000 data points. The result shows that each visualization tool has its own ideal environment.}, 
keywords={Internet;data visualisation;environmental monitoring (geophysics);rendering (computer graphics);scientific information systems;D3;Flex;Google Charts;JfreeChart;Nevada Solar Energy-Water-Environmental Nexus project;OFC;Web-based data visualization tools;data transformation time;environmental monitoring data;layout time;performance testing;rendering time;scientific applications;standalone visualization tool;textual format;Browsers;Data visualization;Flexible printed circuits;Google;Libraries;Rendering (computer graphics);Servers;D3.js;Data Visualization;Flex;Google Charts;JFreeChart;Open Flash Chart;Sensor Data}, 
doi={10.1109/SMC.2014.6974152}, 
ISSN={1062-922X}, 
month={Oct},}
@INPROCEEDINGS{4483205, 
author={S. Chen and D. Moreland and S. Nepal and J. Zic}, 
booktitle={19th Australian Conference on Software Engineering (aswec 2008)}, 
title={Yet Another Performance Testing Framework}, 
year={2008}, 
volume={}, 
number={}, 
pages={170-179}, 
abstract={Performance testing is one of the vital activities spanning the whole life cycle of software engineering. While there are a considerable number of performance testing products and open source tools available, they are either too expensive and complicated for small projects, or too specific and simple for diverse performance tests. This paper presents a general-purpose testing framework for both simple and small, and complicated and large-scale performance testing. Our framework proposes an abstraction to facilitate performance testing by separating the application logic from the common performance testing functionalities. This leads to a set of general-purpose data models and components, which form the core of the framework. The framework has been prototyped on both .NET and Java platforms and was used for a number of performance-related projects.}, 
keywords={Java;program testing;software performance evaluation;.NET platform;Java platform;general-purpose data model;general-purpose testing framework;performance testing framework;performance testing product;software engineering;Australia;Automatic testing;Data models;Grinding machines;Java;Life testing;Logic testing;Prototypes;Software engineering;Software testing}, 
doi={10.1109/ASWEC.2008.4483205}, 
ISSN={1530-0803}, 
month={March},}
@INPROCEEDINGS{4036666, 
author={B. H. Lim and J. R. Kim and K. H. Shim}, 
booktitle={2006 IEEE International Conference on Multimedia and Expo}, 
title={Hierarchical Load Testing Architecture using Large Scale Virtual Clients}, 
year={2006}, 
volume={}, 
number={}, 
pages={581-584}, 
abstract={In this work, we develop a hierarchical load testing architecture using large scale virtual clients to reduce the testing time and ensure the stability of the server for distributed applications. It explicitly secures the stability of the servers for networked virtual environment and at the same time, it elaborately generates actual loads for testing the performance of the servers. Our agent based load testing architecture provides variety of interactions of virtual entities in the virtual worlds to perform realistic simulations. Simulation results illustrate that our proposed architecture ensures the stability and capacity of the servers for both massively multiplayer online games and peer-to-peer network games}, 
keywords={client-server systems;computer games;peer-to-peer computing;performance evaluation;software agents;distributed application;hierarchical agent based load testing architecture;large scale networked virtual client-server environment;multiplayer online games;peer-to-peer network games;Computational modeling;Computer architecture;Computer industry;Electronic equipment testing;Large-scale systems;Network servers;Pervasive computing;Stability;System testing;Virtual environment}, 
doi={10.1109/ICME.2006.262475}, 
ISSN={1945-7871}, 
month={July},}
@INPROCEEDINGS{6903204, 
author={J. Zhou and B. Zhou and S. Li}, 
booktitle={2014 IEEE 38th International Computer Software and Applications Conference Workshops}, 
title={Automated Model-Based Performance Testing for PaaS Cloud Services}, 
year={2014}, 
volume={}, 
number={}, 
pages={644-649}, 
abstract={Recently, cloud computing has become popular for its unique advantages. Many applications have been migrated to cloud as web services. However, evaluating the performance of cloud services is non-trivial. Performance testing is one of the dominant techniques for evaluating system performance. In this paper, we present a model and template-based approach that automatically generates test scripts and test cases to measure service performance in an enterprise private cloud. We describe how load is generated automatically from our tool. Our empirical study shows the proposed approach can significantly decrease the cost of performance testing and help reveal potential performance issues.}, 
keywords={Web services;cloud computing;program testing;software performance evaluation;PaaS cloud services;Web services;automated model;cloud computing;enterprise private cloud;performance testing;Automation;Cloud computing;Computational modeling;Context;Load modeling;Testing;automated;cloud;performance testing;web service}, 
doi={10.1109/COMPSACW.2014.108}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{4637713, 
author={J. Xie and X. Ye and B. Li and F. Xie}, 
booktitle={2008 10th IEEE International Conference on High Performance Computing and Communications}, 
title={A Configurable Web Service Performance Testing Framework}, 
year={2008}, 
volume={}, 
number={}, 
pages={312-319}, 
abstract={More and more softwares based on web service technologies are developed. Before their releases on the Internet, it is necessary to evaluate these systems' performance, especially their response time under different workload pressures. However, existing performance testing benchmarks and tools for web service applications are difficult to adapt to various user-specific testing purposes. This paper proposes a configurable web service performance testing framework which contains client module, application server module and database module. Client module, by using the network cooperation method that one central client drives several other clients, adapts to a great number of concurrent customers to request web services. Application server module contains web services under testing and external supporting web services, each of which is configured as a plug-in. The process to realize mixed ratio of web service interactions is similar to dealing cards and adapts to different commercial application characteristics. In database module, the data model including table and attribute dependence can be customized, and the data scale initialization can be resized according to the topology of above dependence. As such, this framework allows testers to dynamically define their data model, customize their scale of database, configure their transaction characteristics, deploy their application strategies and confirm their performance metrics..}, 
keywords={Web services;client-server systems;data models;program testing;Internet;attribute dependence;client-server module;configurable Web service performance testing;data model;database module;table dependence;user-specific testing purpose;Application software;Benchmark testing;Data models;Delay;Internet;Measurement;Network servers;Topology;Transaction databases;Web services;benchmark;framework;performance testing;web service}, 
doi={10.1109/HPCC.2008.53}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{5276470, 
author={M. Z. Mas'ud and A. H. Yaacob and N. M. Ahmad}, 
booktitle={2006 International Conference on Computing Informatics}, 
title={Network performance testing on VM based autonomous web server}, 
year={2006}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={As online services increasingly play vital roles in modern society, the possibilities and opportunities offered are limitless, unfortunately, so too are the risks and chances of malicious intrusions. Intrusion detection systems (IDSs) has been widely used as an important component in protecting online service towards Web attacks and evasions. Yet, today's architectures for intrusion detection force the IDS designer to make a difficult choice to place IDS, so that it can protect itself from a direct attack. To address these challenges, this paper introduces a novel framework to safeguard IDS from a direct attack. Simply called zero administrative server (ZAS), the system incorporates IDS in a virtual machine (VM) environment. VM offers strong isolation for IDS from the monitored services and provides significant resistance to malicious attacks. Moreover, this VM based WWW server has the ability to monitor the network traffic to the running services; analyse the information obtained and detect the intrusion; alienate the intruder from the services; and reconstruct the corrupted data or damaged files caused by the evasion. In this paper, we demonstrate ZAS by exposing it to several attacking tools as well as to show the effects it takes on the network performance in terms of TCP throughput and application-to-application round trip time.}, 
keywords={Web services;security of data;virtual machines;VM based autonomous Web server;Web attacks;intrusion detection systems;malicious attacks;network performance testing;online services;virtual machine;zero administrative server;File servers;Intrusion detection;Network servers;Protection;Testing;Virtual machine monitors;Virtual machining;Virtual manufacturing;Web server;World Wide Web;Checksum;Intrusion Detection System;Virtual Machine;WWW Server}, 
doi={10.1109/ICOCI.2006.5276470}, 
ISSN={2166-5710}, 
month={June},}
@INPROCEEDINGS{7219669, 
author={T. Kanstrén and P. Aho and A. Lämsä and H. Martin and J. Liikka and M. Seppänen}, 
booktitle={2015 IEEE International Conference on Technologies for Practical Robot Applications (TePRA)}, 
title={Robot-assisted smartphone performance testing}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={This paper describes experiences and lessons learned in applying an approach of using a physical robot for testing overall smartphone device performance based on user profiles. The process consists of capturing user actions, abstracting them to usage profiles, transforming these into test models, and generating test cases from the models. The goal is to support performance testing of touch screen devices and applications in a realistic test environment. To achieve this, the tests are based on real-world generated user profiles and executed using a real physical robot, simulating the actual user. Our performance testing targets different attributes of performance such as response times, power and resource usage, and software/hardware aging. Use of different hardware and software configurations in the test scenarios is considered. This work has been performed in close collaboration with industry partners in robotics provider and user industries.}, 
keywords={program testing;robots;smart phones;software maintenance;software performance evaluation;hardware aging;hardware configuration;overall smartphone device performance testing;physical robot;power usage;resource usage;response times;robot-assisted smartphone performance testing;software aging;software configuration;touch screen devices;user profiles;Electronic mail;Markov processes;Performance evaluation;Robot kinematics;Service robots;Testing}, 
doi={10.1109/TePRA.2015.7219669}, 
ISSN={2325-0526}, 
month={May},}
@ARTICLE{370727, 
author={D. E. Pachucki}, 
journal={IEEE Transactions on Components, Packaging, and Manufacturing Technology: Part A}, 
title={Environmental stress testing experiment using the Taguchi method}, 
year={1995}, 
volume={18}, 
number={1}, 
pages={3-9}, 
abstract={Manufacturing process improvements which increase productivity, decrease test process time, and improve customer satisfaction are highly desirable in today's marketplace. The application of environmental stress screening (ESS) is a method of achieving these improvements. ESS is the application of stresses applied beyond product specification limits in order to find latent product defects. Utilizing ESS achieves increased robustness and lower infant mortality. An experiment was performed to identify the significance or relevancy of the selected stresses for application in the printed wiring board (PWA) production process by using a statistically significant controlled method. The design of experiments statistical approach (analysis of variance), is applied, combined with the Taguchi two-level, seven-factor design method. This experiment concentrated on three stresses (temperature cycling, random vibration, and power cycling) and two diagnostic levels: a prom-based (programmable memory chip), power-on self test (POST), and a functional diagnostic test suite, contained on disk storage. Note that this was not an optimization experiment. Once the significance to the production process is identified, future optimizing of temperature cycling, power cycling, and vibration screens, will be conducted. Also, voltage margining was not included so as to reduce the complexity of the experiment-treatment factors and interactions. Experimental results and conclusions on the effectiveness of different stress regimens are presented in this paper}, 
keywords={automatic testing;covariance analysis;design of experiments;dynamic testing;environmental stress screening;environmental testing;human resource management;life testing;printed circuit manufacture;printed circuit testing;production testing;Taguchi method;analysis of variance;customer satisfaction;design of experiments;diagnostic levels;environmental stress testing;functional diagnostic test suite;infant mortality;latent product defects;power cycling;power-on self test;printed wiring board production;productivity;prom-based diagnostics;random vibration;robustness;statistically significant controlled method;stress regimens;temperature cycling;test process time;Automatic testing;Customer satisfaction;Design methodology;Electronic switching systems;Manufacturing processes;Production;Productivity;Robustness;Stress;Temperature}, 
doi={10.1109/95.370727}, 
ISSN={1070-9886}, 
month={Mar},}
@INPROCEEDINGS{755123, 
author={Qingxin Chen and V. Sorokine}, 
booktitle={1999 IEEE MTT-S International Topical Symposium on Technologies for Wireless Applications (Cat. No. 99TH8390)}, 
title={A fast simulation technique for performance testing of the RF/IF chain of CDMA receivers}, 
year={1999}, 
volume={}, 
number={}, 
pages={23-28}, 
abstract={We propose an improved approach to the simulation of the CDMA forward link. The simulator achieves its computational efficiency by adopting a simplified CDMA system model without compromising much of its practicality. Additional reduction in the computational complexity is obtained by implementing bit level operations for certain receiver tasks. Improved processing algorithms are also introduced, which further facilitates the simulation process. The rationale behind the development of the simulator as well as many techniques involved could prove beneficial to a CDMA receiver designer in terms of shortening the design cycle and reducing the computational power requirements.}, 
keywords={code division multiple access;computational complexity;digital simulation;land mobile radio;radio receivers;signal processing;telecommunication equipment testing;CDMA forward link;CDMA receivers;RF/IF chain;bit level operations;computational complexity reduction;computational efficiency;computational power requirements reduction;design cycle;fast simulation technique;mobile radio;performance testing;processing algorithms;system model;Additive white noise;Computational modeling;Context modeling;Fading;Multiaccess communication;Power system modeling;Radio frequency;Signal generators;Space technology;Testing}, 
doi={10.1109/MTTTWA.1999.755123}, 
ISSN={}, 
month={Feb},}
@INPROCEEDINGS{4925806, 
author={B. Honari and J. Donovan and T. Joyce and S. Wilson}, 
booktitle={2008 Annual Reliability and Maintainability Symposium}, 
title={Application of generalized linear models for optimizing production stress testing}, 
year={2008}, 
volume={}, 
number={}, 
pages={267-271}, 
abstract={Accelerated environmental stress tests (EST) are applied during the manufacturing process to improve reliability by precipitating and detecting latent defects. This test represents an in-process manufacturing screen and the objective of performing it is to avoid early field failures that reduce the customer satisfaction level and increase warranty and compensation costs. Temperature cycling during EST is one of the most commonly used test procedures. Although it is an expensive and energy intensive procedure, usually a lengthy test is initially recommended for a new product. Based on the product test performance or a possible manufacturing process modification, the test duration and regime may be changed after some period. Even if the number of test cycles is reduced, EST continues to be an expensive test and a major process bottleneck. This paper uses generalized linear modeling (GLM) to investigate the effects of the production and EST test variables on the population under test. Both the number of units rejected and the time to failure can be modeled as a regression function of covariates representative of the test environment. The field reliability function is written as a product of the unconditional reliability in each segment of the test profile such as dwell, ramp, etc. The next step is to apply the result of the temperature cycle EST GLM to a mathematical cost model. This cost model includes both the test cost and the warranty and compensation costs of the early field failures. The optimum test regime and number of cycles, which minimizes the total cost is determined by combining the GLM and the cost model. In this way the production test regime can be optimized in terms of field reliability/test cost trade-off.}, 
keywords={costing;flaw detection;life testing;manufacturing processes;production testing;regression analysis;reliability;accelerated environmental stress tests;compensation cost;generalized linear model;latent defect detection;manufacturing process;mathematical cost model;product test performance;production stress testing;regression analysis;reliability;warranty cost;Cost function;Customer satisfaction;Life estimation;Manufacturing processes;Performance evaluation;Production;Stress;Temperature;Testing;Warranties;Environmental Stress Testing;Generalized Linear Models;Test Optimization}, 
doi={10.1109/RAMS.2008.4925806}, 
ISSN={0149-144X}, 
month={Jan},}
@INPROCEEDINGS{8031452, 
author={N. Gois and P. Porfírio and A. Coelho}, 
booktitle={2017 IEEE International Conference on Computer and Information Technology (CIT)}, 
title={A Multi-objective Metaheuristic Approach to Search-Based Stress Testing}, 
year={2017}, 
volume={}, 
number={}, 
pages={55-62}, 
abstract={Nowadays applications need to deal with a large number of concurrent requests. These systems must be stress tested to ensure that they can function correctly under a load. In this context, a research field called Search-based Software Testing has become increasingly important. Most of the search-based test methods are based on single objective optimization. In the case of multi-objective optimization of tests, usually researchers assign different weight values to different objectives and combine them as a single objective. This research paper verifies the use of a multi-objective algorithm in search-based stress testing. The NSGA-II algorithm was implemented in the IAdapter tool using the jMetal framework. IAdapter is a JMeter plugin used for performing search-based stress tests. jMetal is an object-oriented Java-based framework for multi-objective optimization with metaheuristics. One experiment was conducted to validate the proposed approach.}, 
keywords={Java;Pareto optimisation;concurrency control;genetic algorithms;program testing;search problems;IAdapter tool;JMeter plugin;NSGA-II algorithm;Software Testing;concurrent requests;jMetal framework;multiobjective algorithm;multiobjective metaheuristic approach;multiobjective optimization;object-oriented Java-based framework;search-based stress testing;search-based test methods;single objective optimization;weight values;Genetic algorithms;Load modeling;Search problems;Software;Stress;Testing;Time factors;Multi-Objective Metaheuristic;Pareto Frontier;Search-Based Stress Test}, 
doi={10.1109/CIT.2017.19}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{7414168, 
author={D. Kaulbars and F. Schweikowski and C. Wietfeld}, 
booktitle={2015 IEEE Globecom Workshops (GC Wkshps)}, 
title={Spatially Distributed Traffic Generation for Stress Testing the Robustness of Mission-Critical Smart Grid Communication}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Resilient Smart Grids require very robust communication infrastructures, which allow to support the control of the Smart Grid even and especially in critical situations. Current network quality assurance processes, such as drive tests in wireless systems, typically focus on cell coverage and quality of service parameters (e.g., max. data rate) at a specific geographical position, without considering the impact of overload situations. Therefore, this paper introduces a methodology for stress testing a communication infrastructure for Smart Grids by synchronized, distributed so-called Smart Traffic Generators (STGs). Due to their low cost, the STGs become a permanent part of the infrastructure and enable a network operator independent, continuous network quality monitoring. A case study leveraging a LTE deployment demonstrates how the proposed approach can prove the fulfillment of Quality of Service (QoS) requirements of time critical Smart Grid applications, even in stress situations with high cell load. Although, the proposed approach has been introduced for Smart Grids, it can also be used for ensuring the communication resilience for other critical infrastructures, e.g., public safety networks.}, 
keywords={Long Term Evolution;carrier transmission on power lines;quality of service;smart power grids;telecommunication traffic;mission-critical smart grid communication;network quality monitoring;quality of service;spatially distributed traffic generation;stress testing;Generators;Long Term Evolution;Mobile communication;Mobile computing;Quality of service;Smart grids;Stress}, 
doi={10.1109/GLOCOMW.2015.7414168}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{5634372, 
author={X. Wang and B. Zhou and W. Li}, 
booktitle={International Symposium on Parallel and Distributed Processing with Applications}, 
title={Model Based Load Testing of Web Applications}, 
year={2010}, 
volume={}, 
number={}, 
pages={483-490}, 
abstract={In this paper, a usage model is proposed to simulate users' behaviors realistically in load testing of web applications, and another relevant workload model is proposed to help generate realistic load for load testing. It also demonstrates an eclipse-based load testing tool “Load Testing Automation Framework (LTAF)” which is based on these two models and can perform load testing of web applications easily and automatically. Furthermore, these models and tools were successfully applied into a representative web-based system from a big Corporation.}, 
keywords={Internet;program testing;Load Testing Automation Framework;Web applications;Web-based system;eclipse-based load testing tool;model based load testing;usage model;user behaviors;File systems;Load modeling;Markov processes;Navigation;Servers;Testing;Unified modeling language;Load Model;Load Testing;Markov Chains;Performance Engineering;Usage Model}, 
doi={10.1109/ISPA.2010.24}, 
ISSN={2158-9178}, 
month={Sept},}
@INPROCEEDINGS{4652394, 
author={A. Young and T. Holt and M. Elsayed and A. Neuber and M. Kristiansen and L. L. Altgilbers and A. H. Stults}, 
booktitle={2007 16th IEEE International Pulsed Power Conference}, 
title={Fuse and load testing with mid-sized, high energy density flux compression generators}, 
year={2007}, 
volume={2}, 
number={}, 
pages={1165-1168}, 
abstract={Compact Pulsed Power Systems (CPPSs) require power sources that are small in size yet can produce the necessary electrical energy required to drive a given load. Helical Flux Compression Generators (HFCGs) are attractive for single shot applications due to their rapid conversion of chemical energy to electrical energy. Mid-sized generators occupy little total volume (∼4,000-cm3 total with a compressible volume of ∼300-cm3 in the present generator design), while the high explosives used in an HFCG provide an energy density of ∼8,000 MJ/m3. Consistent output current and energy gain from shot to shot are key variables in the ability of an HFCG to drive CPPSs effectively. An investigation into the practicality of using mid-sized HFCGs as the driver for single shot CPPSs is presented. Data and waveforms from generators fired into 3 μH inductive loads are shown, with results measuring the generator’s performance as a driver for an inductive energy storage (IES) system. Results are also shown from adding a power conditioning system to the output of the HFCG, where the measurements demonstrate the ability of an HFCG to drive high impedance loads. The effectiveness of a mid-sized HFCG as drivers for these systems will be evaluated.}, 
keywords={Chemicals;Energy measurement;Energy storage;Explosives;Fuses;Impedance measurement;Power conditioning;Power measurement;Pulse power systems;Testing}, 
doi={10.1109/PPPS.2007.4652394}, 
ISSN={2158-4915}, 
month={June},}
@INPROCEEDINGS{7813849, 
author={R. Khan and M. Amjad}, 
booktitle={2016 International Conference on Computing, Communication and Automation (ICCCA)}, 
title={Web application's performance testing using HP LoadRunner and CA Wily introscope tools}, 
year={2016}, 
volume={}, 
number={}, 
pages={802-806}, 
abstract={This paper cover the importance of performance testing of the web application. The performance of any web application has been depend on the some different type of the testing process like load testing, soak testing, smoke testing and stress testing etc. In this paper we applied smoke testing on a web application. This web application has been developed for the customer before delivering the software to the customer it is duty of tester to test all the aspects of the software and deliver error free and reliable software to the customer. Reliability has its own most important role in the software industry. In this paper performance testing has been performed using HP LoadRunner and CA Wily Introscope tools.}, 
keywords={DP industry;Internet;program testing;software performance evaluation;software reliability;software tools;CA Wily Introscope tool;HP LoadRunner;Web application performance testing;smoke testing;software industry;software reliability;Business;Scalability;Servers;Software;Testing;Throughput;Uniform resource locators;HP LoadRunner;Load Testng;Perforamance Testing;Software Testing;Wily Introscope Tools}, 
doi={10.1109/CCAA.2016.7813849}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{6825689, 
author={J. Mukherjee and M. Wang and D. Krishnamurthy}, 
booktitle={2014 IEEE Seventh International Conference on Software Testing, Verification and Validation Workshops}, 
title={Performance Testing Web Applications on the Cloud}, 
year={2014}, 
volume={}, 
number={}, 
pages={363-369}, 
abstract={Web applications are increasingly resorting to public cloud platforms such as the Amazon Web Services (AWS) Elastic Compute Cloud (EC2). However, previous studies have shown that the virtualized infrastructures used in a cloud environment can introduce performance issues. Hence, it is crucial to test the performance of the cloud to support Web applications. This is challenging because the performance effect of the cloud platform cannot be easily isolated from other extraneous factors. In this paper, we present a systematic experimental process to address this challenge. Following our proposed process, we test the performance of Web applications running on different types of AWS EC2 instances. Results suggest that Web server response times can fluctuate up to 1000% for the same workload under certain circumstances such as instance type, time-of-the-day, and day-of-the-week.}, 
keywords={Web services;cloud computing;software performance evaluation;virtualisation;AWS EC2 instances;Amazon Web Services Elastic Compute Cloud;Web application performance testing;Web server response time;cloud environment;instance type;performance issues;public cloud platform;virtualized infrastructure;Bandwidth;Generators;Testing;Time factors;Web servers}, 
doi={10.1109/ICSTW.2014.57}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{4346025, 
author={A. J. Young and T. A. Holt and M. A. Elsayed and A. A. Neuber and M. Kristiansen and L. L. Altgilbers and A. H. Stults}, 
booktitle={2007 IEEE 34th International Conference on Plasma Science (ICOPS)}, 
title={Fuse and Load Testing with Mid-Sized, High Energy Density Flux Compression Generators}, 
year={2007}, 
volume={}, 
number={}, 
pages={719-719}, 
abstract={Compact pulsed power systems require power sources that are small in size yet can produce the necessary electrical energy required to drive the system. Helical magnetic flux compression generators (HFCGs) are attractive for single shot applications due to their rapid conversion of chemical energy to electrical energy. The small total volume of a generator coupled with the energy density of the fast-reacting high explosives makes mid-sized HFCGs an appealing option as sources in single shot compact pulsed power systems. Consistent output current and energy gain from shot to shot are key variables in the ability of an HFCG to drive compact pulsed power systems efficiently.}, 
keywords={electric fuses;pulse generators;pulsed power supplies;compact pulsed power systems;fuse testing;helical magnetic flux compression generators;high energy density flux compression generators;load testing;Electronic equipment testing;Explosives;Fuses;Impedance;Power generation;Pulse compression methods;Pulse generation;Pulse power systems;Pulse shaping methods;Switches}, 
doi={10.1109/PPPS.2007.4346025}, 
ISSN={0730-9244}, 
month={June},}
@INPROCEEDINGS{8233806, 
author={B. Wunderle and J. Heilmann and D. May and J. Arnold and J. Hirscheider and J. Bauer and R. Schacht and J. Vogel and M. A. Ras}, 
booktitle={2017 23rd International Workshop on Thermal Investigations of ICs and Systems (THERMINIC)}, 
title={Modelling and characterisation of a grease pump-out test stand and its use for accelerated stress testing of thermal greases}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Thermal greases allow a low stress bond at low bond line thicknesses (BLT) at medium thermal conductivities and simple application, all of which make it an alternative to solders, thermal adhesives or pads. It is widely used in power and microprocessor applications, most of which involve large areas to be used for heat transfer. However, for years thermal overload failure of power modules and chips has been a pressing problem due to pump-out of thermal grease as die or module thermal interface material (TIM): Most thermal greases are Bingham fluids and thus no solids, so they can be squeezed out from in between the gap, driven by thermo-mechanical action of the adjacent layers as e.g. DCB substrate or silicon chip with the heat sink. Today, thermal greases have to be qualified in lengthy stress tests in a product relevant environment which consumes substantial resources as often a system test is required. Therefore, a fast test is necessary which accelerates testing and thus allows a fast screening of market-available greases on one hand, and guidelines for material development on the other. For that purpose this paper addresses this topic in a combined simulative and experimental manner, where at the same time a novel test procedure is proposed for accelerated grease pump-out testing (GPOT) in the framework of a completely new approach, combining loading with in-situ failure analytical techniques and decoupling thermal from mechanical loading.}, 
keywords={adhesion;adhesives;failure analysis;greases;heat sinks;integrated circuit packaging;integrated circuit reliability;life testing;microprocessor chips;thermal conductivity;thermal management (packaging);thermal resistance;thermal stresses;accelerated grease pump-out;accelerated stress testing;grease pump-out test;stress tests;thermal adhesives;thermal conductivities;thermal grease;thermal interface material module;thermal overload failure;Conductivity;Life estimation;Loading;Stress;Testing;Thermal conductivity;Thermal stresses}, 
doi={10.1109/THERMINIC.2017.8233806}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6728886, 
author={A. Banerjee and S. Chattopadhyay and A. Roychoudhury}, 
booktitle={2013 IEEE 34th Real-Time Systems Symposium}, 
title={Static Analysis Driven Cache Performance Testing}, 
year={2013}, 
volume={}, 
number={}, 
pages={319-329}, 
abstract={Real-time, embedded software are constrained by several non-functional requirements, such as timing. With the ever increasing performance gap between the processor and the main memory, the performance of memory subsystems often pose a significant bottleneck in achieving the desired performance for a real-time, embedded software. Cache memory plays a key role in reducing the performance gap between a processor and main memory. Therefore, analyzing the cache behaviour of a program is critical for validating the performance of an embedded software. In this paper, we propose a novel approach to automatically generate test inputs that expose the cache performance issues to the developer. Each such test scenario points to the specific parts of a program that exhibit anomalous cache behaviour along with a set of test inputs that lead to such undesirable cache behaviour. We build a framework that leverages the concepts of both static cache analysis and dynamic test generation to systematically compute the cache-performance stressing test inputs. Our framework computes a test-suite which does not contain any false positives. This means that each element in the test-suite points to a real cache performance issue. Moreover, our test generation framework provides an assurance of the test coverage via a well-formed coverage metric. We have implemented our entire framework using Chronos worst case execution time (WCET) analyzer and LLVM compiler infrastructure. Several experiments suggest that our test generation framework quickly converges towards generating cache-performance stressing test cases. We also show the application of our generated test-suite in design space exploration and cache performance optimization.}, 
keywords={cache storage;embedded systems;program compilers;program diagnostics;software performance evaluation;Chronos worst case execution time;LLVM compiler infrastructure;WCET analyzer;anomalous cache behaviour;cache performance optimization;cache-performance stressing test cases;coverage metric;design space exploration;dynamic test generation;real-time embedded software;static cache analysis;test coverage;test-suite;Abstracts;Cache memory;Embedded software;Instruments;Performance analysis;Testing;Cache performance;Performance testing;Test generation}, 
doi={10.1109/RTSS.2013.39}, 
ISSN={1052-8725}, 
month={Dec},}
@INPROCEEDINGS{604303, 
author={K. H. Sueker}, 
booktitle={1997 IEEE International Electric Machines and Drives Conference Record}, 
title={A static dynamometer for load testing large variable frequency motor drives}, 
year={1997}, 
volume={}, 
number={}, 
pages={WB1/9.1-WB1/9.3}, 
abstract={The static dynamometer, an apparent oxymoron, is a system which allows full load testing of variable frequency motor drives with no rotating equipment and only minimal demand from the power line. By inserting a reactor between the drive output and the line from which it is powered, the drive can be made to appear as a synchronous generator. This arrangement offers a practical alternative to the motor-generator sets usually employed for load testing. The required equipment consists of a set of power reactors approximating 10% of the drive rating, a contactor and a phase locked loop circuit for regulating the drive phase relative to the line. The static dynamometer is in production use on variable speed drives from 20 to 5000 hp and 480 to 4160 V. There are no intrinsic limits to either power or voltage for its application}, 
keywords={dynamometers;machine testing;motor drives;variable speed drives;20 to 5000 hp;480 to 4160 V;drive rating;load testing;motor-generator sets;phase locked loop circuit;power reactors;production experience;static dynamometer;synchronous generator;variable frequency motor drives;variable speed drives;Circuit testing;Frequency;Inductors;Motor drives;Phase locked loops;Production;Synchronous generators;System testing;Variable speed drives;Voltage}, 
doi={10.1109/IEMDC.1997.604303}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{5614034, 
author={R. Mansharamani and A. Khanapurkar and B. Mathew and R. Subramanyan}, 
booktitle={2010 IEEE 34th Annual Computer Software and Applications Conference Workshops}, 
title={Performance Testing: Far from Steady State}, 
year={2010}, 
volume={}, 
number={}, 
pages={341-346}, 
abstract={The dot com era ushered in a number of industry standard load testing tools. While there is no doubt that these tools have helped improve the quality of IT systems, performance testing in the IT industry is far from steady state. There are still severe gaps between performance test results and production systems performance in IT projects. This paper proposes a number of areas where performance testing needs to improve radically, several of which can be incorporated in to load testing tools. Examples are also provided of simple analytics during single user performance testing to demonstrate the effectiveness of this extra but necessary step in the testing process.}, 
keywords={DP industry;Internet;electronic commerce;performance evaluation;testing;IT system quality;industry standard load testing tools;production systems;single user performance testing;Databases;Extrapolation;Industries;Testing;Throughput;Time factors;Tuning;load testing tools;performance emulation;performance testing;think time variability}, 
doi={10.1109/COMPSACW.2010.66}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{6200165, 
author={J. A. Meira and E. C. d. Almeida and Y. Le Traon and G. Sunye}, 
booktitle={2012 IEEE Fifth International Conference on Software Testing, Verification and Validation}, 
title={Peer-to-Peer Load Testing}, 
year={2012}, 
volume={}, 
number={}, 
pages={642-647}, 
abstract={Nowadays the large-scale systems are common-place in any kind of applications. The popularity of the web created a new environment in which the applications need to be highly scalable due to the data tsunami generated by a huge load of requests (i.e., connections and business operations). In this context, the main question is to validate how far the web applications can deal with the load generated by the clients. Load testing is a technique to analyze the behavior of the system under test upon normal and heavy load conditions. In this work we present a peer-to-peer load testing approach to isolate bottleneck problems related to centralized testing drivers and to scale up the load. Our approach was tested in a DBMS as study case and presents satisfactory results.}, 
keywords={Internet;peer-to-peer computing;program testing;Web applications;centralized testing drivers;large-scale systems;peer-to-peer load testing;system under test;Cloud computing;Computer architecture;Databases;Large-scale systems;Peer to peer computing;Scalability;Testing;large-scale systems;load testing;peer-to-peer}, 
doi={10.1109/ICST.2012.153}, 
ISSN={2159-4848}, 
month={April},}
@ARTICLE{7298477, 
author={B. Jiang and P. Chen and W. K. Chan and X. Zhang}, 
journal={IEEE Transactions on Reliability}, 
title={To What Extent is Stress Testing of Android TV Applications Automated in Industrial Environments?}, 
year={2016}, 
volume={65}, 
number={3}, 
pages={1223-1239}, 
abstract={An Android-based smart television (TV) must reliably run its applications in an embedded program environment under diverse hardware resource conditions. Owing to the diverse hardware components used to build numerous TV models, TV simulators are usually not sufficiently high in fidelity to simulate various TV models and thus are only regarded as unreliable alternatives when stress testing such applications. Therefore, even though stress testing on real TV sets is tedious, it is the de facto approach to ensure the reliability of these applications in the industry. In this paper, we study to what extent stress testing of smart TV applications can be fully automated in the industrial environments. To the best of our knowledge, no previous work has addressed this important question. We summarize the findings collected from ten industrial test engineers who have tested 20 such TV applications in a real production environment. Our study shows that the industry required test automation supports on high-level GUI object controls and status checking, setup of resource conditions, and the interplay between the two. With such supports, 87% of the industrial test specifications of one TV model can be fully automated, and 71.4% of them were found to be fully reusable to test a subsequent TV model with major upgrades of hardware, operating system, and application. It represents a significant improvement with margins of 28% and 38%, respectively, compared with stress testing without such supports.}, 
keywords={Android (operating system);automatic testing;digital television;graphical user interfaces;production engineering computing;program testing;reliability;Android-based smart TV;Android-based smart television;TV simulators;hardware resource conditions;high-level GUI object controls;industrial environments;industrial test specifications;operating system;reliability;status checking;stress testing;test automation;Androids;Automation;Humanoid robots;Smart phones;Stress;TV;Testing;Android;TV;automated testing;reliability;software reuse;stress testing;test case creation}, 
doi={10.1109/TR.2015.2481601}, 
ISSN={0018-9529}, 
month={Sept},}
@ARTICLE{6770530, 
author={T. P. Parker and G. L. Harrison}, 
journal={AT T Technical Journal}, 
title={Quality improvement using environmental stress testing}, 
year={1992}, 
volume={71}, 
number={4}, 
pages={10-23}, 
abstract={AT&T and other leading manufacturers have developed techniques that use environmental stress testing to enhance the quality and reliability of electronics assemblies. These techniques consist primarily of applying thermal, vibration, and voltage stresses to components or assemblies during design and manufacturing. Environmental stress testing is a tool that is used to accelerate the detection of product weaknesses. When coupled with corrective-action programs, this tool also enhances product quality and reliability. This paper discusses applications of environmental stress testing in the electronics industry. It also reviews the results of environmental stress testing at AT&T's Little Rock Operations Center in Arkansas as applied primarily to the manufacture of circuit-card assemblies.}, 
keywords={}, 
doi={10.1002/j.1538-7305.1992.tb00169.x}, 
ISSN={8756-2324}, 
month={July},}
@INPROCEEDINGS{5254473, 
author={Z. Wandan and J. Ningkang and Z. Xubo}, 
booktitle={2009 Ninth International Conference on Hybrid Intelligent Systems}, 
title={Design and Implementation of a Web Application Automation Testing Framework}, 
year={2009}, 
volume={2}, 
number={}, 
pages={316-318}, 
abstract={In this paper the problems in the automation testing of GUI based Web applications are discussed. A new automation testing framework based on the concept of object feature set and dynamic searching policy is proposed. The design and implementation of it are both given. The framework working using result shows that it makes the testing more convenient and efficient with less resources and time cost but higher testing coverage.The ability of maintenance and stability are both improved.}, 
keywords={Internet;graphical user interfaces;program testing;GUI;Internet technology;Web application automation testing framework;Web application maintenance;dynamic searching policy;object feature set;software development cycle;Application software;Automatic control;Automatic testing;Costs;Design automation;Graphical user interfaces;Java;Programming;Software testing;System testing;Web application testing;automation testing framework;dynamic searching technology}, 
doi={10.1109/HIS.2009.175}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{4299917, 
author={X. Shu and F. Maurer}, 
booktitle={International Conference on Software Engineering Advances (ICSEA 2007)}, 
title={A Tool for Automated Performance Testing of Java3D Applications in Agile Environments}, 
year={2007}, 
volume={}, 
number={}, 
pages={35-35}, 
abstract={Following the agile philosophy that all core features of a system need an automated test harness, performance requirements also need such a check when they are essential for the success of a project. The purpose of this paper is to describe a tool, J3DPerfUnit, which supports automated performance testing for Java3D applications in agile environments. We elicited tool requirements from domain experts through a survey and evaluated J3DPerfUnit using code from our partner's bioinformatics project and Java3D official tutorials. The evaluation pointed out that the tool is effective in detecting performance problems and in identifying where they come from when loading/unloading a 3D object.}, 
keywords={Java;program testing;rendering (computer graphics);software metrics;Java3D application;agile environment;automated performance testing;graphics rendering;software metrics;Application software;Automatic testing;Availability;Bioinformatics;Computer science;Engines;Java;Layout;System testing;Tree graphs}, 
doi={10.1109/ICSEA.2007.11}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{5445814, 
author={L. Motalova and O. Krejcar}, 
booktitle={2010 Second International Conference on Computer Engineering and Applications}, 
title={Stress Testing Data Access via a Web Service for Determination of Adequate Server Hardware for Developed Software Solution}, 
year={2010}, 
volume={1}, 
number={}, 
pages={329-333}, 
abstract={The aim of this project is stress testing of the system for data management and planning of the operations developed for home care agencies which has to be upgrading of the current system based on the older database of Microsoft Access product. The part of the system is a mobile application that allows employees to edit the records of patients directly in the terrain. The whole system, including applications developed for the stress testing is based on Microsoft technology .NET. Our Stress Testing application allows testing a selected problem areas to find any limitations before the tested developing solution will be set up at customer. By the help of our test application, the hardware solution for the server was selected on the base of selected home care agency needs.}, 
keywords={Web services;file servers;information retrieval;program testing;software tools;Microsoft access product database;Microsoft technology .NET;Web service;adequate server hardware;data management system;home care agency;stress testing data access;Databases;Displays;Hardware;Random number generation;Software testing;Stress;System testing;Time factors;Time measurement;Web services;data access;software;stress testing;web services}, 
doi={10.1109/ICCEA.2010.72}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{6569717, 
author={G. Canfora and F. Mercaldo and C. A. Visaggio and M. DAngelo and A. Furno and C. Manganelli}, 
booktitle={2013 IEEE Sixth International Conference on Software Testing, Verification and Validation}, 
title={A Case Study of Automating User Experience-Oriented Performance Testing on Smartphones}, 
year={2013}, 
volume={}, 
number={}, 
pages={66-69}, 
abstract={We have developed a platform named Advanced Test Environment (ATE) for supporting the design and the automatic execution of UX tests for applications running on Android smartphones. The platform collects objective metrics used to estimate the UX. In this paper, we investigate the extent that the metrics captured by ATE are able to approximate the results that are obtained from UX testing with real human users. Our findings suggest that ATE produces UX estimations that are comparable to those reported by human users. We have also compared ATE with three widespread benchmark tools that are commonly used in the industry, and the results show that ATE outperforms these tools.}, 
keywords={Linux;automatic testing;program testing;smart phones;software performance evaluation;ATE;Android smartphones;UX estimations;UX test design;UX testing;advanced test environment;automatic UX test execution;objective metrics;user experience-oriented performance testing automation;Conferences;Software testing;android;mobile applications;smartphone;software testing;usability;user experience}, 
doi={10.1109/ICST.2013.16}, 
ISSN={2159-4848}, 
month={March},}
@INPROCEEDINGS{315756, 
author={D. Grossman and C. J. Staton and B. Bailey and M. C. McCabe and A. Latts and O. Frieder and C. Bock and D. Roberts}, 
booktitle={Proceedings of 3rd Symposium on Assessments of Quality Software Development Tools}, 
title={A prototype-driven approach to application-level performance testing: a case study of a large finance application}, 
year={1994}, 
volume={}, 
number={}, 
pages={125-135}, 
abstract={We present an approach to application-level performance testing. This uses a popular test tool, TPNS (Teleprocessing Network Simulator) to simulate performance of an application. Our approach hinges upon a simple prototype to verify that the system performance falls within acceptable bounds. Once the initial prototype is developed, detailed tuning may take place. We present a case study in which we tested the performance of a large finance application. This approach led to critical performance tuning improvement. Due to this improvement, the average user response time in our simulations was reduced from 30 seconds to under 1.5 seconds. This simulation has been verified by actual system usage during the first two months of live operation in which the average response time has indeed been under 1.5 seconds}, 
keywords={accounts data processing;performance evaluation;program testing;software prototyping;TPNS;Teleprocessing Network Simulator;application-level performance testing;large finance application;prototype-driven approach;system performance;test tool;user response time;Computer aided software engineering;Computer bugs;Database systems;Finance;Financial management;Information technology;Operating systems;Prototypes;System testing;Technology management}, 
doi={10.1109/AQSDT.1994.315756}, 
ISSN={}, 
month={Jun},}
@INPROCEEDINGS{552874, 
author={D. E. Schinstock and T. A. Haskew}, 
booktitle={IECEC 96. Proceedings of the 31st Intersociety Energy Conversion Engineering Conference}, 
title={Dynamic load testing of roller screw EMAs}, 
year={1996}, 
volume={1}, 
number={}, 
pages={221-226 vol.1}, 
abstract={In the electromechanical actuators (EMA) laboratory at The University of Alabama, USA, a dynamic load test stand has been designed and built. This test stand uses large load, high bandwidth and hydraulic actuation to generate load profiles under force control. The test stand can accommodate EMAs up to six feet in length. It can generate dynamic loads of up to 100,000 lb at fundamental frequencies of up to 12 Hz against a stiff environment. This test stand has been used to generate severe loading conditions on a large roller screw in an attempt to qualify the effects of large, high frequency loads on roller screw. During the tests performed in the EMA laboratory the screw was fixed at one end and axial loads were applied to the roller nut at the other. Since the end opposite the nut was fixed, only a small amount of relative rotation between the nut and screw was achieved. This rotation was the result of elastic deformation (wind up) of the screw along the length between the fixed end and the nut. This simulates a severe, but likely, application of the roller screw. The results of the tests performed demonstrate that roller screws may be damaged by dynamic loading with load magnitudes that are well within the static load rating of the screw. While the damage that was observed is not catastrophic, it would be expected to substantially decrease the life of the screw}, 
keywords={electric actuators;machine testing;mechanical testing;test equipment;test facilities;12 Hz;USA;dynamic load test stand;dynamic load testing;dynamic loading;elastic deformation;electromechanical actuators;roller screw actuators;static load rating;test laboratory;Bandwidth;Electric shock;Fasteners;Force control;Frequency;Hydraulic actuators;Laboratories;Lubrication;Performance evaluation;Testing}, 
doi={10.1109/IECEC.1996.552874}, 
ISSN={1089-3547}, 
month={Aug},}
@INPROCEEDINGS{4658079, 
author={Z. M. Jiang and A. E. Hassan and G. Hamann and P. Flora}, 
booktitle={2008 IEEE International Conference on Software Maintenance}, 
title={Automatic identification of load testing problems}, 
year={2008}, 
volume={}, 
number={}, 
pages={307-316}, 
abstract={Many software applications must provide services to hundreds or thousands of users concurrently. These applications must be load tested to ensure that they can function correctly under high load. Problems in load testing are due to problems in the load environment, the load generators, and the application under test. It is important to identify and address these problems to ensure that load testing results are correct and these problems are resolved. It is difficult to detect problems in a load test due to the large amount of data which must be examined. Current industrial practice mainly involves time-consuming manual checks which, for example, grep the logs of the application for error messages. In this paper, we present an approach which mines the execution logs of an application to uncover the dominant behavior (i.e., execution sequences) for the application and flags anomalies (i.e., deviations) from the dominant behavior. Using a case study of two open source and two large enterprise software applications, we show that our approach can automatically identify problems in a load test. Our approach flags < 0.01% of the log lines for closer analysis by domain experts. The flagged lines indicate load testing problems with a relatively small number of false alarms. Our approach scales well for large applications and is currently used daily in practice.}, 
keywords={program testing;public domain software;software engineering;automatic identification;enterprise software;load testing;open source software;Catalogs;Computer bugs;Databases;Generators;Monitoring;Software;Testing}, 
doi={10.1109/ICSM.2008.4658079}, 
ISSN={1063-6773}, 
month={Sept},}
@INPROCEEDINGS{8278490, 
author={N. Ibhar and W. Flores and R. León}, 
booktitle={2017 IEEE 37th Central America and Panama Convention (CONCAPAN XXXVII)}, 
title={Design of a low-cost teleoperated robotic arm: Assembly and performance testing}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={At present, robots are widely used in various tasks, whether for industrial or even domestic uses. Thus, for certain tasks it has become necessary to operate the robot in an intuitive and safe way. The vast majority of current robotic hands do not completely replace the functionality of a hand and can not be used in environments which are designed for the use of a human hand. Thus, this document shows the design of a hybrid system with robotic hand and prosthesis applications. The design of a biomechanically controlled, functional and anthropomorphic robotic arm is shown, which demonstrates that it is feasible to design a real-time, low-cost, robotic arm.}, 
keywords={biomechanics;human-robot interaction;manipulator dynamics;prosthetics;robot dynamics;telerobotics;anthropomorphic robotic arm;biomechanically controlled arm;domestic uses;functional arm;human hand;hybrid system design;industrial uses;low-cost teleoperated robotic arm;performance testing;prosthesis;robotic hand;robotic hands;robots;Manipulators;Service robots;Silicon compounds;Task analysis;Testing;Torque;Human-robot interaction;Humanoid robots;Robot control;Telerobotics}, 
doi={10.1109/CONCAPAN.2017.8278490}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{4340515, 
author={l. liu and w. wei and j. li}, 
booktitle={2007 International Conference on Wireless Communications, Networking and Mobile Computing}, 
title={Wireless Communication System Automation Testing Framework}, 
year={2007}, 
volume={}, 
number={}, 
pages={2981-2984}, 
abstract={This article intends to introduce a leading next generation wireless protocol oriented automation testing framework - WiCAT system. This framework supports multiple protocol messaging testing by simulating the wireless equipments and implementing the telecommunication system logic. WiCAT provides high-efficiency and low-cost performance basing on a distributed, expandable and extensible architecture.}, 
keywords={automatic test software;electronic messaging;mobile radio;protocols;telecommunication computing;telecommunication equipment testing;WiCAT system;multiple protocol messaging testing;next generation wireless protocol;telecommunication system logic;wireless communication system automation testing;Automatic testing;Automation;Computer architecture;Graphical user interfaces;Local area networks;System testing;User interfaces;Utility programs;Wireless application protocol;Wireless communication}, 
doi={10.1109/WICOM.2007.740}, 
ISSN={2161-9646}, 
month={Sept},}
@INPROCEEDINGS{5658927, 
author={N. Nie and J. Guo and J. Fu and Z. Feng}, 
booktitle={2010 2nd International Workshop on Database Technology and Applications}, 
title={Reliability and Performance Testing Model of Web-Based User Login and Access Control}, 
year={2010}, 
volume={}, 
number={}, 
pages={1-4}, 
abstract={In order to test the performance, reliability and security of Web-based system, the paper generates the test scripts template and establishes testing model of system login and access control. Then some Web-based systems are tested by automation test tools. The performance, reliability and security problems of Web login process can be traced and diagnosed. The test result shows that Web-based system can be verified and improved by the test script template of multi-users secure login and resources access control.}, 
keywords={Internet;authorisation;computer network security;performance evaluation;Web based user login;access control;multiuser secure login;performance testing model;reliability testing model;test script template;Access control;Correlation;Driver circuits;Software reliability;Testing}, 
doi={10.1109/DBTA.2010.5658927}, 
ISSN={2167-1923}, 
month={Nov},}
@INPROCEEDINGS{6949287, 
author={R. Angmo and M. Sharma}, 
booktitle={2014 5th International Conference - Confluence The Next Generation Information Technology Summit (Confluence)}, 
title={Performance evaluation of web based automation testing tools}, 
year={2014}, 
volume={}, 
number={}, 
pages={731-735}, 
abstract={In today's 21st century era countless software applications are written as a web based application which runs in a web browsers. With new technologies and commercialization of I.T. sector, the web based system has undergoes frequent and rapid changes. Today Softwares are coded as a web based application, which help to access data from any part of the globe. Even the economic relevance of web based enhances the control and quality of software. The quality assurance of any system depends on its test. But to do manually testing in most of the cases is time consuming, expensive and hectic. For the better business purpose and to save time and money automation testing is required. There are variety of tools are available in the market for this. One of the best known tool is selenium suite which is a combination of different automation testing tool. In this paper we will discuss about the selenium suite. It provides testers with different framework for different test cases. The main objective of this paper is to find the best tool in selenium suite and then compare it with some other tool for same task. For this purpose, performance evaluation is done on the basis of some criteria.}, 
keywords={Internet;program testing;software performance evaluation;software quality;software tools;Web based application;Web based automation testing tools;Web browsers;performance evaluation;selenium suite;software applications;software quality;Automation;Browsers;Information technology;Performance evaluation;Software;Software testing;Automation testing;Performance;Selenium;Test case;Watir-webdriver;Web applications}, 
doi={10.1109/CONFLUENCE.2014.6949287}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{7883617, 
author={H. Kapoh and E. S. Lumunon and N. A. E. Sajangbati}, 
booktitle={2016 International Conference on Knowledge Creation and Intelligent Computing (KCIC)}, 
title={Design model material requirement of coconut flour production and performance testing based multi user in North Sulawesi}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-7}, 
abstract={There has been many previous studies that discuss the control for the production of coconut flour and raw material inventory. But a system or a computer-based model for coconut flour industry in North Sulawesi has not or does not exist. For that reason, coconut flour industries also require tools on in running the business as developed in this study. The problem in this research is how to make the design of the model material production requirement of coconut flour-based multi-user to control the production of industrial centers in North Sulawesi coconut flour and how to test the model. The model generated in this study have been through a survey in the industrial district of coconut flour to get the data that will be used analysis, so that a complete picture processing system coconut flour and can describe the problem also the solution clearly in order to get the system needs a model along the test by using a test black box the program and the respondents used for the performance test in order to know the program's ability to interact with users. The collected data is then analyzed and designed using some design method that is data flow diagrams, use case diagram, entity relationship diagrams and material requirements planning methods. Results of the test will indicate that all functions on the system works well and test the respondent for 30 and 60 minutes resulting in a 60% and 63% of respondents were taken as many as 30 answered easily using the model application.}, 
keywords={design engineering;food processing industry;materials requirements planning;production engineering computing;raw materials inventory;North Sulawesi;coconut flour industry;coconut flour production;computer-based model;data flow diagrams;design model material requirement;entity relationship diagrams;industrial centers;material requirements planning methods;model material production requirement;performance testing based multiuser;picture processing system;raw material inventory;use case diagram;Companies;Computational modeling;Industries;Planning;Production;Raw materials;Testing;coconut flour;design;model;multi-user;production;testing}, 
doi={10.1109/KCIC.2016.7883617}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{5454995, 
author={Y. Pu and M. Xu}, 
booktitle={2009 First International Conference on Information Science and Engineering}, 
title={Load Testing for Web Applications}, 
year={2009}, 
volume={}, 
number={}, 
pages={2954-2957}, 
abstract={The performance testing criteria was analyzed, including response time, concurrency users, throughout and performance counter. Performance testing is necessary for the system reliability. Load testing can be used for software troubleshooting and optimizing. With the LoadRunner and TestDirector testing tools, a load testing scheme based on an online examination system was designed.}, 
keywords={Internet;program testing;software performance evaluation;LoadRunner testing tools;TestDirector testing tools;Web application;concurrency users;load testing;online examination system;performance counter;performance testing criteria;response time;software troubleshooting;system reliability;Application software;Automatic testing;Computer bugs;Concurrent computing;Delay;Reliability engineering;Software performance;Software testing;System performance;System testing}, 
doi={10.1109/ICISE.2009.720}, 
ISSN={2160-1283}, 
month={Dec},}
@INPROCEEDINGS{5458557, 
author={Q. Wu and Y. Wang}, 
booktitle={2010 Second International Workshop on Education Technology and Computer Science}, 
title={Performance Testing and Optimization of J2EE-Based Web Applications}, 
year={2010}, 
volume={2}, 
number={}, 
pages={681-683}, 
abstract={J2EE-based Web applications are becoming increasingly ubiquitous and with their increasing adoption, the performance is the attention focus and the most important factor of evaluating the system by users. In this paper, we present a systematic solution for performance testing and optimization of J2EE-based Web applications. The solution helps to identify and eliminate bottlenecks in the application design and ensures that systems are designed to meet their quality of service requirements. This paper firstly analyses the architecture of J2EE-based Web applications and performance testing principle, and then improves the JMeter testing framework for meeting the more concurrent users. Lastly, performance testing for J2EE-based Web applications is done; it finds performance bottlenecks and puts forward optimum measures, and compares the performance with the former one.}, 
keywords={Internet;Java;program testing;software performance evaluation;J2EE-based Web applications optimization;JMeter testing framework;concurrent users;performance testing;quality of service requirements;systematic solution;Application software;Business;Delay;Educational institutions;Nonhomogeneous media;Performance analysis;Scalability;Service oriented architecture;System performance;System testing;JMeter;Web applications;distributed;optimization;performance}, 
doi={10.1109/ETCS.2010.583}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{5272178, 
author={O. Hamed and N. Kafri}, 
booktitle={2009 First International Conference on Networked Digital Technologies}, 
title={Performance testing for web based application architectures (.NET vs. Java EE)}, 
year={2009}, 
volume={}, 
number={}, 
pages={218-224}, 
abstract={Having an efficient web application is a challenge that we need to achieve when architecting web applications in the development process. This research follows a performance modeling approach that aims to utilize load testing tools to give ideas about performance issues early in the development life cycle for applications implemented using Java Enterprise Edition (Java EE) or .NET platform. Thus, it helps system architects to choose between competitive frameworks. To achieve this, the applications are subjected to artificial workload. Direct measurements are obtained on the specified application scenarios using different tools. Parasoft WebKing and Hewlett-Packard LoadRunner were used for this purpose. Later on, the obtained results indicate that, Java EE performs better than .NET. by means of response time and memory utilization.}, 
keywords={Java;program testing;software architecture;software performance evaluation;Hewlett-Packard LoadRunner;Java Enterprise Edition;Parasoft WebKing;Web based application architectures;artificial workload;development life cycle;load testing tools;performance testing;Analytical models;Application software;Automatic testing;Computational modeling;Delay;Java;Performance analysis;Scalability;Service oriented architecture;System testing}, 
doi={10.1109/NDT.2009.5272178}, 
ISSN={2155-8728}, 
month={July},}
@INBOOK{5444092, 
author={Gail D. Baura}, 
booktitle={System Theory and Practical Applications of Biomedical Signals}, 
title={Pharmacologic Stress Testing Using Closed-Loop Drug Delivery}, 
year={2002}, 
volume={}, 
number={}, 
pages={0-}, 
abstract={
This chapter contains sections titled:

Pharmacokinetics and Pharmacodynamics

Control Theory

Problem Significance

Closed-Loop Drug Infusion in Pharmacological Stress Tests

Summary

References

Peripheral Insulin Kinetics Exercises

}, 
keywords={Absorption;Biomedical monitoring;Blood flow;Drug delivery}, 
doi={10.1109/9780471683179.ch14}, 
ISSN={}, 
publisher={Wiley-IEEE Press}, 
isbn={9780471683179}, 
url={https://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5444092},}
@INPROCEEDINGS{4209887, 
author={B. Kruseman and A. Majhi and G. Gronthoud}, 
booktitle={25th IEEE VLSI Test Symposium (VTS'07)}, 
title={On Performance Testing with Path Delay Patterns}, 
year={2007}, 
volume={}, 
number={}, 
pages={29-34}, 
abstract={Application specific ICs are typically designed to meet a given performance specification. For these ICs a higher performance does not add value and less performance makes the IC useless. This class of ICs is designed based on worst-case corner analysis. It is expected that this will become area costly in more advanced technologies. An alternative is to use statistical design techniques but this implies that the performance needs to be tested with, for example, path delay testing. Our experiments in 65 nm show that the actual delay depends on the global activity within an IC as well as effects in the local neighbourhood of the path. These global and local effects can independently cause about 15% of additional delay. Hence, their impact needs to be included during test and thr authors propose to create (close to) worst-case delay patterns. Individually, the patterns have an enhanced sensitivity for the most important local effects and combined they provide coverage for global effects. This makes them better suited as speed indicators than conventional path delay patterns.}, 
keywords={application specific integrated circuits;delays;integrated circuit testing;65 nm;application specific integrated circuits;path delay testing;performance testing;worst-case corner analysis;Added delay;Consumer electronics;Costs;Delay effects;Electronic equipment testing;Frequency;Libraries;Performance analysis;Ring oscillators;Test pattern generators}, 
doi={10.1109/VTS.2007.45}, 
ISSN={1093-0167}, 
month={May},}
@ARTICLE{7740990, 
author={S. Omidshafiei and A. A. Agha-Mohammadi and Y. F. Chen and N. K. Ure and S. Y. Liu and B. T. Lopez and R. Surati and J. P. How and J. Vian}, 
journal={IEEE Control Systems}, 
title={Measurable Augmented Reality for Prototyping Cyberphysical Systems: A Robotics Platform to Aid the Hardware Prototyping and Performance Testing of Algorithms}, 
year={2016}, 
volume={36}, 
number={6}, 
pages={65-87}, 
abstract={Planning, control, perception, and learning are current research challenges in multirobot systems. The transition dynamics of the robots may be unknown or stochastic, making it difficult to select the best action each robot must take at a given time. The observation model, a function of the robots' sensor systems, may be noisy or partial, meaning that deterministic knowledge of the team's state is often impossible to attain. Moreover, the actions each robot can take may have an associated success rate and/or a probabilistic completion time. Robots designed for real-world applications require careful consideration of such sources of uncertainty, regardless of the control scheme or planning or learning algorithms used for a specific problem. Understanding the underlying mechanisms of planning algorithms can be challenging due to the latent variables they often operate on. When performance testing such algorithms on hardware, the simultaneous use of the debugging and visualization tools available on a workstation can be difficult. This transition from experimentation to implementation becomes especially challenging when the experiments need to replicate some feature of the software tool set in hardware, such as simulation of visually complex environments. This article details a robotics prototyping platform, called measurable augmented reality for prototyping cyberphysical systems (MAR-CPS), that directly addresses this problem, allowing for the real-time visualization of latent state information to aid hardware prototyping and performance testing of algorithms.}, 
keywords={augmented reality;control engineering computing;cyber-physical systems;data visualisation;mobile robots;path planning;robot vision;software prototyping;software tools;MAR-CPS;hardware prototyping;latent state information;measurable augmented reality for prototyping cyberphysical systems;performance testing;planning algorithm;real-time visualization;robot sensor system;robotic platform;software tool set;Algorithm design and analysis;Augmented reality;Central Processing Unit;Cyber-physical systems;Planning;Robot sensing systems;Robots}, 
doi={10.1109/MCS.2016.2602090}, 
ISSN={1066-033X}, 
month={Dec},}
@INPROCEEDINGS{1368035, 
author={K. Gold and A. Brown}, 
booktitle={2004 IEEE Aerospace Conference Proceedings (IEEE Cat. No.04TH8720)}, 
title={Architecture and performance testing of a software GPS receiver for space-based applications}, 
year={2004}, 
volume={4}, 
number={}, 
pages={2404-2416 Vol.4}, 
abstract={Space-based GPS technology presents significant challenges over Earth-based systems. These include visibility issues for rotating platforms and tracking of GPS satellites from spacecraft that are in higher orbits than the GPS, realtime resolution of carrier phase ambiguities, and different dynamics during various mission phases. NAVSYS has developed a software GPS receiver that makes use of 3-dimensional digital beam steering technology and inertial aiding to address these issues. This approach offers several advantages including all round visibility for spinning satellites, tracking of weak GPS signals, reduction of multipath, and reprogrammability to accommodate different mission phases. Additionally, a suite of simulation tools based on the NAVSYS Matlab Toolbox and Advanced GPS Hybrid simulation products have been built to allow testing for simulated space environments. The receiver architecture and test tools are described in this paper.}, 
keywords={Global Positioning System;aerospace computing;artificial satellites;beam steering;hybrid simulation;radio receivers;real-time systems;satellite tracking;software radio;telecommunication equipment testing;3-dimensional digital beam steering technology;Earth based systems;GPS hybrid simulation products;GPS satellite tracking;GPS signal tracking;Matlab toolbox;NAVSYS;carrier phase ambiguity;multipath reduction;realtime resolution;receiver architecture;rotating platforms;simulated space environment;software GPS receiver;space based applications;spinning satellites;Application software;Beam steering;Computer architecture;Global Positioning System;Orbits;Satellites;Software performance;Software testing;Space technology;Space vehicles}, 
doi={10.1109/AERO.2004.1368035}, 
ISSN={1095-323X}, 
month={March},}
@ARTICLE{5977130, 
author={M. Kalita and T. Bezboruah}, 
journal={IET Software}, 
title={Investigation on performance testing and evaluation of PReWebD: a .NET technique for implementing web application}, 
year={2011}, 
volume={5}, 
number={4}, 
pages={357-365}, 
abstract={A prototype research web application based on Visual Studio platform is developed with .NET as framework, Internet Information Server (IIS) (Version: 5.1) as web server and Microsoft Standard Query Language (SQL) Server (Version: 2005) as database server to study the performance and evaluation of the .NET technique used for developing the web application. The authors call it the PReWebD. As the performance is one of the most important features of a web application, to evaluate the performance, testing of PReWebD has been carried out using Mercury LoadRunner (Version 8.0) for validation and to study some other attributes like scalability, reliability etc. The performance depends on parameters such as hits/s, response time, throughput, errors/s etc. These parameters for PReWebD are tested with different stress levels. The statistical testing and analysis is done to assure the stability, reliability and quality of the application. Here the authors report in details the architecture, testing procedure, result of performance testing as well as the results of statistical analysis on recorded data of PReWebD.}, 
keywords={Internet;SQL;network operating systems;program testing;software architecture;software performance evaluation;statistical testing;.NET technique;Internet Information Server;Mercury LoadRunner;Microsoft Standard Query Language;PReWebD;SQL server;Visual Studio platform;Web application;Web server;architecture;database server;performance evaluation;performance testing;statistical analysis;statistical testing;stress level}, 
doi={10.1049/iet-sen.2010.0139}, 
ISSN={1751-8806}, 
month={August},}
@INPROCEEDINGS{8016201, 
author={D. Heukelman}, 
booktitle={2017 1st International Conference on Next Generation Computing Applications (NextComp)}, 
title={Measuring e-readiness: A case study: Self-assessment vs performance testing}, 
year={2017}, 
volume={}, 
number={}, 
pages={215-219}, 
abstract={Measuring the impact of an ICT-skills intervention can be done in different ways. Typically, one would measure before an intervention and again after the intervention. In this paper the use of self-assessment questionnaires, as opposed to performance testing, is investigated and reported on. A self-assessment questionnaire was administered to 345 first year students entering Higher Education for the first time. Students were assessed before commencing the program: 25 questions, requiring participants to assess their own level of skill, to determine their e-readiness. A subgroup of 55 of these students were subsequently given 3 tasks to perform in a computer laboratory, to assess their e-readiness skills level. The efficiency, accuracy and reliability of the two methods were compared. It was concluded that, based on the efficiency, accuracy and depth of knowledge gained, self-assessment is a valuable tool.}, 
keywords={computer literacy;further education;ICT-skills intervention;computer laboratory;e-readiness measurement;e-readiness skills level;higher education;performance testing;self-assessment questionnaire;Atmospheric measurements;Economics;Extraterrestrial measurements;Instruments;Particle measurements;Reliability;Testing;ICT;Skills Measurement;e-Readiness}, 
doi={10.1109/NEXTCOMP.2017.8016201}, 
ISSN={}, 
month={July},}
@ARTICLE{4302730, 
author={S. Pakin}, 
journal={IEEE Transactions on Parallel and Distributed Systems}, 
title={The Design and Implementation of a Domain-Specific Language for Network Performance Testing}, 
year={2007}, 
volume={18}, 
number={10}, 
pages={1436-1449}, 
abstract={CONCEPTUAL is a toolset designed specifically to help measure the performance of high-speed interconnection networks such as those used in workstation clusters and parallel computers. It centers around a high-level domain-specific language, which makes it easy for a programmer to express, measure, and report the performance of complex communication patterns. The primary challenge in implementing a compiler for such a language is that the generated code must be extremely efficient so as not to misattribute overhead costs to the messaging library. At the same time, the language itself must not sacrifice expressiveness for compiler efficiency, or there would be little point in using a high-level language for performance testing. This paper describes the CONCEPTUAL language and the CONCEPTUAL compiler's novel code-generation framework. The language provides primitives for a wide variety of idioms needed for performance testing and emphasizes a readable syntax. The core code-generation technique, based on unrolling CONCEPTUAL programs into sequences of communication events, is simple yet enables the efficient implementation of a variety of high-level constructs. The paper further explains how CONCEPTUAL implements time-bounded loops - even those that comprise blocking communication - in the absence of a time-out mechanism as this is a somewhat unique language/implementation feature.}, 
keywords={computational linguistics;high level languages;message passing;program compilers;program control structures;program testing;software performance evaluation;specification languages;CONCEPTUAL language;blocking communication;code generation;domain-specific language;high-level language;high-speed interconnection networks;messaging library;network performance testing;parallel computers;program compiler;readable syntax;time-bounded loops;time-out mechanism;workstation clusters;Computer networks;Concurrent computing;Costs;Domain specific languages;High performance computing;Libraries;Multiprocessor interconnection networks;Programming profession;Testing;Workstations;Interprocessor communications;Measurement techniques;Specialized application languages}, 
doi={10.1109/TPDS.2007.1065}, 
ISSN={1045-9219}, 
month={Oct},}
@INPROCEEDINGS{6008948, 
author={M. A. S. Netto and S. Menon and H. V. Vieira and L. T. Costa and F. M. de Oliveira and R. Saad and A. Zorzo}, 
booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
title={Evaluating Load Generation in Virtualized Environments for Software Performance Testing}, 
year={2011}, 
volume={}, 
number={}, 
pages={993-1000}, 
abstract={Before placing a software system into production, it is necessary to guarantee it provides users with a certain level of Quality-of-Service. Intensive performance testing is then necessary to achieve such a level and the tests require an isolated computing environment. Virtualization can therefore play an important role for saving energy costs by reducing the number of servers required to run performance tests and for allowing performance isolation when executing multiple tests in the same computing infrastructure. Load generation is an important component in performance testing as it simulates users interacting with the target application. This paper presents our experience in using a virtualized environment for load generation aimed at performance testing. We measured several performance metrics and varied system load, number of virtual machines per physical resource, and the CPU pinning schema for comparison of virtual and physical machines. The two main findings from our experiments are that physical machines produced steadier and faster response times under heavy load and that the pinning schema is an important aspect when setting up a virtualized environment for load generation.}, 
keywords={program testing;software metrics;software performance evaluation;virtual machines;virtualisation;isolated computing environment;load generation;performance metrics;quality-of-service;software performance testing;virtual machines;virtualization;virtualized environment;Generators;Measurement;Servers;Testing;Throughput;Time factors;Virtual machining}, 
doi={10.1109/IPDPS.2011.244}, 
ISSN={1530-2075}, 
month={May},}
@INPROCEEDINGS{7819257, 
author={E. Siivola and S. Sierla and H. Niemistö and T. Karhela and V. Vyatkin}, 
booktitle={2016 IEEE 14th International Conference on Industrial Informatics (INDIN)}, 
title={Requirement verification in simulation-based automation testing}, 
year={2016}, 
volume={}, 
number={}, 
pages={740-743}, 
abstract={The emergence of the Industrial Internet results in an increasing number of complicated temporal interdependencies between automation systems and the processes to be controlled. There is a need for verification methods that scale better than formal verification methods and which are more exact than testing. Simulation-based runtime verification is proposed as such a method, and an application of Metric temporal logic is presented as a contribution. The practical scalability of the proposed approach is validated against a production process designed by an industrial partner, resulting in the discovery of requirement violations.}, 
keywords={Internet;automation;digital simulation;formal verification;production engineering computing;temporal logic;testing;formal verification;industrial Internet emergence;metric temporal logic;production process;requirement verification;simulation-based automation testing;simulation-based runtime verification;Automation;Leaching;Metals;Monitoring;Runtime;Slurries;Testing}, 
doi={10.1109/INDIN.2016.7819257}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{8250706, 
author={P. Seth and N. Rane and A. Wagh and A. Katade and S. Sahu and N. Malhotra}, 
booktitle={2017 International Conference on Intelligent Computing and Control Systems (ICICCS)}, 
title={Uberisation of mobile automation testing}, 
year={2017}, 
volume={}, 
number={}, 
pages={181-183}, 
abstract={Mobile phones and mobile applications have now become an essential part of everyday life. To make Mobile applications more reliable and error free, mobile application testing is important. Currently only a few techniques exist for creating automate tests of mobile applications and their functionality is very limited. In this paper, we introduce the new way of implementing a mobile test automation platform which performs mobile test automation from mobile devices itself. The main aim of automating the testing process is to develop a high quality and optimized applications to deliver efficient results to the customer.}, 
keywords={mobile computing;mobile handsets;program testing;Mobile phones;mobile application testing;mobile automation testing;mobile devices;mobile test automation platform;Androids;Automation;Mobile applications;Mobile communication;Mobile handsets;Testing;Tools;Device automation;Mobile app testing;Software Engineering;Software quality;Test Automation;Wireless testing}, 
doi={10.1109/ICCONS.2017.8250706}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{1625700, 
author={Bum Hyun Lim and Jin Ryong Kim and Kwang Hyun Shim}, 
booktitle={2006 8th International Conference Advanced Communication Technology}, 
title={A load testing architecture for networked virtual environment}, 
year={2006}, 
volume={1}, 
number={}, 
pages={5 pp.-848}, 
abstract={In this work, we develop a load testing architecture for networked virtual environment to reduce the testing time and ensure the stability of the server for distributed applications. It explicitly secures the stability of the server for networked virtual environment and at the same time, it elaborately generates actual loads for testing the performance of the server. Our agent based load testing architecture provides variety of interactions of virtual entities in the virtual worlds to perform realistic simulations. Simulation results show that our proposed architecture ensures the stability and capacity of the servers}, 
keywords={client-server systems;resource allocation;distributed applications;load testing architecture;networked virtual environment;server stability;virtual client;Analytical models;Databases;Discrete event simulation;Environmental management;Large-scale systems;Libraries;Network servers;Protocols;Testing;Virtual environment;Load test;beta test;game simulator;networked virtual environment;stress test;virtual client}, 
doi={10.1109/ICACT.2006.206095}, 
ISSN={}, 
month={Feb},}
@INPROCEEDINGS{5552290, 
author={D. Hao and Y. Chen and F. Tang and F. Qi}, 
booktitle={2010 IEEE International Conference on Software Engineering and Service Sciences}, 
title={Distributed agent-based performance testing framework on Web Services}, 
year={2010}, 
volume={}, 
number={}, 
pages={90-94}, 
abstract={Web Services are applied widely in the field of information technology, and performance testing for Web Services applications has become an important problem. This paper introduces the method of performance testing, and proposes a framework of agent-based performance testing on Web Services, which includes TestFlow Generator, Scenario Creator, Test Manager, Load Generation Agent and Test Analyzer. And the implementation of kernel modules in the framework is introduced especially. To realize the load allocation to distributed Load Generation Agents from Test Manager, a queue-based allocation strategy is given.}, 
keywords={Load modeling;Monitoring;Resource management;Schedules;Testing;Web services;Web Services;allocation strategy;load generation;performance testing}, 
doi={10.1109/ICSESS.2010.5552290}, 
ISSN={2327-0586}, 
month={July},}
@ARTICLE{1377198, 
author={A. Avritzer and E. J. Weyuker}, 
journal={IEEE Transactions on Software Engineering}, 
title={The role of modeling in the performance testing of e-commerce applications}, 
year={2004}, 
volume={30}, 
number={12}, 
pages={1072-1083}, 
abstract={An e-commerce scalability case study is presented in which both traditional performance testing and performance modeling were used to help tune the application for high performance. This involved the creation of a system simulation model as well as the development of an approach for test case generation and execution. We describe our experience using a simulation model to help diagnose production system problems, and discuss ways that the effectiveness of performance testing efforts was improved by its use.}, 
keywords={Java;electronic commerce;program testing;resource allocation;software performance evaluation;e-commerce;production system diagnosis;software performance modeling;software performance testing;test case generation;workload characterization;Aerospace testing;Computer architecture;Databases;Helium;Java;Monitoring;Production systems;Scalability;Software testing;System testing}, 
doi={10.1109/TSE.2004.107}, 
ISSN={0098-5589}, 
month={Dec},}
@INPROCEEDINGS{6570626, 
author={A. J. Maâlej and M. Hamza and M. Krichen}, 
booktitle={2013 Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises}, 
title={WSCLT: A Tool for WS-BPEL Compositions Load Testing}, 
year={2013}, 
volume={}, 
number={}, 
pages={272-277}, 
abstract={This paper addresses the load testing of WS-BPEL compositions. For that, we developed WSCLT tool, which takes as input a specification of the composition under test, expressed as a Timed Automaton, and considers various parameters such as the number of requests to handle simultaneously. Our WSCLT tool injects this load in the application and monitors the sequence of requests, invocations and responses between the components. This log is then analyzed by the tool to separate the actions corresponding to each instance and to check that they follow legitimate paths. A global report is then issued regarding all concurrent instances. We illustrate how to use our prototype tool by means of a case study.}, 
keywords={Web services;automata theory;program testing;WS-BPEL compositions;WSCLT;load testing;timed automaton;Atmospheric modeling;Automata;Delays;Load modeling;Queueing analysis;Testing;Web services;Timed Automaton;WS-BPEL compositions;load testing;log analysis}, 
doi={10.1109/WETICE.2013.71}, 
ISSN={1524-4547}, 
month={June},}
@INPROCEEDINGS{6317675, 
author={C. Williamette and E. Hansen}, 
booktitle={2012 38th IEEE Photovoltaic Specialists Conference}, 
title={Development of electrical performance testing standards for the acceptance of solar photovoltaic projects based on field experience and observation}, 
year={2012}, 
volume={}, 
number={}, 
pages={000554-000559}, 
abstract={As-built performance requirements are becoming more common in Interconnection Applications (IAs) and Power Purchase Agreements (PPAs). Often overlooked as, “just the last step in the commissioning process,” it is important to understand the scope of the testing requirements before committing to the agreement. The worst case scenario is when your project has design flaws that prevent it from meeting requirements. By the time the system is discovered to be failing, it can be too late and too costly to fix. Understanding standards for performance testing can help guide project design to ensure better success meeting those requirements later on.}, 
keywords={commissioning;interconnections;photovoltaic power systems;solar power stations;standards;PPA;commissioning process;electrical performance testing standards;field experience;interconnection applications;power purchase agreements;solar PV systems;solar photovoltaic projects;Indexes;Inverters;Irrigation;Monitoring;Soil;Wiring;Current-voltage characteristics;Performance Analysis;Soil measurements;Solar energy;System analysis and design;Thermal analysis}, 
doi={10.1109/PVSC.2012.6317675}, 
ISSN={0160-8371}, 
month={June},}
@INPROCEEDINGS{5405721, 
author={G. h. Kim and H. c. Moon and G. P. Song and S. K. Shin}, 
booktitle={Proceedings of the 4th International Conference on Ubiquitous Information Technologies Applications}, 
title={Software Performance Testing Scheme Using Virtualization Technology}, 
year={2009}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={In this paper, we propose software performance testing scheme using virtualization technology. Generally, people have used software performance testing tool such as load runner and silk performer. However, people should perform software performance testing manually in case of the situation that people cannot use testing tool. It needs a lot of resources such as human resource and computing resource. Therefore, we propose software performance testing scheme using virtualization technology to reduce resource consumption. Proposed scheme can reduce computer resource consumption because virtualization technology can make a number of virtual computers with a small number of physical computers. Also proposed scheme can reduce human resource consumption because, in proposed scheme, management computer can control keyboard and mouse of virtual computers automatically. Simulation result shows that proposed scheme has possibility to be used for software performance testing.}, 
keywords={software performance evaluation;virtual machines;computer management;computing resource;human resource;software performance testing;virtual computers;virtualization technology;Automatic control;Computational modeling;Human resource management;Keyboards;Mice;Performance evaluation;Physics computing;Resource virtualization;Software performance;Software testing}, 
doi={10.1109/ICUT.2009.5405721}, 
ISSN={1976-0035}, 
month={Dec},}
@ARTICLE{4015510, 
author={D. Krishnamurthy and J. A. Rolia and S. Majumdar}, 
journal={IEEE Transactions on Software Engineering}, 
title={A Synthetic Workload Generation Technique for Stress Testing Session-Based Systems}, 
year={2006}, 
volume={32}, 
number={11}, 
pages={868-882}, 
abstract={Enterprise applications are often business critical but lack effective synthetic workload generation techniques to evaluate performance. These workloads are characterized by sessions of interdependent requests that often cause and exploit dynamically generated responses. Interrequest dependencies must be reflected in synthetic workloads for these systems to exercise application functions correctly. This poses significant challenges for automating the construction of representative synthetic workloads and manipulating workload characteristics for sensitivity analyses. This paper presents a technique to overcome these problems. Given request logs for a system under study, the technique automatically creates a synthetic workload that has specified characteristics and maintains the correct interrequest dependencies. The technique is demonstrated through a case study involving a TPC-W e-commerce system. Results show that incorrect performance results can be obtained by neglecting interrequest dependencies, thereby highlighting the value of our technique. The study also exploits our technique to investigate the impact of several workload characteristics on system performance. Results establish that high variability in the distributions of session length, session idle times, and request service times can cause increased contention among sessions, leading to poor system responsiveness. To the best of our knowledge, these are the first results of this kind for a session-based system. We believe our technique is of value for studies where fine control over workload is essential}, 
keywords={electronic commerce;performance evaluation;program testing;TPC-W e-commerce system;e-commerce system;enterprise application;performance evaluation;sensitivity analyses;stress testing session-based system;synthetic workload generation technique;Application software;Character generation;Computer Society;Delay;Occupational stress;Sensitivity analysis;Stress control;System performance;System testing;Web server;Internet applications;Performance of systems;Web servers.;electronic commerce;measurement techniques;modeling techniques;software engineering;testing tools}, 
doi={10.1109/TSE.2006.106}, 
ISSN={0098-5589}, 
month={Nov},}
@INPROCEEDINGS{7397245, 
author={A. Ali and N. Badr}, 
booktitle={2015 IEEE Seventh International Conference on Intelligent Computing and Information Systems (ICICIS)}, 
title={Performance testing as a service for web applications}, 
year={2015}, 
volume={}, 
number={}, 
pages={356-361}, 
abstract={Software testing is a vital activity that is undertaken during software engineering life cycle to ensure software quality and reliability. Performance testing is a type of software testing that is done to shows how web application behaves under a certain workload. Cloud computing as an emerging technology can be used in the field of software engineering to provide cloud testing in order to overcome all deficiencies of conventional testing by leveraging cloud computing resources. As a result, testing-as-a-service (TaaS) is introduced as a service model that performs all testing activities in fully automated manner, on demand with a pay-for use basis. Moreover, TaaS increases testing efficiency and reduces time and cost required for testing. In this paper, performance TaaS framework for web applications is introduced which provides all performance testing activities including automatic test case generation and test execution. In addition, the proposed framework addresses many issues as: maximize resource utilization and continuous monitoring to ensure system reliability.}, 
keywords={Web services;program testing;software performance evaluation;software quality;Web applications;automatic test case generation;cloud computing resources;cloud testing;continuous monitoring;performance testing;software engineering life cycle;software quality;software reliability;software testing;system reliability;testing-as-a-service;Fault tolerance;Fault tolerant systems;Software;Testing;Virtualization;Cloud Computing;JMeter;Performance Testing;TaaS;web Application Testing}, 
doi={10.1109/IntelCIS.2015.7397245}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{5729579, 
author={R. W. Y. Habash and V. Groza and Y. Yang and C. Blouin and P. Guillemette}, 
booktitle={2011 Sixth IEEE International Symposium on Electronic Design, Test and Application}, 
title={Performance Testing and Control of a Small Wind Energy Converter}, 
year={2011}, 
volume={}, 
number={}, 
pages={263-268}, 
abstract={Responding to more demand in coming years, the task of the small wind energy industry requires progress on several fronts-from public policy initiatives, to technology development, to market growth. Enhanced technologies such as contra-rotating blades, transmission systems, lubrication, airfoils, generators, and power electronics will lower cost and increase energy production. This paper mainly considers two key technological points of a small wind energy converter (SWEC) namely, the performance of the rotor system and induction generator. Small-scale prototypes have been built to experimentally verify the performance of the SWEC. Wind tunnel tests of the power output, power coefficient, and turbine speed were carried out to ascertain the aerodynamic power conversion and the operation capability at lower wind speeds. The results demonstrated a significant increase in performance compared to a single-rotor system of the same type. Another aspect of development and test is to present a comparative performance evaluation between a standard induction generator and an efficient but with modified design (TRIAS Generator) as a realistic solution of clean power for grid-connected SWECs. The paper also discusses issues related to control and monitoring of SWEC.}, 
keywords={aerodynamics;asynchronous generators;power convertors;power generation control;power grids;power markets;rotors;wind power plants;wind tunnels;wind turbines;aerodynamic power conversion;grid connected SWEC;induction generator;market growth;performance testing;public policy;rotor system;small scale prototype;small wind energy converter control;technology development;wind energy industry;wind tunnel;Blades;Generators;Induction motors;Rotors;Wind energy;Wind speed;Wind turbines;Small wind generator;contra-rotating system;induction generator}, 
doi={10.1109/DELTA.2011.55}, 
ISSN={}, 
month={Jan},}
@ARTICLE{536458, 
author={D. Grossman and M. C. McCabe and C. Staton and B. Bailey and O. Frieder and D. C. Roberts}, 
journal={IEEE Software}, 
title={Performance testing a large finance application}, 
year={1996}, 
volume={13}, 
number={5}, 
pages={50-54}, 
abstract={The case study presented in the paper shows how a simple prototype can be used to verify, before production, that a system will perform at an acceptable level under realistic conditions. The study involves the first implementation of American Management System's Federal Financial System (FFS), a financial accounting application, in a customer information control system (CICS) DB2 environment running on a large IBM mainframe}, 
keywords={accounts data processing;financial data processing;program testing;program verification;relational databases;software performance evaluation;American Management System;DB2 environment;Federal Financial System;IBM mainframe;case study;customer information control system;financial accounting application;large finance application;performance testing;program verification;relational database;simple prototype;Control systems;Database systems;Delay;Environmental management;Finance;Financial management;Information technology;Operating systems;Performance evaluation;Production systems;Prototypes;Stress;System testing;Technology management;Testing}, 
doi={10.1109/52.536458}, 
ISSN={0740-7459}, 
month={Sep},}
@INPROCEEDINGS{6131250, 
author={S. Duttagupta and M. Nambiar}, 
booktitle={2011 UKSim 5th European Symposium on Computer Modeling and Simulation}, 
title={Performance Extrapolation for Load Testing Results of Mixture of Applications}, 
year={2011}, 
volume={}, 
number={}, 
pages={424-429}, 
abstract={Load testing of IT applications faces the challenge of providing high quality test results that would represent the performance in production like scenarios, without incurring high cost of commercial load testing tools. It would help IT projects to be able to test with a small number of users and extrapolate to scenarios with much larger number of users. Such an extrapolation strategy when applied to mixture of application workloads running on a shared server environment must take into consideration application characteristics (CPU/IO intensive, memory bound) as well the server capabilities. The goal is to predict the performance of mixture workload, the maximum throughput offered by the application mix and the maximum number of users supported by the system before the throughput starts degrading. In this paper, we propose an extrapolation strategy that analyses a system workload mix based on its service demand on various resources and extrapolates its performance using simple empirical modeling techniques. Moreover, its ability to extrapolate throughput of an application mixture even if there is a change in the mixture, can help in capacity planning of the system.}, 
keywords={extrapolation;program testing;IT application;application mixture;empirical modeling technique;extrapolation strategy;information technology;load testing;Extrapolation;Load modeling;Production;Servers;Telecommunications;Testing;Throughput;Extrapolation;S-curve;load Testing;mixture of applications;multi-classes of job}, 
doi={10.1109/EMS.2011.56}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6449887, 
author={M. Singh and R. Singh}, 
booktitle={2012 2nd IEEE International Conference on Parallel, Distributed and Grid Computing}, 
title={Load Testing of web frameworks}, 
year={2012}, 
volume={}, 
number={}, 
pages={592-596}, 
abstract={This document deals with a comparative analysis on the web frame works namely Spring3.0 MVC, Struts 2.0, JSF 1.2x and Wickets. A detailed study is given on the behavior of the frameworks when they are utilized in the front end and at the backend JPA is used to make communication with the database. The Database utilized is Oracle 10g. Load Testing of all the applications is done using J-meter.}, 
keywords={Internet;database management systems;online front-ends;program testing;J-meter;JSF 1.2x;Oracle 10g;Spring3.0 MVC;Struts 2.0;Web frameworks;Wickets;backend JPA;database;front end;load testing;Bandwidth;Color;Information filters;Process control;Springs;Throughput;JSF 1.2x;Spring3.0 MVC;Struts 2.0;Wickets and JPA}, 
doi={10.1109/PDGC.2012.6449887}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6927571, 
author={A. Freitas and R. Vieira}, 
booktitle={2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)}, 
title={An Ontology for Guiding Performance Testing}, 
year={2014}, 
volume={1}, 
number={}, 
pages={400-407}, 
abstract={Software test is a technique to obtain information about software systems quality. Performance test is a type of software test that aims at evaluating software performance at a given load scenario, but it requires specialized knowledge about tools, activities and metrics of the domain. Since ontology is a promising knowledge representation technique, this paper presents a literature review to identify trends and compare researches of ontologies in the fields of software testing and software performance. Also, to investigate this issue from a practical perspective, it was developed an ontology for representing the core knowledge of performance testing. This paper presents the ontology and compare it with related ones. Then, semantic technologies are explored to demonstrate the practical feasibility of developing ontology-based applications for assisting testers with performance test planning and management.}, 
keywords={ontologies (artificial intelligence);program testing;software management;software performance evaluation;software quality;knowledge representation technique;ontology;performance test management;performance test planning;performance testing guidance;semantic technologies;software performance evaluation;software systems quality;software testing;Measurement;OWL;Ontologies;Software performance;Software testing}, 
doi={10.1109/WI-IAT.2014.62}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{8203630, 
author={H. Khandelwal and P. Mankodi and R. Prajapati}, 
booktitle={2017 International conference of Electronics, Communication and Aerospace Technology (ICECA)}, 
title={Enhancement of automation testing system using Yocto project}, 
year={2017}, 
volume={1}, 
number={}, 
pages={697-700}, 
abstract={Nowadays, in industries, Testing has become one of the important tasks. Testing is necessary for an effective performance of product and software applications. When companies having a mass production of hardware boards, it is necessary to do testing of each and every module of hardware like SPI, UART, GPIO, PWM, ADC, USB, Ethernet. If we do testing manually then it will significantly take more time, which we can be reduced by automation testing. But the solution is not an automation testing because automation testing also requires the same amount of system, for example for 300 boards 300 system is required. The only difference in manual and automation testing is that in automation testing it will require less human effort. Now we are focusing more on developing a solution in which many tests can be done on one single system i.e. for 300 boards only one system is required for testing hence this problem can be solved by Yocto Project. Yocto project have build the tool named Bitbake which is written in Python language, which works on multithreading and scheduling so that simultaneously you can test more boards on a single system. In this paper we did automation testing of GPIO pins using Yocto project.}, 
keywords={automatic test software;Bitbake tool;GPIO pins;Python language;Yocto Project;automation testing system;multithreading;scheduling;Automation;Hardware;Licenses;Pins;Software;Testing;Tools;Automation;Bitbake;Open embedded;Yocto project}, 
doi={10.1109/ICECA.2017.8203630}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{883774, 
author={B. M. Subraya and S. V. Subrahmanya}, 
booktitle={Proceedings First Asia-Pacific Conference on Quality Software}, 
title={Object driven performance testing of Web applications}, 
year={2000}, 
volume={}, 
number={}, 
pages={17-26}, 
abstract={Performance of many Web sites depends on the load on the site at peak time under varying conditions. Performance testing is normally conducted in reasonably simulated environment with the help of performance testing tools. However, performance of a Web site depends on various parameters and each parameter must be tested under varying stress levels. It is not possible to draw a common denominator for performance parameters to test the Web site due to complexity of Web sites. Different parts of the Web site must be tested with different parameters under varying condition and stress level. In such circumstances, it is necessary to decompose the Web site into many components, which represents the behavior of various business components. These business components are mapped to various objects that truly represent the behavior and structure of the part of the web site. These objects are subjected to performance testing with different parameters and stress levels. This paper addresses the new testing process, which uses the concept of decomposing the behavior of the Web site into testable components, which are mapped onto testable objects. These testable objects are subjected to performance testing under varied performance parameters and stress levels}, 
keywords={computational complexity;information resources;program testing;programming environments;software performance evaluation;Web applications;Web sites;complexity;object driven performance testing;performance parameters;simulated environment;Acoustic testing;Application software;Cities and towns;Consumer electronics;Electronic commerce;Life testing;Software testing;Stress;System testing;Time to market}, 
doi={10.1109/APAQ.2000.883774}, 
ISSN={}, 
month={},}
@INPROCEEDINGS{6354629, 
author={N. Baltas and T. Field}, 
booktitle={2012 Ninth International Conference on Quantitative Evaluation of Systems}, 
title={Continuous Performance Testing in Virtual Time}, 
year={2012}, 
volume={}, 
number={}, 
pages={13-22}, 
abstract={In this paper we show how program code and performance models can be made to cooperate seamlessly to support continuous software performance testing throughout the development lifecycle. We achieve this by extending our existing VEX tool for executing programs in virtual time so that events that occur during normal execution and those that occur during the simulation of a performance model can be scheduled on a single global virtual time line. The execution time of an incomplete component of an application is thus estimated by a performance model, whilst that of existing code is measured by instrumentation that is added dynamically at program load time. A key challenge is to be able to map some or all of the resources in a performance model to the real resources of the host platform on which the application is running. We outline a continuous performance engineering methodology that exploits our unified framework and illustrate the principles involved byway of a simple Java application development case study.}, 
keywords={Java;program testing;software performance evaluation;software tools;Java application development;VEX tool;continuous performance engineering methodology;continuous software performance testing;development lifecycle;performance model;program code;program execution;program load time;virtual time;Computational modeling;Instruction sets;Java;Predictive models;Real-time systems;Resumes;Schedules;Modelling Queueing networks;Software Performance;Virtual execution}, 
doi={10.1109/QEST.2012.26}, 
ISSN={}, 
month={Sept},}