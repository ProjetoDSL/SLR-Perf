@INPROCEEDINGS{8070136, 
author={X. Xie and Z. Yang and J. Yu and W. Zhang}, 
booktitle={2016 5th International Conference on Computer Science and Network Technology (ICCSNT)}, 
title={Design and implementation of bank financial business automation testing framework based on QTP}, 
year={2016}, 
volume={}, 
number={}, 
pages={143-147}, 
abstract={The current software testing in the aspects of industrial benefits gradually causes the attention of the domestic financial bank. The innovation of software technology, the increase of software scale and the shortened developing period make the traditional manual testing meeting enormous challenges, while the development of automated testing technology has promoted the progress of the software testing industry. Because of the particularity of financial and banking services, the bank is under an obligation to ensure the quality and reliability of software. Therefore it's vital to test the software. In specific practice, although the powerful third-party testing tools can be used as a solution, it is hard to rely on certain tool to implement automated testing, hence a framework of automated test is required to be introduced for testing, which intends to handle high efficiency and high-quality testing for software automation. This paper proposes a kind of software automation testing framework based on QTP, mainly targeting on the core of the bank, credit, online banking to test the function of the three major operations. The framework is a secondary development based on QTP and mainly for regression testing of software, which integrates techniques including object recognition, data-driven, and keyword-driven technology, checkpoint technology, to proceed business-level testing. The paper expatiated on four issues, which were the test system design, the test standardization, the testing framework design and the testing of the implementation. The practical application shows that the framework can improve the operational efficiency, reduce the test cost, and guarantee the smooth progress of the software automation testing.}, 
keywords={bank data processing;object recognition;program testing;software quality;software reliability;QTP;automated testing technology;bank financial business automation testing framework;banking service;business-level testing;domestic financial bank;financial services;keyword-driven technology;object recognition;online banking;regression testing;software automation testing;software quality;software reliability;software scale;software technology;software testing industry;test cost;test standardization;test system design;testing framework design;third-party testing tools;Automation;Libraries;Object recognition;Software;Standardization;Testing;Tools;QTP automated testing tool;software testing;test automation framework}, 
doi={10.1109/ICCSNT.2016.8070136}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{623350, 
author={D. C. Roberts and D. A. Grossman and O. Frieder and R. Bernstein and E. Bisfiop}, 
booktitle={Proceedings of Sixth International Conference on Computer Communications and Networks}, 
title={Performance testing of communication protocols for three-tier computing: results for ICA and X window protocols}, 
year={1997}, 
volume={}, 
number={}, 
pages={450-455}, 
abstract={We present the results of performance tests to compare two protocols for three-tier computing using the Windows NT operating system. Three-tier computing features a data server for stored databases (Tier 1), an application server that runs applications (Tier 2), and a simple client program that runs on desktop machines that presents the user interface (Tier 3). Three protocols are available to communicate between Tier 2 and 3: intelligence computer architecture (ICA) with and without data compression, and X Window. We measured the performance of the three protocols in a multi-user environment in which we simulated the workload imposed by typical users. We found that, for Microsoft Office 97 and Lotus Notes applications, the X Window protocol uses approximately twice the network bandwidth of ICA, without compression. We also found that compressed ICA generates roughly one third less network traffic than uncompressed ICA at a cost of 20% of additional processor utilization}, 
keywords={client-server systems;computer architecture;data compression;network servers;performance evaluation;program testing;protocols;testing;ICA protocols;Lotus Notes applications;Microsoft Office 97;Tier 1;Tier 2;Tier 3;Windows NT operating system;X window protocols;application server;client program;communication protocols;data compression;data server;desktop machines;intelligence computer architecture;multi-user environment;network bandwidth;network traffic;performance testing;stored databases;three-tier computing;user interface;Application software;Computer architecture;Computer interfaces;Independent component analysis;Machine intelligence;Operating systems;Protocols;Spatial databases;System testing;User interfaces}, 
doi={10.1109/ICCCN.1997.623350}, 
ISSN={1095-2055}, 
month={Sep},}
@INPROCEEDINGS{7359004, 
author={S. Kiran and A. Mohapatra and R. Swamy}, 
booktitle={2015 International Symposium on Technology Management and Emerging Technologies (ISTMET)}, 
title={Experiences in performance testing of web applications with Unified Authentication platform using Jmeter}, 
year={2015}, 
volume={}, 
number={}, 
pages={74-78}, 
abstract={Unified Authentication platform is a Single sign-on (SSO) mechanism which is integrated into Web applications to remove the necessity for multiple application-specific login credentials. Unified Authentication platform (UAP) is a unique platform developed by MIMOS with capability to support multiple authentication mechanism and can be integrated to any Web application to provide Single Sign On (SSO) solution. Performance testing of such web applications using UAP poses some unique challenges because the Jmeter script does not capture all the dynamic values, such as SAML Request, Relay State, Signature Algorithm, Authorization State, Cookie Time, Persistent ID (PID), JSession ID and Shibboleth, generated using single sign-on mechanism of Unified Authentication Platform. This paper explains some of the challenges & experiences to identify an appropriate solution for conducting performance testing on such web application.}, 
keywords={Internet;authorisation;program testing;software performance evaluation;Jmeter script;MIMOS;SSO mechanism;UAP;Web applications;performance testing;single sign-on mechanism;unified authentication platform;Authentication;Browsers;Computer architecture;Generators;MIMO;Servers;Testing;Jmeter;Performance Testing;Single Sign-On;Unified Authentication Platform}, 
doi={10.1109/ISTMET.2015.7359004}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{1602358, 
author={D. Draheim and J. Grundy and J. Hosking and C. Lutteroth and G. Weber}, 
booktitle={Conference on Software Maintenance and Reengineering (CSMR'06)}, 
title={Realistic load testing of Web applications}, 
year={2006}, 
volume={}, 
number={}, 
pages={11 pp.-70}, 
abstract={We present a new approach for performing load testing of Web applications by simulating realistic user behaviour with stochastic form-oriented analysis models. Realism in the simulation of user behaviour is necessary in order to achieve valid testing results. In contrast to many other user models, Web site navigation and time delay are modelled stochastically. The models can be constructed from sample data and can take into account effects of session history on user behaviour and the existence of different categories of users. The approach is implemented in an existing architecture modelling and performance evaluation tool and is integrated with existing methods for forward and reverse engineering}, 
keywords={Web sites;delays;human factors;resource allocation;reverse engineering;software architecture;software performance evaluation;stochastic processes;Web application;Web site navigation;architecture modelling;forward engineering;load testing;performance evaluation tool;reverse engineering;stochastic form-oriented analysis models;time delay;user behaviour;Analytical models;Application software;Computational modeling;Computer science;Delay effects;Navigation;Performance evaluation;Software testing;Software tools;Stochastic processes}, 
doi={10.1109/CSMR.2006.43}, 
ISSN={1534-5351}, 
month={March},}
@INPROCEEDINGS{6274032, 
author={M. Kamra and R. Manna}, 
booktitle={2012 IEEE Eighth World Congress on Services}, 
title={Performance of Cloud-Based Scalability and Load with an Automation Testing Tool in Virtual World}, 
year={2012}, 
volume={}, 
number={}, 
pages={57-64}, 
abstract={The development in cloud computing provides limitless capacity which provides opportunity to evaluate an application performance based on its nature to scale. This paper aims at the analysis of Performance using the Google App Engine(cloud computing paradigm). Virtual Office application is chosen as example to perform experiment of testing the scalability in turn maintaining the performance. An Automation Testing Tool - Test Harness has been used to perform the scale testing of the application while being deployed on the cloud. Results have seen shown in the form of request type and response times(Average time taken/request). Taken into account the consideration that when the application load goes up the Google Cloud expands(increases instance hours) without affecting the running application.}, 
keywords={Web sites;cloud computing;program testing;software performance evaluation;Google App Engine;application performance;automation testing tool;cloud computing;cloud-based scalability;scale testing;test harness;virtual office application;virtual world;Automation;Cloud computing;Google;Scalability;Servers;Teleworking;Testing;API;CPU;GAE;QPS}, 
doi={10.1109/SERVICES.2012.54}, 
ISSN={2378-3818}, 
month={June},}
@INPROCEEDINGS{4669518, 
author={L. Eros and T. Csondes}, 
booktitle={2008 16th International Conference on Software, Telecommunications and Computer Networks}, 
title={Test component assignment in a performance testing environment}, 
year={2008}, 
volume={}, 
number={}, 
pages={399-403}, 
abstract={In this paper we are going to introduce the problem of assigning test components to hosts of a performance (or load) testing environment, and its two novel solutions. When testing the performance of a device (system under test-SUT), the test environment simulates the latter real-life environment of the SUT. The number of hosts in the test environment is however way less than the number of hosts the SUT will have to serve in its real-life environment. Thus, real-life hosts are simulated by software entities, the so-called test components that have to be optimally assigned and then executed on the hosts of the test environment (testing hosts). Our goal is to emulate all the test components by as few testing hosts as possible, that is, to maximize the load on the testing hosts. The problem to be solved is a special case of the task assignment problem for which many solutions have been developed. Our solutions presented in this paper are, however, optimized for distributing load testing traffic. Thus the possibilities and restrictions we had to take into account are very different from those of the classical task assignment case. One of the solutions we present extends existing bin packing heuristics, while the other one solves a series of integer linear programs to make the assignments. Our simulations have shown that by applying our solutions, the average load level on testing hosts can be significantly increased.}, 
keywords={automatic test software;bin packing;digital simulation;integer programming;linear programming;SUT;bin packing heuristic;integer linear program;load testing traffic distribution;performance testing environment;real-life host simulation;software entity;system under test;test component assignment;Emulation;Environmental economics;Heuristic algorithms;Informatics;Software testing;Stress;System testing;Telecommunication traffic;Traffic control}, 
doi={10.1109/SOFTCOM.2008.4669518}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{4636415, 
author={Jingfan Tang and Xiaohua Cao and A. Ma}, 
booktitle={2008 IEEE International Conference on Automation and Logistics}, 
title={Towards adaptive framework of keyword driven automation testing}, 
year={2008}, 
volume={}, 
number={}, 
pages={1631-1636}, 
abstract={This paper presents an adaptive framework of keyword-driven automation testing to support the conversion of the keyword-based test cases into different kinds of test scripts automatically to be executed by different test applications under different test environments (such as GUI environment, database environment, etc.). XML is used to describe the keyword-based commands for the test case. An engine is provided in this framework to parse the XML file and dispatch the command sequences to the different test drivers according to the driver type pre-defined in the command. The test driver is responsible for dispatching the commands to the corresponding test applications to generate the test scripts automatically according to the keywords in the commands. The test scripts will be executed by the test applications on the system-under-test under different test environments. All the test results will be recorded into a log repository for generating all kinds of the test reports.}, 
keywords={XML;program compilers;program testing;XML file parsing;adaptive framework;automation engine layer;keyword driven automation testing;keyword-based command sequence;keyword-based test case conversion;log repository;test driver layer;test execution layer;test report;test script;Application software;Automatic testing;Databases;Educational institutions;Graphical user interfaces;Logistics;Robotics and automation;Software testing;System testing;XML;Keyword Driven;adaptive;automation testing}, 
doi={10.1109/ICAL.2008.4636415}, 
ISSN={2161-8151}, 
month={Sept},}
@INPROCEEDINGS{6253496, 
author={D. Jayasinghe and G. Swint and S. Malkowski and J. Li and Q. Wang and J. Park and C. Pu}, 
booktitle={2012 IEEE Fifth International Conference on Cloud Computing}, 
title={Expertus: A Generator Approach to Automate Performance Testing in IaaS Clouds}, 
year={2012}, 
volume={}, 
number={}, 
pages={115-122}, 
abstract={Cloud computing is an emerging technology paradigm that revolutionizes the computing landscape by providing on-demand delivery of software, platform, and infrastructure over the Internet. Yet, architecting, deploying, and configuring enterprise applications to run well on modern clouds remains a challenge due to associated complexities and non-trivial implications. The natural and presumably unbiased approach to these questions is thorough testing before moving applications to production settings. However, thorough testing of enterprise applications on modern clouds is cumbersome and error-prone due to a large number of relevant scenarios and difficulties in testing process. We address some of these challenges through Expertus---a flexible code generation framework for automated performance testing of distributed applications in Infrastructure as a Service (IaaS) clouds. Expertus uses a multi-pass compiler approach and leverages template-driven code generation to modularly incorporate different software applications on IaaS clouds. Expertus automatically handles complex configuration dependencies of software applications and significantly reduces human errors associated with manual approaches for software configuration and testing. To date, Expertus has been used to study three distributed applications on five IaaS clouds with over 10,000 different hardware, software, and virtualization configurations. The flexibility and extensibility of Expertus and our own experience on using it shows that new clouds, applications, and software packages can easily be incorporated.}, 
keywords={cloud computing;program compilers;program testing;software packages;Expertus;IaaS clouds;Infrastructure as a Service;Internet;automated performance testing;cloud computing;distributed applications;enterprise applications;generator approach;multipass compiler approach;software packages;template-driven code generation;Automation;Cloud computing;Clouds;Testing;Weaving;XML;Aspect;Automation;Clouds;Code Generation;Datacenter;EC2;Emulab;IaaS;Multi-Tier;Open Cirrus;Performance;Scalability;Template;Testing}, 
doi={10.1109/CLOUD.2012.98}, 
ISSN={2159-6182}, 
month={June},}
@INPROCEEDINGS{8203790, 
author={R. S. Liu and Y. S. Chang and C. W. Hung}, 
booktitle={2017 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)}, 
title={VST: A virtual stress testing framework for discovering bugs in SSD flash-translation layers}, 
year={2017}, 
volume={}, 
number={}, 
pages={283-290}, 
abstract={Flash translation layers (FTLs) are the core embedded software (also known as firmware) of NAND flash-based solid-state drives (SSDs). The relentless pursuit of high-performance SSDs renders FTLs increasingly complex and intricate. Therefore, testing and validating FTLs are crucial and challenging tasks. Directly testing and validating FTLs on SSD hardware are common practices though, they are time-consuming and cumbersome because 1) the testing speed is limited by the hardware speed of SSDs and 2) just reproducing bugs can be challenging, let alone locating and root causing the bugs. This work presents virtual stress testing (VST), a simulation framework to enable executing SSD FTLs on PCs or servers against virtual SRAM, DRAM, and flash emulated by host-side main memory. FTL function calls, such as moving data from flash to DRAM, are served by the VST framework. Therefore, VST can test FTLs without SSD hardware requirements nor SSD speed limitations, and root causing bugs becomes manageable tasks. We apply VST to representative SSD design, OpenSSD, which is actively utilized and maintained by SSD and FTL communities. Experimental results show that VST can test FTLs at a speed up to 375 GB/s, which is several hundred times faster than directly testing FTLs on SSD hardware. Moreover, we successfully discover seven new FTL bugs in the OpenSSD design using VST, which is a solid evidence of VST's bug-discovering effectiveness.}, 
keywords={DRAM chips;NAND circuits;SRAM chips;embedded systems;flash memories;DRAM;FTL bugs;NAND flash-based solid-state drives;SSD FTLs;SSD flash-translation layers;VST framework;byte rate 375.0 GByte/s;core embedded software;firmware;flash translation layers;hardware speed;high-performance SSD;host-side main memory;representative SSD design;simulation framework;testing speed;virtual SRAM;virtual stress testing;Computer bugs;Hardware;Random access memory;Servers;Software;Stress;Testing;Embedded software;data storage systems;disk drives;flash memories;software debugging;software testing;systems simulation}, 
doi={10.1109/ICCAD.2017.8203790}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{8334473, 
author={B. Haarmann and C. Martens and H. Petzka and G. Napolitano}, 
booktitle={2018 IEEE 12th International Conference on Semantic Computing (ICSC)}, 
title={A Mighty Dataset for Stress-Testing Question Answering Systems}, 
year={2018}, 
volume={}, 
number={}, 
pages={278-281}, 
abstract={The general goal of semantic question answering systems is to provide correct answers to natural language queries, given a number of structured datasets. The increasing broad deployment of question answering (QA) systems in everyday life requires a comparable and reliable rating of how well QA systems perform and how scalable they are. In order to achieve this, we developed a massive dataset of more than 2 million natural language questions and their SPARQL queries for the DBpedia dataset. We combined natural language processing and linked open data to automatically generate this large amount of valid question-query pairs. Our aim is to assist the benchmarking or scoring of QA systems in terms of answering questions in a range of languages, retrieving answers from heterogeneous sources or answering massive amounts of questions within a limited time. This dataset represents an ideal choice for stress-testing systems' scalability, speed and correctness. As such it has already been included into the Large-scale QA task of the Question Answering Over Linked Data (QALD) Challenge and the HOBBIT project Question Answering Benchmark.}, 
keywords={Linked Data;natural language processing;query processing;question answering (information retrieval);DBpedia dataset;HOBBIT project Question Answering Benchmark;QA systems;SPARQL queries;combined natural language processing;natural language questions;semantic question answering systems;stress-testing Question Answering systems;stress-testing systems;valid question-query pairs;Benchmark testing;Knowledge discovery;Linked data;Natural languages;Resource description framework;Standards;Task analysis;Benchmark;DBpedia;Question-Answering;Semantics}, 
doi={10.1109/ICSC.2018.00054}, 
ISSN={}, 
month={Jan},}
@INPROCEEDINGS{5562998, 
author={B. Ma and B. Chen and X. Bai and J. Huang}, 
booktitle={2010 10th International Conference on Quality Software}, 
title={Design of BDI Agent for Adaptive Performance Testing of Web Services}, 
year={2010}, 
volume={}, 
number={}, 
pages={435-440}, 
abstract={As services are dynamic discovered and bound in the open Internet environment, testing has to be exercised continuously and online to verify and validate the continuous changes and to ensure the quality of the integrated service-based system. During this process, testing strategies have to be adapted in accordance to the changes in the environment and target systems. Software agents are characterized by context awareness, autonomous decision making and social collaboration capabilities. The paper introduces the design of BDI (Believe-Decision-Intention) agents to facilitate adaptive performance testing of Web Services. The BDI model specifies the necessary test knowledge, test goal and action plan to carry out test and adaptive schedule. Performance testing is defined as a scheduling problem to select the workload and test cases in order to achieve the goal of performance abnormal detection. A two-level control architecture is built. At the TR (Test Runner) level, the BDI agents control the workload of concurrent requests. At the TC (Test Coordinator) level, the BDI agents control the complexity of test cases. Agents communicate and collaborate with each other to share knowledge and test plan. The paper introduces the design of the BDI model, the adaptation rules and the control architecture. Case study is exercised to illustrate the adaptive testing process based on the design of BDI agents.}, 
keywords={Adaptation model;Collaboration;Complexity theory;Computer architecture;Load modeling;Testing;Time factors;BDI agent;Web Services;adaptive testing;performance testing}, 
doi={10.1109/QSIC.2010.69}, 
ISSN={1550-6002}, 
month={July},}
@INPROCEEDINGS{6425016, 
author={X. Yang and Z. Chen}, 
booktitle={2012 International Conference on Image Analysis and Signal Processing}, 
title={An improved wavelet denoising method used in electrical throttle performance testing}, 
year={2012}, 
volume={}, 
number={}, 
pages={1-4}, 
abstract={In this paper, an electrical throttle performance test system is designed mainly focusing on its potentiometer and function tests. An improved denoising algorithm based upon the wavelet transform is proposed in non-stationary testing environment. In the experiment, the virtual instrument is used to call the denoising module and processes the acquiring signals. It is proved that its effect is obviously more excellent than conventional algorithms. This test system is then used in actual assembly line. Good parts can be sorted out efficiently and the quality of assembly line is improved.}, 
keywords={assembling;automotive engineering;fuel systems;mechanical testing;signal denoising;wavelet transforms;assembly line;electrical throttle performance testing;nonstationary testing environment;virtual instrument;wavelet denoising;wavelet transform;Algorithm design and analysis;Educational institutions;Noise;Noise reduction;Testing;Wavelet transforms;electrical throttle;performance test;wavelet denoising}, 
doi={10.1109/IASP.2012.6425016}, 
ISSN={2156-0110}, 
month={Nov},}
@INPROCEEDINGS{7574810, 
author={A. Shen and M. Kuzlu and M. Pipattanasomporn and S. Rahman and L. Chen}, 
booktitle={2016 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)}, 
title={A performance testing method for embedded software platforms}, 
year={2016}, 
volume={}, 
number={}, 
pages={135-140}, 
abstract={Performance testing is an important process in the embedded software development. It can detect bugs, help improve software quality and test the system reliability. The objective of this paper is to propose a performance testing method for embedded software platforms. A case study to evaluate the applicability of the proposed method is discussed. Performance tests are performed on three different platforms and test results are compared.}, 
keywords={embedded systems;program debugging;program testing;software performance evaluation;software quality;software reliability;bug detection;embedded software development;embedded software platforms;performance testing;software quality;system reliability;Embedded software;Hardware;Monitoring;Software performance;Testing;Thermostats;Performance testing;embedded software;multi-agent;open source}, 
doi={10.1109/CYBER.2016.7574810}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{7280280, 
author={T. Arnold and A. C. Adewole and R. Tzoneva}, 
booktitle={2015 International Conference on the Industrial and Commercial Use of Energy (ICUE)}, 
title={Performance testing and assessment of multi-vendor protection schemes using proprietary protocols and the IEC 61850 standard}, 
year={2015}, 
volume={}, 
number={}, 
pages={284-290}, 
abstract={The International Electrotechnical Commission (IEC) developed a global standard for power system communication permitting Intelligent Electronic Devices (IEDs) to interoperate within the smart grid environment. However, in order for electric power utility companies to adopt IEC 61850 standard-based devices with confidence, it is necessary to carry out performance tests and evaluations to allay their fears. This paper presents an evaluation of the performance of IEC 61850 standard-based devices with respect to their speed, security, and dependability of operation. The study was implemented using multi-vendor IEDs configured for a Permissive Overreaching Transfer Trip (POTT) communication scheme with conventional proprietary protocols and the IEC 61850 Generic Object Oriented Substation Events (GOOSE) messages based on hardware-in-the-loop simulations with the Real-Time Digital Simulator (RTDS). RSCAD software was used in the modelling of a typical power system network protected by two multi-vendor distance protection IEDs using a lab-scale testbed designed and implemented for the investigations relating to this paper. Real-time simulations for various fault locations and fault resistances were carried out. The results obtained demonstrated the dependability and security of the operation of the IEC 61850-based POTT communication scheme with faster operating times compared with the conventional POTT communication scheme based on vendor-specific proprietary protocols. This paper could serve as a reference to electric power utility companies as they adopt IEC 61850 standard-based devices in their networks.}, 
keywords={IEC standards;electricity supply industry;fault location;power engineering computing;power system faults;protocols;smart power grids;substation automation;substation protection;GOOSE messages;IEC 61850 generic object oriented substation events;IEC 61850 standard-based devices;International Electrotechnical Commission;POTT communication scheme;RSCAD software;RTDS;electric power utility companies;fault locations;fault resistances;hardware-in-the-loop simulations;intelligent electronic devices;multïvendor distance protection IED;multivendor IED;multivendor protection schemes;permissive overreaching transfer trip;power system communication;power system network;real-time digital simulator;smart grid environment;vendor-specific proprietary protocols;Delays;IEC Standards;Impedance;Protocols;Distance protection;GOOSE;IEC 61850;Intelligent Electronic Devices;POTT;real-time digital simulation}, 
doi={10.1109/ICUE.2015.7280280}, 
ISSN={2166-0581}, 
month={Aug},}
@INPROCEEDINGS{8304099, 
author={M. A. Putri and H. N. Hadi and F. Ramdani}, 
booktitle={2017 International Conference on Sustainable Information Engineering and Technology (SIET)}, 
title={Performance testing analysis on web application: Study case student admission web system}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={Websites usage for universities selection entrance (admission) are most visited websites in daily activity, thus its performance is critical. The ability of web applications either to control or to process users' requests determines its reliability. Furthermore, those websites which process students admission in Universitas Brawijaya and Politeknik Negeri Malang certainly engage massive volume of data and information that requires the highest level of reliability. Therefore, there is absolutely needed appropriate testing performances to measure the level of a certain application based on reliability rate. This measurement is used to determine responses, throughput, capability, and system scalability upon workload given. This research has a contribution to present testing performance concepts, goals, targets, types, and tools of Apache JMeter which is engaged for web assessment including detects mistake and error that relates to application performance and helps to improve the level of application performance as expected.}, 
keywords={Internet;Web services;Web sites;educational institutions;Politeknik Negeri Malang;Universitas Brawijaya;application performance;appropriate testing performances;daily activity;performance testing analysis;process students admission;reliability rate;student admission web system;system scalability;testing performance concepts;universities selection entrance;users;web application;websites usage;Computer science;Reliability;Servers;Software;Stress;Testing;Tools;jmeter;performance testing;testing;website}, 
doi={10.1109/SIET.2017.8304099}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{8065747, 
author={R. Abbas and Z. Sultan and S. N. Bhatti}, 
booktitle={2017 International Conference on Communication Technologies (ComTech)}, 
title={Comparative analysis of automated load testing tools: Apache JMeter, Microsoft Visual Studio (TFS), LoadRunner, Siege}, 
year={2017}, 
volume={}, 
number={}, 
pages={39-44}, 
abstract={Software testing is the process of testing, verifying and validating the user's requirements. During whole software development, testing is an ongoing process. Black Box, White Box testing and grey box testing are the three main types of software testing. In Black box testing, user doesn't know intrinsic logics and design of system. In white box testing, Tester knows the intrinsic logic of code. In Grey box testing, Tester has little bit knowledge about the internal structure, code and working of the system. It is commonly used in case of Integration testing. Load testing is the type of testing which helps us to analyze the performance of the system under heavy load or under Zero load. With the help of a automated load Testing Tools, we can do it in better way. The intention for writing this research is to carry out a comparison of four automated load testing tools i.e. Apache JMeter, HP LoadRunner, Microsoft Visual Studio (TFS), Siege based on certain criteria i.e. test scripts generation, plug-in support, result reports, application support and cost. The main focus is to study and analyze these load testing tools and identify which tool is best and more efficient [10]. We assume this comparative analysis can help in selecting the most appropriate tool and motivates the use of open source load testing tools.}, 
keywords={program testing;public domain software;software tools;Black box testing;Integration testing;LoadRunner;Microsoft Visual Studio;Siege;TFS;Zero load;apache JMeter;application support;automated load testing tools;comparative analysis;grey box testing;heavy load;intrinsic logic;open source load testing tools;plug-in support;result reports;software testing;test scripts generation;white box testing;Automation;Manuals;Software;Software testing;Tools;Visualization;Testing;automated testing;load testing;manual testing;stress test;testing tools}, 
doi={10.1109/COMTECH.2017.8065747}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{6419531, 
author={Đ. Miljković and S. Bojić and M. Đukić and M. Jovanović}, 
booktitle={2012 20th Telecommunications Forum (TELFOR)}, 
title={Automation testing of Graphical User Interface}, 
year={2012}, 
volume={}, 
number={}, 
pages={1609-1612}, 
abstract={In this paper is explained one solution for automation of testing Graphical User Interface. The paper gives a description of the problem, the concept of a solution and a description of the implementation of such a solution in order to confirm the above concept. Validation of the implementation was carried out on graphical tool for the development of software for audio target platform.}, 
keywords={graphical user interfaces;program testing;software engineering;audio target platform;automation testing;graphical tool;graphical user interface;software development;Automation;Browsers;Electronic mail;Graphical user interfaces;Manuals;Testing;XML;GUI;GUIPlayer;Lua;XML;ispitivanje}, 
doi={10.1109/TELFOR.2012.6419531}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{8011376, 
author={G. Meyer}, 
booktitle={PCIM Asia 2017; International Exhibition and Conference for Power Electronics, Intelligent Motion, Renewable Energy and Energy Management}, 
title={Enhanced Power Electronics System for High-Performance Testing of Motor Control Units in a Power HIL Environment}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={Hardware-in-the-loop (HIL) simulation is an established test method for analyzing motor control units (MCUs). For highly integrated drive controllers, the controller and the power electronics must be tested at the electric power level (emulation). Using this method requires specific power electronics for emulation. This paper introduces a special hardware solution that is based on an interleaved switching, three-level neutral-point-clamped (NPC) inverter and a sophisticated model-predictive control algorithm to establish a high-bandwidth electronic load for testing electronic power systems.}, 
keywords={}, 
doi={}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{8122351, 
author={D. Shang and X. Zhang and J. Han and X. Xu}, 
booktitle={2017 IEEE 3rd Information Technology and Mechatronics Engineering Conference (ITOEC)}, 
title={MultiModal-database-XJTU: An available database for biometrics recognition with its performance testing}, 
year={2017}, 
volume={}, 
number={}, 
pages={521-526}, 
abstract={The current need for large multimodal databases to evaluate automatic biometrics recognition systems has motivated the development of the XJTU multimodal database. The main purpose has been to consider a large scale population, with statistical significance, in a real multimodal procedure, and including several sources of variability that can be found in real environments. The acquisition process, contents and availability of the single-session baseline corpus are fully described. Some experiments showing consistency of data through the different acquisition sites and assessing data quality are also presented. MultiModal-Database-XJTU, a new multimodal database, is presented. The database consists of fingerprint images acquired with sensor, frontal face images from a camera, iris images from a Cannon scanner, and voice utterances acquired with a microphone. The MultiModal-Database-XJTU includes real multimodal data from 102 individuals. In this contribution, the acquisition setup and protocol are outlined, and the contents of the database are described. The database will be publicly available for research purposes.}, 
keywords={biometrics (access control);feature extraction;fingerprint identification;MultiModal-database-XJTU;XJTU multimodal database;automatic biometrics recognition systems;data quality;multimodal data;multimodal procedure;Authentication;Databases;Face;Feature extraction;Fingerprint recognition;Fingers;Multi-focus image fusion;Perfect reconstruction;Quantum particle swarm optimization;Superior speed}, 
doi={10.1109/ITOEC.2017.8122351}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{5984849, 
author={S. Duttagupta and R. Mansharamani}, 
booktitle={2011 International Symposium on Performance Evaluation of Computer Telecommunication Systems}, 
title={Extrapolation tool for load testing results}, 
year={2011}, 
volume={}, 
number={}, 
pages={69-76}, 
abstract={Load testing of IT applications is fraught with the challenges of time to market, quality of results, high cost of commercial tools, and accurately representing production like scenarios. It would help IT projects to be able to test with a small number of users and extrapolate to scenarios with much larger number of users. This in turn will cut down cycle times and costs and allow for a variety of extrapolations closer to production. We present a simple extrapolation technique based on statistical empirical modeling, which we have found to be more than 90% accurate across a range of applications running across a number of hardware servers. The technique has currently been validated for scenarios where the hardware is the bottleneck and is extensible to a wider range of scenarios as well.}, 
keywords={extrapolation;program testing;statistical analysis;IT applications;IT projects;extrapolation tool;load testing results;statistical empirical modeling;Extrapolation;Linear regression;Load modeling;Servers;Testing;Throughput;Time factors;Extrapolation;S-Curves;load testing;regression}, 
doi={}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{6459909, 
author={A. Underbrink and A. Potter and H. Jaenisch and D. J. Reifer}, 
booktitle={2012 IEEE Conference on Technologies for Homeland Security (HST)}, 
title={Application stress testing Achieving cyber security by testing cyber attacks}, 
year={2012}, 
volume={}, 
number={}, 
pages={556-561}, 
abstract={Application stress testing applies the concept of computer network penetration testing to software applications. Since software applications may be attacked - from inside or outside a protected network boundary - they are threatened by actions and conditions which cause delays, disruptions, or failures. Stress testing exposes software systems to simulated cyber attacks, revealing potential weaknesses and vulnerabilities in their implementation. By using such testing, these internal weaknesses and vulnerabilities can be discovered earlier in the software development life cycle, corrected prior to deployment, and lead to improved software quality. Application stress testing is a process and software prototype for verifying the quality of software applications under severe operating conditions. Since stress testing is rarely - if at all - performed today, the possibility of deploying critical software systems that have been stress tested provides a much stronger indication of their ability to withstand cyber attacks. Many possible attack vectors against critical software can be verified as true threats and mitigated prior to deployment. This improves software quality and serves as a tremendous risk reduction for critical software systems used in government and commercial enterprises. The software prototype models and verifies failure conditions of a system under test (SUT). The SUT is first executed in a virtual environment and its normal operational modes are observed. A normal behavior model is generated in order to predict failure conditions based on attack models and external SUT interfaces. Using off-the-shelf software tools, the predictions are verified in the virtual environment by stressing the executing SUT with attacks against the SUT. Results are presented to testers and system developers for dispensation or mitigation.}, 
keywords={computer network security;program testing;program verification;risk analysis;safety-critical software;software prototyping;software quality;software tools;virtual reality;SUT;application stress testing;commercial enterprises;computer network penetration testing;critical software system;cyber attack testing;cyber security;delay;failure analysis;formal verification;government enterprises;off-the-shelf software tools;potential weaknesses revealing;protected network boundary;risk reduction;software application;software development life cycle;software prototype model;software quality;software systems;software vulnerability;system under test;virtual environment;Databases;Monitoring;Prototypes;Software systems;Stress;Testing;application testing;attack;penetration testing;softwaer quality;software assurance}, 
doi={10.1109/THS.2012.6459909}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{5669732, 
author={H. J. Jo and J. G. Hwang and K. M. Lee}, 
booktitle={ICCAS 2010}, 
title={Proposal of automated performance testing tool for vital software in train control system}, 
year={2010}, 
volume={}, 
number={}, 
pages={1151-1155}, 
abstract={In accordance with the development of recent computer technology, the dependency of train control system on the computer software is being increased further, and accordingly, the testing for the safety and reliability of train control system software became more important. Hence, the safety assurance of the vital software running on the train control system is very critical task and yet, not many works have been done. While much efforts have been reported to improve electronic hardware's safety, not so much systematic approaches to evaluate software's safety. In this paper, we suggested an automated tool for performance testing in train control system, and presented its result of implementation. The testing items in the implemented tool had referred to the international standards in relation to the software for train control system, such as IEC 61508 and IEC 62279. In these international standards, 'performance testing' for train control system S/W has to be recommended highly.}, 
keywords={IEC standards;program testing;railway engineering;railway safety;IEC 61508;IEC 62279;automated performance testing tool;computer software;electronic hardware safety;international standard;performance testing;reliability testing;safety assurance;safety testing;train control system;Control systems;Monitoring;Rail transportation;Safety;Software;Standards;Testing;Performance testing;Software safety;Train control system}, 
doi={10.1109/ICCAS.2010.5669732}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{204204, 
author={T. P. Parker and C. W. Webb}, 
booktitle={1992 Proceedings 42nd Electronic Components Technology Conference}, 
title={A study of failures identified during board level environmental stress testing}, 
year={1992}, 
volume={}, 
number={}, 
pages={177-184}, 
abstract={AT&T has investigated and implemented environmental stress testing (EST) in the production of a variety of circuit board designs as a means of reducing the incidence of early life failures. EST techniques include thermal cycling, random vibration, and others. These techniques have proven more effective than traditional burn-in techniques. In addition, studies have revealed that functional monitoring during thermal stressing of circuit cards more than doubles the effectiveness of EST. Outgoing quality audits and customer first month failure rates have improved by factors of two to four since the implementation of EST}, 
keywords={environmental testing;failure analysis;life testing;printed circuit testing;production testing;EST techniques;board level environmental stress testing;circuit board designs;early life failures;first month failure rates;functional monitoring;random vibration;thermal cycling;Application software;Assembly;Circuit testing;Failure analysis;Life testing;Manufacturing processes;Printed circuits;Production;Thermal stresses;Total quality management}, 
doi={10.1109/ECTC.1992.204204}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{7286553, 
author={Xi Chen and Hao Guo and P. Crossley}, 
booktitle={2015 IEEE Power Energy Society General Meeting}, 
title={Performance testing of IEC 61850 based architecture for UK National Grid standardised Substation automation solutions}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={Traditional protection and control systems in many UK National Grid Substations are reaching the end of their asset design life. This provides an opportunity to investigate whether new architecture that deploys Intelligent Electronic Device (IED) technology can deliver a reliable solution that is economically appropriate and delivers long life. The application of IEDs that utilize the IEC61850 based process bus reduces the life-time cost of the secondary systems and improves flexibility and functionality by accommodating high-speed peer-to-peer communications. The interconnectivity of devices on a single network offers significant benefits including a plug and play approach to future system changes. However, it requires interoperability among multi-vendor protection relays and control devices over an operating life of many decades. The realisation of this requires significant and detailed testing to help National Grid gain confidence in the use of these technologies. In this paper the substation architecture and the associated Power Networks are modelled in RTDS with faults applied at different locations on the transmission lines. The paper presents the results of interoperability tests involving multi-vendor Merging Unit (MU) and IED devices, which are then used to evaluate the functional performance of distance protection schemes.}, 
keywords={open systems;power grids;relay protection;substation automation;substation protection;IEC61850 based process bus;IED technology;RTDS;UK National Grid Standardised Substation automation solutions;asset design life;control devices;distance protection schemes;high-speed peer-to-peer communications;intelligent electronic device technology;interoperability tests;lifetime cost;multi-vendor merging unit;multi-vendor protection relays;plug and play approach;power networks;secondary systems;transmission lines;Circuit faults;IEC Standards;Interoperability;Merging;Substations;Tagging;IEC61850;Interoperability;Power System Reliability;Substation Automation;Substation Protection}, 
doi={10.1109/PESGM.2015.7286553}, 
ISSN={1932-5517}, 
month={July},}
@INPROCEEDINGS{6070157, 
author={J. Amelot and Y. S. Li-Baboud and C. Vasseur and J. Fletcher and D. Anand and J. Moyne}, 
booktitle={2011 IEEE International Symposium on Precision Clock Synchronization for Measurement, Control and Communication}, 
title={An IEEE 1588 Performance Testing Dashboard for Power Industry requirements}, 
year={2011}, 
volume={}, 
number={}, 
pages={132-137}, 
abstract={The numerous time synchronization performance requirements in the Smart Grid necessitates a set of common metrics and test methods. The test methods help to verify the ability of the network system and its components to meet the power industry's accuracy, reliability and interoperability criteria for next-generation substations. In order to develop viable metrics and test methods, an IEEE 1588 Testbed for the power industry has been established. To ease the challenges of testing, monitoring and analysis of the results, a software-based testing dashboard was designed and implemented. The dashboard streamlines the performance testing process by converging multiple tests for accuracy, reliability and interoperability into a centralized interface. The dashboard enables real-time visualization and analysis of the results. The paper details the design and implementation of the IEEE 1588 Power Industry Performance Testing Dashboard as well as an update of the preliminary findings from the testbed.}, 
keywords={open systems;power engineering computing;power generation reliability;smart power grids;substations;synchronisation;IEEE 1588;dashboard streamlines;interoperability;next-generation substations;power industry performance testing dashboard;reliability;smart grid;software-based testing dashboard;time synchronization;Frequency synchronization;Power industry;Robustness;Switches;Synchronization;Time frequency analysis;IEEE 1588;PMU;conformance testing;test methods;time synchronization}, 
doi={10.1109/ISPCS.2011.6070157}, 
ISSN={1949-0305}, 
month={Sept},}
@INPROCEEDINGS{622253, 
author={R. Mahmoudi and J. L. Tauritz}, 
booktitle={Proceedings of 1997 Wireless Communications Conference}, 
title={Performance testing of the North American CDMA system, using an envelope simulator}, 
year={1997}, 
volume={}, 
number={}, 
pages={84-88}, 
abstract={The growing use of spread spectrum techniques for personal communications (PCS) in Japan and USA is proving to be an enormous stimulus for the study of system impact on component design. New and innovative techniques are required to translate system criteria into component specifications. In this paper we have studied the performance of the “North American Digital Cellular IS-95” system proposed by QUALCOMM, under the influence of spurious signals using the new “Circuit Envelope Simulator” in HP-EESOF's Microwave Design System, MDS. The implemented functional blocks facilitate the generation of proper (noisy) CDMA (reverse and forward) signals, which are then used to program an arbitrary wave generator in order to create actual test signals. Additionally, these functional blocks can be replaced with equivalent circuits, consisting of passive and active elements, etc. For illustrative purposes, we discuss the application of these signals to two real amplifiers, one linear and one nonlinear. The measured results are critically compared with the simulation results}, 
keywords={cellular radio;code division multiple access;digital radio;digital simulation;personal communication networks;spread spectrum communication;telecommunication equipment testing;Circuit Envelope Simulator;HP-EESOF's Microwave Design System;North American CDMA system;North American Digital Cellular IS-95;QUALCOMM;equivalent circuits;functional blocks;linear amplifiers;nonlinear amplifier;performance testing;personal communications;spread spectrum techniques;Circuit noise;Circuit simulation;Circuit testing;Multiaccess communication;Noise generators;Personal communication networks;Signal design;Signal generators;Spread spectrum communication;System testing}, 
doi={10.1109/WCC.1997.622253}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6337826, 
author={M. Yan and H. Sun and X. Wang and X. Liu}, 
booktitle={2012 IEEE International Conference on Cluster Computing}, 
title={Building a TaaS Platform for Web Service Load Testing}, 
year={2012}, 
volume={}, 
number={}, 
pages={576-579}, 
abstract={Web services are widely known as the building blocks of typical service oriented applications. The performance of such an application system is mainly dependent on that of component web services. Thus the effective load testing of web services is of great importance to understand and improve the performance of a service oriented system. However, existing Web Service load testing tools ignore the real characteristics of the practical running environment of a web service, which leads to inaccurate test results. In this work, we present WS-TaaS, a load testing platform for web services, which enables load testing process to be as close as possible to the real running scenarios. In this way, we aim at providing testers with more accurate performance testing results than existing tools. WS-TaaS is developed on the basis of our existing Cloud PaaS platform: Service4All. First, we provide detailed analysis of the requirements of Web Service load testing and present the conceptual architecture and design of key components. Then we present the implementation details of WS-TaaS on the basis of Service4All. Finally, we perform a set of experiments based on the testing of real web services, and the experiments illustrate that WS-TaaS can efficiently facilitate the whole process of Web Service load testing.}, 
keywords={Web services;cloud computing;program testing;software tools;Cloud PaaS platform;Service4All;TaaS platform;WS-TaaS;Web service load testing tools;load testing platform;service oriented system;typical service oriented applications;Cloud computing;Computer architecture;Monitoring;Testing;cloud computing;load testing;testing as a service;web services}, 
doi={10.1109/CLUSTER.2012.20}, 
ISSN={1552-5244}, 
month={Sept},}
@INPROCEEDINGS{5581372, 
author={L. Xu and W. Zhang and L. Chen}, 
booktitle={2010 Seventh Web Information Systems and Applications Conference}, 
title={Modeling Users' Visiting Behaviors for Web Load Testing by Continuous Time Markov Chain}, 
year={2010}, 
volume={}, 
number={}, 
pages={59-64}, 
abstract={Virtual users with high quality are the preconditions to ensure the effect of load testing for Web applications. The existed tools for load testing usually generate virtual users with randomly choosing user sessions, manually generating user sessions or mining Log files, which causing such problems as non-real workload, subjectivity or difficult to update. Therefore we set each virtual user with a corresponding configure file, and these files determine the visiting paths, visiting moments and stay time of virtual users based on the Continuous Time Markov Chain. So we firstly finish the pretreatment for Log files, then construct the user visiting model, and next generate the virtual users, lastly carry out the load testing. In this way, we can obtain more reliable results for Web application load testing than the existed methods.}, 
keywords={Markov processes;Web services;data mining;program testing;virtual reality;Web load testing;continuous time Markov chain;log files mining;user visiting model;virtual users;Electromagnetic compatibility;Load modeling;Markov processes;Testing;Time factors;Web pages;Continuous Time Markov Chain;load testing;virtual user}, 
doi={10.1109/WISA.2010.47}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6297158, 
author={L. Nagowah and G. Sowamber}, 
booktitle={2012 International Conference on Computer Information Science (ICCIS)}, 
title={A novel approach of automation testing on mobile devices}, 
year={2012}, 
volume={2}, 
number={}, 
pages={924-930}, 
abstract={Mobile phones and mobile applications have now become an integral part of our everyday life. Mobile application testing plays a pivotal role in making the mobile applications more reliable and defect free. Existing test automation tools have been tailored to perform mobile test automation through mobile emulators. Other tools require the mobile device where the application is installed, to be connected to a computer so that the tests can be run. Obviously, the results obtained from emulators often differ from those obtained on actual mobile devices. To our best knowledge only a few solutions for creating automated tests of mobile applications exist and their functionality is very limited. In this paper, we introduce the idea of implementing a mobile test automation framework MobTAF which performs mobile test automation on the mobile device where connection to a computer is not required. The framework moves the testing infrastructure to the phone, to support test situations that cannot easily be replicated with an emulator. A prototype application was then implemented to test the mobile automation framework, MobTAF. The results prove that MobTAF framework is an efficient way of performing mobile application tests directly on the mobile devices.}, 
keywords={mobile computing;mobile handsets;program testing;MobTAF framework;automated tests;automation testing;defect free;mobile application testing;mobile devices;mobile emulators;mobile phones;mobile test automation framework;prototype application;test automation tools;testing infrastructure;Automation;Generators;Layout;Mobile communication;Robustness;Testing;XML;mobile application testing;mobile device test automation;mobile test automation framework;mobile testing;software testing}, 
doi={10.1109/ICCISci.2012.6297158}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{790205, 
author={C. G. Niederstrasser and C. A. Kitts and M. A. Swartwout}, 
booktitle={1999 IEEE Aerospace Conference. Proceedings (Cat. No.99TH8403)}, 
title={Design and performance testing of a satellite health beacon receiving station}, 
year={1999}, 
volume={5}, 
number={}, 
pages={241-251 vol.5}, 
abstract={As part of its space operations research program, Stanford University's Space Systems Development Laboratory (SSDL) is implementing an automated state of health assessment and notification system for spacecraft. Onboard the spacecraft, this system consists of software that filters telemetry to derive a health assessment and a periodic beacon that broadcasts this assessment to the ground. Throughout the world, a network of low-cost receiving stations receives the beacon signal and relays it to a central mission control center via the Internet. This paper addresses the design and development of a beacon receiving station. Each station is designed to be approximately an order of magnitude lower in price than a conventional two-way ground station. Emphasis is placed on making sure the station is highly autonomous, requiring little or no assistance from the host site. The stations are made up of only three separate components-an antenna, a receiver, and a personal computer}, 
keywords={aerospace test facilities;automatic test equipment;automatic testing;computerised monitoring;ground support systems;receiving antennas;satellite ground stations;signal processing;telecommunication computing;Stanford University;antenna;beacon signal;central mission control center;cost;health assessment;performance testing;periodic beacon;personal computer;satellite health beacon receiving station;telemetry;two-way ground station;Information filtering;Information filters;Laboratories;Operations research;Relays;Satellite broadcasting;Software systems;Space vehicles;Telemetry;Testing}, 
doi={10.1109/AERO.1999.790205}, 
ISSN={}, 
month={},}
@INPROCEEDINGS{5533420, 
author={J. Križanić and A. Grgurić and M. Mošmondor and P. Lazarevski}, 
booktitle={The 33rd International Convention MIPRO}, 
title={Load testing and performance monitoring tools in use with AJAX based web applications}, 
year={2010}, 
volume={}, 
number={}, 
pages={428-434}, 
abstract={In order to deliver quality assured software and avoid potential costs caused by unstable software, software testing is essential in software lifecycle. Load testing is one of the testing types with high importance. It is usually accompanied by performance monitoring of the hosting environment. In the case of web applications which are today widely used, one fact is obvious: most of web applications are public and used by vast number of users, which are making a considerable traffic load on hosting environments and web applications. Load testing and performance monitoring become facilitated with existing tools aimed for load testing and performance monitoring. In the paper we analyze and compare several existing tools which facilitate load testing and performance monitoring, in order to find the most appropriate tools by criteria such as ease of use, supported features, and license. Selected tools were put in action in the real environment, through several web applications. For the case study one of the web applications is used in order to introduce different capabilities of tools, including distributed testing, assembling of test scenario from previously recorded usage scenarios, security support, results analysis, monitoring of key parameters, and reporting and alerting about changes of these parameters.}, 
keywords={Application software;Assembly;Costs;Licenses;Monitoring;Performance analysis;Security;Software quality;Software testing;Telecommunication traffic;AJAX;load testing;performance monitoring;web applications}, 
doi={}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{7780247, 
author={A. Amirante and T. Castaldi and L. Miniero and S. P. Romano}, 
booktitle={2016 Principles, Systems and Applications of IP Telecommunications (IPTComm)}, 
title={Jattack: a WebRTC load testing tool}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={We present Jattack, an automated stressing tool for the analysis of the performance of WebRTC-enabled server-side components. Jattack has been initially conceived with the primary objective of performing a thorough scalability analysis of the well-known Janus WebRTC gateway. As such, it re-uses most of the Janus core stack components in order to reliably emulate the behavior of a dynamically adjustable number of WebRTC clients. The specific testing .scenario can indeed be programmatically reproduced by writing a small "controller" component, which takes on the responsibility of properly orchestrating the scenario itself. The general-purpose nature of the tool, together with its flexibility deriving from the controller-based programmable approach, makes Jattack also suitable for stress-testing other WebRTC-enabled servers.}, 
keywords={Internet;program testing;Jattack;WebRTC load testing tool;WebRTC-enabled server-side components;automated stressing tool;stress-testing;Browsers;Media;Scalability;Servers;Stress;Testing;WebRTC}, 
doi={}, 
ISSN={}, 
month={Oct},}
@ARTICLE{1191406, 
author={L. Angrisani and A. Baccigalupi and G. D'Angiolo}, 
journal={IEEE Transactions on Instrumentation and Measurement}, 
title={A frame-level measurement apparatus for performance testing of ATM equipment}, 
year={2003}, 
volume={52}, 
number={1}, 
pages={20-26}, 
abstract={Performance testing of asynchronous transfer mode (ATM) equipment is dealt with here. The attention is principally paid to frame-level metrics, recently proposed by the ATM Forum because of their suitability to reflect user-perceived performance better than traditional cell-level metrics. Following the suggestions of the ATM Forum, more and more network engineers and production managers are interested today in these metrics, thus increasing the need of instruments and measurement solutions appropriate to their estimation. Trying to satisfy this exigency, a new VME extension for instrumentation (VXI) based measurement apparatus is proposed in the paper. The apparatus features a suitable software, developed by the authors, which allows the evaluation of the aforementioned metrics by simply making use of common ATM analyzers; only two VXI line interfaces, capable of managing the physical and ATM layers, are, in fact, adopted. Some details concerning ATM technology and its hierarchical structure, as well as the main differences between frames, specific to the ATM adaptation layer, and cells, characterizing the underlying ATM layer, are first given. Both the hardware and software solutions of the measurement apparatus are then described in detail, paying particular attention to the measurement procedures implemented. In the end, the performance of a new ATM device is assessed through the proposed apparatus.}, 
keywords={asynchronous transfer mode;automatic test equipment;telecommunication computing;telecommunication equipment testing;ATM equipment;VME extension;VXI instrumentation;frame-level metric;measurement apparatus;performance testing;Asynchronous transfer mode;B-ISDN;Delay;Instruments;Laboratories;Manufacturing;Particle measurements;Quality of service;Software measurement;Testing}, 
doi={10.1109/TIM.2003.809063}, 
ISSN={0018-9456}, 
month={Feb},}
@INPROCEEDINGS{6606651, 
author={H. Malik and H. Hemmati and A. E. Hassan}, 
booktitle={2013 35th International Conference on Software Engineering (ICSE)}, 
title={Automatic detection of performance deviations in the load testing of Large Scale Systems}, 
year={2013}, 
volume={}, 
number={}, 
pages={1012-1021}, 
abstract={Load testing is one of the means for evaluating the performance of Large Scale Systems (LSS). At the end of a load test, performance analysts must analyze thousands of performance counters from hundreds of machines under test. These performance counters are measures of run-time system properties such as CPU utilization, Disk I/O, memory consumption, and network traffic. Analysts observe counters to find out if the system is meeting its Service Level Agreements (SLAs). In this paper, we present and evaluate one supervised and three unsupervised approaches to help performance analysts to 1) more effectively compare load tests in order to detect performance deviations which may lead to SLA violations, and 2) to provide them with a smaller and manageable set of important performance counters to assist in root-cause analysis of the detected deviations. Our case study is based on load test data obtained from both a large scale industrial system and an open source benchmark application. The case study shows, that our wrapper-based supervised approach, which uses a search-based technique to find the best subset of performance counters and a logistic regression model for deviation prediction, can provide up to 89% reduction in the set of performance counters while detecting performance deviations with few false positives (i.e., 95% average precision). The study also shows that the supervised approach is more stable and effective than the unsupervised approaches but it has more overhead due to its semi-automated training phase.}, 
keywords={input-output programs;program testing;public domain software;regression analysis;software performance evaluation;unsupervised learning;CPU utilization;LSS;SLA violations;automatic performance deviation detection;deviation prediction;disk I-O;large scale systems;load testing;logistic regression model;machine learning;memory consumption;network traffic;open source benchmark application;performance counters;root-cause analysis;run-time system properties;search-based technique;service level agreements;wrapper-based supervised approach;Control charts;Large-scale systems;Logistics;Monitoring;Principal component analysis;Radiation detectors;Testing;Machine Learning;Performance;Signature}, 
doi={10.1109/ICSE.2013.6606651}, 
ISSN={0270-5257}, 
month={May},}
@INPROCEEDINGS{4273012, 
author={M. D. Barros and J. Shiau and C. Shang and K. Gidewall and H. Shi and J. Forsmann}, 
booktitle={37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)}, 
title={Web Services Wind Tunnel: On Performance Testing Large-Scale Stateful Web Services}, 
year={2007}, 
volume={}, 
number={}, 
pages={612-617}, 
abstract={New versions of existing large-scale web services such as Passport.comcopy have to go through rigorous performance evaluations in order to ensure a high degree of availability. Performance testing (such as benchmarking, scalability, and capacity tests) of large-scale stateful systems in managed test environments has many different challenges, mainly related to the reproducibility of production conditions in live data centers. One of these challenges is creating a dataset in a test environment that mimics the actual dataset in production. Other challenges involve the characterization of load patterns in production based on log analysis and proper load simulation via reutilization of data from the existing dataset. The intent of this paper is to describe practical approaches to address some of the aforementioned challenges through the use of various novel techniques. For example, this paper discusses data sanitization, which is the alteration of large datasets in a controlled manner to obfuscate sensitive information, preserving data integrity, relationships, and data equivalence classes. This paper also provides techniques for load pattern characterization via the application of Markov chains to custom and generic logs, as well as general guidelines for the development of cache-based load simulation tools tailored for the performance evaluation of stateful systems.}, 
keywords={Web services;program testing;security of data;software performance evaluation;Markov chains;Web services wind tunnel;cache-based load simulation tools;data integrity;data sanitization;log analysis;performance testing;Availability;Benchmark testing;Environmental management;Large-scale systems;Pattern analysis;Production systems;Reproducibility of results;Scalability;System testing;Web services}, 
doi={10.1109/DSN.2007.102}, 
ISSN={1530-0889}, 
month={June},}
@INPROCEEDINGS{5563862, 
author={Ni Jin and Wang Mingming and Wang Jiangqing}, 
booktitle={2010 3rd International Conference on Computer Science and Information Technology}, 
title={Realization on intelligent GUI automation testing based-on .NET}, 
year={2010}, 
volume={1}, 
number={}, 
pages={14-17}, 
abstract={Points out the obvious deficiencies in capture/playback mechanism at present, aiming at difficulties of maintenance and extension in constantly altered GUI elements, presents a new GUI automation testing solution - Building AUILibrary. It can search, identify all the controls, trigger all kinds of mouse and keyboard events, execute data driving verification roundly and accurately, trace and record execution process and save the locale when exception occurs, implement flexible and effective GUI automation testing indeed.}, 
keywords={graphical user interfaces;program testing;software tools;user interface management systems;.NET framework;AUILibrary;capture mechanism;data driving verification;intelligent GUI automation testing;playback mechanism;Automation;Computers;Graphical user interfaces;Indexes;Software;GUI;Software testing;automation}, 
doi={10.1109/ICCSIT.2010.5563862}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{5514222, 
author={G. Li and N. Tan}, 
booktitle={2010 Third International Conference on Information and Computing}, 
title={Design and Implementation of Remote Monitoring and Control System for Freight Train Load Testing}, 
year={2010}, 
volume={1}, 
number={}, 
pages={117-120}, 
abstract={The key technology of the fatigue reliability design and test evaluation of freight train is to establish freight train load spectrum based on operating conditions. Design a set of remote monitoring and control system for the establishment of loading spectrum's actual needs. The system uses GPS technology for vehicle location, speed and other information, through the GPRS technology to build car-side with the ground control center of the interaction channel. Using the ARM7 microprocessors, transplant embedded μC/OS-II operating system, realized the hardware management and task scheduling. The system can achieve vehicle-side with the ground control center data exchange. Through the ground control center monitoring software running real-time get the vehicles and the test equipment status, timely adjustment of test equipment. At the same time enables automatic vehicle equipment. The system basically meet the needs of the overloaded train load test research requirements can be a steady, accurate and complete remote monitoring and control functions.}, 
keywords={Global Positioning System;automatic test equipment;computerised monitoring;microprocessor chips;operating systems (computers);packet radio networks;rail traffic;scheduling;traffic engineering computing;ARM7 microprocessors;GPRS technology;GPS technology;automatic vehicle equipment;data exchange;embedded μC/OS-II operating system;fatigue reliability design;freight train load spectrum;freight train load testing;ground control center;hardware management;remote monitoring;task scheduling;train car-side;Automatic control;Control systems;Fatigue;Global Positioning System;Land vehicles;Loading;Remote monitoring;Road vehicles;System testing;Test equipment;#NAME?}, 
doi={10.1109/ICIC.2010.36}, 
ISSN={2160-7443}, 
month={June},}
@INPROCEEDINGS{7102628, 
author={E. Rodrigues and M. Bernardino and L. Costa and A. Zorzo and F. Oliveira}, 
booktitle={2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)}, 
title={PLeTsPerf - A Model-Based Performance Testing Tool}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={Performance testing is a highly specialized task, since it requires that a performance engineer knows the application to be tested, its usage profile, and the infrastructure where it will execute. Moreover, it requires that testing teams expend a considerable effort and time on its automation. In this paper, we present the PLeTsPerf, a model-based performance testing tool to support the automatic generation of scenarios and scripts from application models. PLetsPerf is a mature tool, developed in collaboration with an IT company, which has been used in several works, experimental studies and pilot studies. We present an example of use to demonstrate the process of generating test scripts and scenarios from UML models to test a Web application. We also present the lessons learned and discuss our conclusions about the use of the tool.}, 
keywords={Internet;program testing;PLeTsPerf tool;UML model;Unified Modeling Language;Web application;model-based performance testing tool;scenario generation;script generation;Companies;Generators;Load modeling;Software;Testing;Unified modeling language;Visualization}, 
doi={10.1109/ICST.2015.7102628}, 
ISSN={2159-4848}, 
month={April},}
@INPROCEEDINGS{6068597, 
author={A. J. Mercer and R. K. James and G. Bennett and P. Patel and C. Johnston and J. Cai}, 
booktitle={2011 IEEE International Conference on RFID-Technologies and Applications}, 
title={Performance testing of RFID systems with RF-harsh materials}, 
year={2011}, 
volume={}, 
number={}, 
pages={537-543}, 
abstract={Radio Frequency Identification (RFID) has been adopted to track items in supply chain, healthcare, and manufacturing applications. Hospitals and factories, however, are difficult environments for radiowave propagation. Cinder block walls with steel rebar, metal obstructions, and RF noise present significant obstacles to RFID system performance. Tagging lossy materials in these environments, such as metals and liquids, can also degrade the performance of RFID systems. In a previous paper [1] we simulated the RF-harsh conditions prevalent in these environments to evaluate UHF RFID system performance. In this paper, we utilize the same laboratory environment to measure RFID system performance when RF-harsh materials are tagged. These tests serve to examine the effect of water and plastic car parts on RFID system performance in an RF harsh environment. We show that the problems posed when tagging RF-harsh materials can be mitigated with either the strategic placement of tags on the item, or the careful choice of tags. While UHF RFID systems can be used in the presence of RF-harsh circumstances, the system architecture must be carefully tested in order to minimize the effects of performance-hindering RF obstacles.}, 
keywords={radiofrequency identification;radiowave propagation;RF-harsh materials;UHF RFID system;performance testing;radio frequency identification;radiowave propagation;Antennas;Belts;Materials;Metals;Radio frequency;Radiofrequency identification;RFID;UHF (Ultra High Frequency);automotive materials;liquids;manufacturing;materials testing;multipath;performance evaluation;radio;radiowave propagation}, 
doi={10.1109/RFID-TA.2011.6068597}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6180593, 
author={T. Sidhu and M. Kanabar and P. Parikh}, 
booktitle={2011 International Conference on Advanced Power System Automation and Protection}, 
title={Configuration and performance testing of IEC 61850 GOOSE}, 
year={2011}, 
volume={2}, 
number={}, 
pages={1384-1389}, 
abstract={The IEC 61850 standard part 8-1 proposes Generic Object Oriented Substation Event (GOOSE) message for time critical applications over the Ethernet network. In order to cover the wide range of applications and achieve flexibility in implementation, GOOSE messages are kept generic in the standard. However, this flexibility leads to configuration problem achieving multi-vendor interoperability. Therefore, some efforts have been carried out in this work to present a systematic GOOSE configuration approach, as well as, verification and performance testing of the GOOSE. First part of this paper configuration of Ethernet switched network, including IEEE 1588 based time synchronization, Rapid Spanning Tree Protocol (RSTP), and IEEE 802.1Q based Quality of Services (QoS). In the second part, the paper leads to step-by-step configuration process comprising IEC 61850 data modeling, datasets of GOOSE within individual IEDs, and system integration of GOOSE. Finally, the verification of configured GOOSE messages is presented using network analyzer tools, and performance testing time delay) over the network is carried out for various network scenarios.}, 
keywords={local area networks;object-oriented methods;open systems;power engineering computing;quality of service;substation automation;synchronisation;Ethernet switched network;IEC 61850 GOOSE performance testing;IEC 61850 data modeling;IEEE 1588 based time synchronization;IEEE 802.1Q based quality of services;QoS;RSTP;generic object oriented substation event message;multivendor interoperability;network analyzer tools;rapid spanning tree protocol;substation automation systems;systematic GOOSE configuration approach;Automation;Bridges;Data models;IEC standards;Power systems;Switches;Testing;Ethernet switched networks;GOOSE;IEC 61850;substation automation systems}, 
doi={10.1109/APAP.2011.6180593}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6526035, 
author={Y. Yao and X. Wang}, 
booktitle={Proceedings of 2012 2nd International Conference on Computer Science and Network Technology}, 
title={A distributed, cross-platform automation testing framework for GUI-driven applications}, 
year={2012}, 
volume={}, 
number={}, 
pages={723-726}, 
abstract={With the rapid development of computer technology, nowadays GUIs have been widely used in desktop applications and web applications. GUI-driven application testing is an emergent approach to software testing and plays a key role to assure software quality. This paper first discusses the various methods for testing GUI-driven applications, and then defines a GUI model and formally defines the test case and the test suite. Finally, it proposes a novel automated, distributed and cross-platform testing framework for GUI. Experiments conducted showed that the proposed testing architecture managed to use parallel cross-platform clusters to test heterogeneous applications whose technologies were incompatible with the testing framework.}, 
keywords={Internet;graphical user interfaces;program testing;software architecture;software quality;GUI model;GUI-driven application testing;Web applications;computer technology;cross-platform automation testing framework;desktop applications;distributed automation testing framework;graphical user interfaces;parallel cross-platform clusters;software quality assurance;software testing;test case;test suite;testing architecture;GUI-driven applications;automation testing;cross-platform testing;distributed testing framework}, 
doi={10.1109/ICCSNT.2012.6526035}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6885425, 
author={W. Naheman and Jianxin Wei}, 
booktitle={Proceedings 2013 International Conference on Mechatronic Sciences, Electric Engineering and Computer (MEC)}, 
title={Review of NoSQL databases and performance testing on HBase}, 
year={2013}, 
volume={}, 
number={}, 
pages={2304-2309}, 
abstract={NoSQL (Not Only SQL) is the generic term of a kind of non-relational database products. This paper, firstly, lists the disadvantages of traditional relational databases, introduces NoSQL databases including their advantages, disadvantages and their application status. Then, a comparison is made between NoSQL databases and SQL database, also another comparison between different NoSQL products. Finally, we introduce the architecture and data model of HBase database, which is a representative of NoSQL databases, and did some performance tests on HBase database, including the column family test, the sort test, the random read/write test and the query test. Test results show that written and query speed of HBase is slow under a single machine environment, but can be significantly improved in multimachine cluster environment.}, 
keywords={SQL;data models;relational databases;software performance evaluation;HBase database;HBase performance testing;NoSQL databases;Not Only SQL database;SQL database;column family test;data model;machine cluster environment;nonrelational database products;query test;random read-write test;single machine environment;sort test;Availability;Blogs;Computer architecture;Distributed databases;Manuals;HBase;NoSQL databases;performance testing;relational database}, 
doi={10.1109/MEC.2013.6885425}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{5632110, 
author={F. Kreit and G. Barberio and C. Subramanian and I. Kostanic and J. P. Pinelli}, 
booktitle={2010 First International Conference on Sensor Device Technologies and Applications}, 
title={Performance Testing of the Wireless Sensor Network System for Hurricane Monitoring}, 
year={2010}, 
volume={}, 
number={}, 
pages={63-72}, 
abstract={A wireless pressure monitoring system was developed by Florida Institute of Technology to measure wind induced pressure on low-rise structures during hurricanes. This study presents tests made to evaluate the performance of the sensors and their ability to measure accurate pressure variations. To test the reliability of the pressure sensors, a series of tests were designed. The resulting measurements were then compared to secondary references. The measurements were also compared to the basic Bernoulli theory. Further, the wind tunnel measurement allowed for the development of the first comparative computational fluid dynamics simulation and experimental results. Due to the components packaging in the remote, the sensor case cannot be completely streamlined. The resulting shape caused some aerodynamic disturbances. In order to study the sensor shape's influence on the pressure measurements, different experiments were set up. Specifically, by using a roof shaped ramp model mounted on a van, a highway test was performed, allowing examination of the error caused by the sensor's shape. Another test was performed at the University of Florida Hurricane Simulator to study the gust (unsteady) effects. This test revealed that the sensors were sensitive to mechanical vibrations. The paper addresses the sensor network systems topic of the conference.}, 
keywords={atmospheric measuring apparatus;atmospheric pressure;computational fluid dynamics;geophysical fluid dynamics;pressure measurement;pressure sensors;storms;wind;wireless sensor networks;Bernoulli theory;Florida Institute of Technology;University of Florida Hurricane Simulator;comparative CFD simulation;computational fluid dynamics;hurricane monitoring;low rise structures;pressure variation measurement;roof shaped ramp model;sensor case shape;sensor performance;wind induced pressure;wind tunnel measurement;wireless pressure monitoring system;wireless sensor network performance testing;Atmospheric measurements;Electron tubes;Fluid flow measurement;Pressure measurement;Sea measurements;Semiconductor device measurement;Wind speed;Multi-sensors;Performance testing;Wireless network}, 
doi={10.1109/SENSORDEVICES.2010.19}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{4588501, 
author={A. Habul and E. Kurtovic}, 
booktitle={ITI 2008 - 30th International Conference on Information Technology Interfaces}, 
title={Load testing an AJAX application}, 
year={2008}, 
volume={}, 
number={}, 
pages={729-732}, 
abstract={This paper presents a methodology for load testing an Ajax application. WebLOAD, an open source tool for performance testing, is used to simulate a huge number of client requests to the server. The load testing is used to evaluate and compare different scenarios on the system performance. In order to avoid misleading results, load testing of Ajax applications should incorporate not only server-side but also client-side code, because it can have a significant impact in determining the generated load.}, 
keywords={Java;XML;performance evaluation;program testing;public domain software;AJAX;WebLOAD;client- side code;load testing;open source tool;performance testing;server-side code;Databases;Delay;Frequency;HTML;Java;Load modeling;Network servers;System performance;System testing;XML;Ajax;load testing;workload model}, 
doi={10.1109/ITI.2008.4588501}, 
ISSN={1330-1012}, 
month={June},}
@ARTICLE{7234834, 
author={M. Hempel and J. W. Tomm and D. Venables and V. Rossin and E. Zucker and T. Elsaesser}, 
journal={Journal of Lightwave Technology}, 
title={Long-Term Aging and Quick Stress Testing of 980-nm Single-Spatial Mode Lasers}, 
year={2015}, 
volume={33}, 
number={21}, 
pages={4450-4456}, 
abstract={Single-spatial mode lasers emitting at 980 nm are studied during continuous-wave long-term operation and ultra-high power short-term operation (stress-test) up to 13.5 W. We find that both tests eventually activate the same degradation mechanism, namely internal catastrophic optical damage. In the case of ultra-high power operation, we show that the mechanism that initializes this effect is a lateral widening of the optical mode, resulting in increased absorption outside the waveguide. Defects formed during long-term aging may eventually lead to the same effect. Stress testing allows for activation of several degradation mechanisms in a device one after the other and for distinguishing between mechanisms induced by aging and independent ones. Stress tests could pave the way toward more time-efficient testing, e.g., for comparison of different technology variants in development.}, 
keywords={Aging;Cameras;Cavity resonators;Degradation;Monitoring;Optical pulses;Temperature measurement;Semiconductor device measurements;reliability;semiconductor diodes;semiconductor lasers},
doi={10.1109/JLT.2015.2475605}, 
ISSN={0733-8724}, 
month={Nov},}
@ARTICLE{206935, 
author={T. P. Parker and C. W. Webb}, 
journal={IEEE Transactions on Components, Hybrids, and Manufacturing Technology}, 
title={A study of failures identified during board level environmental stress testing}, 
year={1992}, 
volume={15}, 
number={6}, 
pages={1086-1092}, 
abstract={AT&T has investigated and implemented environmental stress testing (EST) in the production of a variety of circuit board designs as a means of reducing the incidence of early life failures. EST techniques include thermal cycling (TC), random vibration, etc. These techniques have proven more effective than traditional burn-in techniques. In addition, studies have revealed that functional monitoring during thermal stressing of circuit cards more than doubles the effectiveness of EST. Outgoing quality audits and customer first month failure rates have improved by factors of two to four since the implementation of EST}, 
keywords={environmental testing;failure analysis;life testing;printed circuit testing;quality control;AT&T;EST;board level environmental stress testing;burn-in techniques;circuit board designs;customer first month failure rates;early life failures;environmental stress testing;functional monitoring;outgoing quality audits;random vibration;study of failures;temperature cycling;thermal cycling;thermal stressing;Application software;Assembly;Circuit testing;Failure analysis;Human factors;Life testing;Manufacturing processes;Production;Thermal stresses;Total quality management}, 
doi={10.1109/33.206935}, 
ISSN={0148-6411}, 
month={Dec},}
@INPROCEEDINGS{5571539, 
author={T. Gao and Y. Ge and G. Wu and J. Ni}, 
booktitle={2010 Ninth International Symposium on Distributed Computing and Applications to Business, Engineering and Science}, 
title={A Reactivity-based Framework of Automated Performance Testing for Web Applications}, 
year={2010}, 
volume={}, 
number={}, 
pages={593-597}, 
abstract={To improve the reliability and feasibility of web applications, performance testing is very important for satisfying users. For reducing the cost and improve the efficiency of performance testing, we propose a new reactivity-based performance testing framework in this paper. We also provide a complete approach to generate test cases automatically from original web logs. First our approach retrieves user patterns through logs at the server side. Then, metrics derived from users' perspective are applied and usage pattern from client side are gained. At last test case can be generated automatically by solving an optimization problem through an evolutionary algorithm.}, 
keywords={Internet;automatic test pattern generation;client-server systems;evolutionary computation;performance evaluation;Web application;Web logs;automated reactivity-based performance testing framework;evolutionary algorithm;optimization problem;test case generation;user pattern retrieval;Load modeling;Measurement;Servers;Software;Testing;Time factors;Unified modeling language;automated test case generation;performance testing;testing framework;web applications}, 
doi={10.1109/DCABES.2010.127}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{4017687, 
author={N. Stankovic}, 
booktitle={2006 IEEE International Conference on Electro/Information Technology}, 
title={Patterns and Tools for Performance Testing}, 
year={2006}, 
volume={}, 
number={}, 
pages={152-157}, 
abstract={The growth of software applications in size and complexity is being followed by a number of specific nonfunctional requirements such as portability, interoperability, and availability on various platforms. Most often, these have been addressed by middleware or programming environment. In addition, easy customizability, adaptability, and sharing of components facilitates the development cycle. These should be understood and applied in a broader sense, i.e. to byproducts created during the development process such as programs for functional and performance testing. Much time is spent on developing test programs but their quality and quality of thus obtained results varies largely if the process is not standardized and automated. In this paper we present our experience with performance testing of a large scale suite of gateways that are used for the seamless integration of heterogeneous communication networks. We analyze the commercial and public domain tools for load generation and motivate our decision to define an in-house framework and build a distributed tool for performance, testing that is also not restricted by licensing issues and is readily available to everyone involved. Our tool is built on Visper, the object-oriented distributed programming middleware. The suitability and adaptability of the Visper model for rapid application development and the quality of produced result have proven our decision correct}, 
keywords={distributed programming;middleware;object-oriented programming;program testing;software prototyping;Visper;distributed tool;heterogeneous communication networks;large scale gateways suite;load generation;nonfunctional requirements;object-oriented distributed programming middleware;software applications;software engineering;software testing;software tools;test programs;Application software;Automatic testing;Availability;Communication networks;Large scale integration;Licenses;Middleware;Object oriented programming;Performance analysis;Programming environments;Software testing;software engineering;software tools}, 
doi={10.1109/EIT.2006.252109}, 
ISSN={2154-0357}, 
month={May},}
@ARTICLE{6313588, 
author={M. R. Dhote and G. G. Sarate}, 
journal={IEEE Software}, 
title={Performance Testing Complexity Analysis on Ajax-Based Web Applications}, 
year={2013}, 
volume={30}, 
number={6}, 
pages={70-74}, 
abstract={The Ajax model of Web applications development has rapidly gained popularity because it promises to bring the richness and responsiveness of desktop applications to the Web. Ajax implementations differ fundamentally from other Web implementations - mainly in making asynchronous requests for parts of a Webpage. Techniques routinely used for performance testing traditional Web applications must be modified and enhanced to suit the needs of Ajax-based applications. Using a general example, the authors of this article examine the unique challenges of carrying out performance testing for Ajax-based applications and offer approaches and tools for overcoming them.}, 
keywords={Internet;program testing;software metrics;Ajax-based Web applications;Webpage;performance testing complexity analysis;Browsers;Complexity theory;Internet;Servers;Software measurement;Statistical analysis;Testing;Ajax;performance testing;performance testing and tools;software quality and testing;stress testing}, 
doi={10.1109/MS.2012.132}, 
ISSN={0740-7459}, 
month={Nov},}
@INPROCEEDINGS{7377639, 
author={P. Brčić}, 
booktitle={2015 23rd Telecommunications Forum Telfor (TELFOR)}, 
title={Performance testing of EMC xtremio all-flash storage system}, 
year={2015}, 
volume={}, 
number={}, 
pages={1020-1023}, 
abstract={EMC XtremIO is one of the most advanced all-Flash data storage systems which is becoming an integral part of medim and enterprise data centers. The paper represents implementation of EMC XtremIO storage system for VDI, and adopted, implemented and validated methodology for testing performance of storage systems. There were generated and released three groups of different intense load tests, during which the data was collected, created tables and graphs. Finally was generated detailed analysis of the results.}, 
keywords={flash memories;program testing;EMC XtremIO all-flash storage system;load tests;storage system testing performance;Electromagnetic compatibility;Monitoring;Optical fiber testing;Servers;Synthetic aperture sonar;Virtual machining;All-Flash;XtremIO;data centri;performanse;sistem za skladi¿¿tenje podataka}, 
doi={10.1109/TELFOR.2015.7377639}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{5486954, 
author={J. l. Tang and Y. j. Liu and F. s. Wu}, 
booktitle={2010 2nd International Conference on Advanced Computer Control}, 
title={Virtual experiment system for metal creep performance testing based on VRML}, 
year={2010}, 
volume={4}, 
number={}, 
pages={140-143}, 
abstract={A virtual experiment system for metal creep performance testing is built by virtual reality modeling language (VRML). The structure, function and design principles of the system are described and its implementation procedure is also discussed. The key development process, including object modeling, 3D scene building, VRML connecting to the real-time database, design of interactive virtual 3D scene and complex virtual interaction, is illustrated in this paper. In addition, the following key problems have been solved during the system realization: virtual models building and geometrical transforming, database designing and optimizing, 3D virtual experimental scenes combining dynamically, the realization of database accessing and the communication of virtual entities.}, 
keywords={computer testing;database management systems;human computer interaction;virtual reality languages;3D scene building;complex virtual interaction;geometrical transforming;interactive virtual 3D scene;metal creep performance testing;object modeling;real time database;virtual entities;virtual experiment system;virtual reality modeling language;Buildings;Communication system control;Computer simulation;Creep;Instruments;Layout;Spatial databases;System testing;Virtual environment;Virtual reality;VRML;creep performance test;metal;virtual experiment}, 
doi={10.1109/ICACC.2010.5486954}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{7780234, 
author={L. Dong and X. Jing and Y. Chunhui}, 
booktitle={2016 Third International Conference on Trustworthy Systems and their Applications (TSA)}, 
title={Study of Performance Testing of Information System Based on Domestic CPU and OS}, 
year={2016}, 
volume={}, 
number={}, 
pages={112-116}, 
abstract={In order to evaluate the performance of of information system based on domestic CPU and OS, through the introduction of the background of basic hardware and software based on domestic, we expound the domestic information system performance testing principle and method, according to the testing results of existing mature commercial performance testing tool LoadRunner can not reflect the user experience of time, and can not be directly used for testing the information system which based on domestic CPU/OS, this paper put forward the two kinds of testing schemes that base on user experience of LoadRunner and JMeter domestic information system performance test, and test two kinds of improved schemes, through the comparison of the test data and the user experience time of the two schemes, the variance of the test scheme based on JMeter is smaller than LoadRunner test scheme 70.49%. The results show that the test results of the JMeter scheme are more close to the user experience than LoadRunner.}, 
keywords={information systems;microprocessor chips;operating systems (computers);performance evaluation;JMeter domestic information system performance test;LoadRunner domestic information system performance test;OS;domestic CPU;domestic information system performance testing method;domestic information system performance testing principle;performance evaluation;Browsers;Hardware;Information systems;Operating systems;Rendering (computer graphics);Servers;Testing;JMeter test tool;LoadRunner test tool;domestic CPU;domestic infrastructure software;domistic Operating System(OS);information system;performance test}, 
doi={10.1109/TSA.2016.27}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6413663, 
author={M. Yan and H. Sun and X. Wang and X. Liu}, 
booktitle={2012 IEEE 18th International Conference on Parallel and Distributed Systems}, 
title={WS-TaaS: A Testing as a Service Platform for Web Service Load Testing}, 
year={2012}, 
volume={}, 
number={}, 
pages={456-463}, 
abstract={Web services are widely known as the building blocks of typical service oriented applications. The performance of such an application system is mainly dependent on that of component web services. Thus the effective load testing of web services is of great importance to understand and improve the performance of a service oriented system. However, existing Web Service load testing tools ignore the real characteristics of the practical running environment of a web service, which leads to inaccurate test results. In this work, we present WS-TaaS, a load testing platform for web services, which enables load testing process to be as close as possible to the real running scenarios. In this way, we aim at providing testers with more accurate performance testing results than existing tools. WS-TaaS is developed on the basis of our existing Cloud PaaS platform: Service4All. First, we briefly introduce the functionalities and main components of Service4All. Second, we provide detailed analysis of the requirements of Web Service load testing and present the conceptual architecture and design of key components. Third, we present the implementation details of WS-TaaS on the basis of Service4All. Finally, we perform a set of experiments based on the testing of real web services, and the experiments illustrate that WS-TaaS can efficiently facilitate the whole process of Web Service load testing. Especially, comparing with existing testing tools, WS-TaaS can obtain more effective and accurate test results.}, 
keywords={Web services;cloud computing;performance evaluation;program testing;service-oriented architecture;Service4All;WS-TaaS;Web service load testing tools;building blocks;cloud PaaS platform;component Web services;service oriented applications;service oriented system performance;testing as a service platform;Cloud computing;Monitoring;Runtime;Testing;cloud computing;load testing;testing as a service;web services}, 
doi={10.1109/ICPADS.2012.69}, 
ISSN={1521-9097}, 
month={Dec},}
@ARTICLE{1413639, 
author={A. Helmy and S. Gupta}, 
journal={IEEE Communications Letters}, 
title={FOTG: fault-oriented stress testing of IP multicast}, 
year={2005}, 
volume={9}, 
number={4}, 
pages={375-377}, 
abstract={Network simulators provide a useful tool, for protocol evaluation. However, the results depend heavily on the simulated scenarios, especially for complex protocols such as multicast. There has been little work on scenario generation. In this work we present a fault-oriented test generation (FOTG) algorithm for automated stress testing of multicast protocols. FOTG processes an extended FSM model and uses a mix of forward and backward search techniques. Unlike traditional verification approaches, instead of starting from initial states, FOTG starts from a fault and uses cause-effect relations for automatic topology synthesis then uses backward implication to generate tests. Using FOTG we test various mechanisms commonly employed by multicast routing and validate our results through simulation.}, 
keywords={IP networks;multicast protocols;routing protocols;search problems;telecommunication network topology;FOTG algorithm;FSM model;IP multicast routing;automated stress testing;backward search technique;fault-oriented test generation;forward search technique;network simulator;protocol evaluation;topology synthesis;traditional verification approach;Automatic testing;Engines;Multicast algorithms;Multicast protocols;Robustness;Routing protocols;Stress;System testing;Topology;Very large scale integration}, 
doi={10.1109/LCOMM.2005.1413639}, 
ISSN={1089-7798}, 
month={April},}
@INPROCEEDINGS{7591820, 
author={A. Dinh and F. M. Bui and T. Nguyen}, 
booktitle={2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, 
title={An accelerometer based system to measure myocardial performance index during stress testing}, 
year={2016}, 
volume={}, 
number={}, 
pages={4877-4880}, 
abstract={Stress testing is used to measure the performance of the heart in an elevated stress state, in order to monitor or diagnose certain heart problems. Many measurements can be used to determine the performance of the heart, with the Tei index being the measurement of interest in this work. The Tei index has been used as a reliable method to evaluate systolic and diastolic performance, as it overcomes some limitations of the classical echocardiographic indices. It is calculated based on the time intervals derived from echocardiography. This paper presents an exploratory study, which uses an accelerometer to record mechanical events occurring in each cardiac cycle, also known as the seismocardiogram (SCG). From timing measurements corresponding to various events in the heart, a metric for myocardial performance is calculated based on the Tei index. The use of SCG in addition to ECG has the potential to provide further insights about the heart during stress testing, since the SCG quantifies mechanical actions of the heart.}, 
keywords={accelerometers;biomedical equipment;electrocardiography;ECG;Tei index;accelerometer based system;cardiac cycle;diastolic performance;heart problem diagnosis;mechanical events;myocardial performance index measurements;seismocardiogram;stress state;stress testing;systolic performance;timing measurements;Accelerometers;Electrocardiography;Heart;Indexes;Sensors;Stress;Valves;Accelerometry;Diastole;Echocardiography;Exercise Test;Female;Heart;Heart Function Tests;Humans;Male;Systole;Wireless Technology}, 
doi={10.1109/EMBC.2016.7591820}, 
ISSN={1557-170X}, 
month={Aug},}
@ARTICLE{8085385, 
author={P. Fang and X. Ma and X. Li and X. Qiu and R. Gerhard and X. Zhang and G. Li}, 
journal={IEEE Sensors Journal}, 
title={Fabrication, Structure Characterization, and Performance Testing of Piezoelectret-Film Sensors for Recording Body Motion}, 
year={2018}, 
volume={18}, 
number={1}, 
pages={401-412}, 
abstract={During muscle contractions, radial-force distributions are generated on muscle surfaces due to muscle-volume changes, from which the corresponding body motions can be recorded by means of so-called force myography (FMG). Piezo-or ferroelectrets are flexible piezoelectric materials with attractive materials and sensing properties. In addition to several other applications, they are suitable for detecting force variations by means of wearable devices. In this paper, we prepared piezoelectrets from cellular polypropylene films by optimizing the fabrication procedures, and developed an FMG-recording system based on piezoelectret sensors. Different hand and wrist movements were successfully detected on able-bodied subjects with the FMG system. The FMG patterns were evaluated and identified by means of linear discriminant analysis and artificial neural network algorithms, and average motion-classification accuracies of 96.1% and 94.8%, respectively, were obtained. This paper demonstrates the feasibility of using piezoelectret-film sensors for FMG and may thus lead to alternative methods for detecting body motion and to related applications, e.g., in biomedical engineering or structural-health monitoring.}, 
keywords={biomedical measurement;biomedical transducers;cellular biophysics;computerised instrumentation;electrets;force measurement;force sensors;medical computing;motion measurement;muscle;neural nets;piezoelectric thin films;piezoelectric transducers;polymer films;polymer foams;recorders;thin film sensors;FMG-recording system;artificial neural network algorithm;biomedical engineering;body motion detection;body motion recording;cellular polypropylene film;ferroelectret;force myography;force sensor;linear discriminant analysis;muscle contraction;muscle surface generation;performance testing;piezoelectret-film sensor;piezoelectric material;radial-force distribution;structural-health monitoring;structure characterization;wearable device;Accelerometers;Dynamics;Electrodes;Films;Force;Muscles;Sensors;Forcemyography;film sensor;motion registration;piezoelectret;wearable}, 
doi={10.1109/JSEN.2017.2766663}, 
ISSN={1530-437X}, 
month={Jan},}
@INPROCEEDINGS{7515456, 
author={R. Gao and Z. M. Jiang and C. Barna and M. Litoiu}, 
booktitle={2016 IEEE International Conference on Software Testing, Verification and Validation (ICST)}, 
title={A Framework to Evaluate the Effectiveness of Different Load Testing Analysis Techniques}, 
year={2016}, 
volume={}, 
number={}, 
pages={22-32}, 
abstract={Large-scale software systems like Amazon and eBay must be load tested to ensure they can handle hundreds and millions of current requests in the field. Load testing usually lasts for a few hours or even days and generates large volumes of system behavior data (execution logs and counters). This data must be properly analyzed to check whether there are any performance problems in a load test. However, the sheer size of the data prevents effective manual analysis. In addition, unlike functional tests, there is usually no test oracle associated with a load test. To cope with these challenges, there have been many analysis techniques proposed to automatically detect problems in a load test by comparing the behavior of the current test against previous test(s). Unfortunately, none of these techniques compare their performance against each other. In this paper, we have proposed a framework, which evaluates and compares the effectiveness of different test analysis techniques. We have evaluated a total of 23 test analysis techniques using load testing data from three open source systems. Based on our experiments, we have found that all the test analysis techniques can effectively build performance models using data from both buggy or non-buggy tests and flag the performance deviations between them. It is more cost-effective to compare the current test against two recent previous test(s), while using testing data collected under longer sampling intervals (≥180 seconds). Among all the test analysis techniques, Control Chart, Descriptive Statistics and Regression Tree yield the best performance. Our evaluation framework and findings can be very useful for load testing practitioners and researchers. To encourage further research on this topic, we have made our testing data publicity available to download.}, 
keywords={control charts;large-scale systems;program testing;public domain software;regression analysis;statistics;trees (mathematics);Amazon;control chart;descriptive statistics;eBay;large-scale software systems;load testing analysis;open source systems;regression tree;Data mining;Data models;Load modeling;Queueing analysis;Radiation detectors;Testing;Topology}, 
doi={10.1109/ICST.2016.9}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{6281507, 
author={J. P. H. Knauss and C. Warren and D. Kearns}, 
booktitle={PES T D 2012}, 
title={An innovative approach to smart automation testing at National Grid}, 
year={2012}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={Upon completion of a successful Distribution Automation (DA) Pilot Project centered in National Grid's upstate New York service territory, it was determined that the reliability improvements delivered by the pilot demonstration justified a much more comprehensive effort to further evaluate additional Smart Grid technologies. The vision was to conduct experiments with a full suite of Smart Grid technologies including: AMI; Home Area Network and energy management systems; Automatic Fault Isolation & System Restoration; advanced feeder monitoring; distribution transformer monitoring; single pole tripping and Pulse Closing technology on distribution line reclosers; advanced capacitor control with independent pole operation; faulted circuit indicators with 2-way communication capability; and distribution fault locating capability. This vision came to be known as National Grid's Smart Grid Pilot proposal. Many challenges exist with such a comprehensive approach from public and personnel safety, to ensuring interoperability between devices and systems of different manufacture. In order to determine which technologies would provide the most benefit to National Grid's customer base, a means was needed to prequalify the various types of products available before large scale deployments were initiated. Looking at the large number of Smart Grid device suppliers, architectures and products available, we realized that the optimum solution would be to build a facility wherein a wide range of Smart Grid technologies could be installed and systematically put through their paces; i.e. actually tested in as near a real-world atmosphere as practical. Thus was born the National Grid “Smart Technology Centre” or STC. Soon thereafter, National Grid's Utility of the Future engineering team designed, engineered, and constructed a truly innovative test fixture that enabled system level testing on complex distribution networks to ensure process safety during field de- loyment. One of only a few known organizations in the U.S., National Grid has in-house capability to truly test and evaluate an end-to-end Smart distribution system architecture where systems such as automated fault isolation and system restoration can be evaluated. This paper will discuss interoperability testing that National Grid embarked upon to prepare for its proposed Smart Grid Pilot demonstration and will detail the lengths that were taken in creating a test site where medium voltage Smart Grid technologies could be fully evaluated to ensure that the various applications would play well with each other prior to actually being deployed in the field. Furthermore, this paper will focus on providing an overview of the system level testing and technical evaluation of distribution protection and control equipment with automated fault isolation and system restoration capabilities. It will also detail a number of lessons learned from this effort and discuss future plans for smart technology evaluation as a basis for an educational platform and workforce training tool.}, 
keywords={automatic testing;control equipment;electrical safety;fault location;open systems;power distribution control;power distribution protection;power distribution reliability;power engineering computing;power system restoration;smart power grids;2-way communication capability;AMI;DA Pilot Project;National Grid;New York service territory;STC;Smart Technology Centre;advanced capacitor control;advanced feeder monitoring;automatic fault isolation;automatic system restoration;complex distribution network testing;control equipment;distribution automation;distribution fault locating capability;distribution line reclosers;distribution protection;distribution transformer monitoring;educational platform;end-to-end smart distribution system architecture;energy management systems;faulty circuit indicators;home area network;interoperability;large scale deployments;medium voltage smart grid technologies;personnel safety;process safety;public safety;pulse closing technology;reliability improvements;single pole tripping;smart automation testing;smart grid device suppliers;smart grid pilot demonstration;smart technology evaluation;system level testing;workforce training tool;Automation;Circuit faults;Control systems;Monitoring;Safety;Smart grids;Testing}, 
doi={10.1109/TDC.2012.6281507}, 
ISSN={2160-8555}, 
month={May},}
@INPROCEEDINGS{5635852, 
author={Y. Liu and B. Du and S. Wang and H. Yang and X. Wang}, 
booktitle={2010 First International Conference on Pervasive Computing, Signal Processing and Applications}, 
title={Design and Implementation of Performance Testing Utility for RTSP Streaming Media Server}, 
year={2010}, 
volume={}, 
number={}, 
pages={193-196}, 
abstract={RTSP has been widely used in a variety of streaming media applications and streaming service providers hope to choose a high-performance streaming media server to meet their needs, so it is an important research topic about how to evaluate the serving performance of RTSP streaming media server. This paper analyzes the performance metric of streaming media applications comprehensively, and proposes an approach to design and implement a Performance Testing Utility for RTSP Streaming Server. According to different stress test, the utility mainly evaluates a streaming server's performance in the case of delivering a large number of concurrent streams and quantifies the statistics of various performance metrics. The tool utilizes multi-thread mechanism to create multiple pseudo-terminal instances to simulate a certain number of concurrent users for sending RTSP signals, receives media flow by a special IP address, analyzes RTP packets, and counts the related performance metrics value of the server. Experiments validate the efficiency and accuracy of the tool.}, 
keywords={media streaming;multi-threading;multimedia servers;performance evaluation;protocols;IP address;RTP packets;RTSP streaming media server;multiple pseudo-terminal instances;multithread mechanism;performance metric;performance testing utility;real-time streaming protocol;streaming server performance evaluation;streaming service providers;Measurement;Media;Protocols;Real time systems;Servers;Streaming media;Testing;Concurrent streams;Media flow;Performance metrics;Streaming media server;Testing utility}, 
doi={10.1109/PCSPA.2010.55}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{7793853, 
author={F. Schloegl and M. Buescher and K. Diwold and S. Lehnhoff and L. Fischer and F. Zeilinger and T. Gawron-Deutsch}, 
booktitle={IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society}, 
title={Performance testing Smart Grid applications using a distributed co-simulation approach}, 
year={2016}, 
volume={}, 
number={}, 
pages={6305-6310}, 
abstract={Co-simulation is an established approach for Smart Grid simulations as it allows to break down the very complex system into sub-systems. The modularity of co-simulation environments makes easy to distribute it across different sites. One reason for such a distribution may be, that this way confidential software can stay within its secure domain. However the transmission of data between the sites is time consuming. This paper demonstrates how Smart Grid applications can be tested using a co-simulation approach. It investigates the costs of such an approach by measuring the time required for data transmission in a case study.}, 
keywords={data communication;power system security;smart power grids;data transmission;distributed cosimulation;smart grid;Computational modeling;Data models;Hardware;Load modeling;Smart grids;Software;Topology}, 
doi={10.1109/IECON.2016.7793853}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6958400, 
author={J. Zhou and B. Zhou and S. Li}, 
booktitle={2014 14th International Conference on Quality Software}, 
title={LTF: A Model-Based Load Testing Framework for Web Applications}, 
year={2014}, 
volume={}, 
number={}, 
pages={154-163}, 
abstract={Performance evaluation is an important approach for various systems to guarantee the quality of their services. However, most performance evaluation tasks face a problem: how to model the system workload? Traditional workload models have limitations when it comes to modeling different workloads. In this paper, we propose a workload model for characterizing and generating synthetic web workloads. First, we introduce a Context-based Sequential Action Model to describe users that exhibit similar access patterns. Next, we present a Workload Parameter Specification Language to describe workload parameters for workload generation. Then, we introduce our load-testing framework based on the proposed model. The representativeness and features of our model are demonstrated by comparing it to other models. Experiments show that our framework can generate accurate and stable synthetic workloads.}, 
keywords={Internet;software performance evaluation;specification languages;LTF;Web applications;context-based sequential action model;model-based load testing framework;performance evaluation;synthetic Web workloads;workload generation;workload model;workload parameter specification language;Computational modeling;Context;Context modeling;Load modeling;Testing;Unified modeling language;load testing;model;performance;workload characterization}, 
doi={10.1109/QSIC.2014.53}, 
ISSN={1550-6002}, 
month={Oct},}
@INPROCEEDINGS{524640, 
author={K. Roy and R. K. Roy and A. Chatterjee}, 
booktitle={1995 International Symposium on VLSI Technology, Systems, and Applications. Proceedings of Technical Papers}, 
title={Stress testing of combinational VLSI circuits using existing test sets}, 
year={1995}, 
volume={}, 
number={}, 
pages={93-98}, 
abstract={We present a stress testing method which can provide an attractive low-cost alternative to burn-in. The technique is based on reordering of test vectors such that a desired circuit activity or electrical stress is generated across the VLSI chip while achieving a high coverage for stuck-at defects. The test methodology can also be used to generate localized electrical or thermal stress in a circuit. Such testing procedure can be important for weeding out circuits with infant mortality problems. Experimental results on benchmark circuits show that the stress requirements can be changed by more than a factor of 4 by reordering the stuck-at test vectors}, 
keywords={CMOS logic circuits;VLSI;combinational circuits;integrated circuit testing;integrated logic circuits;logic testing;combinational VLSI circuits;infant mortality problems;localized electrical stress;localized thermal stress;stress testing method;stuck-at defects;test vectors reordering;Circuit faults;Circuit testing;Costs;Current density;Monitoring;National electric code;Ovens;Temperature;Thermal stresses;Very large scale integration}, 
doi={10.1109/VTSA.1995.524640}, 
ISSN={1524-766X}, 
month={May},}
@INPROCEEDINGS{7436040, 
author={A. Shojaee and N. Agheli and B. Hosseini}, 
booktitle={2015 2nd International Conference on Knowledge-Based Engineering and Innovation (KBEI)}, 
title={Cloud-based load testing method for web services with VMs management}, 
year={2015}, 
volume={}, 
number={}, 
pages={170-176}, 
abstract={Due to the increased loading the large number of users connected to pervasive web services during the past decade, their load testing and providing the needed resources in low time and cost, requires more attention. In this context cloud computing technology offers new ideas to solve such problems and has reduced the concern of large and complex testing systems. In this research in order to improve the quality and performance of web applications load testing, we proposed a method for web applications load testing based on cloud computing. The proposed method uses the existing facilities in the cloud including pool of computing resources without initial cost, unlimited data storage and cloud computing managerial procedures, containing the actual load generating and multi-user concurrency testing, that lead to improved load testing flexibility, time and operational costs. Moreover, in this load testing method, in order to manage resources and virtual machines, significant improvement is achieved by use of appropriate allocation, reducing performance and unnecessary migration avoiding methods. Through evaluation section of the proposed method through a simulated test environment, it is shown that cloud-based load testing in comparison with traditional methods of load testing, improves factors such as effort, cost and time.}, 
keywords={Web services;cloud computing;program testing;resource allocation;ubiquitous computing;virtual machines;VM management;Web applications load testing performance;Web applications load testing quality;cloud computing technology;cloud-based load testing method;computing resources pool;load generation;multiuser concurrency testing;pervasive Web services;resource management;virtual machines;Cloud computing;Decision support systems;Handheld computers;Systems architecture;Testing;Virtual machining;Cloud Computing;Load Testing;VMs;Web Service}, 
doi={10.1109/KBEI.2015.7436040}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{367502, 
author={H. A. Chan}, 
booktitle={1994 Proceedings. 44th Electronic Components and Technology Conference}, 
title={A formulation to optimize stress testing}, 
year={1994}, 
volume={}, 
number={}, 
pages={1020-1027}, 
abstract={Although hard-defects may be detectable in factory tests, weak products may exhibit failures or degrade only under certain stress conditions. Without stress testing, these weak products may often be shipped to customers causing early failures in the field. A candidate product for stress testing needs to get more business benefits to more than pay off the cost of stress testing. A business measure of the success of the stress testing program is the net benefit, which is the total benefit minus the total cost of the program. The optimum stress testing program maximizes this net benefit. A given unit of a product has a probability of encountering a maximum stress X during its product life. It also has a probability of possessing a product yield strength Y, which is the maximum stress the unit can survive without failure. While the strength distribution depends on the design and manufacture processes, the distribution of the maximum stress is determined by the customers' environment. A convenient picture is to construct the contour map of the joint probability distribution of X and Y. In this contour map, a unit falling in the Y<X region will fail during its product life, whereas one falling in the Y>X region will not result in field failure. The effects of stress testing at a given maximum stress level, XST, are shown by a dividing line on the product strength into stress test failure and stress test pass. The units in the contour map are then divided into four regions by the Y=X line and the XST line. The cost and benefits may now be evaluated for each region. Now the value of XST is a free parameter that determines the relative size of each region. The second free parameter is the fraction of units going through stress testing. These two parameters may be adjusted to maximize the net benefit of the stress testing program}, 
keywords={circuit optimisation;environmental stress screening;environmental testing;failure analysis;integrated circuit yield;life testing;probability;production testing;contour map;early failures;factory tests;joint probability distribution;maximum stress;net benefit;product life;product yield strength;stress conditions;stress test failure;stress test pass;stress testing;Circuit testing;Costs;Degradation;Electronic equipment testing;Manufacturing processes;Probability distribution;Process design;Production facilities;Stress measurement;System testing}, 
doi={10.1109/ECTC.1994.367502}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{5325380, 
author={H. Kim and B. Choi and W. E. Wong}, 
booktitle={2009 Third IEEE International Conference on Secure Software Integration and Reliability Improvement}, 
title={Performance Testing of Mobile Applications at the Unit Test Level}, 
year={2009}, 
volume={}, 
number={}, 
pages={171-180}, 
abstract={With the rapid growth of the wireless market and the development of various mobile devices, innovative methods and technologies to produce high-quality mobile applications and reduce time to market have been emerging. Mobile applications are often characterized by an array of limitations such as the short development lifecycle to gain a competitive advantage and difficulties to update once released. Hence, rigorous testing on the applications is required before distribution to the market, including structural white-box, functional black-box, integration and system testing. Although recently performance testing at the system test level has become crucial given its direct connection with the product quality improvement, most such tests are confined to the areas of load, usability, and stress testing. Moreover, the implementation itself is insufficient due to the limitations of the development environment. This paper proposes a method to support performance testing utilizing a database established through benchmark testing in emulator-based test environment at the unit test level. It also presents the tool that supports the proposed method of performance testing and verifies the reliability of performance test results through experiments.}, 
keywords={integrated software;program testing;emulator-based test environment;functional black-box;integration;mobile applications;performance testing;structural white-box;system testing;unit test level;wireless market;Application software;Benchmark testing;Computer science;Databases;Mobile computing;Process control;Software performance;Software testing;Stress;System testing;emulator-based test;mobile application;performance test;unit test}, 
doi={10.1109/SSIRI.2009.28}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{929479, 
author={L. Angrisani and A. Baccigalupi and G. D'Angiolo}, 
booktitle={IMTC 2001. Proceedings of the 18th IEEE Instrumentation and Measurement Technology Conference. Rediscovering Measurement in the Age of Informatics (Cat. No.01CH 37188)}, 
title={A frame-level measurement apparatus for performance testing of ATM equipment}, 
year={2001}, 
volume={3}, 
number={}, 
pages={1630-1635 vol.3}, 
abstract={Performance testing of ATM equipment is here dealt with. In particular, the attention is paid to frame-level metrics, recently proposed by the ATM forum because of their suitability to reflect user-perceived performance better than traditional cell-level metrics. Following the suggestions of the ATM forum, more and more network engineers and production managers are nowadays interested in these metrics, thus increasing the need of instruments and measurement solutions appropriate to their estimation. Trying to satisfy this exigency, a new VXI-based measurement apparatus is proposed in the paper. The apparatus features a suitable software, developed by the authors, which allows the evaluation of the aforementioned metrics by making simply use of common ATM analyzers; only two VXI line interfaces, capable of managing both the physical and ATM layer, are, in fact, adopted. At first, some details about the hierarchical structure of the ATM technology as used as the main differences between frames, peculiar to the ATM adaptation layer, and cells characterizing the lower ATM layer are given. Then, both the hardware and software solutions of the measurement apparatus are described in detail with a particular attention to the measurement procedures implemented. At the end the performance of a new ATM device, developed by Ericsson, is assessed in terms of frame-level metrics by means of the proposed apparatus}, 
keywords={asynchronous transfer mode;automatic test equipment;performance evaluation;peripheral interfaces;telecommunication equipment testing;ATM adaptation layer;ATM equipment;Ericsson;VXI line interfaces;VXI-based measurement apparatus;common ATM analyzers;frame-level measurement;frame-level metrics;hardware;hierarchical structure;performance testing;software;user-perceived performance;3G mobile communication;Asynchronous transfer mode;B-ISDN;Communication switching;GSM;Particle measurements;Quality of service;Software measurement;Telecommunication switching;Testing}, 
doi={10.1109/IMTC.2001.929479}, 
ISSN={1091-5281}, 
month={},}
@INPROCEEDINGS{4297593, 
author={V. Yakovyna and D. Fedasyuk and M. Seniv and O. Bilas}, 
booktitle={2007 9th International Conference - The Experience of Designing and Applications of CAD Systems in Microelectronics}, 
title={The Performance Testing of RSA Algorithm Software Realization}, 
year={2007}, 
volume={}, 
number={}, 
pages={390-392}, 
abstract={The software realization of RSA public key encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested. The present paper shows, that the encryption rate is 306.4 plusmn 0.6 kbytes/sec, while the coefficient of encryption time increasing with file size increasing is 3.299. It is concluded that the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.}, 
keywords={application program interfaces;network operating systems;public key cryptography;.NET platform;CryptoAPI;RSA algorithm software realization;RSA public key encryption algorithm;coefficient-of-encryption time;cryptographic software;encryption rate;flexible architecture independent tool;public-key cryptography;secure implementation;Algorithm design and analysis;Application software;Costs;Hardware;Public key;Public key cryptography;Software algorithms;Software performance;Software quality;Software testing;.NET;Operation performance;Public-key cryptography;RSA algorithm;Software realization}, 
doi={10.1109/CADSM.2007.4297593}, 
ISSN={}, 
month={Feb},}
@INPROCEEDINGS{4639351, 
author={A. Bertolino and G. De Angelis and A. Sabetta}, 
booktitle={2008 23rd IEEE/ACM International Conference on Automated Software Engineering}, 
title={VCR: Virtual Capture and Replay for Performance Testing}, 
year={2008}, 
volume={}, 
number={}, 
pages={399-402}, 
abstract={This paper proposes a novel approach to performance testing, called virtual capture and replay (VCR), that couples capture and replay techniques with the checkpointing capabilities provided by the latest virtualization technologies. VCR enables software performance testers to automatically take a snapshot of a running system when certain critical conditions are verified, and to later replay the scenario that led to those conditions. Several in-depth analyses can be separately carried out in the laboratory just by rewinding the captured scenario and replaying it using different probes and analysis tools.}, 
keywords={program testing;virtual reality;VCR;checkpointing capabilities;software performance testing;virtual capture;virtual replay;virtualization technologies;Automatic testing;Checkpointing;Monitoring;Paper technology;Performance analysis;Software performance;Software testing;Space technology;System testing;Video recording}, 
doi={10.1109/ASE.2008.58}, 
ISSN={1938-4300}, 
month={Sept},}
@INPROCEEDINGS{4297591, 
author={V. Yakovyna and D. Fedasyuk and M. Seniv}, 
booktitle={2007 9th International Conference - The Experience of Designing and Applications of CAD Systems in Microelectronics}, 
title={Software Realization and Performance Testing of DES Cryptographic Algorithm on the .NET Platform}, 
year={2007}, 
volume={}, 
number={}, 
pages={386-388}, 
abstract={The software realization of DES symmetric encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested and it was shown, that the encryption rate is 11.1 Mb/sec on the Intel Celeron D 351 3.2 GHz processor, while the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.}, 
keywords={computer software;cryptography;.NET platform;DES symmetric encryption algorithm;Intel Celeron D 351 3.2 GHz processor;data encryption standard;software implementation;software realization;Algorithm design and analysis;Application software;Cryptography;Hardware;Protection;Software algorithms;Software performance;Software quality;Software testing;Software tools;.NET;CryptoAPI;DES algorithm;Software realization;Symmetric cryptography}, 
doi={10.1109/CADSM.2007.4297591}, 
ISSN={}, 
month={Feb},}
@INPROCEEDINGS{5777983, 
author={Zhang Xinfeng and Shen Yong and SongGe}, 
booktitle={2011 International Conference on Electric Information and Control Engineering}, 
title={Stress testing on car remote monitoring system}, 
year={2011}, 
volume={}, 
number={}, 
pages={1715-1718}, 
abstract={A virtual on-board concurrent user based remote monitoring system stress testing method is proposed. First, the scenario of maximum concurrent users is obtained through system analysis and the method is proposed. Second, the virtual on-board concurrent users are realized by computer data generation and coding according to package protocol. Finally, a case study of stress testing is done. It is turned out that the remote monitoring system's performance can be effectively evaluated by such test method, and the maximum number of concurrent users also can be predicted.}, 
keywords={automobile industry;automotive engineering;computerised monitoring;mechanical engineering computing;stress analysis;car remote monitoring system;computer data coding;computer data generation;package protocol;stress testing method;system analysis;virtual on-board concurrent user;Real time systems;Remote monitoring;Servers;Software;Stress;Testing;New energy Car;Remote monitoring system;Stress Test;virtual on-board terminal}, 
doi={10.1109/ICEICE.2011.5777983}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{659249, 
author={H. H. Schurig and M. A. Kruer and M. N. Levesque and E. M. Gaddy and W. J. Andiario}, 
booktitle={IECEC-97 Proceedings of the Thirty-Second Intersociety Energy Conversion Engineering Conference (Cat. No.97CH6203)}, 
title={Performance testing of the 5 kW EOS AM-1 flexible solar array blanket}, 
year={1997}, 
volume={1}, 
number={}, 
pages={550-555 vol.1}, 
abstract={A GaAs/Ge flexible solar array blanket has been developed for use on the NASA/GSFC remote sensing EOS AM-1 spacecraft. This single wing array has been designed to provide 5 kW of power after five years in a low Earth polar orbit. The blanket configuration includes design features such as thin GaAs/Ge cell stacks mounted on a large flexible, hinged substrate, parallel connected solar cell strings providing high voltage output, a printed circuit harness, and a multi-layer jumper bus providing electrical continuity between the cell strings and the printed circuit harness. This work was contracted to TRW Space and Electronics Group in 1993 by Lockheed Martin Missiles & Space (LMMS). This paper presents the essential design of the EOS AM-1 solar array blanket, and summarizes the results of a qualification test program designed to demonstrate adequate design margins and to assess the performance of the mechanical and electrical components after exposure to a simulated mission space environment. It also reviews the complexities of performing electrical output testing on a 8.9 m×5.0 m deployed solar array blanket under AM0 conditions}, 
keywords={III-V semiconductors;aerospace testing;artificial satellites;elemental semiconductors;gallium arsenide;germanium;photovoltaic power systems;semiconductor device testing;solar cell arrays;space vehicle power plants;5 kW;5 m;8.9 m;AM0 conditions;EOS AM-1 spacecraft;GaAs-Ge;design features;flexible solar array blanket;low Earth polar orbit;mission space environment;performance testing;qualification test program;single wing array;Earth Observing System;Flexible printed circuits;Gallium arsenide;Missiles;NASA;Photovoltaic cells;Remote sensing;Space vehicles;Testing;Voltage}, 
doi={10.1109/IECEC.1997.659249}, 
ISSN={}, 
month={Jul},}
@INPROCEEDINGS{7492562, 
author={C. Gavrilă and C. Z. Kertész}, 
booktitle={2016 International Conference on Development and Application Systems (DAS)}, 
title={Automated performance testing of end-to-end streaming solutions over HbbTV architecture}, 
year={2016}, 
volume={}, 
number={}, 
pages={135-138}, 
abstract={This paper presents an automated test execution environment designed to analyze the accessibility, reliability and streaming performance of an end-to-end Hybrid broadcast broadband TV (HbbTV) solution. Its purpose is to provide the means for the TV providers to test their HbbTV solution by simulating real-world scenarios and online functioning in a local, offline environment, before making it available for the end users. This way, common problems like server overload, poor streaming quality and HbbTV incorrect functionality can be foreseen and corrected.}, 
keywords={Computer architecture;Digital TV;Measurement;Servers;Simple object access protocol;Testing;Automated testing;HbbTV;Network conditions simulation;Streaming media;Web services}, 
doi={10.1109/DAAS.2016.7492562}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{6154026, 
author={X. Yan and F. Wen and C. Fan and X. Wang}, 
booktitle={2011 First International Conference on Instrumentation, Measurement, Computer, Communication and Control}, 
title={Performance Testing of Open Laboratory Management System Based on LoadRunner}, 
year={2011}, 
volume={}, 
number={}, 
pages={164-167}, 
abstract={Open Laboratory Management System provides an open virtual experiment environment for students, so that its system performance immediately impacts the quality of students learning. According to analyze the performance requirements of Open Laboratory Management System, the author discovers performance testing points, implements automated performance testing for performance testing points of the system based on Load Runner. In this paper, taking the students login for example, it elaborates testing process and provides the reference for system optimization.}, 
keywords={computer aided instruction;laboratories;program testing;virtual reality;LoadRunner;open laboratory management system;student learning;student login;testing process;virtual experiment environment;Educational institutions;Laboratories;Monitoring;Protocols;Time factors;LoadRunner;Open Laboratory Management System;performance testing}, 
doi={10.1109/IMCCC.2011.50}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{651034, 
author={D. C. Leonard}, 
booktitle={Proceedings: Electrical Insulation Conference and Electrical Manufacturing and Coil Winding Conference}, 
title={Simplifying motor performance testing in the production environment}, 
year={1997}, 
volume={}, 
number={}, 
pages={185-190}, 
abstract={The objective of this paper is to illustrate how performance test systems on the factory floor can be enhanced by utilizing the power and speed of integral computer hardware and software to automate and simplify tasks typically performed in the production environment. The first part of this paper discusses why the test system is needed to perform additional tasks. The second section defines the relationships between various departments within the organization, and the test system. The third section discusses the benefits of integrating additional functions into the test system. The final sections of the paper discusses incorporating artificial intelligence and networking to simplify tasks associated with the production environment}, 
keywords={artificial intelligence;automatic testing;computer networks;electric motors;machine testing;power engineering computing;production testing;additional functions integration;artificial intelligenc;integral computer hardware;integral computer software;motor performance testing;networking;production environment;test system}, 
doi={10.1109/EEIC.1997.651034}, 
ISSN={0362-2479}, 
month={Sep},}
@INPROCEEDINGS{472644, 
author={Chih-Ang Chen and S. K. Gupta}, 
booktitle={Electro/94 International. Conference Proceedings. Combined Volumes.}, 
title={BIST/DFT for performance testing of bare dies and MCMs}, 
year={1994}, 
volume={}, 
number={}, 
pages={803-812}, 
abstract={High emphasis on performance and high cost of MCM repairs necessitates a frame work for performance testing of dies, substrates, and final MCMs. Application of performance tests to bare dies is very expensive due to the need for small and high speed probes and ATE, BIST, scan, and boundary scan can provide a framework to accomplish performance testing in a cost effective manner. It has been shown that traditional BIST, scan, and boundary scan techniques do not provide the framework for performance testing. Special BIST and scan design techniques that can be employed to guarantee high coverage of delay faults are described. Typically, these techniques produce BIST test pattern generators and scan chain designs that require slightly increased hardware overhead over conventional BIST/scan. However, they can drastically decrease the complexity of bare die performance testing. Furthermore, when used in combination with the proposed enhanced boundary scan design, they provide a framework for detection and diagnosis of dynamic failures}, 
keywords={built-in self test;fault diagnosis;multichip modules;substrates;BIST;MCMs;bare dies;boundary scan;delay faults;dynamic failures;performance testing;scan;Built-in self-test;Circuit faults;Costs;Delay;Economic forecasting;Integrated circuit interconnections;Logic testing;Parasitic capacitance;Probes;System testing}, 
doi={10.1109/ELECTR.1994.472644}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{6532032, 
author={S. Rangaraj and D. Kwon and M. Pei and J. Hicks and G. Leatherman and A. Lucero and T. Wilson and S. Streit and J. He}, 
booktitle={2013 IEEE International Reliability Physics Symposium (IRPS)}, 
title={Accelerated stress testing methodology to risk assess silicon-package thermomechanical failure modes resulting from moisture exposure under use condition}, 
year={2013}, 
volume={}, 
number={}, 
pages={5C.3.1-5C.3.5}, 
abstract={IC components are exposed to moisture and thermal cycles during chip-package-board assembly and in their end use conditions. Moisture exposure influences the mechanical integrity of silicon backend dielectrics, assembly/packaging materials and packages. Reliability performance under accelerated stresses that simulate use conditions are often a critical factor in choice of materials, processing options and design rules. A complete assessment of the cumulative environmental exposure from chip-package assembly, shipment/storage, board system assembly, through end-customer use is required to guarantee product performance and reliability. This paper will detail these end user environments and use failure mode/mechanism specific acceleration models to develop accurate accelerated life testing plans and requirements. These requirements will then be compared to JEDEC standards based requirements and a need for re-calibration of these standards to more appropriate temperatures and stress durations will be highlighted.}, 
keywords={assembling;failure analysis;integrated circuit packaging;integrated circuit reliability;integrated circuit testing;life testing;risk management;stress analysis;IC components;JEDEC standards;accelerated life testing plans;accelerated stress testing methodology;assembly-packaging materials;board system assembly;chip-package-board assembly;cumulative environmental exposure;design rules;end user environments;failure mode-mechanism specific acceleration models;mechanical integrity;moisture cycle;moisture exposure;processing options;product performance;reliability performance;risk assessment;silicon backend dielectrics;silicon-package thermomechanical failure modes;standard re-calibration;stress durations;thermal cycle;through end-customer use;Acceleration;Materials;Mathematical model;Moisture;Reliability;Standards;Stress;HAST;JEDEC standard;acceleration model;moisture;thermal cyclin;use conditions}, 
doi={10.1109/IRPS.2013.6532032}, 
ISSN={1541-7026}, 
month={April},}
@INPROCEEDINGS{6605950, 
author={C. H. Kao and C. C. Lin and J. N. Chen}, 
booktitle={2013 13th International Conference on Quality Software}, 
title={Performance Testing Framework for REST-Based Web Applications}, 
year={2013}, 
volume={}, 
number={}, 
pages={349-354}, 
abstract={Recently, enterprises, organizations, and software companies are building more and more web applications to provide their services over the Internet. In order to fulfill various requirements, the complexity of web applications nowadays is increasing dramatically. As a result, the performance characteristics of web applications, including response time, throughput, etc, become more critical than before and should be taken into careful consideration. If the response time of a web application is poor, users may lose their interests even the function of the web application is correct. Therefore, how to execute performance testing on a complex web application systematically and efficiently will be an important issue. In this paper, a performance testing framework for REST-based web applications is introduced. The performance testing framework aims to provide software testers with an integrated process from test cases design, test scripts generation, to test execution. Based on the test cases designed by software testers and the appropriate software artifacts preserved by the framework (e.g., API document), the framework generates the corresponding performance test scripts, which can be executed by specific performance test tools. This helps software testers to focus more in the design of performance test cases. In addition, effort needed to understand the design and implementation of the application and to learn the operation of testing tools decrease. Thus, the efficiency of performance testing can be highly facilitated.}, 
keywords={Internet;program testing;Internet;REST-based Web applications;performance test scripts;performance test tools;performance testing framework;representational state transfer;software artifacts;software companies;software testers;test cases design;test execution;test scripts generation;Complexity theory;Computer architecture;Engines;Software;Testing;Time factors;XML;Performance testing;software testing;web application}, 
doi={10.1109/QSIC.2013.32}, 
ISSN={1550-6002}, 
month={July},}
@INPROCEEDINGS{7968862, 
author={L. Capelli and S. Sironi}, 
booktitle={2017 ISOCS/IEEE International Symposium on Olfaction and Electronic Nose (ISOEN)}, 
title={Monitoring odour emisssions from an oil gas plant: Electronic nose performance testing in the field}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-3}, 
abstract={This paper focuses on performance testing of electronic noses for environmental odour monitoring in terms of their capability of correctly classifying odours at low odour concentrations. The studied case concerns the realization of an electronic nose network for the continuous monitoring of odour emissions from a crude oil extraction and separation plant. The novelty of the work consists in the fact that performance testing, which is typically carried out in laboratory before installation in the field for environmental odour monitoring outside the plant boundaries, in this case was carried out after installation with the aim of testing the instruments performances in the effective working conditions. This involved the necessity to develop a specific and repeatable procedure to obtain samples at known quality and concentration in the field. Electronic nose performance was evaluated in terms of classification accuracy, which produced satisfactory results towards the considered olfactory classes.}, 
keywords={chemical variables measurement;crude oil;electronic noses;gas industry;crude oil extraction;electronic nose network;environmental odour emisssion monitoring;gas plant;oil plant;olfactory class;performance testing;separation plant;Earth Observing System;Electronic noses;Instruments;Liquids;Monitoring;Oils;Testing;continuous odour monitoring;electronic nose;odour concentration;performance testing;sample preparation}, 
doi={10.1109/ISOEN.2017.7968862}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{6974152, 
author={S. Lee and J. Y. Jo and Y. Kim}, 
booktitle={2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
title={Performance testing of web-based data visualization}, 
year={2014}, 
volume={}, 
number={}, 
pages={1648-1653}, 
abstract={Many scientific applications generate massive data that requires visualization. For example, the Nevada Solar Energy-Water-Environmental Nexus project has been generating a large amount of environmental monitoring data in textual format. As the data is available on the web, a web-based visualization tool is desirable for the project rather than a standalone tool. This research analyzes the processing mechanisms of four popular web-based data visualization tools, that is, Google Charts, Flex, OFC, D3, and compares their performances. A standalone visualization tool, JfreeChart, have been also used for comparison. The processing times have been divided into three segments, layout time, data transformation time, and rendering time, and separately measured. The actual temperature data from the Nevada Nexus project has been used for testing in different scales ranging from 100 to 100,000 data points. The result shows that each visualization tool has its own ideal environment.}, 
keywords={Internet;data visualisation;environmental monitoring (geophysics);rendering (computer graphics);scientific information systems;D3;Flex;Google Charts;JfreeChart;Nevada Solar Energy-Water-Environmental Nexus project;OFC;Web-based data visualization tools;data transformation time;environmental monitoring data;layout time;performance testing;rendering time;scientific applications;standalone visualization tool;textual format;Browsers;Data visualization;Flexible printed circuits;Google;Libraries;Rendering (computer graphics);Servers;D3.js;Data Visualization;Flex;Google Charts;JFreeChart;Open Flash Chart;Sensor Data}, 
doi={10.1109/SMC.2014.6974152}, 
ISSN={1062-922X}, 
month={Oct},}
@INPROCEEDINGS{4483205, 
author={S. Chen and D. Moreland and S. Nepal and J. Zic}, 
booktitle={19th Australian Conference on Software Engineering (aswec 2008)}, 
title={Yet Another Performance Testing Framework}, 
year={2008}, 
volume={}, 
number={}, 
pages={170-179}, 
abstract={Performance testing is one of the vital activities spanning the whole life cycle of software engineering. While there are a considerable number of performance testing products and open source tools available, they are either too expensive and complicated for small projects, or too specific and simple for diverse performance tests. This paper presents a general-purpose testing framework for both simple and small, and complicated and large-scale performance testing. Our framework proposes an abstraction to facilitate performance testing by separating the application logic from the common performance testing functionalities. This leads to a set of general-purpose data models and components, which form the core of the framework. The framework has been prototyped on both .NET and Java platforms and was used for a number of performance-related projects.}, 
keywords={Java;program testing;software performance evaluation;.NET platform;Java platform;general-purpose data model;general-purpose testing framework;performance testing framework;performance testing product;software engineering;Australia;Automatic testing;Data models;Grinding machines;Java;Life testing;Logic testing;Prototypes;Software engineering;Software testing}, 
doi={10.1109/ASWEC.2008.4483205}, 
ISSN={1530-0803}, 
month={March},}
@INPROCEEDINGS{4036666, 
author={B. H. Lim and J. R. Kim and K. H. Shim}, 
booktitle={2006 IEEE International Conference on Multimedia and Expo}, 
title={Hierarchical Load Testing Architecture using Large Scale Virtual Clients}, 
year={2006}, 
volume={}, 
number={}, 
pages={581-584}, 
abstract={In this work, we develop a hierarchical load testing architecture using large scale virtual clients to reduce the testing time and ensure the stability of the server for distributed applications. It explicitly secures the stability of the servers for networked virtual environment and at the same time, it elaborately generates actual loads for testing the performance of the servers. Our agent based load testing architecture provides variety of interactions of virtual entities in the virtual worlds to perform realistic simulations. Simulation results illustrate that our proposed architecture ensures the stability and capacity of the servers for both massively multiplayer online games and peer-to-peer network games}, 
keywords={client-server systems;computer games;peer-to-peer computing;performance evaluation;software agents;distributed application;hierarchical agent based load testing architecture;large scale networked virtual client-server environment;multiplayer online games;peer-to-peer network games;Computational modeling;Computer architecture;Computer industry;Electronic equipment testing;Large-scale systems;Network servers;Pervasive computing;Stability;System testing;Virtual environment}, 
doi={10.1109/ICME.2006.262475}, 
ISSN={1945-7871}, 
month={July},}
@INPROCEEDINGS{6903204, 
author={J. Zhou and B. Zhou and S. Li}, 
booktitle={2014 IEEE 38th International Computer Software and Applications Conference Workshops}, 
title={Automated Model-Based Performance Testing for PaaS Cloud Services}, 
year={2014}, 
volume={}, 
number={}, 
pages={644-649}, 
abstract={Recently, cloud computing has become popular for its unique advantages. Many applications have been migrated to cloud as web services. However, evaluating the performance of cloud services is non-trivial. Performance testing is one of the dominant techniques for evaluating system performance. In this paper, we present a model and template-based approach that automatically generates test scripts and test cases to measure service performance in an enterprise private cloud. We describe how load is generated automatically from our tool. Our empirical study shows the proposed approach can significantly decrease the cost of performance testing and help reveal potential performance issues.}, 
keywords={Web services;cloud computing;program testing;software performance evaluation;PaaS cloud services;Web services;automated model;cloud computing;enterprise private cloud;performance testing;Automation;Cloud computing;Computational modeling;Context;Load modeling;Testing;automated;cloud;performance testing;web service}, 
doi={10.1109/COMPSACW.2014.108}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{664526, 
author={J. Bisgrove and R. Dayao and B. Houser and T. Jones and J. C. Mayes and M. McGinnis and M. Schmidt and G. Skyles and B. K. Tan}, 
booktitle={1997 IEEE International Symposium on Semiconductor Manufacturing Conference Proceedings (Cat. No.97CH36023)}, 
title={Integrated test facility (ITF)-automation testing to support Intel's manufacturing output}, 
year={1997}, 
volume={}, 
number={}, 
pages={D17-D21}, 
abstract={To meet the challenges of increasing automation and the potential for downtime, the current Virtual Factory Joint Automation Managers (JAM) worked with Components Automation Systems (CAS), the central engineering group responsible for the automation system, to create an Integrated Test Facility (ITF). ITF's mission is to conduct volume integrated testing of the automation suite prior to production release and to ensure that the automation suite does not hinge factory ramp. The ITF is a complete factory automation system running simulated production wafers. Established in January 1996, the ITF tests new automation product changes integrated into a complete factory manufacturing automation system and certifies that they can run in high volume. Integrated with CAS automation processes, the ITF is a key part of a process that delivers quality software}, 
keywords={factory automation;production engineering computing;production testing;test facilities;automation testing;factory manufacturing automation system;factory ramp;integrated test facility;manufacturing output;production release;quality software;simulated production wafers;volume integrated testing;Automatic testing;Content addressable storage;Engineering management;Fasteners;Manufacturing automation;Production facilities;Production systems;System testing;Test facilities;Virtual manufacturing}, 
doi={10.1109/ISSM.1997.664526}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{4637713, 
author={J. Xie and X. Ye and B. Li and F. Xie}, 
booktitle={2008 10th IEEE International Conference on High Performance Computing and Communications}, 
title={A Configurable Web Service Performance Testing Framework}, 
year={2008}, 
volume={}, 
number={}, 
pages={312-319}, 
abstract={More and more softwares based on web service technologies are developed. Before their releases on the Internet, it is necessary to evaluate these systems' performance, especially their response time under different workload pressures. However, existing performance testing benchmarks and tools for web service applications are difficult to adapt to various user-specific testing purposes. This paper proposes a configurable web service performance testing framework which contains client module, application server module and database module. Client module, by using the network cooperation method that one central client drives several other clients, adapts to a great number of concurrent customers to request web services. Application server module contains web services under testing and external supporting web services, each of which is configured as a plug-in. The process to realize mixed ratio of web service interactions is similar to dealing cards and adapts to different commercial application characteristics. In database module, the data model including table and attribute dependence can be customized, and the data scale initialization can be resized according to the topology of above dependence. As such, this framework allows testers to dynamically define their data model, customize their scale of database, configure their transaction characteristics, deploy their application strategies and confirm their performance metrics..}, 
keywords={Web services;client-server systems;data models;program testing;Internet;attribute dependence;client-server module;configurable Web service performance testing;data model;database module;table dependence;user-specific testing purpose;Application software;Benchmark testing;Data models;Delay;Internet;Measurement;Network servers;Topology;Transaction databases;Web services;benchmark;framework;performance testing;web service}, 
doi={10.1109/HPCC.2008.53}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{5276470, 
author={M. Z. Mas'ud and A. H. Yaacob and N. M. Ahmad}, 
booktitle={2006 International Conference on Computing Informatics}, 
title={Network performance testing on VM based autonomous web server}, 
year={2006}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={As online services increasingly play vital roles in modern society, the possibilities and opportunities offered are limitless, unfortunately, so too are the risks and chances of malicious intrusions. Intrusion detection systems (IDSs) has been widely used as an important component in protecting online service towards Web attacks and evasions. Yet, today's architectures for intrusion detection force the IDS designer to make a difficult choice to place IDS, so that it can protect itself from a direct attack. To address these challenges, this paper introduces a novel framework to safeguard IDS from a direct attack. Simply called zero administrative server (ZAS), the system incorporates IDS in a virtual machine (VM) environment. VM offers strong isolation for IDS from the monitored services and provides significant resistance to malicious attacks. Moreover, this VM based WWW server has the ability to monitor the network traffic to the running services; analyse the information obtained and detect the intrusion; alienate the intruder from the services; and reconstruct the corrupted data or damaged files caused by the evasion. In this paper, we demonstrate ZAS by exposing it to several attacking tools as well as to show the effects it takes on the network performance in terms of TCP throughput and application-to-application round trip time.}, 
keywords={Web services;security of data;virtual machines;VM based autonomous Web server;Web attacks;intrusion detection systems;malicious attacks;network performance testing;online services;virtual machine;zero administrative server;File servers;Intrusion detection;Network servers;Protection;Testing;Virtual machine monitors;Virtual machining;Virtual manufacturing;Web server;World Wide Web;Checksum;Intrusion Detection System;Virtual Machine;WWW Server}, 
doi={10.1109/ICOCI.2006.5276470}, 
ISSN={2166-5710}, 
month={June},}
@INPROCEEDINGS{7219669, 
author={T. Kanstrén and P. Aho and A. Lämsä and H. Martin and J. Liikka and M. Seppänen}, 
booktitle={2015 IEEE International Conference on Technologies for Practical Robot Applications (TePRA)}, 
title={Robot-assisted smartphone performance testing}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={This paper describes experiences and lessons learned in applying an approach of using a physical robot for testing overall smartphone device performance based on user profiles. The process consists of capturing user actions, abstracting them to usage profiles, transforming these into test models, and generating test cases from the models. The goal is to support performance testing of touch screen devices and applications in a realistic test environment. To achieve this, the tests are based on real-world generated user profiles and executed using a real physical robot, simulating the actual user. Our performance testing targets different attributes of performance such as response times, power and resource usage, and software/hardware aging. Use of different hardware and software configurations in the test scenarios is considered. This work has been performed in close collaboration with industry partners in robotics provider and user industries.}, 
keywords={program testing;robots;smart phones;software maintenance;software performance evaluation;hardware aging;hardware configuration;overall smartphone device performance testing;physical robot;power usage;resource usage;response times;robot-assisted smartphone performance testing;software aging;software configuration;touch screen devices;user profiles;Electronic mail;Markov processes;Performance evaluation;Robot kinematics;Service robots;Testing}, 
doi={10.1109/TePRA.2015.7219669}, 
ISSN={2325-0526}, 
month={May},}
@ARTICLE{370727, 
author={D. E. Pachucki}, 
journal={IEEE Transactions on Components, Packaging, and Manufacturing Technology: Part A}, 
title={Environmental stress testing experiment using the Taguchi method}, 
year={1995}, 
volume={18}, 
number={1}, 
pages={3-9}, 
abstract={Manufacturing process improvements which increase productivity, decrease test process time, and improve customer satisfaction are highly desirable in today's marketplace. The application of environmental stress screening (ESS) is a method of achieving these improvements. ESS is the application of stresses applied beyond product specification limits in order to find latent product defects. Utilizing ESS achieves increased robustness and lower infant mortality. An experiment was performed to identify the significance or relevancy of the selected stresses for application in the printed wiring board (PWA) production process by using a statistically significant controlled method. The design of experiments statistical approach (analysis of variance), is applied, combined with the Taguchi two-level, seven-factor design method. This experiment concentrated on three stresses (temperature cycling, random vibration, and power cycling) and two diagnostic levels: a prom-based (programmable memory chip), power-on self test (POST), and a functional diagnostic test suite, contained on disk storage. Note that this was not an optimization experiment. Once the significance to the production process is identified, future optimizing of temperature cycling, power cycling, and vibration screens, will be conducted. Also, voltage margining was not included so as to reduce the complexity of the experiment-treatment factors and interactions. Experimental results and conclusions on the effectiveness of different stress regimens are presented in this paper}, 
keywords={automatic testing;covariance analysis;design of experiments;dynamic testing;environmental stress screening;environmental testing;human resource management;life testing;printed circuit manufacture;printed circuit testing;production testing;Taguchi method;analysis of variance;customer satisfaction;design of experiments;diagnostic levels;environmental stress testing;functional diagnostic test suite;infant mortality;latent product defects;power cycling;power-on self test;printed wiring board production;productivity;prom-based diagnostics;random vibration;robustness;statistically significant controlled method;stress regimens;temperature cycling;test process time;Automatic testing;Customer satisfaction;Design methodology;Electronic switching systems;Manufacturing processes;Production;Productivity;Robustness;Stress;Temperature}, 
doi={10.1109/95.370727}, 
ISSN={1070-9886}, 
month={Mar},}
@INPROCEEDINGS{6032540, 
author={C. Barna and M. Litoiu and H. Ghanbari}, 
booktitle={2011 33rd International Conference on Software Engineering (ICSE)}, 
title={Model-based performance testing: NIER track}, 
year={2011}, 
volume={}, 
number={}, 
pages={872-875}, 
abstract={In this paper, we present a method for performance testing of transactional systems. The methods models the system under test, finds the software and hardware bottlenecks and generate the workloads that saturate them. The framework is adaptive, the model and workloads are determined during the performance test execution by measuring the system performance, fitting a performance model and by analytically computing the number and mix of users that will saturate the bottlenecks. We model the software system using a two layers queuing model and use analytical techniques to find the workload mixes that change the bottlenecks in the system. Those workload mixes become stress vectors and initial starting points for the stress test cases. The rest of test cases are generated based on a feedback loop that drives the software system towards the worst case behaviour.}, 
keywords={program control structures;program testing;queueing theory;feedback loop;model-based performance testing NIER track;performance test execution;queuing model;stress test cases;stress vectors;system under test;transactional systems;Adaptation models;Computational modeling;Hardware;Software;Stress;Testing;Time factors;adaptive system;performance models;performance testing;stress testing}, 
doi={10.1145/1985793.1985930}, 
ISSN={0270-5257}, 
month={May},}
@INPROCEEDINGS{8282262, 
author={C. Y. Lo and Y. W. Hua and W. C. Yu and Y. M. Chuang}, 
booktitle={2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, 
title={Functional verification and performance testing for OpenAirinterface (OAI) eNodeB}, 
year={2017}, 
volume={}, 
number={}, 
pages={1456-1459}, 
abstract={In this paper we develop and build an open air interface(OAI) eNodeB test platform for system developers to implement the network function verification and system performance evaluation for LTE network. In this test platform it also includes commercially available instruments such as EXFO EPC Simulator, Cobham TM UE Emulator and Cobham Data Generator to make this test platform performing the basic LTE network functions. The performances of this developed OAIeNodeB platform have been compared with the commercial LTE small cell eNodeB system, which is considered as the bench mark system based on Gemteck eNodeB, for proposed system parameters and various test cases .}, 
keywords={Long Term Evolution;performance evaluation;Cobham Data Generator;Cobham TM UE Emulator;EXFO EPC Simulator;Gemteck eNodeB;LTE network functions;developed OAIeNodeB platform;network function verification;open air interface eNodeB test platform;system performance evaluation;5G;B4G;EPC Emulator;OAI (Openairinterface);Open Source;UE Emulator;Verification Platform;eNodeB Emulator}, 
doi={10.1109/APSIPA.2017.8282262}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{755123, 
author={Qingxin Chen and V. Sorokine}, 
booktitle={1999 IEEE MTT-S International Topical Symposium on Technologies for Wireless Applications (Cat. No. 99TH8390)}, 
title={A fast simulation technique for performance testing of the RF/IF chain of CDMA receivers}, 
year={1999}, 
volume={}, 
number={}, 
pages={23-28}, 
abstract={We propose an improved approach to the simulation of the CDMA forward link. The simulator achieves its computational efficiency by adopting a simplified CDMA system model without compromising much of its practicality. Additional reduction in the computational complexity is obtained by implementing bit level operations for certain receiver tasks. Improved processing algorithms are also introduced, which further facilitates the simulation process. The rationale behind the development of the simulator as well as many techniques involved could prove beneficial to a CDMA receiver designer in terms of shortening the design cycle and reducing the computational power requirements.}, 
keywords={code division multiple access;computational complexity;digital simulation;land mobile radio;radio receivers;signal processing;telecommunication equipment testing;CDMA forward link;CDMA receivers;RF/IF chain;bit level operations;computational complexity reduction;computational efficiency;computational power requirements reduction;design cycle;fast simulation technique;mobile radio;performance testing;processing algorithms;system model;Additive white noise;Computational modeling;Context modeling;Fading;Multiaccess communication;Power system modeling;Radio frequency;Signal generators;Space technology;Testing}, 
doi={10.1109/MTTTWA.1999.755123}, 
ISSN={}, 
month={Feb},}
@INPROCEEDINGS{8031452, 
author={N. Gois and P. Porfírio and A. Coelho}, 
booktitle={2017 IEEE International Conference on Computer and Information Technology (CIT)}, 
title={A Multi-objective Metaheuristic Approach to Search-Based Stress Testing}, 
year={2017}, 
volume={}, 
number={}, 
pages={55-62}, 
abstract={Nowadays applications need to deal with a large number of concurrent requests. These systems must be stress tested to ensure that they can function correctly under a load. In this context, a research field called Search-based Software Testing has become increasingly important. Most of the search-based test methods are based on single objective optimization. In the case of multi-objective optimization of tests, usually researchers assign different weight values to different objectives and combine them as a single objective. This research paper verifies the use of a multi-objective algorithm in search-based stress testing. The NSGA-II algorithm was implemented in the IAdapter tool using the jMetal framework. IAdapter is a JMeter plugin used for performing search-based stress tests. jMetal is an object-oriented Java-based framework for multi-objective optimization with metaheuristics. One experiment was conducted to validate the proposed approach.}, 
keywords={Java;Pareto optimisation;concurrency control;genetic algorithms;program testing;search problems;IAdapter tool;JMeter plugin;NSGA-II algorithm;Software Testing;concurrent requests;jMetal framework;multiobjective algorithm;multiobjective metaheuristic approach;multiobjective optimization;object-oriented Java-based framework;search-based stress testing;search-based test methods;single objective optimization;weight values;Genetic algorithms;Load modeling;Search problems;Software;Stress;Testing;Time factors;Multi-Objective Metaheuristic;Pareto Frontier;Search-Based Stress Test}, 
doi={10.1109/CIT.2017.19}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{7414168, 
author={D. Kaulbars and F. Schweikowski and C. Wietfeld}, 
booktitle={2015 IEEE Globecom Workshops (GC Wkshps)}, 
title={Spatially Distributed Traffic Generation for Stress Testing the Robustness of Mission-Critical Smart Grid Communication}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Resilient Smart Grids require very robust communication infrastructures, which allow to support the control of the Smart Grid even and especially in critical situations. Current network quality assurance processes, such as drive tests in wireless systems, typically focus on cell coverage and quality of service parameters (e.g., max. data rate) at a specific geographical position, without considering the impact of overload situations. Therefore, this paper introduces a methodology for stress testing a communication infrastructure for Smart Grids by synchronized, distributed so-called Smart Traffic Generators (STGs). Due to their low cost, the STGs become a permanent part of the infrastructure and enable a network operator independent, continuous network quality monitoring. A case study leveraging a LTE deployment demonstrates how the proposed approach can prove the fulfillment of Quality of Service (QoS) requirements of time critical Smart Grid applications, even in stress situations with high cell load. Although, the proposed approach has been introduced for Smart Grids, it can also be used for ensuring the communication resilience for other critical infrastructures, e.g., public safety networks.}, 
keywords={Long Term Evolution;carrier transmission on power lines;quality of service;smart power grids;telecommunication traffic;mission-critical smart grid communication;network quality monitoring;quality of service;spatially distributed traffic generation;stress testing;Generators;Long Term Evolution;Mobile communication;Mobile computing;Quality of service;Smart grids;Stress}, 
doi={10.1109/GLOCOMW.2015.7414168}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{5634372, 
author={X. Wang and B. Zhou and W. Li}, 
booktitle={International Symposium on Parallel and Distributed Processing with Applications}, 
title={Model Based Load Testing of Web Applications}, 
year={2010}, 
volume={}, 
number={}, 
pages={483-490}, 
abstract={In this paper, a usage model is proposed to simulate users' behaviors realistically in load testing of web applications, and another relevant workload model is proposed to help generate realistic load for load testing. It also demonstrates an eclipse-based load testing tool “Load Testing Automation Framework (LTAF)” which is based on these two models and can perform load testing of web applications easily and automatically. Furthermore, these models and tools were successfully applied into a representative web-based system from a big Corporation.}, 
keywords={Internet;program testing;Load Testing Automation Framework;Web applications;Web-based system;eclipse-based load testing tool;model based load testing;usage model;user behaviors;File systems;Load modeling;Markov processes;Navigation;Servers;Testing;Unified modeling language;Load Model;Load Testing;Markov Chains;Performance Engineering;Usage Model}, 
doi={10.1109/ISPA.2010.24}, 
ISSN={2158-9178}, 
month={Sept},}
@INPROCEEDINGS{4652394, 
author={A. Young and T. Holt and M. Elsayed and A. Neuber and M. Kristiansen and L. L. Altgilbers and A. H. Stults}, 
booktitle={2007 16th IEEE International Pulsed Power Conference}, 
title={Fuse and load testing with mid-sized, high energy density flux compression generators}, 
year={2007}, 
volume={2}, 
number={}, 
pages={1165-1168}, 
abstract={Compact Pulsed Power Systems (CPPSs) require power sources that are small in size yet can produce the necessary electrical energy required to drive a given load. Helical Flux Compression Generators (HFCGs) are attractive for single shot applications due to their rapid conversion of chemical energy to electrical energy. Mid-sized generators occupy little total volume (∼4,000-cm3 total with a compressible volume of ∼300-cm3 in the present generator design), while the high explosives used in an HFCG provide an energy density of ∼8,000 MJ/m3. Consistent output current and energy gain from shot to shot are key variables in the ability of an HFCG to drive CPPSs effectively. An investigation into the practicality of using mid-sized HFCGs as the driver for single shot CPPSs is presented. Data and waveforms from generators fired into 3 μH inductive loads are shown, with results measuring the generator’s performance as a driver for an inductive energy storage (IES) system. Results are also shown from adding a power conditioning system to the output of the HFCG, where the measurements demonstrate the ability of an HFCG to drive high impedance loads. The effectiveness of a mid-sized HFCG as drivers for these systems will be evaluated.}, 
keywords={Chemicals;Energy measurement;Energy storage;Explosives;Fuses;Impedance measurement;Power conditioning;Power measurement;Pulse power systems;Testing}, 
doi={10.1109/PPPS.2007.4652394}, 
ISSN={2158-4915}, 
month={June},}
@ARTICLE{4163031, 
author={M. J. Johnson and C. W. Ho and E. M. Maximilien and L. Williams}, 
journal={IEEE Software}, 
title={Incorporating Performance Testing in Test-Driven Development}, 
year={2007}, 
volume={24}, 
number={3}, 
pages={67-73}, 
abstract={Our performance-testing approach required manually inspecting the performance logs. During the project's development, JUnit-based performance testing tools, such as JUnitPerf, weren't available. Such tools provide better visibility of performance problems than manual inspection of performance logs. Although we believe manual inspection of performance trends is necessary, specifying the bottom-line performance in assert-based test cases can complement the use of performance log files, making the TFP testing results more visible to the developers. We're investigating the design of assert-based performance testing to improve the TFP process. Another direction of future work is automatic performance test generation. In this project, we relied on the performance architect's experience to identify the execution paths and measurement points for performance testing. We can derive this crucial information for performance testing from the performance requirements and system design. We plan to find guidelines for specifications of performance requirements and system design to make the automation possible}, 
keywords={formal specification;formal verification;program testing;software performance evaluation;systems analysis;JUnit-based performance testing tool;assert-based test case;automatic performance test generation;performance requirement specification;system design;test-driven development;Delay;Java;Printers;Process design;Software performance;Software testing;Switches;System software;System testing;Throughput;performance measures;test execution;testing strategies}, 
doi={10.1109/MS.2007.77}, 
ISSN={0740-7459}, 
month={May},}
@INPROCEEDINGS{693672, 
author={A. Helmy and D. Estrin}, 
booktitle={Proceedings. Sixth International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems (Cat. No.98TB100247)}, 
title={Simulation-based `STRESS' testing case study: a multicast routing protocol}, 
year={1998}, 
volume={}, 
number={}, 
pages={36-43}, 
abstract={We propose a method for using simulation to analyze the robustness of multiparty (multicast-based) protocols in a systematic fashion. We call our method Systematic Testing of Robustness by Examination of Selected Scenarios (STRESS). STRESS aims to cut the time and effort needed to explore pathological cases of a protocol during its design. This paper has two goals: (1) to describe the method, and (2) to serve as a case study of robustness analysis of multicast routing protocols. We aim to offer design tools similar to those used in CAD and VLSI design, and demonstrate how effective systematic simulation can be in studying protocol robustness}, 
keywords={digital simulation;local area networks;multicast communication;performance evaluation;telecommunication computing;telecommunication network routing;transport protocols;CAD;LAN;VLSI design;design tools;multicast routing protocols;multiparty protocols;pathological cases;robustness analysis;scenario generation;simulation-based STRESS testing;systematic robustness testing;systematic simulation;Analytical models;Computational modeling;Computer aided software engineering;Computer science;Multicast protocols;Network topology;Routing protocols;Stress;System testing;Unicast}, 
doi={10.1109/MASCOT.1998.693672}, 
ISSN={}, 
month={Jul},}
@INPROCEEDINGS{7813849, 
author={R. Khan and M. Amjad}, 
booktitle={2016 International Conference on Computing, Communication and Automation (ICCCA)}, 
title={Web application's performance testing using HP LoadRunner and CA Wily introscope tools}, 
year={2016}, 
volume={}, 
number={}, 
pages={802-806}, 
abstract={This paper cover the importance of performance testing of the web application. The performance of any web application has been depend on the some different type of the testing process like load testing, soak testing, smoke testing and stress testing etc. In this paper we applied smoke testing on a web application. This web application has been developed for the customer before delivering the software to the customer it is duty of tester to test all the aspects of the software and deliver error free and reliable software to the customer. Reliability has its own most important role in the software industry. In this paper performance testing has been performed using HP LoadRunner and CA Wily Introscope tools.}, 
keywords={DP industry;Internet;program testing;software performance evaluation;software reliability;software tools;CA Wily Introscope tool;HP LoadRunner;Web application performance testing;smoke testing;software industry;software reliability;Business;Scalability;Servers;Software;Testing;Throughput;Uniform resource locators;HP LoadRunner;Load Testng;Perforamance Testing;Software Testing;Wily Introscope Tools}, 
doi={10.1109/CCAA.2016.7813849}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{6802679, 
author={X. Baiquan}, 
booktitle={2014 Sixth International Conference on Measuring Technology and Mechatronics Automation}, 
title={Design of Platform for Performance Testing Based on JADE}, 
year={2014}, 
volume={}, 
number={}, 
pages={251-254}, 
abstract={For solving the problems presently such as coordination of the virtual users' act and the real-time acquisition of information, based on agent and JADE, this paper brings forward an architecture model of the platform for performance testing. JADE is multi-agent development environment which supports the management and communications control for agents. The principle of JADE is described and the basic method to design a platform for performance testing based on JADE is introduced, and offers a technology approach to realize the platform for performance testing.}, 
keywords={Java;multi-agent systems;program testing;software performance evaluation;JADE;Java Agent Development Framework;multiagent development environment;open source software;performance testing platform design;real-time information acquisition;virtual users act coordination;Automation;Mechatronics;Agent;JADE;Platform for performance testing}, 
doi={10.1109/ICMTMA.2014.63}, 
ISSN={2157-1473}, 
month={Jan},}
@INPROCEEDINGS{7793156, 
author={A. H. Kadam and R. Menon and S. S. Williamson}, 
booktitle={IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society}, 
title={Traction inverter performance testing using mathematical and real-time controller-in-the-loop Permanent Magnet Synchronous Motor emulator}, 
year={2016}, 
volume={}, 
number={}, 
pages={6651-6656}, 
abstract={In the development stage of electric vehicle drive, simulation plays a vital role. It's a powerful tool which allows the developer to investigate various control strategies and test hardware systems in harmless work environment. The software simulations platform does have constraints. In that the complex mathematical operations take longer time to solve and eventually increases the overall simulation time and cannot perform the real-time operation. This simulation further needs to be converted to the target processor's language, either assembly or C- language, which will operate in the drive system. However, if a real-time simulation environment could be comprehended, then the real processor used in the system could be incorporated in the simulation. This eventually will eliminate the chance of introducing error during code translation as well as reduce simulation time. Also, the target controller could be tested within the simulation before introducing it the actual system. This paper discuss a concept of controller-in-loop simulation, which can be used to simulate the entire system in real-time. A simple dynamic model of Permanent Magnet Synchronous Motor is simulated with MATLAB/Simulink as well as on a TMS320F28069 digital signal processor from Texas Instruments Inc. Comparative study of simulation results of both the platforms, demonstrate that although MATLAB/Simulink provides excellent GUI and functionality, it fails to performs real-time simulation which can be accomplished with controller-in-simulation.}, 
keywords={digital signal processing chips;invertors;machine control;microcontrollers;permanent magnet motors;synchronous motors;GUI;MATLAB;Simulink;TMS320F28069 digital signal processor;controller-in-the-loop permanent magnet synchronous motor emulator;traction inverter performance testing;Digital signal processing;Frequency control;Integrated circuits;MATLAB;Mathematical model;Real-time systems;Stators;Control systems;electric machines;emulation;modeling;motor drives;power electronics}, 
doi={10.1109/IECON.2016.7793156}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{7752106, 
author={G. E. Subtirelu and M. Dobriceanu and M. Linca}, 
booktitle={2016 IEEE International Power Electronics and Motion Control Conference (PEMC)}, 
title={Virtual instrumentation for no-load testing of induction motor}, 
year={2016}, 
volume={}, 
number={}, 
pages={854-859}, 
abstract={The main objective of this paper is to solve a practical and current problem, by taking advantage of the virtual instrumentation in testing electrical machines. The abilities of virtual instrumentation are used to data acquisition, measurement and analyze the values of no-load testing's parameters for three-phase induction motor. The virtual measurement system bench is designed and consist from two principal components: the hardware components (six LEM transducers for measuring three voltages and three currents; elements for signal conditioning and power transducers; USB multifunction Input / Output module; a personal computer) and the software components (operating system for the computer; drivers for the acquisition and manipulation of data; virtual instrument for calculation and graphical presentation of results). The LabVIEW graphical programming environment is used for designing virtual instrument. This virtual measurement system bench is an easy to use device which can be used in engineering education laboratories from universities or in electrical machines testing workbenches; it is capable of data acquisition, storage or memorization on different media, visualization of different graphs or analysis on-line or off-line of the results obtained. The virtual measurement system described in the paper can work independently (in the Simulation mode or Real time Acquisition mode) or integrated as part of a future complex virtual system for measurement and analysis in the domain of electrical machines testing workbenches.}, 
keywords={data acquisition;graph theory;induction motors;machine testing;virtual instrumentation;LEM transducers;LabVIEW graphical programming environment;USB multifunction input-output module;data acquisition;electrical machines testing;engineering education laboratories;no-load testing;personal computer;power transducers;signal conditioning;three-phase induction motor;virtual instrumentation;virtual measurement system;Artificial intelligence;Current measurement;Data acquisition;Induction motors;Instruments;Testing;Voltage measurement}, 
doi={10.1109/EPEPEMC.2016.7752106}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6748556, 
author={Haojie Fan and Yongmin Mu}, 
booktitle={International Conference on Cyberspace Technology (CCT 2013)}, 
title={A performance testing and optimization tool for system developed by Python language}, 
year={2013}, 
volume={}, 
number={}, 
pages={24-27}, 
abstract={With a wide range of Python language in developing programs, More and more programmers choose to use the Python language for systems development, it gradually becomes scientific computing, web and games' Choice Awards. However, the performance of python is always a headache for developers. For reasonable selection of functions in base library, the usage of third-party plug-ins' functions and methods, and the design of custom functions, the problem whether they are the best choices for general developers is difficult to make a positive answer. After the system's performance bottleneck occurs, it is particularly important to determine where to tune and how to tune. Through the analysis and dynamic tracking of source code, with the built-in method in Python, we can get information about the system to be optimized, included: functions, grammatical structures, running time of each function, the relationship between function calls etc. This information provides an effective basis for further optimization of the system. Experimental results show that the system optimized by the tool has a significantly improvement.}, 
keywords={Performance testing;Python;System Optimization}, 
doi={10.1049/cp.2013.2086}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6825689, 
author={J. Mukherjee and M. Wang and D. Krishnamurthy}, 
booktitle={2014 IEEE Seventh International Conference on Software Testing, Verification and Validation Workshops}, 
title={Performance Testing Web Applications on the Cloud}, 
year={2014}, 
volume={}, 
number={}, 
pages={363-369}, 
abstract={Web applications are increasingly resorting to public cloud platforms such as the Amazon Web Services (AWS) Elastic Compute Cloud (EC2). However, previous studies have shown that the virtualized infrastructures used in a cloud environment can introduce performance issues. Hence, it is crucial to test the performance of the cloud to support Web applications. This is challenging because the performance effect of the cloud platform cannot be easily isolated from other extraneous factors. In this paper, we present a systematic experimental process to address this challenge. Following our proposed process, we test the performance of Web applications running on different types of AWS EC2 instances. Results suggest that Web server response times can fluctuate up to 1000% for the same workload under certain circumstances such as instance type, time-of-the-day, and day-of-the-week.}, 
keywords={Web services;cloud computing;software performance evaluation;virtualisation;AWS EC2 instances;Amazon Web Services Elastic Compute Cloud;Web application performance testing;Web server response time;cloud environment;instance type;performance issues;public cloud platform;virtualized infrastructure;Bandwidth;Generators;Testing;Time factors;Web servers}, 
doi={10.1109/ICSTW.2014.57}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{7377638, 
author={J. Kričković and Đ. Miljković and M. Đukić}, 
booktitle={2015 23rd Telecommunications Forum Telfor (TELFOR)}, 
title={Automation testing of Bootloader for target DSP platform}, 
year={2015}, 
volume={}, 
number={}, 
pages={1016-1019}, 
abstract={In this paper is given the implementation of solutions for automated testing of Bootloader on the target DSP platform. Existing tools for manual testing do not meet the challenges of developing modern products, and its necessity for higher percentages of automation. The aim is to save time testing, reducing the occurrence of errors during testing due to human factors, and the ability that testing may execute a person who has no previous knowledge of a given field.}, 
keywords={digital signal processing chips;human factors;program testing;Bootloader;automation testing;human factor;software testing;target DSP platform;Automation;Digital signal processing;Electronic mail;Field programmable gate arrays;Hardware design languages;Linux;Testing;Bootloader;Python;TeraTerm;ispitivanje}, 
doi={10.1109/TELFOR.2015.7377638}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{5968369, 
author={Y. Fang-ying}, 
booktitle={2011 Chinese Control and Decision Conference (CCDC)}, 
title={The credit risk macro stress testing of the Chinese banking system}, 
year={2011}, 
volume={}, 
number={}, 
pages={1198-1203}, 
abstract={In order to test the overall credit risk of loans of China's banking system, a macroeconomic credit risk model is designed, including a multiple linear regression model describing default probability, and a set of regression models describing macroeconomic environment. Studies show that bank loan default rates and key macroeconomic factors are related. Then stress tests are implemented one by one according to different shocks. The results showed that most banks continue to profit even at 90% confidence level when estimated risk of loss, reflecting a moderate credit risk in the banking system. However, if confidence level rises to 99% when estimated risk of loss, the banking system will face significant losses. The results show that it is necessary to prevent the credit risk of real estate loans and government debt.}, 
keywords={banking;credit transactions;macroeconomics;probability;profitability;regression analysis;risk management;Chinese banking system;bank loan;confidence level;credit risk macrostress testing;default probability;default rate;government debt;linear regression model;macroeconomic credit risk model;macroeconomic environment;profit;real estate loan;Banking;Economic indicators;Electric shock;Equations;Macroeconomics;Mathematical model;Stress}, 
doi={10.1109/CCDC.2011.5968369}, 
ISSN={1948-9439}, 
month={May},}
@INPROCEEDINGS{4346025, 
author={A. J. Young and T. A. Holt and M. A. Elsayed and A. A. Neuber and M. Kristiansen and L. L. Altgilbers and A. H. Stults}, 
booktitle={2007 IEEE 34th International Conference on Plasma Science (ICOPS)}, 
title={Fuse and Load Testing with Mid-Sized, High Energy Density Flux Compression Generators}, 
year={2007}, 
volume={}, 
number={}, 
pages={719-719}, 
abstract={Compact pulsed power systems require power sources that are small in size yet can produce the necessary electrical energy required to drive the system. Helical magnetic flux compression generators (HFCGs) are attractive for single shot applications due to their rapid conversion of chemical energy to electrical energy. The small total volume of a generator coupled with the energy density of the fast-reacting high explosives makes mid-sized HFCGs an appealing option as sources in single shot compact pulsed power systems. Consistent output current and energy gain from shot to shot are key variables in the ability of an HFCG to drive compact pulsed power systems efficiently.}, 
keywords={electric fuses;pulse generators;pulsed power supplies;compact pulsed power systems;fuse testing;helical magnetic flux compression generators;high energy density flux compression generators;load testing;Electronic equipment testing;Explosives;Fuses;Impedance;Power generation;Pulse compression methods;Pulse generation;Pulse power systems;Pulse shaping methods;Switches}, 
doi={10.1109/PPPS.2007.4346025}, 
ISSN={0730-9244}, 
month={June},}
@INPROCEEDINGS{8233806, 
author={B. Wunderle and J. Heilmann and D. May and J. Arnold and J. Hirscheider and J. Bauer and R. Schacht and J. Vogel and M. A. Ras}, 
booktitle={2017 23rd International Workshop on Thermal Investigations of ICs and Systems (THERMINIC)}, 
title={Modelling and characterisation of a grease pump-out test stand and its use for accelerated stress testing of thermal greases}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Thermal greases allow a low stress bond at low bond line thicknesses (BLT) at medium thermal conductivities and simple application, all of which make it an alternative to solders, thermal adhesives or pads. It is widely used in power and microprocessor applications, most of which involve large areas to be used for heat transfer. However, for years thermal overload failure of power modules and chips has been a pressing problem due to pump-out of thermal grease as die or module thermal interface material (TIM): Most thermal greases are Bingham fluids and thus no solids, so they can be squeezed out from in between the gap, driven by thermo-mechanical action of the adjacent layers as e.g. DCB substrate or silicon chip with the heat sink. Today, thermal greases have to be qualified in lengthy stress tests in a product relevant environment which consumes substantial resources as often a system test is required. Therefore, a fast test is necessary which accelerates testing and thus allows a fast screening of market-available greases on one hand, and guidelines for material development on the other. For that purpose this paper addresses this topic in a combined simulative and experimental manner, where at the same time a novel test procedure is proposed for accelerated grease pump-out testing (GPOT) in the framework of a completely new approach, combining loading with in-situ failure analytical techniques and decoupling thermal from mechanical loading.}, 
keywords={adhesion;adhesives;failure analysis;greases;heat sinks;integrated circuit packaging;integrated circuit reliability;life testing;microprocessor chips;thermal conductivity;thermal management (packaging);thermal resistance;thermal stresses;accelerated grease pump-out;accelerated stress testing;grease pump-out test;stress tests;thermal adhesives;thermal conductivities;thermal grease;thermal interface material module;thermal overload failure;Conductivity;Life estimation;Loading;Stress;Testing;Thermal conductivity;Thermal stresses}, 
doi={10.1109/THERMINIC.2017.8233806}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6728886, 
author={A. Banerjee and S. Chattopadhyay and A. Roychoudhury}, 
booktitle={2013 IEEE 34th Real-Time Systems Symposium}, 
title={Static Analysis Driven Cache Performance Testing}, 
year={2013}, 
volume={}, 
number={}, 
pages={319-329}, 
abstract={Real-time, embedded software are constrained by several non-functional requirements, such as timing. With the ever increasing performance gap between the processor and the main memory, the performance of memory subsystems often pose a significant bottleneck in achieving the desired performance for a real-time, embedded software. Cache memory plays a key role in reducing the performance gap between a processor and main memory. Therefore, analyzing the cache behaviour of a program is critical for validating the performance of an embedded software. In this paper, we propose a novel approach to automatically generate test inputs that expose the cache performance issues to the developer. Each such test scenario points to the specific parts of a program that exhibit anomalous cache behaviour along with a set of test inputs that lead to such undesirable cache behaviour. We build a framework that leverages the concepts of both static cache analysis and dynamic test generation to systematically compute the cache-performance stressing test inputs. Our framework computes a test-suite which does not contain any false positives. This means that each element in the test-suite points to a real cache performance issue. Moreover, our test generation framework provides an assurance of the test coverage via a well-formed coverage metric. We have implemented our entire framework using Chronos worst case execution time (WCET) analyzer and LLVM compiler infrastructure. Several experiments suggest that our test generation framework quickly converges towards generating cache-performance stressing test cases. We also show the application of our generated test-suite in design space exploration and cache performance optimization.}, 
keywords={cache storage;embedded systems;program compilers;program diagnostics;software performance evaluation;Chronos worst case execution time;LLVM compiler infrastructure;WCET analyzer;anomalous cache behaviour;cache performance optimization;cache-performance stressing test cases;coverage metric;design space exploration;dynamic test generation;real-time embedded software;static cache analysis;test coverage;test-suite;Abstracts;Cache memory;Embedded software;Instruments;Performance analysis;Testing;Cache performance;Performance testing;Test generation}, 
doi={10.1109/RTSS.2013.39}, 
ISSN={1052-8725}, 
month={Dec},}
@INPROCEEDINGS{4392122, 
author={C. Xing and G. Zhang and M. Chen}, 
booktitle={2007 International Symposium on Communications and Information Technologies}, 
title={Research on universal network performance testing model}, 
year={2007}, 
volume={}, 
number={}, 
pages={780-784}, 
abstract={Network performance testing is one of the key components in optimizing network resource configuration and improving network performance. Existing performance testing tools usually focus on single performance parameters, and lack of the ability to satisfy integrated testing demands of network administrators. In this paper, a universal network performance testing model based on policy scheduling is proposed, which integrates many kinds of performance testing tools into a single system, and provides a uniform testing interface to network administrators. Universal Probe (UP) is the key component of such a model, thus a detailed study is given on UP, which includes UP architecture, policy-based UP cooperation, mobility, and UP deployment under resource constraints. At last, a practical Network Monitor and Measurement System that designed based on the discussed concepts is presented.}, 
keywords={computer network management;computer network reliability;monitoring;optimisation;scheduling;network monitor-measurement system;network resource configuration optimization;policy scheduling;uniform testing interface;universal network performance testing model;universal probe;Information technology;Testing}, 
doi={10.1109/ISCIT.2007.4392122}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{171303, 
author={J. A. Hadfield}, 
booktitle={12th International Conference on Telecommunications Energy}, 
title={Development of an economical, software-controlled battery load testing system}, 
year={1990}, 
volume={}, 
number={}, 
pages={553-555}, 
abstract={Battery discharge capacity tests have traditionally been performed manually, although several mechanized systems are commercially available. A need was identified at the Manitoba Telephone System (MTS) to accurately and economically load test batteries in the field, to verify the capacity of new installations as well as to assist determining the true end-of-life of existing strings. The development of an economical, software-controlled system for testing -48 volt battery strings in the telephone environment is discussed.<>}, 
keywords={automatic test equipment;battery testers;power supplies to apparatus;secondary cells;telephone equipment;-48 V;Canada;automatic testing;battery testers;development;discharge capacity;end-of-life;load testing;software;telephone equipment;Automatic testing;Batteries;Electronic equipment testing;Environmental economics;Prototypes;Software standards;Software testing;System testing;Telephony;Voltage}, 
doi={10.1109/INTLEC.1990.171303}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6023983, 
author={X. Meng}, 
booktitle={Proceedings of 2011 International Conference on Electronic Mechanical Engineering and Information Technology}, 
title={Designing approach analysis on small-scale software performance testing tools}, 
year={2011}, 
volume={8}, 
number={}, 
pages={4254-4257}, 
abstract={Currently, most software performance testing tools in the market are large ones designated for enterprises. Aiming at the demand of small-sized and individual customers' conduction of software performance testing, the paper proposes an approach for designing and realizing a small tool for testing. Core design refers to simulating multi-user concurrent operation by simultaneous execution of multithreading and measuring performance of the system tested through whether each threading responses in a correct manner as well as testing data such as period of responding. Testing tool, which is realized by Java language, consists of three modules of case management, test implementation and test report. Multiple designing modes are utilized in a combined manner during designing, which makes the designing scheme a simple one with high efficiency and easy to expand. The market of performance testing is developing in a rapid manner and researching software performance test is gaining increasingly significance.}, 
keywords={Java;automatic test software;concurrency control;multi-threading;program testing;software performance evaluation;software tools;Java language;case management;multithreading;multiuser concurrent operation;small-scale software performance testing tool design;test implementation;test report;Databases;Educational institutions;Instruction sets;Presses;Servers;Software performance;Testing;designing approach;designing mode;small-scaled testing tool;software performance test}, 
doi={10.1109/EMEIT.2011.6023983}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{604303, 
author={K. H. Sueker}, 
booktitle={1997 IEEE International Electric Machines and Drives Conference Record}, 
title={A static dynamometer for load testing large variable frequency motor drives}, 
year={1997}, 
volume={}, 
number={}, 
pages={WB1/9.1-WB1/9.3}, 
abstract={The static dynamometer, an apparent oxymoron, is a system which allows full load testing of variable frequency motor drives with no rotating equipment and only minimal demand from the power line. By inserting a reactor between the drive output and the line from which it is powered, the drive can be made to appear as a synchronous generator. This arrangement offers a practical alternative to the motor-generator sets usually employed for load testing. The required equipment consists of a set of power reactors approximating 10% of the drive rating, a contactor and a phase locked loop circuit for regulating the drive phase relative to the line. The static dynamometer is in production use on variable speed drives from 20 to 5000 hp and 480 to 4160 V. There are no intrinsic limits to either power or voltage for its application}, 
keywords={dynamometers;machine testing;motor drives;variable speed drives;20 to 5000 hp;480 to 4160 V;drive rating;load testing;motor-generator sets;phase locked loop circuit;power reactors;production experience;static dynamometer;synchronous generator;variable frequency motor drives;variable speed drives;Circuit testing;Frequency;Inductors;Motor drives;Phase locked loops;Production;Synchronous generators;System testing;Variable speed drives;Voltage}, 
doi={10.1109/IEMDC.1997.604303}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{5614034, 
author={R. Mansharamani and A. Khanapurkar and B. Mathew and R. Subramanyan}, 
booktitle={2010 IEEE 34th Annual Computer Software and Applications Conference Workshops}, 
title={Performance Testing: Far from Steady State}, 
year={2010}, 
volume={}, 
number={}, 
pages={341-346}, 
abstract={The dot com era ushered in a number of industry standard load testing tools. While there is no doubt that these tools have helped improve the quality of IT systems, performance testing in the IT industry is far from steady state. There are still severe gaps between performance test results and production systems performance in IT projects. This paper proposes a number of areas where performance testing needs to improve radically, several of which can be incorporated in to load testing tools. Examples are also provided of simple analytics during single user performance testing to demonstrate the effectiveness of this extra but necessary step in the testing process.}, 
keywords={DP industry;Internet;electronic commerce;performance evaluation;testing;IT system quality;industry standard load testing tools;production systems;single user performance testing;Databases;Extrapolation;Industries;Testing;Throughput;Time factors;Tuning;load testing tools;performance emulation;performance testing;think time variability}, 
doi={10.1109/COMPSACW.2010.66}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{6200165, 
author={J. A. Meira and E. C. d. Almeida and Y. Le Traon and G. Sunye}, 
booktitle={2012 IEEE Fifth International Conference on Software Testing, Verification and Validation}, 
title={Peer-to-Peer Load Testing}, 
year={2012}, 
volume={}, 
number={}, 
pages={642-647}, 
abstract={Nowadays the large-scale systems are common-place in any kind of applications. The popularity of the web created a new environment in which the applications need to be highly scalable due to the data tsunami generated by a huge load of requests (i.e., connections and business operations). In this context, the main question is to validate how far the web applications can deal with the load generated by the clients. Load testing is a technique to analyze the behavior of the system under test upon normal and heavy load conditions. In this work we present a peer-to-peer load testing approach to isolate bottleneck problems related to centralized testing drivers and to scale up the load. Our approach was tested in a DBMS as study case and presents satisfactory results.}, 
keywords={Internet;peer-to-peer computing;program testing;Web applications;centralized testing drivers;large-scale systems;peer-to-peer load testing;system under test;Cloud computing;Computer architecture;Databases;Large-scale systems;Peer to peer computing;Scalability;Testing;large-scale systems;load testing;peer-to-peer}, 
doi={10.1109/ICST.2012.153}, 
ISSN={2159-4848}, 
month={April},}
@ARTICLE{638869, 
author={T. Suryanarayana and J. L. Bhattacharya and K. S. N. Raju and K. A. Durga Prasad}, 
journal={IEEE Transactions on Energy Conversion}, 
title={Development and performance testing of a 200 kVA damperless superconducting generator}, 
year={1997}, 
volume={12}, 
number={4}, 
pages={330-336}, 
abstract={A 200 kVA, 3000 RPM superconducting generator has been developed and tested. The rotor has been wound with superconducting wire of Nb-Ti alloy. A closed-circuit liquid helium system has been designed and installed for cooling the superconducting windings. The stator carries the air-gap type armature windings and a laminated-iron flux-shield. A new concept in the design of superconducting generators with high short-circuit ratio (more than 5) has been introduced. This eliminates the requirement of an electromagnetic damper and quick response excitation system. The generator has been comprehensively tested in the superconducting state. Open-circuit and sustained short-circuit tests, three-phase sudden short-circuit tests, synchronization with the grid and parallel operation with power systems have been conducted. The synchronous machine was operated up to its rated kVA in the four quadrants-as a generator and as a condenser with leading and lagging power factors. A few special tests on superconducting generators, which were not reported earlier, such as direct-online starting of a 20 hp squirrel-cage induction motor and negative phase sequence tests have also been performed successfully. Test results and conclusions are given}, 
keywords={electric generators;machine testing;rotors;stators;superconducting machines;superconducting magnets;20 hp;200 kVA;NbTi;air-gap type armature windings;closed-circuit liquid helium system;damperless superconducting generator;laminated-iron flux-shield;open-circuit tests;performance testing;short-circuit ratio;short-circuit tests;stator;superconducting windings cooling;superconducting wire rotor;Air gaps;Cooling;Helium;Induction generators;Rotors;Stators;Superconducting filaments and wires;Superconducting transmission lines;System testing;Wounds}, 
doi={10.1109/60.638869}, 
ISSN={0885-8969}, 
month={Dec},}
@INPROCEEDINGS{6525558, 
author={Q. Gao and W. Wang and G. Wu and X. Li and J. Wei and H. Zhong}, 
booktitle={2013 IEEE Seventh International Symposium on Service-Oriented System Engineering}, 
title={Migrating Load Testing to the Cloud: A Case Study}, 
year={2013}, 
volume={}, 
number={}, 
pages={429-434}, 
abstract={Cloud computing has emerged as a new paradigm for the delivery of computing resources. It brings great opportunities to software testing, especially to load testing. In this paper, we focus on migrating conventional load testing tools to the cloud, for which the two significant issues are about multi-tenancy and load simulating resource management. We propose a four layer model for cloud-based load testing, along with the approach of test request admission control and scheduling to solve these issues. We carried out a concrete case study on our proposed approach and made the efficiency of cloud-based load testing shown successfully by two contrast experiments.}, 
keywords={cloud computing;program testing;resource allocation;scheduling;cloud computing;cloud-based load testing;computing resource delivery;four layer model;load simulating resource management;load testing migration;multitenancy;scheduling;software testing;test request admission control;Admission control;Databases;Load modeling;Monitoring;Resource management;Software;Testing;cloud computing;load testing;migrating}, 
doi={10.1109/SOSE.2013.59}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{4155356, 
author={L. Pan and L. M. Batten}, 
booktitle={Systematic Approaches to Digital Forensic Engineering, 2007. SADFE 2007. Second International Workshop on}, 
title={A Lower Bound on Effective Performance Testing for Digital Forensic Tools}, 
year={2007}, 
volume={}, 
number={}, 
pages={117-130}, 
abstract={The increasing complexity and number of digital forensic tasks required in criminal investigations demand the development of an effective and efficient testing methodology, enabling tools of similar functionalities to be compared based on their performance. Assuming that the tool tester is familiar with the underlying testing platform and has the ability to use the tools correctly, we provide a numerical solution for the lower bound on the number of testing cases needed to determine comparative capabilities of any set of digital forensic tools. We also present a case study on the performance testing of password cracking tools, which allows us to confirm that the lower bound on the number of testing runs needed is closely related to the row size of certain orthogonal arrays. We show how to reduce the number of test runs by using knowledge of the underlying system}, 
keywords={computer crime;digital forensic tools;password cracking tools;performance testing;Blindness;Digital forensics;High performance computing;Home computing;Information technology;Kernel;Linux;Software performance;Software testing;System testing;Abstraction Layer Model;Orthogonal Arrays;Partition Testing;SADFE;Software Performance.}, 
doi={10.1109/SADFE.2007.2}, 
ISSN={}, 
month={April},}
@ARTICLE{7298477, 
author={B. Jiang and P. Chen and W. K. Chan and X. Zhang}, 
journal={IEEE Transactions on Reliability}, 
title={To What Extent is Stress Testing of Android TV Applications Automated in Industrial Environments?}, 
year={2016}, 
volume={65}, 
number={3}, 
pages={1223-1239}, 
abstract={An Android-based smart television (TV) must reliably run its applications in an embedded program environment under diverse hardware resource conditions. Owing to the diverse hardware components used to build numerous TV models, TV simulators are usually not sufficiently high in fidelity to simulate various TV models and thus are only regarded as unreliable alternatives when stress testing such applications. Therefore, even though stress testing on real TV sets is tedious, it is the de facto approach to ensure the reliability of these applications in the industry. In this paper, we study to what extent stress testing of smart TV applications can be fully automated in the industrial environments. To the best of our knowledge, no previous work has addressed this important question. We summarize the findings collected from ten industrial test engineers who have tested 20 such TV applications in a real production environment. Our study shows that the industry required test automation supports on high-level GUI object controls and status checking, setup of resource conditions, and the interplay between the two. With such supports, 87% of the industrial test specifications of one TV model can be fully automated, and 71.4% of them were found to be fully reusable to test a subsequent TV model with major upgrades of hardware, operating system, and application. It represents a significant improvement with margins of 28% and 38%, respectively, compared with stress testing without such supports.}, 
keywords={Android (operating system);automatic testing;digital television;graphical user interfaces;production engineering computing;program testing;reliability;Android-based smart TV;Android-based smart television;TV simulators;hardware resource conditions;high-level GUI object controls;industrial environments;industrial test specifications;operating system;reliability;status checking;stress testing;test automation;Androids;Automation;Humanoid robots;Smart phones;Stress;TV;Testing;Android;TV;automated testing;reliability;software reuse;stress testing;test case creation}, 
doi={10.1109/TR.2015.2481601}, 
ISSN={0018-9529}, 
month={Sept},}
@INPROCEEDINGS{5254473, 
author={Z. Wandan and J. Ningkang and Z. Xubo}, 
booktitle={2009 Ninth International Conference on Hybrid Intelligent Systems}, 
title={Design and Implementation of a Web Application Automation Testing Framework}, 
year={2009}, 
volume={2}, 
number={}, 
pages={316-318}, 
abstract={In this paper the problems in the automation testing of GUI based Web applications are discussed. A new automation testing framework based on the concept of object feature set and dynamic searching policy is proposed. The design and implementation of it are both given. The framework working using result shows that it makes the testing more convenient and efficient with less resources and time cost but higher testing coverage.The ability of maintenance and stability are both improved.}, 
keywords={Internet;graphical user interfaces;program testing;GUI;Internet technology;Web application automation testing framework;Web application maintenance;dynamic searching policy;object feature set;software development cycle;Application software;Automatic control;Automatic testing;Costs;Design automation;Graphical user interfaces;Java;Programming;Software testing;System testing;Web application testing;automation testing framework;dynamic searching technology}, 
doi={10.1109/HIS.2009.175}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6496814, 
author={J. Finnigan}, 
booktitle={2013 IEEE Aerospace Conference}, 
title={Radiation Belt Storm Probes (RBSP) Flight Software stress testing: Case study and lessons learned}, 
year={2013}, 
volume={}, 
number={}, 
pages={1-12}, 
abstract={This paper presents a case study of the Radiation Belt Storm Probes (RBSP) mission Command and Data Handling (C&DH) Flight Software stress testing program. Background information on the motivation for stress testing embedded software, and the general principles and goals of a stress test are provided as an introduction. Details of the stress test program that was implemented for the RBSP C&DH Flight Software are presented and discussed. This discussion includes the design and development of a test framework that was implemented to incrementally build the test scenarios, increase the productivity of the RBSP stress test team, and facilitate reuse for regression testing. Results of the RBSP stress test program are summarized, and lessons learned that may be useful for future embedded software test programs are documented.}, 
keywords={aerospace computing;aerospace testing;embedded systems;probes;program testing;radiation belts;regression analysis;software reusability;team working;C&DH flight software stress testing program;RBSP flight software stress testing;RBSP stress test team productivity;command and data handling flight software stress testing program;embedded software test programs;radiation belt storm probes;regression testing reusability;test framework design;test framework development;Computer architecture;Loading;Planning;Software;Space vehicles;Stress;Testing}, 
doi={10.1109/AERO.2013.6496814}, 
ISSN={1095-323X}, 
month={March},}
@INPROCEEDINGS{4299917, 
author={X. Shu and F. Maurer}, 
booktitle={International Conference on Software Engineering Advances (ICSEA 2007)}, 
title={A Tool for Automated Performance Testing of Java3D Applications in Agile Environments}, 
year={2007}, 
volume={}, 
number={}, 
pages={35-35}, 
abstract={Following the agile philosophy that all core features of a system need an automated test harness, performance requirements also need such a check when they are essential for the success of a project. The purpose of this paper is to describe a tool, J3DPerfUnit, which supports automated performance testing for Java3D applications in agile environments. We elicited tool requirements from domain experts through a survey and evaluated J3DPerfUnit using code from our partner's bioinformatics project and Java3D official tutorials. The evaluation pointed out that the tool is effective in detecting performance problems and in identifying where they come from when loading/unloading a 3D object.}, 
keywords={Java;program testing;rendering (computer graphics);software metrics;Java3D application;agile environment;automated performance testing;graphics rendering;software metrics;Application software;Automatic testing;Availability;Bioinformatics;Computer science;Engines;Java;Layout;System testing;Tree graphs}, 
doi={10.1109/ICSEA.2007.11}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{5445814, 
author={L. Motalova and O. Krejcar}, 
booktitle={2010 Second International Conference on Computer Engineering and Applications}, 
title={Stress Testing Data Access via a Web Service for Determination of Adequate Server Hardware for Developed Software Solution}, 
year={2010}, 
volume={1}, 
number={}, 
pages={329-333}, 
abstract={The aim of this project is stress testing of the system for data management and planning of the operations developed for home care agencies which has to be upgrading of the current system based on the older database of Microsoft Access product. The part of the system is a mobile application that allows employees to edit the records of patients directly in the terrain. The whole system, including applications developed for the stress testing is based on Microsoft technology .NET. Our Stress Testing application allows testing a selected problem areas to find any limitations before the tested developing solution will be set up at customer. By the help of our test application, the hardware solution for the server was selected on the base of selected home care agency needs.}, 
keywords={Web services;file servers;information retrieval;program testing;software tools;Microsoft access product database;Microsoft technology .NET;Web service;adequate server hardware;data management system;home care agency;stress testing data access;Databases;Displays;Hardware;Random number generation;Software testing;Stress;System testing;Time factors;Time measurement;Web services;data access;software;stress testing;web services}, 
doi={10.1109/ICCEA.2010.72}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{6569717, 
author={G. Canfora and F. Mercaldo and C. A. Visaggio and M. DAngelo and A. Furno and C. Manganelli}, 
booktitle={2013 IEEE Sixth International Conference on Software Testing, Verification and Validation}, 
title={A Case Study of Automating User Experience-Oriented Performance Testing on Smartphones}, 
year={2013}, 
volume={}, 
number={}, 
pages={66-69}, 
abstract={We have developed a platform named Advanced Test Environment (ATE) for supporting the design and the automatic execution of UX tests for applications running on Android smartphones. The platform collects objective metrics used to estimate the UX. In this paper, we investigate the extent that the metrics captured by ATE are able to approximate the results that are obtained from UX testing with real human users. Our findings suggest that ATE produces UX estimations that are comparable to those reported by human users. We have also compared ATE with three widespread benchmark tools that are commonly used in the industry, and the results show that ATE outperforms these tools.}, 
keywords={Linux;automatic testing;program testing;smart phones;software performance evaluation;ATE;Android smartphones;UX estimations;UX test design;UX testing;advanced test environment;automatic UX test execution;objective metrics;user experience-oriented performance testing automation;Conferences;Software testing;android;mobile applications;smartphone;software testing;usability;user experience}, 
doi={10.1109/ICST.2013.16}, 
ISSN={2159-4848}, 
month={March},}
@INPROCEEDINGS{315756, 
author={D. Grossman and C. J. Staton and B. Bailey and M. C. McCabe and A. Latts and O. Frieder and C. Bock and D. Roberts}, 
booktitle={Proceedings of 3rd Symposium on Assessments of Quality Software Development Tools}, 
title={A prototype-driven approach to application-level performance testing: a case study of a large finance application}, 
year={1994}, 
volume={}, 
number={}, 
pages={125-135}, 
abstract={We present an approach to application-level performance testing. This uses a popular test tool, TPNS (Teleprocessing Network Simulator) to simulate performance of an application. Our approach hinges upon a simple prototype to verify that the system performance falls within acceptable bounds. Once the initial prototype is developed, detailed tuning may take place. We present a case study in which we tested the performance of a large finance application. This approach led to critical performance tuning improvement. Due to this improvement, the average user response time in our simulations was reduced from 30 seconds to under 1.5 seconds. This simulation has been verified by actual system usage during the first two months of live operation in which the average response time has indeed been under 1.5 seconds}, 
keywords={accounts data processing;performance evaluation;program testing;software prototyping;TPNS;Teleprocessing Network Simulator;application-level performance testing;large finance application;prototype-driven approach;system performance;test tool;user response time;Computer aided software engineering;Computer bugs;Database systems;Finance;Financial management;Information technology;Operating systems;Prototypes;System testing;Technology management}, 
doi={10.1109/AQSDT.1994.315756}, 
ISSN={}, 
month={Jun},}
@INPROCEEDINGS{4658079, 
author={Z. M. Jiang and A. E. Hassan and G. Hamann and P. Flora}, 
booktitle={2008 IEEE International Conference on Software Maintenance}, 
title={Automatic identification of load testing problems}, 
year={2008}, 
volume={}, 
number={}, 
pages={307-316}, 
abstract={Many software applications must provide services to hundreds or thousands of users concurrently. These applications must be load tested to ensure that they can function correctly under high load. Problems in load testing are due to problems in the load environment, the load generators, and the application under test. It is important to identify and address these problems to ensure that load testing results are correct and these problems are resolved. It is difficult to detect problems in a load test due to the large amount of data which must be examined. Current industrial practice mainly involves time-consuming manual checks which, for example, grep the logs of the application for error messages. In this paper, we present an approach which mines the execution logs of an application to uncover the dominant behavior (i.e., execution sequences) for the application and flags anomalies (i.e., deviations) from the dominant behavior. Using a case study of two open source and two large enterprise software applications, we show that our approach can automatically identify problems in a load test. Our approach flags < 0.01% of the log lines for closer analysis by domain experts. The flagged lines indicate load testing problems with a relatively small number of false alarms. Our approach scales well for large applications and is currently used daily in practice.}, 
keywords={program testing;public domain software;software engineering;automatic identification;enterprise software;load testing;open source software;Catalogs;Computer bugs;Databases;Generators;Monitoring;Software;Testing}, 
doi={10.1109/ICSM.2008.4658079}, 
ISSN={1063-6773}, 
month={Sept},}
@INPROCEEDINGS{5202971, 
author={G. Wang and S. Jiao and H. Song}, 
booktitle={2009 International Conference on Measuring Technology and Mechatronics Automation}, 
title={Mine Pump Comprehensive Performance Testing System Based on Labview}, 
year={2009}, 
volume={1}, 
number={}, 
pages={300-303}, 
abstract={The pump is one of the key equipments for the safety production of coal mine. It bears the important task to discharge all the underground water. However, the performance efficiency of the water pump will be declined, in the long run. Therefore, in order to ensure the safety production, users should check and test the pump performance regularly ,to test if every target pump has live up to the ldquoCoal Mine Safety Regulationsrdquo. The ultimate goal in finding the fault in time, eliminating hidden dangers, reducing accidents,and saving maintenance costs can be attained. Virtual instrument is the production of modern computer and instrument technology combined in-depth, and is an important technology of computer-assisted testing area. The core idea is "software replacing hardware". The paper introduces the virtual instrument technology into the field of pump performance testing, and designs the mine pump comprehensive performance testing system based on Labview. The system takes software development environment-LabVIEW as platform and based on personal computer, and realizes the function that pumppsilas import and export of water pressure, flow, speed, power, and other signals measured in real-time and dynamic displayed. It uses the polynomial fitting module of LabVIEW to fit the performance curve,and shows the performance curve by the waveform display. At the same time,it uses the Web Publishing Tool of LabVIEW to release the testing interface to the internet,and realizes its network communication function. Compared with traditional instruments,the pump performance testing system which based on Virtual instrument run stably, have strongly data analytical and processing functions, beautiful interface, easy operation, strongly visual function, highly testing precision.}, 
keywords={mining;mining equipment;polynomial approximation;pumps;safety;virtual instrumentation;LabVIEW;coal mine safety production;coal mine safety regulations;computer-assisted testing;mine pump comprehensive performance testing system;network communication function;polynomial fitting module;virtual instrument technology;Costs;Hardware;Instruments;Microcomputers;Paper technology;Product safety;Production;Programming;Safety devices;System testing;labview;pump;testing system}, 
doi={10.1109/ICMTMA.2009.179}, 
ISSN={2157-1473}, 
month={April},}
@INPROCEEDINGS{7551414, 
author={Y. Zhang and D. Meisner and J. Mars and L. Tang}, 
booktitle={2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)}, 
title={Treadmill: Attributing the Source of Tail Latency through Precise Load Testing and Statistical Inference}, 
year={2016}, 
volume={}, 
number={}, 
pages={456-468}, 
abstract={Managing tail latency of requests has become one of the primary challenges for large-scale Internet services. Data centers are quickly evolving and service operators frequently desire to make changes to the deployed software and production hardware configurations. Such changes demand a confident understanding of the impact on one's service, in particular its effect on tail latency (e.g., 95th-or 99th-percentile response latency of the service). Evaluating the impact on the tail is challenging because of its inherent variability. Existing tools and methodologies for measuring these effects suffer from a number of deficiencies including poor load tester design, statistically inaccurate aggregation, and improper attribution of effects. As shown in the paper, these pitfalls can often result in misleading conclusions. In this paper, we develop a methodology for statistically rigorous performance evaluation and performance factor attribution for server workloads. First, we find that careful design of the server load tester can ensure high quality performance evaluation, and empirically demonstrate the inaccuracy of load testers in previous work. Learning from the design flaws in prior work, we design and develop a modular load tester platform, Treadmill, that overcomes pitfalls of existing tools. Next, utilizing Treadmill, we construct measurement and analysis procedures that can properly attribute performance factors. We rely on statistically-sound performance evaluation and quantile regression, extending it to accommodate the idiosyncrasies of server systems. Finally, we use our augmented methodology to evaluate the impact of common server hardware features with Facebook production workloads on production hardware. We decompose the effects of these features on request tail latency and demonstrate that our evaluation methodology provides superior results, particularly in capturing complicated and counter-intuitive performance behaviors. By tuning the hardware features - s suggested by the attribution, we reduce the 99th-percentile latency by 43% and its variance by 93%.}, 
keywords={Internet;computer centres;computer network performance evaluation;regression analysis;Facebook production workloads;Treadmill;counter-intuitive performance behaviors;data centers;large-scale Internet services;modular load tester platform;performance evaluation;performance factor attribution;precise load testing;production hardware configurations;quantile regression;request tail latency management;server hardware features;server load tester;server systems;server workloads;service operators;software hardware configurations;statistical inference;statistically-sound performance evaluation;Hardware;Histograms;Production;Servers;Testing;Web and internet services;data center;load testing;tail latency}, 
doi={10.1109/ISCA.2016.47}, 
ISSN={1063-6897}, 
month={June},}
@INPROCEEDINGS{7555000, 
author={C. Zhou and D. Du and Z. Cao and Y. Wang and X. Yang}, 
booktitle={2016 35th Chinese Control Conference (CCC)}, 
title={Assets overlapping networks and stress testing on stability of financial systems}, 
year={2016}, 
volume={}, 
number={}, 
pages={10385-10389}, 
abstract={Financial networks, creating potential propagation channels for shocks in crises, are widely viewed as a key factor to systemic stability. In this paper, we develop a dynamic model of deleveraging in an overlapping network of assets. We study the deleveraging spirals driven by the interaction between fire sales and confidence effects, and show how distress is amplified and propagated throughout the network. Using the regulatory data from the Peoples Bank of China (PBC), we construct the assets overlapping network and then apply the model to the system. The result suggests that: (1) the mutually reinforcing effects of fire sales and confidence can contribute to contagion significantly; (2) The vulnerability of the system are largely dependant on the distribution of large illiquid assets. Our model provides a ready-to-use yet powerful stress testing tool for macro-prudential regulation.}, 
keywords={asset management;finance;PBC;Peoples Bank of China;assets overlapping networks;confidence effects;deleveraging dynamic model;deleveraging spirals;financial systems stability;fire sales;illiquid assets;macroprudential regulation;stress testing;Electric shock;Heuristic algorithms;Investment;Portfolios;Stability analysis;Stress;Testing;Confidence Effects;Deleveraging;Financial Networks;Stress Testing;Systemic Risk}, 
doi={10.1109/ChiCC.2016.7555000}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{8278490, 
author={N. Ibhar and W. Flores and R. León}, 
booktitle={2017 IEEE 37th Central America and Panama Convention (CONCAPAN XXXVII)}, 
title={Design of a low-cost teleoperated robotic arm: Assembly and performance testing}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={At present, robots are widely used in various tasks, whether for industrial or even domestic uses. Thus, for certain tasks it has become necessary to operate the robot in an intuitive and safe way. The vast majority of current robotic hands do not completely replace the functionality of a hand and can not be used in environments which are designed for the use of a human hand. Thus, this document shows the design of a hybrid system with robotic hand and prosthesis applications. The design of a biomechanically controlled, functional and anthropomorphic robotic arm is shown, which demonstrates that it is feasible to design a real-time, low-cost, robotic arm.}, 
keywords={biomechanics;human-robot interaction;manipulator dynamics;prosthetics;robot dynamics;telerobotics;anthropomorphic robotic arm;biomechanically controlled arm;domestic uses;functional arm;human hand;hybrid system design;industrial uses;low-cost teleoperated robotic arm;performance testing;prosthesis;robotic hand;robotic hands;robots;Manipulators;Service robots;Silicon compounds;Task analysis;Testing;Torque;Human-robot interaction;Humanoid robots;Robot control;Telerobotics}, 
doi={10.1109/CONCAPAN.2017.8278490}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{4340515, 
author={l. liu and w. wei and j. li}, 
booktitle={2007 International Conference on Wireless Communications, Networking and Mobile Computing}, 
title={Wireless Communication System Automation Testing Framework}, 
year={2007}, 
volume={}, 
number={}, 
pages={2981-2984}, 
abstract={This article intends to introduce a leading next generation wireless protocol oriented automation testing framework - WiCAT system. This framework supports multiple protocol messaging testing by simulating the wireless equipments and implementing the telecommunication system logic. WiCAT provides high-efficiency and low-cost performance basing on a distributed, expandable and extensible architecture.}, 
keywords={automatic test software;electronic messaging;mobile radio;protocols;telecommunication computing;telecommunication equipment testing;WiCAT system;multiple protocol messaging testing;next generation wireless protocol;telecommunication system logic;wireless communication system automation testing;Automatic testing;Automation;Computer architecture;Graphical user interfaces;Local area networks;System testing;User interfaces;Utility programs;Wireless application protocol;Wireless communication}, 
doi={10.1109/WICOM.2007.740}, 
ISSN={2161-9646}, 
month={Sept},}
@INPROCEEDINGS{5067800, 
author={P. O. Iversen and K. Rutkowski and S. Issartel and L. Foged and A. Scannavini}, 
booktitle={2009 3rd European Conference on Antennas and Propagation}, 
title={Radiated performance testing of diversity and MIMO enabled terminals}, 
year={2009}, 
volume={}, 
number={}, 
pages={1069-1071}, 
abstract={This paper discuss general methods available for test and design engineers for testing radiated performances of multi-antenna enabled terminals in a controlled environment such as anechoic chambers. Methods for testing SIMO (Single-input Multi-Output), and MIMO (Multi-Input Multi-Output) performances in both passive and active way are highlighted. Information such as user defined propagation channel characteristic can be taking into account in passive measurements and is currently being investigated for the active testing.}, 
keywords={MIMO communication;antenna arrays;antenna radiation patterns;diversity reception;wireless channels;MIMO enabled terminals;diversity testing;multiantenna enabled terminals;passive measurements;propagation channel characteristics;radiated performance testing;Anechoic chambers;Antenna arrays;Antenna radiation patterns;Antennas and propagation;Current measurement;Design engineering;MIMO;Performance evaluation;Polarization;System testing}, 
doi={}, 
ISSN={2164-3342}, 
month={March},}
@INPROCEEDINGS{5658927, 
author={N. Nie and J. Guo and J. Fu and Z. Feng}, 
booktitle={2010 2nd International Workshop on Database Technology and Applications}, 
title={Reliability and Performance Testing Model of Web-Based User Login and Access Control}, 
year={2010}, 
volume={}, 
number={}, 
pages={1-4}, 
abstract={In order to test the performance, reliability and security of Web-based system, the paper generates the test scripts template and establishes testing model of system login and access control. Then some Web-based systems are tested by automation test tools. The performance, reliability and security problems of Web login process can be traced and diagnosed. The test result shows that Web-based system can be verified and improved by the test script template of multi-users secure login and resources access control.}, 
keywords={Internet;authorisation;computer network security;performance evaluation;Web based user login;access control;multiuser secure login;performance testing model;reliability testing model;test script template;Access control;Correlation;Driver circuits;Software reliability;Testing}, 
doi={10.1109/DBTA.2010.5658927}, 
ISSN={2167-1923}, 
month={Nov},}
@INPROCEEDINGS{6949287, 
author={R. Angmo and M. Sharma}, 
booktitle={2014 5th International Conference - Confluence The Next Generation Information Technology Summit (Confluence)}, 
title={Performance evaluation of web based automation testing tools}, 
year={2014}, 
volume={}, 
number={}, 
pages={731-735}, 
abstract={In today's 21st century era countless software applications are written as a web based application which runs in a web browsers. With new technologies and commercialization of I.T. sector, the web based system has undergoes frequent and rapid changes. Today Softwares are coded as a web based application, which help to access data from any part of the globe. Even the economic relevance of web based enhances the control and quality of software. The quality assurance of any system depends on its test. But to do manually testing in most of the cases is time consuming, expensive and hectic. For the better business purpose and to save time and money automation testing is required. There are variety of tools are available in the market for this. One of the best known tool is selenium suite which is a combination of different automation testing tool. In this paper we will discuss about the selenium suite. It provides testers with different framework for different test cases. The main objective of this paper is to find the best tool in selenium suite and then compare it with some other tool for same task. For this purpose, performance evaluation is done on the basis of some criteria.}, 
keywords={Internet;program testing;software performance evaluation;software quality;software tools;Web based application;Web based automation testing tools;Web browsers;performance evaluation;selenium suite;software applications;software quality;Automation;Browsers;Information technology;Performance evaluation;Software;Software testing;Automation testing;Performance;Selenium;Test case;Watir-webdriver;Web applications}, 
doi={10.1109/CONFLUENCE.2014.6949287}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{5279915, 
author={M. Nieminen and T. Raty and J. Palokangas}, 
booktitle={2009 First International Conference on Advances in System Testing and Validation Lifecycle}, 
title={Stress Testing the Logical Decision Making Server of a Surveillance System}, 
year={2009}, 
volume={}, 
number={}, 
pages={98-103}, 
abstract={The current generation of distributed and automated physical location surveillance systems faces high demands for robustness and reliability. We present and evaluate the design of the Logical Decision Making Server (LDMS), a rule-based automated decision making component used in the Single Location Surveillance Point (SLSP) system. To validate the robustness of the LDMS design for operation in the SLSP environment, we design and conduct a stress test experiment in which large load of TCP/IP input messages is sent instantaneously to the LDMS prototype implementation using the Nethawk EAST software. The stress test results are compared to measurements obtained during a real-life scenario. The LDMS is observed to withstand a significant amount of load without crashing, and its performance is can be considered sufficient for the SLSP system needs. A detailed analysis of results however shows an increase in the latency resulting from an extreme temporal load. We identify potential areas in the design to be improved if demands for higher response rates arise. The research is based on the construction of the related publications and technologies, and the results are established from the testing and validation of the implemented LDMS within the SLSP system.}, 
keywords={decision support systems;digital simulation;logic design;network servers;performance evaluation;transport protocols;video surveillance;Nethawk EAST software;TCP/IP input messages;automated decision making;environment for automated systems testing;logical decision making server;rule-based component;stress testing;surveillance system;Decision making;Logic testing;Robustness;Software prototyping;Software testing;Stress;Surveillance;System testing;TCPIP;Vehicle crash testing;decision making;stress testing;surveillance}, 
doi={10.1109/VALID.2009.16}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{7883617, 
author={H. Kapoh and E. S. Lumunon and N. A. E. Sajangbati}, 
booktitle={2016 International Conference on Knowledge Creation and Intelligent Computing (KCIC)}, 
title={Design model material requirement of coconut flour production and performance testing based multi user in North Sulawesi}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-7}, 
abstract={There has been many previous studies that discuss the control for the production of coconut flour and raw material inventory. But a system or a computer-based model for coconut flour industry in North Sulawesi has not or does not exist. For that reason, coconut flour industries also require tools on in running the business as developed in this study. The problem in this research is how to make the design of the model material production requirement of coconut flour-based multi-user to control the production of industrial centers in North Sulawesi coconut flour and how to test the model. The model generated in this study have been through a survey in the industrial district of coconut flour to get the data that will be used analysis, so that a complete picture processing system coconut flour and can describe the problem also the solution clearly in order to get the system needs a model along the test by using a test black box the program and the respondents used for the performance test in order to know the program's ability to interact with users. The collected data is then analyzed and designed using some design method that is data flow diagrams, use case diagram, entity relationship diagrams and material requirements planning methods. Results of the test will indicate that all functions on the system works well and test the respondent for 30 and 60 minutes resulting in a 60% and 63% of respondents were taken as many as 30 answered easily using the model application.}, 
keywords={design engineering;food processing industry;materials requirements planning;production engineering computing;raw materials inventory;North Sulawesi;coconut flour industry;coconut flour production;computer-based model;data flow diagrams;design model material requirement;entity relationship diagrams;industrial centers;material requirements planning methods;model material production requirement;performance testing based multiuser;picture processing system;raw material inventory;use case diagram;Companies;Computational modeling;Industries;Planning;Production;Raw materials;Testing;coconut flour;design;model;multi-user;production;testing}, 
doi={10.1109/KCIC.2016.7883617}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{4041302, 
author={L. Liu and J. Lin and Z. Li and J. Li}, 
booktitle={2006 IEEE Asia-Pacific Conference on Services Computing (APSCC'06)}, 
title={State Machine Based CDMA Stress Testing Service System}, 
year={2006}, 
volume={}, 
number={}, 
pages={625-628}, 
abstract={This paper introduces a system model of CDMA stress testing service platform based on state machine technology. This system provides an efficient service oriented solution on protocol and stress testing of CDMA system, with high performance and automatic capability. The concurrent multitask mechanism and the state machine framework enable the high performance and automatic capability of this system. And the scalable distributed architecture offers the maximum flexibility of deployment}, 
keywords={code division multiple access;computer architecture;finite state machines;protocols;stress analysis;CDMA stress testing service system;concurrent multitask mechanism;protocol;scalable distributed architecture;state machine;Communication system control;Computer architecture;Electronic equipment testing;Hardware;Mobile communication;Multiaccess communication;Protocols;Software testing;Stress;System testing;Service;State Machine;Stress Testing}, 
doi={10.1109/APSCC.2006.93}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{5454995, 
author={Y. Pu and M. Xu}, 
booktitle={2009 First International Conference on Information Science and Engineering}, 
title={Load Testing for Web Applications}, 
year={2009}, 
volume={}, 
number={}, 
pages={2954-2957}, 
abstract={The performance testing criteria was analyzed, including response time, concurrency users, throughout and performance counter. Performance testing is necessary for the system reliability. Load testing can be used for software troubleshooting and optimizing. With the LoadRunner and TestDirector testing tools, a load testing scheme based on an online examination system was designed.}, 
keywords={Internet;program testing;software performance evaluation;LoadRunner testing tools;TestDirector testing tools;Web application;concurrency users;load testing;online examination system;performance counter;performance testing criteria;response time;software troubleshooting;system reliability;Application software;Automatic testing;Computer bugs;Concurrent computing;Delay;Reliability engineering;Software performance;Software testing;System performance;System testing}, 
doi={10.1109/ICISE.2009.720}, 
ISSN={2160-1283}, 
month={Dec},}
@INPROCEEDINGS{1285473, 
author={H. A. Chan}, 
booktitle={Annual Symposium Reliability and Maintainability, 2004 - RAMS}, 
title={Accelerated stress testing for both hardware and software}, 
year={2004}, 
volume={}, 
number={}, 
pages={346-351}, 
abstract={Accelerated stress testing (AST) has been used in electronic, electromechanical, and mechanical systems to achieve robustness with high reliability primarily for hardware. For software products, the reliability program is often conducted separate from any hardware accelerated stress testing. Yet, many systems are consist of concurrent software and hardware issues. In addition, the stress testing processes were primarily adopted by those responsible to develop and manufacture hardware. For example, the stresses usually include temperature extremes, thermal cycles, vibrations, etc. These stresses are effective in accelerating latent hardware defects from degradable, marginal, or intermittent failures to hard failures so that root cause analyses and corrective actions may be made. Although experiments had indicated that software faults and hardware defects are related, the available formulation of the fundamental principles was still based on hardware systems. AST for software and for operating systems have been discussed in [M. Werner, et al., "Improving Customer Satisfaction via Accelerated Stress Testing of General Purpose Computer Operating Systems"] and [M. Werner, et al., 2002], but a fundamental understanding of AST for software is lacking. In order to generalize the fundamentals of accelerated stress testing to address both software and hardware, we need to define accelerated stress testing for software and to address whether they are needed, i.e., whether there are effective methods to achieve high software reliability. The basic reliability concepts categorize systems into different categories according to the presence of defects and faults and whether these weaknesses are explicit enough. The concepts for both hardware and software reliability separate the notion of defects and faults from failures. It further conceptually separates the notion of stressing and the notion of detection. The fundamental concept is that all failures except the explicit ones must be manifested under certain stress conditions. There is then a threshold stress level beyond which a system fails. The cumulative effect of stresses is included by defining time as one type of stress. Both hardware and software systems have marginal weakness, and degradable weakness. The process o- f recovery and repair are also examined for both hardware and software events. The basic reliability principles in accelerated stress testing for both software and hardware systems are combined and explained in this paper. While [M. Werner, et al., "Improving Customer Satisfaction via Accelerated Stress Testing of General Purpose Computer Operating Systems"] and [M. Werner, et al., 2002] also address the needs and advantages of AST for software, an effective software AST program requires efficient tools yet to be developed. The benefits should justify the needed further research and development in this area.}, 
keywords={conformance testing;life testing;software reliability;stress analysis;accelerated stress testing;corrective actions;hardware defects;hardware reliability;reliability program;root cause analysis;software faults;software reliability;Customer satisfaction;Hardware;Life estimation;Operating systems;Software reliability;Software systems;Software testing;Software tools;System testing;Thermal stresses}, 
doi={10.1109/RAMS.2004.1285473}, 
ISSN={}, 
month={},}
@INPROCEEDINGS{103992, 
author={P. A. Singer}, 
booktitle={Military Communications Conference, 1989. MILCOM '89. Conference Record. Bridging the Gap. Interoperability, Survivability, Security., 1989 IEEE}, 
title={Trends in VLF/LF modem performance testing}, 
year={1989}, 
volume={}, 
number={}, 
pages={581-584 vol.2}, 
abstract={The author reviews the historical development of digital VLF/LF modem testing. He discusses the introduction of test equipment in the following four major functional areas: (a) transmit simulation, (b) channel simulation, (c) noise and interference generation, and (d) reception characterization. He demonstrates two major trends: (1) the use of general-purpose hardware and off-line software replacing special-purpose hardware; (2) Gaussian noise, atmospheric laboratory test environments being replaced by tailored simulated electromagnetic interference and atmospheric noise}, 
keywords={automatic test equipment;digital simulation;electronic equipment testing;modems;performance evaluation;Gaussian noise;LF;VLF;atmospheric laboratory test environments;atmospheric noise;channel simulation;digital modem;electromagnetic interference;general-purpose hardware;interference generation;modem performance testing;noise generation;off-line software;reception characterization;test equipment;transmit simulation;Atmospheric modeling;Electromagnetic interference;Gaussian noise;Hardware;Low-frequency noise;Modems;Noise generators;Test equipment;Testing;Working environment noise}, 
doi={10.1109/MILCOM.1989.103992}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{5458557, 
author={Q. Wu and Y. Wang}, 
booktitle={2010 Second International Workshop on Education Technology and Computer Science}, 
title={Performance Testing and Optimization of J2EE-Based Web Applications}, 
year={2010}, 
volume={2}, 
number={}, 
pages={681-683}, 
abstract={J2EE-based Web applications are becoming increasingly ubiquitous and with their increasing adoption, the performance is the attention focus and the most important factor of evaluating the system by users. In this paper, we present a systematic solution for performance testing and optimization of J2EE-based Web applications. The solution helps to identify and eliminate bottlenecks in the application design and ensures that systems are designed to meet their quality of service requirements. This paper firstly analyses the architecture of J2EE-based Web applications and performance testing principle, and then improves the JMeter testing framework for meeting the more concurrent users. Lastly, performance testing for J2EE-based Web applications is done; it finds performance bottlenecks and puts forward optimum measures, and compares the performance with the former one.}, 
keywords={Internet;Java;program testing;software performance evaluation;J2EE-based Web applications optimization;JMeter testing framework;concurrent users;performance testing;quality of service requirements;systematic solution;Application software;Business;Delay;Educational institutions;Nonhomogeneous media;Performance analysis;Scalability;Service oriented architecture;System performance;System testing;JMeter;Web applications;distributed;optimization;performance}, 
doi={10.1109/ETCS.2010.583}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{7980227, 
author={B. Chapuis and B. Garbinato}, 
booktitle={2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)}, 
title={Scaling and Load Testing Location-Based Publish and Subscribe}, 
year={2017}, 
volume={}, 
number={}, 
pages={2543-2546}, 
abstract={The rise of the Internet of things (IoT) poses massive scalability issues for location-based services. More particularly, location-aware publish and subscribe services are struggling to scale out the computation of matches between publications and subscriptions that continuously update their location. In this demonstration paper, we propose a novel distributed and horizontally scalable architecture for location-aware publish and subscribe. Our middleware architecture relies on a multi-step routing mechanism based on consistent hashing and range partitioning. To demonstrate its scalability, we present a traffic data generator, which, in contrast to existing generators, can be used to perform real-time load tests. Finally, we show that our architecture can be deployed on a small 10-node cluster and can process up to 80,000 location updates per second producing 25,000 matches per seconds.}, 
keywords={Internet of Things;message passing;middleware;Internet of Things;location-aware publish and subscribe services;location-based services;middleware architecture;multi-step routing mechanism;traffic data generator;Computer architecture;Generators;Middleware;Real-time systems;Roads;Routing;Scalability}, 
doi={10.1109/ICDCS.2017.234}, 
ISSN={1063-6927}, 
month={June},}
@INPROCEEDINGS{6334582, 
author={J. Wu}, 
booktitle={2012 IEEE AUTOTESTCON Proceedings}, 
title={Stress testing software to determine fault tolerance for hardware failure and anomalies}, 
year={2012}, 
volume={}, 
number={}, 
pages={294-298}, 
abstract={Today's military systems rely for their performance on combinations of hardware and software. While testing of hardware performance during design, development and operation is well understood, the testing of software is less mature. In particular, the effect of hardware failures in the field on software performance, and therefore systems performance, is all-too-often overlooked or is tested in a far less rigorous manner that that applied to Hardware failures alone. Numerous examples exist of major system failures driven by software anomalies but triggered by Hardware failures, with consequences that range from degraded mission performance to weapons system destruction and operator fatalities. Measuring software development quality and fault tolerance is a challenging task. Many software test methods focus on source-code only approach (unit tests, modular test) and neglect the impacts caused by hardware anomalies or failures. Such missing test coverage can and will result in potential degraded software performance quality, thereby adding to project cost and delaying schedule. It can also result in far more disastrous consequences for the warfighters. This paper will discuss the general nature of the hardware-failure-software anomaly - system failure flow-down. It will then describe techniques that exist for system software testing and will highlight extensions of these techniques to focus on an effective and comprehensive software testing that includes performance prediction and hardware failure fault tolerance. The end result is a suite of test methods that, when properly applied, offer a systematic and comprehensive analysis of prime software behaviors under a range of hardware field failure conditions.}, 
keywords={fault tolerant computing;military computing;missiles;program testing;software metrics;software performance evaluation;software quality;delaying schedule;fault tolerance measurement;hardware anomalies;hardware failure fault tolerance;hardware field failure conditions;hardware performance testing;missing test coverage;mission performance degradation;operator fatalities;performance prediction;project cost;software anomalies;software behavior comprehensive analysis;software development quality measurement;software performance;software testing;source code;stress testing software;system failure flow-down;warfighters;weapon system destruction;Embedded systems;Fault detection;Hardware;Monitoring;Real-time systems;Voltage control}, 
doi={10.1109/AUTEST.2012.6334582}, 
ISSN={1088-7725}, 
month={Sept},}
@INPROCEEDINGS{5272178, 
author={O. Hamed and N. Kafri}, 
booktitle={2009 First International Conference on Networked Digital Technologies}, 
title={Performance testing for web based application architectures (.NET vs. Java EE)}, 
year={2009}, 
volume={}, 
number={}, 
pages={218-224}, 
abstract={Having an efficient web application is a challenge that we need to achieve when architecting web applications in the development process. This research follows a performance modeling approach that aims to utilize load testing tools to give ideas about performance issues early in the development life cycle for applications implemented using Java Enterprise Edition (Java EE) or .NET platform. Thus, it helps system architects to choose between competitive frameworks. To achieve this, the applications are subjected to artificial workload. Direct measurements are obtained on the specified application scenarios using different tools. Parasoft WebKing and Hewlett-Packard LoadRunner were used for this purpose. Later on, the obtained results indicate that, Java EE performs better than .NET. by means of response time and memory utilization.}, 
keywords={Java;program testing;software architecture;software performance evaluation;Hewlett-Packard LoadRunner;Java Enterprise Edition;Parasoft WebKing;Web based application architectures;artificial workload;development life cycle;load testing tools;performance testing;Analytical models;Application software;Automatic testing;Computational modeling;Delay;Java;Performance analysis;Scalability;Service oriented architecture;System testing}, 
doi={10.1109/NDT.2009.5272178}, 
ISSN={2155-8728}, 
month={July},}
@INBOOK{5444092, 
author={Gail D. Baura}, 
booktitle={System Theory and Practical Applications of Biomedical Signals}, 
title={Pharmacologic Stress Testing Using Closed-Loop Drug Delivery}, 
year={2002}, 
volume={}, 
number={}, 
pages={0-}, 
abstract={
This chapter contains sections titled:

Pharmacokinetics and Pharmacodynamics

Control Theory

Problem Significance

Closed-Loop Drug Infusion in Pharmacological Stress Tests

Summary

References

Peripheral Insulin Kinetics Exercises

}, 
keywords={Absorption;Biomedical monitoring;Blood flow;Drug delivery}, 
doi={10.1109/9780471683179.ch14}, 
ISSN={}, 
publisher={Wiley-IEEE Press}, 
isbn={9780471683179}, 
url={https://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5444092},}
@INPROCEEDINGS{6158278, 
author={Li Zhang and Yinghui Chen and Fan Tang and Xiong Ao}, 
booktitle={2011 6th International ICST Conference on Communications and Networking in China (CHINACOM)}, 
title={Design and implementation of cloud-based performance testing system for web services}, 
year={2011}, 
volume={}, 
number={}, 
pages={875-880}, 
abstract={Nowadays testing plays an important role in software development process. While software testing is expensive and time-consuming, sufficient testing is hard, especially for a distributed system using web services technique in the real circumstance. The development of cloud computing provides us new ideas to solve these testing problems. To address these issues, we propose a framework which integrates cloud computing and performance testing technologies. In this paper, first we present the architecture of the cloud-based performance testing system for web services (CPTS), which is a portable, extensible and easy-to-use framework for generating and submitting test workloads to computing clouds. Then, we show the process how to use CPTS to run a performance test and present the concept of dynamic migration in CPTS. Finally, we present our experiences with CPTS in Amazon EC2. We found that the CPTS allows a user to easily set up and test a web services system on the cloud and improve test effectively.}, 
keywords={Web services;cloud computing;program testing;software performance evaluation;Amazon EC2;CPTS;Web services;cloud computing;cloud-based performance testing system;distributed system;dynamic migration;software development process;software testing;Cloud computing;Dispatching;Dynamic scheduling;Monitoring;Servers;Testing;cloud computing;dynamic migration;performance testing;virtual machine;web services}, 
doi={10.1109/ChinaCom.2011.6158278}, 
ISSN={}, 
month={Aug},}
@ARTICLE{7740990, 
author={S. Omidshafiei and A. A. Agha-Mohammadi and Y. F. Chen and N. K. Ure and S. Y. Liu and B. T. Lopez and R. Surati and J. P. How and J. Vian}, 
journal={IEEE Control Systems}, 
title={Measurable Augmented Reality for Prototyping Cyberphysical Systems: A Robotics Platform to Aid the Hardware Prototyping and Performance Testing of Algorithms}, 
year={2016}, 
volume={36}, 
number={6}, 
pages={65-87}, 
abstract={Planning, control, perception, and learning are current research challenges in multirobot systems. The transition dynamics of the robots may be unknown or stochastic, making it difficult to select the best action each robot must take at a given time. The observation model, a function of the robots' sensor systems, may be noisy or partial, meaning that deterministic knowledge of the team's state is often impossible to attain. Moreover, the actions each robot can take may have an associated success rate and/or a probabilistic completion time. Robots designed for real-world applications require careful consideration of such sources of uncertainty, regardless of the control scheme or planning or learning algorithms used for a specific problem. Understanding the underlying mechanisms of planning algorithms can be challenging due to the latent variables they often operate on. When performance testing such algorithms on hardware, the simultaneous use of the debugging and visualization tools available on a workstation can be difficult. This transition from experimentation to implementation becomes especially challenging when the experiments need to replicate some feature of the software tool set in hardware, such as simulation of visually complex environments. This article details a robotics prototyping platform, called measurable augmented reality for prototyping cyberphysical systems (MAR-CPS), that directly addresses this problem, allowing for the real-time visualization of latent state information to aid hardware prototyping and performance testing of algorithms.}, 
keywords={augmented reality;control engineering computing;cyber-physical systems;data visualisation;mobile robots;path planning;robot vision;software prototyping;software tools;MAR-CPS;hardware prototyping;latent state information;measurable augmented reality for prototyping cyberphysical systems;performance testing;planning algorithm;real-time visualization;robot sensor system;robotic platform;software tool set;Algorithm design and analysis;Augmented reality;Central Processing Unit;Cyber-physical systems;Planning;Robot sensing systems;Robots}, 
doi={10.1109/MCS.2016.2602090}, 
ISSN={1066-033X}, 
month={Dec},}
@INPROCEEDINGS{6111055, 
author={L. Zhizhong and W. Sen and X. Jun and N. Bo and J. Hongliang and X. Hua}, 
booktitle={2011 7th Asia-Pacific International Conference on Lightning}, 
title={Performance testing and comprehensive evaluation on large grounding connection}, 
year={2011}, 
volume={}, 
number={}, 
pages={983-989}, 
abstract={To comprehensively evaluate the safety of large grounding connection, testing and action principle of the main factors that impact the safe operation of grounding connection, were analyzed and studied, and the following conclusions were drew by theoretical analysis and simulation research. While evaluating step voltage and touch voltage, it's inadvisable to consider seasonal factors during the selection of soil resistivity; the testing direction of step voltage and touch voltage should be selected based on simulation computation for getting reliable data; eligibility criterion on electric integrity of grounding connection should not be 200mΩ but appropriately lowered; corrosion evaluation of grounding connection can be get rudely by analogized ways, which need the adding appropriate monitoring point in the corner of the grounding grid. Finally, the grading criterion and reference methods of weight value for the testing results of safe operation factors of grounding connection is proposed for establishing a quantified evaluation system of grading grounding connection, detailing the state evaluation system of large grounding connection.}, 
keywords={earthing;power grids;grounding connection;grounding grid;soil resistivity;step voltage;touch voltage;Corrosion;Electric potential;Grounding;Immune system;Resistance;Testing;Thermal stability;Grounding connection;comprehensive evaluation;grading criterion;grounding grid;integrity of grounding connection;quantified evaluation}, 
doi={10.1109/APL.2011.6111055}, 
ISSN={}, 
month={Nov},}
@ARTICLE{4319794, 
author={H. C. Kyle}, 
journal={IEEE Transactions on Aerospace}, 
title={Compatibility and Performance Testing of Communications Systems}, 
year={1965}, 
volume={AS-3}, 
number={2}, 
pages={139-143}, 
abstract={During the normal progress of design, fabrication, and integration of communications subsystems for spacecraft and for ground installations, every effort is made to assure that the equipment meets certain specifications relating to performance, environment, reliability, and interface capability. These specifications are based on the best available definition of requirements and interface characteristics of complementing subsystems. Frequently, in the field of manned spaceflight, the spacecraft subsystems, the launch vehicle subsystems, and the ground systems must be designed and constructed concurrently. This means that the operating and interface characteristics of one subsystem are not available for use by the engineers in the design of the other subsystems. Close technical liaison among the various engineering groups is essential in the accomplishment of overall systems' integrity. Component and subsystem testing has been developed to a high degree, but the results of these are necessarily limited. They cannot validate the overall systems' performance and compatibility. It is considered mandatory that the interfacing subsystems be mated to form a complete system in a controlled test environment as early as practicable in any program, especially in one involving communications systems as new and as complex as those for Apollo. This must be accomplished at such a phase in the program that corrective engineering details can be fed back to the cognizant design, fabrication, or integration groups involved in time for necessary modifications prior to the beginning of the flight phase.}, 
keywords={Aerospace engineering;Automotive engineering;Communication system control;Control systems;Design engineering;Fabrication;Land vehicles;Road vehicles;Space vehicles;System testing}, 
doi={10.1109/TA.1965.4319794}, 
ISSN={0536-1516}, 
month={June},}
@INPROCEEDINGS{1368035, 
author={K. Gold and A. Brown}, 
booktitle={2004 IEEE Aerospace Conference Proceedings (IEEE Cat. No.04TH8720)}, 
title={Architecture and performance testing of a software GPS receiver for space-based applications}, 
year={2004}, 
volume={4}, 
number={}, 
pages={2404-2416 Vol.4}, 
abstract={Space-based GPS technology presents significant challenges over Earth-based systems. These include visibility issues for rotating platforms and tracking of GPS satellites from spacecraft that are in higher orbits than the GPS, realtime resolution of carrier phase ambiguities, and different dynamics during various mission phases. NAVSYS has developed a software GPS receiver that makes use of 3-dimensional digital beam steering technology and inertial aiding to address these issues. This approach offers several advantages including all round visibility for spinning satellites, tracking of weak GPS signals, reduction of multipath, and reprogrammability to accommodate different mission phases. Additionally, a suite of simulation tools based on the NAVSYS Matlab Toolbox and Advanced GPS Hybrid simulation products have been built to allow testing for simulated space environments. The receiver architecture and test tools are described in this paper.}, 
keywords={Global Positioning System;aerospace computing;artificial satellites;beam steering;hybrid simulation;radio receivers;real-time systems;satellite tracking;software radio;telecommunication equipment testing;3-dimensional digital beam steering technology;Earth based systems;GPS hybrid simulation products;GPS satellite tracking;GPS signal tracking;Matlab toolbox;NAVSYS;carrier phase ambiguity;multipath reduction;realtime resolution;receiver architecture;rotating platforms;simulated space environment;software GPS receiver;space based applications;spinning satellites;Application software;Beam steering;Computer architecture;Global Positioning System;Orbits;Satellites;Software performance;Software testing;Space technology;Space vehicles}, 
doi={10.1109/AERO.2004.1368035}, 
ISSN={1095-323X}, 
month={March},}
@INPROCEEDINGS{7764458, 
author={B. Wunderle and T. Onken and J. Heilmann and D. Silbernagl and J. Arnold and T. Bieniek and R. Pufall}, 
booktitle={2016 6th Electronic System-Integration Technology Conference (ESTC)}, 
title={Reliability of sputtered thin aluminium films under accelerated stress testing by vibration loading and modeling}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-14}, 
abstract={Aluminium is still one of the most important contact metallisations for power electronic chips like MOSFETs or IGBTs. With a large difference in thermal expansion coefficients (CTEs) between aluminium and silicon and the temperatures generated in hot-spots during high power transients, these layers are prone to failure due to thermo-mechanical fatigue. Usually lifetime assessment is done by subjecting dedicated test specimens to standardised stress tests as e.g. active or passive thermal cycling. This paper proposes a novel method for accelerated stress testing and lifetime modelling of thin aluminium films in the high-cycle fatigue regime by isothermal mechanical loading. The proposed novel test method is suggested to complement or replace resource-demanding thermal cycling tests and allow simple in-situ monitoring of failure.}, 
keywords={semiconductor device reliability;thermal expansion;vibrations;CTE;IGBT;MOSFET;accelerated stress testing;active thermal cycling;high power transients;high-cycle fatigue regime;hot-spots;isothermal mechanical loading;lifetime modelling;passive thermal cycling;power electronic chips;sputtered thin aluminium films reliability;thermal expansion coefficients;thermomechanical fatigue;thin aluminium films;vibration loading;vibration modeling;Aluminum;Fatigue;Life estimation;Silicon;Stress;Testing}, 
doi={10.1109/ESTC.2016.7764458}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6674729, 
author={B. Querbach and S. Puligundla and D. Becerra and Z. T. Schoenborn and P. Chiang}, 
booktitle={2013 IEEE 56th International Midwest Symposium on Circuits and Systems (MWSCAS)}, 
title={Comparison of hardware based and software based stress testing of memory IO interface}, 
year={2013}, 
volume={}, 
number={}, 
pages={637-640}, 
abstract={In post-silicon testing and validation of circuit functionality, an effective IO stress pattern can identify bugs quickly and provide adequate test coverage. A lot of work has been done to identify the right stress patterns specific to each IO interface. While some patterns can be generic enough to apply to all IOs, other patterns are interface topology specific. In addition to identifying the worst-case pattern, tradeoffs between test-time and test coverage must be made depending on the test goals. Pseudo Random Bit Stream (PRBS) generators are commonly used to generate test patterns because of the adequate frequency content in the PRBS patterns, the ease of implementation, and minimal gate count. This paper introduces an Advanced Pattern Generator and Checker (APGC) based on PRBS that retains all the aforementioned advantages. The APGC was implemented for a DDR memory interface where different LFSRs beat against each other spatially on neighboring IO lanes while rotating this form of aggressor-victim pattern in time. The results of the APGC stress patterns are compared to a form of advanced software-based learning algorithm based patterns that exhaustively search this complete parameter space. The comparison of APGC to software showed that the measured bit error rate (BER) plotted on a Q-scale of both methods is similar for the Receiver side. On the Transmitter side, APGC showed less eye opening than the software. In addition to the margin comparison, on the test execution side, APGC can speed up the test and validation execution time compared to the software by 32 to 2048 times depending on aggressor victim lane width of 8 to 64 lanes.}, 
keywords={automatic test pattern generation;electronic engineering computing;error statistics;integrated circuit testing;learning (artificial intelligence);peripheral interfaces;random number generation;semiconductor storage;APGC stress pattern;BER;DDR memory interface;IO stress pattern;LFSR;PRBS generators;Q-scale;advanced pattern generator and checker;aggressor-victim pattern;bit error rate;bug identification;circuit functionality validation;gate count;hardware based stress testing;interface topology;memory IO interface;post-silicon testing;pseudorandom bit stream generators;software based stress testing;software-based learning algorithm;test coverage;test execution;test pattern generation;test time;worst-case pattern}, 
doi={10.1109/MWSCAS.2013.6674729}, 
ISSN={1548-3746}, 
month={Aug},}
@INPROCEEDINGS{6159734, 
author={Ren Mingqiu and Cai Jinyan and Zhu Yuanqing and Han Zhuangzhi}, 
booktitle={Proceedings of 2011 IEEE CIE International Conference on Radar}, 
title={Design of radar ECCM performance testing system and its semi-physical simulation experiment}, 
year={2011}, 
volume={2}, 
number={}, 
pages={1058-1062}, 
abstract={This paper describes the theory, design, implementation, simulation and testing of a radar ECCM performance testing system capable of generating target echo, clutter and jamming signal for radar ECM/ECCM experiment. With the help of the proposed testing system, the jamming styles and parameters can be smartly intercalated with a variety of simulation scenarios. The rubs are resolved such as radar states data acquisition, echo real time simulation and display & control terminals setup of signal environment. Then a radar ECM semi-physical simulation experiment is applied to measure six typical ECCM performance indexes in the signal environment generated by the testing system. Experiment and data processing results show the testing platform is valid and practical. The testing system can be used to solve problems such as radar ECCM performance evaluation, radar advanced design and ECCM strategies when the equipment is relatively small in tracking and guidance phase.}, 
keywords={electronic countermeasures;jamming;radar clutter;radar tracking;target tracking;testing;data processing;echo real time simulation;guidance phase;jamming signal;radar ECCM performance testing system;radar clutter;radar states data acquisition;semiphysical simulation experiment;target echo;tracking phase;Electronic countermeasures;Jamming;Radar antennas;Radar tracking;Target tracking;Testing;Radar ECCM;active jamming;evaluation index;semi-physical simulation experiment;testing system}, 
doi={10.1109/CIE-Radar.2011.6159734}, 
ISSN={1097-5764}, 
month={Oct},}
@INPROCEEDINGS{6493621, 
author={Y. Kim and L. K. John and S. Pant and S. Manne and M. Schulte and W. L. Bircher and M. S. S. Govindan}, 
booktitle={2012 45th Annual IEEE/ACM International Symposium on Microarchitecture}, 
title={AUDIT: Stress Testing the Automatic Way}, 
year={2012}, 
volume={}, 
number={}, 
pages={212-223}, 
abstract={Sudden variations in current (large di/dt) can lead to significant power supply voltage droops and timing errors in modern microprocessors. Several papers discuss the complexity involved with developing test programs, also known as stress marks, to stress the system. Authors of these papers produced tools and methodologies to generate stress marks automatically using techniques such as integer linear programming or genetic algorithms. However, nearly all of the previous work took place in the context of single-core systems, and results were collected and analyzed using cycle-level simulators. In this paper, we measure and analyze di/dt issues on state-of-the-art multi-core x86 systems using real hardware rather than simulators. We build on an existing single-core stress mark generation tool to develop an Automated DI/dT stress mark generation framework, referred to as AUDIT, to generate di/dt stress marks quickly and effectively for multicore systems. We showcase AUDIT's capabilities to adjust to micro architectural and architectural changes. We also present a dithering algorithm to address thread alignment issues on multi-core processors. We compare standard benchmarks, existing di/dt stress marks, and AUDIT-generated stress marks executing on multi-threaded, multi-core systems with complex out-of-order pipelines. Finally, we show how stress analysis using simulators may lead to flawed insights about di/dt issues.}, 
keywords={integrated circuit testing;microprocessor chips;multiprocessing systems;stress analysis;AUDIT capabilities;AUDIT-generated stress marks;automated DI-dT stress mark generation framework;cycle-level simulators;dithering algorithm;genetic algorithms;integer linear programming;microarchitectural changes;microprocessors;multicore processors;multithreaded multicore systems;out-of-order pipelines;power supply voltage droops;single-core stress mark generation tool;single-core systems;stress analysis;stress testing;test programs;thread alignment issues;timing errors;di/dt;genetic algorithm;hardware measurement;inductive noise;low power;power distribution network;stressmark generation;voltage droop}, 
doi={10.1109/MICRO.2012.28}, 
ISSN={1072-4451}, 
month={Dec},}
@ARTICLE{5977130, 
author={M. Kalita and T. Bezboruah}, 
journal={IET Software}, 
title={Investigation on performance testing and evaluation of PReWebD: a .NET technique for implementing web application}, 
year={2011}, 
volume={5}, 
number={4}, 
pages={357-365}, 
abstract={A prototype research web application based on Visual Studio platform is developed with .NET as framework, Internet Information Server (IIS) (Version: 5.1) as web server and Microsoft Standard Query Language (SQL) Server (Version: 2005) as database server to study the performance and evaluation of the .NET technique used for developing the web application. The authors call it the PReWebD. As the performance is one of the most important features of a web application, to evaluate the performance, testing of PReWebD has been carried out using Mercury LoadRunner (Version 8.0) for validation and to study some other attributes like scalability, reliability etc. The performance depends on parameters such as hits/s, response time, throughput, errors/s etc. These parameters for PReWebD are tested with different stress levels. The statistical testing and analysis is done to assure the stability, reliability and quality of the application. Here the authors report in details the architecture, testing procedure, result of performance testing as well as the results of statistical analysis on recorded data of PReWebD.}, 
keywords={Internet;SQL;network operating systems;program testing;software architecture;software performance evaluation;statistical testing;.NET technique;Internet Information Server;Mercury LoadRunner;Microsoft Standard Query Language;PReWebD;SQL server;Visual Studio platform;Web application;Web server;architecture;database server;performance evaluation;performance testing;statistical analysis;statistical testing;stress level}, 
doi={10.1049/iet-sen.2010.0139}, 
ISSN={1751-8806}, 
month={August},}
@INPROCEEDINGS{7998430, 
author={A. P. Samoylenko and A. I. Panychev and S. A. Panychev}, 
booktitle={2017 International Siberian Conference on Control and Communications (SIBCON)}, 
title={Evaluation of telecommunication system reliability via stress testing}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={The problem of evaluating reliability of telecommunication systems in general, and their components is considered. The method of forecasting the reliability of a telecommunications system designed according to the results of stress testing is proposed. The essence of the proposed method is to use the emissions of a random process as a diagnostic parameter that displays the trajectory of a monitored quantity values. As a quantitative measure of reliability used system average uptime. The simulation for normal distribution law of a random parameters with different correlation functions is carried out. The estimation of the average uptime for various sizes of tolerance range of parameters is calculated. It is shown that the theory of random processes emissions is an adequate mathematical apparatus for the formalization of the results of stress testing.}, 
keywords={mathematical analysis;telecommunication network reliability;diagnostic parameter;different correlation functions;mathematical apparatus;monitored quantity values;normal distribution law;random parameters;random process emissions;stress testing;system average uptime;telecommunication system reliability;Monitoring;Random processes;Reliability;Stress;Telecommunications;Testing;Trajectory;average uptime;emissions of a random process;forced testing;reliability;stress test;survivability;telecommunication system;the trajectory of a random parameter;tolerance domain}, 
doi={10.1109/SIBCON.2017.7998430}, 
ISSN={}, 
month={June},}
@ARTICLE{4302730, 
author={S. Pakin}, 
journal={IEEE Transactions on Parallel and Distributed Systems}, 
title={The Design and Implementation of a Domain-Specific Language for Network Performance Testing}, 
year={2007}, 
volume={18}, 
number={10}, 
pages={1436-1449}, 
abstract={CONCEPTUAL is a toolset designed specifically to help measure the performance of high-speed interconnection networks such as those used in workstation clusters and parallel computers. It centers around a high-level domain-specific language, which makes it easy for a programmer to express, measure, and report the performance of complex communication patterns. The primary challenge in implementing a compiler for such a language is that the generated code must be extremely efficient so as not to misattribute overhead costs to the messaging library. At the same time, the language itself must not sacrifice expressiveness for compiler efficiency, or there would be little point in using a high-level language for performance testing. This paper describes the CONCEPTUAL language and the CONCEPTUAL compiler's novel code-generation framework. The language provides primitives for a wide variety of idioms needed for performance testing and emphasizes a readable syntax. The core code-generation technique, based on unrolling CONCEPTUAL programs into sequences of communication events, is simple yet enables the efficient implementation of a variety of high-level constructs. The paper further explains how CONCEPTUAL implements time-bounded loops - even those that comprise blocking communication - in the absence of a time-out mechanism as this is a somewhat unique language/implementation feature.}, 
keywords={computational linguistics;high level languages;message passing;program compilers;program control structures;program testing;software performance evaluation;specification languages;CONCEPTUAL language;blocking communication;code generation;domain-specific language;high-level language;high-speed interconnection networks;messaging library;network performance testing;parallel computers;program compiler;readable syntax;time-bounded loops;time-out mechanism;workstation clusters;Computer networks;Concurrent computing;Costs;Domain specific languages;High performance computing;Libraries;Multiprocessor interconnection networks;Programming profession;Testing;Workstations;Interprocessor communications;Measurement techniques;Specialized application languages}, 
doi={10.1109/TPDS.2007.1065}, 
ISSN={1045-9219}, 
month={Oct},}
@INPROCEEDINGS{6008948, 
author={M. A. S. Netto and S. Menon and H. V. Vieira and L. T. Costa and F. M. de Oliveira and R. Saad and A. Zorzo}, 
booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
title={Evaluating Load Generation in Virtualized Environments for Software Performance Testing}, 
year={2011}, 
volume={}, 
number={}, 
pages={993-1000}, 
abstract={Before placing a software system into production, it is necessary to guarantee it provides users with a certain level of Quality-of-Service. Intensive performance testing is then necessary to achieve such a level and the tests require an isolated computing environment. Virtualization can therefore play an important role for saving energy costs by reducing the number of servers required to run performance tests and for allowing performance isolation when executing multiple tests in the same computing infrastructure. Load generation is an important component in performance testing as it simulates users interacting with the target application. This paper presents our experience in using a virtualized environment for load generation aimed at performance testing. We measured several performance metrics and varied system load, number of virtual machines per physical resource, and the CPU pinning schema for comparison of virtual and physical machines. The two main findings from our experiments are that physical machines produced steadier and faster response times under heavy load and that the pinning schema is an important aspect when setting up a virtualized environment for load generation.}, 
keywords={program testing;software metrics;software performance evaluation;virtual machines;virtualisation;isolated computing environment;load generation;performance metrics;quality-of-service;software performance testing;virtual machines;virtualization;virtualized environment;Generators;Measurement;Servers;Testing;Throughput;Time factors;Virtual machining}, 
doi={10.1109/IPDPS.2011.244}, 
ISSN={1530-2075}, 
month={May},}
@INPROCEEDINGS{6119091, 
author={S. Tangadpalliwar and K. Sandrasegaran and M. Raymond and A. Moitra and F. Madani}, 
booktitle={2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing}, 
title={Benchmarking Embedded Devices for Broadband Performance Testing}, 
year={2011}, 
volume={}, 
number={}, 
pages={321-327}, 
abstract={Real time monitoring of broadband performance parameters is critical for estimating the user experience of new broadband services like VoIP, IPTV, Gaming and Video. This information is of interest to service providers themselves for efficient network design and maintenance and government regulatory bodies for analyzing ISPs, regions and national benchmarking. A web-based system TRUEE (Tool for Real-time User Experience Estimation) is a distributed system that incorporates independent modules such as standalone measurement devices installed at customer premises, data centers, test servers and web-clients for remote monitoring and management of the system. The focus of this paper is to discuss the process of benchmarking three commercial embedded devices with PC as reference device representing an end user system for accessing broadband services. This work is part of the ongoing development process of TRUEE. This benchmarking process is of significant importance for making an informed decision on the suitability of an embedded device capable of providing desired accuracy and consistency in estimation of the broadband performance parameters. Based on literature review, online forum reviews and cost analysis three devices based on ARM viz. SheevaPlug, Texas Instrument's BeagleBoard-xM and Gumstix Overo are selected for benchmarking. Results show that Marvell's SheevaPlug outperforms the other two devices in accurately measuring the broadband parameters on its network interface.}, 
keywords={Internet;benchmark testing;broadband networks;embedded systems;performance evaluation;ARM based device;Gumstix Overo;ISP analysis;Marvell SheevaPlug;TRUEE;Texas Instrument's BeagleBoard-xM;Web-based system;Web-clients;benchmarking embedded device;broadband performance parameter;broadband performance testing;broadband service;customer premises;data center;distributed system;end user system;government regulatory body;national benchmarking;network interface;real time monitoring;region benchmarking;remote monitoring;service provider;test servers;tool for real-time user experience estimation;Bandwidth;Benchmark testing;Broadband communication;Jitter;Linux;Performance evaluation;Throughput;Benchmarking;Broadband;Embedded device;Network Monitoring;Performance Testing}, 
doi={10.1109/DASC.2011.71}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{7819257, 
author={E. Siivola and S. Sierla and H. Niemistö and T. Karhela and V. Vyatkin}, 
booktitle={2016 IEEE 14th International Conference on Industrial Informatics (INDIN)}, 
title={Requirement verification in simulation-based automation testing}, 
year={2016}, 
volume={}, 
number={}, 
pages={740-743}, 
abstract={The emergence of the Industrial Internet results in an increasing number of complicated temporal interdependencies between automation systems and the processes to be controlled. There is a need for verification methods that scale better than formal verification methods and which are more exact than testing. Simulation-based runtime verification is proposed as such a method, and an application of Metric temporal logic is presented as a contribution. The practical scalability of the proposed approach is validated against a production process designed by an industrial partner, resulting in the discovery of requirement violations.}, 
keywords={Internet;automation;digital simulation;formal verification;production engineering computing;temporal logic;testing;formal verification;industrial Internet emergence;metric temporal logic;production process;requirement verification;simulation-based automation testing;simulation-based runtime verification;Automation;Leaching;Metals;Monitoring;Runtime;Slurries;Testing}, 
doi={10.1109/INDIN.2016.7819257}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{8250706, 
author={P. Seth and N. Rane and A. Wagh and A. Katade and S. Sahu and N. Malhotra}, 
booktitle={2017 International Conference on Intelligent Computing and Control Systems (ICICCS)}, 
title={Uberisation of mobile automation testing}, 
year={2017}, 
volume={}, 
number={}, 
pages={181-183}, 
abstract={Mobile phones and mobile applications have now become an essential part of everyday life. To make Mobile applications more reliable and error free, mobile application testing is important. Currently only a few techniques exist for creating automate tests of mobile applications and their functionality is very limited. In this paper, we introduce the new way of implementing a mobile test automation platform which performs mobile test automation from mobile devices itself. The main aim of automating the testing process is to develop a high quality and optimized applications to deliver efficient results to the customer.}, 
keywords={mobile computing;mobile handsets;program testing;Mobile phones;mobile application testing;mobile automation testing;mobile devices;mobile test automation platform;Androids;Automation;Mobile applications;Mobile communication;Mobile handsets;Testing;Tools;Device automation;Mobile app testing;Software Engineering;Software quality;Test Automation;Wireless testing}, 
doi={10.1109/ICCONS.2017.8250706}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{1625700, 
author={Bum Hyun Lim and Jin Ryong Kim and Kwang Hyun Shim}, 
booktitle={2006 8th International Conference Advanced Communication Technology}, 
title={A load testing architecture for networked virtual environment}, 
year={2006}, 
volume={1}, 
number={}, 
pages={5 pp.-848}, 
abstract={In this work, we develop a load testing architecture for networked virtual environment to reduce the testing time and ensure the stability of the server for distributed applications. It explicitly secures the stability of the server for networked virtual environment and at the same time, it elaborately generates actual loads for testing the performance of the server. Our agent based load testing architecture provides variety of interactions of virtual entities in the virtual worlds to perform realistic simulations. Simulation results show that our proposed architecture ensures the stability and capacity of the servers}, 
keywords={client-server systems;resource allocation;distributed applications;load testing architecture;networked virtual environment;server stability;virtual client;Analytical models;Databases;Discrete event simulation;Environmental management;Large-scale systems;Libraries;Network servers;Protocols;Testing;Virtual environment;Load test;beta test;game simulator;networked virtual environment;stress test;virtual client}, 
doi={10.1109/ICACT.2006.206095}, 
ISSN={}, 
month={Feb},}
@INPROCEEDINGS{5552290, 
author={D. Hao and Y. Chen and F. Tang and F. Qi}, 
booktitle={2010 IEEE International Conference on Software Engineering and Service Sciences}, 
title={Distributed agent-based performance testing framework on Web Services}, 
year={2010}, 
volume={}, 
number={}, 
pages={90-94}, 
abstract={Web Services are applied widely in the field of information technology, and performance testing for Web Services applications has become an important problem. This paper introduces the method of performance testing, and proposes a framework of agent-based performance testing on Web Services, which includes TestFlow Generator, Scenario Creator, Test Manager, Load Generation Agent and Test Analyzer. And the implementation of kernel modules in the framework is introduced especially. To realize the load allocation to distributed Load Generation Agents from Test Manager, a queue-based allocation strategy is given.}, 
keywords={Load modeling;Monitoring;Resource management;Schedules;Testing;Web services;Web Services;allocation strategy;load generation;performance testing}, 
doi={10.1109/ICSESS.2010.5552290}, 
ISSN={2327-0586}, 
month={July},}
@INPROCEEDINGS{7203126, 
author={Z. M. J. Jiang}, 
booktitle={2015 IEEE/ACM 37th IEEE International Conference on Software Engineering}, 
title={Load Testing Large-Scale Software Systems}, 
year={2015}, 
volume={2}, 
number={}, 
pages={955-956}, 
abstract={Large-scale software systems (e.g., Amazon and Dropbox) must be load tested to ensure that they can service thousands or millions of concurrent requests every day. In this technical briefing, we will describe the state of research and practices in the area of load testing. We will focus on the techniques used in the three phases of a load test: (1) designing a load test, (2) executing a load test, and (3) analyzing the results of a load test. This technical briefing is targeted at load testing practitioners and software engineering researchers interested in testing and analyzing the behavior of large-scale software systems.}, 
keywords={program testing;Amazon;Dropbox;large-scale software system load testing;Computer science;Conferences;Monitoring;Software engineering;Software systems;Testing;load testing;performance;scalability;software testing}, 
doi={10.1109/ICSE.2015.304}, 
ISSN={0270-5257}, 
month={May},}
@INPROCEEDINGS{5366326, 
author={Z. Liang and L. Jianhua and W. Ruofei and G. Xiaobin}, 
booktitle={2009 International Conference on Energy and Environment Technology}, 
title={Design of Performance Testing System for Train Air Conditioning}, 
year={2009}, 
volume={1}, 
number={}, 
pages={85-89}, 
abstract={The design of performance testing system for train air conditioning was done according to the NATIONAL STANDARD TB/T 1804-2003. The cooling capacity was measured by means of air enthalpy difference method. The hardware part of the test system consists of data collection unit and test instrument, while the software is programmed with Visual Basic 6.0, accompanied with the Microsoft Access database. The PLC unit and the touch screen are employed for local control of the system to achieve precise adjustment to the temperature and humidity of environmental chamber, the speed and flow of air. In view of the system characteristics of complex nonlinearity and being difficult to control exactly, test system adopts a fuzzy PID control based on plc to control experimental parameters such as temperature and humidity.}, 
keywords={Visual BASIC;air conditioning;computerised instrumentation;fuzzy control;programmable controllers;test equipment;three-term control;touch sensitive screens;visual programming;Microsoft Access database;National Standard TB/T 1804-2003;PLC unit;Visual Basic 6.0;air enthalpy difference method;cooling capacity;data collection unit;environmental chamber humidity;fuzzy PID control;performance testing system;programmable logic controller;test instrument;touch screen;train air conditioning;Air conditioning;Control systems;Cooling;Hardware;Humidity control;Nonlinear control systems;Programmable control;Software testing;System testing;Temperature control;data acquisition;fuzzy control;performance test system;train air conditioning}, 
doi={10.1109/ICEET.2009.27}, 
ISSN={}, 
month={Oct},}
@ARTICLE{4314840, 
author={P. D. Baxter and V. Lang and A. Anouchi}, 
journal={IEEE Transactions on Instrumentation and Measurement}, 
title={A Microprocessor-Based Positive Displacement Measurement System for Diesel Pump and Injector Performance Testing}, 
year={1979}, 
volume={28}, 
number={4}, 
pages={317-320}, 
abstract={New stringent emissions and economy requirements for the burgeoning diesel engine market have resulted in development of a new entirely digital microprocessor-based fuel delivery measurement system. The system uses a unique inherently digital transducer and a microprocessor for measurement and control.}, 
keywords={Diesel engines;Displacement measurement;Engine cylinders;Fluid flow measurement;Fuels;Maintenance;Pressure measurement;System testing;Transducers;Velocity measurement}, 
doi={10.1109/TIM.1979.4314840}, 
ISSN={0018-9456}, 
month={Dec},}
@ARTICLE{1377198, 
author={A. Avritzer and E. J. Weyuker}, 
journal={IEEE Transactions on Software Engineering}, 
title={The role of modeling in the performance testing of e-commerce applications}, 
year={2004}, 
volume={30}, 
number={12}, 
pages={1072-1083}, 
abstract={An e-commerce scalability case study is presented in which both traditional performance testing and performance modeling were used to help tune the application for high performance. This involved the creation of a system simulation model as well as the development of an approach for test case generation and execution. We describe our experience using a simulation model to help diagnose production system problems, and discuss ways that the effectiveness of performance testing efforts was improved by its use.}, 
keywords={Java;electronic commerce;program testing;resource allocation;software performance evaluation;e-commerce;production system diagnosis;software performance modeling;software performance testing;test case generation;workload characterization;Aerospace testing;Computer architecture;Databases;Helium;Java;Monitoring;Production systems;Scalability;Software testing;System testing}, 
doi={10.1109/TSE.2004.107}, 
ISSN={0098-5589}, 
month={Dec},}
@INPROCEEDINGS{6317675, 
author={C. Williamette and E. Hansen}, 
booktitle={2012 38th IEEE Photovoltaic Specialists Conference}, 
title={Development of electrical performance testing standards for the acceptance of solar photovoltaic projects based on field experience and observation}, 
year={2012}, 
volume={}, 
number={}, 
pages={000554-000559}, 
abstract={As-built performance requirements are becoming more common in Interconnection Applications (IAs) and Power Purchase Agreements (PPAs). Often overlooked as, “just the last step in the commissioning process,” it is important to understand the scope of the testing requirements before committing to the agreement. The worst case scenario is when your project has design flaws that prevent it from meeting requirements. By the time the system is discovered to be failing, it can be too late and too costly to fix. Understanding standards for performance testing can help guide project design to ensure better success meeting those requirements later on.}, 
keywords={commissioning;interconnections;photovoltaic power systems;solar power stations;standards;PPA;commissioning process;electrical performance testing standards;field experience;interconnection applications;power purchase agreements;solar PV systems;solar photovoltaic projects;Indexes;Inverters;Irrigation;Monitoring;Soil;Wiring;Current-voltage characteristics;Performance Analysis;Soil measurements;Solar energy;System analysis and design;Thermal analysis}, 
doi={10.1109/PVSC.2012.6317675}, 
ISSN={0160-8371}, 
month={June},}
@INPROCEEDINGS{5405721, 
author={G. h. Kim and H. c. Moon and G. P. Song and S. K. Shin}, 
booktitle={Proceedings of the 4th International Conference on Ubiquitous Information Technologies Applications}, 
title={Software Performance Testing Scheme Using Virtualization Technology}, 
year={2009}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={In this paper, we propose software performance testing scheme using virtualization technology. Generally, people have used software performance testing tool such as load runner and silk performer. However, people should perform software performance testing manually in case of the situation that people cannot use testing tool. It needs a lot of resources such as human resource and computing resource. Therefore, we propose software performance testing scheme using virtualization technology to reduce resource consumption. Proposed scheme can reduce computer resource consumption because virtualization technology can make a number of virtual computers with a small number of physical computers. Also proposed scheme can reduce human resource consumption because, in proposed scheme, management computer can control keyboard and mouse of virtual computers automatically. Simulation result shows that proposed scheme has possibility to be used for software performance testing.}, 
keywords={software performance evaluation;virtual machines;computer management;computing resource;human resource;software performance testing;virtual computers;virtualization technology;Automatic control;Computational modeling;Human resource management;Keyboards;Mice;Performance evaluation;Physics computing;Resource virtualization;Software performance;Software testing}, 
doi={10.1109/ICUT.2009.5405721}, 
ISSN={1976-0035}, 
month={Dec},}
@ARTICLE{4015510, 
author={D. Krishnamurthy and J. A. Rolia and S. Majumdar}, 
journal={IEEE Transactions on Software Engineering}, 
title={A Synthetic Workload Generation Technique for Stress Testing Session-Based Systems}, 
year={2006}, 
volume={32}, 
number={11}, 
pages={868-882}, 
abstract={Enterprise applications are often business critical but lack effective synthetic workload generation techniques to evaluate performance. These workloads are characterized by sessions of interdependent requests that often cause and exploit dynamically generated responses. Interrequest dependencies must be reflected in synthetic workloads for these systems to exercise application functions correctly. This poses significant challenges for automating the construction of representative synthetic workloads and manipulating workload characteristics for sensitivity analyses. This paper presents a technique to overcome these problems. Given request logs for a system under study, the technique automatically creates a synthetic workload that has specified characteristics and maintains the correct interrequest dependencies. The technique is demonstrated through a case study involving a TPC-W e-commerce system. Results show that incorrect performance results can be obtained by neglecting interrequest dependencies, thereby highlighting the value of our technique. The study also exploits our technique to investigate the impact of several workload characteristics on system performance. Results establish that high variability in the distributions of session length, session idle times, and request service times can cause increased contention among sessions, leading to poor system responsiveness. To the best of our knowledge, these are the first results of this kind for a session-based system. We believe our technique is of value for studies where fine control over workload is essential}, 
keywords={electronic commerce;performance evaluation;program testing;TPC-W e-commerce system;e-commerce system;enterprise application;performance evaluation;sensitivity analyses;stress testing session-based system;synthetic workload generation technique;Application software;Character generation;Computer Society;Delay;Occupational stress;Sensitivity analysis;Stress control;System performance;System testing;Web server;Internet applications;Performance of systems;Web servers.;electronic commerce;measurement techniques;modeling techniques;software engineering;testing tools}, 
doi={10.1109/TSE.2006.106}, 
ISSN={0098-5589}, 
month={Nov},}
@INPROCEEDINGS{6933530, 
author={G. H. Hwang and C. Wu-Lee and Y. H. Tung and C. J. Chuang and S. F. Wu}, 
booktitle={2014 IEEE 5th International Conference on Software Engineering and Service Science}, 
title={Implementing TaaS-based stress testing by MapReduce computing model}, 
year={2014}, 
volume={}, 
number={}, 
pages={137-140}, 
abstract={In this paper we propose to employ the MapReduce computing model to implement a Testing as a Service (TaaS) for stress testing. We focus on stress testing for heavy-weight network transactions. The computation power of MapReduce computing system is used to simulate concurrent network transactions issued by a lot of users. The user first describes the testing scenario which he wants to be simulate in a testing script. The TaaS platform analyzes the testing script and then automatically distributes required testing data including details of transactions and files into a MapReduce computing system. We propose three different schemes to distribute testing data and measure their performances. We compare them with the popular stress testing tool JMeter and find out that our scheme can always have the tested system deliver higher error rate during the stress testing.}, 
keywords={distributed programming;program testing;JMeter;MapReduce computing model;TaaS-based stress testing;testing as a service;Computational modeling;Computer crashes;Error analysis;Instruction sets;Servers;Stress;Hadoop;MapReduce;Stress testing}, 
doi={10.1109/ICSESS.2014.6933530}, 
ISSN={2327-0586}, 
month={June},}
@INPROCEEDINGS{8329877, 
author={J. Wienke and D. Wigand and N. Koster and S. Wrede}, 
booktitle={2018 Second IEEE International Conference on Robotic Computing (IRC)}, 
title={Model-Based Performance Testing for Robotics Software Components}, 
year={2018}, 
volume={}, 
number={}, 
pages={25-32}, 
abstract={In complex technical systems like robotics platforms, a manifold of issues can impair their dependability. While common testing and simulation methods largely focus on functional aspects, the utilization of resources like CPU, network bandwidth, or memory is only rarely tested systematically. With this contribution we propose a novel Domain-Specific Language (DSL) for modeling performance tests for individual robotics components with the aim to establish a systematic testing process for detecting regressions regarding the resource utilization. This DSL builds upon a testing framework from previous research and aims to significantly reduce the effort and complexity for creating performance tests. The DSL is built using the MPS language workbench and provides a feature-rich editor with modern editing aids. An evaluation indicates that developing performance tests requires only one third of the work in comparison to the original Java-based API.}, 
keywords={C language;control engineering computing;embedded systems;formal specification;object-oriented programming;product development;program diagnostics;public domain software;robots;specification languages;DSL;Domain-Specific Language;MPS language workbench;complex technical systems;editing aids;feature-rich editor;model-based performance tests;performance testing;resource utilization;robotics platforms;robotics software components;simulation methods;systematic testing process;DSL;Resource management;Robots;Software;Testing;Tools;Unified modeling language;CBSE;DSL;MPS;performance;performance testing;resource awareness;testing}, 
doi={10.1109/IRC.2018.00013}, 
ISSN={}, 
month={Jan},}
@INPROCEEDINGS{527964, 
author={D. Le and I. Karolik and R. Smith and A. J. Mcgovern and C. Curette and J. Ulbin and M. Zarubaiko and C. Henry and L. Stevens}, 
booktitle={Proceedings., International Test Conference}, 
title={Environmental Stress Testing with Boundary-Scan}, 
year={1994}, 
volume={}, 
number={}, 
pages={307-313}, 
abstract={Environmental Stress Testing (EST) enhances product quality and reliability by detecting latent or marginal defects in a product. For EST to be effective, testing of a product must achieve a high fault coverage so that as many EST-induced defects can be detected. By utilizing Boundary-Scan (IEEE Std 1149.1-1990), EST can achieve a high fault coverage and at the same time, minimize test cost. The paper describes a complete infrastructure, both software and hardware, for using Boundary-Scan (B-S) in EST. In addition, the paper shows a simplified control mechanism to select individual circuit packs for Boundary-Scan testing. This control mechanism minimizes the number of wires required to drive the control interface and thus, the number of wires in the cable that connects a tester to the backplane of a system under test and across which Boundary-Scan tests are executed. Finally, the paper presents and discusses some study results for evaluating the effectiveness of monitored EST}, 
keywords={IEEE standards;automatic testing;boundary scan testing;environmental stress screening;production testing;IEEE Std 1149.1;boundary scan testing;control;control interface;effectiveness;environmental stress testing;fault coverage;latent defects;marginal defects;product quality;reliability;test cost;Circuit faults;Circuit testing;Control systems;Costs;Electrical fault detection;Fault detection;Hardware;Stress;System testing;Wires}, 
doi={10.1109/TEST.1994.527964}, 
ISSN={1089-3539}, 
month={Oct},}
@INPROCEEDINGS{7397245, 
author={A. Ali and N. Badr}, 
booktitle={2015 IEEE Seventh International Conference on Intelligent Computing and Information Systems (ICICIS)}, 
title={Performance testing as a service for web applications}, 
year={2015}, 
volume={}, 
number={}, 
pages={356-361}, 
abstract={Software testing is a vital activity that is undertaken during software engineering life cycle to ensure software quality and reliability. Performance testing is a type of software testing that is done to shows how web application behaves under a certain workload. Cloud computing as an emerging technology can be used in the field of software engineering to provide cloud testing in order to overcome all deficiencies of conventional testing by leveraging cloud computing resources. As a result, testing-as-a-service (TaaS) is introduced as a service model that performs all testing activities in fully automated manner, on demand with a pay-for use basis. Moreover, TaaS increases testing efficiency and reduces time and cost required for testing. In this paper, performance TaaS framework for web applications is introduced which provides all performance testing activities including automatic test case generation and test execution. In addition, the proposed framework addresses many issues as: maximize resource utilization and continuous monitoring to ensure system reliability.}, 
keywords={Web services;program testing;software performance evaluation;software quality;Web applications;automatic test case generation;cloud computing resources;cloud testing;continuous monitoring;performance testing;software engineering life cycle;software quality;software reliability;software testing;system reliability;testing-as-a-service;Fault tolerance;Fault tolerant systems;Software;Testing;Virtualization;Cloud Computing;JMeter;Performance Testing;TaaS;web Application Testing}, 
doi={10.1109/IntelCIS.2015.7397245}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{284630, 
author={J. A. Jodice and S. Harpham}, 
booktitle={Developments in the Use of Global Positioning Systems}, 
title={`End-to-end transient simulation for protection system performance testing'}, 
year={1994}, 
volume={}, 
number={}, 
pages={6/1-6/5}, 
abstract={Formatted according to the new IEEE Standard C37.111, 1992 (COMTRADE), digital information describing power system disturbances controls a test system which produces transient simulation signals for analyzing protective relay performance. Global positioning system (GPS) satellite timing signals are used to synchronize two remotely located test systems for performing transient end-to-end simulation tests. DFR records of actual events and Electromagnetic Transient Program (EMTP) simulations of multiple fault events, played back through satellite-synchronized end-to-end test systems have proven comprehensive analytical tools-virtually eliminating the need for costly and dangerous staged fault tests generally performed at a limited number of locations}, 
keywords={digital simulation;electrical faults;power system analysis computing;power system protection;radionavigation;relay protection;satellite relay systems;software packages;synchronisation;Electromagnetic Transient Program;GPS;Global Positioning System;IEEE Standard C37.111;digital fault recorders;digital simulation;end-to-end simulation;multiple fault events;performance testing;power system disturbances;protective relay performance;satellite timing signals;synchronisation;transient simulation signals}, 
doi={}, 
ISSN={}, 
month={Feb},}
@INPROCEEDINGS{6008274, 
author={W. Xu and C. Lv}, 
booktitle={2011 2nd International Conference on Intelligent Control and Information Processing}, 
title={Research of virtual reality in industrial design manufacture and performance testing}, 
year={2011}, 
volume={1}, 
number={}, 
pages={403-405}, 
abstract={Virtual reality (VR) is a new method of visual operating and interacting of complex data can be realized by computers, in which one would have an immersed sense to observe and operate objects in three dimensions timely and unboundedly. VR is a new developing technique and a complex simulation tool for industry, it builds a simulated environment in which researchers can do many things such as driving, operating, designing and performance test in a unaffected way. Performance test plays an important role in vehicle design. Most of interactive processing in virtual vehicle manufacturing is perfect, but many deep interactive functions are under emphasis such as performance test after manufacturing, variation and recording of performance parameters. Research of VRML combining with JavaScript is presented in this paper, and vehicle designing and manufacturing, testing system are built based on it, in which we can real-time and dynamic control the car through keyboard and mouse, and get the real-time performance parameters.}, 
keywords={Java;automatic test software;automobile manufacture;performance evaluation;production engineering computing;virtual manufacturing;virtual reality languages;JavaScript;VRML;industrial design manufacture;interactive processing;performance testing;simulation tool;vehicle design;virtual reality;virtual vehicle manufacturing;visual interaction;Computational modeling;Shape}, 
doi={10.1109/ICICIP.2011.6008274}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{5456825, 
author={Xiao-yang Guo and Ying-hui Chen and Xue-song Qiu and Fan Tang}, 
booktitle={2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics (CAR 2010)}, 
title={Design and implementation of performance testing model for Web Services}, 
year={2010}, 
volume={1}, 
number={}, 
pages={353-356}, 
abstract={The performance testing model for Web Services is proposed. Aiming to enhance testing efficiency and automation, the model provides a multi-machine joint testing model and strategy model. The former is used to share the heavy load to multiple units, which could also be called load balance model, and the latter is used to simulate a realistic Web Services running environment. The model has been applied to an original web services testing software, and proved to be a feasible way for performance testing for web services.}, 
keywords={Web services;program testing;resource allocation;software performance evaluation;heavy load share;load balance model;multi-machine joint testing model;realistic Web services running environment;software performance testing model;Asia;Automatic control;Automatic testing;Informatics;Laboratories;Load modeling;Robotics and automation;Service oriented architecture;Software testing;Web services;load balance;multi-machine testing;performance testing;strategy model;web services}, 
doi={10.1109/CAR.2010.5456825}, 
ISSN={1948-3414}, 
month={March},}
@INPROCEEDINGS{5729579, 
author={R. W. Y. Habash and V. Groza and Y. Yang and C. Blouin and P. Guillemette}, 
booktitle={2011 Sixth IEEE International Symposium on Electronic Design, Test and Application}, 
title={Performance Testing and Control of a Small Wind Energy Converter}, 
year={2011}, 
volume={}, 
number={}, 
pages={263-268}, 
abstract={Responding to more demand in coming years, the task of the small wind energy industry requires progress on several fronts-from public policy initiatives, to technology development, to market growth. Enhanced technologies such as contra-rotating blades, transmission systems, lubrication, airfoils, generators, and power electronics will lower cost and increase energy production. This paper mainly considers two key technological points of a small wind energy converter (SWEC) namely, the performance of the rotor system and induction generator. Small-scale prototypes have been built to experimentally verify the performance of the SWEC. Wind tunnel tests of the power output, power coefficient, and turbine speed were carried out to ascertain the aerodynamic power conversion and the operation capability at lower wind speeds. The results demonstrated a significant increase in performance compared to a single-rotor system of the same type. Another aspect of development and test is to present a comparative performance evaluation between a standard induction generator and an efficient but with modified design (TRIAS Generator) as a realistic solution of clean power for grid-connected SWECs. The paper also discusses issues related to control and monitoring of SWEC.}, 
keywords={aerodynamics;asynchronous generators;power convertors;power generation control;power grids;power markets;rotors;wind power plants;wind tunnels;wind turbines;aerodynamic power conversion;grid connected SWEC;induction generator;market growth;performance testing;public policy;rotor system;small scale prototype;small wind energy converter control;technology development;wind energy industry;wind tunnel;Blades;Generators;Induction motors;Rotors;Wind energy;Wind speed;Wind turbines;Small wind generator;contra-rotating system;induction generator}, 
doi={10.1109/DELTA.2011.55}, 
ISSN={}, 
month={Jan},}
@ARTICLE{801951, 
author={P. K. Ghosh and L. G. Durante}, 
journal={IEEE Transactions on Power Systems}, 
title={Measurement performance testing for nonsinusoidal environments}, 
year={1999}, 
volume={14}, 
number={4}, 
pages={1526-1532}, 
abstract={A comparative study of the measurement accuracy capabilities of solid state watthour meters and other commercially available measurement instruments was performed. This study proposes a set of mathematically designed "waveforms" that could be used as a standard for the uniform, meaningful and reproducible evaluation testing of solid state watthour meters designed for use in nonsinusoidal environments. The test waveforms were theoretically developed based on an extensive database of field captured distorted waveforms that, in most cases, were monitored and recorded during power quality investigations over the last five years. Experimentation was performed using both the theoretically developed waveforms and the field captured waveforms.}, 
keywords={calibration;harmonic distortion;power measurement;power supply quality;power system harmonics;watthour meters;measurement accuracy;measurement instruments;measurement performance testing;nonsinusoidal supply environments;power quality;solid state watthour meters;Electric variables measurement;Guidelines;Harmonic distortion;Laboratories;Power system harmonics;Power systems;Semiconductor materials;Solid state circuits;Testing;Watthour meters}, 
doi={10.1109/59.801951}, 
ISSN={0885-8950}, 
month={Nov},}
@ARTICLE{4112302, 
author={R. E. Lee and M. T. Bishop}, 
journal={IEEE Transactions on Power Apparatus and Systems}, 
title={Performance Testing of the Ratio Ground Relay on a Four-Wire Distribution Feeder}, 
year={1983}, 
volume={PAS-102}, 
number={9}, 
pages={2943-2949}, 
abstract={Digital fault investigations on six Pennsylvania Power and Light 12 kV distribution feeders led to the development of a prototype Ratio Ground Relay to theoretically provide better detection of broken conductor faults. Further assessment of the relay's performance was provided through analog computer tests followed by staged fault testing on an operating distribution feeder. Performance tests are described and documented. These positive test results provided the incentive to monitor the performance of the Ratio Ground Relay on several PP&L distribution feeders.}, 
keywords={Analog computers;Circuit faults;Circuit testing;Conductors;Digital relays;Fault detection;Impedance;Performance evaluation;Power system relaying;Prototypes}, 
doi={10.1109/TPAS.1983.318145}, 
ISSN={0018-9510}, 
month={Sept},}
@ARTICLE{536458, 
author={D. Grossman and M. C. McCabe and C. Staton and B. Bailey and O. Frieder and D. C. Roberts}, 
journal={IEEE Software}, 
title={Performance testing a large finance application}, 
year={1996}, 
volume={13}, 
number={5}, 
pages={50-54}, 
abstract={The case study presented in the paper shows how a simple prototype can be used to verify, before production, that a system will perform at an acceptable level under realistic conditions. The study involves the first implementation of American Management System's Federal Financial System (FFS), a financial accounting application, in a customer information control system (CICS) DB2 environment running on a large IBM mainframe}, 
keywords={accounts data processing;financial data processing;program testing;program verification;relational databases;software performance evaluation;American Management System;DB2 environment;Federal Financial System;IBM mainframe;case study;customer information control system;financial accounting application;large finance application;performance testing;program verification;relational database;simple prototype;Control systems;Database systems;Delay;Environmental management;Finance;Financial management;Information technology;Operating systems;Performance evaluation;Production systems;Prototypes;Stress;System testing;Technology management;Testing}, 
doi={10.1109/52.536458}, 
ISSN={0740-7459}, 
month={Sep},}
@INPROCEEDINGS{6131250, 
author={S. Duttagupta and M. Nambiar}, 
booktitle={2011 UKSim 5th European Symposium on Computer Modeling and Simulation}, 
title={Performance Extrapolation for Load Testing Results of Mixture of Applications}, 
year={2011}, 
volume={}, 
number={}, 
pages={424-429}, 
abstract={Load testing of IT applications faces the challenge of providing high quality test results that would represent the performance in production like scenarios, without incurring high cost of commercial load testing tools. It would help IT projects to be able to test with a small number of users and extrapolate to scenarios with much larger number of users. Such an extrapolation strategy when applied to mixture of application workloads running on a shared server environment must take into consideration application characteristics (CPU/IO intensive, memory bound) as well the server capabilities. The goal is to predict the performance of mixture workload, the maximum throughput offered by the application mix and the maximum number of users supported by the system before the throughput starts degrading. In this paper, we propose an extrapolation strategy that analyses a system workload mix based on its service demand on various resources and extrapolates its performance using simple empirical modeling techniques. Moreover, its ability to extrapolate throughput of an application mixture even if there is a change in the mixture, can help in capacity planning of the system.}, 
keywords={extrapolation;program testing;IT application;application mixture;empirical modeling technique;extrapolation strategy;information technology;load testing;Extrapolation;Load modeling;Production;Servers;Telecommunications;Testing;Throughput;Extrapolation;S-curve;load Testing;mixture of applications;multi-classes of job}, 
doi={10.1109/EMS.2011.56}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6449887, 
author={M. Singh and R. Singh}, 
booktitle={2012 2nd IEEE International Conference on Parallel, Distributed and Grid Computing}, 
title={Load Testing of web frameworks}, 
year={2012}, 
volume={}, 
number={}, 
pages={592-596}, 
abstract={This document deals with a comparative analysis on the web frame works namely Spring3.0 MVC, Struts 2.0, JSF 1.2x and Wickets. A detailed study is given on the behavior of the frameworks when they are utilized in the front end and at the backend JPA is used to make communication with the database. The Database utilized is Oracle 10g. Load Testing of all the applications is done using J-meter.}, 
keywords={Internet;database management systems;online front-ends;program testing;J-meter;JSF 1.2x;Oracle 10g;Spring3.0 MVC;Struts 2.0;Web frameworks;Wickets;backend JPA;database;front end;load testing;Bandwidth;Color;Information filters;Process control;Springs;Throughput;JSF 1.2x;Spring3.0 MVC;Struts 2.0;Wickets and JPA}, 
doi={10.1109/PDGC.2012.6449887}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6927571, 
author={A. Freitas and R. Vieira}, 
booktitle={2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)}, 
title={An Ontology for Guiding Performance Testing}, 
year={2014}, 
volume={1}, 
number={}, 
pages={400-407}, 
abstract={Software test is a technique to obtain information about software systems quality. Performance test is a type of software test that aims at evaluating software performance at a given load scenario, but it requires specialized knowledge about tools, activities and metrics of the domain. Since ontology is a promising knowledge representation technique, this paper presents a literature review to identify trends and compare researches of ontologies in the fields of software testing and software performance. Also, to investigate this issue from a practical perspective, it was developed an ontology for representing the core knowledge of performance testing. This paper presents the ontology and compare it with related ones. Then, semantic technologies are explored to demonstrate the practical feasibility of developing ontology-based applications for assisting testers with performance test planning and management.}, 
keywords={ontologies (artificial intelligence);program testing;software management;software performance evaluation;software quality;knowledge representation technique;ontology;performance test management;performance test planning;performance testing guidance;semantic technologies;software performance evaluation;software systems quality;software testing;Measurement;OWL;Ontologies;Software performance;Software testing}, 
doi={10.1109/WI-IAT.2014.62}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{7066184, 
author={J. Li and Q. Li and T. Bi and H. Liu and K. Xu and F. Sun}, 
booktitle={2014 IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC)}, 
title={PMUs performance testing and evaluation in China}, 
year={2014}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Phasor measurement units (PMU) are taking an increasingly important role in power system dynamic security monitoring and control. However, traditional Discrete Fourier Transforms (DFT) used by PMUs cannot obtain accurate phasor measurements during frequency excursion and transient events, being limited by its static phasor model. Therefore, the performance of PMUs under both static and dynamic conditions is fundamental. In this paper, the averaging effect of DFT is explored, which results in the measurement errors of PMUs under dynamic conditions. Then, a PMU testing system is introduced. With that, a centralized test aiming to improve the performance of M-class PMUs in China is accomplished by evaluating the PMUs from seven manufactures in China under static and dynamic conditions. The testing results show that the PMUs under test can satisfy most requirements in the standard by improving their algorithms. The testing data is analyzed to demonstrate the correctness of the theoretical derivation of the averaging effect of DFT.}, 
keywords={discrete Fourier transforms;phasor measurement;power system control;power system security;China;DFT;M-class PMU measurement error;PMU performance evaluation;discrete Fourier transform;frequency excursion;phasor measurement unit performance testing;power system dynamic control;power system dynamic security monitoring;static phasor model;Discrete Fourier transforms;Frequency measurement;Phasor measurement units;Power system dynamics;Standards;Testing;Time measurement;Discrete Fourier transforms (DFT);dynamic phasor algorithm;phasor measurement units (PMU);power system measurements;power system transients}, 
doi={10.1109/APPEEC.2014.7066184}, 
ISSN={2157-4839}, 
month={Dec},}
@INPROCEEDINGS{7015753, 
author={P. Bot and C. Vatamanu and D. Gavrilut and R. M. Benchea}, 
booktitle={2014 Second Workshop on Anti-malware Testing Research (WATeR)}, 
title={Performance testing framework: Evaluating the impact on the system speed}, 
year={2014}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={The world we live in now is defined by the word “speed” and any device, technology, or system that doesn't keep up is rejected or replaced immediately. Because of this, one of the biggest concerns today is “optimization”. Its purpose is to reduce the impact on the user's device. The Anti-Virus industry is also confronting with this challenge. Although the first concern is to keep the user safe, providing a flawless protection, it is crucial to reduce the impact brought on the user's system, preventing him to disable or uninstall the AV solution and thus remaining unprotected. The increased number of malware types/families as well as their complexity generated the need for complicated detection methods, which means a constant evaluation is needed. Because of these reasons, our antimalware laboratory has developed a generic framework for measuring the impact that the AV solutions have on the system they are installed on. This system was designed to be easily configurable, managing the big number of changes that occur every day and fast so that every update released to the users can be tested. Also, this framework is used to test and develop new technologies that improve the performance of our AV product.}, 
keywords={DP industry;data protection;invasive software;program testing;software performance evaluation;AV solution;antivirus industry;flawless protection;malware type;performance testing framework;system speed impact;Computers;Databases;Gold;Laboratories;Operating systems;Servers;generic framework;impact;performance;user interaction}, 
doi={10.1109/WATeR.2014.7015753}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{8203630, 
author={H. Khandelwal and P. Mankodi and R. Prajapati}, 
booktitle={2017 International conference of Electronics, Communication and Aerospace Technology (ICECA)}, 
title={Enhancement of automation testing system using Yocto project}, 
year={2017}, 
volume={1}, 
number={}, 
pages={697-700}, 
abstract={Nowadays, in industries, Testing has become one of the important tasks. Testing is necessary for an effective performance of product and software applications. When companies having a mass production of hardware boards, it is necessary to do testing of each and every module of hardware like SPI, UART, GPIO, PWM, ADC, USB, Ethernet. If we do testing manually then it will significantly take more time, which we can be reduced by automation testing. But the solution is not an automation testing because automation testing also requires the same amount of system, for example for 300 boards 300 system is required. The only difference in manual and automation testing is that in automation testing it will require less human effort. Now we are focusing more on developing a solution in which many tests can be done on one single system i.e. for 300 boards only one system is required for testing hence this problem can be solved by Yocto Project. Yocto project have build the tool named Bitbake which is written in Python language, which works on multithreading and scheduling so that simultaneously you can test more boards on a single system. In this paper we did automation testing of GPIO pins using Yocto project.}, 
keywords={automatic test software;Bitbake tool;GPIO pins;Python language;Yocto Project;automation testing system;multithreading;scheduling;Automation;Hardware;Licenses;Pins;Software;Testing;Tools;Automation;Bitbake;Open embedded;Yocto project}, 
doi={10.1109/ICECA.2017.8203630}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{883774, 
author={B. M. Subraya and S. V. Subrahmanya}, 
booktitle={Proceedings First Asia-Pacific Conference on Quality Software}, 
title={Object driven performance testing of Web applications}, 
year={2000}, 
volume={}, 
number={}, 
pages={17-26}, 
abstract={Performance of many Web sites depends on the load on the site at peak time under varying conditions. Performance testing is normally conducted in reasonably simulated environment with the help of performance testing tools. However, performance of a Web site depends on various parameters and each parameter must be tested under varying stress levels. It is not possible to draw a common denominator for performance parameters to test the Web site due to complexity of Web sites. Different parts of the Web site must be tested with different parameters under varying condition and stress level. In such circumstances, it is necessary to decompose the Web site into many components, which represents the behavior of various business components. These business components are mapped to various objects that truly represent the behavior and structure of the part of the web site. These objects are subjected to performance testing with different parameters and stress levels. This paper addresses the new testing process, which uses the concept of decomposing the behavior of the Web site into testable components, which are mapped onto testable objects. These testable objects are subjected to performance testing under varied performance parameters and stress levels}, 
keywords={computational complexity;information resources;program testing;programming environments;software performance evaluation;Web applications;Web sites;complexity;object driven performance testing;performance parameters;simulated environment;Acoustic testing;Application software;Cities and towns;Consumer electronics;Electronic commerce;Life testing;Software testing;Stress;System testing;Time to market}, 
doi={10.1109/APAQ.2000.883774}, 
ISSN={}, 
month={},}
@ARTICLE{945309, 
author={R. Pendurkar and A. Chatterjee and Y. Zorian}, 
journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
title={Switching activity generation with automated BIST synthesis for performance testing of interconnects}, 
year={2001}, 
volume={20}, 
number={9}, 
pages={1143-1158}, 
abstract={A novel scheme of synthesizing nonlinear feedback shift register structures that can be superimposed on the boundary of the component of a system under test to generate interconnect switching activities that resemble real life interconnect switching profiles is proposed. The goal is to perform at-speed interconnect test while simultaneously capturing the dynamic switching effects such as crosstalk and ground bounce, as accurately as possible during interconnect built-in self-test. A library of nonlinear feedback shift register structures called precharacterized test pattern generators (P-TPGs) is constructed. Components of P-TPGs can be modeled using Markov chain and can be interconnected together in specific ways to recreate the switching activity profile of the interconnections being tested. The unique advantage of this scheme is that there is no simulation overhead since P-TPG components are precharacterized by solving Markov equations analytically. An integrated genetic algorithm-based search and optimization technique for finding the best P-TPG component among various possible implementations and matching its activity profiles with those of the interconnections under test has been designed and implemented synthesis for testability allows generation of the worst case interconnect switching activities. Experimental results confirm the validity of our approach}, 
keywords={Markov processes;automatic testing;built-in self test;crosstalk;design for testability;genetic algorithms;integrated circuit interconnections;integrated circuit testing;shift registers;Markov chain;automated BIST synthesis;crosstalk;design for testability;genetic algorithm;ground bounce;interconnect performance testing;nonlinear feedback shift register;precharacterized test pattern generator;search optimization;switching activity;Automatic testing;Built-in self-test;Crosstalk;Feedback;Libraries;Life testing;Nonlinear dynamical systems;Performance evaluation;Shift registers;System testing}, 
doi={10.1109/43.945309}, 
ISSN={0278-0070}, 
month={Sep},}
@INPROCEEDINGS{6354629, 
author={N. Baltas and T. Field}, 
booktitle={2012 Ninth International Conference on Quantitative Evaluation of Systems}, 
title={Continuous Performance Testing in Virtual Time}, 
year={2012}, 
volume={}, 
number={}, 
pages={13-22}, 
abstract={In this paper we show how program code and performance models can be made to cooperate seamlessly to support continuous software performance testing throughout the development lifecycle. We achieve this by extending our existing VEX tool for executing programs in virtual time so that events that occur during normal execution and those that occur during the simulation of a performance model can be scheduled on a single global virtual time line. The execution time of an incomplete component of an application is thus estimated by a performance model, whilst that of existing code is measured by instrumentation that is added dynamically at program load time. A key challenge is to be able to map some or all of the resources in a performance model to the real resources of the host platform on which the application is running. We outline a continuous performance engineering methodology that exploits our unified framework and illustrate the principles involved byway of a simple Java application development case study.}, 
keywords={Java;program testing;software performance evaluation;software tools;Java application development;VEX tool;continuous performance engineering methodology;continuous software performance testing;development lifecycle;performance model;program code;program execution;program load time;virtual time;Computational modeling;Instruction sets;Java;Predictive models;Real-time systems;Resumes;Schedules;Modelling Queueing networks;Software Performance;Virtual execution}, 
doi={10.1109/QEST.2012.26}, 
ISSN={}, 
month={Sept},}