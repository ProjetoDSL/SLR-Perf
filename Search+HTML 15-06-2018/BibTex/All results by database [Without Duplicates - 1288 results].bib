% Encoding: UTF-8

@InProceedings{Coelho2016,
  author    = {Coelho, Tiago and Lima, Bruno and Faria, Jo\~{a}o Pascoal},
  title     = {MT4A: A No-programming Test Automation Framework for Android Applications},
  booktitle = {Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation},
  year      = {2016},
  series    = {A-TEST 2016},
  pages     = {59--65},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2994300},
  doi       = {10.1145/2994291.2994300},
  isbn      = {978-1-4503-4401-2},
  keywords  = {Android, Mobile applications, Software testing, Test automation, Testing framework},
  location  = {Seattle, WA, USA},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2994291.2994300},
}

@InProceedings{Matinnejad2016,
  author    = {Matinnejad, Reza and Nejati, Shiva and Briand, Lionel C. and Bruckmann, Thomas},
  title     = {Automated Test Suite Generation for Time-continuous Simulink Models},
  booktitle = {Proceedings of the 38th International Conference on Software Engineering},
  year      = {2016},
  series    = {ICSE '16},
  pages     = {595--606},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2884797},
  doi       = {10.1145/2884781.2884797},
  isbn      = {978-1-4503-3900-1},
  keywords  = {Simulink Design Verifier (SLDV), output diversity, search-based software testing, signal features, simulink models, software testing, structural coverage, time-continuous behaviors},
  location  = {Austin, Texas},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/2884781.2884797},
}

@InProceedings{Lochmann2017,
  author    = {Lochmann, Alexander and Bruckner, Fabian and Spinczyk, Olaf},
  title     = {Reproducible Load Tests for Android Systems with Trace-based Benchmarks},
  booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
  year      = {2017},
  series    = {ICPE '17 Companion},
  pages     = {73--76},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3053615},
  doi       = {10.1145/3053600.3053615},
  isbn      = {978-1-4503-4899-7},
  keywords  = {android, application tracing, benchmark, benchmark generator, load testing},
  location  = {L'Aquila, Italy},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/3053600.3053615},
}

@InProceedings{Xu2014,
  author    = {Xu, Guoqing},
  title     = {Language, Compiler, and Runtime System Support Towards Highly Scalable Big Data Application (Invited Talk Abstract)},
  booktitle = {Proceedings of the 2014 Joint International Workshop on Dynamic Analysis (WODA) and Software and System Performance Testing, Debugging, and Analytics (PERTEA)},
  year      = {2014},
  series    = {WODA+PERTEA 2014},
  pages     = {13--13},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2638835},
  doi       = {10.1145/2632168.2638835},
  isbn      = {978-1-4503-2934-7},
  keywords  = {Highly Scalable Big Data Application, System Support},
  location  = {San Jose, CA, USA},
  numpages  = {1},
  url       = {http://doi.acm.org/10.1145/2632168.2638835},
}

@InProceedings{Taneja2010,
  author    = {Taneja, Kunal and Zhang, Yi and Xie, Tao},
  title     = {MODA: Automated Test Generation for Database Applications via Mock Objects},
  booktitle = {Proceedings of the IEEE/ACM International Conference on Automated Software Engineering},
  year      = {2010},
  series    = {ASE '10},
  pages     = {289--292},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1859053},
  doi       = {10.1145/1858996.1859053},
  isbn      = {978-1-4503-0116-9},
  keywords  = {database application, mock object, test generation},
  location  = {Antwerp, Belgium},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/1858996.1859053},
}

@InProceedings{MilaniFard2014,
  author    = {Milani Fard, Amin and Mirzaaghaei, Mehdi and Mesbah, Ali},
  title     = {Leveraging Existing Tests in Automated Test Generation for Web Applications},
  booktitle = {Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
  year      = {2014},
  series    = {ASE '14},
  pages     = {67--78},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2642991},
  doi       = {10.1145/2642937.2642991},
  isbn      = {978-1-4503-3013-8},
  keywords  = {automated test generation, test reuse, web applications},
  location  = {Vasteras, Sweden},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/2642937.2642991},
}

@InProceedings{Michael2017,
  author    = {Michael, Nicolas and Ramannavar, Nitin and Shen, Yixiao and Patil, Sheetal and Sung, Jan-Lung},
  title     = {CloudPerf: A Performance Test Framework for Distributed and Dynamic Multi-Tenant Environments},
  booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
  year      = {2017},
  series    = {ICPE '17},
  pages     = {189--200},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3044530},
  doi       = {10.1145/3030207.3044530},
  isbn      = {978-1-4503-4404-3},
  keywords  = {cloud, load generation, multi-tenancy, performance testing, statistics collection, workload modeling},
  location  = {L'Aquila, Italy},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/3030207.3044530},
}

@InProceedings{Anbalagan2006,
  author    = {Anbalagan, Prasanth},
  title     = {Automated Testing of Pointcuts in AspectJ Programs},
  booktitle = {Companion to the 21st ACM SIGPLAN Symposium on Object-oriented Programming Systems, Languages, and Applications},
  year      = {2006},
  series    = {OOPSLA '06},
  pages     = {758--759},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1176711},
  doi       = {10.1145/1176617.1176711},
  isbn      = {1-59593-491-X},
  keywords  = {AspectJ, aspect oriented software development, software testing},
  location  = {Portland, Oregon, USA},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/1176617.1176711},
}

@InProceedings{Artzi2011,
  author    = {Artzi, Shay and Dolby, Julian and Jensen, Simon Holm and M{\o}ller, Anders and Tip, Frank},
  title     = {A Framework for Automated Testing of Javascript Web Applications},
  booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
  year      = {2011},
  series    = {ICSE '11},
  pages     = {571--580},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1985871},
  doi       = {10.1145/1985793.1985871},
  isbn      = {978-1-4503-0445-0},
  keywords  = {ajax, automated testing, debugging, event driven, javascript, random testing, web applications},
  location  = {Waikiki, Honolulu, HI, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1985793.1985871},
}

@InProceedings{Xie2014,
  author    = {Xie, Qing},
  title     = {Automated Test Generation for API Proxy Code (Invited Talk Abstract)},
  booktitle = {Proceedings of the 2014 Joint International Workshop on Dynamic Analysis (WODA) and Software and System Performance Testing, Debugging, and Analytics (PERTEA)},
  year      = {2014},
  series    = {WODA+PERTEA 2014},
  pages     = {6--6},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2638828},
  doi       = {10.1145/2632168.2638828},
  isbn      = {978-1-4503-2934-7},
  keywords  = {API Proxy Code, Automated Test Generation},
  location  = {San Jose, CA, USA},
  numpages  = {1},
  url       = {http://doi.acm.org/10.1145/2632168.2638828},
}

@InProceedings{Avritzer1994,
  author    = {Avritzer, Alberto and Weyuker, Elaine J.},
  title     = {Generating Test Suites for Software Load Testing},
  booktitle = {Proceedings of the 1994 ACM SIGSOFT International Symposium on Software Testing and Analysis},
  year      = {1994},
  series    = {ISSTA '94},
  pages     = {44--57},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {186507},
  doi       = {10.1145/186258.186507},
  isbn      = {0-89791-683-2},
  location  = {Seattle, Washington, USA},
  numpages  = {14},
  url       = {http://doi.acm.org/10.1145/186258.186507},
}

@InProceedings{Vila2017,
  author    = {Vila, Elior and Novakova, Galia and Todorova, Diana},
  title     = {Automation Testing Framework for Web Applications with Selenium WebDriver: Opportunities and Threats},
  booktitle = {Proceedings of the International Conference on Advances in Image Processing},
  year      = {2017},
  series    = {ICAIP 2017},
  pages     = {144--150},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3133300},
  doi       = {10.1145/3133264.3133300},
  isbn      = {978-1-4503-5295-6},
  keywords  = {Automation testing tool, Selenium WebDriver, automation testing script, software product, testing framework, web application},
  location  = {Bangkok, Thailand},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/3133264.3133300},
}

@InProceedings{Makki2016,
  author    = {Makki, Majid and Van Landuyt, Dimitri and Joosen, Wouter},
  title     = {Automated Workflow Regression Testing for Multi-tenant SaaS: Integrated Support in Self-service Configuration Dashboard},
  booktitle = {Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation},
  year      = {2016},
  series    = {A-TEST 2016},
  pages     = {70--73},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2994302},
  doi       = {10.1145/2994291.2994302},
  isbn      = {978-1-4503-4401-2},
  keywords  = {Application-level Multi-tenancy, Automated Regression Testing, Software-as-a-Service},
  location  = {Seattle, WA, USA},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2994291.2994302},
}

@InProceedings{Liu2017,
  author    = {Liu, Ren-Shuo and Chang, Yun-Sheng and Hung, Chih-Wen},
  title     = {VST: A Virtual Stress Testing Framework for Discovering Bugs in SSD Flash-translation Layers},
  booktitle = {Proceedings of the 36th International Conference on Computer-Aided Design},
  year      = {2017},
  series    = {ICCAD '17},
  pages     = {283--290},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {3199738},
  keywords  = {data storage systems, disk drives, embedded software, flash memories, software debugging, software testing, systems simulation},
  location  = {Irvine, California},
  numpages  = {8},
  url       = {http://dl.acm.org/citation.cfm?id=3199700.3199738},
}

@InProceedings{Avritzer2002,
  author    = {Avritzer, Alberto and Kondek, Joe and Liu, Danielle and Weyuker, Elaine J.},
  title     = {Software Performance Testing Based on Workload Characterization},
  booktitle = {Proceedings of the 3rd International Workshop on Software and Performance},
  year      = {2002},
  series    = {WOSP '02},
  pages     = {17--24},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {584373},
  doi       = {10.1145/584369.584373},
  isbn      = {1-58113-563-7},
  keywords  = {software performance testing, software testing, workload characterization},
  location  = {Rome, Italy},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/584369.584373},
}

@InProceedings{Castro2013,
  author    = {de Castro, Andreza M. F. V. and Macedo, Gisele A. and Collins, Eliane F. and Dias-Neto, Arilo C.},
  title     = {Extension of Selenium RC Tool to Perform Automated Testing with Databases in Web Applications},
  booktitle = {Proceedings of the 8th International Workshop on Automation of Software Test},
  year      = {2013},
  series    = {AST '13},
  pages     = {125--131},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {2662441},
  isbn      = {978-1-4673-6161-3},
  keywords  = {database testing, functional testing, selenium RC, software testing, test automation},
  location  = {San Francisco, California},
  numpages  = {7},
  url       = {http://dl.acm.org/citation.cfm?id=2662413.2662441},
}

@InProceedings{Jensen2013,
  author    = {Jensen, Casper S. and Prasad, Mukul R. and M{\o}ller, Anders},
  title     = {Automated Testing with Targeted Event Sequence Generation},
  booktitle = {Proceedings of the 2013 International Symposium on Software Testing and Analysis},
  year      = {2013},
  series    = {ISSTA 2013},
  pages     = {67--77},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2483777},
  doi       = {10.1145/2483760.2483777},
  isbn      = {978-1-4503-2159-4},
  keywords  = {Android, Symbolic execution, mobile applications, test generation},
  location  = {Lugano, Switzerland},
  numpages  = {11},
  url       = {http://doi.acm.org/10.1145/2483760.2483777},
}

@Article{Fisher2006,
  author     = {Fisher,II, Marc and Rothermel, Gregg and Brown, Darren and Cao, Mingming and Cook, Curtis and Burnett, Margaret},
  title      = {Integrating Automated Test Generation into the WYSIWYT Spreadsheet Testing Methodology},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  year       = {2006},
  volume     = {15},
  number     = {2},
  pages      = {150--194},
  month      = apr,
  issn       = {1049-331X},
  acmid      = {1131423},
  address    = {New York, NY, USA},
  doi        = {10.1145/1131421.1131423},
  issue_date = {April 2006},
  keywords   = {End-user software engineering, end-user programming, test case generation, testing},
  numpages   = {45},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/1131421.1131423},
}

@InProceedings{Sevcikova2006,
  author    = {\v{S}ev\v{c}\'{\i}kov\'{a}, Hana and Borning, Alan and Socha, David and Bleek, Wolf-Gideon},
  title     = {Automated Testing of Stochastic Systems: A Statistically Grounded Approach},
  booktitle = {Proceedings of the 2006 International Symposium on Software Testing and Analysis},
  year      = {2006},
  series    = {ISSTA '06},
  pages     = {215--224},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1146263},
  doi       = {10.1145/1146238.1146263},
  isbn      = {1-59593-263-1},
  keywords  = {hypothesis testing, software engineering, software testing, stochastic algorithms, unit tests},
  location  = {Portland, Maine, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1146238.1146263},
}

@Article{Robbert1991,
  author     = {Robbert, Maryann and Maryanski, Fred J.},
  title      = {Automated Test Plan Generator for Database Applications Systems},
  journal    = {SIGSMALL/PC Notes},
  year       = {1991},
  volume     = {17},
  number     = {3-4},
  pages      = {29--35},
  month      = sep,
  issn       = {0893-2875},
  acmid      = {140763},
  address    = {New York, NY, USA},
  doi        = {10.1145/140738.140763},
  issue_date = {Fall/Winter 1991},
  numpages   = {7},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/140738.140763},
}

@InProceedings{Puhakka2006,
  author    = {Puhakka, Tapani and Palola, Marko},
  title     = {Towards Automating Testing of Communicational B3G Applications},
  booktitle = {Proceedings of the 3rd International Conference on Mobile Technology, Applications \&\#38; Systems},
  year      = {2006},
  series    = {Mobility '06},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1292362},
  articleno = {27},
  doi       = {10.1145/1292331.1292362},
  isbn      = {1-59593-519-3},
  keywords  = {B3G, automated testing, mobile application, mobile phone, mobile services, record and play testing, test automation},
  location  = {Bangkok, Thailand},
  url       = {http://doi.acm.org/10.1145/1292331.1292362},
}

@Article{Denaro2004,
  author     = {Denaro, Giovanni and Polini, Andrea and Emmerich, Wolfgang},
  title      = {Early Performance Testing of Distributed Software Applications},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {2004},
  volume     = {29},
  number     = {1},
  pages      = {94--103},
  month      = jan,
  issn       = {0163-5948},
  acmid      = {974059},
  address    = {New York, NY, USA},
  doi        = {10.1145/974043.974059},
  issue_date = {January 2004},
  keywords   = {distributed software architecture, middleware, performance analysis models, software performance, software testing},
  numpages   = {10},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/974043.974059},
}

@InProceedings{Denaro2004a,
  author    = {Denaro, Giovanni and Polini, Andrea and Emmerich, Wolfgang},
  title     = {Early Performance Testing of Distributed Software Applications},
  booktitle = {Proceedings of the 4th International Workshop on Software and Performance},
  year      = {2004},
  series    = {WOSP '04},
  pages     = {94--103},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {974059},
  doi       = {10.1145/974044.974059},
  isbn      = {1-58113-673-0},
  keywords  = {distributed software architecture, middleware, performance analysis models, software performance, software testing},
  location  = {Redwood Shores, California},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/974044.974059},
}

@InProceedings{Enriquez2016,
  author    = {Enr\'{\i}quez, J. G. and Blanco, Raquel and Dom\'{\i}nguez-Mayo, F. J. and Tuya, Javier and Escalona, M. J.},
  title     = {Towards an MDE-based Approach to Test Entity Reconciliation Applications},
  booktitle = {Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation},
  year      = {2016},
  series    = {A-TEST 2016},
  pages     = {74--77},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2994303},
  doi       = {10.1145/2994291.2994303},
  isbn      = {978-1-4503-4401-2},
  keywords  = {Big Data, Entity Reconciliation, MDE, Software Testing},
  location  = {Seattle, WA, USA},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2994291.2994303},
}

@InProceedings{Meng2015,
  author    = {Meng, Zhanshuai and Jiang, Yanyan and Xu, Chang},
  title     = {Facilitating Reusable and Scalable Automated Testing and Analysis for Android Apps},
  booktitle = {Proceedings of the 7th Asia-Pacific Symposium on Internetware},
  year      = {2015},
  series    = {Internetware '15},
  pages     = {166--175},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2875937},
  doi       = {10.1145/2875913.2875937},
  isbn      = {978-1-4503-3641-3},
  keywords  = {Android, framework, testing},
  location  = {Wuhan, China},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2875913.2875937},
}

@InProceedings{Robbert1991a,
  author    = {Robbert, Mary Ann and Maryanski, Fred J.},
  title     = {Automated Test Plan Generator for Database Application Systems},
  booktitle = {Proceedings of the 1991 ACM SIGSMALL/PC Symposium on Small Systems},
  year      = {1991},
  series    = {SIGSMALL '91},
  pages     = {100--106},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {111061},
  doi       = {10.1145/111048.111061},
  isbn      = {0-89791-396-5},
  location  = {Toronto, Ontario, Canada},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/111048.111061},
}

@InProceedings{An2013,
  author    = {An, Kyoungho and Kuroda, Takayuki and Gokhale, Aniroddha and Tambe, Sumant and Sorbini, Andrea},
  title     = {Model-driven Generative Framework for Automated OMG DDS Performance Testing in the Cloud},
  booktitle = {Proceedings of the 2013 Companion Publication for Conference on Systems, Programming, \&\#38; Applications: Software for Humanity},
  year      = {2013},
  series    = {SPLASH '13},
  pages     = {93--94},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2508096},
  doi       = {10.1145/2508075.2508096},
  isbn      = {978-1-4503-1995-9},
  keywords  = {generative programming, model-driven engineering, performance testing, publish/subscribe},
  location  = {Indianapolis, Indiana, USA},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/2508075.2508096},
}

@InProceedings{Ramler2014,
  author    = {Ramler, Rudolf and Putsch\"{o}gl, Werner and Winkler, Dietmar},
  title     = {Automated Testing of Industrial Automation Software: Practical Receipts and Lessons Learned},
  booktitle = {Proceedings of the 1st International Workshop on Modern Software Engineering Methods for Industrial Automation},
  year      = {2014},
  series    = {MoSEMInA 2014},
  pages     = {7--16},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2593788},
  doi       = {10.1145/2593783.2593788},
  isbn      = {978-1-4503-2851-7},
  keywords  = {IEC 61131-3, PLC software, Software testing, test automation},
  location  = {Hyderabad, India},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2593783.2593788},
}

@InProceedings{Naik2014,
  author    = {Naik, Kshirasagar and Ali, Yasir and Mahinthan, Veluppillai and Singh, Ajit and Abogharaf, Abdulhakim},
  title     = {Categorizing Configuration Parameters of Smartphones for Energy Performance Testing},
  booktitle = {Proceedings of the 9th International Workshop on Automation of Software Test},
  year      = {2014},
  series    = {AST 2014},
  pages     = {15--21},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2593504},
  doi       = {10.1145/2593501.2593504},
  isbn      = {978-1-4503-2858-6},
  keywords  = {Smartphone, energy performance, software testing},
  location  = {Hyderabad, India},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2593501.2593504},
}

@InProceedings{Barna2011,
  author    = {Barna, Cornel and Litoiu, Marin and Ghanbari, Hamoun},
  title     = {Autonomic Load-testing Framework},
  booktitle = {Proceedings of the 8th ACM International Conference on Autonomic Computing},
  year      = {2011},
  series    = {ICAC '11},
  pages     = {91--100},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1998598},
  doi       = {10.1145/1998582.1998598},
  isbn      = {978-1-4503-0607-2},
  keywords  = {autonomic system, performance models, performance testing, stress testing},
  location  = {Karlsruhe, Germany},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1998582.1998598},
}

@InProceedings{Nurmuradov2016,
  author    = {Nurmuradov, Dmitry and Bryce, Ren{\'e}e and Do, Hyunsook},
  title     = {Multilevel Coarse-to-fine-grained Prioritization for GUI and Web Applications},
  booktitle = {Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation},
  year      = {2016},
  series    = {A-TEST 2016},
  pages     = {1--7},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2994292},
  doi       = {10.1145/2994291.2994292},
  isbn      = {978-1-4503-4401-2},
  keywords  = {Multiple Criteria Test Suite Prioritization, Regression Testing, Software Testing, Test Suite Prioritization},
  location  = {Seattle, WA, USA},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2994291.2994292},
}

@InProceedings{Ferme2018,
  author    = {Ferme, Vincenzo and Pautasso, Cesare},
  title     = {A Declarative Approach for Performance Tests Execution in Continuous Software Development Environments},
  booktitle = {Proceedings of the 2018 ACM/SPEC International Conference on Performance Engineering},
  year      = {2018},
  series    = {ICPE '18},
  pages     = {261--272},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3184417},
  doi       = {10.1145/3184407.3184417},
  isbn      = {978-1-4503-5095-2},
  keywords  = {continuous software performance testing, declarative performance tests, goal-driven performance tests},
  location  = {Berlin, Germany},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/3184407.3184417},
}

@InProceedings{Mao2016,
  author    = {Mao, Ke and Harman, Mark and Jia, Yue},
  title     = {Sapienz: Multi-objective Automated Testing for Android Applications},
  booktitle = {Proceedings of the 25th International Symposium on Software Testing and Analysis},
  year      = {2016},
  series    = {ISSTA 2016},
  pages     = {94--105},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2931054},
  doi       = {10.1145/2931037.2931054},
  isbn      = {978-1-4503-4390-9},
  keywords  = {Android, Search-based software testing, Test generation},
  location  = {Saarbr\&\#252;cken, Germany},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/2931037.2931054},
}

@InProceedings{Bondi2016,
  author    = {Bondi, Andr{\'e} B.},
  title     = {Challenges with Applying Performance Testing Methods for Systems Deployed on Shared Environments with Indeterminate Competing Workloads: Position Paper},
  booktitle = {Companion Publication for ACM/SPEC on International Conference on Performance Engineering},
  year      = {2016},
  series    = {ICPE '16 Companion},
  pages     = {41--44},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2859895},
  doi       = {10.1145/2859889.2859895},
  isbn      = {978-1-4503-4147-9},
  keywords  = {cloud performance., performance measurement and testing, software performance engineering},
  location  = {Delft, The Netherlands},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2859889.2859895},
}

@InProceedings{Matinnejad2017,
  author    = {Matinnejad, Reza and Nejati, Shiva and Briand, Lionel C.},
  title     = {Automated Testing of Hybrid Simulink/Stateflow Controllers: Industrial Case Studies},
  booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
  year      = {2017},
  series    = {ESEC/FSE 2017},
  pages     = {938--943},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3117770},
  doi       = {10.1145/3106237.3117770},
  isbn      = {978-1-4503-5105-8},
  keywords  = {Automotive software systems, Matlab/Simulink, testing},
  location  = {Paderborn, Germany},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/3106237.3117770},
}

@InProceedings{Xia2005,
  author    = {Xia, Songtao and Di Vito, Ben and Mu\~{n}oz, C{\'e}sar},
  title     = {Automated Test Generation for Engineering Applications},
  booktitle = {Proceedings of the 20th IEEE/ACM International Conference on Automated Software Engineering},
  year      = {2005},
  series    = {ASE '05},
  pages     = {283--286},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1101951},
  doi       = {10.1145/1101908.1101951},
  isbn      = {1-58113-993-4},
  keywords  = {model-checking, predicate abstraction, test case generation},
  location  = {Long Beach, CA, USA},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/1101908.1101951},
}

@Article{Xie2008,
  author     = {Xie, Qing and Memon, Atif M},
  title      = {Using a Pilot Study to Derive a GUI Model for Automated Testing},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  year       = {2008},
  volume     = {18},
  number     = {2},
  pages      = {7:1--7:35},
  month      = nov,
  issn       = {1049-331X},
  acmid      = {1416567},
  address    = {New York, NY, USA},
  articleno  = {7},
  doi        = {10.1145/1416563.1416567},
  issue_date = {November 2008},
  keywords   = {Graphical user interfaces, model-based testing, test minimization, test suite management},
  numpages   = {35},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/1416563.1416567},
}

@InProceedings{Mnad2016,
  author    = {Mnad, Mouna Tka and Deleuze, Christophe and Parissis, Ioannis and Launay, Jackie and Gning, Jean Baptiste},
  title     = {Automated Test Generation for Synchronous Controllers},
  booktitle = {Proceedings of the 11th International Workshop on Automation of Software Test},
  year      = {2016},
  series    = {AST '16},
  pages     = {1--7},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2896924},
  doi       = {10.1145/2896921.2896924},
  isbn      = {978-1-4503-4151-6},
  keywords  = {automatic test data generation, constraint logic programming, software testing, synchronous approach},
  location  = {Austin, Texas},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2896921.2896924},
}

@InProceedings{Memon2013,
  author    = {Memon, Atif M. and Cohen, Myra B.},
  title     = {Automated Testing of GUI Applications: Models, Tools, and Controlling Flakiness},
  booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
  year      = {2013},
  series    = {ICSE '13},
  pages     = {1479--1480},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {2487046},
  isbn      = {978-1-4673-3076-3},
  location  = {San Francisco, CA, USA},
  numpages  = {2},
  url       = {http://dl.acm.org/citation.cfm?id=2486788.2487046},
}

@InProceedings{Arif2018,
  author    = {Arif, Muhammad Moiz and Shang, Weiyi and Shihab, Emad},
  title     = {Empirical Study on the Discrepancy Between Performance Testing Results from Virtual and Physical Environments},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering},
  year      = {2018},
  series    = {ICSE '18},
  pages     = {822--822},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3182527},
  doi       = {10.1145/3180155.3182527},
  isbn      = {978-1-4503-5638-1},
  keywords  = {software performance analysis, software performance engineering, testing on virtual environments},
  location  = {Gothenburg, Sweden},
  numpages  = {1},
  url       = {http://doi.acm.org/10.1145/3180155.3182527},
}

@InProceedings{Vigo2013,
  author    = {Vigo, Markel and Brown, Justin and Conway, Vivienne},
  title     = {Benchmarking Web Accessibility Evaluation Tools: Measuring the Harm of Sole Reliance on Automated Tests},
  booktitle = {Proceedings of the 10th International Cross-Disciplinary Conference on Web Accessibility},
  year      = {2013},
  series    = {W4A '13},
  pages     = {1:1--1:10},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2461124},
  articleno = {1},
  doi       = {10.1145/2461121.2461124},
  isbn      = {978-1-4503-1844-0},
  keywords  = {WCAG, accessibility, benchmark, evaluation, testing, tools},
  location  = {Rio de Janeiro, Brazil},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2461121.2461124},
}

@InProceedings{Morrison2013,
  author    = {Morrison, Patrick and Holmgreen, Casper and Massey, Aaron and Williams, Laurie},
  title     = {Proposing Regulatory-driven Automated Test Suites for Electronic Health Record Systems},
  booktitle = {Proceedings of the 5th International Workshop on Software Engineering in Health Care},
  year      = {2013},
  series    = {SEHC '13},
  pages     = {46--49},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {2663588},
  isbn      = {978-1-4673-6282-5},
  keywords  = {behavior-driven-development, healthcare it, regulatory compliance, security, software engineering, software testing},
  location  = {San Francisco, California},
  numpages  = {4},
  url       = {http://dl.acm.org/citation.cfm?id=2663575.2663588},
}

@InProceedings{Jensen2013a,
  author    = {Jensen, Casper S. and M{\o}ller, Anders and Su, Zhendong},
  title     = {Server Interface Descriptions for Automated Testing of JavaScript Web Applications},
  booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
  year      = {2013},
  series    = {ESEC/FSE 2013},
  pages     = {510--520},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2491421},
  doi       = {10.1145/2491411.2491421},
  isbn      = {978-1-4503-2237-9},
  keywords  = {Web applications, automated testing, interface descriptions},
  location  = {Saint Petersburg, Russia},
  numpages  = {11},
  url       = {http://doi.acm.org/10.1145/2491411.2491421},
}

@InProceedings{Apte2017,
  author    = {Apte, Varsha and Viswanath, T.V.S. and Gawali, Devidas and Kommireddy, Akhilesh and Gupta, Anshul},
  title     = {AutoPerf: Automated Load Testing and Resource Usage Profiling of Multi-Tier Internet Applications},
  booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
  year      = {2017},
  series    = {ICPE '17},
  pages     = {115--126},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3030222},
  doi       = {10.1145/3030207.3030222},
  isbn      = {978-1-4503-4404-3},
  keywords  = {capacity analysis, cpu service demand measurement, load testing tool},
  location  = {L'Aquila, Italy},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/3030207.3030222},
}

@InProceedings{DelGrosso2005,
  author    = {Del Grosso, Concettina and Antoniol, Giuliano and Di Penta, Massimiliano and Galinier, Philippe and Merlo, Ettore},
  title     = {Improving Network Applications Security: A New Heuristic to Generate Stress Testing Data},
  booktitle = {Proceedings of the 7th Annual Conference on Genetic and Evolutionary Computation},
  year      = {2005},
  series    = {GECCO '05},
  pages     = {1037--1043},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1068185},
  doi       = {10.1145/1068009.1068185},
  isbn      = {1-59593-010-8},
  keywords  = {evolutionary testing, security, stress testing, test data generation},
  location  = {Washington DC, USA},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/1068009.1068185},
}

@InProceedings{Jaygarl2010,
  author    = {Jaygarl, Hojun and Kim, Sunghun and Xie, Tao and Chang, Carl K.},
  title     = {OCAT: Object Capture-based Automated Testing},
  booktitle = {Proceedings of the 19th International Symposium on Software Testing and Analysis},
  year      = {2010},
  series    = {ISSTA '10},
  pages     = {159--170},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1831729},
  doi       = {10.1145/1831708.1831729},
  isbn      = {978-1-60558-823-0},
  keywords  = {automated testing, object capturing, object generation, object mutation},
  location  = {Trento, Italy},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/1831708.1831729},
}

@InProceedings{Martin2006,
  author    = {Martin, Evan},
  title     = {Automated Test Generation for Access Control Policies},
  booktitle = {Companion to the 21st ACM SIGPLAN Symposium on Object-oriented Programming Systems, Languages, and Applications},
  year      = {2006},
  series    = {OOPSLA '06},
  pages     = {752--753},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1176708},
  doi       = {10.1145/1176617.1176708},
  isbn      = {1-59593-491-X},
  keywords  = {XACML, access control policy, test generation},
  location  = {Portland, Oregon, USA},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/1176617.1176708},
}

@InProceedings{Yesudas2015,
  author    = {Yesudas, Michael and S, Girish Menon and Nair, Satheesh K},
  title     = {High-Volume Performance Test Framework Using Big Data},
  booktitle = {Proceedings of the 4th International Workshop on Large-Scale Testing},
  year      = {2015},
  series    = {LT '15},
  pages     = {13--16},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2693185},
  doi       = {10.1145/2693182.2693185},
  isbn      = {978-1-4503-3337-5},
  keywords  = {big data, document oriented storage, load testing, order management, rapid prototyping, test automation tool, test harness},
  location  = {Austin, Texas, USA},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2693182.2693185},
}

@Article{Xie2007,
  author     = {Xie, Qing and Memon, Atif M.},
  title      = {Designing and Comparing Automated Test Oracles for GUI-based Software Applications},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  year       = {2007},
  volume     = {16},
  number     = {1},
  month      = feb,
  issn       = {1049-331X},
  acmid      = {1189752},
  address    = {New York, NY, USA},
  articleno  = {4},
  doi        = {10.1145/1189748.1189752},
  issue_date = {February 2007},
  keywords   = {GUI state, GUI testing, Test oracles, graphical user interfaces, user interfaces, widgets},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/1189748.1189752},
}

@Article{Alesio2015,
  author     = {Alesio, Stefano Di and Briand, Lionel C. and Nejati, Shiva and Gotlieb, Arnaud},
  title      = {Combining Genetic Algorithms and Constraint Programming to Support Stress Testing of Task Deadlines},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  year       = {2015},
  volume     = {25},
  number     = {1},
  pages      = {4:1--4:37},
  month      = dec,
  issn       = {1049-331X},
  acmid      = {2818640},
  address    = {New York, NY, USA},
  articleno  = {4},
  doi        = {10.1145/2818640},
  issue_date = {December 2015},
  keywords   = {Real-time systems, constraint programming, genetic algorithms, search-based software testing, stress testing, task deadline},
  numpages   = {37},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/2818640},
}

@InProceedings{Zhang2012,
  author    = {Zhang, Pingyu and Elbaum, Sebastian and Dwyer, Matthew B.},
  title     = {Compositional Load Test Generation for Software Pipelines},
  booktitle = {Proceedings of the 2012 International Symposium on Software Testing and Analysis},
  year      = {2012},
  series    = {ISSTA 2012},
  pages     = {89--99},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2336764},
  doi       = {10.1145/2338965.2336764},
  isbn      = {978-1-4503-1454-1},
  location  = {Minneapolis, MN, USA},
  numpages  = {11},
  url       = {http://doi.acm.org/10.1145/2338965.2336764},
}

@InProceedings{Kim2009,
  author    = {Kim, Heejin and Choi, Byoungju and Yoon, Seokjin},
  title     = {Performance Testing Based on Test-driven Development for Mobile Applications},
  booktitle = {Proceedings of the 3rd International Conference on Ubiquitous Information Management and Communication},
  year      = {2009},
  series    = {ICUIMC '09},
  pages     = {612--617},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1516349},
  doi       = {10.1145/1516241.1516349},
  isbn      = {978-1-60558-405-8},
  keywords  = {mobile applications, performance testing, test-driven development(TDD)},
  location  = {Suwon, Korea},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/1516241.1516349},
}

@InProceedings{Chen2017,
  author    = {Chen, Tse-Hsun and Syer, Mark D. and Shang, Weiyi and Jiang, Zhen Ming and Hassan, Ahmed E. and Nasser, Mohamed and Flora, Parminder},
  title     = {Analytics-driven Load Testing: An Industrial Experience Report on Load Testing of Large-scale Systems},
  booktitle = {Proceedings of the 39th International Conference on Software Engineering: Software Engineering in Practice Track},
  year      = {2017},
  series    = {ICSE-SEIP '17},
  pages     = {243--252},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {3103144},
  doi       = {10.1109/ICSE-SEIP.2017.26},
  isbn      = {978-1-5386-2717-4},
  keywords  = {load testing, mining software repositories, performance testing, test analysis},
  location  = {Buenos Aires, Argentina},
  numpages  = {10},
  url       = {https://doi.org/10.1109/ICSE-SEIP.2017.26},
}

@InProceedings{Kim2012,
  author    = {Kim, Youngtaek and John, Lizy Kurian and Pant, Sanjay and Manne, Srilatha and Schulte, Michael and Bircher, W. Lloyd and Govindan, Madhu S. Sibi},
  title     = {AUDIT: Stress Testing the Automatic Way},
  booktitle = {Proceedings of the 2012 45th Annual IEEE/ACM International Symposium on Microarchitecture},
  year      = {2012},
  series    = {MICRO-45},
  pages     = {212--223},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {2457500},
  doi       = {10.1109/MICRO.2012.28},
  isbn      = {978-0-7695-4924-8},
  keywords  = {di/dt, inductive noise, stressmark generation, voltage droop, power distribution network, low power, genetic algorithm, hardware measurement},
  location  = {Vancouver, B.C., CANADA},
  numpages  = {12},
  url       = {https://doi.org/10.1109/MICRO.2012.28},
}

@InProceedings{Nejati2012,
  author    = {Nejati, Shiva and Di Alesio, Stefano and Sabetzadeh, Mehrdad and Briand, Lionel},
  title     = {Modeling and Analysis of CPU Usage in Safety-critical Embedded Systems to Support Stress Testing},
  booktitle = {Proceedings of the 15th International Conference on Model Driven Engineering Languages and Systems},
  year      = {2012},
  series    = {MODELS'12},
  pages     = {759--775},
  address   = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  acmid     = {2405027},
  doi       = {10.1007/978-3-642-33666-9_48},
  isbn      = {978-3-642-33665-2},
  location  = {Innsbruck, Austria},
  numpages  = {17},
  url       = {https://doi.org/10.1007/978-3-642-33666-9_48},
}

@InProceedings{Kounev2015,
  author    = {Kounev, Samuel},
  title     = {Load Testing Elasticity and Performance Isolation in Shared Execution Environments},
  booktitle = {Proceedings of the 4th International Workshop on Large-Scale Testing},
  year      = {2015},
  series    = {LT '15},
  pages     = {1--2},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2693186},
  doi       = {10.1145/2693182.2693186},
  isbn      = {978-1-4503-3337-5},
  keywords  = {cloud computing, dependability, elasticity, load testing, performance, shared execution environments},
  location  = {Austin, Texas, USA},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/2693182.2693186},
}

@InProceedings{Arts2014,
  author    = {Arts, Thomas},
  title     = {On Shrinking Randomly Generated Load Tests},
  booktitle = {Proceedings of the Thirteenth ACM SIGPLAN Workshop on Erlang},
  year      = {2014},
  series    = {Erlang '14},
  pages     = {25--31},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2633452},
  doi       = {10.1145/2633448.2633452},
  isbn      = {978-1-4503-3038-1},
  keywords  = {load testing, model-based testing, property-based testing, quickcheck},
  location  = {Gothenburg, Sweden},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2633448.2633452},
}

@InProceedings{Fisher2002,
  author    = {Fisher, Marc and Cao, Mingming and Rothermel, Gregg and Cook, Curtis R. and Burnett, Margaret M.},
  title     = {Automated Test Case Generation for Spreadsheets},
  booktitle = {Proceedings of the 24th International Conference on Software Engineering},
  year      = {2002},
  series    = {ICSE '02},
  pages     = {141--153},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {581359},
  doi       = {10.1145/581339.581359},
  isbn      = {1-58113-472-X},
  location  = {Orlando, Florida},
  numpages  = {13},
  url       = {http://doi.acm.org/10.1145/581339.581359},
}

@InProceedings{Malik2013,
  author    = {Malik, Haroon and Hemmati, Hadi and Hassan, Ahmed E.},
  title     = {Automatic Detection of Performance Deviations in the Load Testing of Large Scale Systems},
  booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
  year      = {2013},
  series    = {ICSE '13},
  pages     = {1012--1021},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {2486927},
  isbn      = {978-1-4673-3076-3},
  location  = {San Francisco, CA, USA},
  numpages  = {10},
  url       = {http://dl.acm.org/citation.cfm?id=2486788.2486927},
}

@InProceedings{Jiang2010,
  author    = {Jiang, Zhen Ming},
  title     = {Automated Analysis of Load Testing Results},
  booktitle = {Proceedings of the 19th International Symposium on Software Testing and Analysis},
  year      = {2010},
  series    = {ISSTA '10},
  pages     = {143--146},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1831726},
  doi       = {10.1145/1831708.1831726},
  isbn      = {978-1-60558-823-0},
  keywords  = {dynamic analysis, load testing, software mining},
  location  = {Trento, Italy},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/1831708.1831726},
}

@InProceedings{Salihu2016,
  author    = {Salihu, Ibrahim Anka and Ibrahim, Rosziati},
  title     = {Systematic Exploration of Android Apps' Events for Automated Testing},
  booktitle = {Proceedings of the 14th International Conference on Advances in Mobile Computing and Multi Media},
  year      = {2016},
  series    = {MoMM '16},
  pages     = {50--54},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3011072},
  doi       = {10.1145/3007120.3011072},
  isbn      = {978-1-4503-4806-5},
  keywords  = {Android app, Code coverage, Dynamic analysis, GUI testing, Hybrid testing, Static analysis, Systematic exploration, Test case generation},
  location  = {Singapore, Singapore},
  numpages  = {5},
  url       = {http://doi.acm.org/10.1145/3007120.3011072},
}

@Article{An2013a,
  author     = {An, Kyoungho and Kuroda, Takayuki and Gokhale, Aniroddha and Tambe, Sumant and Sorbini, Andrea},
  title      = {Model-driven Generative Framework for Automated OMG DDS Performance Testing in the Cloud},
  journal    = {SIGPLAN Not.},
  year       = {2013},
  volume     = {49},
  number     = {3},
  pages      = {179--182},
  month      = oct,
  issn       = {0362-1340},
  acmid      = {2517216},
  address    = {New York, NY, USA},
  doi        = {10.1145/2637365.2517216},
  issue_date = {March 2014},
  keywords   = {generative programming, model-driven engineering, performance testing, publish/subscribe},
  numpages   = {4},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/2637365.2517216},
}

@InProceedings{An2013b,
  author    = {An, Kyoungho and Kuroda, Takayuki and Gokhale, Aniroddha and Tambe, Sumant and Sorbini, Andrea},
  title     = {Model-driven Generative Framework for Automated OMG DDS Performance Testing in the Cloud},
  booktitle = {Proceedings of the 12th International Conference on Generative Programming: Concepts \&\#38; Experiences},
  year      = {2013},
  series    = {GPCE '13},
  pages     = {179--182},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2517216},
  doi       = {10.1145/2517208.2517216},
  isbn      = {978-1-4503-2373-4},
  keywords  = {generative programming, model-driven engineering, performance testing, publish/subscribe},
  location  = {Indianapolis, Indiana, USA},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2517208.2517216},
}

@InProceedings{Robinson2011,
  author    = {Robinson, Brian and Ernst, Michael D. and Perkins, Jeff H. and Augustine, Vinay and Li, Nuo},
  title     = {Scaling Up Automated Test Generation: Automatically Generating Maintainable Regression Unit Tests for Programs},
  booktitle = {Proceedings of the 2011 26th IEEE/ACM International Conference on Automated Software Engineering},
  year      = {2011},
  series    = {ASE '11},
  pages     = {23--32},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {2190143},
  doi       = {10.1109/ASE.2011.6100059},
  isbn      = {978-1-4577-1638-6},
  numpages  = {10},
  url       = {http://dx.doi.org/10.1109/ASE.2011.6100059},
}

@InProceedings{Syer2014,
  author    = {Syer, Mark D. and Jiang, Zhen Ming and Nagappan, Meiyappan and Hassan, Ahmed E. and Nasser, Mohamed and Flora, Parminder},
  title     = {Continuous Validation of Load Test Suites},
  booktitle = {Proceedings of the 5th ACM/SPEC International Conference on Performance Engineering},
  year      = {2014},
  series    = {ICPE '14},
  pages     = {259--270},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2568101},
  doi       = {10.1145/2568088.2568101},
  isbn      = {978-1-4503-2733-6},
  keywords  = {continuous testing, execution logs, performance engineering},
  location  = {Dublin, Ireland},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/2568088.2568101},
}

@Article{Paepcke1990,
  author     = {Paepcke, Andreas},
  title      = {PCLOS: Stress Testing CLOS Experiencing the Metaobject Protocol},
  journal    = {SIGPLAN Not.},
  year       = {1990},
  volume     = {25},
  number     = {10},
  pages      = {194--211},
  month      = sep,
  issn       = {0362-1340},
  acmid      = {97969},
  address    = {New York, NY, USA},
  doi        = {10.1145/97946.97969},
  issue_date = {Oct. 1990},
  numpages   = {18},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/97946.97969},
}

@InProceedings{Paepcke1990a,
  author    = {Paepcke, Andreas},
  title     = {PCLOS: Stress Testing CLOS Experiencing the Metaobject Protocol},
  booktitle = {Proceedings of the European Conference on Object-oriented Programming on Object-oriented Programming Systems, Languages, and Applications},
  year      = {1990},
  series    = {OOPSLA/ECOOP '90},
  pages     = {194--211},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {97969},
  doi       = {10.1145/97945.97969},
  isbn      = {0-89791-411-2},
  location  = {Ottawa, Canada},
  numpages  = {18},
  url       = {http://doi.acm.org/10.1145/97945.97969},
}

@InProceedings{Bhattacharyya2016,
  author    = {Bhattacharyya, Arnamoy and Malgazhdarov, Timur},
  title     = {PredSym: Estimating Software Testing Budget for a Bug-free Release},
  booktitle = {Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation},
  year      = {2016},
  series    = {A-TEST 2016},
  pages     = {16--22},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2994294},
  doi       = {10.1145/2994291.2994294},
  isbn      = {978-1-4503-4401-2},
  keywords  = {Bugs, Software Testing, Symbolic Execution},
  location  = {Seattle, WA, USA},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2994291.2994294},
}

@InProceedings{Zhang2011,
  author    = {Zhang, Pingyu and Elbaum, Sebastian and Dwyer, Matthew B.},
  title     = {Automatic Generation of Load Tests},
  booktitle = {Proceedings of the 2011 26th IEEE/ACM International Conference on Automated Software Engineering},
  year      = {2011},
  series    = {ASE '11},
  pages     = {43--52},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {2190151},
  doi       = {10.1109/ASE.2011.6100093},
  isbn      = {978-1-4577-1638-6},
  numpages  = {10},
  url       = {http://dx.doi.org/10.1109/ASE.2011.6100093},
}

@InProceedings{Blanco2015,
  author    = {Blanco, Raquel and Tuya, Javier},
  title     = {A Test Model for Graph Database Applications: An MDA-based Approach},
  booktitle = {Proceedings of the 6th International Workshop on Automating Test Case Design, Selection and Evaluation},
  year      = {2015},
  series    = {A-TEST 2015},
  pages     = {8--15},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2804324},
  doi       = {10.1145/2804322.2804324},
  isbn      = {978-1-4503-3813-4},
  keywords  = {Graph database testing, MDA, model-based testing, specification-based testing},
  location  = {Bergamo, Italy},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2804322.2804324},
}

@InProceedings{Jiang2015,
  author    = {Jiang, Zhen Ming (Jack)},
  title     = {Load Testing Large-scale Software Systems},
  booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
  year      = {2015},
  series    = {ICSE '15},
  pages     = {955--956},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {2819227},
  location  = {Florence, Italy},
  numpages  = {2},
  url       = {http://dl.acm.org/citation.cfm?id=2819009.2819227},
}

@InProceedings{Wongsirichot2017,
  author    = {Wongsirichot, Thakerng and Elz, Nittida and Suwanmanee, Napaporn and Hmad-a-dam, Hassana and Plansangket, Suthira and Sukpisit, Sukgamon},
  title     = {Hearing Performance Testing Application},
  booktitle = {Proceedings of the 1st International Conference on Medical and Health Informatics 2017},
  year      = {2017},
  series    = {ICMHI '17},
  pages     = {7--11},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3107516},
  doi       = {10.1145/3107514.3107516},
  isbn      = {978-1-4503-5224-6},
  keywords  = {Hearing impairment, Hearing test, Mobile application},
  location  = {Taichung City, Taiwan},
  numpages  = {5},
  url       = {http://doi.acm.org/10.1145/3107514.3107516},
}

@InProceedings{Hewett2009,
  author    = {Hewett, Rattikorn and Kijsanayothin, Phongphun},
  title     = {Automated Test Order Generation for Software Component Integration Testing},
  booktitle = {Proceedings of the 2009 IEEE/ACM International Conference on Automated Software Engineering},
  year      = {2009},
  series    = {ASE '09},
  pages     = {211--220},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {1747521},
  doi       = {10.1109/ASE.2009.84},
  isbn      = {978-0-7695-3891-4},
  keywords  = {software testing, component integration, heuristic algorithms, directed feedback vertex-set problem},
  numpages  = {10},
  url       = {https://doi.org/10.1109/ASE.2009.84},
}

@InProceedings{Berner2005,
  author    = {Berner, Stefan and Weber, Roland and Keller, Rudolf K.},
  title     = {Observations and Lessons Learned from Automated Testing},
  booktitle = {Proceedings of the 27th International Conference on Software Engineering},
  year      = {2005},
  series    = {ICSE '05},
  pages     = {571--579},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1062556},
  doi       = {10.1145/1062455.1062556},
  isbn      = {1-58113-963-2},
  keywords  = {automated testing, software test, test management},
  location  = {St. Louis, MO, USA},
  numpages  = {9},
  url       = {http://doi.acm.org/10.1145/1062455.1062556},
}

@InProceedings{Malik2010,
  author    = {Malik, Haroon},
  title     = {A Methodology to Support Load Test Analysis},
  booktitle = {Proceedings of the 32Nd ACM/IEEE International Conference on Software Engineering - Volume 2},
  year      = {2010},
  series    = {ICSE '10},
  pages     = {421--424},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1810408},
  doi       = {10.1145/1810295.1810408},
  isbn      = {978-1-60558-719-6},
  keywords  = {automation, counters, load test, performance counters, principal component analysis},
  location  = {Cape Town, South Africa},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/1810295.1810408},
}

@InProceedings{Tanno2015,
  author    = {Tanno, Haruto and Zhang, Xiaojing and Hoshino, Takashi and Sen, Koushik},
  title     = {TesMa and CATG: Automated Test Generation Tools for Models of Enterprise Applications},
  booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
  year      = {2015},
  series    = {ICSE '15},
  pages     = {717--720},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {2819147},
  location  = {Florence, Italy},
  numpages  = {4},
  url       = {http://dl.acm.org/citation.cfm?id=2819009.2819147},
}

@InProceedings{Tillmann2013,
  author    = {Tillmann, Nikolai and De Halleux, Jonathan and Xie, Tao and Bishop, Judith},
  title     = {Pex4Fun: A Web-based Environment for Educational Gaming via Automated Test Generation},
  booktitle = {Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering},
  year      = {2013},
  series    = {ASE'13},
  pages     = {730--733},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {3107761},
  doi       = {10.1109/ASE.2013.6693144},
  isbn      = {978-1-4799-0215-6},
  location  = {Silicon Valley, CA, USA},
  numpages  = {4},
  url       = {https://doi.org/10.1109/ASE.2013.6693144},
}

@InProceedings{Garousi2006,
  author    = {Garousi, Vahid and Briand, Lionel C. and Labiche, Yvan},
  title     = {Traffic-aware Stress Testing of Distributed Systems Based on UML Models},
  booktitle = {Proceedings of the 28th International Conference on Software Engineering},
  year      = {2006},
  series    = {ICSE '06},
  pages     = {391--400},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1134340},
  doi       = {10.1145/1134285.1134340},
  isbn      = {1-59593-375-1},
  keywords  = {UML, distributed systems, model-based testing, network traffic, stress testing},
  location  = {Shanghai, China},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1134285.1134340},
}

@InProceedings{Tillmann2014,
  author    = {Tillmann, Nikolai and de Halleux, Jonathan and Xie, Tao},
  title     = {Transferring an Automated Test Generation Tool to Practice: From Pex to Fakes and Code Digger},
  booktitle = {Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
  year      = {2014},
  series    = {ASE '14},
  pages     = {385--396},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2642941},
  doi       = {10.1145/2642937.2642941},
  isbn      = {978-1-4503-3013-8},
  keywords  = {symbolic execution, technology transfer, testing},
  location  = {Vasteras, Sweden},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/2642937.2642941},
}

@InProceedings{Moran2015,
  author    = {Mor\'{a}n, Jes\'{u}s and Riva, Claudio de la and Tuya, Javier},
  title     = {Testing Data Transformations in MapReduce Programs},
  booktitle = {Proceedings of the 6th International Workshop on Automating Test Case Design, Selection and Evaluation},
  year      = {2015},
  series    = {A-TEST 2015},
  pages     = {20--25},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2804326},
  doi       = {10.1145/2804322.2804326},
  isbn      = {978-1-4503-3813-4},
  keywords  = {Data Flow Testing, MapReduce programs, Software Testing},
  location  = {Bergamo, Italy},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/2804322.2804326},
}

@InProceedings{Amalfitano2012,
  author    = {Amalfitano, Domenico and Fasolino, Anna Rita and Tramontana, Porfirio and De Carmine, Salvatore and Memon, Atif M.},
  title     = {Using GUI Ripping for Automated Testing of Android Applications},
  booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering},
  year      = {2012},
  series    = {ASE 2012},
  pages     = {258--261},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2351717},
  doi       = {10.1145/2351676.2351717},
  isbn      = {978-1-4503-1204-2},
  keywords  = {Android, Testing Automation, Testing Tools},
  location  = {Essen, Germany},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2351676.2351717},
}

@InProceedings{Rao2018,
  author    = {Rao, Nageswara S. V. and Liu, Qiang and Sen, Satyabrata and Kettimuthu, Raj and Boley, Josh and Settlemyer, Bradley W. and Chen, Hsing B. and Katramatos, Dimitrios and Yu, Dantong},
  title     = {Software-Defined Network Solutions for Science Scenarios: Performance Testing Framework and Measurements},
  booktitle = {Proceedings of the 19th International Conference on Distributed Computing and Networking},
  year      = {2018},
  series    = {ICDCN '18},
  pages     = {53:1--53:10},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3154336},
  articleno = {53},
  doi       = {10.1145/3154273.3154336},
  isbn      = {978-1-4503-6372-3},
  keywords  = {Software-Defined networks, controllers, dedicated connections, science scenarios, switching response method},
  location  = {Varanasi, India},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/3154273.3154336},
}

@InProceedings{Le2015,
  author    = {Le, Vu and Sun, Chengnian and Su, Zhendong},
  title     = {Randomized Stress-testing of Link-time Optimizers},
  booktitle = {Proceedings of the 2015 International Symposium on Software Testing and Analysis},
  year      = {2015},
  series    = {ISSTA 2015},
  pages     = {327--337},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2771785},
  doi       = {10.1145/2771783.2771785},
  isbn      = {978-1-4503-3620-8},
  keywords  = {Compiler testing, automated testing, link-time optimizer},
  location  = {Baltimore, MD, USA},
  numpages  = {11},
  url       = {http://doi.acm.org/10.1145/2771783.2771785},
}

@InProceedings{Cavalli2004,
  author    = {Cavalli, Ana and Maag, Stephane},
  title     = {Automated Test Scenarios Generation for an e-Barter System},
  booktitle = {Proceedings of the 2004 ACM Symposium on Applied Computing},
  year      = {2004},
  series    = {SAC '04},
  pages     = {795--799},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {968064},
  doi       = {10.1145/967900.968064},
  isbn      = {1-58113-812-1},
  keywords  = {e-commerce, formal methods, specification techniques, testing tools},
  location  = {Nicosia, Cyprus},
  numpages  = {5},
  url       = {http://doi.acm.org/10.1145/967900.968064},
}

@InProceedings{Im2008,
  author    = {Im, Kyungsoo and Im, Tacksoo and McGregor, John D.},
  title     = {Automating Test Case Definition Using a Domain Specific Language},
  booktitle = {Proceedings of the 46th Annual Southeast Regional Conference on XX},
  year      = {2008},
  series    = {ACM-SE 46},
  pages     = {180--185},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1593152},
  doi       = {10.1145/1593105.1593152},
  isbn      = {978-1-60558-105-7},
  keywords  = {domain specific language, ontology, software product line, software testing},
  location  = {Auburn, Alabama},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/1593105.1593152},
}

@InProceedings{Guo2014,
  author    = {Guo, Chenkai and Xu, Jing and Yang, Hongji and Zeng, Ying and Xing, Shuang},
  title     = {An Automated Testing Approach for Inter-application Security in Android},
  booktitle = {Proceedings of the 9th International Workshop on Automation of Software Test},
  year      = {2014},
  series    = {AST 2014},
  pages     = {8--14},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2593503},
  doi       = {10.1145/2593501.2593503},
  isbn      = {978-1-4503-2858-6},
  keywords  = {Android, automated testing, mobile phone security},
  location  = {Hyderabad, India},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2593501.2593503},
}

@InProceedings{Daniel2007,
  author    = {Daniel, Brett and Dig, Danny and Garcia, Kely and Marinov, Darko},
  title     = {Automated Testing of Refactoring Engines},
  booktitle = {Proceedings of the the 6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering},
  year      = {2007},
  series    = {ESEC-FSE '07},
  pages     = {185--194},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1287651},
  doi       = {10.1145/1287624.1287651},
  isbn      = {978-1-59593-811-4},
  keywords  = {automated testing, bounded-exhaustive testing, imperative generators, refactoring engines, test data generation},
  location  = {Dubrovnik, Croatia},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1287624.1287651},
}

@InProceedings{Thummalapenta2012,
  author    = {Thummalapenta, Suresh and Sinha, Saurabh and Singhania, Nimit and Chandra, Satish},
  title     = {Automating Test Automation},
  booktitle = {Proceedings of the 34th International Conference on Software Engineering},
  year      = {2012},
  series    = {ICSE '12},
  pages     = {881--891},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {2337327},
  isbn      = {978-1-4673-1067-3},
  location  = {Zurich, Switzerland},
  numpages  = {11},
  url       = {http://dl.acm.org/citation.cfm?id=2337223.2337327},
}

@InProceedings{Harman2009,
  author    = {Harman, Mark and Islam, Fayezin and Xie, Tao and Wappler, Stefan},
  title     = {Automated Test Data Generation for Aspect-oriented Programs},
  booktitle = {Proceedings of the 8th ACM International Conference on Aspect-oriented Software Development},
  year      = {2009},
  series    = {AOSD '09},
  pages     = {185--196},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1509264},
  doi       = {10.1145/1509239.1509264},
  isbn      = {978-1-60558-442-3},
  keywords  = {aspect-oriented software development, evolutionary testing, search-based software engineering, test data generation},
  location  = {Charlottesville, Virginia, USA},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/1509239.1509264},
}

@Article{Memon2000,
  author     = {Memon, Atif M. and Pollack, Martha E. and Soffa, Mary Lou},
  title      = {Automated Test Oracles for GUIs},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {2000},
  volume     = {25},
  number     = {6},
  pages      = {30--39},
  month      = nov,
  issn       = {0163-5948},
  acmid      = {355050},
  address    = {New York, NY, USA},
  doi        = {10.1145/357474.355050},
  issue_date = {Nov. 2000},
  keywords   = {GUI test oracles, GUI testing, automated oracles},
  numpages   = {10},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/357474.355050},
}

@InProceedings{Memon2000a,
  author    = {Memon, Atif M. and Pollack, Martha E. and Soffa, Mary Lou},
  title     = {Automated Test Oracles for GUIs},
  booktitle = {Proceedings of the 8th ACM SIGSOFT International Symposium on Foundations of Software Engineering: Twenty-first Century Applications},
  year      = {2000},
  series    = {SIGSOFT '00/FSE-8},
  pages     = {30--39},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {355050},
  doi       = {10.1145/355045.355050},
  isbn      = {1-58113-205-0},
  keywords  = {GUI test oracles, GUI testing, automated oracles},
  location  = {San Diego, California, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/355045.355050},
}

@Article{Avritzer1993,
  author     = {Avritzer, Alberto and Larson, Brian},
  title      = {Load Testing Software Using Deterministic State Testing},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {1993},
  volume     = {18},
  number     = {3},
  pages      = {82--88},
  month      = jul,
  issn       = {0163-5948},
  acmid      = {154244},
  address    = {New York, NY, USA},
  doi        = {10.1145/174146.154244},
  issue_date = {July 1993},
  numpages   = {7},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/174146.154244},
}

@InProceedings{Avritzer1993a,
  author    = {Avritzer, Alberto and Larson, Brian},
  title     = {Load Testing Software Using Deterministic State Testing},
  booktitle = {Proceedings of the 1993 ACM SIGSOFT International Symposium on Software Testing and Analysis},
  year      = {1993},
  series    = {ISSTA '93},
  pages     = {82--88},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {154244},
  doi       = {10.1145/154183.154244},
  isbn      = {0-89791-608-5},
  location  = {Cambridge, Massachusetts, USA},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/154183.154244},
}

@InProceedings{Sen2015,
  author    = {Sen, Koushik},
  title     = {Automated Test Generation Using Concolic Testing},
  booktitle = {Proceedings of the 8th India Software Engineering Conference},
  year      = {2015},
  series    = {ISEC '15},
  pages     = {9--9},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2723768},
  doi       = {10.1145/2723742.2723768},
  isbn      = {978-1-4503-3432-7},
  keywords  = {Automated Test Generation},
  location  = {Bangalore, India},
  numpages  = {1},
  url       = {http://doi.acm.org/10.1145/2723742.2723768},
}

@InProceedings{Barna2011a,
  author    = {Barna, Cornel and Litoiu, Marin and Ghanbari, Hamoun},
  title     = {Model-based Performance Testing (NIER Track)},
  booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
  year      = {2011},
  series    = {ICSE '11},
  pages     = {872--875},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1985930},
  doi       = {10.1145/1985793.1985930},
  isbn      = {978-1-4503-0445-0},
  keywords  = {adaptive system, performance models, performance testing, stress testing},
  location  = {Waikiki, Honolulu, HI, USA},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/1985793.1985930},
}

@InProceedings{Zhang2011a,
  author    = {Zhang, Sai},
  title     = {Palus: A Hybrid Automated Test Generation Tool for Java},
  booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
  year      = {2011},
  series    = {ICSE '11},
  pages     = {1182--1184},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1986036},
  doi       = {10.1145/1985793.1986036},
  isbn      = {978-1-4503-0445-0},
  keywords  = {automated test generation, static and dynamic analyses},
  location  = {Waikiki, Honolulu, HI, USA},
  numpages  = {3},
  url       = {http://doi.acm.org/10.1145/1985793.1986036},
}

@Article{Bouquet2005,
  author     = {Bouquet, F. and Jaffuel, E. and Legeard, B. and Peureux, F. and Utting, M.},
  title      = {Requirements Traceability in Automated Test Generation: Application to Smart Card Software Validation},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {2005},
  volume     = {30},
  number     = {4},
  pages      = {1--7},
  month      = may,
  issn       = {0163-5948},
  acmid      = {1083282},
  address    = {New York, NY, USA},
  doi        = {10.1145/1082983.1083282},
  issue_date = {July 2005},
  keywords   = {formal model, model-based testing, requirements traceability},
  numpages   = {7},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/1082983.1083282},
}

@InProceedings{Bierbaum2003,
  author    = {Bierbaum, Allen and Hartling, Patrick and Cruz-Neira, Carolina},
  title     = {Automated Testing of Virtual Reality Application Interfaces},
  booktitle = {Proceedings of the Workshop on Virtual Environments 2003},
  year      = {2003},
  series    = {EGVE '03},
  pages     = {107--114},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {769966},
  doi       = {10.1145/769953.769966},
  isbn      = {1-58113-686-2},
  keywords  = {VR Juggler, extreme programming, unit testing},
  location  = {Zurich, Switzerland},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/769953.769966},
}

@InProceedings{Voegele2014,
  author    = {V\"{o}gele, Christian and Brunnert, Andreas and Danciu, Alexandru and Tertilt, Daniel and Krcmar, Helmut},
  title     = {Using Performance Models to Support Load Testing in a Large SOA Environment},
  booktitle = {Proceedings of the Third International Workshop on Large Scale Testing},
  year      = {2014},
  series    = {LT '14},
  pages     = {5--6},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2577038},
  doi       = {10.1145/2577036.2577038},
  isbn      = {978-1-4503-2762-6},
  keywords  = {load testing, performance models, service workload, service-oriented architecture, usage scenario},
  location  = {Dublin, Ireland},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/2577036.2577038},
}

@InProceedings{Babic2011,
  author    = {Babi\'{c}, Domagoj and Martignoni, Lorenzo and McCamant, Stephen and Song, Dawn},
  title     = {Statically-directed Dynamic Automated Test Generation},
  booktitle = {Proceedings of the 2011 International Symposium on Software Testing and Analysis},
  year      = {2011},
  series    = {ISSTA '11},
  pages     = {12--22},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2001423},
  doi       = {10.1145/2001420.2001423},
  isbn      = {978-1-4503-0562-4},
  keywords  = {automated testing, dynamic analysis, prioritization, static analysis},
  location  = {Toronto, Ontario, Canada},
  numpages  = {11},
  url       = {http://doi.acm.org/10.1145/2001420.2001423},
}

@InProceedings{Hothersall-Thomas2015,
  author    = {Hothersall-Thomas, Charlie and Maffeis, Sergio and Novakovic, Chris},
  title     = {BrowserAudit: Automated Testing of Browser Security Features},
  booktitle = {Proceedings of the 2015 International Symposium on Software Testing and Analysis},
  year      = {2015},
  series    = {ISSTA 2015},
  pages     = {37--47},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2771789},
  doi       = {10.1145/2771783.2771789},
  isbn      = {978-1-4503-3620-8},
  keywords  = {Content Security Policy, Cross-Origin Resource Sharing, Same-Origin Policy, Web security, click-jacking, cookies, web browser testing},
  location  = {Baltimore, MD, USA},
  numpages  = {11},
  url       = {http://doi.acm.org/10.1145/2771783.2771789},
}

@InProceedings{Ayala-Rivera2018,
  author    = {Ayala-Rivera, Vanessa and Kaczmarski, Maciej and Murphy, John and Darisa, Amarendra and Portillo-Dominguez, A. Omar},
  title     = {One Size Does Not Fit All: In-Test Workload Adaptation for Performance Testing of Enterprise Applications},
  booktitle = {Proceedings of the 2018 ACM/SPEC International Conference on Performance Engineering},
  year      = {2018},
  series    = {ICPE '18},
  pages     = {211--222},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3184418},
  doi       = {10.1145/3184407.3184418},
  isbn      = {978-1-4503-5095-2},
  keywords  = {analysis, automation, performance, testing, workload},
  location  = {Berlin, Germany},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/3184407.3184418},
}

@InProceedings{Portillo-Dominguez2014,
  author    = {Portillo-Dominguez, A. Omar and Wang, Miao and Murphy, John and Magoni, Damien and Mitchell, Nick and Sweeney, Peter F. and Altman, Erik},
  title     = {Towards an Automated Approach to Use Expert Systems in the Performance Testing of Distributed Systems},
  booktitle = {Proceedings of the 2014 Workshop on Joining AcadeMiA and Industry Contributions to Test Automation and Model-Based Testing},
  year      = {2014},
  series    = {JAMAICA 2014},
  pages     = {22--27},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2631895},
  doi       = {10.1145/2631890.2631895},
  isbn      = {978-1-4503-2933-0},
  keywords  = {Automation, Distributed Systems, Expert Systems, Performance Analysis, Performance Testing},
  location  = {San Jose, CA, USA},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/2631890.2631895},
}

@InProceedings{Hoffman1976,
  author    = {Hoffman, Robert H.},
  title     = {An Interactive Automated Test Data Generator},
  booktitle = {Proceedings of the 1976 Annual Conference},
  year      = {1976},
  series    = {ACM '76},
  pages     = {483--487},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {805646},
  doi       = {10.1145/800191.805646},
  location  = {Houston, Texas, USA},
  numpages  = {5},
  url       = {http://doi.acm.org/10.1145/800191.805646},
}

@InProceedings{Nivas2011,
  author    = {Nivas, Tuli},
  title     = {Test Harness and Script Design Principles for Automated Testing of non-GUI or Web Based Applications},
  booktitle = {Proceedings of the First International Workshop on End-to-End Test Script Engineering},
  year      = {2011},
  series    = {ETSE '11},
  pages     = {30--37},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2002936},
  doi       = {10.1145/2002931.2002936},
  isbn      = {978-1-4503-0808-3},
  keywords  = {non GUI testing, test script design, test script engineering},
  location  = {Toronto, Ontario, Canada},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2002931.2002936},
}

@InProceedings{Moran2017,
  author    = {Moran, Kevin and Linares-V\'{a}squez, Mario and Bernal-C\'{a}rdenas, Carlos and Vendome, Christopher and Poshyvanyk, Denys},
  title     = {CrashScope: A Practical Tool for Automated Testing of Android Applications},
  booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
  year      = {2017},
  series    = {ICSE-C '17},
  pages     = {15--18},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {3098350},
  doi       = {10.1109/ICSE-C.2017.16},
  isbn      = {978-1-5386-1589-8},
  keywords  = {Android, automated testing, crash reports},
  location  = {Buenos Aires, Argentina},
  numpages  = {4},
  url       = {https://doi.org/10.1109/ICSE-C.2017.16},
}

@InProceedings{Nilsson2007,
  author    = {Nilsson, Robert and Offutt, Jeff},
  title     = {Automated Testing of Timeliness: A Case Study},
  booktitle = {Proceedings of the Second International Workshop on Automation of Software Test},
  year      = {2007},
  series    = {AST '07},
  pages     = {11--},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {1270264},
  doi       = {10.1109/AST.2007.5},
  isbn      = {0-7695-2971-2},
  url       = {http://dx.doi.org/10.1109/AST.2007.5},
}

@InProceedings{Abbors2013,
  author    = {Abbors, Fredrik and Ahmad, Tanwir and Truscan, Dragos and Porres, Ivan},
  title     = {Model-based Performance Testing in the Cloud Using the Mbpet Tool},
  booktitle = {Proceedings of the 4th ACM/SPEC International Conference on Performance Engineering},
  year      = {2013},
  series    = {ICPE '13},
  pages     = {423--424},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2479937},
  doi       = {10.1145/2479871.2479937},
  isbn      = {978-1-4503-1636-1},
  keywords  = {load generation, model-based testing, performance testing, probabilistic timed automata},
  location  = {Prague, Czech Republic},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/2479871.2479937},
}

@InProceedings{Martin2007,
  author    = {Martin, Evan and Xie, Tao},
  title     = {Automated Test Generation for Access Control Policies via Change-Impact Analysis},
  booktitle = {Proceedings of the Third International Workshop on Software Engineering for Secure Systems},
  year      = {2007},
  series    = {SESS '07},
  pages     = {5--},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {1269065},
  doi       = {10.1109/SESS.2007.5},
  isbn      = {0-7695-2952-6},
  url       = {https://doi.org/10.1109/SESS.2007.5},
}

@InProceedings{Dyrkorn2008,
  author    = {Dyrkorn, Kristoffer and Wathne, Frank},
  title     = {Automated Testing of Non-functional Requirements},
  booktitle = {Companion to the 23rd ACM SIGPLAN Conference on Object-oriented Programming Systems Languages and Applications},
  year      = {2008},
  series    = {OOPSLA Companion '08},
  pages     = {719--720},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1449828},
  doi       = {10.1145/1449814.1449828},
  isbn      = {978-1-60558-220-7},
  keywords  = {automated testing, metrics, non-functional requirements, open source},
  location  = {Nashville, TN, USA},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/1449814.1449828},
}

@InProceedings{Vokolos1998,
  author    = {Vokolos, Filippos I. and Weyuker, Elaine J.},
  title     = {Performance Testing of Software Systems},
  booktitle = {Proceedings of the 1st International Workshop on Software and Performance},
  year      = {1998},
  series    = {WOSP '98},
  pages     = {80--87},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {287337},
  doi       = {10.1145/287318.287337},
  isbn      = {1-58113-060-0},
  location  = {Santa Fe, New Mexico, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/287318.287337},
}

@InProceedings{Thoss2014,
  author    = {Thoss, Marcus and Beckmann, Kai and Kroeger, Reinhold and Muenchhof, Marco and Mellert, Christian},
  title     = {A Framework-based Approach for Automated Testing of CNC Firmware},
  booktitle = {Proceedings of the 2014 Workshop on Joining AcadeMiA and Industry Contributions to Test Automation and Model-Based Testing},
  year      = {2014},
  series    = {JAMAICA 2014},
  pages     = {7--12},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2631892},
  doi       = {10.1145/2631890.2631892},
  isbn      = {978-1-4503-2933-0},
  keywords  = {Automated testing, CNC, Eclipse TPTP, MATLAB, regression testing},
  location  = {San Jose, CA, USA},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/2631890.2631892},
}

@InProceedings{Paiva2016,
  author    = {Paiva, Sofia Costa and Simao, Adenilso and Varshosaz, Mahsa and Mousavi, Mohammad Reza},
  title     = {Complete IOCO Test Cases: A Case Study},
  booktitle = {Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation},
  year      = {2016},
  series    = {A-TEST 2016},
  pages     = {38--44},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2994297},
  doi       = {10.1145/2994291.2994297},
  isbn      = {978-1-4503-4401-2},
  keywords  = {Complete input output conformance, Conformance testing, Input output conformance (IOCO), Mealy input output transition systems, fault models},
  location  = {Seattle, WA, USA},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2994291.2994297},
}

@InProceedings{Zibitsker2017,
  author    = {Zibitsker, Boris and Lupersolsky, Alex},
  title     = {Modeling Expands Value of Performance Testing for Big Data Applications},
  booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
  year      = {2017},
  series    = {ICPE '17 Companion},
  pages     = {119--123},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3053624},
  doi       = {10.1145/3053600.3053624},
  isbn      = {978-1-4503-4899-7},
  keywords  = {benchmark, big data applications, big data infrastructure, performance assurance, performance engineering, performance models, performance prediction., performance testing},
  location  = {L'Aquila, Italy},
  numpages  = {5},
  url       = {http://doi.acm.org/10.1145/3053600.3053624},
}

@InProceedings{Bondi2016a,
  author    = {Bondi, Andre B.},
  title     = {Automated Analysis of Load Test Results of Systems with Equilibrium or Transient Behavior: Invited Talk},
  booktitle = {Companion Publication for ACM/SPEC on International Conference on Performance Engineering},
  year      = {2016},
  series    = {ICPE '16 Companion},
  pages     = {7--7},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2880447},
  doi       = {10.1145/2859889.2880447},
  isbn      = {978-1-4503-4147-9},
  keywords  = {automated analysis of performance test data, load testing, performance testing, steady loads, transient loads},
  location  = {Delft, The Netherlands},
  numpages  = {1},
  url       = {http://doi.acm.org/10.1145/2859889.2880447},
}

@InProceedings{Schulz2018,
  author    = {Schulz, Henning and Angerstein, Tobias and van Hoorn, Andr{\'e}},
  title     = {Towards Automating Representative Load Testing in Continuous Software Engineering},
  booktitle = {Companion of the 2018 ACM/SPEC International Conference on Performance Engineering},
  year      = {2018},
  series    = {ICPE '18},
  pages     = {123--126},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3186288},
  doi       = {10.1145/3185768.3186288},
  isbn      = {978-1-4503-5629-9},
  keywords  = {continuous delivery, continuous integration, continuous software engineering, devops, load testing, microservices, performance, workload modeling},
  location  = {Berlin, Germany},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/3185768.3186288},
}

@InProceedings{Frajtak2015,
  author    = {Frajt\'{a}k, Karel and Bure\v{s}, Miroslav and Jel\'{\i}nek, Ivan},
  title     = {Transformation of IFML Schemas to Automated Tests},
  booktitle = {Proceedings of the 2015 Conference on Research in Adaptive and Convergent Systems},
  year      = {2015},
  series    = {RACS},
  pages     = {509--511},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2811556},
  doi       = {10.1145/2811411.2811556},
  isbn      = {978-1-4503-3738-0},
  keywords  = {IFML, automated testing, model--based testing},
  location  = {Prague, Czech Republic},
  numpages  = {3},
  url       = {http://doi.acm.org/10.1145/2811411.2811556},
}

@InProceedings{Pasareanu2014,
  author    = {P\u{a}s\u{a}reanu, Corina S.},
  title     = {On the Probabilistic Analysis of Software (Invited Talk Abstract)},
  booktitle = {Proceedings of the 2014 Joint International Workshop on Dynamic Analysis (WODA) and Software and System Performance Testing, Debugging, and Analytics (PERTEA)},
  year      = {2014},
  series    = {WODA+PERTEA 2014},
  pages     = {10--10},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2638832},
  doi       = {10.1145/2632168.2638832},
  isbn      = {978-1-4503-2934-7},
  keywords  = {Probabilistic Analysis},
  location  = {San Jose, CA, USA},
  numpages  = {1},
  url       = {http://doi.acm.org/10.1145/2632168.2638832},
}

@InProceedings{Jovic2010,
  author    = {Jovic, Milan and Adamoli, Andrea and Zaparanuks, Dmitrijs and Hauswirth, Matthias},
  title     = {Automating Performance Testing of Interactive Java Applications},
  booktitle = {Proceedings of the 5th Workshop on Automation of Software Test},
  year      = {2010},
  series    = {AST '10},
  pages     = {8--15},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1808268},
  doi       = {10.1145/1808266.1808268},
  isbn      = {978-1-60558-970-1},
  location  = {Cape Town, South Africa},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1808266.1808268},
}

@InProceedings{Makhdoom2014,
  author    = {Makhdoom, Sarmad and Khan, Muhammad Adeel and Siddiqui, Junaid Haroon},
  title     = {Incremental Symbolic Execution for Automated Test Suite Maintenance},
  booktitle = {Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
  year      = {2014},
  series    = {ASE '14},
  pages     = {271--276},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2642961},
  doi       = {10.1145/2642937.2642961},
  isbn      = {978-1-4503-3013-8},
  keywords  = {incremental analysis, klee, symbolic execution},
  location  = {Vasteras, Sweden},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/2642937.2642961},
}

@InProceedings{Rodrigues2014,
  author    = {Rodrigues, Elder M. and Saad, Rodrigo S. and Oliveira, Flavio M. and Costa, Leandro T. and Bernardino, Maicon and Zorzo, Avelino F.},
  title     = {Evaluating Capture and Replay and Model-based Performance Testing Tools: An Empirical Comparison},
  booktitle = {Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
  year      = {2014},
  series    = {ESEM '14},
  pages     = {9:1--9:8},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2652587},
  articleno = {9},
  doi       = {10.1145/2652524.2652587},
  isbn      = {978-1-4503-2774-9},
  keywords  = {experiment, performance testing, testing tools},
  location  = {Torino, Italy},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2652524.2652587},
}

@InProceedings{Melo2015,
  author    = {Melo, Silvana M. and Souza, Simone R. S. and Silva, Rodolfo A. and Souza, Paulo S. L.},
  title     = {Concurrent Software Testing in Practice: A Catalog of Tools},
  booktitle = {Proceedings of the 6th International Workshop on Automating Test Case Design, Selection and Evaluation},
  year      = {2015},
  series    = {A-TEST 2015},
  pages     = {31--40},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2804328},
  doi       = {10.1145/2804322.2804328},
  isbn      = {978-1-4503-3813-4},
  keywords  = {Concurrent programs, Systematic mapping, Testing tools},
  location  = {Bergamo, Italy},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2804322.2804328},
}

@InProceedings{Garousi2008,
  author    = {Garousi, Vahid},
  title     = {Empirical Analysis of a Genetic Algorithm-based Stress Test Technique},
  booktitle = {Proceedings of the 10th Annual Conference on Genetic and Evolutionary Computation},
  year      = {2008},
  series    = {GECCO '08},
  pages     = {1743--1750},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1389433},
  doi       = {10.1145/1389095.1389433},
  isbn      = {978-1-60558-130-9},
  keywords  = {empirical analysis, genetic algorithms, stress testing},
  location  = {Atlanta, GA, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1389095.1389433},
}

@InProceedings{Fisher2016,
  author    = {Fisher, Gene and Johnson, Corrigan},
  title     = {Making Formal Methods More Relevant to Software Engineering Students via Automated Test Generation},
  booktitle = {Proceedings of the 2016 ACM Conference on Innovation and Technology in Computer Science Education},
  year      = {2016},
  series    = {ITiCSE '16},
  pages     = {224--229},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2899424},
  doi       = {10.1145/2899415.2899424},
  isbn      = {978-1-4503-4231-5},
  keywords  = {automated test generation, formal methods, software engineering education, software testing},
  location  = {Arequipa, Peru},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/2899415.2899424},
}

@Article{Vogel1993,
  author     = {Vogel, Peter A.},
  title      = {An Integrated General Purpose Automated Test Environment},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {1993},
  volume     = {18},
  number     = {3},
  pages      = {61--69},
  month      = jul,
  issn       = {0163-5948},
  acmid      = {154200},
  address    = {New York, NY, USA},
  doi        = {10.1145/174146.154200},
  issue_date = {July 1993},
  numpages   = {9},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/174146.154200},
}

@InProceedings{Vogel1993a,
  author    = {Vogel, Peter A.},
  title     = {An Integrated General Purpose Automated Test Environment},
  booktitle = {Proceedings of the 1993 ACM SIGSOFT International Symposium on Software Testing and Analysis},
  year      = {1993},
  series    = {ISSTA '93},
  pages     = {61--69},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {154200},
  doi       = {10.1145/154183.154200},
  isbn      = {0-89791-608-5},
  location  = {Cambridge, Massachusetts, USA},
  numpages  = {9},
  url       = {http://doi.acm.org/10.1145/154183.154200},
}

@InProceedings{Li2009,
  author    = {Li, Nuo and Xie, Tao and Tillmann, Nikolai and Halleux, Jonathan de and Schulte, Wolfram},
  title     = {Reggae: Automated Test Generation for Programs Using Complex Regular Expressions},
  booktitle = {Proceedings of the 2009 IEEE/ACM International Conference on Automated Software Engineering},
  year      = {2009},
  series    = {ASE '09},
  pages     = {515--519},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {1747547},
  doi       = {10.1109/ASE.2009.67},
  isbn      = {978-0-7695-3891-4},
  keywords  = {test generation, dynamic symbolic execution, string generation},
  numpages  = {5},
  url       = {https://doi.org/10.1109/ASE.2009.67},
}

@InProceedings{Sas1991,
  author    = {van Sas, Jos and Catthoor, Francky and Vandeput, Peter and Rossaert, Frank and De Man, Hugo},
  title     = {Automated Test Pattern Generation for the Cathedral-II/2Nd Architectural Synthesis Environment},
  booktitle = {Proceedings of the Conference on European Design Automation},
  year      = {1991},
  series    = {EURO-DAC '91},
  pages     = {208--213},
  address   = {Los Alamitos, CA, USA},
  publisher = {IEEE Computer Society Press},
  acmid     = {951559},
  isbn      = {0-8186-2130-3},
  location  = {Amsterdam, The Netherlands},
  numpages  = {6},
  url       = {http://dl.acm.org/citation.cfm?id=951513.951559},
}

@InProceedings{Hummer2013,
  author    = {Hummer, Waldemar and Rosenberg, Florian and Oliveira, F\'{a}bio and Eilam, Tamar},
  title     = {Automated Testing of Chef Automation Scripts},
  booktitle = {Proceedings Demo \&\#38; Poster Track of ACM/IFIP/USENIX International Middleware Conference},
  year      = {2013},
  series    = {MiddlewareDPT '13},
  pages     = {4:1--4:2},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2541632},
  articleno = {4},
  doi       = {10.1145/2541614.2541632},
  isbn      = {978-1-4503-2549-3},
  location  = {Beijing, China},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/2541614.2541632},
}

@Article{Yang1996,
  author     = {Yang, Cheer-Sun D. and Pollock, Lori L.},
  title      = {Towards a Structural Load Testing Tool},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {1996},
  volume     = {21},
  number     = {3},
  pages      = {201--208},
  month      = may,
  issn       = {0163-5948},
  acmid      = {226318},
  address    = {New York, NY, USA},
  doi        = {10.1145/226295.226318},
  issue_date = {May 1996},
  numpages   = {8},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/226295.226318},
}

@InProceedings{Yang1996a,
  author    = {Yang, Cheer-Sun D. and Pollock, Lori L.},
  title     = {Towards a Structural Load Testing Tool},
  booktitle = {Proceedings of the 1996 ACM SIGSOFT International Symposium on Software Testing and Analysis},
  year      = {1996},
  series    = {ISSTA '96},
  pages     = {201--208},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {226318},
  doi       = {10.1145/229000.226318},
  isbn      = {0-89791-787-1},
  location  = {San Diego, California, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/229000.226318},
}

@InProceedings{Bucur2013,
  author    = {Bucur, Stefan and Kinder, Johannes and Candea, George},
  title     = {Making Automated Testing of Cloud Applications an Integral Component of PaaS},
  booktitle = {Proceedings of the 4th Asia-Pacific Workshop on Systems},
  year      = {2013},
  series    = {APSys '13},
  pages     = {18:1--18:7},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2500730},
  articleno = {18},
  doi       = {10.1145/2500727.2500730},
  isbn      = {978-1-4503-2316-1},
  location  = {Singapore, Singapore},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2500727.2500730},
}

@InProceedings{Kim-Park2010,
  author    = {Kim-Park, Dae S. and de la Riva, Claudio and Tuya, Javier},
  title     = {An Automated Test Oracle for XML Processing Programs},
  booktitle = {Proceedings of the First International Workshop on Software Test Output Validation},
  year      = {2010},
  series    = {STOV '10},
  pages     = {5--12},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1868050},
  doi       = {10.1145/1868048.1868050},
  isbn      = {978-1-4503-0138-1},
  keywords  = {XML queries, XML-based testing, software testing, test oracles},
  location  = {Trento, Italy},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1868048.1868050},
}

@InProceedings{Rodriguez2015,
  author    = {Rodriguez, Daniel and Dolado, Javier and Tuya, Javier},
  title     = {Bayesian Concepts in Software Testing: An Initial Review},
  booktitle = {Proceedings of the 6th International Workshop on Automating Test Case Design, Selection and Evaluation},
  year      = {2015},
  series    = {A-TEST 2015},
  pages     = {41--46},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2804329},
  doi       = {10.1145/2804322.2804329},
  isbn      = {978-1-4503-3813-4},
  keywords  = {Bayesian networks, Bayesian statistics, probabilistic graphical models, software testing},
  location  = {Bergamo, Italy},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/2804322.2804329},
}

@InProceedings{Jiang2013,
  author    = {Jiang, ZhenMing and Litoiu, Marin and Hassan, Ahmed E. and Vytas, Paul},
  title     = {2Nd International Workshop on Load Testing of Large Software Systems (LT 2013)},
  booktitle = {Proceedings of the 2013 Conference of the Center for Advanced Studies on Collaborative Research},
  year      = {2013},
  series    = {CASCON '13},
  pages     = {353--354},
  address   = {Riverton, NJ, USA},
  publisher = {IBM Corp.},
  acmid     = {2555564},
  location  = {Ontario, Canada},
  numpages  = {2},
  url       = {http://dl.acm.org/citation.cfm?id=2555523.2555564},
}

@InProceedings{Zeng2016,
  author    = {Zeng, Xia and Li, Dengfeng and Zheng, Wujie and Xia, Fan and Deng, Yuetang and Lam, Wing and Yang, Wei and Xie, Tao},
  title     = {Automated Test Input Generation for Android: Are We Really There Yet in an Industrial Case?},
  booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  year      = {2016},
  series    = {FSE 2016},
  pages     = {987--992},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2983958},
  doi       = {10.1145/2950290.2983958},
  isbn      = {978-1-4503-4218-6},
  keywords  = {Android, Code coverage, GUI testing, Test case generating},
  location  = {Seattle, WA, USA},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/2950290.2983958},
}

@InProceedings{Zhang2016,
  author    = {Zhang, Hailong and Wu, Haowei and Rountev, Atanas},
  title     = {Automated Test Generation for Detection of Leaks in Android Applications},
  booktitle = {Proceedings of the 11th International Workshop on Automation of Software Test},
  year      = {2016},
  series    = {AST '16},
  pages     = {64--70},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2896932},
  doi       = {10.1145/2896921.2896932},
  isbn      = {978-1-4503-4151-6},
  location  = {Austin, Texas},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2896921.2896932},
}

@InProceedings{Butler2010,
  author    = {Butler, Bernard and Jennings, Brendan and Botvich, Dmitri},
  title     = {XACML Policy Performance Evaluation Using a Flexible Load Testing Framework},
  booktitle = {Proceedings of the 17th ACM Conference on Computer and Communications Security},
  year      = {2010},
  series    = {CCS '10},
  pages     = {648--650},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1866385},
  doi       = {10.1145/1866307.1866385},
  isbn      = {978-1-4503-0245-6},
  keywords  = {access control policies, measurement testbed, performance evaluation},
  location  = {Chicago, Illinois, USA},
  numpages  = {3},
  url       = {http://doi.acm.org/10.1145/1866307.1866385},
}

@InProceedings{Sasnauskas2014,
  author    = {Sasnauskas, Raimondas and Regehr, John},
  title     = {Intent Fuzzer: Crafting Intents of Death},
  booktitle = {Proceedings of the 2014 Joint International Workshop on Dynamic Analysis (WODA) and Software and System Performance Testing, Debugging, and Analytics (PERTEA)},
  year      = {2014},
  series    = {WODA+PERTEA 2014},
  pages     = {1--5},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2632169},
  doi       = {10.1145/2632168.2632169},
  isbn      = {978-1-4503-2934-7},
  keywords  = {Android IPC, fuzz testing, random testing, static analysis},
  location  = {San Jose, CA, USA},
  numpages  = {5},
  url       = {http://doi.acm.org/10.1145/2632168.2632169},
}

@InProceedings{Gao2017,
  author    = {Gao, Ruoyu and Jiang, Zhen Ming (Jack)},
  title     = {An Exploratory Study on Assessing the Impact of Environment Variations on the Results of Load Tests},
  booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
  year      = {2017},
  series    = {MSR '17},
  pages     = {379--390},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {3104235},
  doi       = {10.1109/MSR.2017.22},
  isbn      = {978-1-5386-1544-7},
  location  = {Buenos Aires, Argentina},
  numpages  = {12},
  url       = {https://doi.org/10.1109/MSR.2017.22},
}

@InProceedings{Arcuri2018,
  author    = {Arcuri, Andre},
  title     = {Journal First Presentation of an Experience Report on Applying Software Testing Academic Results in Industry: We Need Usable Automated Test Generation},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering},
  year      = {2018},
  series    = {ICSE '18},
  pages     = {1065--1065},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3182555},
  doi       = {10.1145/3180155.3182555},
  isbn      = {978-1-4503-5638-1},
  keywords  = {applied research, impact, industry, practice, technology transfer},
  location  = {Gothenburg, Sweden},
  numpages  = {1},
  url       = {http://doi.acm.org/10.1145/3180155.3182555},
}

@InProceedings{Kaczmarski2017,
  author    = {Kaczmarski, Maciej and Perry, Philip and Murphy, John and Portillo-Dominguez, A. Omar},
  title     = {In-Test Adaptation of Workload in Enterprise Application Performance Testing},
  booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
  year      = {2017},
  series    = {ICPE '17 Companion},
  pages     = {69--72},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3053614},
  doi       = {10.1145/3053600.3053614},
  isbn      = {978-1-4503-4899-7},
  keywords  = {analysis, engineering, performance, testing},
  location  = {L'Aquila, Italy},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/3053600.3053614},
}

@Article{Monpratarnchai2014,
  author     = {Monpratarnchai, Supasit and Fujiwara, Shoichiro and Katayama, Asako and Uehara, Tadahiro},
  title      = {Automated Testing for Java Programs Using JPF-based Test Case Generation},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {2014},
  volume     = {39},
  number     = {1},
  pages      = {1--5},
  month      = feb,
  issn       = {0163-5948},
  acmid      = {2560575},
  address    = {New York, NY, USA},
  doi        = {10.1145/2557833.2560575},
  issue_date = {January 2014},
  keywords   = {JPF, JUnit, Java, automation, coverage, driver, eclipse, generation, program testing, stub, symbolic execution, test case},
  numpages   = {5},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/2557833.2560575},
}

@InProceedings{Briand2005,
  author    = {Briand, Lionel C. and Labiche, Yvan and Shousha, Marwa},
  title     = {Stress Testing Real-time Systems with Genetic Algorithms},
  booktitle = {Proceedings of the 7th Annual Conference on Genetic and Evolutionary Computation},
  year      = {2005},
  series    = {GECCO '05},
  pages     = {1021--1028},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1068183},
  doi       = {10.1145/1068009.1068183},
  isbn      = {1-59593-010-8},
  keywords  = {genetic algorithms, schedulability theory},
  location  = {Washington DC, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1068009.1068183},
}

@InProceedings{Camargo2016,
  author    = {de Camargo, Andr{\'e} and Salvadori, Ivan and Mello, Ronaldo dos Santos and Siqueira, Frank},
  title     = {An Architecture to Automate Performance Tests on Microservices},
  booktitle = {Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services},
  year      = {2016},
  series    = {iiWAS '16},
  pages     = {422--429},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3011179},
  doi       = {10.1145/3011141.3011179},
  isbn      = {978-1-4503-4807-2},
  keywords  = {microservices, performance test, test automation},
  location  = {Singapore, Singapore},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/3011141.3011179},
}

@InProceedings{Hallenberg2012,
  author    = {Hallenberg, Niels and Carlsen, Philip Lykke},
  title     = {Declarative Automated Test},
  booktitle = {Proceedings of the 7th International Workshop on Automation of Software Test},
  year      = {2012},
  series    = {AST '12},
  pages     = {96--102},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {2663628},
  isbn      = {978-1-4673-1822-8},
  keywords  = {F\#, automated testing, domain specific language, functional testing},
  location  = {Zurich, Switzerland},
  numpages  = {7},
  url       = {http://dl.acm.org/citation.cfm?id=2663608.2663628},
}

@InProceedings{Zhang2011b,
  author    = {Zhang, Sai and Saff, David and Bu, Yingyi and Ernst, Michael D.},
  title     = {Combined Static and Dynamic Automated Test Generation},
  booktitle = {Proceedings of the 2011 International Symposium on Software Testing and Analysis},
  year      = {2011},
  series    = {ISSTA '11},
  pages     = {353--363},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2001463},
  doi       = {10.1145/2001420.2001463},
  isbn      = {978-1-4503-0562-4},
  keywords  = {automated test generation, dynamic analyses, static},
  location  = {Toronto, Ontario, Canada},
  numpages  = {11},
  url       = {http://doi.acm.org/10.1145/2001420.2001463},
}

@InProceedings{Ramakrishnan2017,
  author    = {Ramakrishnan, Raghu and Shrawan, Vandana and Singh, Prabhpahul},
  title     = {Setting Realistic Think Times in Performance Testing: A Practitioner's Approach},
  booktitle = {Proceedings of the 10th Innovations in Software Engineering Conference},
  year      = {2017},
  series    = {ISEC '17},
  pages     = {157--164},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3021479},
  doi       = {10.1145/3021460.3021479},
  isbn      = {978-1-4503-4856-0},
  keywords  = {Performance testing, load testing, think time},
  location  = {Jaipur, India},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/3021460.3021479},
}

@InProceedings{Xie2007a,
  author    = {Xie, Tao and Zhao, Jianjun},
  title     = {Perspectives on Automated Testing of Aspect-oriented Programs},
  booktitle = {Proceedings of the 3rd Workshop on Testing Aspect-oriented Programs},
  year      = {2007},
  series    = {WTAOP '07},
  pages     = {7--12},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1229386},
  doi       = {10.1145/1229384.1229386},
  isbn      = {978-1-59593-663-9},
  keywords  = {AspectJ, aspect-oriented software development, software testing},
  location  = {Vancouver, British Columbia, Canada},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/1229384.1229386},
}

@InProceedings{Leitner2017,
  author    = {Leitner, Philipp and Bezemer, Cor-Paul},
  title     = {An Exploratory Study of the State of Practice of Performance Testing in Java-Based Open Source Projects},
  booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
  year      = {2017},
  series    = {ICPE '17},
  pages     = {373--384},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3030213},
  doi       = {10.1145/3030207.3030213},
  isbn      = {978-1-4503-4404-3},
  keywords  = {empirical software engineering, mining software repositories, open source, performance engineering, performance testing},
  location  = {L'Aquila, Italy},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/3030207.3030213},
}

@InProceedings{Gambi2013,
  author    = {Gambi, Alessio and Hummer, Waldemar and Dustdar, Schahram},
  title     = {Automated Testing of Cloud-based Elastic Systems with AUToCLES},
  booktitle = {Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering},
  year      = {2013},
  series    = {ASE'13},
  pages     = {714--717},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {3107757},
  doi       = {10.1109/ASE.2013.6693140},
  isbn      = {978-1-4799-0215-6},
  location  = {Silicon Valley, CA, USA},
  numpages  = {4},
  url       = {https://doi.org/10.1109/ASE.2013.6693140},
}

@InProceedings{Keng2016,
  author    = {Keng, Joseph Chan Joo},
  title     = {Automated Testing and Notification of Mobile App Privacy Leak-cause Behaviours},
  booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
  year      = {2016},
  series    = {ASE 2016},
  pages     = {880--883},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2975935},
  doi       = {10.1145/2970276.2975935},
  isbn      = {978-1-4503-3845-5},
  keywords  = {Automated static analysis, Dynamic Analysis, Security and Privacy},
  location  = {Singapore, Singapore},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2970276.2975935},
}

@InProceedings{Kube2011,
  author    = {Kube, Nate and Yoo, Kevin and Hoffman, Daniel},
  title     = {Automated Testing of Industrial Control Devices: The Delphi Database},
  booktitle = {Proceedings of the 6th International Workshop on Automation of Software Test},
  year      = {2011},
  series    = {AST '11},
  pages     = {71--76},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1982611},
  doi       = {10.1145/1982595.1982611},
  isbn      = {978-1-4503-0592-1},
  keywords  = {automated software testing, industrial cyber security, network vulnerability testing},
  location  = {Waikiki, Honolulu, HI, USA},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/1982595.1982611},
}

@InProceedings{Gerhold2016,
  author    = {Gerhold, Marcus and Stoelinga, Mari\"{e}lle},
  title     = {Model-based Testing of Stochastic Systems with IOCO Theory},
  booktitle = {Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation},
  year      = {2016},
  series    = {A-TEST 2016},
  pages     = {45--51},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2994298},
  doi       = {10.1145/2994291.2994298},
  isbn      = {978-1-4503-4401-2},
  keywords  = {Hypothesis Testing, Markov automata, Model-Based Testing, ioco},
  location  = {Seattle, WA, USA},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2994291.2994298},
}

@InProceedings{Korel1996,
  author    = {Korel, Bogdan and Al-Yami, Ali M.},
  title     = {Assertion-oriented Automated Test Data Generation},
  booktitle = {Proceedings of the 18th International Conference on Software Engineering},
  year      = {1996},
  series    = {ICSE '96},
  pages     = {71--80},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {227740},
  isbn      = {0-8186-7246-3},
  keywords  = {assertion oriented automated test data generation, automated test data generation, automatic programming, automatic run time detection, program input, program testing, software engineering, software errors, white box testing},
  location  = {Berlin, Germany},
  numpages  = {10},
  url       = {http://dl.acm.org/citation.cfm?id=227726.227740},
}

@InProceedings{Gueldali2009,
  author    = {G\"{u}ldali, Baris and Funke, Holger and Jahnich, Michael and Sauer, Stefan and Engels, Gregor},
  title     = {Semi-automated Test Planning for e-ID Systems by Using Requirements Clustering},
  booktitle = {Proceedings of the 2009 IEEE/ACM International Conference on Automated Software Engineering},
  year      = {2009},
  series    = {ASE '09},
  pages     = {29--39},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {1747506},
  doi       = {10.1109/ASE.2009.86},
  isbn      = {978-0-7695-3891-4},
  keywords  = {Acceptance Testing, Test Planning, Requirements Clustering, Linguistic Analysis, Open Distributed Processing Systems},
  numpages  = {11},
  url       = {https://doi.org/10.1109/ASE.2009.86},
}

@InProceedings{Vincenzi2016,
  author    = {Vincenzi, Auri M. R. and Bachiega, Tiago and de Oliveira, Daniel G. and de Souza, Simone R. S. and Maldonado, Jos{\'e} C.},
  title     = {The Complementary Aspect of Automatically and Manually Generated Test Case Sets},
  booktitle = {Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation},
  year      = {2016},
  series    = {A-TEST 2016},
  pages     = {23--30},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2994295},
  doi       = {10.1145/2994291.2994295},
  isbn      = {978-1-4503-4401-2},
  keywords  = {Automated Test Data Generation, Automated Testing, Manual Testing, Software Testing},
  location  = {Seattle, WA, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2994291.2994295},
}

@InProceedings{Dubrov2013,
  author    = {Dubrov, Denis V.},
  title     = {N Queens Problem: A Metaprogramming Stress Test for the Compiler},
  booktitle = {Proceedings of the 9th ACM SIGPLAN Workshop on Generic Programming},
  year      = {2013},
  series    = {WGP '13},
  pages     = {35--46},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2502492},
  doi       = {10.1145/2502488.2502492},
  isbn      = {978-1-4503-2389-5},
  keywords  = {boost, clang, constexpr, gcc, mpl, queens puzzle},
  location  = {Boston, Massachusetts, USA},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/2502488.2502492},
}

@InProceedings{Crowley1996,
  author    = {Crowley, J. L. and Leathrum, J. F. and Liburdy, K. A.},
  title     = {Issues in the Full Scale Use of Formal Methods for Automated Testing},
  booktitle = {Proceedings of the 1996 ACM SIGSOFT International Symposium on Software Testing and Analysis},
  year      = {1996},
  series    = {ISSTA '96},
  pages     = {71--78},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {226303},
  doi       = {10.1145/229000.226303},
  isbn      = {0-89791-787-1},
  location  = {San Diego, California, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/229000.226303},
}

@Article{Crowley1996a,
  author     = {Crowley, J. L. and Leathrum, J. F. and Liburdy, K. A.},
  title      = {Issues in the Full Scale Use of Formal Methods for Automated Testing},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {1996},
  volume     = {21},
  number     = {3},
  pages      = {71--78},
  month      = may,
  issn       = {0163-5948},
  acmid      = {226303},
  address    = {New York, NY, USA},
  doi        = {10.1145/226295.226303},
  issue_date = {May 1996},
  numpages   = {8},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/226295.226303},
}

@InProceedings{Landhaeuser2012,
  author    = {Landh\"{a}u\sser, Mathias and Tichy, Walter F.},
  title     = {Automated Test-case Generation by Cloning},
  booktitle = {Proceedings of the 7th International Workshop on Automation of Software Test},
  year      = {2012},
  series    = {AST '12},
  pages     = {83--88},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {2663625},
  isbn      = {978-1-4673-1822-8},
  keywords  = {automatic testing, software testing, test oracle, testing},
  location  = {Zurich, Switzerland},
  numpages  = {6},
  url       = {http://dl.acm.org/citation.cfm?id=2663608.2663625},
}

@InProceedings{Appelt2014,
  author    = {Appelt, Dennis and Nguyen, Cu Duy and Briand, Lionel C. and Alshahwan, Nadia},
  title     = {Automated Testing for SQL Injection Vulnerabilities: An Input Mutation Approach},
  booktitle = {Proceedings of the 2014 International Symposium on Software Testing and Analysis},
  year      = {2014},
  series    = {ISSTA 2014},
  pages     = {259--269},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2610403},
  doi       = {10.1145/2610384.2610403},
  isbn      = {978-1-4503-2645-2},
  keywords  = {Mutation Testing, SQL Injection, Test Generation},
  location  = {San Jose, CA, USA},
  numpages  = {11},
  url       = {http://doi.acm.org/10.1145/2610384.2610403},
}

@InProceedings{Xu2012,
  author    = {Xu, Dianxiang and Thomas, Lijo and Kent, Michael and Mouelhi, Tejeddine and Le Traon, Yves},
  title     = {A Model-based Approach to Automated Testing of Access Control Policies},
  booktitle = {Proceedings of the 17th ACM Symposium on Access Control Models and Technologies},
  year      = {2012},
  series    = {SACMAT '12},
  pages     = {209--218},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2295173},
  doi       = {10.1145/2295136.2295173},
  isbn      = {978-1-4503-1295-0},
  keywords  = {access control, model-based testing, mutation analysis, petri nets, software testing},
  location  = {Newark, New Jersey, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2295136.2295173},
}

@InProceedings{Kresse2016,
  author    = {Kresse, Antonia and Kruse, Peter M.},
  title     = {Development and Maintenance Efforts Testing Graphical User Interfaces: A Comparison},
  booktitle = {Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation},
  year      = {2016},
  series    = {A-TEST 2016},
  pages     = {52--58},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2994299},
  doi       = {10.1145/2994291.2994299},
  isbn      = {978-1-4503-4401-2},
  keywords  = {Empirical study, GUI Testing},
  location  = {Seattle, WA, USA},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2994291.2994299},
}

@InProceedings{Bayan2008,
  author    = {Bayan, Mohamad and Cangussu, Jo\~{a}o W.},
  title     = {Automatic Feedback, Control-based, Stress and Load Testing},
  booktitle = {Proceedings of the 2008 ACM Symposium on Applied Computing},
  year      = {2008},
  series    = {SAC '08},
  pages     = {661--666},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1363847},
  doi       = {10.1145/1363686.1363847},
  isbn      = {978-1-59593-753-7},
  location  = {Fortaleza, Ceara, Brazil},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/1363686.1363847},
}

@Article{Bhasin2014,
  author     = {Bhasin, Harsh},
  title      = {Artificial Life and Cellular Automata Based Automated Test Case Generator},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {2014},
  volume     = {39},
  number     = {1},
  pages      = {1--5},
  month      = feb,
  issn       = {0163-5948},
  acmid      = {2557843},
  address    = {New York, NY, USA},
  doi        = {10.1145/2557833.2557843},
  issue_date = {January 2014},
  keywords   = {artificial life, automated test data generation, cellular automata, testing},
  numpages   = {5},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/2557833.2557843},
}

@InProceedings{Canou2009,
  author    = {Canou, Benjamin and Darrasse, Alexis},
  title     = {Fast and Sound Random Generation for Automated Testing and Benchmarking in Objective Caml},
  booktitle = {Proceedings of the 2009 ACM SIGPLAN Workshop on ML},
  year      = {2009},
  series    = {ML '09},
  pages     = {61--70},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1596637},
  doi       = {10.1145/1596627.1596637},
  isbn      = {978-1-60558-509-3},
  keywords  = {Boltzmann model, algebraic data types, random generation, specification-based testing},
  location  = {Edinburgh, Scotland},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1596627.1596637},
}

@InProceedings{Zabrovskiy2017,
  author    = {Zabrovskiy, Anatoliy and Kuzmin, Evgeny and Petrov, Evgeny and Timmerer, Christian and Mueller, Christopher},
  title     = {AdViSE: Adaptive Video Streaming Evaluation Framework for the Automated Testing of Media Players},
  booktitle = {Proceedings of the 8th ACM on Multimedia Systems Conference},
  year      = {2017},
  series    = {MMSys'17},
  pages     = {217--220},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3083221},
  doi       = {10.1145/3083187.3083221},
  isbn      = {978-1-4503-5002-0},
  keywords  = {AdViSE, Adaptive streaming, Automated Testing, Evaluation framework, MPEG-DASH, Media players, Metrics, Mininet, Network emulation, Quality of Experience, Selenium},
  location  = {Taipei, Taiwan},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/3083187.3083221},
}

@InProceedings{Zheng2017,
  author    = {Zheng, Haibing and Li, Dengfeng and Liang, Beihai and Zeng, Xia and Zheng, Wujie and Deng, Yuetang and Lam, Wing and Yang, Wei and Xie, Tao},
  title     = {Automated Test Input Generation for Android: Towards Getting There in an Industrial Case},
  booktitle = {Proceedings of the 39th International Conference on Software Engineering: Software Engineering in Practice Track},
  year      = {2017},
  series    = {ICSE-SEIP '17},
  pages     = {253--262},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {3103145},
  doi       = {10.1109/ICSE-SEIP.2017.32},
  isbn      = {978-1-5386-2717-4},
  location  = {Buenos Aires, Argentina},
  numpages  = {10},
  url       = {https://doi.org/10.1109/ICSE-SEIP.2017.32},
}

@InProceedings{Singi2015,
  author    = {Singi, Kapil and Kaulgud, Vikrant and Era, Dipin},
  title     = {Visual Requirements Specification and Automated Test Generation for Digital Applications},
  booktitle = {Proceedings of the Second International Workshop on Requirements Engineering and Testing},
  year      = {2015},
  series    = {RET '15},
  pages     = {37--40},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {2820715},
  location  = {Florence, Italy},
  numpages  = {4},
  url       = {http://dl.acm.org/citation.cfm?id=2820704.2820715},
}

@InProceedings{Qadeer2014,
  author    = {Qadeer, Shaz},
  title     = {P: A Domain-specific Language for Asynchronous Event-driven Programming (Invited Talk Abstract)},
  booktitle = {Proceedings of the 2014 Joint International Workshop on Dynamic Analysis (WODA) and Software and System Performance Testing, Debugging, and Analytics (PERTEA)},
  year      = {2014},
  series    = {WODA+PERTEA 2014},
  pages     = {8--8},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2638830},
  doi       = {10.1145/2632168.2638830},
  isbn      = {978-1-4503-2934-7},
  keywords  = {Asynchrony, Domain-Specific Language},
  location  = {San Jose, CA, USA},
  numpages  = {1},
  url       = {http://doi.acm.org/10.1145/2632168.2638830},
}

@InProceedings{Sridharan2014,
  author    = {Sridharan, Manu},
  title     = {Effective Race Detection for Event-driven Programs (Invited Talk Abstract)},
  booktitle = {Proceedings of the 2014 Joint International Workshop on Dynamic Analysis (WODA) and Software and System Performance Testing, Debugging, and Analytics (PERTEA)},
  year      = {2014},
  series    = {WODA+PERTEA 2014},
  pages     = {9--9},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2638831},
  doi       = {10.1145/2632168.2638831},
  isbn      = {978-1-4503-2934-7},
  keywords  = {Effective Race Detection},
  location  = {San Jose, CA, USA},
  numpages  = {1},
  url       = {http://doi.acm.org/10.1145/2632168.2638831},
}

@InProceedings{Ahsan2017,
  author    = {Ahsan, Imran and Butt, Wasi Haider and Ahmed, Mudassar Adeel and Anwar, Muhammad Waseem},
  title     = {A Comprehensive Investigation of Natural Language Processing Techniques and Tools to Generate Automated Test Cases},
  booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
  year      = {2017},
  series    = {ICC '17},
  pages     = {132:1--132:10},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3036375},
  articleno = {132},
  doi       = {10.1145/3018896.3036375},
  isbn      = {978-1-4503-4774-7},
  keywords  = {NLP, SLR, nature language processing, test case generation, test cases, text mining},
  location  = {Cambridge, United Kingdom},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/3018896.3036375},
}

@Article{Sant2005,
  author     = {Sant, Jessica and Souter, Amie and Greenwald, Lloyd},
  title      = {An Exploration of Statistical Models for Automated Test Case Generation},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {2005},
  volume     = {30},
  number     = {4},
  pages      = {1--7},
  month      = may,
  issn       = {0163-5948},
  acmid      = {1083256},
  address    = {New York, NY, USA},
  doi        = {10.1145/1082983.1083256},
  issue_date = {July 2005},
  numpages   = {7},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/1082983.1083256},
}

@Article{Prins1982,
  author     = {Prins, Jan F.},
  title      = {Automated Testing in APL\&Mdash;an Application of Exception Handling},
  journal    = {SIGAPL APL Quote Quad},
  year       = {1982},
  volume     = {13},
  number     = {1},
  pages      = {260--264},
  month      = jul,
  issn       = {0163-6006},
  acmid      = {802254},
  address    = {New York, NY, USA},
  doi        = {10.1145/390006.802254},
  issue_date = {September 1982},
  numpages   = {5},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/390006.802254},
}

@InProceedings{Prins1982a,
  author    = {Prins, Jan F.},
  title     = {Automated Testing in APL\&Mdash;an Application of Exception Handling},
  booktitle = {Proceedings of the International Conference on APL},
  year      = {1982},
  series    = {APL '82},
  pages     = {260--264},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {802254},
  doi       = {10.1145/800071.802254},
  isbn      = {0-89791-078-8},
  location  = {Heidelberg, Germany},
  numpages  = {5},
  url       = {http://doi.acm.org/10.1145/800071.802254},
}

@InProceedings{Cordemans2015,
  author    = {Cordemans, Piet and Steegmans, Eric and Boydens, Jeroen},
  title     = {Deterministically Testing Actor-based Concurrent Software},
  booktitle = {Proceedings of the 6th International Workshop on Automating Test Case Design, Selection and Evaluation},
  year      = {2015},
  series    = {A-TEST 2015},
  pages     = {26--30},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2804327},
  doi       = {10.1145/2804322.2804327},
  isbn      = {978-1-4503-3813-4},
  keywords  = {Actor Model, Concurrent Software, Deterministic Testing},
  location  = {Bergamo, Italy},
  numpages  = {5},
  url       = {http://doi.acm.org/10.1145/2804322.2804327},
}

@Article{Harty2011,
  author     = {Harty, Julian},
  title      = {Finding Usability Bugs with Automated Tests},
  journal    = {Commun. ACM},
  year       = {2011},
  volume     = {54},
  number     = {2},
  pages      = {44--49},
  month      = feb,
  issn       = {0001-0782},
  acmid      = {1897836},
  address    = {New York, NY, USA},
  doi        = {10.1145/1897816.1897836},
  issue_date = {February 2011},
  numpages   = {6},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/1897816.1897836},
}

@InProceedings{Nistor2014,
  author    = {Nistor, Adrian},
  title     = {Detecting and Repairing Performance Bugs Using Execution and Code Patterns (Invited Talk Abstract)},
  booktitle = {Proceedings of the 2014 Joint International Workshop on Dynamic Analysis (WODA) and Software and System Performance Testing, Debugging, and Analytics (PERTEA)},
  year      = {2014},
  series    = {WODA+PERTEA 2014},
  pages     = {12--12},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2638834},
  doi       = {10.1145/2632168.2638834},
  isbn      = {978-1-4503-2934-7},
  keywords  = {Code Patterns, Execution, Performance Bugs},
  location  = {San Jose, CA, USA},
  numpages  = {1},
  url       = {http://doi.acm.org/10.1145/2632168.2638834},
}

@InProceedings{RealesMateo2013,
  author    = {Reales Mateo, Pedro and Polo Usaola, Macario},
  title     = {Automated Test Generation for Multi-state Systems},
  booktitle = {Proceedings of the 15th Annual Conference Companion on Genetic and Evolutionary Computation},
  year      = {2013},
  series    = {GECCO '13 Companion},
  pages     = {211--212},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2464677},
  doi       = {10.1145/2464576.2464677},
  isbn      = {978-1-4503-1964-5},
  keywords  = {genetic algorihtms, mutation testing, test generation},
  location  = {Amsterdam, The Netherlands},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/2464576.2464677},
}

@InProceedings{Hoskins2005,
  author    = {Hoskins, Dean S. and Colbourn, Charles J. and Montgomery, Douglas C.},
  title     = {Software Performance Testing Using Covering Arrays: Efficient Screening Designs with Categorical Factors},
  booktitle = {Proceedings of the 5th International Workshop on Software and Performance},
  year      = {2005},
  series    = {WOSP '05},
  pages     = {131--136},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1071034},
  doi       = {10.1145/1071021.1071034},
  isbn      = {1-59593-087-6},
  keywords  = {D-optimal designs, covering arrays, performance testing},
  location  = {Palma, Illes Balears, Spain},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/1071021.1071034},
}

@InProceedings{Xiao2014,
  author    = {Xiao, Xusheng},
  title     = {Context-sensitive Delta Inference for Identifying Workload-dependent Performance Bottlenecks (Invited Talk Abstract)},
  booktitle = {Proceedings of the 2014 Joint International Workshop on Dynamic Analysis (WODA) and Software and System Performance Testing, Debugging, and Analytics (PERTEA)},
  year      = {2014},
  series    = {WODA+PERTEA 2014},
  pages     = {11--11},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2638833},
  doi       = {10.1145/2632168.2638833},
  isbn      = {978-1-4503-2934-7},
  keywords  = {Context-Sensitive Delta Inference, Workload-Dependent Performance},
  location  = {San Jose, CA, USA},
  numpages  = {1},
  url       = {http://doi.acm.org/10.1145/2632168.2638833},
}

@Article{Bhasin2014a,
  author     = {Bhasin, Harsh and Kaur, Harleen},
  title      = {Toward a Secured Automated Test-data Generator Using S-Box},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {2014},
  volume     = {39},
  number     = {5},
  pages      = {1--5},
  month      = sep,
  issn       = {0163-5948},
  acmid      = {2659127},
  address    = {New York, NY, USA},
  doi        = {10.1145/2659118.2659127},
  issue_date = {September 2014},
  keywords   = {S-box, artificial-life-based automated test-data generator (ALATDG), cipher text, decryption, encryption, test cases, testing},
  numpages   = {5},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/2659118.2659127},
}

@InProceedings{Abogharaf2012,
  author    = {Abogharaf, Abdulhakim and Palit, Rajesh and Naik, Kshirasagar and Singh, Ajit},
  title     = {A Methodology for Energy Performance Testing of Smartphone Applications},
  booktitle = {Proceedings of the 7th International Workshop on Automation of Software Test},
  year      = {2012},
  series    = {AST '12},
  pages     = {110--116},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {2663630},
  isbn      = {978-1-4673-1822-8},
  keywords  = {energy performance, smartphones, testing},
  location  = {Zurich, Switzerland},
  numpages  = {7},
  url       = {http://dl.acm.org/citation.cfm?id=2663608.2663630},
}

@InProceedings{Ratiu2016,
  author    = {Ratiu, Daniel and Voelter, Markus},
  title     = {Automated Testing of DSL Implementations: Experiences from Building Mbeddr},
  booktitle = {Proceedings of the 11th International Workshop on Automation of Software Test},
  year      = {2016},
  series    = {AST '16},
  pages     = {15--21},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2896922},
  doi       = {10.1145/2896921.2896922},
  isbn      = {978-1-4503-4151-6},
  location  = {Austin, Texas},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2896921.2896922},
}

@Article{Morrison2012,
  author     = {Morrison, Kevin and Haddad, Hisham M.},
  title      = {Converting Users to Testers: An Alternative Approach to Load Test Script Creation, Parameterization and Data Corellation},
  journal    = {J. Comput. Sci. Coll.},
  year       = {2012},
  volume     = {28},
  number     = {2},
  pages      = {188--196},
  month      = dec,
  issn       = {1937-4771},
  acmid      = {2382917},
  address    = {USA},
  issue_date = {December 2012},
  numpages   = {9},
  publisher  = {Consortium for Computing Sciences in Colleges},
  url        = {http://dl.acm.org/citation.cfm?id=2382887.2382917},
}

@InProceedings{Janjic2013,
  author    = {Janjic, Werner and Atkinson, Colin},
  title     = {Utilizing Software Reuse Experience for Automated Test Recommendation},
  booktitle = {Proceedings of the 8th International Workshop on Automation of Software Test},
  year      = {2013},
  series    = {AST '13},
  pages     = {100--106},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {2662436},
  isbn      = {978-1-4673-6161-3},
  location  = {San Francisco, California},
  numpages  = {7},
  url       = {http://dl.acm.org/citation.cfm?id=2662413.2662436},
}

@InProceedings{Miller2012,
  author    = {Miller, Bailey and Vahid, Frank and Givargis, Tony},
  title     = {MEDS: Mockup Electronic Data Sheets for Automated Testing of Cyber-physical Systems Using Digital Mockups},
  booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
  year      = {2012},
  series    = {DATE '12},
  pages     = {1417--1420},
  address   = {San Jose, CA, USA},
  publisher = {EDA Consortium},
  acmid     = {2493055},
  isbn      = {978-3-9810801-8-6},
  location  = {Dresden, Germany},
  numpages  = {4},
  url       = {http://dl.acm.org/citation.cfm?id=2492708.2493055},
}

@Article{Bogdanov2015,
  author     = {Bogdanov, Kirill and Pe\'{o}n-Quir\'{o}s, Miguel and Maguire,Jr., Gerald Q. and Kosti\'{c}, Dejan},
  title      = {Toward Automated Testing of Geo-Distributed Replica Selection Algorithms},
  journal    = {SIGCOMM Comput. Commun. Rev.},
  year       = {2015},
  volume     = {45},
  number     = {4},
  pages      = {89--90},
  month      = aug,
  issn       = {0146-4833},
  acmid      = {2790013},
  address    = {New York, NY, USA},
  doi        = {10.1145/2829988.2790013},
  issue_date = {October 2015},
  keywords   = {replica selection algorithms, software testing and debugging, symbolic execution, wide area networks},
  numpages   = {2},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/2829988.2790013},
}

@InProceedings{Bogdanov2015a,
  author    = {Bogdanov, Kirill and Pe\'{o}n-Quir\'{o}s, Miguel and Maguire,Jr., Gerald Q. and Kosti\'{c}, Dejan},
  title     = {Toward Automated Testing of Geo-Distributed Replica Selection Algorithms},
  booktitle = {Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication},
  year      = {2015},
  series    = {SIGCOMM '15},
  pages     = {89--90},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2790013},
  doi       = {10.1145/2785956.2790013},
  isbn      = {978-1-4503-3542-3},
  keywords  = {replica selection algorithms, software testing and debugging, symbolic execution, wide area networks},
  location  = {London, United Kingdom},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/2785956.2790013},
}

@InProceedings{Jain2005,
  author    = {Jain, Sanjay and Leong, Swee},
  title     = {Stress Testing a Supply Chain Using Simulation},
  booktitle = {Proceedings of the 37th Conference on Winter Simulation},
  year      = {2005},
  series    = {WSC '05},
  pages     = {1650--1657},
  publisher = {Winter Simulation Conference},
  acmid     = {1162995},
  isbn      = {0-7803-9519-0},
  location  = {Orlando, Florida},
  numpages  = {8},
  url       = {http://dl.acm.org/citation.cfm?id=1162708.1162995},
}

@InProceedings{Field2018,
  author    = {Field, Tony and Chatley, Robert and Wei, David},
  title     = {Software Performance Testing in Virtual Time},
  booktitle = {Companion of the 2018 ACM/SPEC International Conference on Performance Engineering},
  year      = {2018},
  series    = {ICPE '18},
  pages     = {173--174},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3186409},
  doi       = {10.1145/3185768.3186409},
  isbn      = {978-1-4503-5629-9},
  keywords  = {performance, test-driven development},
  location  = {Berlin, Germany},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/3185768.3186409},
}

@InProceedings{Campos2014,
  author    = {Campos, Jos{\'e} and Arcuri, Andrea and Fraser, Gordon and Abreu, Rui},
  title     = {Continuous Test Generation: Enhancing Continuous Integration with Automated Test Generation},
  booktitle = {Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
  year      = {2014},
  series    = {ASE '14},
  pages     = {55--66},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2643002},
  doi       = {10.1145/2642937.2643002},
  isbn      = {978-1-4503-3013-8},
  keywords  = {automated test generation, continuous integration, continuous testing, unit testing},
  location  = {Vasteras, Sweden},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/2642937.2643002},
}

@InProceedings{Saddler2016,
  author    = {Saddler, Jonathan and Cohen, Myra B.},
  title     = {EventFlowSlicer: Goal Based Test Generation for Graphical User Interfaces},
  booktitle = {Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation},
  year      = {2016},
  series    = {A-TEST 2016},
  pages     = {8--15},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2994293},
  doi       = {10.1145/2994291.2994293},
  isbn      = {978-1-4503-4401-2},
  keywords  = {goal-based testing, graphical user interfaces, software test generation},
  location  = {Seattle, WA, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2994291.2994293},
}

@Article{Gupta1998,
  author     = {Gupta, Neelam and Mathur, Aditya P. and Soffa, Mary Lou},
  title      = {Automated Test Data Generation Using an Iterative Relaxation Method},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {1998},
  volume     = {23},
  number     = {6},
  pages      = {231--244},
  month      = nov,
  issn       = {0163-5948},
  acmid      = {288321},
  address    = {New York, NY, USA},
  doi        = {10.1145/291252.288321},
  issue_date = {Nov. 1998},
  keywords   = {dynamic test data generation, input dependency set, path testing, predicate residuals, predicate sliccs, relaxation methods},
  numpages   = {14},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/291252.288321},
}

@InProceedings{Gupta1998a,
  author    = {Gupta, Neelam and Mathur, Aditya P. and Soffa, Mary Lou},
  title     = {Automated Test Data Generation Using an Iterative Relaxation Method},
  booktitle = {Proceedings of the 6th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  year      = {1998},
  series    = {SIGSOFT '98/FSE-6},
  pages     = {231--244},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {288321},
  doi       = {10.1145/288195.288321},
  isbn      = {1-58113-108-9},
  keywords  = {dynamic test data generation, input dependency set, path testing, predicate residuals, predicate sliccs, relaxation methods},
  location  = {Lake Buena Vista, Florida, USA},
  numpages  = {14},
  url       = {http://doi.acm.org/10.1145/288195.288321},
}

@Article{Poston1994,
  author     = {Poston, Robert M.},
  title      = {Automated Testing from Object Models},
  journal    = {Commun. ACM},
  year       = {1994},
  volume     = {37},
  number     = {9},
  pages      = {48--58},
  month      = sep,
  issn       = {0001-0782},
  acmid      = {184074},
  address    = {New York, NY, USA},
  doi        = {10.1145/182987.184074},
  issue_date = {Sept. 1994},
  numpages   = {11},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/182987.184074},
}

@InProceedings{Do2012,
  author    = {Do, TheAnh and Fong, Alvis C. M. and Pears, Russel},
  title     = {Scalable Automated Test Generation Using Coverage Guidance and Random Search},
  booktitle = {Proceedings of the 7th International Workshop on Automation of Software Test},
  year      = {2012},
  series    = {AST '12},
  pages     = {71--75},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {2663623},
  isbn      = {978-1-4673-1822-8},
  keywords  = {automated test input generation, dynamic symbolic execution, software testing},
  location  = {Zurich, Switzerland},
  numpages  = {5},
  url       = {http://dl.acm.org/citation.cfm?id=2663608.2663623},
}

@InProceedings{Kernighan1973,
  author    = {Kernighan, B. W. and Hamilton, P. A.},
  title     = {Synthetically Generated Performance Test Loads for Operating Systems},
  booktitle = {Proceedings of the 1973 ACM SIGME Symposium},
  year      = {1973},
  series    = {SIGME '73},
  pages     = {121--126},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {809343},
  doi       = {10.1145/800268.809343},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/800268.809343},
}

@InProceedings{Chiw2017,
  author    = {Chiw, Charisee and Kindlmann, Gordon and Reppy, John},
  title     = {DATm: Diderot's Automated Testing Model},
  booktitle = {Proceedings of the 12th International Workshop on Automation of Software Testing},
  year      = {2017},
  series    = {AST '17},
  pages     = {45--51},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {3100162},
  doi       = {10.1109/AST.2017.5},
  isbn      = {978-1-5386-1548-5},
  location  = {Buenos Aires, Argentina},
  numpages  = {7},
  url       = {https://doi.org/10.1109/AST.2017.5},
}

@InProceedings{Freitas2014,
  author    = {Freitas, Artur and Vieira, Renata},
  title     = {An Ontology for Guiding Performance Testing},
  booktitle = {Proceedings of the 2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT) - Volume 01},
  year      = {2014},
  series    = {WI-IAT '14},
  pages     = {400--407},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {2682748},
  doi       = {10.1109/WI-IAT.2014.62},
  isbn      = {978-1-4799-4143-8},
  numpages  = {8},
  url       = {http://dx.doi.org/10.1109/WI-IAT.2014.62},
}

@InProceedings{Ciccozzi2010,
  author    = {Ciccozzi, Federico and Cicchetti, Antonio and Siljam\"{a}ki, Toni and Kavadiya, Jenis},
  title     = {Automating Test Cases Generation: From xtUML System Models to QML Test Models},
  booktitle = {Proceedings of the 7th International Workshop on Model-Based Methodologies for Pervasive and Embedded Software},
  year      = {2010},
  series    = {MOMPES '10},
  pages     = {9--16},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1865877},
  doi       = {10.1145/1865875.1865877},
  isbn      = {978-1-4503-0123-7},
  keywords  = {automatic test cases generation, model-based development, model-based testing, model-driven engineering},
  location  = {Antwerpen, Belgium},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1865875.1865877},
}

@InProceedings{Olajubu2015,
  author    = {Olajubu, Oyindamola and Ajit, Suraj and Johnson, Mark and Turner, Scott and Thomson, Scott and Edwards, Mark},
  title     = {Automated Test Case Generation from Domain Specific Models of High-level Requirements},
  booktitle = {Proceedings of the 2015 Conference on Research in Adaptive and Convergent Systems},
  year      = {2015},
  series    = {RACS},
  pages     = {505--508},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2811555},
  doi       = {10.1145/2811411.2811555},
  isbn      = {978-1-4503-3738-0},
  keywords  = {domain specific languages, model-based testing},
  location  = {Prague, Czech Republic},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2811411.2811555},
}

@Article{Harty2011a,
  author     = {Harty, Julian},
  title      = {Finding Usability Bugs with Automated Tests},
  journal    = {Queue},
  year       = {2011},
  volume     = {9},
  number     = {1},
  pages      = {20:20--20:27},
  month      = jan,
  issn       = {1542-7730},
  acmid      = {1925091},
  address    = {New York, NY, USA},
  articleno  = {20},
  doi        = {10.1145/1922539.1925091},
  issue_date = {January 2011},
  numpages   = {8},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/1922539.1925091},
}

@InProceedings{Remkes1989,
  author    = {Remkes, David L. and Gutzmann, Kurt M. and Sizer, Frank E.},
  title     = {Automated Test Support for Ada PDL},
  booktitle = {Proceedings of the Sixth Washington Ada Symposium on Ada},
  year      = {1989},
  series    = {WADAS '89},
  pages     = {39--45},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {326502},
  doi       = {10.1145/326490.326502},
  location  = {McLean, Virginia, USA},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/326490.326502},
}

@InProceedings{Gligoric2014,
  author    = {Gligoric, Milos and Negara, Stas and Legunsen, Owolabi and Marinov, Darko},
  title     = {An Empirical Evaluation and Comparison of Manual and Automated Test Selection},
  booktitle = {Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
  year      = {2014},
  series    = {ASE '14},
  pages     = {361--372},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2643019},
  doi       = {10.1145/2642937.2643019},
  isbn      = {978-1-4503-3013-8},
  keywords  = {regression testing, software quality, test selection},
  location  = {Vasteras, Sweden},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/2642937.2643019},
}

@InProceedings{Choi2013,
  author    = {Choi, Wontae},
  title     = {Automated Testing of Graphical User Interfaces: A New Algorithm and Challenges},
  booktitle = {Proceedings of the 2013 ACM Workshop on Mobile Development Lifecycle},
  year      = {2013},
  series    = {MobileDeLi '13},
  pages     = {27--28},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2542136},
  doi       = {10.1145/2542128.2542136},
  isbn      = {978-1-4503-2603-2},
  keywords  = {android, automata, gui testing, learning},
  location  = {Indianapolis, Indiana, USA},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/2542128.2542136},
}

@InProceedings{Luo2016,
  author    = {Luo, Qi},
  title     = {Input-sensitive Performance Testing},
  booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  year      = {2016},
  series    = {FSE 2016},
  pages     = {1085--1087},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2983953},
  doi       = {10.1145/2950290.2983953},
  isbn      = {978-1-4503-4218-6},
  keywords  = {Performance testing, change impact analysis, genetic algorithms, machine learning algorithms},
  location  = {Seattle, WA, USA},
  numpages  = {3},
  url       = {http://doi.acm.org/10.1145/2950290.2983953},
}

@InProceedings{Patel2015,
  author    = {Patel, Sachin and Shah, Vipul},
  title     = {Automated Testing of Software-as-a-service Configurations Using a Variability Language},
  booktitle = {Proceedings of the 19th International Conference on Software Product Line},
  year      = {2015},
  series    = {SPLC '15},
  pages     = {253--262},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2791072},
  doi       = {10.1145/2791060.2791072},
  isbn      = {978-1-4503-3613-0},
  keywords  = {enterprise software testing, model based testing, software-as-a-service, test automation, variability specification},
  location  = {Nashville, Tennessee},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2791060.2791072},
}

@InProceedings{Doesinger2012,
  author    = {D\"{o}singer, Stefan and Mordinyi, Richard and Biffl, Stefan},
  title     = {Communicating Continuous Integration Servers for Increasing Effectiveness of Automated Testing},
  booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering},
  year      = {2012},
  series    = {ASE 2012},
  pages     = {374--377},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2351751},
  doi       = {10.1145/2351676.2351751},
  isbn      = {978-1-4503-1204-2},
  keywords  = {Software testing, dependency management, software libraries, software project dependency, test coverage},
  location  = {Essen, Germany},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2351676.2351751},
}

@InProceedings{Zhang2017,
  author    = {Zhang, Li Lyna and Liang, Chieh-Jan Mike and Zhang, Wei and Chen, Enhong},
  title     = {Towards A Contextual and Scalable Automated-testing Service for Mobile Apps},
  booktitle = {Proceedings of the 18th International Workshop on Mobile Computing Systems and Applications},
  year      = {2017},
  series    = {HotMobile '17},
  pages     = {97--102},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3032972},
  doi       = {10.1145/3032970.3032972},
  isbn      = {978-1-4503-4907-9},
  keywords  = {App testing, Contextual Fuzzing, Device labs, Split Execution},
  location  = {Sonoma, CA, USA},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/3032970.3032972},
}

@InProceedings{Schwerdtfeger2009,
  author    = {Schwerdtfeger, Bjorn and Reif, Rupert and Gunthner, Willibald A. and Klinker, Gudrun and Hamacher, Daniel and Schega, Lutz and Bockelmann, Irina and Doil, Fabian and Tumler, Johannes},
  title     = {Pick-by-Vision: A First Stress Test},
  booktitle = {Proceedings of the 2009 8th IEEE International Symposium on Mixed and Augmented Reality},
  year      = {2009},
  series    = {ISMAR '09},
  pages     = {115--124},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {1682317},
  doi       = {10.1109/ISMAR.2009.5336484},
  isbn      = {978-1-4244-5390-0},
  numpages  = {10},
  url       = {http://dx.doi.org/10.1109/ISMAR.2009.5336484},
}

@InProceedings{Deka2017,
  author    = {Deka, Biplab and Huang, Zifeng and Franzen, Chad and Nichols, Jeffrey and Li, Yang and Kumar, Ranjitha},
  title     = {ZIPT: Zero-Integration Performance Testing of Mobile App Designs},
  booktitle = {Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology},
  year      = {2017},
  series    = {UIST '17},
  pages     = {727--736},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3126647},
  doi       = {10.1145/3126594.3126647},
  isbn      = {978-1-4503-4981-9},
  keywords  = {app design, design support tools, zero-integration performance testing},
  location  = {Qu\&\#233;bec City, QC, Canada},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/3126594.3126647},
}

@InProceedings{Luo2016a,
  author    = {Luo, Qi},
  title     = {Automatic Performance Testing Using Input-sensitive Profiling},
  booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  year      = {2016},
  series    = {FSE 2016},
  pages     = {1139--1141},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2983975},
  doi       = {10.1145/2950290.2983975},
  isbn      = {978-1-4503-4218-6},
  keywords  = {Input-sensitive profiling, change impact analysis, genetic algorithms, machine learning algorithms, performance testing},
  location  = {Seattle, WA, USA},
  numpages  = {3},
  url       = {http://doi.acm.org/10.1145/2950290.2983975},
}

@InProceedings{Guo2014a,
  author    = {Guo, Hui and Wang, Zhenjiang and Wu, Chenggang and He, Ruining},
  title     = {EATBit: Effective Automated Test for Binary Translation with High Code Coverage},
  booktitle = {Proceedings of the Conference on Design, Automation \& Test in Europe},
  year      = {2014},
  series    = {DATE '14},
  pages     = {84:1--84:6},
  address   = {3001 Leuven, Belgium, Belgium},
  publisher = {European Design and Automation Association},
  acmid     = {2616710},
  articleno = {84},
  isbn      = {978-3-9815370-2-4},
  location  = {Dresden, Germany},
  numpages  = {6},
  url       = {http://dl.acm.org/citation.cfm?id=2616606.2616710},
}

@Article{Pomeranz2014,
  author     = {Pomeranz, Irith},
  title      = {Low-power Skewed-load Tests Based on Functional Broadside Tests},
  journal    = {ACM Trans. Des. Autom. Electron. Syst.},
  year       = {2014},
  volume     = {19},
  number     = {2},
  pages      = {18:1--18:18},
  month      = mar,
  issn       = {1084-4309},
  acmid      = {2566664},
  address    = {New York, NY, USA},
  articleno  = {18},
  doi        = {10.1145/2566664},
  issue_date = {March 2014},
  keywords   = {Functional broadside tests, low-power test generation, skewed-load tests, switching activity, transition faults},
  numpages   = {18},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/2566664},
}

@InProceedings{Henard2013,
  author    = {Henard, Christopher and Papadakis, Mike and Perrouin, Gilles and Klein, Jacques and Le Traon, Yves},
  title     = {Towards Automated Testing and Fixing of Re-engineered Feature Models},
  booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
  year      = {2013},
  series    = {ICSE '13},
  pages     = {1245--1248},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {2486975},
  isbn      = {978-1-4673-3076-3},
  location  = {San Francisco, CA, USA},
  numpages  = {4},
  url       = {http://dl.acm.org/citation.cfm?id=2486788.2486975},
}

@InProceedings{Burnim2009,
  author    = {Burnim, Jacob and Juvekar, Sudeep and Sen, Koushik},
  title     = {WISE: Automated Test Generation for Worst-case Complexity},
  booktitle = {Proceedings of the 31st International Conference on Software Engineering},
  year      = {2009},
  series    = {ICSE '09},
  pages     = {463--473},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {1555060},
  doi       = {10.1109/ICSE.2009.5070545},
  isbn      = {978-1-4244-3453-4},
  numpages  = {11},
  url       = {http://dx.doi.org/10.1109/ICSE.2009.5070545},
}

@InProceedings{Bures2014,
  author    = {Bures, Miroslav},
  title     = {Automated Testing in the Czech Republic: The Current Situation and Issues},
  booktitle = {Proceedings of the 15th International Conference on Computer Systems and Technologies},
  year      = {2014},
  series    = {CompSysTech '14},
  pages     = {294--301},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2659605},
  doi       = {10.1145/2659532.2659605},
  isbn      = {978-1-4503-2753-4},
  keywords  = {maintenance of test scripts, return of investment, survey, test automation, trend},
  location  = {Ruse, Bulgaria},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2659532.2659605},
}

@Article{Donat2005,
  author     = {Donat, Michael},
  title      = {Orchestrating an Automated Test Lab},
  journal    = {Queue},
  year       = {2005},
  volume     = {3},
  number     = {1},
  pages      = {46--53},
  month      = feb,
  issn       = {1542-7730},
  acmid      = {1046946},
  address    = {New York, NY, USA},
  doi        = {10.1145/1046931.1046946},
  issue_date = {February 2005},
  numpages   = {8},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/1046931.1046946},
}

@InProceedings{Meyers2016,
  author    = {Meyers, Bart and Denil, Joachim and D\'{a}vid, Istv\'{a}n and Vangheluwe, Hans},
  title     = {Automated Testing Support for Reactive Domain-specific Modelling Languages},
  booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering},
  year      = {2016},
  series    = {SLE 2016},
  pages     = {181--194},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2997367},
  doi       = {10.1145/2997364.2997367},
  isbn      = {978-1-4503-4447-0},
  keywords  = {Domain-Specific Modelling, Language Engineering, Verification},
  location  = {Amsterdam, Netherlands},
  numpages  = {14},
  url       = {http://doi.acm.org/10.1145/2997364.2997367},
}

@InProceedings{Kattepur2016,
  author    = {Kattepur, Ajay and Nambiar, Manoj},
  title     = {Service Demand Modeling and Prediction with Single-user Performance Tests},
  booktitle = {Proceedings of the 9th Annual ACM India Conference},
  year      = {2016},
  series    = {COMPUTE '16},
  pages     = {31--41},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2998483},
  doi       = {10.1145/2998476.2998483},
  isbn      = {978-1-4503-4808-9},
  keywords  = {CPU Performance Counters, Mean Value Analysis, Performance Prediction, Principal Component Analysis, Service Demand Modeling},
  location  = {Gandhinagar, India},
  numpages  = {11},
  url       = {http://doi.acm.org/10.1145/2998476.2998483},
}

@InProceedings{Chang2011,
  author    = {Chang, George and Law, Emily and Malhotra, Shan},
  title     = {Demonstration of LMMP Automated Performance Testing Using Cloud Computing Architecture},
  booktitle = {Proceedings of the 2Nd International Workshop on Software Engineering for Cloud Computing},
  year      = {2011},
  series    = {SECLOUD '11},
  pages     = {71--71},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1985515},
  doi       = {10.1145/1985500.1985515},
  isbn      = {978-1-4503-0582-2},
  keywords  = {architecture, cloud computing, jpl, lmmp, nasa, performance, testing},
  location  = {Waikiki, Honolulu, HI, USA},
  numpages  = {1},
  url       = {http://doi.acm.org/10.1145/1985500.1985515},
}

@InProceedings{Karami2016,
  author    = {Karami, Mohammad and Park, Youngsam and McCoy, Damon},
  title     = {Stress Testing the Booters: Understanding and Undermining the Business of DDoS Services},
  booktitle = {Proceedings of the 25th International Conference on World Wide Web},
  year      = {2016},
  series    = {WWW '16},
  pages     = {1033--1043},
  address   = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  acmid     = {2883004},
  doi       = {10.1145/2872427.2883004},
  isbn      = {978-1-4503-4143-1},
  keywords  = {booter, ddos, measurement, paypal},
  location  = {Montr\&\#233;al, Qu\&\#233;bec, Canada},
  numpages  = {11},
  url       = {https://doi.org/10.1145/2872427.2883004},
}

@InProceedings{Gerking2015,
  author    = {Gerking, Christopher and Ladleif, Jan and Sch\"{a}fer, Wilhelm},
  title     = {Model-driven Test Case Design for Model-to-model Semantics Preservation},
  booktitle = {Proceedings of the 6th International Workshop on Automating Test Case Design, Selection and Evaluation},
  year      = {2015},
  series    = {A-TEST 2015},
  pages     = {1--7},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2804323},
  doi       = {10.1145/2804322.2804323},
  isbn      = {978-1-4503-3813-4},
  keywords  = {Model transformation, semantics preservation, test case design},
  location  = {Bergamo, Italy},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2804322.2804323},
}

@InProceedings{Wey2004,
  author    = {Wey, Chin-Long and Khalil, M. A. and Liu, Jim and Wierzba, Gregory},
  title     = {Hierarchical Extreme-voltage Stress Test of Analog CMOS ICs for Gate-oxide Reliability Enhancement},
  booktitle = {Proceedings of the 14th ACM Great Lakes Symposium on VLSI},
  year      = {2004},
  series    = {GLSVLSI '04},
  pages     = {322--327},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {989030},
  doi       = {10.1145/988952.989030},
  isbn      = {1-58113-853-9},
  keywords  = {IC reliability},
  location  = {Boston, MA, USA},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/988952.989030},
}

@InProceedings{Sadowski2014,
  author    = {Sadowski, Caitlin},
  title     = {Usable Program Analysis at Google-scale (Invited Talk Abstract)},
  booktitle = {Proceedings of the 2014 Joint International Workshop on Dynamic Analysis (WODA) and Software and System Performance Testing, Debugging, and Analytics (PERTEA)},
  year      = {2014},
  series    = {WODA+PERTEA 2014},
  pages     = {7--7},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2638829},
  doi       = {10.1145/2632168.2638829},
  isbn      = {978-1-4503-2934-7},
  keywords  = {Program Analysis},
  location  = {San Jose, CA, USA},
  numpages  = {1},
  url       = {http://doi.acm.org/10.1145/2632168.2638829},
}

@Article{Kaushik2014,
  author     = {R, Kaushik and Tauro, Clarence J.M. and Souza, Vishal D. and Bhowmick, Koushik},
  title      = {A Novel Approach for Collaborative Last-mile Performance Testing Implementation Using an Object-oriented Approach},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {2014},
  volume     = {39},
  number     = {2},
  pages      = {1--4},
  month      = mar,
  issn       = {0163-5948},
  acmid      = {2579297},
  address    = {New York, NY, USA},
  doi        = {10.1145/2579281.2579297},
  issue_date = {March 2014},
  keywords   = {last-mile performance testing, load testing, load testing from end user agents},
  numpages   = {4},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/2579281.2579297},
}

@InProceedings{Noetzli2018,
  author    = {N\"{o}tzli, Andres and Khan, Jehandad and Fingerhut, Andy and Barrett, Clark and Athanas, Peter},
  title     = {P4Pktgen: Automated Test Case Generation for P4 Programs},
  booktitle = {Proceedings of the Symposium on SDN Research},
  year      = {2018},
  series    = {SOSR '18},
  pages     = {5:1--5:7},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3185497},
  articleno = {5},
  doi       = {10.1145/3185467.3185497},
  isbn      = {978-1-4503-5664-0},
  location  = {Los Angeles, CA, USA},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/3185467.3185497},
}

@InProceedings{Lamari2007,
  author    = {Lamari, Maher},
  title     = {Towards an Automated Test Generation for the Verification of Model Transformations},
  booktitle = {Proceedings of the 2007 ACM Symposium on Applied Computing},
  year      = {2007},
  series    = {SAC '07},
  pages     = {998--1005},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1244220},
  doi       = {10.1145/1244002.1244220},
  isbn      = {1-59593-480-4},
  keywords  = {MDA (Model Driven Architecture), automated verification, input test models, model transformation, test case generation},
  location  = {Seoul, Korea},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1244002.1244220},
}

@InProceedings{Baluda2015,
  author    = {Baluda, Mauro},
  title     = {EvoSE: Evolutionary Symbolic Execution},
  booktitle = {Proceedings of the 6th International Workshop on Automating Test Case Design, Selection and Evaluation},
  year      = {2015},
  series    = {A-TEST 2015},
  pages     = {16--19},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2804325},
  doi       = {10.1145/2804322.2804325},
  isbn      = {978-1-4503-3813-4},
  keywords  = {Test automation, search-based software testing, symbolic execution},
  location  = {Bergamo, Italy},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2804322.2804325},
}

@Article{Karr2005,
  author     = {Karr, Alan F. and Porter, Adam A.},
  title      = {Distributed Performance Testing Using Statistical Modeling},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {2005},
  volume     = {30},
  number     = {4},
  pages      = {1--7},
  month      = may,
  issn       = {0163-5948},
  acmid      = {1083287},
  address    = {New York, NY, USA},
  doi        = {10.1145/1082983.1083287},
  issue_date = {July 2005},
  keywords   = {distributed continuous quality assurance, statistical modeling},
  numpages   = {7},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/1082983.1083287},
}

@InProceedings{Besson2011,
  author    = {Besson, Felipe M. and Leal, Pedro M.B. and Kon, Fabio and Goldman, Alfredo and Milojicic, Dejan},
  title     = {Towards Automated Testing of Web Service Choreographies},
  booktitle = {Proceedings of the 6th International Workshop on Automation of Software Test},
  year      = {2011},
  series    = {AST '11},
  pages     = {109--110},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1982621},
  doi       = {10.1145/1982595.1982621},
  isbn      = {978-1-4503-0592-1},
  keywords  = {agile methods, choreography testing, web services},
  location  = {Waikiki, Honolulu, HI, USA},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/1982595.1982621},
}

@InProceedings{Keimling2013,
  author    = {Keimling, Ren{\'e} and Hansen, Christian and Bilgic, Attila},
  title     = {A System for Automated Testing in Development of Measuring Devices for Industrial Process Instrumentation},
  booktitle = {Proceedings of the 2013 International Workshop on Joining AcadeMiA and Industry Contributions to Testing Automation},
  year      = {2013},
  series    = {JAMAICA 2013},
  pages     = {65--70},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2489289},
  doi       = {10.1145/2489280.2489289},
  isbn      = {978-1-4503-2161-7},
  keywords  = {Automation, Functional Safety, Integration Testing, Process Industry, SIL, Testing, Verification},
  location  = {Lugano, Switzerland},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/2489280.2489289},
}

@InProceedings{Sun2004,
  author    = {Sun, Yanhong and Jones, Edward L.},
  title     = {Specification-driven Automated Testing of GUI-based Java Programs},
  booktitle = {Proceedings of the 42Nd Annual Southeast Regional Conference},
  year      = {2004},
  series    = {ACM-SE 42},
  pages     = {140--145},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {986570},
  doi       = {10.1145/986537.986570},
  isbn      = {1-58113-870-9},
  keywords  = {test automation, test engine, test specification language},
  location  = {Huntsville, Alabama},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/986537.986570},
}

@InProceedings{Kaehkoenen2012,
  author    = {K\"{a}hk\"{o}nen, Kari and Saarikivi, Olli and Heljanko, Keijo},
  title     = {Using Unfoldings in Automated Testing of Multithreaded Programs},
  booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering},
  year      = {2012},
  series    = {ASE 2012},
  pages     = {150--159},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2351698},
  doi       = {10.1145/2351676.2351698},
  isbn      = {978-1-4503-1204-2},
  keywords  = {Dynamic symbolic execution, unfoldings},
  location  = {Essen, Germany},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2351676.2351698},
}

@InProceedings{Amelot2012,
  author    = {Amelot, Julien and Fletcher, Jeffrey and Li-Baboud, Ya-Shian and Anand, Dhananjay and Vasseur, Clement and Moyne, James},
  title     = {An IEEE 1588 Performance Testing Dashboard for Power Industry Requirements},
  booktitle = {Proceedings of the Workshop on Performance Metrics for Intelligent Systems},
  year      = {2012},
  series    = {PerMIS '12},
  pages     = {216--222},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2393131},
  doi       = {10.1145/2393091.2393131},
  isbn      = {978-1-4503-1126-7},
  keywords  = {IEEE 1588, PMU, conformance testing, test methods, time synchronization},
  location  = {College Park, Maryland},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2393091.2393131},
}

@InProceedings{Korel1996a,
  author    = {Korel, Bogdan},
  title     = {Automated Test Data Generation for Programs with Procedures},
  booktitle = {Proceedings of the 1996 ACM SIGSOFT International Symposium on Software Testing and Analysis},
  year      = {1996},
  series    = {ISSTA '96},
  pages     = {209--215},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {226319},
  doi       = {10.1145/229000.226319},
  isbn      = {0-89791-787-1},
  location  = {San Diego, California, USA},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/229000.226319},
}

@Article{Korel1996b,
  author     = {Korel, Bogdan},
  title      = {Automated Test Data Generation for Programs with Procedures},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {1996},
  volume     = {21},
  number     = {3},
  pages      = {209--215},
  month      = may,
  issn       = {0163-5948},
  acmid      = {226319},
  address    = {New York, NY, USA},
  doi        = {10.1145/226295.226319},
  issue_date = {May 1996},
  numpages   = {7},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/226295.226319},
}

@InProceedings{Liu2014,
  author    = {Liu, Yu David},
  title     = {Improving Energy Efficiency of Work-stealing Parallel Languages (Invited Talk Abstract)},
  booktitle = {Proceedings of the 2014 Joint International Workshop on Dynamic Analysis (WODA) and Software and System Performance Testing, Debugging, and Analytics (PERTEA)},
  year      = {2014},
  series    = {WODA+PERTEA 2014},
  pages     = {14--14},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2638836},
  doi       = {10.1145/2632168.2638836},
  isbn      = {978-1-4503-2934-7},
  keywords  = {Energy Efficiency},
  location  = {San Jose, CA, USA},
  numpages  = {1},
  url       = {http://doi.acm.org/10.1145/2632168.2638836},
}

@InProceedings{Sherry2017,
  author    = {Sherry, Dylan and Schmidt, Michael},
  title     = {Performance Testing of Automated Modeling for Industrial Applications},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
  year      = {2017},
  series    = {GECCO '17},
  pages     = {1605--1612},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3082534},
  doi       = {10.1145/3067695.3082534},
  isbn      = {978-1-4503-4939-0},
  keywords  = {benchmark, case study, genetic programming, machine learning, performance test},
  location  = {Berlin, Germany},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/3067695.3082534},
}

@InProceedings{Stege2017,
  author    = {Stege, Nikolas and Wegener, Christoph and Basse, Tobias and Kunze, Frederik},
  title     = {Mapping Interest Rate Projections Using Neural Networks Under Cointegration: An Application from Stress Testing Approaches},
  booktitle = {Proceedings of the 1st International Conference on Internet of Things and Machine Learning},
  year      = {2017},
  series    = {IML '17},
  pages     = {13:1--13:5},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3109774},
  articleno = {13},
  doi       = {10.1145/3109761.3109774},
  isbn      = {978-1-4503-5243-7},
  keywords  = {artificial neural networks, cointegration, mapping interest rate projections, net interest rate income, risk management},
  location  = {Liverpool, United Kingdom},
  numpages  = {5},
  url       = {http://doi.acm.org/10.1145/3109761.3109774},
}

@InProceedings{Harman2007,
  author    = {Harman, Mark},
  title     = {Automated Test Data Generation Using Search Based Software Engineering},
  booktitle = {Proceedings of the Second International Workshop on Automation of Software Test},
  year      = {2007},
  series    = {AST '07},
  pages     = {2--},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {1270255},
  doi       = {10.1109/AST.2007.4},
  isbn      = {0-7695-2971-2},
  url       = {http://dx.doi.org/10.1109/AST.2007.4},
}

@InProceedings{Blom2003,
  author    = {Blom, Johan and Jonsson, Bengt},
  title     = {Automated Test Generation for Industrial Erlang Applications},
  booktitle = {Proceedings of the 2003 ACM SIGPLAN Workshop on Erlang},
  year      = {2003},
  series    = {ERLANG '03},
  pages     = {8--14},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {940882},
  doi       = {10.1145/940880.940882},
  isbn      = {1-58113-772-9},
  location  = {Uppsala, Sweden},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/940880.940882},
}

@InProceedings{Dunning2011,
  author    = {Dunning, Shaun and Sawyer, Darren},
  title     = {A Little Language for Rapidly Constructing Automated Performance Tests},
  booktitle = {Proceedings of the 2Nd ACM/SPEC International Conference on Performance Engineering},
  year      = {2011},
  series    = {ICPE '11},
  pages     = {371--380},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1958798},
  doi       = {10.1145/1958746.1958798},
  isbn      = {978-1-4503-0519-8},
  location  = {Karlsruhe, Germany},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1958746.1958798},
}

@Article{Boyapati2002,
  author     = {Boyapati, Chandrasekhar and Khurshid, Sarfraz and Marinov, Darko},
  title      = {Korat: Automated Testing Based on Java Predicates},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {2002},
  volume     = {27},
  number     = {4},
  pages      = {123--133},
  month      = jul,
  issn       = {0163-5948},
  acmid      = {566191},
  address    = {New York, NY, USA},
  doi        = {10.1145/566171.566191},
  issue_date = {July 2002},
  numpages   = {11},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/566171.566191},
}

@InProceedings{Boyapati2002a,
  author    = {Boyapati, Chandrasekhar and Khurshid, Sarfraz and Marinov, Darko},
  title     = {Korat: Automated Testing Based on Java Predicates},
  booktitle = {Proceedings of the 2002 ACM SIGSOFT International Symposium on Software Testing and Analysis},
  year      = {2002},
  series    = {ISSTA '02},
  pages     = {123--133},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {566191},
  doi       = {10.1145/566172.566191},
  isbn      = {1-58113-562-9},
  location  = {Roma, Italy},
  numpages  = {11},
  url       = {http://doi.acm.org/10.1145/566172.566191},
}

@Article{Leathrum1994,
  author     = {Leathrum, J. F. and Liburdy, K. A.},
  title      = {Automated Testing of POSIX Standards},
  journal    = {StandardView},
  year       = {1994},
  volume     = {2},
  number     = {1},
  pages      = {55--59},
  month      = mar,
  issn       = {1067-9936},
  acmid      = {224154},
  address    = {New York, NY, USA},
  doi        = {10.1145/224145.224154},
  issue_date = {March 1994},
  numpages   = {5},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/224145.224154},
}

@Article{Buy2000,
  author     = {Buy, Ugo and Orso, Alessandro and Pezze, Mauro},
  title      = {Automated Testing of Classes},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {2000},
  volume     = {25},
  number     = {5},
  pages      = {39--48},
  month      = aug,
  issn       = {0163-5948},
  acmid      = {348870},
  address    = {New York, NY, USA},
  doi        = {10.1145/347636.348870},
  issue_date = {Sept. 2000},
  keywords   = {class testing, data flow analysis, symbolic execution, testing and analysis, testing object-oriented software},
  numpages   = {10},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/347636.348870},
}

@InProceedings{Buy2000a,
  author    = {Buy, Ugo and Orso, Alessandro and Pezze, Mauro},
  title     = {Automated Testing of Classes},
  booktitle = {Proceedings of the 2000 ACM SIGSOFT International Symposium on Software Testing and Analysis},
  year      = {2000},
  series    = {ISSTA '00},
  pages     = {39--48},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {348870},
  doi       = {10.1145/347324.348870},
  isbn      = {1-58113-266-2},
  keywords  = {class testing, data flow analysis, symbolic execution, testing and analysis, testing object-oriented software},
  location  = {Portland, Oregon, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/347324.348870},
}

@InProceedings{Aguirre2017,
  author    = {Aguirre, Nazareno},
  title     = {Efficient SAT-based Software Analysis: From Automated Testing to Automated Verification and Repair},
  booktitle = {Proceedings of the 5th International FME Workshop on Formal Methods in Software Engineering},
  year      = {2017},
  series    = {FormaliSE '17},
  pages     = {2--2},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {3101292},
  doi       = {10.1109/FormaliSE.2017..21},
  isbn      = {978-1-5386-0422-9},
  location  = {Buenos Aires, Argentina},
  numpages  = {1},
  url       = {https://doi.org/10.1109/FormaliSE.2017..21},
}

@InProceedings{Tendulkar2011,
  author    = {Tendulkar, D. M. and Phalak, C.},
  title     = {Proactive Performance Testing Using SQL Performance Assurance Services (SQL-PASS)},
  booktitle = {Proceedings of the International Conference \&\#38; Workshop on Emerging Trends in Technology},
  year      = {2011},
  series    = {ICWET '11},
  pages     = {541--547},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1980138},
  doi       = {10.1145/1980022.1980138},
  isbn      = {978-1-4503-0449-8},
  keywords  = {SQL performance, database emulation, database statistics, explain plan, extrapolation of database statistics, query execution time forecasting, query optimization},
  location  = {Mumbai, Maharashtra, India},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/1980022.1980138},
}

@InProceedings{Marinov2008,
  author    = {Marinov, Darko and Schulte, Wolfram},
  title     = {Workshop on State-space Exploration for Automated Testing (SSEAT 2008)},
  booktitle = {Proceedings of the 2008 International Symposium on Software Testing and Analysis},
  year      = {2008},
  series    = {ISSTA '08},
  pages     = {315--316},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1390672},
  doi       = {10.1145/1390630.1390672},
  isbn      = {978-1-60558-050-0},
  keywords  = {automated testing, constraint solving, genetic algorithms, model checking, random exploration, state-space exploration, symbolic execution},
  location  = {Seattle, WA, USA},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/1390630.1390672},
}

@InProceedings{Zhou2013,
  author    = {Zhou, Junzan and Li, Shanping and Zhang, Zhen and Ye, Zhen},
  title     = {Position Paper: Cloud-based Performance Testing: Issues and Challenges},
  booktitle = {Proceedings of the 2013 International Workshop on Hot Topics in Cloud Services},
  year      = {2013},
  series    = {HotTopiCS '13},
  pages     = {55--62},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2462321},
  doi       = {10.1145/2462307.2462321},
  isbn      = {978-1-4503-2051-1},
  keywords  = {challenge, cloud, load testing, overview, performance testing},
  location  = {Prague, Czech Republic},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2462307.2462321},
}

@InProceedings{Vu2015,
  author    = {Vu, Thi--Dao and Hung, Pham Ngoc and Nguyen, Viet-Ha},
  title     = {A Method for Automated Test Data Generation from Sequence Diagrams and Object Constraint Language},
  booktitle = {Proceedings of the Sixth International Symposium on Information and Communication Technology},
  year      = {2015},
  series    = {SoICT 2015},
  pages     = {335--341},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2833294},
  doi       = {10.1145/2833258.2833294},
  isbn      = {978-1-4503-3843-1},
  keywords  = {Class diagram, Model based Testing, Object Constraint Language, Sequence diagram, Test Data Generation, Test Scenario},
  location  = {Hue City, Viet Nam},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2833258.2833294},
}

@Article{Zhang2016a,
  author     = {Zhang, Yunqi and Meisner, David and Mars, Jason and Tang, Lingjia},
  title      = {Treadmill: Attributing the Source of Tail Latency Through Precise Load Testing and Statistical Inference},
  journal    = {SIGARCH Comput. Archit. News},
  year       = {2016},
  volume     = {44},
  number     = {3},
  pages      = {456--468},
  month      = jun,
  issn       = {0163-5964},
  acmid      = {3001186},
  address    = {New York, NY, USA},
  doi        = {10.1145/3007787.3001186},
  issue_date = {June 2016},
  keywords   = {data center, load testing, tail latency},
  numpages   = {13},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/3007787.3001186},
}

@InProceedings{Zhang2016b,
  author    = {Zhang, Yunqi and Meisner, David and Mars, Jason and Tang, Lingjia},
  title     = {Treadmill: Attributing the Source of Tail Latency Through Precise Load Testing and Statistical Inference},
  booktitle = {Proceedings of the 43rd International Symposium on Computer Architecture},
  year      = {2016},
  series    = {ISCA '16},
  pages     = {456--468},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {3001186},
  doi       = {10.1109/ISCA.2016.47},
  isbn      = {978-1-4673-8947-1},
  keywords  = {data center, load testing, tail latency},
  location  = {Seoul, Republic of Korea},
  numpages  = {13},
  url       = {https://doi.org/10.1109/ISCA.2016.47},
}

@InProceedings{Holmes2016,
  author    = {Holmes, Josie and Groce, Alex and Alipour, Mohammad Amin},
  title     = {Mitigating (and Exploiting) Test Reduction Slippage},
  booktitle = {Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation},
  year      = {2016},
  series    = {A-TEST 2016},
  pages     = {66--69},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2994301},
  doi       = {10.1145/2994291.2994301},
  isbn      = {978-1-4503-4401-2},
  keywords  = {delta debugging. slippage, test manipulation and reduction},
  location  = {Seattle, WA, USA},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2994291.2994301},
}

@InProceedings{Hodovan2016,
  author    = {Hodov\'{a}n, Ren\'{a}ta and Kiss, \'{A}kos},
  title     = {Modernizing Hierarchical Delta Debugging},
  booktitle = {Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation},
  year      = {2016},
  series    = {A-TEST 2016},
  pages     = {31--37},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2994296},
  doi       = {10.1145/2994291.2994296},
  isbn      = {978-1-4503-4401-2},
  keywords  = {Extended Context-free Grammars, Hierarchical Delta Debugging, Parallel},
  location  = {Seattle, WA, USA},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/2994291.2994296},
}

@Article{Donaldson2017,
  author     = {Donaldson, Alastair F. and Evrard, Hugues and Lascu, Andrei and Thomson, Paul},
  title      = {Automated Testing of Graphics Shader Compilers},
  journal    = {Proc. ACM Program. Lang.},
  year       = {2017},
  volume     = {1},
  number     = {OOPSLA},
  pages      = {93:1--93:29},
  month      = oct,
  issn       = {2475-1421},
  acmid      = {3133917},
  address    = {New York, NY, USA},
  articleno  = {93},
  doi        = {10.1145/3133917},
  issue_date = {October 2017},
  keywords   = {GLSL, GPUs, OpenGL, compilers, shaders, testing},
  numpages   = {29},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/3133917},
}

@InProceedings{Boehme2014,
  author    = {B\"{o}hme, Marcel and Paul, Soumya},
  title     = {On the Efficiency of Automated Testing},
  booktitle = {Proceedings of the 22Nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  year      = {2014},
  series    = {FSE 2014},
  pages     = {632--642},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2635923},
  doi       = {10.1145/2635868.2635923},
  isbn      = {978-1-4503-3056-5},
  keywords  = {Efficient Testing, Error-based Partitioning, Partition Testing, Random Testing, Testing Theory},
  location  = {Hong Kong, China},
  numpages  = {11},
  url       = {http://doi.acm.org/10.1145/2635868.2635923},
}

@InProceedings{Dimitrov2013,
  author    = {Dimitrov, Stanislav and Stoilov, Todor},
  title     = {Loading Test of Apache HTTP Server by Video File and Usage Measurements of the Hardware Components},
  booktitle = {Proceedings of the 14th International Conference on Computer Systems and Technologies},
  year      = {2013},
  series    = {CompSysTech '13},
  pages     = {59--66},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2516799},
  doi       = {10.1145/2516775.2516799},
  isbn      = {978-1-4503-2021-4},
  keywords  = {Apache HTTP server, ApacheBench, mod_deflate, sar},
  location  = {Ruse, Bulgaria},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2516775.2516799},
}

@Article{Sayre2005,
  author     = {Sayre, Kirk},
  title      = {Usage Model-based Automated Testing of C++ Templates},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {2005},
  volume     = {30},
  number     = {4},
  pages      = {1--5},
  month      = may,
  issn       = {0163-5948},
  acmid      = {1083277},
  address    = {New York, NY, USA},
  doi        = {10.1145/1082983.1083277},
  issue_date = {July 2005},
  numpages   = {5},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/1082983.1083277},
}

@InProceedings{Raasveldt2018,
  author    = {Raasveldt, Mark and Holanda, Pedro and Gubner, Tim and M\"{u}hleisen, Hannes},
  title     = {Fair Benchmarking Considered Difficult: Common Pitfalls In Database Performance Testing},
  booktitle = {Proceedings of the Workshop on Testing Database Systems},
  year      = {2018},
  series    = {DBTest'18},
  pages     = {2:1--2:6},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3209955},
  articleno = {2},
  doi       = {10.1145/3209950.3209955},
  isbn      = {978-1-4503-5826-2},
  keywords  = {Benchmarking, Performance Evaluation},
  location  = {Houston, TX, USA},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/3209950.3209955},
}

@InProceedings{Bulej2016,
  author    = {Bulej, Lubom\'{\i}r},
  title     = {Performance Testing in Software Development: Getting the Developers on Board},
  booktitle = {Companion Publication for ACM/SPEC on International Conference on Performance Engineering},
  year      = {2016},
  series    = {ICPE '16 Companion},
  pages     = {9--9},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2880448},
  doi       = {10.1145/2859889.2880448},
  isbn      = {978-1-4503-4147-9},
  keywords  = {performance awareness, performance regression testing, performance unit testing},
  location  = {Delft, The Netherlands},
  numpages  = {1},
  url       = {http://doi.acm.org/10.1145/2859889.2880448},
}

@Article{Dunning2011b,
  author     = {Dunning, Shaun and Sawyer, Darren},
  title      = {A Little Language for Rapidly Constructing Automated Performance Tests (Abstracts Only)},
  journal    = {SIGMETRICS Perform. Eval. Rev.},
  year       = {2011},
  volume     = {39},
  number     = {3},
  pages      = {19--19},
  month      = dec,
  issn       = {0163-5999},
  acmid      = {2160843},
  address    = {New York, NY, USA},
  doi        = {10.1145/2160803.2160843},
  issue_date = {December 2011},
  numpages   = {1},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/2160803.2160843},
}

@InProceedings{Teixeira2008,
  author    = {Teixeira, Cl\'{a}udio and Pinto, Joaquim Sousa and Martins, Joaquim Arnaldo},
  title     = {UNIMARC-XML Performance Testing},
  booktitle = {Proceedings of the 2008 Euro American Conference on Telematics and Information Systems},
  year      = {2008},
  series    = {EATIS '08},
  pages     = {31:1--31:4},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1621118},
  articleno = {31},
  doi       = {10.1145/1621087.1621118},
  isbn      = {978-1-59593-988-3},
  keywords  = {XML query performance, XML search and indexing, XML storage},
  location  = {Aracaju, Brazil},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/1621087.1621118},
}

@InProceedings{Reichelt2018,
  author    = {Reichelt, David Georg and K\"{u}hne, Stefan},
  title     = {Better Early Than Never: Performance Test Acceleration by Regression Test Selection},
  booktitle = {Companion of the 2018 ACM/SPEC International Conference on Performance Engineering},
  year      = {2018},
  series    = {ICPE '18},
  pages     = {127--130},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3186289},
  doi       = {10.1145/3185768.3186289},
  isbn      = {978-1-4503-5629-9},
  keywords  = {benchmarking, performance testing, regression test selection},
  location  = {Berlin, Germany},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/3185768.3186289},
}

@InProceedings{Brglez2007,
  author    = {Brglez, Franc and Osborne, Jason A.},
  title     = {Performance Testing of Combinatorial Solvers with Isomorph Class Instances},
  booktitle = {Proceedings of the 2007 Workshop on Experimental Computer Science},
  year      = {2007},
  series    = {ExpCS '07},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1281713},
  articleno = {13},
  doi       = {10.1145/1281700.1281713},
  isbn      = {978-1-59593-751-3},
  keywords  = {scientific method},
  location  = {San Diego, California},
  url       = {http://doi.acm.org/10.1145/1281700.1281713},
}

@InProceedings{Bernardino2016,
  author    = {Bernardino, Maicon and Rodrigues, Elder M. and Zorzo, Avelino F.},
  title     = {Performance Testing Modeling: An Empirical Evaluation of DSL and UML-based Approaches},
  booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
  year      = {2016},
  series    = {SAC '16},
  pages     = {1660--1665},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2851832},
  doi       = {10.1145/2851613.2851832},
  isbn      = {978-1-4503-3739-7},
  keywords  = {domain-specific language, experiment, performance testing},
  location  = {Pisa, Italy},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/2851613.2851832},
}

@InProceedings{Arya2011,
  author    = {Arya, Deepak and Jawahar, C. V. and Bhagvati, Chakravorty and Patnaik, Tushar and Chaudhuri, B. B. and Lehal, G. S. and Chaudhury, Santanu and Ramakrishna, A. G.},
  title     = {Experiences of Integration and Performance Testing of Multilingual OCR for Printed Indian Scripts},
  booktitle = {Proceedings of the 2011 Joint Workshop on Multilingual OCR and Analytics for Noisy Unstructured Text Data},
  year      = {2011},
  series    = {MOCR_AND '11},
  pages     = {9:1--9:8},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2034628},
  articleno = {9},
  doi       = {10.1145/2034617.2034628},
  isbn      = {978-1-4503-0685-0},
  keywords  = {feature extraction, hierarchical classification, multilingual, shape analysis, template matching},
  location  = {Beijing, China},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2034617.2034628},
}

@Article{Ural1984,
  author     = {Ural, H. and Probert, R. L.},
  title      = {Automated Testing of Protocol Specifications and Their Implementations},
  journal    = {SIGCOMM Comput. Commun. Rev.},
  year       = {1984},
  volume     = {14},
  number     = {2},
  pages      = {149--155},
  month      = jun,
  issn       = {0146-4833},
  acmid      = {802072},
  address    = {New York, NY, USA},
  doi        = {10.1145/639624.802072},
  issue_date = {June 1984},
  numpages   = {7},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/639624.802072},
}

@InProceedings{Ural1984a,
  author    = {Ural, H. and Probert, R. L.},
  title     = {Automated Testing of Protocol Specifications and Their Implementations},
  booktitle = {Proceedings of the ACM SIGCOMM Symposium on Communications Architectures and Protocols: Tutorials \&Amp; Symposium},
  year      = {1984},
  series    = {SIGCOMM '84},
  pages     = {149--155},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {802072},
  doi       = {10.1145/800056.802072},
  isbn      = {0-89791-136-9},
  location  = {Montr\&eacute;al, Quebec, Canada, USA},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/800056.802072},
}

@InProceedings{Simon2000,
  author    = {Simon, C. and Summons, Peter},
  title     = {Automated Testing of Databases and Spreadsheets - the Long and the Short of It},
  booktitle = {Proceedings of the Australasian Conference on Computing Education},
  year      = {2000},
  series    = {ACSE '00},
  pages     = {215--219},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {359402},
  doi       = {10.1145/359369.359402},
  isbn      = {1-58113-271-9},
  location  = {Melbourne, Australia},
  numpages  = {5},
  url       = {http://doi.acm.org/10.1145/359369.359402},
}

@Article{Qureshi2016,
  author     = {Qureshi, Mubashir Adnan and Mahimkar, Ajay and Qiu, Lili and Ge, Zihui and Puthenpura, Sarat and Mir, Nabeel and Ahuja, Sanjeev},
  title      = {Automated Test Location Selection For Cellular Network Upgrades},
  journal    = {SIGMETRICS Perform. Eval. Rev.},
  year       = {2016},
  volume     = {44},
  number     = {1},
  pages      = {371--372},
  month      = jun,
  issn       = {0163-5999},
  acmid      = {2901505},
  address    = {New York, NY, USA},
  doi        = {10.1145/2964791.2901505},
  issue_date = {June 2016},
  keywords   = {cellular network, diagnosis, test planning},
  numpages   = {2},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/2964791.2901505},
}

@InProceedings{Qureshi2016a,
  author    = {Qureshi, Mubashir Adnan and Mahimkar, Ajay and Qiu, Lili and Ge, Zihui and Puthenpura, Sarat and Mir, Nabeel and Ahuja, Sanjeev},
  title     = {Automated Test Location Selection For Cellular Network Upgrades},
  booktitle = {Proceedings of the 2016 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Science},
  year      = {2016},
  series    = {SIGMETRICS '16},
  pages     = {371--372},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2901505},
  doi       = {10.1145/2896377.2901505},
  isbn      = {978-1-4503-4266-7},
  keywords  = {cellular network, diagnosis, test planning},
  location  = {Antibes Juan-les-Pins, France},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/2896377.2901505},
}

@InProceedings{Alexander1953,
  author    = {Alexander, S. N. and Elbourn, R. D.},
  title     = {Computer Performance Tests Employed by the National Bureau of Standards},
  booktitle = {Papers and Discussions Presented at the Dec. 8-10, 1953, Eastern Joint AIEE-IRE Computer Conference: Information Processing Systems---reliability and Requirements},
  year      = {1953},
  series    = {AIEE-IRE '53 (Eastern)},
  pages     = {58--61},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1434893},
  doi       = {10.1145/1434878.1434893},
  location  = {Washington, D.C.},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/1434878.1434893},
}

@InProceedings{Sakamoto2002,
  author    = {Sakamoto, M. and Brisson, L. and Katsuno, A. and Inoue, A. and Kimura, Y.},
  title     = {Reverse Tracer: A software tool for generating realistic performance test programs},
  year      = {2002},
  volume    = {2002-January},
  pages     = {81 - 91},
  address   = {Cambridge, MA, United states},
  note      = {Accurate performance;Application codes;Cycle accurate;High performance processors;Logic simulations;Performance characteristics;Performance tests;Software performance models;},
  abstract  = {During the development of high-performance processors, software performance models are used to obtain performance estimates. These models are not cycle-accurate, so their results can have significant errors, leading to performance surprises after the hardware is built. Some performance tests can run directly on the logic simulators, to get more accurate results, but those simulators cannot run large interactive workloads with I/O and much operating system code. So the accurate performance estimates from logic simulators are only available for application code, and are not adequate for the evaluation of powerful server systems that are primarily intended to run large interactive workloads. We discuss a software tool system, the "Reverse Tracer", that generates executable performance tests from an instruction trace of the workload. The generated performance tests retain the essential performance characteristics of multi-user I/O-intensive workloads without doing any real I/O, so they can run in logic simulation to measure performance accurately before the hardware is built.<br/> &copy; 2002 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {15300897},
  journal   = {Proceedings - International Symposium on High-Performance Computer Architecture},
  key       = {Software testing},
  keywords  = {Computer aided software engineering;Computer architecture;Computer circuits;Embedded systems;Hardware;Simulators;Supercomputers;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/HPCA.2002.995700},
}

@InProceedings{Jo2010,
  author    = {Jo, Hyun-Jeong and Hwang, Jong-Gyu and Lee, Kang-Mi},
  title     = {Proposal of automated performance testing tool for vital software in train control system},
  year      = {2010},
  pages     = {1151 - 1155},
  note      = {Automated tools;Computer technology;Electronic hardwares;International standards;Performance testing;Safety assurance;Software safety;Train control systems;},
  abstract  = {In accordance with the development of recent computer technology, the dependency of train control system on the computer software is being increased further, and accordingly, the testing for the safety and reliability of train control system software became more important. Hence, the safety assurance of the vital software running on the train control system is very critical task and yet, not many works have been done. While much efforts have been reported to improve electronic hardware's safety, not so much systematic approaches to evaluate software's safety. In this paper, we suggested an automated tool for performance testing in train control system, and presented its result of implementation. The testing items in the implemented tool had referred to the international standards in relation to the software for train control system, such as IEC 61508 and IEC 62279. In these international standards, 'performance testing' for train control system S/W has to be recommended highly. &copy;ICROS.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {ICCAS 2010 - International Conference on Control, Automation and Systems},
  key       = {Computer control systems},
  keywords  = {Automation;Computer control;Computer software selection and evaluation;Safety testing;Software reliability;Software testing;Vehicle performance;},
  language  = {English},
}

@InProceedings{Gojare2015,
  author    = {Gojare, Satish and Joshi, Rahul and Gaigaware, Dhanashree},
  title     = {Analysis and design of selenium webdriver automation testing framework},
  year      = {2015},
  volume    = {50},
  pages     = {341 - 346},
  address   = {Chennai, India},
  note      = {Automation testing;Automation tools;Human intervention;Software systems;Test reports;Test suites;WEB application;Web-based applications;},
  abstract  = {Nowadays, number of software system has been implemented as web-based applications. These web applications are very complex. It is very difficult to test such complex web applications. Automation testing uses automation tools to reduce human intervention and repeatable tasks. In this paper we have designed and implemented automation testing framework for testing web applications. This new automation testing framework has been implemented using selenium WebDriver tool. Using this framework tester can easily write their test cases efficiently and in less time. Tester need not to study the selenium webdriver tool in detail. This framework is helpful to developer to analyze their code due to screen shot property of framework. This framework produces the customized test report to tester. It is very easy to maintain and repair the test suite for new release of the application using this framework.<br/> &copy; 2015 The Authors. Published by Elsevier B.V.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {18770509},
  journal   = {Procedia Computer Science},
  key       = {Big data},
  keywords  = {Application programs;Automation;Selenium;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.procs.2015.04.038},
}

@InProceedings{Chunye2017,
  author    = {Chunye, Du and Wei, Song and Jianhua, Wu},
  title     = {Based on the analysis of mobile terminal application software performance test},
  year      = {2017},
  pages     = {391 - 394},
  address   = {Kanazawa, Japan},
  note      = {Loadrunner;Mobile applications;Mobile terminal;Performance tests;Test method;Test technology;},
  abstract  = {With the rapid development of mobile terminal, mobile applications are gradually penetrated into all aspects of people's life and work. Mobile games, mobile streaming media, location services, mobile Internet news, instant messaging, mobile music and other rich and colorful information era are changing the social life. In view of this, we propose the application software performance test based on the mobile terminal, and analyze the performance test technology and method of the mobile application. Experimental results show that the performance test of the application system can predict the pressure in real environment, the system will be applied in the problems exposed, through the analysis of the data of the test, it will provide help for performance optimization of application system. &copy; 2017 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing, SNPD 2017},
  key       = {Application programs},
  keywords  = {Artificial intelligence;Computer software;Computer terminals;Media streaming;Mobile computing;Mobile phones;Mobile telecommunication systems;Software engineering;Software testing;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/SNPD.2017.8022751},
}

@InProceedings{Underbrink2012,
  author    = {Underbrink, Al and Potter, Andrew and Jaenisch, Holger and Reifer, Donald J.},
  title     = {Application stress testing: Achieving cyber security by testing cyber attacks},
  year      = {2012},
  pages     = {556 - 561},
  address   = {Waltham, MA, United states},
  note      = {Application testing;attack;Attack model;Attack vector;Commercial enterprise;Critical software;Cyber security;Cyber-attacks;Failure conditions;Network penetration testing;Normal behavior;Operating condition;Operational modes;Penetration testing;Protected networks;Quality of softwares;Risk reductions;Software applications;Software assurance;Software development life cycle;Software prototypes;Software Quality;Software systems;Stress Testing;System developers;System under test;},
  abstract  = {Application stress testing applies the concept of computer network penetration testing to software applications. Since software applications may be attacked - from inside or outside a protected network boundary - they are threatened by actions and conditions which cause delays, disruptions, or failures. Stress testing exposes software systems to simulated cyber attacks, revealing potential weaknesses and vulnerabilities in their implementation. By using such testing, these internal weaknesses and vulnerabilities can be discovered earlier in the software development life cycle, corrected prior to deployment, and lead to improved software quality. Application stress testing is a process and software prototype for verifying the quality of software applications under severe operating conditions. Since stress testing is rarely - if at all - performed today, the possibility of deploying critical software systems that have been stress tested provides a much stronger indication of their ability to withstand cyber attacks. Many possible attack vectors against critical software can be verified as true threats and mitigated prior to deployment. This improves software quality and serves as a tremendous risk reduction for critical software systems used in government and commercial enterprises. The software prototype models and verifies failure conditions of a system under test (SUT). The SUT is first executed in a virtual environment and its normal operational modes are observed. A normal behavior model is generated in order to predict failure conditions based on attack models and external SUT interfaces. Using off-the-shelf software tools, the predictions are verified in the virtual environment by stressing the executing SUT with attacks against the SUT. Results are presented to testers and system developers for dispensation or mitigation. &copy; 2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {2012 IEEE International Conference on Technologies for Homeland Security, HST 2012},
  key       = {Software testing},
  keywords  = {Ability testing;Application programs;Computer software selection and evaluation;Crime;National security;Security systems;Software design;Software prototyping;Virtual reality;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/THS.2012.6459909},
}

@InProceedings{Xie2016,
  author    = {Xie, Xianjie and Yang, Zhijun and Yu, Jiankun and Zhang, Weifeng},
  title     = {Design and implementation of bank financial business automation testing framework based on QTP},
  year      = {2016},
  pages     = {143 - 147},
  address   = {Changchun, China},
  note      = {Automated testing tools;Business automation;Design and implementations;Operational efficiencies;Secondary development;Software automation;Software technology;Test automation frameworks;},
  abstract  = {The current software testing in the aspects of industrial benefits gradually causes the attention of the domestic financial bank. The innovation of software technology, the increase of software scale and the shortened developing period make the traditional manual testing meeting enormous challenges, while the development of automated testing technology has promoted the progress of the software testing industry. Because of the particularity of financial and banking services, the bank is under an obligation to ensure the quality and reliability of software. Therefore it's vital to test the software. In specific practice, although the powerful third-party testing tools can be used as a solution, it is hard to rely on certain tool to implement automated testing, hence a framework of automated test is required to be introduced for testing, which intends to handle high efficiency and high-quality testing for software automation. This paper proposes a kind of software automation testing framework based on QTP, mainly targeting on the core of the bank, credit, online banking to test the function of the three major operations. The framework is a secondary development based on QTP and mainly for regression testing of software, which integrates techniques including object recognition, data-driven, and keyword-driven technology, checkpoint technology, to proceed business-level testing. The paper expatiated on four issues, which were the test system design, the test standardization, the testing framework design and the testing of the implementation. The practical application shows that the framework can improve the operational efficiency, reduce the test cost, and guarantee the smooth progress of the software automation testing.<br/> &copy; 2016 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of 2016 5th International Conference on Computer Science and Network Technology, ICCSNT 2016},
  key       = {Software testing},
  keywords  = {Application programs;Automation;Computer networks;Computer software;Efficiency;Finance;Object recognition;Software engineering;Software reliability;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICCSNT.2016.8070136},
}

@InProceedings{Hadfield1990,
  author    = {Hadfield, J.A.},
  title     = {Development of an economical, software-controlled battery load testing system},
  year      = {1990},
  pages     = {553 - 555},
  address   = {Orlando, FL, USA},
  note      = {Battery Discharges;Battery Loads;Battery Strings;},
  abstract  = {Battery discharge capacity tests have traditionally been performed manually, although several mechanized systems are commercially available. A need was identified at the Manitoba Telephone System (MTS) to accurately and economically load test batteries in the field, to verify the capacity of new installations as well as to assist determining the true end-of-life of existing strings. The development of an economical, software-controlled system for testing -48-volt battery strings in the telephone environment is discussed.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {02750473},
  journal   = {INTELEC, International Telecommunications Energy Conference (Proceedings)},
  key       = {Electric Batteries},
  keywords  = {Computer Software;Electric Discharges;Telephone Systems;},
  language  = {English},
}

@InProceedings{Saba2006,
  author    = {Saba, Hugo and De Freitas Jorge, Eduardo Manuel and Costa, Victor Franco and De Barros Pereira, Hernane Borges},
  title     = {Webteste: A stress test tool},
  year      = {2006},
  volume    = {IT/WIA},
  pages     = {246 - 249},
  address   = {Setubal, Portugal},
  note      = {Engineering perspective;Robust software;Stress test;Stress test tools;WEB application;Web servers;Web system;WebTeste;},
  abstract  = {The usage of web applications has became a very common activity in the organizations' scope. From the software engineering perspective, the incessant search for production of more robust softwares, with better quality, is a continuous requirement. The main purpose of this paper is to present the WebTeste, which is a test tool used to verify the robustness of a web application. After comparison of several simulation's results, the use of distributed and ordered computers suggests more reliable tests. In addition, the analysis of the obtained results can suggest a new (re)design of a web system. The WebTeste could be used to perform stress test in order to verify the robustness of a web application more precisely. &copy; 2010.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {WEBIST 2006 - 2nd International Conference on Web Information Systems and Technologies, Proceedings},
  key       = {Web crawler},
  keywords  = {Information systems;Software engineering;Testing;},
  language  = {English},
}

@InProceedings{Ramasamy2015,
  author    = {Ramasamy, Gobi and Ramalingam, Sathishkumar},
  title     = {An effective automation testing framework for OATS tool},
  year      = {2015},
  volume    = {324},
  pages     = {543 - 550},
  address   = {Kumaracoil, India},
  note      = {Automation tests;Ez2Auto;OATS;Open script;Test suites;},
  abstract  = {Oracle application test suite (OATS) is a test tool of Oracle. It is a very good integrated testing tool for Web applications, Web services, Oracle applications, and Oracle databases. The Oracle application testing suite is part of the Oracle Enterprise Manager product family and comprises the following tightly integrated products. They are Oracle load testing for scalability, performance and load testing, Oracle functional testing for automated functional and regression testing, and Oracle Test Manager for test process management, including test requirements management, test management, test execution, and defect tracking. OATS uses OpenScript platform. This paper discusses model-based test automation methods and tools referred to collectively as the Test Automation Framework that reduces the time and resources necessary to develop high-quality and high-assurance systems using OATS functional testing tool. Framework is named as Easy to Automate (Ez2Auto) framework. This OATS tool is newly available in market, and there is no established framework available in literature or ready to use in market.<br/> &copy; Springer India 2015.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {21945357},
  journal   = {Advances in Intelligent Systems and Computing},
  key       = {Load testing},
  keywords  = {Artificial intelligence;Automation;Commerce;Evolutionary algorithms;Managers;Model checking;Software testing;Web services;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-81-322-2126-5_59},
}

@InProceedings{Netto2011,
  author    = {Netto, Marco A.S. and Menon, Suzane and Vieira, Hugo V. and Costa, Leandro T. and De Oliveira, Flavio M. and Saad, Rodrigo and Zorzo, Avelino},
  title     = {Evaluating load generation in virtualized environments for software performance testing},
  year      = {2011},
  pages     = {993 - 1000},
  address   = {Anchorage, AK, United states},
  note      = {Computing environments;Computing infrastructures;Loadrunner;Multicore architectures;Performance isolations;Performance testing;Software performance testing;Virtualized environment;},
  abstract  = {Before placing a software system into production, it is necessary to guarantee it provides users with a certain level of Quality-of-Service. Intensive performance testing is then necessary to achieve such a level and the tests require an isolated computing environment. Virtualization can therefore play an important role for saving energy costs by reducing the number of servers required to run performance tests and for allowing performance isolation when executing multiple tests in the same computing infrastructure. Load generation is an important component in performance testing as it simulates users interacting with the target application. This paper presents our experience in using a virtualized environment for load generation aimed at performance testing. We measured several performance metrics and varied system load, number of virtual machines per physical resource, and the CPU pinning schema for comparison of virtual and physical machines. The two main findings from our experiments are that physical machines produced steadier and faster response times under heavy load and that the pinning schema is an important aspect when setting up a virtualized environment for load generation. &copy; 2011 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum},
  key       = {Software testing},
  keywords  = {Computer architecture;Load testing;Quality of service;Virtual reality;Virtualization;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/IPDPS.2011.244},
}

@Article{Grossman1996,
  author    = {Grossman, David and McCabe, M.Catherine and Staton, Christopher and Bailey, Bret and Frieder, Ophir and Roberts, David C.},
  title     = {Performance testing a large finance application},
  journal   = {IEEE Software},
  year      = {1996},
  volume    = {13},
  number    = {5},
  pages     = {50 - 54},
  issn      = {07407459},
  note      = {Software package Federal financial system;Software package Teleprocessing network simulator;},
  abstract  = {American Management System's Federal Financial System, a financial accounting application, was applied in a Customer Information Control System DB2 environment running on a large IBM mainframe. A test tool, TPNS (Teleprocessing Network Simulator), was used to verify if the software's performance is within acceptable standards. Detailed tuning was made after the development of the initial prototype. The test produced a fair approximation of the actual performance during the first two years of operation.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Computer software selection and evaluation},
  keywords  = {Computer aided software engineering;Computer operating systems;Computer simulation;Database systems;Financial data processing;Response time (computer systems);},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/52.536458},
}

@InProceedings{Cai2004,
  author    = {Cai, Yuhong and Grundy, John and Hosking, John},
  title     = {Experiences integrating and scaling a performance test bed generator with an open source CASE tool},
  year      = {2004},
  pages     = {36 - 45},
  address   = {Linz, Austria},
  note      = {Architectural analysis;Experience report;Software performance testing;Software tool extension;},
  abstract  = {We report on our experiences developing a performance test-bed generator for industrial usage by extending an open-source UML CASE tool. This tool generates client and server code, database configuration and deployment scripts from a high-level software architecture description. It automates the code generation, compilation, deployment and performance metric result collection processes. We identify a range of problems that arose from our previous research on performance test-bed generation that needed to be addressed to scale this automated software engineering technique. We describe a range of approaches we used to solve these problems in our new tool. We then report on industrial deployment and evaluation of our new tool and discuss the effectiveness of these solutions. &copy; 2004 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - 19th International Conference on Automated Software Engineering, ASE 2004},
  key       = {Computer aided software engineering},
  keywords  = {Codes (symbols);Computer architecture;Computer programming languages;Computer simulation;Computer software;Database systems;Industrial applications;Mathematical models;Problem solving;Program compilers;},
  language  = {English},
}

@Article{Deng2009,
  author    = {Deng, Jie-Qing and Yuan, Yu-Bo},
  title     = {Realization and application of transformer substation automation test simulation system based on PLC module},
  journal   = {Dianli Xitong Baohu yu Kongzhi/Power System Protection and Control},
  year      = {2009},
  volume    = {37},
  number    = {24},
  pages     = {157 - 160},
  issn      = {16743415},
  note      = {Automation systems;Electrical networks;Hardware and software;Measurement and control;Simulation environment;Simulation systems;Substation automation;Substation Automation Systems;},
  abstract  = {The current transformer substation automation test is mainly for single measurement and control device, is not for automation system. So transformer substation automation test simulation system based on PLC module is proposed and the effective test for automation system is carried out. Firstly, this paper describes structure of automation system test and explains test simulation system's constitution. Then it carries on explanation to the simulation environment reality from two aspects of hardware and software. Secondly, it elaborates in detail how to use the test simulation system to simulate electrical network breakdown, to test performance of automation system. Lastly, this paper points out because the PLC system provides the user the development contact surface, it enables the test simulation system to have certain flexibility and the extendibility.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Electric transformer testing},
  keywords  = {Automation;Computer software;Electric transformers;Transformer substations;},
  language  = {Chinese},
}

@InProceedings{Kim2013,
  author    = {Kim, Gwang-Hun and Kim, Yeon-Gyun and Shin, Seok-Kyu},
  title     = {Software performance test automation by using the virtualization},
  year      = {2013},
  volume    = {215 LNEE},
  pages     = {1191 - 1199},
  address   = {Pyeong Chang, Korea, Republic of},
  note      = {Computer resources;Performance efficiency;Performance testing;Software performance;Software performance engineerings;Software performance testing;System architectures;Technical limitations;Test Automation;Test engineers;Test Environment;Virtualization technologies;Virtualizations;},
  abstract  = {In this paper, we propose a method on software performance test automation by using the virtualization. In general, most test engineers use the public performance testwares such as Load Runner and Silk Performer to validate the performance efficiency of their own systems. In case that they cannot use the performance testwares due to some technical limitations in the testwares, the testers should perform the testing in manually. As waste of computer and human resources is resulted from the situation, we need to propose the test automation scheme by using the virtualization technology to prevent the dissipation in the test environment which has limited resources. The system architecture considered efficient usage of computer resources and test automation to reduce human acts are addressed mainly in this paper. Finally, a number of experiments show that the proposed schemes allow offering the possibility for automated software performance testing by using the virtualization. &copy; 2013 Springer Science+Business Media. automation*Virtualization.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {18761100},
  journal   = {Lecture Notes in Electrical Engineering},
  key       = {Software testing},
  keywords  = {Automation;Virtual reality;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-94-007-5860-5_143},
}

@Article{Varela-Gonzalez2013,
  author    = {Varela-Gonzalez, M. and Gonzalez-Jorge, H. and Riveiro, B. and Arias, P.},
  title     = {Performance testing of LiDAR exploitation software},
  journal   = {Computers and Geosciences},
  year      = {2013},
  volume    = {54},
  pages     = {122 - 129},
  issn      = {00983004},
  note      = {AutoCad;Carlson;Computational requirements;Geosciences;Large datasets;Loading time;Mobile lidar;Mobile lidar system;Performance testing;Point cloud;Software performance testing;Software solution;Stress test;},
  abstract  = {Mobile LiDAR systems are being used widely in recent years for many applications in the field of geoscience. One of most important limitations of this technology is the large computational requirements involved in data processing. Several software solutions for data processing are available in the market, but users are often unknown about the methodologies to verify their performance accurately. In this work a methodology for LiDAR software performance testing is presented and six different suites are studied: QT Modeler, AutoCAD Civil 3D, Mars 7, Fledermaus, Carlson and TopoDOT (all of them in x64). Results depict as QTModeler, TopoDOT and AutoCAD Civil 3D allow the loading of large datasets, while Fledermaus, Mars7 and Carlson do not achieve these powerful performance. AutoCAD Civil 3D needs large loading time in comparison with the most powerful softwares such as QTModeler and TopoDOT. Carlson suite depicts the poorest results among all the softwares under study, where point clouds larger than 5 million points cannot be loaded and loading time is very large in comparison with the other suites even for the smaller datasets. AutoCAD Civil 3D, Carlson and TopoDOT show more threads than other softwares like QTModeler, Mars7 and Fledermaus. &copy; 2012 Elsevier Ltd.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Loading},
  keywords  = {Computer aided design;Data processing;Optical radar;Software testing;Three dimensional computer graphics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.cageo.2012.12.001},
}

@Article{Garousi2010,
  author    = {Garousi, Vahid},
  title     = {A genetic algorithm-based stress test requirements generator tool and its empirical evaluation},
  journal   = {IEEE Transactions on Software Engineering},
  year      = {2010},
  volume    = {36},
  number    = {6},
  pages     = {778 - 797},
  issn      = {00985589},
  note      = {Distributed real time system;Empirical analysis;Empirical evaluations;Genetic algorithm (GAs);Performance bottlenecks;Stress Testing;Test Automation;Test tools;},
  abstract  = {Genetic algorithms (GAs) have been applied previously to UML-driven stress test requirements generation with the aim of increasing chances of discovering faults relating to network traffic in distributed real-time systems. However, since evolutionary algorithms are heuristic, their performance can vary across multiple executions, which may affect robustness and scalability. To address this, we present the design and technical detail of a UML-driven, GA-based stress test requirements generation tool, together with its empirical analysis. The main goal is to analyze and improve the applicability, efficiency, and effectiveness and also to validate the design choices of the GA used in the tool. Findings of the empirical evaluation reveal that the tool is robust and reasonably scalable when it is executed on large-scale experimental design models. The study also reveals the main bottlenecks and limitations of the tools, e.g., there is a performance bottleneck when the system under test has a large number of sequence diagrams which could be triggered independently from each other. In addition, issues specific to stress testing, e.g., the impact of variations in task arrival pattern types, reveal that the tool generally generates effective test requirements, although the features of those test requirements might be different in different runs (e.g., different stress times from the test start time might be chosen). While the use of evolutionary algorithms to generate software test cases has been widely reported, the extent, depth, and detail of the empirical findings presented in this paper are novel and suggest that the proposed approach is effective and efficient in generating stress test requirements. It is hoped that the findings of this empirical study will help other SBSE researchers with the empirical evaluation of their own techniques and tools. &copy; 2010 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Software testing},
  keywords  = {Genetic algorithms;Heuristic algorithms;Interactive computer systems;Real time systems;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/TSE.2010.5},
}

@InProceedings{Xie2011,
  author    = {Xie, Qi and Xu, Wei and Gu, Qimin and Xu, Huigang},
  title     = {Design of comprehensive performance test system for residual current fire monitoring detector based on virtual instrument technology},
  year      = {2011},
  volume    = {1},
  pages     = {950 - 953},
  note      = {Comprehensive performance;Data acquisition cards;Fire Monitoring;High speed data acquisition;Intelligent test;Intelligent test system;LabVIEW virtual instrument;Virtual instrument technology;},
  abstract  = {Aiming at the need of detecting the residual current fire monitoring detector, an intelligent test system based on virtual instrument technology was designed. This system was composed of industrial computer, data acquisition card, signal conditioning circuit, three-phase great current generator and pneumatic fixture, etc. Using LabVIEW virtual instrument technology platform, the related test and data processing program codes were developed, and its high speed data acquisition and data processing satisfied the needs of ex-factory comprehensive performance test for residual current fire monitoring detector. The hardware design was given and the working principles of this generator were introduced, the module design of system software was also introduced in detail. Practical application shows that the intelligent test system features with stable and reliable, easy to operate and maintain, high precision and can improve the design and performance of products, which can be widely used.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - 3rd International Conference on Measuring Technology and Mechatronics Automation, ICMTMA 2011},
  key       = {Software testing},
  keywords  = {Data acquisition;Data handling;Digital instruments;Fires;Product design;Signal conditioning circuits;Signal processing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICMTMA.2011.238},
}

@InProceedings{Rao2018a,
  author    = {Rao, Nageswara S.V. and Liu, Qiang and Sen, Satyabrata and Kettimuthu, Raj and Boley, Josh and Settlemyer, Bradley W. and Chen, Hsing B. and Katramatos, Dimitrios and Yu, Dantong},
  title     = {Software-defined network solutions for science scenarios: Performance testing framework and measurements},
  year      = {2018},
  pages     = {ACM Special Interest Group on Mobility of Systems, Users, Data and Computing (SIGMOBILE); ACM Special Interest Group on Operating Systems (SIGOPS) -},
  address   = {Varanasi, India},
  note      = {Dedicated networks;Performance testing framework;Physical testbeds;Science scenarios;Scientific instrument;Scientific workflows;Switching response;Throughput performance;},
  abstract  = {High-performance scientific workflows utilize supercomputers, scientific instruments, and large storage systems. Their executions require fast setup of a small number of dedicated network connections across the geographically distributed facility sites.We present Software-Defined Network (SDN) solutions consisting of site daemons that use dpctl, Floodlight, ONOS, or OpenDaylight controllers to set up these connections. The development of these SDN solutions could be quite disruptive to the infrastructure, while requiring a close coordination among multiple sites; in addition, the large number of possible controller and device combinations to investigate could make the infrastructure unavailable to regular users for extended periods of time. In response, we develop a Virtual Science Network Environment (VSNE) using virtual machines, Mininet, and custom scripts that support the development, testing, and evaluation of SDN solutions, without the constraints and expenses of multi-site physical infrastructures; furthermore, the chosen solutions can be directly transferred to production deployments. By complementing VSNE with a physical testbed, we conduct targeted performance tests of various SDN solutions to help choose the best candidates. In addition, we propose a switching response method to assess the setup times and throughput performances of different SDN solutions, and present experimental results that show their advantages and limitations.<br/> &copy; 2018 ACM. 978-1-4503-6372-3/18/01. . . $15.00.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {ACM International Conference Proceeding Series},
  key       = {Distributed computer systems},
  keywords  = {Controllers;Data storage equipment;Electric lighting;Software defined networking;Software testing;Solution mining;Supercomputers;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/3154273.3154336},
}

@InProceedings{Gao2016,
  author    = {Gao, Ruoyu and Jiang, Zhen Ming and Barna, Cornel and Litoiu, Marin},
  title     = {A Framework to Evaluate the Effectiveness of Different Load Testing Analysis Techniques},
  year      = {2016},
  pages     = {22 - 32},
  address   = {Chicago, IL, United states},
  note      = {Analysis techniques;Descriptive statistics;Evaluation framework;Large-scale software systems;Open source system;Performance Model;Performance problems;Sampling interval;},
  abstract  = {Large-scale software systems like Amazon and eBay must be load tested to ensure they can handle hundreds and millions of current requests in the field. Load testing usually lasts for a few hours or even days and generates large volumes of system behavior data (execution logs and counters). This data must be properly analyzed to check whether there are any performance problems in a load test. However, the sheer size of the data prevents effective manual analysis. In addition, unlike functional tests, there is usually no test oracle associated with a load test. To cope with these challenges, there have been many analysis techniques proposed to automatically detect problems in a load test by comparing the behavior of the current test against previous test(s). Unfortunately, none of these techniques compare their performance against each other. In this paper, we have proposed a framework, which evaluates and compares the effectiveness of different test analysis techniques. We have evaluated a total of 23 test analysis techniques using load testing data from three open source systems. Based on our experiments, we have found that all the test analysis techniques can effectively build performance models using data from both buggy or non-buggy tests and flag the performance deviations between them. It is more cost-effective to compare the current test against two recent previous test(s), while using testing data collected under longer sampling intervals (&le; 180 seconds). Among all the test analysis techniques, Control Chart, Descriptive Statistics and Regression Tree yield the best performance. Our evaluation framework and findings can be very useful for load testing practitioners and researchers. To encourage further research on this topic, we have made our testing data publicity available to download. &copy; 2016 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - 2016 IEEE International Conference on Software Testing, Verification and Validation, ICST 2016},
  key       = {Software testing},
  keywords  = {Cost effectiveness;Internet;Load testing;Open source software;Open systems;Testing;Verification;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICST.2016.9},
}

@InProceedings{Yao2012,
  author    = {Yao, Yepeng and Wang, Xuren},
  title     = {A distributed, cross-platform automation testing framework for GUI-driven applications},
  year      = {2012},
  pages     = {723 - 726},
  address   = {Changchun, China},
  note      = {Application testing;Automation testing;Computer technology;Cross-platform;Desktop applications;Distributed testing;Software Quality;Testing framework;},
  abstract  = {With the rapid development of computer technology, nowadays GUIs have been widely used in desktop applications and web applications. GUI-driven application testing is an emergent approach to software testing and plays a key role to assure software quality. This paper first discusses the various methods for testing GUI-driven applications, and then defines a GUI model and formally defines the test case and the test suite. Finally, it proposes a novel automated, distributed and cross-platform testing framework for GUI. Experiments conducted showed that the proposed testing architecture managed to use parallel cross-platform clusters to test heterogeneous applications whose technologies were incompatible with the testing framework. &copy; 2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of 2nd International Conference on Computer Science and Network Technology, ICCSNT 2012},
  key       = {Graphical user interfaces},
  keywords  = {Automation;Computer science;Computer software selection and evaluation;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICCSNT.2012.6526035},
}

@InProceedings{Xu2010,
  author    = {Xu, Wei and Xu, Huigang and Xie, Qi and Yang, Yunfei and Dai, Mei},
  title     = {Design of automatic performance test system for CPS},
  year      = {2010},
  volume    = {4},
  pages     = {206 - 209},
  note      = {Accurate performance;Automatic test system;Communication functions;Industrial control computer;LabViEW;Measurement function;Performance tests;Three-phase currents;},
  abstract  = {In order to satisfy the needs of comprehensive and accurate performance test for CPS (Control and Protective Switching), an automatic performance test system was studied in this paper. The hardware structure and software was introduced in detail; the hardware system was made up of the industrial control computer, the three-phase current generator, adjustable single-phase power, pneumatic fixture, and so on. The test system software developed by LabVIEW was mainly used to achieve the functions of data acquisition, data processing and data display. The designed system is able to automatically test all functions of different types of CPS, including measurement function, communication function, multiple protection function, and so on. Practical application shows that the test system has following properties: high precision, low cost, strong anti-interference and convenient maintenance. &copy; 2010 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {2010 International Conference on Computer, Mechatronics, Control and Electronic Engineering, CMCE 2010},
  key       = {Computer control systems},
  keywords  = {Automatic testing;Computer hardware;Computer programming languages;Data acquisition;Data handling;Electric equipment protection;Hardware;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/CMCE.2010.5610188},
}

@Article{Liu2009,
  author    = {Liu, Zhenzhong and Zhao, Lianyu and Liu, Qingjian and Wang, Taiyong},
  title     = {Measurement and control system for car clutch cover assembly comprehensive performance test rig},
  journal   = {Yi Qi Yi Biao Xue Bao/Chinese Journal of Scientific Instrument},
  year      = {2009},
  volume    = {30},
  number    = {SUPPL.},
  pages     = {226 - 229},
  issn      = {02543087},
  note      = {Comprehensive performance;Host computers;Industrial computers;Measurement and control systems;Motion controller;Object oriented method;Test rigs;Windows XP;},
  abstract  = {The measurement and control system for car clutch cover assembly comprehensive performance test rig is designed and developed. In the system, the motion controller, acting as a client computer, controls the servo motors, and the industrial computer, acting as a host computer, acquires and processes signal, commands the client computer, and achieves the function of human-computer interaction. Procedure of the measurement and control system was designed with application of VC++6.0 software based on the object oriented method in the environment of Windows XP Embedded. The result shows that the system can test multi-specifications (&Phi;275-&Phi;430) clutch cover assembly and function well.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Computer control},
  keywords  = {Application programs;Clutches;Control systems;Human computer interaction;Object oriented programming;Servomotors;Vehicle performance;},
  language  = {Chinese},
}

@Article{Eros2008,
  author    = {Eros, Levente and Bozoki, Ferenc},
  title     = {Test component assignment and scheduling in a load testing environment},
  journal   = {Periodica Polytechnica Electrical Engineering},
  year      = {2008},
  volume    = {52},
  number    = {3-4},
  pages     = {145 - 152},
  issn      = {03246000},
  note      = {Distributing-load;Hardware resources;Software entities;System under test;Task assignment;Test components;Test Environment;Testing environment;},
  abstract  = {In this paper we introduce two major problems from the field of load (or performance) testing and our solutions for them. When testing the performance of a device (System Under Test - SUT), the test environment executes many software entities (the so-called test components) on the hosts of the test environment (testing hosts). Our goal is to maximize the load on the testing hosts by assigning the test components to them closely to optimal. The first problem to be solved is, thus, a special case of the task assignment problem for which many algorithms have been developed. Our solutions presented in this paper are, however, optimized for distributing load testing traffic in the case of which the possibilities and restrictions to be taken into account are very different from those of the classical task assignment case. The other problem we deal with is how to schedule test components running on the same testing host. Most of the papers written on scheduling focus on the characteristics of the generated load, but not on the way of generating it. These papers usually assume that the load can be generated by improving hardware resources. In this paper, however, we introduce a model and an algorithm which improves the efficiency of scheduling in a load testing environment with way less hardware resources. The algorithm is based on our novel concept of virtual threads. Our simulations have shown that by applying our solutions, the efficiency of load testing can be significantly increased. &copy; Periodica Polytechnica 2008.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Load testing},
  keywords  = {Combinatorial optimization;Computational complexity;Efficiency;Hardware;Scheduling;Software testing;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.3311/pp.ee.2008-3-4.03},
}

@InProceedings{Gold2004,
  author    = {Gold, Kenn and Brown, Alison},
  title     = {Architecture and performance testing of a software GPS receiver for space-based applications},
  year      = {2004},
  volume    = {2004},
  pages     = {624 - 635},
  address   = {San Diego, CA, United states},
  note      = {Constellations;GPS signals;Hybrid simulators;Space-software GPS receiver (SSGR);},
  abstract  = {NAVSYS has modified the design of its Software GPS Receiver to optimize performance for various space-based scenarios. These include capabilities to track GPS satellites from missions that are at altitudes higher than the GPS constellation. The approach is based on Digital Beam Steering, which also presents significant advantages for multipath mitigation, which will improve kinematic carrier phase tracking and GPS interferometric attitude determination for orbital applications. In addition, the composite signal formed from the beam steering algorithms lends itself to antenna placement around the spacecraft body, which will result in continuous visibility, even for spinning satellites. Inertial aiding with the SGR has also been adapted for space applications including high dynamic scenarios in which it is difficult to track GPS. In order to test the modifications required for the Space-Software GPS Receiver (SSGR), the NAVSYS simulation tools suite has been augmented to account for orbital scenarios. This involved adding an interface to the GPS Toolbox product to accept orbital trajectories generated with Satellite Tool Kit. The Toolbox in turn drives the hardware simulations with the Advanced GPS Hybrid Simulator.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of the National Technical Meeting, Institute of Navigation},
  key       = {Global positioning system},
  keywords  = {Acoustic receivers;Algorithms;Computer simulation;Computer software;Geostationary satellites;Kinematics;Orbits;Space applications;Testing;Tracking (position);},
  language  = {English},
}

@InProceedings{Angmo2014,
  author    = {Angmo, Rigzin and Sharma, Monika},
  title     = {Performance evaluation of web based automation testing tools},
  year      = {2014},
  pages     = {731 - 735},
  address   = {Noida, India},
  abstract  = {In today's 21<sup>st</sup> century era countless software applications are written as a web based application which runs in a web browsers. With new technologies and commercialization of I.T. sector, the web based system has undergoes frequent and rapid changes. Today Softwares are coded as a web based application, which help to access data from any part of the globe. Even the economic relevance of web based enhances the control and quality of software. The quality assurance of any system depends on its test. But to do manually testing in most of the cases is time consuming, expensive and hectic. For the better business purpose and to save time and money automation testing is required. There are variety of tools are available in the market for this. One of the best known tool is selenium suite which is a combination of different automation testing tool. In this paper we will discuss about the selenium suite. It provides testers with different framework for different test cases. The main objective of this paper is to find the best tool in selenium suite and then compare it with some other tool for same task. For this purpose, performance evaluation is done on the basis of some criteria.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of the 5th International Conference on Confluence 2014: The Next Generation Information Technology Summit},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/CONFLUENCE.2014.6949287},
}

@Article{Jiang2016,
  author    = {Jiang, Bo and Chen, Peng and Chan, Wing Kwong and Zhang, Xinchao},
  title     = {To What Extent is Stress Testing of Android TV Applications Automated in Industrial Environments?},
  journal   = {IEEE Transactions on Reliability},
  year      = {2016},
  volume    = {65},
  number    = {3},
  pages     = {1223 - 1239},
  issn      = {00189529},
  note      = {Android;Automated testing;Hardware components;Industrial environments;Production environments;Resource conditions;Stress Testing;Test case;},
  abstract  = {An Android-based smart television (TV) must reliably run its applications in an embedded program environment under diverse hardware resource conditions. Owing to the diverse hardware components used to build numerous TV models, TV simulators are usually not sufficiently high in fidelity to simulate various TV models and thus are only regarded as unreliable alternatives when stress testing such applications. Therefore, even though stress testing on real TV sets is tedious, it is the de facto approach to ensure the reliability of these applications in the industry. In this paper, we study to what extent stress testing of smart TV applications can be fully automated in the industrial environments. To the best of our knowledge, no previous work has addressed this important question. We summarize the findings collected from ten industrial test engineers who have tested 20 such TV applications in a real production environment. Our study shows that the industry required test automation supports on high-level GUI object controls and status checking, setup of resource conditions, and the interplay between the two. With such supports, 87% of the industrial test specifications of one TV model can be fully automated, and 71.4% of them were found to be fully reusable to test a subsequent TV model with major upgrades of hardware, operating system, and application. It represents a significant improvement with margins of 28% and 38%, respectively, compared with stress testing without such supports.<br/> &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Software testing},
  keywords  = {Android (operating system);Application programs;Automation;Computer software reusability;Drag reduction;Hardware;Reliability;Software reliability;Television;Television applications;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/TR.2015.2481601},
}

@InProceedings{Feng2007,
  author    = {Feng, Li and Zhuang, Sheng},
  title     = {Action-driven automation test framework for Graphical User Interface (GUI) software testing},
  year      = {2007},
  pages     = {22 - 27},
  address   = {Baltimore, MD, United states},
  note      = {Automation tests;Design and implementations;Graphical user interfaces (GUI);GUI software;Process of learning;Test case;},
  abstract  = {In this paper we describe the design and implementation of an action-driven automation test framework especially for GUI software testing. The idea of action-driven automation test framework comes from the core concept of "Quality Assurance (QA)". Better quality can be ensured by increasing the coverage of test cases on the software but the process of creating large number of test cases has to be optimized. With this goal the framework was designed to primarily increase the efficiency and flexibility in composing test cases and simplify the process of learning the test cases. This paper describes the background, features, and implementation details of the framework.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {AUTOTESTCON (Proceedings)},
  key       = {Software testing},
  keywords  = {Automation;Graphical user interfaces;Quality assurance;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/AUTEST.2007.4374197},
}

@Article{Ming2010,
  author    = {Ming, Zhong and Yin, Jianfei and Yang, Wei and Wang, Hui and Xiao, Zhijiao},
  title     = {A Web performance testing framework and its mixed performance modeling process},
  journal   = {Jisuanji Yanjiu yu Fazhan/Computer Research and Development},
  year      = {2010},
  volume    = {47},
  number    = {7},
  pages     = {1192 - 1200},
  issn      = {10001239},
  note      = {Analysis and testing;Performance forecasting;Performance Model;Performance testing;Queueing network model;Scalability modeling;Software and hardwares;System response time;},
  abstract  = {Methods of pure performance testing or single analytical modeling, such as queueing network model, etc, have their limitation on the accuracy of performance indexes measurement, the validity of performance forecasting, and the controlling of testing iteration due to the complexity of Web systems. A Web performance modeling framework supporting mixed performance modeling is proposed. It uses different performance modeling methods for different kinds of performance indexes to derive closed form functions and their hypothesis of measurement. The regression analysis and testing are used on the training data to estimate the parameters of the closed form functions. To demonstrate the feasibility and validity of this framework, a real-world Web community system (igroot.com) is studied under the framework. For the indexes of system response time and scalability, a mixed modeling method is proposed by combining queueing network reduction and extended universal scalability model US-&gamma;. Compared with other practical system performance testing methods, such as universal scalability model US, the model accuracy of performance forecasting is greatly improved and the cost of software and hardware used in the process is greatly reduced. The error rate of estimated response time is within 4 percent, the error rate of estimated throughout saturation point is within 1 percent, and the error rate of estimated infimum of buckle point is within 5 percent. Correlating the scalability model and threads data of the Web server, an HTTP processing bottleneck at the architecture level is identified.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Queueing networks},
  keywords  = {Distributed computer systems;Errors;HTTP;Iterative methods;Queueing theory;Regression analysis;Response time (computer systems);Scalability;Software testing;Testing;},
  language  = {Chinese},
}

@InProceedings{Kao2013,
  author    = {Kao, Chia Hung and Lin, Chun Cheng and Chen, Juei-Nan},
  title     = {Performance testing framework for rest-based web applications},
  year      = {2013},
  pages     = {349 - 354},
  address   = {Nanjing, Jiangsu, China},
  note      = {Design and implementations;Performance characteristics;Performance testing;Performance testing framework;Performance tests;Software artifacts;Software company;WEB application;},
  abstract  = {Recently, enterprises, organizations, and software companies are building more and more web applications to provide their services over the Internet. In order to fulfill various requirements, the complexity of web applications nowadays is increasing dramatically. As a result, the performance characteristics of web applications, including response time, throughput, etc, become more critical than before and should be taken into careful consideration. If the response time of a web application is poor, users may lose their interests even the function of the web application is correct. Therefore, how to execute performance testing on a complex web application systematically and efficiently will be an important issue. In this paper, a performance testing framework for REST-based web applications is introduced. The performance testing framework aims to provide software testers with an integrated process from test cases design, test scripts generation, to test execution. Based on the test cases designed by software testers and the appropriate software artifacts preserved by the framework (e.g., API document), the framework generates the corresponding performance test scripts, which can be executed by specific performance test tools. This helps software testers to focus more in the design of performance test cases. In addition, effort needed to understand the design and implementation of the application and to learn the operation of testing tools decrease. Thus, the efficiency of performance testing can be highly facilitated. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of the International Symposium on the Physical and Failure Analysis of Integrated Circuits, IPFA},
  key       = {Software testing},
  keywords  = {Applications;Design;Industry;World Wide Web;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/QSIC.2013.32},
}

@InProceedings{Yakovyna2007,
  author    = {Yakovyna, Vitaly and Fedasyuk, Dmytro and Seniv, Maxym},
  title     = {Software realization and performance testing of des cryptographic algorithm on the .NET platform},
  year      = {2007},
  pages     = {386 - 388},
  address   = {Lviv-Polyana, Ukraine},
  note      = {.NET;CryptoAPI;Cryptographic algorithms;Cryptographic software;DES algorithms;Development environment;Software implementation;Symmetric cryptography;},
  abstract  = {The software realization of DES symmetric encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested and it was shown, that the encryption rate is 11.1 Mb/sec on the Intel Celeron D 351 3.2GHz processor, while the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {The Experience of Designing and Application of CAD Systems in Microelectronics - Proceedings of the 9th International Conference, CADSM 2007},
  key       = {Cryptography},
  keywords  = {Computer aided design;Microelectronics;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/CADSM.2007.4297591},
}

@InProceedings{Yakovyna2007a,
  author    = {Yakovyna, Vitaly and Fedasyuk, Dmytro and Seniv, Maxym and Bilas, Orest},
  title     = {The Performance testing of RSA algorithm software realization},
  year      = {2007},
  pages     = {390 - 392},
  address   = {Lviv-Polyana, Ukraine},
  note      = {.NET;Cryptographic software;Development environment;Flexible architectures;Operation performance;Public key encryption algorithms;RSA algorithms;Software implementation;},
  abstract  = {The software realization of RSA public key encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested. The present paper shows, that the encryption rate is 306.4&plusmn;0.6 kbytes/sec, while the coefficient of encryption time increasing with file size increasing is 3.299. It is concluded that the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {The Experience of Designing and Application of CAD Systems in Microelectronics - Proceedings of the 9th International Conference, CADSM 2007},
  key       = {Computer aided design},
  keywords  = {Microelectronics;Public key cryptography;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/CADSM.2007.4297593},
}

@InProceedings{Finnigan2013,
  author    = {Finnigan, Jeremiah},
  title     = {Radiation Belt Storm Probes (RBSP) Flight Software stress testing: Case study and lessons learned},
  year      = {2013},
  address   = {Big Sky, MT, United states},
  note      = {Background information;Design and Development;Flight Software;Lessons learned;Mission command;Regression testing;Stress Testing;Test framework;},
  abstract  = {This paper presents a case study of the Radiation Belt Storm Probes (RBSP) mission Command and Data Handling (C&amp;DH) Flight Software stress testing program. Background information on the motivation for stress testing embedded software, and the general principles and goals of a stress test are provided as an introduction. Details of the stress test program that was implemented for the RBSP C&amp;DH Flight Software are presented and discussed. This discussion includes the design and development of a test framework that was implemented to incrementally build the test scenarios, increase the productivity of the RBSP stress test team, and facilitate reuse for regression testing. Results of the RBSP stress test program are summarized, and lessons learned that may be useful for future embedded software test programs are documented. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {1095323X},
  journal   = {IEEE Aerospace Conference Proceedings},
  key       = {Software testing},
  keywords  = {C (programming language);Data handling;Embedded software;Probes;Radiation belts;Storms;Test facilities;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/AERO.2013.6496814},
}

@InProceedings{Wang2009,
  author    = {Wang, Guimei and Jiao, Shanlin and Song, Hui},
  title     = {Mine pump comprehensive performance testing system based on labview},
  year      = {2009},
  volume    = {1},
  pages     = {300 - 303},
  address   = {Zhangjiajie, Hunan, China},
  note      = {Comprehensive performance;Computer assisted testing;LabViEW;Network communications;Performance efficiency;Software development environment;Testing systems;Virtual instrument technology;},
  abstract  = {The pump is one of the key equipments for the safety production of coal mine. It bears the important task to discharge all the underground water. However, the performance efficiency of the water pump will be declined, in the long run. Therefore, in order to ensure the safety production, users should check and test the pump performance regularly, to test if every target pump has live up to the "Coal Mine Safety Regulations". The ultimate goal in finding the fault in time, eliminating hidden dangers, reducing accidents, and saving maintenance costs can be attained. Virtual instrument is the production of modern computer and instrument technology combined in-depth, and is an important technology of computer-assisted testing area. The core idea is "software replacing hardware". The paper introduces the virtual instrument technology into the field of pump performance testing, and designs the mine pump comprehensive performance testing system based on Labview. The system takes software development environment-LabVIEW as platform and based on personal computer, and realizes the function that pump's import and export of water pressure, flow, speed, power, and other signals measured in real-time and dynamic displayed. It uses the polynomial fitting module of LabVIEW to fit the performance curve, and shows the performance curve by the waveform display. At the same time, it uses the Web Publishing Tool of LabVIEW to release the testing interface to the internet, and realizes its network communication function. Compared with traditional instruments, the pump performance testing system which based on Virtual instrument run stably, have strongly data analytical and processing functions, beautiful interface, easy operation, strongly visual function, highly testing precision. &copy; 2009 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {2009 International Conference on Measuring Technology and Mechatronics Automation, ICMTMA 2009},
  key       = {Instrument testing},
  keywords  = {Coal mines;Computer programming languages;Computer testing;Curve fitting;Data handling;Digital instruments;Groundwater;Mining machinery;Personal computers;Pumps;Software design;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICMTMA.2009.179},
}

@InProceedings{Lee2016,
  author    = {Lee, Shin-Jie and Lin, You-Chen and Lin, Kun-Hui and You, Jie-Lin},
  title     = {A framework for composing heterogeneous service tools involved in load testing lifecycle},
  year      = {2016},
  pages     = {1075 - 1080},
  address   = {Osaka, Japan},
  note      = {Automatically generated;Experimental evaluation;Heterogeneous services;Integrated service;Resource monitoring;System footprints;System under test;Traditional approaches;},
  abstract  = {Load testing is the process of applying ordinary stress to a software system to determine the system performance under normal conditions. In a typical load testing lifecycle, three kinds of service tools are involved: test case recording service tools that make testers easier to generate test cases through a web browsing-like behavior; test case execution service tools that exercise test cases with simulations of a large number of concurrent users; system resource monitoring service tools that provide information of system footprints during the test case executions. However, using these three kinds of service tools one by one to complete a load testing may require extra effort on operating and configuring each service. In this paper, we proposed a framework for composing the three types of service tools as an integrated service for load testing. A raw test case recorded by Badboy tool is automatically converted into an expanded test case that can be executed by JMeter. JMeter and Cacti are then automatically invoked by the framework. The execution time period of JMeter is automatically identified as the input to Cacti for resource monitoring of the system under test. The test report together with system footprints is also automatically generated. In the experimental evaluation, the result shows that the framework significantly save time on operating and configuring the load testing service tools than the traditional approach under a t-test. &copy; 2016 Taylor & Francis Group.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Applied System Innovation - Proceedings of the International Conference on Applied System Innovation, ICASI 2015},
  key       = {Software testing},
  keywords  = {Automatic test pattern generation;Life cycle;Load testing;Monitoring;Network function virtualization;},
  language  = {English},
}

@Article{Lin2017,
  author    = {Lin, Ying-Dar and Lai, Yu-Kuen and Wang, Chen-You and Lai, Yuan-Cheng},
  title     = {OFBench: Performance Test Suite on OpenFlow Switches},
  journal   = {IEEE Systems Journal},
  year      = {2017},
  issn      = {19328184},
  note      = {Automation controls;End-to-end measurement;Internal performance;Large-scale deployment;Openflow;performance evaluation;Performance metrics;system performance;},
  abstract  = {Performance issues of OpenFlow switches are attracting a lot of attention owing to the potential large-scale deployment of software-defined devices. This paper presents the OFBench which is an automatic test suite for evaluating the performance of OpenFlow switches. The design, as part of the Automation Control Test System (ACTS) development, is based on a controller-agent architecture which allows the development of test cases that are written in a high-level script language. In addition to the end-to-end measurement methodology, novel methods are proposed to further profile the internal performance metrics, which are difficult to get due to the black-box nature of the device under test. The prototype of this suite currently comprises five test cases to evaluate five performance metrics, which are action time, pipeline time, buffer size, pipeline efficiency, and timeout accuracy. OpenFlow switches are evaluated and three issues are observed associated with switches during the testing. First, some switches may not be well implemented in the design of apply-action instructions. Second, some switches suffer from random crashes with a high volume of bursty packet-in traffic. Finally, the timer of idle-timeout is often not reset properly with matching flow entry. IEEE},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Computer network performance evaluation},
  keywords  = {Computer networks;High level languages;Pipelines;Software defined networking;Software testing;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/JSYST.2017.2720758},
}

@InProceedings{Eros2008a,
  author    = {Eros, Levente and Csondes, Tibor},
  title     = {Test component assignment in a performance testing environment},
  year      = {2008},
  pages     = {399 - 403},
  address   = {Split-Dubrovnik, Croatia},
  note      = {Distributing-load;Integer linear programs;Performance testing;Software entities;System under test;Task assignment;Test Environment;Testing environment;},
  abstract  = {In this paper we are going to introduce the problem of assigning test components to hosts of a performance (or load) testing environment, and its two novel solutions. When testing the performance of a device (System Under Test - SUT), the test environment simulates the latter real-life environment of the SUT. The number of hosts in the test environment is however way less than the number of hosts the SUT will have to serve in its real-life environment. Thus, real-life hosts are simulated by software entities, the so-called test components that have to be optimally assigned and then executed on the hosts of the test environment (testing hosts). Our goal is to emulate all the test components by as few testing hosts as possible, that is, to maximize the load on the testing hosts. The problem to be solved is a special case of the task assignment problem for which many solutions have been developed. Our solutions presented in this paper are, however, optimized for distributing load testing traffic. Thus the possibilities and restrictions we had to take into account are very different from those of the classical task assignment case. One of the solutions we present extends existing bin packing heuristics, while the other one solves a series of integer linear programs to make the assignments. Our simulations have shown that by applying our solutions, the average load level on testing hosts can be significantly increased.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {SoftCom 2008: 16th International Conference on Software, Telecommuncations and Computer Networks},
  key       = {Software testing},
  keywords  = {Combinatorial optimization;Computer networks;Integer programming;Load testing;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/SOFTCOM.2008.4669518},
}

@InProceedings{Stupiec2013,
  author    = {Stupiec, Emil and Walkowiak, Tomasz},
  title     = {Automatic load testing of web application in SaaS model},
  year      = {2013},
  volume    = {224},
  pages     = {421 - 430},
  address   = {Brunow, Poland},
  note      = {Active monitoring;Automatically generated;E-services;Hardware architecture;High availability;Software solution;User Modeling;WEB application;},
  abstract  = {Necessity of monitoring in combination with the actual complexity of the e-services creates a need for constructing systems for active monitoring of various types of web services. Usually those systems are high-availability services, that require on one hand ingenious software solutions and on the other hand reliable hardware architecture. The created systems need to be flexible enough to satisfy customers requirements. This paper introduces an example solution of a system, that implement functional monitor of services provided in SaaS model. The provided system allows to check certain functionalities or whole service by running functional/load tests scenarios that are automatically generated, based on specially prepared user model. &copy; Springer International Publishing Switzerland 2013.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {21945357},
  journal   = {Advances in Intelligent Systems and Computing},
  key       = {Software as a service (SaaS)},
  keywords  = {Automatic test pattern generation;Customer satisfaction;Web services;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-00945-2_38},
}

@InProceedings{Ali2015,
  author    = {Ali, Amira and Badr, Nagwa},
  title     = {Performance testing as a service for web applications},
  year      = {2015},
  pages     = {356 - 361},
  address   = {Cairo, Egypt},
  note      = {Automatic test-case generations;Continuous monitoring;Emerging technologies;JMeter;Performance testing;Software engineering life-cycle;TaaS;Web application testing;},
  abstract  = {Software testing is a vital activity that is undertaken during software engineering life cycle to ensure software quality and reliability. Performance testing is a type of software testing that is done to shows how web application behaves under a certain workload. Cloud computing as an emerging technology can be used in the field of software engineering to provide cloud testing in order to overcome all deficiencies of conventional testing by leveraging cloud computing resources. As a result, testing-as-a-service (TaaS) is introduced as a service model that performs all testing activities in fully automated manner, on demand with a pay-for use basis. Moreover, TaaS increases testing efficiency and reduces time and cost required for testing. In this paper, performance TaaS framework for web applications is introduced which provides all performance testing activities including automatic test case generation and test execution. In addition, the proposed framework addresses many issues as: maximize resource utilization and continuous monitoring to ensure system reliability. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {2015 IEEE 7th International Conference on Intelligent Computing and Information Systems, ICICIS 2015},
  key       = {Software testing},
  keywords  = {Application programs;Cloud computing;Computer software selection and evaluation;Information systems;Intelligent computing;Life cycle;Software engineering;Software reliability;World Wide Web;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/IntelCIS.2015.7397245},
}

@Article{Chen2014,
  author    = {Chen, Yit-Jin and Liao, Ming-Ru and Lin, Shiu-Shin and Huang, Jen-Kai and Marcos, Maria Cecilia M.},
  title     = {Development of an integrated web-based system with a pile load test database and pre-analyzed data},
  journal   = {Geomechanics and Engineering},
  year      = {2014},
  volume    = {7},
  number    = {1},
  pages     = {37 - 53},
  issn      = {2005307X},
  note      = {Advanced applications;Apache web server;Automatic translation;Design parameters;Software design techniques;Structured Query Language;System architectures;Web based;},
  abstract  = {A Web-based pile load test (WBPLT) system was developed and implemented in this study. Object-oriented and concept-based software design techniques were adopted to integrate the pile load test database into the system. A total of 673 case histories of pile load test were included in the database. The data consisted of drilled shaft and driven precast concrete pile axial load tests in drained, undrained, and gravel loading conditions as well as pre-analyzed data and back-calculated design parameters. Unified modeling language, a standard software design tool, was utilized to design the WBPLT system architecture with five major concept-based components. These components provide the static structure and dynamic behavior of system message flows in a visualized manner. The open-source Apache Web server is the building block of the WBPLT system, and PHP Web programming language implements the operation of the WBPLT components, particularly the automatic translation of user query into structured query language. A simple search and inexpensive query can be implemented through the Internet browser. The pile load test database is helpful, and data can be easily retrieved and utilized worldwide for research and advanced applications. &copy; 2014 Techno-Press, Ltd.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Piles},
  keywords  = {Database systems;Internet;Load testing;Object oriented programming;Object-oriented databases;Open source software;Open systems;Precast concrete;Program translators;Query languages;Query processing;Software design;Software testing;Unified Modeling Language;Websites;},
  language  = {English},
  url       = {http://dx.doi.org/10.12989/gae.2014.7.1.037},
}

@Article{Kalita2011,
  author    = {Kalita, M. and Bezboruah, T.},
  title     = {Investigation on performance testing and evaluation of PReWebD: A.NET technique for implementing web application},
  journal   = {IET Software},
  year      = {2011},
  volume    = {5},
  number    = {4},
  pages     = {357 - 365},
  issn      = {17518806},
  note      = {Data-base servers;Important features;Internet information servers;Performance testing;Standard query languages;Statistical testing;Testing procedure;WEB application;},
  abstract  = {A prototype research web application based on Visual Studio platform is developed with.NET as framework, Internet Information Server (IIS) (Version: 5.1) as web server and Microsoft Standard Query Language (SQL) Server (Version: 2005) as database server to study the performance and evaluation of the.NET technique used for developing the web application. The authors call it the PReWebD. As the performance is one of the most important features of a web application, to evaluate the performance, testing of PReWebD has been carried out using Mercury LoadRunner (Version 8.0) for validation and to study some other attributes like scalability, reliability etc. The performance depends on parameters such as hits/s, response time, throughput, errors/s etc. These parameters for PReWebD are tested with different stress levels. The statistical testing and analysis is done to assure the stability, reliability and quality of the application. Here the authors report in details the architecture, testing procedure, result of performance testing as well as the results of statistical analysis on recorded data of PReWebD. &copy; 2011 The Institution of Engineering and Technology.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Quality control},
  keywords  = {Query languages;Query processing;Reliability analysis;Software prototyping;Visual languages;Windows operating system;},
  language  = {English},
  url       = {http://dx.doi.org/10.1049/iet-sen.2010.0139},
}

@InProceedings{Meng2011,
  author    = {Meng, Xiangfeng},
  title     = {Designing approach analysis on small-scale software performance testing tools},
  year      = {2011},
  volume    = {8},
  pages     = {4254 - 4257},
  address   = {Harbin, China},
  note      = {Concurrent operations;designing approach;designing mode;Individual customers;Measuring performance;Software performance;Software performance testing;Testing tools;},
  abstract  = {Currently, most software performance testing tools in the market are large ones designated for enterprises. Aiming at the demand of small-sized and individual customers' conduction of software performance testing, the paper proposes an approach for designing and realizing a small tool for testing. Core design refers to simulating multi-user concurrent operation by simultaneous execution of multithreading and measuring performance of the system tested through whether each threading responses in a correct manner as well as testing data such as period of responding. Testing tool, which is realized by Java language, consists of three modules of case management, test implementation and test report. Multiple designing modes are utilized in a combined manner during designing, which makes the designing scheme a simple one with high efficiency and easy to expand. The market of performance testing is developing in a rapid manner and researching software performance test is gaining increasingly significance. &copy; 2011 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of 2011 International Conference on Electronic and Mechanical Engineering and Information Technology, EMEIT 2011},
  key       = {Software testing},
  keywords  = {Commerce;Multitasking;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/EMEIT.2011.6023983},
}

@Article{Kim2015,
  author    = {Kim, Gwang-Hun and Kim, Yeon-Gyun and Chung, Kyung-Yong},
  title     = {Towards virtualized and automated software performance test architecture},
  journal   = {Multimedia Tools and Applications},
  year      = {2015},
  volume    = {74},
  number    = {20},
  pages     = {8745 - 8759},
  issn      = {13807501},
  note      = {Performance efficiency;Performance measurements;Performance testing;Software performance engineerings;Software performance testing;Technical limitations;Test Automation;Virtualization technologies;},
  abstract  = {In this paper, we propose the towards virtualized and automated software performance test architecture. In general, test engineers use the public performance testwares such as Load Runner, Silk Performer to validate the performance efficiency of their own systems. In case that they do not allowed to use the performance testwares due to the technical limitations in the testwares, most testers should perform the testing in manually. According to the waste of computer and human resources resulted from the situation, we need to propose the test automation scheme by using the virtualization technology to prevent the dissipation in the test environment which has limited resources. The system architecture considered efficient usage of computer resources and test automation to reduce human acts are addressed mainly in this paper. we describe our proposed method which deals with the system architecture and test automation procedures. In our system architecture, we will show how to use the virtual machines and the types of the virtual machines for performance measurement. In addition, the six steps of the test automation are introduced for the automated testing procedures. Finally, a number of experiments show that the proposed schemes allow offering the possibility for automated software performance testing by using the virtualization.<br/> &copy; 2013, Springer Science+Business Media New York.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Software testing},
  keywords  = {Automation;Computer architecture;Network security;Virtual machine;Virtual reality;Virtualization;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/s11042-013-1536-3},
}

@InProceedings{Gold2004a,
  author    = {Gold, Kenn and Brown, Alison},
  title     = {Architecture and performance testing of a software GPS receiver for space-based applications},
  year      = {2004},
  volume    = {4},
  pages     = {2404 - 2415},
  address   = {Big Sky, MT, United states},
  note      = {Digital beam steering technology;Goddard space flight center (GSFC);Precision applications;Satellite signals;},
  abstract  = {Space-based GPS technology presents significant challenges over Earth-based systems. These include visibility issues for rotating platforms and tracking of GPS satellites from spacecraft that are in higher orbits than the GPS, realtime resolution of carrier phase ambiguities, and different dynamics during various mission phases. NAVSYS has developed a software GPS receiver that makes use of 3-dimensional Digital Beam Steering technology and inertial aiding to address these issues. This approach offers several advantages including all around visibility for spinning satellites, tracking of weak GPS signals, reduction of multipath, and reprogrammability to accommodate different mission phases. Additionally, a suite of simulation tools based around the NAVSYS Matlab Toolbox and Advanced GPS Hybrid Simulation products have been built to allow testing for simulated space environments. The receiver architecture and test tools are described in this paper.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {1095323X},
  journal   = {IEEE Aerospace Conference Proceedings},
  key       = {Global positioning system},
  keywords  = {Computer architecture;Computer simulation;Computer software;Orbits;Satellites;Signal processing;Signal to noise ratio;Space applications;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/AERO.2004.1368035},
}

@InProceedings{Jayasinghe2012,
  author    = {Jayasinghe, Deepal and Swint, Galen and Malkowski, Simon and Li, Jack and Wang, Qingyang and Park, Junhee and Pu, Calton},
  title     = {Expertus: A generator approach to automate performance testing in IaaS clouds},
  year      = {2012},
  pages     = {115 - 122},
  address   = {Honolulu, HI, United states},
  note      = {Aspect;Code Generation;Datacenter;Emulab;IaaS;Multi-tier;Open Cirrus;Performance;Template;},
  abstract  = {Cloud computing is an emerging technology paradigm that revolutionizes the computing landscape by providing on-demand delivery of software, platform, and infrastructure over the Internet. Yet, architecting, deploying, and configuring enterprise applications to run well on modern clouds remains a challenge due to associated complexities and non-trivial implications. The natural and presumably unbiased approach to these questions is thorough testing before moving applications to production settings. However, thorough testing of enterprise applications on modern clouds is cumbersome and error-prone due to a large number of relevant scenarios and difficulties in testing process. We address some of these challenges through Expertus - -a flexible code generation framework for automated performance testing of distributed applications in Infrastructure as a Service (IaaS) clouds. Expertus uses a multi-pass compiler approach and leverages template-driven code generation to modularly incorporate different software applications on IaaS clouds. Expertus automatically handles complex configuration dependencies of software applications and significantly reduces human errors associated with manual approaches for software configuration and testing. To date, Expertus has been used to study three distributed applications on five IaaS clouds with over 10,000 different hardware, software, and virtualization configurations. The flexibility and extensibility of Expertus and our own experience on using it shows that new clouds, applications, and software packages can easily be incorporated. &copy; 2012 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - 2012 IEEE 5th International Conference on Cloud Computing, CLOUD 2012},
  key       = {Infrastructure as a service (IaaS)},
  keywords  = {Application programs;Automation;Clouds;Codes (symbols);Program compilers;Scalability;Software testing;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/CLOUD.2012.98},
}

@Article{Tang2013,
  author    = {Tang, Jingfan and Zhu, Qin and Jiang, Ming},
  title     = {Towards an interface-based automation testing framework for sirverlight applications},
  journal   = {Information Technology Journal},
  year      = {2013},
  volume    = {12},
  number    = {4},
  pages     = {829 - 834},
  issn      = {18125638},
  note      = {Automation testing;GUI testing;Human actions;Model based testing;Model tests;Open sources;Operation process;Software applications;Spec Explorer;Test case;Test execution;Test models;WebAii;},
  abstract  = {Nowadays software applications are increasingly becoming large in scale and complexity, thus, Graphical User Interface (GUI) testing plays a formal important role in ensuring the correctness and reliability of software applications. A variety of approaches in the area of GUI testing have emerged in recent years. One notable trend is Model-Based Testing (MBT) which creates an abstract test model that simulates the anticipated behavior of the System Under Testing (SUT) by using some software generated tools to generate model tests. This study highlights the designing as well as the presentation of a new automation testing framework for silverlight applications with particular focuses upon the integration of the Spec Explorer based MBT with a free web framework called WebAii. Both of the tools are available as open source. Spec Explorer can be used to generate the test cases automatically, while WebAii is used to simulate human action and operation processes to complete the test execution in an automated way. &copy; 2013 Asian Network for Scientific Information.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Software testing},
  keywords  = {Automation;Graphical user interfaces;Software reliability;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.3923/itj.2013.829.834},
}

@Article{Lehotzky2001,
  author    = {Lehotzky, P. and Trescher, C.},
  title     = {LCC/RAM performance test for Wiener Linien tramway stock using the CaLCC\&reg data collection system module},
  journal   = {ZEV-Zeitschrift fuer Eisenbahnwesen und Verkehrstechnik - Journal for Railway and Transport},
  year      = {2001},
  volume    = {125},
  number    = {9-10},
  pages     = {371 - 373},
  issn      = {09410589},
  note      = {Bonus-penalty system;Data collection system module;Life cycle cost;},
  abstract  = {A software tool is presented which makes it possible to store and evaluate the life cycle cost (LCC) data of a vehicle fleet. Wiener Linien use this tool for the purpose of implementing a performance test and for determining parameters for the application of a bonus/penalty system that has been agreed upon between the vehicle manufacturer and operator.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Railroad rolling stock},
  keywords  = {Computer aided software engineering;Cost benefit analysis;Data acquisition;Data reduction;Information retrieval systems;Performance;},
  language  = {German},
}

@Article{Wang2011,
  author    = {Wang, Guohua and Cui, Yan and Wang, Shuo and Meng, Xiaofeng},
  title     = {Design and performance test of spacecraft test and operation software},
  journal   = {Acta Astronautica},
  year      = {2011},
  volume    = {68},
  number    = {11-12},
  pages     = {1774 - 1781},
  issn      = {00945765},
  note      = {Electrical ground support equipments;Main test processor;Management capabilities;Open architecture systems;Performance tests;Process management;Processing capability;Space technologies;},
  abstract  = {Main test processor (MTP) software is the key element of Electrical Ground Support Equipment (EGSE) for spacecraft test and operation used in the Chinese Academy of Space Technology (CAST) for years without innovation. With the increasing demand for a more efficient and agile MTP software, the new MTP software was developed. It adopts layered and plug-in based software architecture, whose core runtime server provides message queue management, share memory management and process management services and forms the framework for a configurable and open architecture system. To investigate the MTP softwares performance, the test case of network response time, test sequence management capability and data-processing capability was introduced in detail. Test results show that the MTP software is common and has higher performance than the legacy one. &copy; 2011 Elsevier Ltd. All rights reserved.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Software testing},
  keywords  = {Aerospace ground support;Computer architecture;Data handling;Ground supports;Information management;Network architecture;Spacecraft equipment;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.actaastro.2011.02.002},
}

@InProceedings{Gois2017,
  author    = {Gois, Nauber and Porfirio, Pedro and Coelho, Andre},
  title     = {A Multi-objective Metaheuristic Approach to Search-Based Stress Testing},
  year      = {2017},
  pages     = {55 - 62},
  address   = {Helsinki, Finland},
  note      = {Concurrent requests;Multi objective algorithm;Multi-objective metaheuristics;NSGA-II algorithm;Pareto frontiers;Search-based software testing;Single objective optimization;Stress test;},
  abstract  = {Nowadays applications need to deal with a large number of concurrent requests. These systems must be stress tested to ensure that they can function correctly under a load. In this context, a research field called Search-based Software Testing has become increasingly important. Most of the search-based test methods are based on single objective optimization. In the case of multi-objective optimization of tests, usually researchers assign different weight values to different objectives and combine them as a single objective. This research paper verifies the use of a multi-objective algorithm in search-based stress testing. The NSGA-II algorithm was implemented in the IAdapter tool using the jMetal framework. IAdapter is a JMeter plugin used for performing search-based stress tests. jMetal is an object-oriented Java-based framework for multi-objective optimization with metaheuristics. One experiment was conducted to validate the proposed approach. &copy; 2017 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {IEEE CIT 2017 - 17th IEEE International Conference on Computer and Information Technology},
  key       = {Multiobjective optimization},
  keywords  = {Heuristic methods;Object oriented programming;Optimization;Software testing;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/CIT.2017.19},
}

@InProceedings{Chen2008,
  author    = {Chen, Shiping and Moreland, David and Nepal, Surya and Zic, John},
  title     = {Yet another performance testing framework},
  year      = {2008},
  pages     = {170 - 179},
  address   = {Perth, WA, Australia},
  note      = {Application logic;Java platforms;Open source tools;Performance testing;Performance testing framework;Performance tests;Testing framework;Whole life cycles;},
  abstract  = {Performance testing is one of the vital activities spanning the whole life cycle of software engineering. While there are a consideruble number of performance testing products and open source tools available, they are either too expensive and complicated for small projects, or too specific and simple for diverse performance tests. This paper presents a general-purpose testing framework for both simple and small, and complicated and large-scale performance testing. Our framework proposes an abstraction to facilitate performance testing by separating the application logic from the common performance testing functionalities. This leads to a set of general-purpose data models and components, which form the core of the framework. The framework has been prototyped on both.NET and Java platforms and was used for a number of performance-related projects. &copy; 2008 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of the Australian Software Engineering Conference, ASWEC},
  key       = {Software testing},
  keywords  = {Life cycle;Open source software;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ASWEC.2008.4483205},
}

@InProceedings{Luo2014,
  author    = {Luo, Jun and Yang, Wei},
  title     = {A performance testing tool for source code},
  year      = {2014},
  volume    = {490-491},
  pages     = {1553 - 1559},
  address   = {Beijing, China},
  note      = {Code analysis;Memory consumption;Open source projects;Performance optimizations;Performance problems;Performance testing;Software performance;Static analysis method;},
  abstract  = {With the rapid development of the information age, computer software develops toward systematization and complication. In application areas such as commerce, finance and medical treatment, the performance of software is attracting more and more attention which even becomes one of the important factors to determine whether users are willing to use a piece of software. Currently, static checking tools are mostly designed to check the code errors but pay little attention to the performance problems. In order to detect the defects in source code that may cause performance problems, this paper designs and achieves a performance testing tool based on static analysis method. The experiments of detecting several open source projects using our testing tool demonstrate that it can quickly find the defects in source code with high accuracy rate. The result of defection removing shows that it can significantly reduce the memory consumption of software, and it can effectively improve software performance. &copy; (2014) Trans Tech Publications, Switzerland.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {16609336},
  journal   = {Applied Mechanics and Materials},
  key       = {Static analysis},
  keywords  = {Application programs;Computer programming languages;Defects;Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.4028/www.scientific.net/AMM.490-491.1553},
}

@InProceedings{Grossman1994,
  author    = {Grossman, D. and Staton, C.J. and Bailey, B. and McCabe, M.C. and Latts, A. and Frieder, O. and Bock, C. and Roberts, D.},
  title     = {Prototype-driven approach to application-level performance testing: A case study of a large finance application},
  year      = {1994},
  pages     = {125 - 135},
  address   = {Washington, DC, USA},
  note      = {Application level testing;Database management systems (DMBS);Initial production usage performance problems;Performance tuning;System level testing;Teleprocessing network simulator (TPNS);},
  abstract  = {We present an approach to application-level performance testing. This uses a popular test tool, TPNS (Teleprocessing Network Simulator) to simulate performance of an application. Our approach hinges upon a simple prototype to verify that the system performance falls within acceptable bounds. Once the initial prototype is developed, detailed tuning may take place. We present a case study in which we tested the performance of a large finance application. This approach led to critical performance tuning improvement. Due to this improvement, the average user response time in our simulations was reduced from 30 seconds to under 1.5 seconds. This simulation has been verified by actual system usage during the first two months of live operation in which the average response time has indeed been under 1.5 seconds.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of the Symposium on Assessment of Quality Software Development Tools},
  key       = {Database systems},
  keywords  = {Computer aided analysis;Computer networks;Computer operating systems;Computer simulation;Computer software selection and evaluation;Data processing;Product design;Program diagnostics;Response time (computer systems);Standards;Systems analysis;},
  language  = {English},
}

@Article{Jia2011,
  author    = {Jia, Hong-Shu and Hong, Guo-Tong and Chen, Hou-Lei},
  title     = {Design and performance testing of moving coil linear motor for Stirling generator},
  journal   = {Dianji yu Kongzhi Xuebao/Electric Machines and Control},
  year      = {2011},
  volume    = {15},
  number    = {12},
  pages     = {21 - 25},
  issn      = {1007449X},
  note      = {Constant magnetic fields;Experimental system;Finite element simulations;Finite element software;Frequency;Moving coils;Output characteristics;Stirling generators;},
  abstract  = {In order to develop linear motor for free piston Stirling generator, moving coil linear motor structure was designed. Magnetic field of the motor was obtained by finite element simulation and testing, and the output characteristic were studied. The calculated results of magnetic field using the finite element software ANSYS meet the experimental results, and the results show that magnetic flux density achieved 626 mT at the air-gap is 6 mm. Experimental system for testing output characteristics of the moving coil motor was established. Output characteristics testing of moving coil linear motor was conducted. The results show that effective output voltage increases linearly with displacement at constant magnetic field strength, coil length and moving frequency. The slope is the function of coil impedance and external load. Moreover, the output voltage increases at load resistance under conditions of same input voltage at a constant coil displacement. The calculatied natrual frequency is 16.5 Hz. The output current of the motor decreases with the increasing of work frequency away from the system natural frequency, and the efficiency of the system is 20%.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Linear motors},
  keywords  = {Finite element method;Magnetic devices;Magnetic fields;Magnetic flux;Pistons;},
  language  = {Chinese},
}

@InProceedings{Lee2006,
  author    = {Lee, Jongyoung and Kim, Naesoo},
  title     = {Performance test tool for RFID middleware: Parameters, design, implementation, and features},
  year      = {2006},
  volume    = {1},
  pages     = {149 - 152},
  address   = {Phoenix Park, Korea, Republic of},
  note      = {Performance test tool;RFID technology;Software testing;},
  abstract  = {Recently, Major software vendors(such as Sun, IBM, Oracle) introduce RFID middleware product which process RFID tag data cause of extending RFID related technology and application. RFID middleware which receives tag data from reader, internal process receiving data, and transmit result to application acts key role of applying RFID technology to application. In this paper, we define parameters for RFID middleware performance and introduce design of performance test tool of RFID middleware.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {8th International Conference Advanced Communication Technology, ICACT 2006 - Proceedings},
  key       = {Middleware},
  keywords  = {Computer software;Data reduction;Identification (control systems);Parameter estimation;},
  language  = {English},
}

@InProceedings{Wen2009,
  author    = {Wen, Huaming and Bailey, Wendell and Goddard, Kevin and Al-Mosawi, Maitham and Beduz, Carlo and Yang, Yifeng},
  title     = {Performance test of a 100 kW HTS generator operating at 67 K-77 K},
  year      = {2009},
  volume    = {19},
  number    = {3},
  pages     = {1652 - 1655},
  note      = {Bscco coils;Harmonic characteristics;High temperature superconducting;HTS motors;Liquid nitrogen temperature;Performance tests;Rotating superconducting machines;Superconducting winding;},
  abstract  = {A systematic test program is in progress to fully characterize a 100 kW HTS synchronous generator which was successfully constructed in 2004. The machine was one of the first HTS synchronous generator/motors to operate at liquid nitrogen temperatures while achieving a power rating relevant to practical application. It has a conventional 3-phase stator and a cold rotor with a magnetic core and a superconducting winding consisting of 10 HTS Bi2223 pancake coils separated by magnetic flux diverters. The test program includes a series of tests at various speeds, field currents and temperatures (65 K-77 K) with the machine in open circuit to determine the critical currents of the HTS rotor, the waveform and harmonic characteristics of generated voltage at different levels of iron saturation. Stationary measurements of the rotor critical current are carried out using dc current in the stator windings to quantify the influence of stator field on the performance of the superconducting winding. The voltages and temperatures of the rotor are measured using a radio frequency telemetry system. &copy; 2009 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {10518223},
  journal   = {IEEE Transactions on Applied Superconductivity},
  key       = {Electric generators},
  keywords  = {AC generator motors;High temperature superconductors;Rotors (windings);Software testing;Stators;Superconducting coils;Superconducting devices;Synchronous generators;Winding;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/TASC.2009.2017832},
}

@Article{Xu2013,
  author    = {Xu, Yonggang and Ren, Guoqiang and Wu, Qinzhang and Wu, Wei},
  title     = {High speed NAND Flash image recorder load test system},
  journal   = {Hongwai yu Jiguang Gongcheng/Infrared and Laser Engineering},
  year      = {2013},
  volume    = {42},
  number    = {10},
  pages     = {2858 - 2864},
  issn      = {10072276},
  note      = {Climbing search;Exponential regression;Gigabit Ethernet;Log-normal distribution;NAND Flash;Recording systems;Search Algorithms;Test systems;},
  abstract  = {In order to determine the stability of the NAND Flash image recorder and the peak recording speed, reducing the amount of manual testing, a new load test system was designed. To solve the problem of stability test, speed load model based on exponential regression and test time control model based on the lognormal distribution were proposed. To test the peak recording speed, the test methods combining hardware with software based on climbing search algorithm and speed dichotomy was praser. The hardware data generator was designed, whose speed was software adjustable according to valid data duty cycle mechanism. Climbing search algorithm rough determined the peak recording speed range, and then the speed dichotomy approached the peak recording speed; the test report was transferred to PC for display through the serial port and Gigabit Ethernet. Experimental results show that the speed load regulation accuracy is up to 0.1 MB/s; the speed load range is from 0 to 1600 MB/s; verification of read back data using hardware has no clock delay; the tested NAND Flash recorder connecting with 8 SLC NAND Flash chips has the peak recording speed of 240.12 MB/s; under the speed load 200 MB/s, the NAND Flash record controller can work well continuously for more than 24 h. The load test system can be used for load test of other transmission and recording system because of its universal architecture.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Search engines},
  keywords  = {Convergence of numerical methods;Hardware;Image recording;Learning algorithms;Load testing;Software testing;Speed;System stability;},
  language  = {Chinese},
}

@Article{Wu2013,
  author    = {Wu, Weibin and Zhao, Ben and Hong, Tiansheng and Zhao, Wenfeng and Deng, Xiaoling and Zhu, Yuqing and Ruan, Shaomeng},
  title     = {Performance testing system of trailer axle based on virtual instrument},
  journal   = {Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering},
  year      = {2013},
  volume    = {29},
  number    = {SUPPL1},
  pages     = {25 - 31},
  issn      = {10026819},
  note      = {Automotive technology;Average relative error;Data acquisition cards;Intensity;LabViEW;Linear relationships;Maximum displacement;Performance tests;},
  abstract  = {The axle is one of the most important components directly relating the safety operation of vehicles. However, the testing method of axle on site used in China is backward and inefficient, while checking failures occur now and then. But the theory of reliability design of fatigue, which has been well developed, is difficult to be applied to the test of axle on site. In recent years, the computing automotive technology is advocated at abroad to solve the complicated problem of how to put the reliability analysis of fatigue into practice. This paper realized the 3D simulation of testing system through the Pro/E software as well as constructed the system, which was based on the trailer axle testing system prototype. The system hardware was comprised of support, guide, sensors, AC servo motor and servo driver; meanwhile, the system software adapted the modularized idea in order to divide the monolithic construction into five parts, including main operation control module and 4 testing modules. Every testing module was constituted by 5 submodules. The system software program was written by LabVIEW. It drove the linkage device by controlling the rotation of the servo motor and loaded the simulated axle through two pressure heads, then the displacement and pressure were collected as feedback through the data acquisition card. The displacement-voltage linear relationship of A/B pressure head was obtained through experiments on displacement sensors before system test. By calibrating the straight-line equation, the result was that the maximum locating relative error is 5.207%, and the absolute value of average relative error was 1.4%. The voltage-load linear relationship of A/B pressure head was obtained by accurate positioning of load. Analyzed by software SPSS, in the equation of the load stress and voltage linear regression, the result was that R &gt; 0.994, Sig. &lt; 0.05, thus regression was significant. According the constructed testing system, the performance of fatigue, stiffness, strength, and stress of the simulated axle were tested and analyzed. In fatigue test, flaw occurred after 821 times vibration and efficacy was lost after 1067 times vibration; in stiffness test, spot D almost stayed unchanged and the displacements of spot C and E ranged from 60 to 63 mm; in strength test, the maximum displacement of sensor E was 66.622 mm; in stress test, the maximum displacement of spot E was 66.751 mm, and the maximum stress was 259.444 MPa. The system was steady. The simulated test had been lasting for one month and no bug was found. Therefore, the result generally meets the project requirement.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Axles},
  keywords  = {AC generator motors;Computer software;Digital devices;Fatigue of materials;Fatigue testing;Instruments;Reliability theory;Sensors;Servomotors;Stiffness;},
  language  = {Chinese},
  url       = {http://dx.doi.org/10.3969/j.issn.1002-6819.2013.z1.004},
}

@InProceedings{Nieminen2009,
  author    = {Nieminen, Mikko and Raty, Tomi and Palokangas, Jukka},
  title     = {Stress testing the Logical Decision Making Server of a surveillance system},
  year      = {2009},
  pages     = {98 - 103},
  address   = {Porto, Portugal},
  note      = {Automated decision making;Component;Current generation;Logical decisions;Physical locations;Prototype implementations;Stress Testing;Surveillance systems;},
  abstract  = {The current generation of distributed and automated physical location surveillance systems faces high demands for robustness and reliability. We present and evaluate the design of the Logical Decision Making Server (LDMS), a rule-based automated decision making component used in the Single Location Surveillance Point (SLSP) system. To validate the robustness of the LDMS design for operation in the SLSP environment, we design and conduct a stress test experiment in which large load of TCP/IP input messages is sent instantaneously to the LDMS prototype implementation using the Nethawk EAST software. The stress test results are compared to measurements obtained during a real-life scenario. The LDMS is observed to withstand a significant amount of load without crashing, and its performance is can be considered sufficient for the SLSP system needs. A detailed analysis of results however shows an increase in the latency resulting from an extreme temporal load. We identify potential areas in the design to be improved if demands for higher response rates arise. The research is based on the construction of the related publications and technologies, and the results are established from the testing and validation of the implemented LDMS within the SLSP system. &copy; 2009 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {1st International Conference on Advances in System Testing and Validation Lifecycle, VALID 2009},
  key       = {Decision making},
  keywords  = {Life cycle;Monitoring;Security systems;Software testing;Space surveillance;System theory;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/VALID.2009.16},
}

@InProceedings{GeethaDevasena2017,
  author    = {Geetha Devasena, M.S. and Krishna Kumar, V. and Kingsy Grace, R.},
  title     = {LTTC: A load testing tool for cloud},
  year      = {2017},
  volume    = {508},
  pages     = {689 - 698},
  address   = {Ahmedabad, India},
  note      = {Cloud services;Cloud systems;Cloud testing;Maximum load;Running-in;},
  abstract  = {Software testing is the process of software engineering to free the software from bugs. Load testing is one of the techniques in software testing and is used to find the maximum load that software can handle without affecting its performance. Load testing is used to test the cloud services that are running in a cloud. All the resources in a cloud are used by the cloud users based on their demand. Using cloud, it is easy to gather the required load for a particular application by forming clusters. If the required load is coming from different clusters and it is not known quantitatively then the problem of load balancing is raised. The proposed load testing tool avoids the problem of getting unequal loads coming from different clusters by distributing the same amount of load to all the clusters. Also the proposed load testing tool for cloud is used to find the maximum number of simultaneous users for a particular cloud system is to handle. &copy; Springer Nature Singapore Pte Ltd. 2017.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {21945357},
  journal   = {Advances in Intelligent Systems and Computing},
  key       = {Load testing},
  keywords  = {Program debugging;Resource allocation;Software engineering;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-981-10-2750-5_70},
}

@InProceedings{Krejcar2011,
  author    = {Krejcar, Ondrej and Motalova, Leona},
  title     = {Home care web services evaluation by stress testing},
  year      = {2011},
  volume    = {171 CCIS},
  pages     = {238 - 248},
  note      = {Developing process;Developing solutions;Hardware solutions;Software applications;SQL servers;Stress Testing;Test applications;Web service interface;},
  abstract  = {Development of software applications result in complete application or solution. The last phase of developing process is the final testing of developed solution. The goal of our paper has focused on this problem in case of web services. The developed testing application can be used for any other software solutions with web service interface. The developed test environment, including application developed for the stress testing is based on Microsoft .NET Framework technology. Our stress testing application allows testing of selected problem areas to find any limitations before the tested developing solution will be set up at customer. By the help of our test application, the hardware solution for the server was selected on the base of selected home care agency needs. &copy; 2011 Springer-Verlag.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {18650929},
  journal   = {Communications in Computer and Information Science},
  key       = {Web services},
  keywords  = {Application programs;Hardware;Mobile devices;Response time (computer systems);Software testing;Websites;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-22729-5_20},
}

@InProceedings{Merton1997,
  author    = {Merton, Joseph K.},
  title     = {Performance testing in a client-server environment},
  year      = {1997},
  volume    = {1},
  pages     = {594 - 601},
  address   = {Orlando, FL, USA},
  note      = {Client/server environment;},
  abstract  = {As an enterprise grows and adapts to changing business conditions, performance of client-server systems is affected by workload changes caused by growth, functional application changes, and configuration changes in hardware, software, or network topology. This paper presents a case study of the implementation of performance testing in a client-server environment. It describes performance testing objectives, evaluation and selection of performance testing software, construction of a performance testing environment, construction and execution of test cases, and evaluation of results.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {CMG Proceedings},
  key       = {Online systems},
  keywords  = {Computer aided software engineering;Computer networks;Computer software selection and evaluation;Response time (computer systems);Systems analysis;},
  language  = {English},
}

@InProceedings{Hao2010,
  author    = {Hao, Dan and Chen, Yinghui and Tang, Fan and Qi, Feng},
  title     = {Distributed agent-based performance testing framework on Web Services},
  year      = {2010},
  pages     = {90 - 94},
  note      = {Agent based;Allocation strategy;Distributed agents;Distributed loads;Kernel modules;Load allocation;Performance testing;Performance testing framework;},
  abstract  = {Web Services are applied widely in the field of information technology, and performance testing for Web Services applications has become an important problem. This paper introduces the method of performance testing, and proposes a framework of agent-based performance testing on Web Services, which includes TestFlow Generator, Scenario Creator, Test Manager, Load Generation Agent and Test Analyzer. And the implementation of kernel modules in the framework is introduced especially. To realize the load allocation to distributed Load Generation Agents from Test Manager, a queue-based allocation strategy is given. &copy; 2010 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings 2010 IEEE International Conference on Software Engineering and Service Sciences, ICSESS 2010},
  key       = {Web services},
  keywords  = {Load testing;Managers;Software engineering;Websites;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICSESS.2010.5552290},
}

@InProceedings{Zhang2011c,
  author    = {Zhang, Li and Chen, Yinghui and Tang, Fan and Ao, Xiong},
  title     = {Design and implementation of cloud-based performance testing system for web services},
  year      = {2011},
  pages     = {875 - 880},
  address   = {Harbin, China},
  note      = {Cloud-based;Computing clouds;Design and implementations;Distributed systems;Dynamic migration;Performance testing;Performance tests;Software development process;},
  abstract  = {Nowadays testing plays an important role in software development process. While software testing is expensive and time-consuming, sufficient testing is hard, especially for a distributed system using web services technique in the real circumstance. The development of cloud computing provides us new ideas to solve these testing problems. To address these issues, we propose a framework which integrates cloud computing and performance testing technologies. In this paper, first we present the architecture of the cloud-based performance testing system for web services (CPTS), which is a portable, extensible and easy-to-use framework for generating and submitting test workloads to computing clouds. Then, we show the process how to use CPTS to run a performance test and present the concept of dynamic migration in CPTS. Finally, we present our experiences with CPTS in Amazon EC2. We found that the CPTS allows a user to easily set up and test a web services system on the cloud and improve test effectively. &copy; 2011 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of the 2011 6th International ICST Conference on Communications and Networking in China, CHINACOM 2011},
  key       = {Web services},
  keywords  = {Cloud computing;Software design;Software testing;Testing;Virtual machine;Websites;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ChinaCom.2011.6158278},
}

@InProceedings{Li2016,
  author    = {Li, Dong and Xiong, Jing and Yang, Chunhui},
  title     = {Study of performance testing of information system based on domestic CPU and OS},
  year      = {2016},
  pages     = {112 - 116},
  address   = {Wuhan, Hubei, China},
  note      = {Domistic Operating System(OS);Hardware and software;Improved scheme;Infrastructure software;Performance testing;Performance tests;Test tools;User experience;},
  abstract  = {In order to evaluate the performance of of information system based on domestic CPU and OS, through the introduction of the background of basic hardware and software based on domestic, we expound the domestic information system performance testing principle and method, according to the testing results of existing mature commercial performance testing tool LoadRunner can not reflect the user experience of time, and can not be directly used for testing the information system which based on domestic CPU/OS, this paper put forward the two kinds of testing schemes that base on user experience of LoadRunner and JMeter domestic information system performance test, and test two kinds of improved schemes, through the comparison of the test data and the user experience time of the two schemes, the variance of the test scheme based on JMeter is smaller than LoadRunner test scheme 70.49%. The results show that the test results of the JMeter scheme are more close to the user experience than LoadRunner. &copy; 2016 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - 2016 3rd International Conference on Trustworthy Systems and Their Applications, TSA 2016},
  key       = {Software testing},
  keywords  = {Information systems;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/TSA.2016.27},
}

@InProceedings{Xie2017,
  author    = {Xie, Qiyou},
  title     = {A new method for SSD black-box performance test},
  year      = {2017},
  pages     = {1116 - 1122},
  address   = {St. Petersburg, Russia},
  note      = {Embedded application;Excitation signals;Performance tests;Protocol analyzers;Solid state disks (SSD);Testing software;Time parameter;Trim mechanisms;},
  abstract  = {In the past decade, NAND Flash has stood out from numerous non-volatile storage mediums. The NAND Flash based Solid State Disk (SSD) has been widely used in many storing required fields such as embedded applications and data center. A new and efficient SSD black-box performance test method is revising in this paper. The designed test system contains time parameter getter, excitation signal generator, buffer unit, write/read controller and SSD. With the application of the proposed method, not only the influence of TRIM mechanism could been analyzed, but also the test precision is increased significantly. To verify the validity and performance of our test system, the IOPS, response time and write/read bandwidth of the universal testing software (IOMETER, HDTUNE, etc.) and SATA protocol analyzer are presented and compared with our method in detail.<br/> &copy; 2018 Electromagnetics Academy. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {15599450},
  journal   = {Progress in Electromagnetics Research Symposium},
  key       = {Software testing},
  keywords  = {Flash-based SSDs;Memory architecture;NAND circuits;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/PIERS.2017.8261912},
}

@InProceedings{Gillies2014,
  author    = {Gillies, K. and Bhate, Yogesh},
  title     = {Performance testing open source products for the TMT event service},
  year      = {2014},
  volume    = {9152},
  pages     = {The Society of Photo-Optical Instrumentation Engineers (SPIE) -},
  address   = {Montreal, QC, Canada},
  note      = {Commercial market;Distributed systems;Open source products;Performance requirements;Performance testing;Performance tests;Software products;Software services;},
  abstract  = {The software system for TMT is a distributed system with many components on many computers. Each component integrates with the overall system using a set of software services. The Event Service is a publish-subscribe message system that allows the distribution of demands and other events. The performance requirements for the Event Service are demanding with a goal of over 60 thousand events/second. This service is critical to the success of the TMT software architecture; therefore, a project was started to survey the open source and commercial market for viable software products. A trade study led to the selection of five products for thorough testing using a specially constructed computer/network configuration and test suite. The best performing product was chosen as the basis of a prototype Event Service implementation. This paper describes the process and performance tests conducted by Persistent Systems that led to the selection of the product for the prototype Event Service. &copy; 2014 SPIE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {0277786X},
  journal   = {Proceedings of SPIE - The International Society for Optical Engineering},
  key       = {Open systems},
  keywords  = {Commerce;Middleware;Open source software;Software design;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1117/12.2057148},
}

@InProceedings{Kim2009a,
  author    = {Kim, Gwang-Hun and Moon, Hui-Choun and Song, Gi-Pyeung and Shin, Seok-Kyu},
  title     = {Software performance testing scheme using virtualization technology},
  year      = {2009},
  address   = {Fukuoka, Japan},
  note      = {Computer resources;Computing resource;Performance testing;Resource consumption;Software performance engineerings;Software performance testing;Test Automation;Virtualization technologies;},
  abstract  = {In this paper, we propose software performance testing scheme using virtualization technology. Generally, people have used software performance testing tool such as load runner and silk performer. However, people should perform software performance testing manually in case of the situation that people cannot use testing tool. It needs a lot of resources such as human resource and computing resource. Therefore, we propose software performance testing scheme using virtualization technology to reduce resource consumption. Proposed scheme can reduce computer resource consumption because virtualization technology can make a number of virtual computers with a small number of physical computers. Also proposed scheme can reduce human resource consumption because, in proposed scheme, management computer can control keyboard and mouse of virtual computers automatically. Simulation result shows that proposed scheme has possibility to be used for software performance testing. &copy; 2009 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of the 4th International Conference on Ubiquitous Information Technologies and Applications, ICUT 2009},
  key       = {Software testing},
  keywords  = {Computer resource management;Human resource management;Load testing;Virtual reality;Virtualization;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICUT.2009.5405721},
}

@Article{Bhatt2013,
  author    = {Bhatt, Alok N. and Babu Rajasekhara, M. and Bhatt, Anuja J.},
  title     = {Automation testing software that aid in efficiency increase of regressionprocess},
  journal   = {Recent Patents on Computer Science},
  year      = {2013},
  volume    = {6},
  number    = {2},
  pages     = {107 - 114},
  issn      = {18744796},
  note      = {Client server;Cost effective;GUI-Web objects;Multiple platforms;Object oriented;Time-efficient;},
  abstract  = {Accuracy of any software release to the market depends on how efficiently it has been debugged. Debugging is a systematic procedure, used to identify and figure out the cause of defects or any anomaly that the software has and make the software behave as expected. The issues generated by the customer of any company are logged into a database, wherein issues are picked up selected, solved and reverted back to the customers. After solving an issue, it may happen that the issue affects other components which results into a greater number of bugs. The resultant issues are called regression issues. The objective of this paper is to propose and implement a client-server, object-oriented, multiple plat form supporting frame work called RATS Framework which automates the process of regression and thereby helps debug engineers to solve time-consuming regression issues at a faster rate. It automates the process with the help of web-scrapping algorithm (W-S-A) that includes HTML/XML parsing to extract the needed content in the form of GUI-Web Objects, than using Network-Binary Search Algorithm (N/W-BS-A) and Change Finder Algorithm, a variant of Binary Search method, RATS finds out the nearest pass/fail driver build and change in the driver build that cause the new defect in the driver respectively. Because the RATS Framework does this at runtime, client-server approach has to be followed making use of Remote Identification and Installation-Algorithm. Hence RATS framework is a cost effective and time efficient approach for regression issues. The present article has the discussion of few of the patents relevant to automation testing software. &copy; 2013 Bentham Science Publishers.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Program debugging},
  keywords  = {Algorithms;Cost effectiveness;Defects;Graphical user interfaces;Object oriented programming;Rats;Regression analysis;Software testing;},
  language  = {English},
}

@InProceedings{Khandelwal2017,
  author    = {Khandelwal, Harita and Mankodi, Parthesh and Prajapati, Ritesh},
  title     = {Enhancement of automation testing system using Yocto project},
  year      = {2017},
  volume    = {2017-January},
  pages     = {697 - 700},
  address   = {Coimbatore, India},
  note      = {Automation testing;Bitbake;Effective performance;Mass production;Open embedded;PYTHON language;Software applications;Yocto project;},
  abstract  = {Nowadays, in industries, Testing has become one of the important tasks. Testing is necessary for an effective performance of product and software applications. When companies having a mass production of hardware boards, it is necessary to do testing of each and every module of hardware like SPI, UART, GPIO, PWM, ADC, USB, Ethernet. If we do testing manually then it will significantly take more time, which we can be reduced by automation testing. But the solution is not an automation testing because automation testing also requires the same amount of system, for example for 300 boards 300 system is required. The only difference in manual and automation testing is that in automation testing it will require less human effort. Now we are focusing more on developing a solution in which many tests can be done on one single system i.e. for 300 boards only one system is required for testing hence this problem can be solved by Yocto Project. Yocto project have build the tool named Bitbake which is written in Python language, which works on multithreading and scheduling so that simultaneously you can test more boards on a single system. In this paper we did automation testing of GPIO pins using Yocto project.<br/> &copy; 2017 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of the International Conference on Electronics, Communication and Aerospace Technology, ICECA 2017},
  key       = {Software testing},
  keywords  = {Application programs;Automation;Hardware;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICECA.2017.8203630},
}

@InProceedings{Stankovic2006,
  author    = {Stankovic, Nenad},
  title     = {Patterns and tools for performance testing},
  year      = {2006},
  pages     = {152 - 157},
  address   = {East Lansing, MI, United states},
  note      = {Distributed tools;Heterogeneous communication networks;Object oriented distributed programming;},
  abstract  = {The growth of software applications in size and complexity is being followed by a number of specific nonfunctional requirements such as portability, interoperability, and availability on various platforms. Most often, these have been addressed by middleware or programming environment. In addition, easy customizability, adaptability, and sharing of components facilitates the development cycle. These should be understood and applied in a broader sense, i.e. to byproducts created during the development process such as programs for functional and performance testing. Much time is spent on developing test programs but their quality and quality of thus obtained results varies largely if the process is not standardized and automated. In this paper we present our experience with performance testing of a large scale suite of gateways that are used for the seamless integration of heterogeneous communication networks. We analyze the commercial and public domain tools for load generation and motivate our decision to define an in-house framework and build a distributed tool for performance, testing that is also not restricted by licensing issues and is readily available to everyone involved. Our tool is built on Visper, the object-oriented distributed programming middleware. The suitability and adaptability of the Visper model for rapid application development and the quality of produced result have proven our decision correct.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {2006 IEEE International Conference on Electro Information Technology},
  key       = {Software testing},
  keywords  = {Computer aided software engineering;Data transfer rates;Gateways (computer networks);Interoperability;Middleware;Object oriented programming;Process control;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/EIT.2006.252109},
}

@InProceedings{Chiang2007,
  author    = {Chiang, Hsiao-Wei D. and Chiang, I-Che and Li, Hsin-Lung},
  title     = {Performance testing of microturbine generator system fueled by biodiesel},
  year      = {2007},
  volume    = {1},
  pages     = {459 - 466},
  address   = {Montreal, Que., Canada},
  note      = {Compressor discharges;Global energy crisis;Rotating disk regenerators;},
  abstract  = {Using microturbine generator systems for distributed power generation has become the recent trend. To face the impact of the global energy crisis, one of the options is to use biofuels including biodiesel. To this end, this program is to perform study on biodiesel microturbine testing and analysis. A 150kW microturbine generator set with twin rotating disk regenerators was used. Designed as a vehicular microturbine engine, the twin rotating ceramic disk regenerators dramatically improve fuel consumption by transferring heat energy from the exhaust gas stream to compressor discharge. This paper involved testing of the microturbine generator set at different load conditions using 10%-30% biodiesel fuel. A software program was used to predict the performance of the microturbine generator set at different operating conditions in order to compare with the test results. Both biodiesel and petrodiesel fuels are used on the microturbine generator system in this study and the results will be compared. Copyright &copy; 2007 by ASME.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of the ASME Turbo Expo},
  key       = {Turbines},
  keywords  = {Biodiesel;Compressors;Electric generators;Fuel consumption;Rotating disks;Thermal energy;Vehicles;},
  language  = {English},
  url       = {http://dx.doi.org/10.1115/GT2007-28075},
}

@Article{Finotello2005,
  author    = {Finotello, R. and Losito, S. and Mondellini, C. and Rossi, G. and Zampato, M.},
  title     = {Stereo vision measurement system qualification and preliminary performance test results},
  journal   = {European Space Agency, (Special Publication) ESA SP},
  year      = {2005},
  number    = {603},
  pages     = {617 - 623},
  issn      = {03796566},
  note      = {Environment geometry;Space measurement;Stereo vision processing;},
  abstract  = {The paper presents the Stereo Vision Measurement System. The system has been developed at proto-flight model level and features the stereo vision processing for in space measurement of the environment geometry. The SVMS subsystems and the relevant qualification tests are presented. Preliminary evaluations of the performances of the software system by using the laboratory prototype are included.},
  address   = {Munich, Germany},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Computer software},
  keywords  = {Space research;Stereo vision;},
  language  = {English},
}

@InProceedings{Meira2012,
  author    = {Meira, Jorge Augusto and Almeida, Eduardo Cunha De and Le Traon, Yves and Sunye, Gerson},
  title     = {Peer-to-peer load testing},
  year      = {2012},
  pages     = {642 - 647},
  address   = {Montreal, QC, Canada},
  note      = {Bottleneck problem;Business operation;Heavy load conditions;Peer to peer;Scale-up;Study case;System under test;WEB application;},
  abstract  = {Nowadays the large-scale systems are common-place in any kind of applications. The popularity of the web created a new environment in which the applications need to be highly scalable due to the data tsunami generated by a huge load of requests (i.e., connections and business operations). In this context, the main question is to validate how far the web applications can deal with the load generated by the clients. Load testing is a technique to analyze the behavior of the system under test upon normal and heavy load conditions. In this work we present a peer-to-peer load testing approach to isolate bottleneck problems related to centralized testing drivers and to scale up the load. Our approach was tested in a DBMS as study case and presents satisfactory results. &copy; 2012 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - IEEE 5th International Conference on Software Testing, Verification and Validation, ICST 2012},
  key       = {Load testing},
  keywords  = {Large scale systems;Peer to peer networks;Software testing;Verification;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICST.2012.153},
}

@Article{Dillenseger2009,
  author    = {Dillenseger, Bruno},
  title     = {CLIF, a framework based on Fractal for flexible, distributed load testing},
  journal   = {Annales des Telecommunications/Annals of Telecommunications},
  year      = {2009},
  volume    = {64},
  number    = {1-2},
  pages     = {101 - 120},
  issn      = {00034347},
  note      = {Component-based software engineering;Computing resource;Distributed systems;Fractal component models;IS performance evaluation;Open source projects;Performance evaluations;Testing platforms;},
  abstract  = {The context of this work is performance evaluation of IT systems based on load testing. It typically consists in generating a flow of requests on a system under test, and to measure response times, request throughput, or computing resource usage. A quick overview of available load testing platforms shows that there exist hundreds of such platforms, including in the open source domain. However, many testers still tend to develop their own ad hoc load testing tooling. Why? This paper starts by looking for possible answers to this question, in order to introduce the CLIF load injection framework, which intends not to be yet another load testing platform. Based on the Fractal component model, the CLIF open source project aims at addressing key issues such as flexibility, adaptation, and scalability. We give here details about CLIF's architecture and associated tools as well as some feedback from a bunch of practical utilizations. &copy; 2008 Institut TELECOM and Springer-Verlag.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Load testing},
  keywords  = {Fractals;Open source software;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/s12243-008-0067-9},
}

@InProceedings{Wu2013a,
  author    = {Wu, Zhong Qian and Li, Jin Zhe and Liao, Zeng Zeng},
  title     = {Keyword driven automation test},
  year      = {2013},
  volume    = {427-429},
  pages     = {652 - 655},
  address   = {Chongqing, China},
  note      = {Automated testing;Interface applications;KDTFA;Keyword driven;Mobile;System architectures;Test automation frameworks;Verification results;},
  abstract  = {In order to improve software reusability of automated test scripts, presents a keyword-driven test automation framework (KDTFA). First, the current existing automated testing framework for inductive analysis; then raised KDTFA system architecture; finally, an example of the android interface application framework and the existing framework for KDTFA actual contrast verification results show that the framework has a reduced scale of test scripts to improve the overall test efficiency and other advantages. &copy; (2013) Trans Tech Publications, Switzerland.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {16609336},
  journal   = {Applied Mechanics and Materials},
  key       = {Testing},
  keywords  = {Automation;Computer software reusability;Industrial electronics;Information technology;Mechanical engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.4028/www.scientific.net/AMM.427-429.652},
}

@InProceedings{Yongzhong2008,
  author    = {Yongzhong, Lu and Danping, Yan and Songlin, Nie and Chun, Wang},
  title     = {Development of an improved GUI automation test system based on Event-flow graph},
  year      = {2008},
  volume    = {2},
  pages     = {712 - 715},
  address   = {Wuhan, Hubei, China},
  note      = {Automation tests;Automation tools;Event-flow graph;Goal directed;Graphic user interface (GUI);Improved ant colony optimization;Prototype system;Test Modeling;},
  abstract  = {A more highly automated graphic user interface (GUI) test model, which is based on the event-flow graph, is proposed. In the model, an automation tool is first used to carry out reverse engineering for a GUI test sample so as to obtain the event-flow graph. Then an improved ant colony optimization algorithm and a goal-directed searching approach are adopted to create GUI test sample cases. Moreover, a corresponding prototype system based on Microsoft UI automation framework is developed. &copy; 2008 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - International Conference on Computer Science and Software Engineering, CSSE 2008},
  key       = {Flow graphs},
  keywords  = {Ant colony optimization;Automation;Graphic methods;Graphical user interfaces;Reverse engineering;Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/CSSE.2008.1336},
}

@InProceedings{Shan2009,
  author    = {Shan, Min and Wang, Xianrong and Zhao, Lijun and Guo, Lili},
  title     = {Using TTCN-3 in performance test for service application},
  year      = {2009},
  pages     = {253 - 258},
  address   = {Haikou, China},
  note      = {Concurrent requests;Description languages;Performance testing;Performance testing framework;Service applications;Testing framework;TTCN-3;Typical application;},
  abstract  = {Service applications are applicable to provide services for requests of users from network. Due to the fact that they have to endure a big number of concurrent requests, the performance of service applications running under specific arrival rate of requests should be assessed. To measure the performance of a service application, Multi-party testing context is needed to simulate a number of concurrent requests and collect the responses. TTCN-3 is a test description language; it provides basic language elements for multi-party testing context that can be used in performance tests. This paper proposes a general approach of using TTCN-3 in multiparty performance testing service application. To this aim, a model of service application is presented, and performance testing framework for service applications is discussed. This testing framework is realized for a typical application by developing a reusable TTCN-3 abstract test suite. &copy; 2009 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - 7th ACIS International Conference on Software Engineering Research, Management and Applications, SERA09},
  key       = {Application programs},
  keywords  = {Computer software reusability;Engineering research;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/SERA.2009.18},
}

@InProceedings{Querbach2013,
  author    = {Querbach, Bruce and Puligundla, Sudeep and Becerra, Daniel and Schoenborn, Zale T. and Chiang, Patrick},
  title     = {Comparison of hardware based and software based stress testing of memory IO interface},
  year      = {2013},
  pages     = {637 - 640},
  address   = {Columbus, OH, United states},
  note      = {Advanced softwares;Aggressor-victim;Circuit functionality;Frequency contents;Parameter spaces;Pattern generator;Pseudo random bit stream;Worst case pattern;},
  abstract  = {In post-silicon testing and validation of circuit functionality, an effective IO stress pattern can identify bugs quickly and provide adequate test coverage. A lot of work has been done to identify the right stress patterns specific to each IO interface. While some patterns can be generic enough to apply to all IOs, other patterns are interface topology specific. In addition to identifying the worst-case pattern, tradeoffs between test-time and test coverage must be made depending on the test goals. Pseudo Random Bit Stream (PRBS) generators are commonly used to generate test patterns because of the adequate frequency content in the PRBS patterns, the ease of implementation, and minimal gate count. This paper introduces an Advanced Pattern Generator and Checker (APGC) based on PRBS that retains all the aforementioned advantages. The APGC was implemented for a DDR memory interface where different LFSRs beat against each other spatially on neighboring IO lanes while rotating this form of aggressor-victim pattern in time. The results of the APGC stress patterns are compared to a form of advanced software-based learning algorithm based patterns that exhaustively search this complete parameter space. The comparison of APGC to software showed that the measured bit error rate (BER) plotted on a Q-scale of both methods is similar for the Receiver side. On the Transmitter side, APGC showed less eye opening than the software. In addition to the margin comparison, on the test execution side, APGC can speed up the test and validation execution time compared to the software by 32 to 2048 times depending on aggressor victim lane width of 8 to 64 lanes. &copy; 2013 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {15483746},
  journal   = {Midwest Symposium on Circuits and Systems},
  key       = {Software testing},
  keywords  = {Bit error rate;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/MWSCAS.2013.6674729},
}

@InProceedings{He2013,
  author    = {He, Ze Gang and Tai, Xiao Hong and Shen, Rong Wei and Han, Jiong Gang},
  title     = {The design of comprehensive performance test-bed of automobile electric power steering system},
  year      = {2013},
  volume    = {333-335},
  pages     = {2301 - 2304},
  address   = {Guilin, China},
  note      = {AC servo systems;Assist characteristic;Automobile electric;Comprehensive performance;Data collection card;Designed;Electric power steering system;Motion control card;},
  abstract  = {A kind of comprehensive performance test-bed of automobile electric power steering system was designed. IPC was applied to the main control system. Testing software was developed based on Visual Basic. AC servo system was assembled to respectively simulate input torque and load torque, the manual input torque can also be realized by operating steering wheel. The motion control card MPC08 is used to control the motion of Servo motor. Test data is collected by using multi-function data collection card. The lifting gears were assembled to install input/output shaft servo motor and EPS. Test results show that the test-bed can verify the control strategies and accurately detect the assist characteristic of EPS. &copy; (2013) Trans Tech Publications, Switzerland.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {16609336},
  journal   = {Applied Mechanics and Materials},
  key       = {Software testing},
  keywords  = {AC generator motors;Servomechanisms;Visual BASIC;},
  language  = {English},
  url       = {http://dx.doi.org/10.4028/www.scientific.net/AMM.333-335.2301},
}

@Article{Hu2007,
  author    = {Hu, Min and Yang, Wei-Min and Lin, Chun-Xiao},
  title     = {Research on the load testing system based on CORBA and its implementation},
  journal   = {Shanghai Ligong Daxue Xuebao/Journal of University of Shanghai for Science and Technology},
  year      = {2007},
  volume    = {29},
  number    = {2},
  pages     = {189 - 194},
  issn      = {10076735},
  abstract  = {The load testing system based on CDRBA is described, and the constitution, structure, and module design of the system as well as some related key techniques are discussed. The application of the system will improve the efficiency of the test of the software under distributed calculating environment, so as to guarantee the software quality.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  language  = {Chinese},
}

@InProceedings{Abbas2017,
  author    = {Abbas, Rabiya and Sultan, Zainab and Bhatti, Shahid Nazir},
  title     = {Comparative analysis of automated load testing tools: Apache JMeter, Microsoft Visual Studio (TFS), LoadRunner, Siege},
  year      = {2017},
  pages     = {39 - 44},
  address   = {Rawalpindi, Pakistan},
  note      = {Automated testing;Comparative analysis;Grey-box testing;Internal structure;Manual testing;Stress test;Testing tools;White-box testing;},
  abstract  = {Software testing is the process of testing, verifying and validating the user's requirements. During whole software development, testing is an ongoing process. Black Box, White Box testing and grey box testing are the three main types of software testing. In Black box testing, user doesn't know intrinsic logics and design of system. In white box testing, Tester knows the intrinsic logic of code. In Grey box testing, Tester has little bit knowledge about the internal structure, code and working of the system. It is commonly used in case of Integration testing. Load testing is the type of testing which helps us to analyze the performance of the system under heavy load or under Zero load. With the help of a automated load Testing Tools, we can do it in better way. The intention for writing this research is to carry out a comparison of four automated load testing tools i.e. Apache JMeter, HP LoadRunner, Microsoft Visual Studio (TFS), Siege based on certain criteria i.e. test scripts generation, plug-in support, result reports, application support and cost. The main focus is to study and analyze these load testing tools and identify which tool is best and more efficient [10]. We assume this comparative analysis can help in selecting the most appropriate tool and motivates the use of open source load testing tools.<br/> &copy; 2017 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {International Conference on Communication Technologies, ComTech 2017},
  key       = {Black-box testing},
  keywords  = {Automation;Integration testing;Load testing;Open source software;Software design;Software engineering;Software testing;Studios;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/COMTECH.2017.8065747},
}

@InProceedings{Fan2013,
  author    = {Fan, Haojie and Mu, Yongmin},
  title     = {A performance testing and optimization tool for system developed by python language},
  year      = {2013},
  volume    = {2013},
  number    = {637 CP},
  pages     = {24 - 27},
  address   = {Beijing, China},
  note      = {Developing projects;Grammatical structure;Optimization tools;Performance testing;Python;System optimizations;Systems development;Systems performance;},
  abstract  = {With a wide range of Python language in developing programs, More and more programmers choose to use the Python language for systems development, it gradually becomes scientific computing, web and games' Choice Awards. However, the performance of python is always a headache for developers. For reasonable selection of functions in base library, the usage of third-party plug-ins functions and methods, and the design of custom functions, the problem whether they are the best choices for general developers is difficult to make a positive answer. After the systems performance bottleneck occurs, it is particularly important to determine where to tune and how to tune. Through the analysis and dynamic tracking of source code, with the built-in method in Python, we can get information about the system to be optimized, included: functions, grammatical structures, running time of each function, the relationship between function calls etc. This information provides an effective basis for further optimization of the system. Experimental results show that the system optimized by the tool has a significantly improvement.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {IET Conference Publications},
  key       = {Computer software},
  keywords  = {Computer games;Computers;High level languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1049/cp.2013.2086},
}

@InProceedings{Krizanic2010,
  author    = {Krizanic, J. and Grguric, A. and Momondor, M. and Lazarevski, P.},
  title     = {Load testing and performance monitoring tools in use with AJAX based web applications},
  year      = {2010},
  pages     = {428 - 434},
  address   = {Opatija, Croatia},
  note      = {AJAX;Distributed testing;Performance monitoring;Real environments;Security support;Software life cycles;Usage scenarios;WEB application;},
  abstract  = {In order to deliver quality assured software and avoid potential costs caused by unstable software, software testing is essential in software lifecycle. Load testing is one of the testing types with high importance. It is usually accompanied by performance monitoring of the hosting environment. In the case of web applications which are today widely used, one fact is obvious: most of web applications are public and used by vast number of users, which are making a considerable traffic load on hosting environments and web applications. Load testing and performance monitoring become facilitated with existing tools aimed for load testing and performance monitoring. In the paper we analyze and compare several existing tools which facilitate load testing and performance monitoring, in order to find the most appropriate tools by criteria such as ease of use, supported features, and license. Selected tools were put in action in the real environment, through several web applications. For the case study one of the web applications is used in order to introduce different capabilities of tools, including distributed testing, assembling of test scenario from previously recorded usage scenarios, security support, results analysis, monitoring of key parameters, and reporting and alerting about changes of these parameters.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {MIPRO 2010 - 33rd International Convention on Information and Communication Technology, Electronics and Microelectronics, Proceedings},
  key       = {Load testing},
  keywords  = {Microelectronics;Monitoring;Software testing;},
  language  = {English},
}

@InProceedings{Chattopadhyay2017,
  author    = {Chattopadhyay, Sudipta},
  title     = {Directed automated memory performance testing},
  year      = {2017},
  volume    = {10206 LNCS},
  pages     = {38 - 55},
  address   = {Uppsala, Sweden},
  note      = {Dynamic symbolic executions;Execution platforms;Memory performance;Non functional properties;Open source projects;Satisfiability modulo Theories;Software performance;Software security;},
  abstract  = {Understanding software non-functional properties (e.g. time, energy and security) requires deep understanding of the execution platform. The design of caches plays a crucial role in impacting software performance (for low latency of caches) and software security (for cache being used as a side channel). We present CATAPULT, a novel test generation framework to systematically explore the cache behaviour of an arbitrary program. Our framework leverages dynamic symbolic execution and satisfiability modulo theory (SMT) solvers for generating test inputs. We show the application of CATAPULT in testing timing-related properties and testing cache side-channel vulnerabilities in several open-source programs, including applications from OpenSSL and Linux GDK libraries. &copy; Springer-Verlag GmbH Germany 2017.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Software testing},
  keywords  = {Application programs;Computer operating systems;Open source software;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-662-54580-5_3},
}

@InProceedings{Shankar2011,
  author    = {Shankar, Subramanian Shiva and Shankar, Jayaratnam Siva},
  title     = {Synthesizable verification IP to stress test system-on-chip emulation and prototyping platforms},
  year      = {2011},
  pages     = {609 - 612},
  address   = {SingaporeSingapore, Singapore},
  note      = {Communication infrastructure;FPGA prototyping;Industry standards;Prototyping platform;Prototyping systems;Stress Testing;UTMI;Verification environment;},
  abstract  = {One of the biggest challenges today with Pre-silicon System-on-Chip verification is to stress out the SoC to uncover as many corner case design issues by injecting heavy real time data traffic into the system. The inherent efficiency and the performance of the Emulation and FPGA prototyping systems make them the ideal platforms to run these tests. A typical solution is to inject data traffic through protocol exercisers with proprietary hardware (vendor specific slow down solutions) which can bridge the emulated DUT with a real time device or use software API's with transaction based SCE-MI communication infrastructure. The need for a complex input output interface makes the former difficult to be used with all emulators / FPGA prototyping systems while SCE-MI communication infrastructure being protocol specific is a disadvantage. So, a synthesizable verification architecture compliant with SCE-MI 2.0 infrastructure through which the protocol specific traffic is injected through industry standard interfaces. i.e. PIPE (PCIe), UTMI (USB), MII (Ethernet) based on user configured stimuli has been designed and implemented. Being synthesizable, the verification environment can run in both emulation and prototyping platforms effectively stress testing the complete system. &copy; 2011 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {2011 International Symposium on Integrated Circuits, ISIC 2011},
  key       = {System-on-chip},
  keywords  = {Application specific integrated circuits;Design for testability;Network architecture;Pipe;Programmable logic controllers;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ISICir.2011.6131936},
}

@InProceedings{Eljuse2016,
  author    = {Eljuse, Basil and Walkinshaw, Neil},
  title     = {A search based approach for stress-testing integrated circuits},
  year      = {2016},
  volume    = {9962 LNCS},
  pages     = {80 - 95},
  address   = {Raleigh, NC, United states},
  note      = {Automated searches;Cache coherent interconnect;Cache management;Design parameters;Hardware platform;Multiple processors;Software complexity;Stress Testing;},
  abstract  = {In order to reduce software complexity and be power efficient, hardware platforms are increasingly incorporating functionality that was traditionally administered at a software-level (such as cache management). This functionality is often complex, incorporating multiple processors along with a multitude of design parameters. Such devices can only be reliably tested at a &lsquo;system&rsquo; level, which presents various testing challenges; behaviour is often non-deterministic (from a software perspective), and finding suitable test sets to &lsquo;stress&rsquo; the system adequately is often an inefficient, manual activity that yields fixed test sets that can rarely be reused. In this paper we investigate this problem with respect to ARM&rsquo;s Cache Coherent Interconnect (CCI) Unit. We present an automated search-based testing approach that combines a parameterised testgeneration framework with the hill-climbing heuristic to find test sets that maximally &lsquo;stress&rsquo; the CCI by producingmuch larger numbers of data stall cycles than the corresponding manual test sets. &copy; Springer International Publishing AG 2016.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Software testing},
  keywords  = {Integrated circuit interconnects;Integrated circuits;Reconfigurable hardware;Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-47106-8_6},
}

@InProceedings{Shinbo2010,
  author    = {Shinbo, Hiroyuki and Tagami, Atsushi and Ano, Shigehiro and Hasegawa, Toru and Suzuki, Kenji},
  title     = {Practical end-to-end performance testing tool for high speed 3G-based networks},
  year      = {2010},
  volume    = {6435 LNCS},
  pages     = {205 - 220},
  note      = {Clock Synchronization;End-to-end performance;Header extraction;IP communications;Killer-application;Off-the-shelf hardwares;Packet header;Performance degradation;},
  abstract  = {High speed IP communication is a killer application for 3rd generation (3G) mobile systems. Thus 3G network operators should perform extensive tests to check whether expected end-to-end performances are provided to customers under various environments. An important objective of such tests is to check whether network nodes fulfill requirements to durations of processing packets because a long duration of such processing causes performance degradation. This requires testers (persons who do tests) to precisely know how long a packet is hold by various network nodes. Without any tool's help, this task is time-consuming and error prone. Thus we propose a multi-point packet header analysis tool which extracts and records packet headers with synchronized timestamps at multiple observation points. Such recorded packet headers enable testers to calculate such holding durations. The notable feature of this tool is that it is implemented on off-the shelf hardware platforms, i.e., lap-top personal computers. The key challenges of the implementation are precise clock synchronization without any special hardware and a sophisticated header extraction algorithm without any drop. &copy; 2010 IFIP International Federation for Information Processing.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {3G mobile communication systems},
  keywords  = {Computer hardware;Hardware;Mechanical clocks;Personal computers;Software testing;Synchronization;Technology transfer;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-16573-3_15},
}

@InProceedings{Zhang2015,
  author    = {Zhang, Qiang and Chen, Daxing and Li, Yusheng and Li, Keqiang},
  title     = {Research on performance test method of lane departure warning system with PreScan},
  year      = {2015},
  volume    = {328},
  pages     = {445 - 453},
  address   = {Opole, Poland},
  note      = {Lane-departure-warning systems;Model-based method;Real time simulations;Real-time computer;Test scenario;Vehicle dynamic model;Vehicle experiment;Virtual integration;},
  abstract  = {A performance test method of lane departure warning system (LDWS) with PreScan software is proposed. In the process of virtual integration, the LDWS camera is located in the front of a computer monitor displaying virtual environment so as to capture pictures including lane marks and other information. Vehicle dynamic model and maneuver model run on a real-time computer, which represents a virtual vehicle and communicates with LDWS controller with CAN bus. The results show that the method will make it easier to create various test scenarios, which can save time and cost by transferring complex testing catalogues to the laboratory. The dangers presented in vehicle experiments in some critical scenarios can also be reduced. The repeatable model-based method makes it more convenient to locate the problem, which would make it easier to compare and assess the performance of LDWS produced by different companies objectively.<br/> &copy; Springer-Verlag Berlin Heidelberg 2015.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {18761100},
  journal   = {Lecture Notes in Electrical Engineering},
  key       = {Software testing},
  keywords  = {Testing;Vehicles;Virtual reality;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-662-45043-7_45},
}

@Article{Avritzer1996,
  author    = {Avritzer, Alberto and Weyuker, Elaine J.},
  title     = {Deriving workloads for performance testing},
  journal   = {Software - Practice and Experience},
  year      = {1996},
  volume    = {26},
  number    = {6},
  pages     = {613 - 633},
  issn      = {00380644},
  note      = {Benchmark tuning;Performance testing;Workloads;},
  abstract  = {An approach is presented to compare the performance of an existing production platform and a proposed replacement architecture. The traditional approach to such a comparison is to develop software for the proposed platform, build the new architecture, and collect performance measurements on both the existing system in production and the new system in the development environment. In this paper we propose a new way to design an application-independent workload for doing such a performance evaluation. We demonstrate the applicability of our approach by describing our experience using it to help an industrial organization determine whether or not a proposed architecture would be adequate to meet their organization's performance requirements.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Computer software},
  keywords  = {Computer architecture;Computer software portability;Performance;Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1002/(SICI)1097-024X(199606)26:6<613::AID-SPE23>3.0.CO;2-5},
}

@Article{Shah2013,
  author    = {Shah, Himanshu and Wankhede, Paresh and Borkar, Anup},
  title     = {Challenges on amazon cloud in load balancing, performance testing and upgrading},
  journal   = {Advances in Intelligent Systems and Computing},
  year      = {2013},
  volume    = {203},
  pages     = {31 - 40},
  issn      = {21945357},
  note      = {Amazon web services;Data centres;Peak load;Performance testing;Return on investments;Software installations;Test applications;WEB application;},
  abstract  = {Web application hosting in a data centre is clouded with quite a few issues ranging from hardware provisioning, software installation and maintaining the servers. Traditional data-centre techniques need production grade hardware to test application's behavior/performance under expected peak load. This could be costly and procuring hardware could be very time consuming causing delays in software delivery. Cloud (Infrastructure-as-a- Service) can be an answer to this. Cloud Computing provides production grade server instances at very cheap rates. This whitepaper is divided into two sub parts: first part details out the typical web application setup on Amazon Web Services cloud (AWS) [Ref 2], challenges faced during the setup and resolution for the same, while the second part talks about the observations made during load testing using Apache JMeter performance testing tool on AWS cloud. Three different application setup topologies (single tier, two tier and three tier) are tested and findings and learning from it are discussed here. This whitepaper only highlights the pitfalls encountered and possible resolutions for each and is not a comment on performance of Amazon cloud. The whitepaper endeavors to find out the best architecture which would give maximum return on investment. &copy; Springer-Verlag Berlin Heidelberg 2013.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Computer hardware},
  keywords  = {Hardware;Profitability;Web services;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-35461-8},
}

@Article{Xiong2017,
  author    = {Xiong, Benhai and Jiang, Linshu and Yang, Liang and Pan, Xiaohua},
  title     = {Design and performance testing of production performance determination system for boar},
  journal   = {Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering},
  year      = {2017},
  volume    = {33},
  number    = {9},
  pages     = {174 - 179},
  issn      = {10026819},
  note      = {Automatic identification;Boar;Data collection;Electronic control systems;Functional verification;Performance measurements;Production performance;Reliability and stability;},
  abstract  = {In order to monitor feeding behavior of sows and further attain the sow's precise feeding, an intelligent production performance testing system was designed in this study, which played functions in sows' automatic identification, body weight perception, automatic feeding data acquisition and data analysis simultaneously. The system was composed of electric ear tag identification module, precise feed flow control module, feed trough and boar weighing module, data communication and remote control module. The mechanical device system was constituted of feeding bin, brackets, railing and blocking apron. The mechanical device system was constituted of feeder's vertical wall, weighting platform, flapper, feed loading device, feed bin, control box, switch of discharge and ear tag recognizer. Electronic control systems included microprocessor (LPC1766, ARM Cortex-M3, Working temperature -40-105&#8451;, Operating voltage 2.0-3.6 V, flash 256 K, low power consumption et al.), RS232 reader port, data storage chip (the default storage capacity is 256 KB), circuit of watchdog, weighing circuit, exterior-drivers circuit, JTAG connector circuit and stabilivolt source circuit. Among above, the sensor used for pigs weighing was Delux ADS1232 which had 2 rate options, 10 times per second and 80 times per second, with high precision and large range of features. The performance testing experiment revealed that: 1) the system's precision meets the monitoring requirement of sow production performance. The discharge rate of feeder depended on the level of feed in stock bin, and the average amount of unloading feed was 93&plusmn;2 g at one time; the range of pig weighing was 0-200 kg with the precision error below 10 g, and the dynamic weighing error was below 0.5% of pig's weight. 2) The feeding behavior monitor for 40 gilts (25-60 kg) showed that the frequency of free feed intake was 10-12 times per day, the average feed time was 78 min, the feed conversion ratio was 2.33:1, and their weight gain was converged to the Gompertz curves (e.g. W<inf>t</inf>=172.1exp(-4.0187exp(-0.0122*t)), W<inf>t</inf>means body weight, kg; t means day old, day), the predicted decreasing daily weight gain of growing pigs by Gompertz curve occurred at day 111-117, with corresponding inflection point weight in the range of 63-64 kg. The observed and predicted results above could precisely determine the growth performance, indicating that the software systems and hardware devices could satisfy the requirement of growth performance determination in sows. 3) The wiper motor rather than early stepping motor was used in feed discharging control system, which reduced the cost of production. In addition, the combined wiper motor with cylindrical scraper structure decreased the discharge rate of feeder and improved the precision of unloading control system. 4) The core chip in control system was imported, multi-redundant, and protection systems were applied in circuit design. Multiply functional verification was adopted in software writing. The redundancy design in software and hardware eliminated the interference of power, electrical machine and electromagnetic wave, and improved the systems' reliability and stability. 5) The collected data could be saved or transferred, which facilitates the accumulation of pig production, data mining and sow breeding. &copy; 2017, Editorial Department of the Transactions of the Chinese Society of Agricultural Engineering. All right reserved.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Identification (control systems)},
  keywords  = {Anthropometry;Automation;Bins;Control systems;Data acquisition;Digital storage;Electric discharges;Electromagnetic waves;Feeding;Hardware;Integrated circuit manufacture;Mammals;Models;Printed circuit design;Redundancy;Software reliability;Software testing;Unloading;Verification;Weighing;},
  language  = {Chinese},
  url       = {http://dx.doi.org/10.11975/j.issn.1002-6819.2017.09.022},
}

@InProceedings{Leonard1997,
  author    = {Leonard, Donald C.},
  title     = {Simplifying motor performance testing in the production environment},
  year      = {1997},
  pages     = {185 - 190},
  address   = {Rosemont, IL, USA},
  note      = {Factory floor;Performance testing;},
  abstract  = {The objective of this paper is to illustrate how performance test systems on the factory floor can be enhanced by utilizing the power and speed of integral computer hardware and software to automate and simplify tasks typically performed in the production environment. The first part of this paper discusses why the test system is needed to perform additional tasks. The second section defines the relationships between various departments within the organization, and the test system. The third section discusses the benefits of integrating additional functions into the test system. The final sections of the paper discusses incorporating artificial intelligence and networking to simplify tasks associated with the production environment.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {03622479},
  journal   = {Proceedings of the Electrical/Electronics Insulation Conference},
  key       = {Electric motors},
  keywords  = {Artificial intelligence;Automatic testing;Computer hardware;Computer integrated manufacturing;Computer software;Decision making;Factory automation;Performance;},
  language  = {English},
}

@InProceedings{Banerjee2013,
  author    = {Banerjee, Abhijeet and Chattopadhyay, Sudipta and Roychoudhury, Abhik},
  title     = {Static analysis driven cache performance testing},
  year      = {2013},
  pages     = {319 - 329},
  address   = {Vancouver, BC, Canada},
  note      = {Cache performance;Design space exploration;Memory subsystems;Non-functional requirements;Performance testing;Static cache analysis;Test generations;Worst-case execution time;},
  abstract  = {Real-time, embedded software are constrained by several non-functional requirements, such as timing. With the ever increasing performance gap between the processor and the main memory, the performance of memory subsystems often pose a significant bottleneck in achieving the desired performance for a real-time, embedded software. Cache memory plays a key role in reducing the performance gap between a processor and main memory. Therefore, analyzing the cache behaviour of a program is critical for validating the performance of an embedded software. In this paper, we propose a novel approach to automatically generate test inputs that expose the cache performance issues to the developer. Each such test scenario points to the specific parts of a program that exhibit anomalous cache behaviour along with a set of test inputs that lead to such undesirable cache behaviour. We build a framework that leverages the concepts of both static cache analysis and dynamic test generation to systematically compute the cache-performance stressing test inputs. Our framework computes a test-suite which does not contain any false positives. This means that each element in the test-suite points to a real cache performance issue. Moreover, our test generation framework provides an assurance of the test coverage via a well-formed coverage metric. We have implemented our entire framework using Chronos worst case execution time (WCET) analyzer and LLVM compiler infrastructure. Several experiments suggest that our test generation framework quickly converges towards generating cache-performance stressing test cases. We also show the application of our generated test-suite in design space exploration and cache performance optimization. &copy; 2013 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {10528725},
  journal   = {Proceedings - Real-Time Systems Symposium},
  key       = {Software testing},
  keywords  = {Cache memory;Embedded software;Interactive computer systems;Program compilers;Real time systems;Static analysis;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/RTSS.2013.39},
}

@InProceedings{Bozoki2008,
  author    = {Bozoki, Ferenc and Csondes, Tibor},
  title     = {Scheduling in performance test environment},
  year      = {2008},
  pages     = {404 - 408},
  address   = {Split-Dubrovnik, Croatia},
  note      = {Architecture-based;Description languages;Development process;Hardware resources;Load characteristics;Performance testing;Performance tests;System under test;},
  abstract  = {Nowadays automatic testing is getting more and more important in the telecommunication world. The sooner a fault is discovered the cheaper it is to correct it. If a fault is discovered during the development process the cost of the correction is significantly smaller. There are different test strategies, with different approaches like, Conformance Test, System Test and Performance Test. The System Test takes place after a successful Conformance Test. Performance Test is analyzing the load characteristics of the System Under Test (SUT). In this article we describe the main attributes of performance testing, where the main challenge is to generate the expected load without having as complex hardware as the SUT is itself. Most of the papers, presented in this subject are focusing on the characteristics of the generated load, but not the way how to achieve it. These papers usually have the assumption that the load can be generated by deploying more hardware resources. Other papers propose new extensions for test description languages such SDL or TTCN-3 [4]. In this article we intend to describe a Finite State Machine (FSM) based model and an algorithm which improves the efficiency of Scheduling in this Performance Test environment. We present an architecture based on the so called Virtual Threads, an algorithm to optimize the scheduling between these threads, and an example to demonstrate the algorithm.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {SoftCom 2008: 16th International Conference on Software, Telecommuncations and Computer Networks},
  key       = {Load testing},
  keywords  = {Automatic testing;Computer hardware;Computer networks;Hardware;Scheduling;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/SOFTCOM.2008.4669519},
}

@Article{Pachucki1995,
  author    = {Pachucki, Dennis E.},
  title     = {Environmental stress testing experiment using the Taguchi method},
  journal   = {IEEE transactions on components, packaging, and manufacturing technology. Part A},
  year      = {1995},
  volume    = {18},
  number    = {1},
  pages     = {3 - 9},
  issn      = {10709886},
  note      = {Analysis of variance;Environmental stress testing;Functional diagnostic test suite;Power cycling;Power on self test;Printed wiring board;Programmable memory chip;Random vibration;Taguchi method;Temperature cycling;},
  abstract  = {An environmental stress screening (ESS), a method for improving manufacturing process by applying stress beyond product specification detect latent defects in the product, was performed to find out the relevant stress used in the production of printed wiring boards. Three types of stress - random vibration, temperature cycling and power cycling - were emphasized. Experimental results were statistically obtained using the Taguchi design method.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Printed circuit manufacture},
  keywords  = {Application specific integrated circuits;Computer software;Data acquisition;Data storage equipment;Environmental testing;Microprocessor chips;Random processes;Statistical methods;Stresses;Thermal cycling;Vibrations (mechanical);},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/95.370727},
}

@InProceedings{Xueling2007,
  author    = {Xueling, Shu and Maurer, Frank},
  title     = {A tool for automated performance testing of Java3D applications in agile environments},
  year      = {2007},
  address   = {Cap Esterel, France},
  note      = {Agile environment;Automated test;Core features;Domain experts;Performance problems;Performance requirements;Performance testing;Tool requirements;},
  abstract  = {Following the agile philosophy that all core features of a system need an automated test harness, performance requirements also need such a check when they are essential for the success of a project. The purpose of this paper is to describe a tool, J3DPerfUnit, which supports automated performance testing for Java3D applications in agile environments. We elicited tool requirements from domain experts through a survey and evaluated J3DPerfUnit using code from our partner's bioinformatics project and Java3D official tutorials. The evaluation pointed out that the tool is effective in detecting performance problems and in identifying where they come from when loading/unloading a 3D object. &copy; 2007 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {2nd International Conference on Software Engineering Advances - ICSEA 2007},
  key       = {Software engineering},
  keywords  = {Automation;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICSEA.2007.11},
}

@Article{Williams1999,
  author    = {Williams, Andrew},
  title     = {Network application performance testing for lotus notes},
  journal   = {CMG Transactions},
  year      = {1999},
  number    = {95},
  pages     = {49 - 64},
  note      = {Lotus notes;Network application performance testing;},
  abstract  = {As customers move toward network applications, the problem of acceptable performance and user load stresses have not evaporated. Increasingly, customers need to simulate large network user loads to measure end-to-end response time and identify potential bottlenecks. This paper presents a methodology to achieve this and details results from real applications evaluations on an OS/2 and AIX Lotus Notes 4.1 environment. In all, thirty client machines were setup in a laboratory and linked to an additional set of seventy virtual users all exercising Lotus Notes application test cases to create a user load of 100 active concurrent users. During the process the clients and servers were monitored with various tools. The paper details the process used, a sample of the results, problems found in the process, the metrics required and future directions for network performance test solutions. It will focus mostly on the method of creating large, realistic loads for Lotus Notes applications - a topic largely ignored by the testing community up to this point in time. The subject will be of interest to any owner interested in implementing a network application or client/server application or a test specialist involved in testing these type of applications.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Computer applications},
  keywords  = {Client server computer systems;Computer software;Computer testing;Internet;Performance;Response time (computer systems);},
  language  = {English},
}

@Article{Arif2018a,
  author    = {Arif, Muhammad Moiz and Shang, Weiyi and Shihab, Emad},
  title     = {Empirical study on the discrepancy between performance testing results from virtual and physical environments},
  journal   = {Empirical Software Engineering},
  year      = {2018},
  volume    = {23},
  number    = {3},
  pages     = {1490 - 1518},
  issn      = {13823256},
  note      = {Large software systems;Performance metrices;Performance metrics;Performance testing;Physical environments;Software performance;Software performance engineerings;Testing environment;},
  abstract  = {Large software systems often undergo performance tests to ensure their capability to handle expected loads. These performance tests often consume large amounts of computing resources and time since heavy loads need to be generated. Making it worse, the ever evolving field requires frequent updates to the performance testing environment. In practice, virtual machines (VMs) are widely exploited to provide flexible and less costly environments for performance tests. However, the use of VMs may introduce confounding overhead (e.g., a higher than expected memory utilization with unstable I/O traffic) to the testing environment and lead to unrealistic performance testing results. Yet, little research has studied the impact on test results of using VMs in performance testing activities. To evaluate the discrepancy between the performance testing results from virtual and physical environments, we perform a case study on two open source systems &ndash; namely Dell DVD Store (DS2) and CloudStore. We conduct the same performance tests in both virtual and physical environments and compare the performance testing results based on the three aspects that are typically examined for performance testing results: 1) single performance metric (e.g. CPU Time from virtual environment vs. CPU Time from physical environment), 2) the relationship among performance metrics (e.g. correlation between CPU and I/O) and 3) performance models that are built to predict system performance. Our results show that 1) A single metric from virtual and physical environments do not follow the same distribution, hence practitioners cannot simply use a scaling factor to compare the performance between environments, 2) correlations among performance metrics in virtual environments are different from those in physical environments 3) statistical models built based on the performance metrics from virtual environments are different from the models built from physical environments suggesting that practitioners cannot use the performance testing results across virtual and physical environments. In order to assist the practitioners leverage performance testing results in both environments, we investigate ways to reduce the discrepancy. We find that such discrepancy can be reduced by normalizing performance metrics based on deviance. Overall, we suggest that practitioners should not use the performance testing results from virtual environment with the simple assumption of straightforward performance overhead. Instead, practitioners should consider leveraging normalization techniques to reduce the discrepancy before examining performance testing results from virtual and physical environments.<br/> &copy; 2017, Springer Science+Business Media, LLC.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Software testing},
  keywords  = {Open source software;Open systems;Virtual reality;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/s10664-017-9553-x},
}

@InProceedings{Jiang2008,
  author    = {Jiang, Zhen Ming and Hassan, Ahmed E. and Hamann, Gilbert and Flora, Parminder},
  title     = {Automatic identification of load testing problems},
  year      = {2008},
  pages     = {307 - 316},
  address   = {Beijing, China},
  note      = {Application under tests;Automatic identification;Domain experts;Execution sequences;Industrial practices;Large enterprise;Number of false alarms;Software applications;},
  abstract  = {Many software applications must provide services to hundreds or thousands of users concurrently. These applications must be load tested to ensure that they can function correctly under high load. Problems in load testing are due to problems in the load environment, the load generators, and the application under test. It is important to identify and address these problems to ensure that load testing results are correct and these problems are resolved. It is difficult to detect problems in a load test due to the large amount of data which must be examined. Current industrial practice mainly involves time-consuming manual checks which, for example, grep the logs of the application for error messages. In this paper, we present an approach which mines the execution logs of an application to uncover the dominant behavior (i.e., execution sequences) for the application and flags anomalies (i.e., deviations) from the dominant behavior. Using a case study of two open source and two large enterprise software applications, we show that our approach can automatically identify problems in a load test. Our approach flags &lt; 0.01% of the log lines for closer analysis by domain experts. The flagged lines indicate load testing problems with a relatively small number of false alarms. Our approach scales well for large applications and is currently used daily in practice. &copy; 2008 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {IEEE International Conference on Software Maintenance, ICSM},
  key       = {Load testing},
  keywords  = {Automation;Computer software maintenance;Enterprise software;Open source software;Open systems;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICSM.2008.4658079},
}

@InProceedings{Gao2010,
  author    = {Gao, Yuanlou and Fei, Xiaoxing},
  title     = {A research on the torque converter performance test-bed control system},
  year      = {2010},
  pages     = {3224 - 3226},
  note      = {Constant voltage;Converter performance;Eddy current dynamometer;Excitation voltage;Motor-speed control;Performance tests;Test Environment;Torsional loadings;},
  abstract  = {According to the characteristics of test bed, using a motor driven program based on inverter with a speed sensor, and an eddy current dynamometer constant torsional loading scheme, it implements the stability of constant speed drive and torsional load for the torque converter test-bed, providing a good test environment for the performance test. This method is economical and practical, energy saving and environmental protective. The constant voltage-frequency ratio of frequency control method is applied in motor speed control, and a way of changing the excitation voltage to change the output torque of the eddy current dynamometer is used. The results show that the system achieve good control results. &copy; 2010 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - International Conference on Electrical and Control Engineering, ICECE 2010},
  key       = {Electric machine control},
  keywords  = {Dynamometers;Eddy currents;Energy conservation;Equipment testing;Hydraulic torque converters;Software testing;Structural loads;Torque;},
  language  = {Chinese},
  url       = {http://dx.doi.org/10.1109/iCECE.2010.787},
}

@InProceedings{Briand2006,
  author    = {Briand, Lionel C. and Labiche, Yvan and Shousha, Marwa},
  title     = {Using genetic algorithms for early schedulability analysis and stress testing in real-time systems},
  year      = {2006},
  volume    = {7},
  number    = {2},
  pages     = {145 - 170},
  note      = {Critical deadline;Schedulability theory;Software verification and validation;System task architecture;},
  abstract  = {Reactive real-time systems have to react to external events within time constraints: Triggered tasks must execute within deadlines. It is therefore important for the designers of such systems to analyze the schedulability of tasks during the design process, as well as to test the system's response time to events in an effective manner once it is implemented. This article explores the use of genetic algorithms to provide automated support for both tasks. Our main objective is then to automate, based on the system task architecture, the derivation of test cases that maximize the chances of critical deadline misses within the system; we refer to this testing activity as stress testing. A second objective is to enable an early but realistic analysis of tasks' schedulability at design time. We have developed a specific solution based on genetic algorithms and implemented it in a tool. Case studies were run and results show that the tool (1) is effective at identifying test cases that will likely stress the system to such an extent that some tasks may miss deadlines, (2) can identify situations that were deemed to be schedulable based on standard schedulability analysis but that, nevertheless, exhibit deadline misses.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {13892576},
  journal   = {Genetic Programming and Evolvable Machines},
  key       = {Genetic algorithms},
  keywords  = {Real time systems;Scheduling;Stress analysis;Systems analysis;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/s10710-006-9003-9},
}

@InProceedings{Chiang2004,
  author    = {Chiang, Hsiao-Wei D. and Wang, Chun-Hao and Hsu, Chih-Neng},
  title     = {Performance testing of a microturbine generator set with twin rotating disk regenerators},
  year      = {2004},
  volume    = {6},
  pages     = {37 - 44},
  address   = {Vienna, Austria},
  note      = {Combined heat and power (CHP);Microturbine generators;Rotating disk regenerators;Vehicular microturbine engine;},
  abstract  = {An investigation was conducted to study the performance of a 150 kW microturbine generator set with twin rotating disk regenerators, including testing and analyses. Originally designed as a vehicular microturbine engine, twin rotating ceramic disk regenerators were used to dramatically improve fuel consumption by transferring heat energy from the exhaust gas stream to compressor discharge. This microturbine engine consists of a gasifier assembly, a power turbine, a combustor, a regenerator system, a reduction and accessory drive gearbox, and a fuel management system. Because the microturbine engine did not come with the necessary start and control system (including electronic engine control unit), a start sequence was successfully developed and a manual control system installed. This paper reports on testing of the microturbine generator set at different load conditions using load banks. As a parallel effort, a software program was used to predict the performance of the microturbine generator set at different operating conditions in order to compare with the test results.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of the ASME Turbo Expo 2004},
  key       = {Turbines},
  keywords  = {Control systems;Disks (machine components);Gas generators;Mechanical testing;Performance;Regenerators;Rotors;Shafts (machine components);},
  language  = {English},
}

@InProceedings{Brey1992,
  author    = {Brey, Jack},
  title     = {Stress testing a non-existent application tools, methods, and results},
  year      = {1992},
  pages     = {520 - 529},
  address   = {Reno, NV, USA},
  note      = {Software development;},
  abstract  = {How do you test an application that doesn't exist yet? How do you make an architectural decision when there are no similar applications in production anywhere? This case study covers the decision making process, the tools selected, the test plan, and the test results of an analysis used to choose between the use of a CASE tool and ACMS for a proposed application. The study involved use of both an analytic model and a benchmarking tool to establish the saturation point of a VAX 9000 under each alternative. The paper will discuss creation of the models, the results of the modeling activities, and the criteria that went into the actual decision.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {CMG Proceedings},
  key       = {Computer software},
  keywords  = {Decision theory;Testing;},
  language  = {English},
}

@InProceedings{Chen2014a,
  author    = {Chen, Min Gang and Zhong, Wen Bin and Chen, Wen Jie and Hu, Yun and Cai, Li Zhi},
  title     = {A web automation testing framework over cloud},
  year      = {2014},
  volume    = {556-562},
  pages     = {6149 - 6153},
  address   = {Shanghai, China},
  note      = {Automation testing;Cloud computing environments;Cloud testing;Key technologies;Software automation;TaaS;Testing resources;Web automation;},
  abstract  = {With the increasingly fast-paced software releasing or updating, research on the method of an efficient software automation testing framework based on cloud computing has become particularly important. In this paper, we propose an automation testing framework over cloud. We also describe some key technologies in the aspect of the design of hierarchical test case and automatic distribution of test cases in the cloud computing environment. Testing experiments show that our framework can take advantage of on-demand testing resources in the cloud to improve the efficiency of automation testing. &copy; (2014) Trans Tech Publications, Switzerland.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {16609336},
  journal   = {Applied Mechanics and Materials},
  key       = {Software testing},
  keywords  = {Automation;Cloud computing;Computer systems;Information technology;},
  language  = {English},
  url       = {http://dx.doi.org/10.4028/www.scientific.net/AMM.556-562.6149},
}

@InProceedings{Wang2011a,
  author    = {Wang, Chongwen},
  title     = {The research and design of NSL-oriented automation testing framework},
  year      = {2011},
  volume    = {128},
  pages     = {367 - 373},
  note      = {Automation testing;Multi languages;Open sources;Parallel executions;Test case;Testing efficiency;Testing framework;Testing tools;},
  abstract  = {By analyzing the Selenium and other open source testing tool, the lack of Selenium and the design of testing scripts are given to discuss and try to improve to resolve problems of NLS. These improvements include the using of page elements, enhancement of the response of the heavyweight component, optimization of testing scripts for multi-language versions. The parallel execution strategy for multilingual test cases has been provided, through which the users can execute test cases of multi-language in a great number of test servers at the same time, greatly improving the overall testing efficiency. The testing framework proposed has been applied to the actual web product globalization testing, and achieved very good results. &copy; Springer-Verlag Berlin Heidelberg 2011.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {18675662},
  journal   = {Advances in Intelligent and Soft Computing},
  key       = {Open source software},
  keywords  = {Selenium;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-25989-0_60},
}

@Article{Najjar2017,
  author    = {Najjar, S. and Saad, G. and Abdallah, Y.},
  title     = {Rational decision framework for designing pile-load test programs},
  journal   = {Geotechnical Testing Journal},
  year      = {2017},
  volume    = {40},
  number    = {2},
  pages     = {302 - 316},
  issn      = {01496115},
  note      = {Bayesian approaches;Capacity distribution;Decision framework;Decision-making frameworks;Deep foundations;Field testing;Pile test program;Site-specific information;},
  abstract  = {There is currently an inconsistency in the recommendations that are available in pile-design codes and practices regarding the required number of proof-load tests and the level of the proof loads for piles. In this paper, a pre-posterior decision-making framework is proposed to allow for selecting the optimal pile-load test program that would result in the maximum expected benefit to a project, while maintaining a target level of reliability in the pile design at the site. This proposed methodology is original, practical, and is based on site-specific information that is unique to any given project. The proposed methodology is based on a robust Bayesian approach that allows for updating the capacity distribution of piles at a site, given the results of the proof-load test program. The efficiency of the proposed decision framework is demonstrated by applying it on a practical design example that involves piles that are driven in a site consisting of medium-dense sand. Results indicate that: (1) the optimum proof-load level that results in the maximum benefit to the example project is 1.5 times the design load, (2) the optimum number of tests is a function of the number of piles (superstructure load) and the costs of the pile construction and testing, (3) as the number of piles in the site increases, the optimal required number of proof-load tests also increase, with the optimum number of pile-load tests being around 1 % to 2 % of the total number of piles at the site, and (4) the optimal number of pile-load tests increases as the cost of pile construction and installation increases and as the cost of implementing the pile test program decreases. Copyright &copy; 2017 by ASTM International.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Piles},
  keywords  = {Bayesian networks;Costs;Decision making;Decision theory;Load testing;Reliability;Reliability analysis;Software testing;Statistical tests;Test facilities;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1520/GTJ20160088},
}

@InProceedings{Rodrigues2015,
  author    = {Rodrigues, Elder and Bernardino, Maicon and Costa, Leandro and Zorzo, Avelino and Oliveira, Flavio},
  title     = {PLeTsPerf - A Model-Based Performance Testing Tool},
  year      = {2015},
  pages     = {Graz University of Technology (TU Graz); IEEE Computer Society -},
  address   = {Graz, Austria},
  note      = {Application models;Automatic Generation;Model based testing;Model-based OPC;Performance testing;Pilot studies;Testing tools;WEB application;},
  abstract  = {Performance testing is a highly specialized task, since it requires that a performance engineer knows the application to be tested, its usage profile, and the infrastructure where it will execute. Moreover, it requires that testing teams expend a considerable effort and time on its automation. In this paper, we present the PLeTsPerf, a model-based performance testing tool to support the automatic generation of scenarios and scripts from application models. PLetsPerf is a mature tool, developed in collaboration with an IT company, which has been used in several works, experimental studies and pilot studies. We present an example of use to demonstrate the process of generating test scripts and scenarios from UML models to test a Web application. We also present the lessons learned and discuss our conclusions about the use of the tool.<br/> &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {2015 IEEE 8th International Conference on Software Testing, Verification and Validation, ICST 2015 - Proceedings},
  key       = {Software testing},
  keywords  = {Model checking;Unified Modeling Language;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICST.2015.7102628},
}

@InProceedings{Yang2008,
  author    = {Yang, Xing and Li, Xiang and Ji, Yipeng and Sha, Mo},
  title     = {CROWNBench: A grid performance testing system using customizable synthetic workload},
  year      = {2008},
  volume    = {4976 LNCS},
  pages     = {190 - 201},
  address   = {Shenyang, China},
  note      = {CROWNBench;Grid performance;Performance testing;Synthetic workloads;},
  abstract  = {The Grid middleware must be developed iteratively and incrementally, so Grid performance testing is critical for middleware developers of Grid system. Considering the special characters of Grid system, in order to gain meaningful and comprehensive results of performance testing, it is necessary to implement testing on real Grid environment with various types of workload. CROWNBench, as described in this paper, is a system for helping Grid middleware developers to evaluate middleware design and implement using customizable synthetic workload. Middleware developers can customize testing workload basing on the model of Grid workload derived from real workload traces, including its structure and parameters, and then workload is synthesized automatically and contained jobs will be submitted by CROWNBench in a distributed manner. CROWNBench defines several metrics for measuring Grid performance as automatic testing results. The experiment, which used CROWNBench to test the performance of Grid system with CROWN Grid middleware, shows that the system already finished have accomplished its prospective goal. It can implement Grid performance testing in an efficient, flexible, controllable, replayable and automatic way to help middleware developers evaluate and improve their products effectively. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Software testing},
  keywords  = {Grid computing;Middleware;Parameter estimation;Problem solving;Software design;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-540-78849-2_21},
}

@Article{DiAlesio2015,
  author    = {Di Alesio, Stefano and Briand, Lionel C. and Nejati, Shiva and Gotlieb, Arnaud},
  title     = {Combining genetic algorithms and constraint programming to support stress testing of task deadlines},
  journal   = {ACM Transactions on Software Engineering and Methodology},
  year      = {2015},
  volume    = {25},
  number    = {1},
  issn      = {1049331X},
  note      = {Constraint programming;Environment state;Real-time embedded systems;Search strategies;Search-based software testing;Stress Testing;Task deadline;Worst case scenario;},
  abstract  = {Tasks in real-time embedded systems (RTES) are often subject to hard deadlines that constrain how quickly the system must react to external inputs. These inputs and their timing vary in a large domain depending on the environment state and can never be fully predicted prior to system execution. Therefore, approaches for stress testing must be developed to uncover possible deadline misses of tasks for different input arrival times. In this article, we describe stress-test case generation as a search problem over the space of task arrival times. Specifically, we search for worst-case scenarios maximizing deadline misses, where each scenario characterizes a test case. In order to scale our search to large industrial-size problems, we combine two state-of-the-art search strategies, namely, genetic algorithms (GA) and constraint programming (CP). Our experimental results show that, in comparison with GA and CP in isolation, GA+CP achieves nearly the same effectiveness as CP and the same efficiency and solution diversity as GA, thus combining the advantages of the two strategies. In light of these results, we conclude that a combined GA+CP approach to stress testing is more likely to scale to large and complex systems. 2015 Copyright is held by the owner/author(s).<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Genetic algorithms},
  keywords  = {Computer programming;Constraint theory;Embedded systems;Interactive computer systems;Real time systems;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2818640},
}

@InProceedings{He2014,
  author    = {He, Zhong Hai and Zhang, Xiang and Zhu, Xiang Yin},
  title     = {Design and implementation of automation testing framework based on keyword driven},
  year      = {2014},
  volume    = {602-605},
  pages     = {2142 - 2146},
  address   = {Chongqing, China},
  note      = {Automated testing;Automation testing;Design and implementations;Key technologies;Keyword driven;Overall efficiency;System architectures;Test scripts;},
  abstract  = {For the purpose of settling problems in the present automated testing frameworks, the paper presents an automated testing framework based on keyword driven technology. At first, it summarized and analyzed the recent automated testing frameworks; and then it proposed the framework's system architecture, and also presented the key technology details of the framework. At last, this paper compared this paper's framework with the recent frameworks by the IP phone, which proved that this framework had superiority in reducing the scale of test scripts, raising the overall efficiency of testing and so on. &copy; (2014) Trans Tech Publications, Switzerland.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {16609336},
  journal   = {Applied Mechanics and Materials},
  key       = {Software testing},
  keywords  = {Materials;Mechanics;},
  language  = {English},
  url       = {http://dx.doi.org/10.4028/www.scientific.net/AMM.602-605.2142},
}

@InBook{Jang2007,
  pages     = {143 - 146},
  title     = {Study on the Establishment of Dynamic Performance Test Environment for the Digital Protective Relay using RTDS},
  year      = {2007},
  author    = {Jang, ByungTae and Choe, ChangYoul and Jung, GilJo},
  note      = {Digital protective relay;Dynamic performance tests;Equivalent impedance;Korea electric power research institutes;Performance tests;Performance verification;Real time digital simulator;Test equipments;},
  abstract  = {This chapter presents a study on the establishment of dynamic performance test environment for the digital protective relay using real time digital simulator (RTDS). A performance test of digital protective relay is divided into three parts, which include a static test, a dynamic test, and EMC test. Among these, a dynamic test the most important, but it is not easy to diffuse a technique for dynamic test because of the intricate approach to real time digital simulator. To solve these problems, Korea Electric Power Research Institute (KEPRI) has established environments for performance test, which consist of a system model and a performance test procedure for the dynamic test. Differing from the general test equipment, RTDS has a strong point to examine real time close-loop test. Since users should articulately use both software (PSCAD) and hardware (RTDS), it is difficult for the users to access a dynamic performance test. The system modeling was performed by using equivalent impedance data of transmission line, equivalent impedance data of bus, and no load loss data of transformer. When carrying out performance test of the digital protective relay by using RTDS in domestic and overseas organizations, engineers can utilize this procedure for examining reliability and propriety in terms of the result of performance verification test. &copy; 2007 Elsevier Ltd All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Power Plants and Power Systems Control 2006},
  key       = {Software testing},
  keywords  = {Electric fault currents;Electromagnetic compatibility;Equipment testing;Equivalent circuits;Mechanisms;Relay protection;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/B978-008046620-0/50024-4},
}

@InProceedings{Mazzetta2009,
  author    = {Mazzetta, Jason A. and Scopatz, Stephen D.},
  title     = {Ultraviolet through infrared imager performance testing},
  year      = {2009},
  volume    = {7481},
  pages     = {SPIE Europe -},
  address   = {Berlin, Germany},
  note      = {Blackbody;Integrating spheres;Multi-spectral;Ultraviolet;Visible;},
  abstract  = {The objective of any imaging system is to optimize the amount of pertinent information collected from a scene. Whether it is used for artistic reproduction, scientific research, or camouflage detection, a camera has the same ultimate requirement. In the era of broadband, multi-spectral, hyperspectral, and fused sensor systems, both spectral and spatial data continue to play battling roles in determining which is dominant in how well an imaging system meets its definitive objective. Typically sensor testing requires hardware and software exclusively designed for the spectral region of interest. Thus an imaging system with ultraviolet through infrared imaging capabilities could require three or more separate test benches for sensor characterization. Obviously this not only increases the complexity, and subsequently the cost of testing, but also more importantly tends to produce discontinuous results. This paper will outline the hardware and software developed by the authors that employ identical test methods and shared optics to complete infrared, visible, and ultraviolet sensor performance analysis. Challenges encompassing multiple emitting source switching, splitting, and combining will be addressed along with new single fused type source designs. Decisions related to specifying optics and targets of sufficient quality and construction to provide coverage of the full spectral region will be discussed along with sample performance specifications and data. Test methodology controlled by a single automated software suite will be summarized including modulation transfer function, signal to noise ratio, uniformity, focus, distortion, intrascene dynamic range, and sensitivity. Selected examples of results obtained by this test set will be presented. &copy; 2009 SPIE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {0277786X},
  journal   = {Proceedings of SPIE - The International Society for Optical Engineering},
  key       = {Signal to noise ratio},
  keywords  = {Hardware;Hyperspectral imaging;Image segmentation;Imaging systems;Infrared devices;Infrared radiation;Optics;Software testing;Testing;Thermography (imaging);},
  language  = {English},
  url       = {http://dx.doi.org/10.1117/12.830536},
}

@InProceedings{Subtirelu2016,
  author    = {Subtirelu, Gheorghe-Eugen and Dobriceanu, Mircea and Linca, Mihaita},
  title     = {Virtual instrumentation for no-load testing of induction motor},
  year      = {2016},
  pages     = {854 - 859},
  address   = {Varna, Bulgaria},
  note      = {Graphical presentations;Labview graphical programming;Measurement and analysis;Principal Components;Real time acquisition;Three phase induction motor;Virtual Instrumentation;Virtual measurement system;},
  abstract  = {The main objective of this paper is to solve a practical and current problem, by taking advantage of the virtual instrumentation in testing electrical machines. The abilities of virtual instrumentation are used to data acquisition, measurement and analyze the values of no-load testing's parameters for three-phase induction motor. The virtual measurement system bench is designed and consist from two principal components: the hardware components (six LEM transducers for measuring three voltages and three currents; elements for signal conditioning and power transducers; USB multifunction Input / Output module; a personal computer) and the software components (operating system for the computer; drivers for the acquisition and manipulation of data; virtual instrument for calculation and graphical presentation of results). The LabVIEW graphical programming environment is used for designing virtual instrument. This virtual measurement system bench is an easy to use device which can be used in engineering education laboratories from universities or in electrical machines testing workbenches; it is capable of data acquisition, storage or memorization on different media, visualization of different graphs or analysis on-line or off-line of the results obtained. The virtual measurement system described in the paper can work independently (in the Simulation mode or Real time Acquisition mode) or integrated as part of a future complex virtual system for measurement and analysis in the domain of electrical machines testing workbenches. &copy; 2016 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - 2016 IEEE International Power Electronics and Motion Control Conference, PEMC 2016},
  key       = {Electric variables measurement},
  keywords  = {Automobile engines;Computer graphics;Computer hardware;Computer operating systems;Data acquisition;Data visualization;Digital instruments;Digital storage;Distance education;Electric machinery;Induction motors;Load testing;Motion control;Personal computers;Power control;Power electronics;Transducers;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/EPEPEMC.2016.7752106},
}

@Article{Alessandro2015,
  author    = {Alessandro, Velenosi and Gianni, Campatelli and Antonio, Scippa},
  title     = {Axis geometrical errors analysis through a performance test to evaluate kinematic error in a five axis tilting-rotary table machine tool},
  journal   = {Precision Engineering},
  year      = {2015},
  volume    = {39},
  pages     = {224 - 233},
  issn      = {01416359},
  note      = {Accuracy;Cutting test;Different architectures;Five-axis machine tools;Indirect measurements;Kinematic error;Laser interferometer;Straightness errors;},
  abstract  = {Geometrical work piece errors in milling process are commonly generated by different error sources. Axis geometrical errors, such as the straightness error for linear axis and the offset location error of the origin of rotary axis, introduce kinematic error in the tool path. Direct measurement of kinematic error requires special devices such as laser interferometers, grid plate encoders or double ball bars, which impose production stop and specialized staff. These problems could be analyzed using indirect measurements obtained by means of a cutting performance test that is already a standard for three axis machine tools. Because of the different architectures of five-axis milling machines these tests are hardly standardizable, therefore this paper proposes a devised easy-to-use and time efficient cutting performance test to identify and quantify axis geometrical errors for a five axis tilting-rotary table machine tool. This test can be performed as a periodical checkup or, in case of production, as a re-start test. The main goal of this study is to develop a kinematic analytical model capable of correlating the work-piece geometrical errors to the axis geometrical errors of the machine tool. The model has been implemented on a multi-body software in order to simulate the axes motion sequence of the performance test and validated to decouple the kinematic error into the geometrical axis errors. The developed models have demonstrated to be capable of correcting a generic five axis tool path by predicting the tool-path error displacement. The overall validation of this approach has been carried out by comparing the simulated and experimentally measured profile of the NAS 979 standard five axis contouring cone frustum profile.<br/> &copy; 2014 Elsevier Inc.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Errors},
  keywords  = {Cutting tools;Geometry;Interferometers;Kinematics;Laser interferometry;Machine tools;Milling (machining);Milling machines;Software testing;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.precisioneng.2014.09.007},
}

@InProceedings{Nagowah2012,
  author    = {Nagowah, Leckraj and Sowamber, Gayeree},
  title     = {A novel approach of automation testing on mobile devices},
  year      = {2012},
  volume    = {2},
  pages     = {924 - 930},
  address   = {Kuala Lumpur, Malaysia},
  note      = {Automation testing;Mobile application testing;Mobile applications;Mobile device test automations;Mobile test automation frameworks;Mobile testing;Test automation tool;Testing infrastructure;},
  abstract  = {Mobile phones and mobile applications have now become an integral part of our everyday life. Mobile application testing plays a pivotal role in making the mobile applications more reliable and defect free. Existing test automation tools have been tailored to perform mobile test automation through mobile emulators. Other tools require the mobile device where the application is installed, to be connected to a computer so that the tests can be run. Obviously, the results obtained from emulators often differ from those obtained on actual mobile devices. To our best knowledge only a few solutions for creating automated tests of mobile applications exist and their functionality is very limited. In this paper, we introduce the idea of implementing a mobile test automation framework MobTAF which performs mobile test automation on the mobile device where connection to a computer is not required. The framework moves the testing infrastructure to the phone, to support test situations that cannot easily be replicated with an emulator. A prototype application was then implemented to test the mobile automation framework, MobTAF. The results prove that MobTAF framework is an efficient way of performing mobile application tests directly on the mobile devices. &copy; 2012 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {2012 International Conference on Computer and Information Science, ICCIS 2012 - A Conference of World Engineering, Science and Technology Congress, ESTCON 2012 - Conference Proceedings},
  key       = {Software testing},
  keywords  = {Application programs;Automation;Mobile computing;Mobile devices;Telephone sets;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICCISci.2012.6297158},
}

@InProceedings{Lan2012,
  author    = {Lan, Yuqing and Xu, Hao and Liu, Xiaohui},
  title     = {The research of performance test method for Linux process scheduling},
  year      = {2012},
  pages     = {216 - 219},
  address   = {Shanghai, China},
  note      = {Benchmark tests;linux;Performance analysis;Performance testing;Process scheduling;},
  abstract  = {Performance test plays a fundamental and irreplaceable role in the field of software test, especially in guaranteeing the quality and reliability of an operating system. The performance of the process scheduling subsystem directly affects the accuracy and stability of the whole operating system. Linux operating system vendors execute performance test almost in every period of the Linux operating system research and development to enhance their products' competitiveness. However, the lack of methods and tools for the Linux process scheduling performance test has caused great difficulties for Linux operating system vendors to evaluate and tune the Linux kernel performance. Therefore, in order to solve the issues mentioned above, this paper, based on the analysis of Linux process scheduling mechanism, proposes a Linux process scheduling performance test method, implements a Linux process scheduling performance test tool as well, and finally validates the tool experimentally. &copy; 2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of the 2012 4th International Symposium on Information Science and Engineering, ISISE 2012},
  key       = {Computer operating systems},
  keywords  = {Benchmarking;Competition;Information science;Scheduling;Software reliability;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ISISE.2012.54},
}

@Article{Sun2007,
  author    = {Sun, Yong-Zhao and Li, Wei-Dong and Mao, Ze-Pu and Ma, Qiu-Mei and Ma, Xiang and Wang, Liang-Liang and Wang, Ji-Ke and Deng, Zi-Yan and You, Zheng-Yun and Wen, Shuo-Pin and Bian, Jian-Ming and Sun, Sheng-Sen and Zhu, Yong-Sheng and Liu, Huai-Min and Liu, Chun-Xiu and Wu, Ling-Hui and Li, Hai-Bo and Li, Gang and Zhang, Chang-Chun and Zhang, Ling and Zhang, Yao and Zhang, Xue-Yao and Zhang, Jian-Yong and Zou, Jia-Heng and Qiu, Jin-Fa and He, Miao and He, Kang-Lin and Ji, Xiao-Bin and Yang, Ming and Yuan, Chang-Zheng and Mao, Ya-Jun and Yu, Guo-Wei and Mo, Xiao-Hu and Yuan, Ye and Cao, Guo-Fu and Huang, Bin and Xie, Yu-Guang and Zang, Shi-Lei},
  title     = {BES III offline software system and performance test},
  journal   = {Hedianzixue Yu Tance Jishu/Nuclear Electronics and Detection Technology},
  year      = {2007},
  volume    = {27},
  number    = {5},
  pages     = {842 - 846},
  issn      = {02580934},
  abstract  = {The offline software for the BESIII experiment and the control flow for data processing are described. With the software tool, Tuning and Analysis Utilities (TAU), its system performance has been measured. The BESIII computing requirements have been re-estimated and results are consistent with the previous calculation in the BESIII Technical Design Report.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  language  = {Chinese},
}

@InProceedings{Bennett2011,
  author    = {Bennett, Paul M. and Brown, Laura L.},
  title     = {Recent successes and changes of the HPCMP sustained systems performance test},
  year      = {2011},
  pages     = {453 - 462},
  address   = {Schaumburg, IL, United states},
  note      = {High performance computing modernization programs;Numerical accuracy;Performance issues;Sustained systems;System acquisition;System administrators;Systems under tests;Technology insertion;},
  abstract  = {The sustained systems performance (SSP) test has been implemented on certain High Performance Computing Modernization Program (HPCMP) HPC systems in order to quantitatively evaluate updates to system software, hardware repairs, job queuing policy modifications, and revisions to the job scheduler as necessary. The test employs codes used in the system acquisition cycle with proven migration capability to HPCMP HPC systems and non-empirical tests for numerical accuracy. Metrics such as compilation time, queue wait time, benchmark execution time, and total test throughput time are gathered and compared against metric data from previous tests to monitor the systems under test while minimizing impact to the users. Jobs failing to execute properly or in anomalously short or long times are investigated, and the results are reported to system administrators and center directors at each center for appropriate actions. During the past year, the SSP test has been instrumental in surfacing configuration issues with the PBS scheduler and performance issues on several HPC systems. Additionally, the frequency of the SSP test on systems procured in Technology Insertion 2009 (TI-09) and thereafter has increased, with attendant changes in the test cases comprising the test. The SSP test continues to play an important role in monitoring the quality of service delivering HPC to HPCMP users at the system, DoD Supercomputing Resource Center, and vendor levels. &copy; 2011 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - 2010 DoD High Performance Computing Modernization Program Users Group Conference, HPCMP UGC 2010},
  key       = {Software testing},
  keywords  = {Modernization;Quality of service;Scheduling;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/HPCMP-UGC.2010.46},
}

@Article{Zhang2006,
  author    = {Zhang, Bao-Gang and Cheng, Xi-Ming},
  title     = {Study on APU performance test based on virtual instrument technology},
  journal   = {Beijing Ligong Daxue Xuebao/Transaction of Beijing Institute of Technology},
  year      = {2006},
  volume    = {26},
  number    = {SUPPL. 2},
  pages     = {26 - 30},
  issn      = {10010645},
  note      = {Auxiliary power unit (APU);Graphical programming environment Lab VIEW;Human machine interface;PCI-DAQ board;Test system;Virtual instrument (VI);},
  abstract  = {The dynamic performance test of the auxiliary power unit (APU) is built on virtual instrument (VI) to evaluate its controls applied on the series hybrid electric vehicle. And its test method is presented. This test system is developed on a PCI-DAQ board and an industrial PC as its hardware basis and the graphical programming environment LabVIEW as its software platform, on which signals of the engine ECU and multi-sensor are adopted, adjusted, filtered, stored and processed to analyze the control performance of the APU. This test data shoud that the VI method is proved exact for the APU control system in practice.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Electric vehicles},
  keywords  = {Analog to digital conversion;Data acquisition;Dynamics;Hardware;Sensors;Software design;},
  language  = {Chinese},
}

@Article{Li2010,
  author    = {Li, Jie and Shen, Qiang and Tang, Wan-Ling and Zhao, Hong-Juan and Peng, Hong-Sheng},
  title     = {Dynamic GPS receiver carrier-wave Doppler analysis and loop tracking performance test},
  journal   = {Beijing Ligong Daxue Xuebao/Transaction of Beijing Institute of Technology},
  year      = {2010},
  volume    = {30},
  number    = {2},
  pages     = {136 - 139},
  issn      = {10010645},
  note      = {Carrier waves;Doppler frequency shift;Dynamic condition;First-order frequency;GPS receivers;Satellite signals;Software receivers;Tracking performance;},
  abstract  = {Against the problem that the ordinary GPS receiver can not work normally under the dynamic conditions of the cannon-launched guided ammunition, this paper adopts SPIRENT satellite signal simulator to analyze the carrier-wave Doppler frequency and its variation rate under several dynamic conditions, and generate the satellite signal under different dynamic status conditions of the carrier. A software receiver is utilized to perform the test to analyze on the performances of the tracking loop adopting the second-order and third-order phase-locked loops (PLL), the second-order PLL assisted by the first-order frequency-locked loop (FLL), and the third-order PLL assisted by the second-order FLL. It shows that when the acceleration is 40g, only PLL will lose lock, while the PLL assisted by the FLL tracks normally. However, in ballistic environment, the second-order PLL assisted by the first-order FLL tracks normally by one channel, the third-order PLL assisted by the second-order FLL tracks normally by two channels. This paper puts forward an improvement proposal for the carrier-wave tracking loop.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Global positioning system},
  keywords  = {Doppler effect;Locks (fasteners);Phase locked loops;Satellites;Signal receivers;Software testing;},
  language  = {Chinese},
}

@InProceedings{Zhuang2013,
  author    = {Zhuang, Lei and Gao, Zhen and Wu, Hao and Yang, Chun Xin and Zheng, Miao},
  title     = {Research on DB2 performance testing automation},
  year      = {2013},
  volume    = {756-759},
  pages     = {2204 - 2208},
  address   = {Nanjing, Jiangsu, China},
  note      = {Automated testing;Automated testing tools;Continuous improvements;Performance testing;Quality requirements;RFT;Software development and maintenances;Testing framework;},
  abstract  = {Software testing play a significant role in modern software development and maintenance process, which is also an important means to ensure software reliability and improve software quality. With the continuous improvement of quality requirements of the software products and software engineering technology become more sophisticated, software testing has been participating into every phase of software lift cycle, become more and more important in software development and maintenance. DB2 Performance testing consists of four parts, which are environment setup, workload run, data measurement and environment clean up. Before all the operations are done manually and need about two hours' continuous attention. What's worse, even three times a day. This mechanical and complicated procedure is clearly unacceptable. This paper put forward a reusable automated testing framework based on IBM automated testing tools RFT to achieve the whole testing procedure automation. It reduces the count of human-computer interaction and greatly improves the efficiency of DB2 performance testing. &copy; (2013) Trans Tech Publications, Switzerland.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {10226680},
  journal   = {Advanced Materials Research},
  key       = {Information technology},
  keywords  = {Computer software selection and evaluation;Maintenance;Materials science;Software design;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.4028/www.scientific.net/AMR.756-759.2204},
}

@Article{Maalej2015,
  author    = {Maalej, Afef Jmal and Krichen, Moez and Jmaiel, Mohamed},
  title     = {A comparative evaluation of state-of-the-art load and stress testing approaches},
  journal   = {International Journal of Computer Applications in Technology},
  year      = {2015},
  volume    = {51},
  number    = {4},
  pages     = {283 - 293},
  issn      = {09528091},
  note      = {Comparative evaluations;Emerging paradigms;Performance monitoring;State of the art;Stress Testing;Web service composition;},
  abstract  = {In order to deliver quality assured software and avoid potential costs caused by unstable software, testing is essential in software life cycle. Load testing is one of the testing types with high importance. It is usually accompanied by performance monitoring of the hosting environment. The purpose of this paper is to present related solutions to both load and stress testing issues in different fields and emerging paradigms, and to evaluate them in order to identify their advantages and their shortcomings. Looking at the areas focused by existing researchers, gaps and untouched zones of different systems relatively to load testing can be discovered. This investigation will especially allow promoting future research in the context of load testing of web service compositions, considered as an arising concept in service-oriented architecture (SOA).<br/> &copy; 2015 Inderscience Enterprises Ltd.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Load testing},
  keywords  = {Application programs;Computer applications;Information services;Life cycle;Service oriented architecture (SOA);Software architecture;Software testing;Web services;Websites;},
  language  = {English},
  url       = {http://dx.doi.org/10.1504/IJCAT.2015.070491},
}
{20181905163736,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Standard Guide for Thermal Performance Testing of Cryogenic Insulation Systems},
journal = {Standard Guide for Thermal Performance Testing of Cryogenic Insulation Systems},
year = {2013},
abstract = {Scope: This guide provides information for the laboratory measurement of the steady-state thermal transmission properties and heat flux of thermal insulation systems under cryogenic conditions. Thermal insulation systems may be composed of one or more materials that may be homogeneous or non-homogeneous; flat, cylindrical, or spherical; at boundary conditions from near absolute zero or 4 K up to 400 K; and in environments from high vacuum to an ambient pressure of air or residual gas. The testing approaches presented as part of this guide are distinct from, and yet complementary to, other ASTM thermal test methods including C177, C518, and C335. A key aspect of this guide is the notion of an insulation system, not an insulation material. Under the practical use environment of most cryogenic applications even a single-material system can still be a complex insulation system (1-3).<sup>2</sup>To determine the inherent thermal properties of insulation materials, the standard test methods as cited in this guide should be consulted. The function of most cryogenic thermal insulation systems used in these applications is to maintain large temperature differences thereby providing high levels of thermal insulating performance. The combination of warm and cold boundary temperatures can be any two temperatures in the range of near 0 K to 400 K. Cold boundary temperatures typically range from 4 K to 100 K, but can be much higher such as 300 K. Warm boundary temperatures typically range from 250 K to 400 K, but can be much lower such as 40 K. Large temperature differences up to 300 K are typical. Testing for thermal performance at large temperature differences with one boundary at cryogenic temperature is typical and representative of most applications. Thermal performance as a function of temperature can also be evaluated or calculated in accordance with Practices C1058 or C1045 when sufficient information on the temperature profile and physical modeling are available. The range of residual gas pressures for this Guide is from 10<sup>-7</sup>torr to 10<sup>+3</sup>torr (1.33<sup>-5</sup>Pa to 133 kPa) with different purge gases as required. Corresponding to the applications in cryogenic systems, three sub-ranges of vacuum are also defined: High Vacuum (HV) from &lt;10<sup>-6</sup>torr to 10<sup>-3</sup>torr (1.333<sup>-4</sup>Pa to 0.133 Pa) [free molecular regime], Soft Vacuum (SV) from 10<sup>-2</sup>torr to 10 torr (from 1.33 Pa to 1,333 Pa) [transition regime], No Vacuum (NV) from 100 torr to 1000 torr (13.3 kPa to 133 kPa) [continuum regime]. Thermal performance can vary by four orders of magnitude over the entire vacuum pressure range. Effective thermal conductivities can range from 0.010 mW/m-K to 100 mW/m-K. The primary governing factor in thermal performance is the pressure of the test environment. High vacuum insulation systems are often in the range from 0.05 mW/m-K to 2 mW/m-K while non-vacuum systems are typically in the range from 10 mW/m-K to 30 mW/m-K. Soft vacuum systems are generally between these two extremes (4). Of particular demand is the very low thermal conductivity (very high thermal resistance) range in sub-ambient temperature environments. For example, careful delineation of test results in the range of 0.01 mW/m-K to 1 mW/m-K (from R-value 14,400 to R-value 144) is required as a matter of normal engineering applications for many cryogenic insulation systems (5-7). The application of effective thermal conductivity values to multilayer insulation (MLI) systems and other combinations of diverse materials, because they are highly anisotropic and specialized, must be done with due caution and full provision of supporting technical information (8). The use of heat flux (W/m<sup>2</sup>) is, in general, more suitable for reporting the thermal performance of MLI systems (9-11). This guide covers different approaches for thermal performance measurement in sub-ambient temperature environments. The test apparatuses (apparatus) are divided into two categories: boiloff calorimetry and electrical power. Both absolute and comparative apparatuses are included. This guide sets forth the general design requirements necessary to construct and operate a satisfactory test apparatus. A wide variety of apparatus constructions, test conditions, and operating conditions are covered. Detailed designs are not given but must be developed within the constraints of the general requirements. Examples of different cryogenic test apparatuses are found in the literature (12). These apparatuses include boiloff types (13-17) as well as electrical types (18-21). These testing approaches are applicable to the measurement of a wide variety of specimens, ranging from opaque solids to porous or transparent materials, and a wide range of environmental conditions including measurements conducted at extremes of temperature and with various gases and over a range of pressures. Of particular importance is the ability to test highly anisotropic materials and systems such as multilayer insulation (MLI) systems (22-25). Other test methods are limited in this regard and do not cover the testing of MLI and other layered systems under the extreme cryogenic and vacuum conditions that are typical for these systems. In order to ensure the level of precision and accuracy expected, users applying this standard must possess a working knowledge of the requirements of thermal measurements and testing practice and of the practical application of heat transfer theory relating to thermal insulation materials and systems. Detailed operating procedures, including design schematics and electrical drawings, should be available for each apparatus to ensure that tests are in accordance with this Guide. In addition, automated data collecting and handling systems connected to the apparatus must be verified as to their accuracy. Verification can be done by calibration and comparing data sets, which have known results associated with them, using computer models. It is impractical to establish all details of design and construction of thermal insulation test equipment and to provide procedures covering all contingencies associated with the measurement of heat flow, extremely delicate thermal balances, high vacuum, temperature measurements, and general testing practices. The user may also find it necessary, when repairing or modifying the apparatus, to become a designer or builder, or both, on whom the demands for fundamental understanding and careful experimental technique are even greater. The test methodologies given here are for practical use and adaptation as well as to enable future development of improved equipment or procedures. This guide does not specify all details necessary for the operation of the apparatus. Decisions on sampling, specimen selection, preconditioning, specimen mounting and positioning, the choice of test conditions, and the evaluation of test data shall follow applicable ASTM Test Methods, Guides, Practices or Product Specifications or governmental regulations. If no applicable standard exists, sound engineering judgment that reflects accepted heat transfer principles must be used and documented. This guide allows a wide range of apparatus design and design accuracy to be used in order to satisfy the requirements of specific measurement problems. Compliance with a further specified test method should include a report with a discussion of the significant error factors involved as well the uncertainty of each reported variable. The values stated in SI units are to be regarded as the standard. The values given in parentheses are for information only. Either SI or Imperial units may be used in the report, unless otherwise specified. Safety precautions including normal handling and usage practices for the cryogen of use. Prior to operation of the apparatus with any potentially hazardous cryogen or fluid, a complete review of the design, construction, and installation of all systems shall be conducted. Safety practices and procedures regarding handling of hazardous fluids have been extensively developed and proven through many years of use. For systems containing hydrogen, particular attention shall be given to ensure the following precautions are addressed: (1) adequate ventilation in the test area, (2) prevention of leaks, (3) elimination of ignition sources, (4) fail safe design, and (5) redundancy provisions for fluid fill and vent lines. This standard does not purport to address all of the safety concerns, if any, associated with its use. It is the responsibility of the user of this standard to establish appropriate safety and health practices and determine the applicability of regulatory limitations prior to use. Major sections within this standard are arranged as follows: (Table Presented)<br/> &copy;2013 ASTM International. All rights reserved.},
key = {Thermal insulation},
keywords = {Anisotropy;Construction equipment;Cryogenics;Data handling;Equipment testing;Hazards;Heat flux;Heating equipment;Materials testing;Multilayers;Permafrost;Software testing;Tapes;Temperature;Temperature measurement;Thermal conductivity;Thermal insulating materials;Vacuum applications;},
note = {Effective thermal conductivity;Environmental conditions;Governmental regulations;Low thermal conductivity;Temperature environments;Thermal insulation materials;Thermal insulation systems;Thermal performance testing;},
URL = {http://dx.doi.org/10.1520/C1774},
versions = {1},
standard designation = {C1774},
standardID = {C1774-13},
}

@InProceedings{Bondi2009,
  author    = {Bondi, Andre B. and Ros, Johannes P.},
  title     = {Experience with training a remotely located performance test team in a quasi-agile global environment},
  year      = {2009},
  pages     = {254 - 261},
  address   = {Limerick, Ireland},
  note      = {Cultural difference;Global environment;Laboratory procedures;On-site training;Performance testing;Performance tests;Prior experience;Time-differences;},
  abstract  = {We describe our experience of training a remotely located team of developers and testers to prepare and execute performance tests. The team is located in India. The lead performance engineer and the test project manager are based in New Jersey. The team members had little or no prior experience of performance testing. We describe how we overcame cultural differences and a large time difference to develop a performance testing team that is now functioning well with far less supervision than was required at its inception. Cultural differences included contrasting views on adherence to strict laboratory procedures and assumptions about the prior knowledge, experience, and expectations of working habits of the India-based and New Jersey-based teams. We show how these differences and organizational challenges were overcome with intensive on-site training, the use of twice-daily scrum meetings, the careful designation of team leaders and role players at the remote testing site, and, eventually, the development intensive use of automated tools to execute performance tests and track the results. &copy; 2009 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - 2009 4th IEEE International Conference on Global Software Engineering, ICGSE 2009},
  key       = {Personnel training},
  keywords  = {Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICGSE.2009.34},
}

@InProceedings{Pan2007,
  author    = {Pan, Lei and Batten, Lynn M.},
  title     = {A lower bound on effective performance testing for digital forensic tools},
  year      = {2007},
  pages     = {117 - 130},
  address   = {Bell Harbor, WA, United states},
  note      = {Abstraction layer model;Orthogonal arrays;Partition testing;SADFE;Software performance;},
  abstract  = {The increasing complexity and number of digital forensic tasks required in criminal investigations demand the development of an effective and efficient testing methodology, enabling tools of similar functionalities to be compared based on their performance. Assuming that the tool tester is familiar with the underlying testing platform and has the ability to use the tools correctly, we provide a numerical solution for the lower bound on the number of testing cases needed to determine comparative capabilities of any set of digital forensic tools. We also present a case study on the performance testing of password cracking tools, which allows us to confirm that the lower bound on the number of testing runs needed is closely related to the row size of certain orthogonal arrays. We show how to reduce the number of test runs by using knowledge of the underlying system. &copy; 2007 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - SADFE 2007: Second International Workshop on Systematic Approaches to Digital Forensic Engineering},
  key       = {Software testing},
  keywords  = {Computational complexity;Computer aided software engineering;Data reduction;Parallel processing systems;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/SADFE.2007.2},
}

@InProceedings{Baltas2012,
  author    = {Baltas, Nikos and Field, Tony},
  title     = {Continuous performance testing in virtual time},
  year      = {2012},
  pages     = {13 - 22},
  address   = {London, United kingdom},
  note      = {Execution time;Global virtual time;Java applications;Performance engineering;Performance Model;Performance testing;Program code;Software performance;Software performance testing;Unified framework;Virtual execution;Virtual-time;},
  abstract  = {In this paper we show how program code and performance models can be made to cooperateseamlessly to support continuous software performance testing throughout thedevelopment lifecycle. We achieve this by extending our existing VEXtool for executing programs in virtual time so that events that occurduring normal execution and those that occur during the simulation of a performance model can bescheduled on a single global virtual time line. The execution time of anincomplete component of an application is thus estimated by a performance model, whilstthat of existing code is measured by instrumentation that is added dynamicallyat program load time. A key challenge is to be able to map some or all of the resourcesin a performance model to the real resources of the host platform on which theapplication is running. We outline a continuous performance engineering methodologythat exploits our unified framework and illustrate the principles involved byway of a simple Java application development case study. &copy; 2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - 2012 9th International Conference on Quantitative Evaluation of Systems, QEST 2012},
  key       = {Software testing},
  keywords  = {Computer simulation;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/QEST.2012.26},
}

@Article{Eschelbach1984,
  author    = {Eschelbach, R.E.},
  title     = {'ASAP': A microcomputer-based automated safety and performance testing system},
  journal   = {Journal of clinical engineering},
  year      = {1984},
  volume    = {9},
  number    = {1},
  pages     = {21 - 27},
  issn      = {03638855},
  note      = {AUTOMATED PERFORMANCE TESTING;AUTOMATED SAFETY TESTING;MICROCOMPUTERS;},
  abstract  = {An HP-85 microcomputer programmed in BASIC was interfaced to a PEI 2000 safety analyzer via an HP-6942A Multiprogrammer and appropriate interface cards. This configuration allows automated safety and performance testing as well as report generation. The system is operated by means of a menu displayed on a built-in CRT and the keyboard. Data are displayed and then stored on the built-in cassette unit. Additional testing features are easily added with minimal software development, since all programming is in BASIC and all interface drivers are part of the hardware.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {BIOMEDICAL EQUIPMENT},
  keywords  = {COMPUTER PROGRAMMING LANGUAGES - BASIC;COMPUTERS, MICROPROCESSOR - Medical Applications;DATA STORAGE, MAGNETIC - Tape;DISPLAY DEVICES - Medical Applications;MAINTENANCE - Computer Applications;},
  language  = {English},
}

@Article{Izworski2004,
  author    = {Izworski, Antoni and Skowronski, Slawomir and Lewoc, Jozef B.},
  title     = {A MSK performance testing/measuring tool sitwa},
  journal   = {Advances in Modelling and Analysis B},
  year      = {2004},
  volume    = {47},
  number    = {5-6},
  pages     = {77 - 90},
  issn      = {12404543},
  note      = {Internal tools;MSK performance testing;Network development;TCP/IP networks;},
  abstract  = {It is rather difficult to find detailed and in-depth references concerning communication network performance testing/measuring tools. Therefore, the paper presents the solution developed earlier for the Interuniversity Computer Network in Poland. The structure and the functionality of the tool described are modified so that the description may be directly applied to TCP/IP networks. Some testing/measuring results are presented and benefits gained are discussed. The possible use of similar solution in present day communication networks is depicted.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Computer networks},
  keywords  = {Computer software;Data transfer;Measurement theory;Microcomputers;Network protocols;Telecommunication networks;Testing;},
  language  = {English},
}

@InProceedings{Gottifredi2008,
  author    = {Gottifredi, F. and Martinino, F. and Morante, Q. and Eleuteri, M. and Varriale, E. and Valle, V. and Pesci, G.},
  title     = {Galileo test range: Performance test results},
  year      = {2008},
  address   = {Toulouse, France},
  note      = {Achievable performance;Application services;Directional Antenna;Laboratory facilities;Long term stability;Navigation performance;Satellite navigation;Time synchronization;},
  abstract  = {The Galileo Test Range (GTR) project is an initiative of Regione Lazio in the frame of its support to the Italian technical research and innovation in satellite navigation. It is born as the Italian National permanent Laboratory for the experimentation and analysis of the Galileo Signal, for testing and certification of user terminals and support services for the development of application services. The development of the GTR is foreseen in two phases: - Phase A = Definition and Start up: implementation of the initial system, based on the generation on ground of navigation signals (GPS-like), using pseudolite technology (4 PSL), and to receive real signals coming from GPS, EGNOS and the new GIOVE-A Experimental Satellite. - Phase B = Full deployment and initialization of the GTR: implementation of the GTR final configuration, not only able to generate Galileo-like signals (from 9 PSL), but also to receive and process real signals coming from Galileo IOV satellites. The Phase A architecture is composed by the following macro segments: - The Analysis &amp; Control Centre composed by the Control Centre (CC) and all the specialized laboratories (i.e. Time, Orbitography, Synchronization, Integrity, R&amp;D); - The Experimental Area (covered by Differential Reference Stations) including the Test Area (covered by the Pseudolites - PSL) The 4 PSL deployed for the Phase A (2 fixed and 2 transportable) are equipped with the following main elements: &bull; an atomic reference clock composed by an OCXO locked to Rb oscillator in order to obtain good short and long term stability; &bull; a dual frequency GPS/SBAS Receiver Assembly; &bull; a GPS-like signal generator &bull; a directional antenna to disseminate the GPS-Like signal in the Test Area The PSL Receiver observables are sent to the GTR-CC and then to the Orbitography Laboratory Facility in charge of the Time Synchronization function of the GTR based on the SynchroNet product of TAS-I. The reference for this Synchronization is given by the Time Laboratory Facility, equipped with an Active Hydrogen Maser and 4 Caesium Clocks. The clock corrections are sent back to the PSL, uploaded in the Navigation Message and broadcasted to the Users in the Test Area. Users equipped with a GPS Receiver can connect it to a PC with a dedicated software (developed by TAS-I) that makes a data fusion between GPS satellites observables and PSL ones so as to compute a better 3D position. If required, the SW can compute a 2D solution using only the Pseudolite observables, Users can compute a 2D position. The PSLs guarantee in a flexible way, thanks to the transportable PSLs, an increased availability of GNSS-like signals in the Test Area that users can use to improve theirs navigation performances. The tests carried out show that the achievable performance in the Test Area with the 4 PSL of Phase A are in the order of 5 m in 3D and 3 m in 2D. With the upgrade foreseen in Phase B in number and type of signal, the performance achievable will improve and potential applications can be satisfied with the use of the PSL technology. The aims of this paper are to present the advantages of the availability of signals generated by PSLs (fixed and transportable) in a controlled area and to present the reached performances for the phase A of the GTR using PSLs. Furthermore it will be presented an overview on the potential applications for this technology that can be a good solution for all those environments that require augmentations in performance and availability (i.e. urban canyons, harbors, container movement, etc&mellip;).<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {ENC-GNSS 2008 - European Navigation Conference},
  key       = {Global positioning system},
  keywords  = {Clocks;Data fusion;Directive antennas;Geostationary satellites;Hydrogen masers;Laboratories;Navigation;Orbits;Signal receivers;Synchronization;Testing;},
  language  = {English},
}

@InProceedings{Ma2010,
  author    = {Ma, Bo and Chen, Bin and Bai, Xiaoying and Huang, Junfei},
  title     = {Design of BDI agent for adaptive performance testing of Web services},
  year      = {2010},
  pages     = {435 - 440},
  note      = {Adaptive testing;Autonomous decision;BDI Agent;Collaboration capabilities;Concurrent requests;Control architecture;Internet environment;Performance testing;},
  abstract  = {As services are dynamic discovered and bound in the open Internet environment, testing has to be exercised continuously and online to verify and validate the continuous changes and to ensure the quality of the integrated service-based system. During this process, testing strategies have to be adapted in accordance to the changes in the environment and target systems. Software agents are characterized by context awareness, autonomous decision making and social collaboration capabilities. The paper introduces the design of BDI (Believe-Decision-Intention) agents to facilitate adaptive performance testing of Web Services. The BDI model specifies the necessary test knowledge, test goal and action plan to carry out test and adaptive schedule. Performance testing is defined as a scheduling problem to select the workload and test cases in order to achieve the goal of performance abnormal detection. A two-level control architecture is built. At the TR (Test Runner) level, the BDI agents control the workload of concurrent requests. At the TC (Test Coordinator) level, the BDI agents control the complexity of test cases. Agents communicate and collaborate with each other to share knowledge and test plan. The paper introduces the design of the BDI model, the adaptation rules and the control architecture. Case study is exercised to illustrate the adaptive testing process based on the design of BDI agents. &copy; 2010 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {15506002},
  journal   = {Proceedings - International Conference on Quality Software},
  key       = {Web services},
  keywords  = {Autonomous agents;Concurrency control;Decision making;Intelligent agents;Software agents;Web crawler;Websites;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/QSIC.2010.69},
}

@Article{Li2007,
  author    = {Li, Fang and Weng, Wenbing and Wang, Hengshan and Liu, Zhanjie},
  title     = {Development of client-oriented computer integrated test and control system for thermal performance test},
  journal   = {Yi Qi Yi Biao Xue Bao/Chinese Journal of Scientific Instrument},
  year      = {2007},
  volume    = {28},
  number    = {8},
  pages     = {1445 - 1450},
  issn      = {02543087},
  abstract  = {High precision air conditioner performance test equipment should have good test and control means and client-friendly test software. The factors that influence air conditioner test precision were analyzed and a test and control system was designed. The test and control system is based on client-oriented principle; high performance measurement sensors, automatic control elements and touch-screen monitor are adopted, and critical control and data-acquisition software is written, which makes the system have good control precision, convenient operation, friendly interface and reliable performance. The system has been applied successfully in several air conditioner test equipment.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  language  = {Chinese},
}

@Article{Trubiani2018,
  author    = {Trubiani, Catia and Bran, Alexander and van Hoorn, Andre and Avritzer, Alberto and Knoche, Holger},
  title     = {Exploiting load testing and profiling for Performance Antipattern Detection},
  journal   = {Information and Software Technology},
  year      = {2018},
  volume    = {95},
  pages     = {329 - 345},
  issn      = {09505849},
  note      = {Anti-patterns;Complex software systems;Empirical data;Execution environments;Performance assessment;Performance measurements;Software characteristic;Software performance engineerings;},
  abstract  = {Context: The performance assessment of complex software systems is not a trivial task since it depends on the design, code, and execution environment. All these factors may affect the system quality and generate negative consequences, such as delays and system failures. The identification of bad practices leading to performance flaws is of key relevance to avoid expensive rework in redesign, reimplementation, and redeployment. Objective: The goal of this manuscript is to provide a systematic process, based on load testing and profiling data, to identify performance issues with runtime data. These performance issues represent an important source of knowledge as they are used to trigger the software refactoring process. Software characteristics and performance measurements are matched with well-known performance antipatterns to document common performance issues and their solutions. Method: We execute load testing based on the characteristics of collected operational profile, thus to produce representative workloads. Performance data from the system under test is collected using a profiler tool to create profiler snapshots and get performance hotspot reports. From such data, performance issues are identified and matched with the specification of antipatterns. Software refactorings are then applied to solve these performance antipatterns. Results: The approach has been applied to a real-world industrial case study and to a representative laboratory study. Experimental results demonstrate the effectiveness of our tool-supported approach that is able to automatically detect two performance antipatterns by exploiting the knowledge of domain experts. In addition, the software refactoring process achieves a significant performance gain at the operational stage in both case studies. Conclusion: Performance antipatterns can be used to effectively support the identification of performance issues from load testing and profiling data. The detection process triggers an antipattern-based software refactoring that in our two case studies results in a substantial performance improvement.<br/> &copy; 2017 Elsevier B.V.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Software testing},
  keywords  = {Load testing;Systems engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.infsof.2017.11.016},
}

@InProceedings{Badarinath2016,
  author    = {Badarinath, R. and Abhilash, M.T.},
  title     = {GP-GPU based high-performance test equipment for debugging radar digital units},
  year      = {2016},
  pages     = {387 - 391},
  address   = {Ernakulam, India},
  note      = {Active phased array radar;Built in tests;Development time;Digital beam forming;Graphical processing unit (GPUs);High throughput;Optimal performance;Performance tests;},
  abstract  = {Modern active phased array radars are made to optimize the size, weight and power without compromising its capability to combat with advanced electronic warfare. To accomplish this task, the signal is digitized at element level or at sub-array level and processed with the help of advanced digital signal processor. Proving the capabilities of this firmware at bench level helps to reduce the overall development time. Hence, it is necessary to have a built-in test unit or test vector generator to verify the optimal performance of digital modules. The best way to accomplish this goal is to use a high speed baseband I &amp; Q radar data generator which helps in testing, identifying and segregating the problems at various stages. In this paper we have explored the capability of latest general purpose graphical processing unit (GP-GPU) as software defined built in test vector generator with high throughput for active array radar applications. &copy; 2016 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of 2016 International Conference on Data Mining and Advanced Computing, SAPIENCE 2016},
  key       = {Digital signal processors},
  keywords  = {Application programs;Data mining;Electronic warfare;Equipment testing;Firmware;Program processors;Radar;Radar signal processing;Signal processing;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/SAPIENCE.2016.7684173},
}

@InProceedings{Zhang2016c,
  author    = {Zhang, Hailong and Nie, Jun},
  title     = {Program performance test based on different computing environment},
  year      = {2016},
  pages     = {174 - 177},
  address   = {Chongqing, China},
  note      = {C language;Computing environments;Cython;Execution speed;Large-scale computing;Program performance;Python;Python programming language;},
  abstract  = {To test the efficiency of different programming languages and find out the suitable one for solving the calculation problem of spherical distance between two points, we have developed serial and parallel calculate algorithms according C, Python programming languages, and tested the execution speed of all algorithms. As for the inefficiency of Python, we improved the performance by replacing some functions and variables of Python procedure with Cython. The experimental results show that Python programs can get the same execution efficiency as C language does with the same Large-scale computing environment. &copy; 2016 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of 2016 IEEE International Conference of Online Analysis and Computing Science, ICOACS 2016},
  key       = {C (programming language)},
  keywords  = {Cesium;Computer software;Efficiency;High level languages;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICOACS.2016.7563073},
}

@InProceedings{Budiyanto2016,
  author    = {Budiyanto, Setiyo and Nugraha, Beny and Widiastuti, Dian},
  title     = {Performance Test of Various Types of Antenna Arrays in Real Propagation Environment},
  year      = {2016},
  volume    = {105},
  number    = {1},
  address   = {Yogyakarta, Indonesia},
  note      = {Binomial arrays;Chebyshev arrays;Real propagation;Taylor Array;Uniform array;},
  abstract  = {The research was conducted on various types of antenna arrays namely Uniform Array, Binomial Array, Dolph-Chebyshev Array, and Taylor Array. This research is done in the real propagation environment in order to define precisely the number of antenna elements, the distance between the elements, the angle of the antenna arrays, the side lobe level and the n-bar array distribution. The testing process is done by using Matlab and the Non-Uniform Array Simulation Program. The results obtained for various types of antenna arrays are as follows: On Uniform Array produces Half Power Beam Width (HPBW) of 10.152&deg; and directivity of l0 dB, on Binomial Array generates Half Power Beam Width (HPBW) of 20.245&deg; and directivity of 7.47 dB, on Dolph-Chebyshev Arrayproduces Half Power Beam Width (HPBW) of 20.304&deg; and directivity of 4.0185 dB, and on Taylor Arrayproduces Half Power Beam Width (HPBW) of 12.78&deg; and directivity of 8.9 dB.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {17578981},
  journal   = {IOP Conference Series: Materials Science and Engineering},
  key       = {Antenna arrays},
  keywords  = {Antenna lobes;Bins;MATLAB;Planning;Software testing;Sustainable development;},
  language  = {English},
  url       = {http://dx.doi.org/10.1088/1757-899X/105/1/012015},
}

@InProceedings{Harris2004,
  author    = {Harris, R. and Ausin, A.M. and Angulo, J.S. and Valafar, F. and Impelluso, T.},
  title     = {VSTM: Virtual stress testing machine},
  year      = {2004},
  volume    = {3},
  pages     = {1345 - 1351},
  address   = {Las Vegas, NV, United states},
  note      = {Distributed Memory;Finite element codes;Stress Testing;Virtual stress testing machines (VSTM);},
  abstract  = {Virtual stress testing machine is a client-server software environment with a distributed memory system. VSTM encompasses a stress testing machine, a server component that initiates and controls all processes, a computational finite element component, and a number of visualization components. The goal of this design is to provide a virtual stress analysis environment, in which a specimen undergoes a series of stress applications. The finite element component calculates the displacement (deformation) of the specimen under stress. The visualization clients read the results of the finite element analysis, and construct an image of the deformed specimen color-coded to indicate varying levels of stress. A multitude of applications have been envisioned for this system, including studies in medicine.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings of the International Conference on Parallel and Distributed Processing Techniques and Applications, PDPTA'04},
  key       = {Computer software},
  keywords  = {Animation;Client server computer systems;Data processing;Distributed computer systems;Finite element method;Fluid mechanics;Virtual reality;Visualization;},
  language  = {English},
}

@Article{Cao2009,
  author    = {Cao, Rui and Wu, Jianping and Xu, Mingwei},
  title     = {Parallel stream scheduling for high-speed performance test systems},
  journal   = {Qinghua Daxue Xuebao/Journal of Tsinghua University},
  year      = {2009},
  volume    = {49},
  number    = {4},
  pages     = {608 - 611},
  issn      = {10000054},
  note      = {High-speed network devices;High-speed performance;Network devices;Performance tests;Scheduling mechanism;Stream Scheduling;Stream sequence;Stream slice;},
  abstract  = {Existing hardware-based parallel stream scheduling algorithms are not applicable to high-speed test systems. This paper proves that a universal purely hardware-based parallel stream scheduling mechanism does not exist and then presents a software-based pre-computed parallel stream scheduling mechanism for high speed network device test systems. This scheduling mechanism computes a stream sequence in software and then the hardware schedules the stream according to this stream sequence. Experiments on a test system with a 10 Gb/s interface show that the mechanism provides good uniformity and equity, and can work in a full-load environment. The stream scheduling mechanism is independent of the number of streams and the test device interface speed, is suitable for any test system and has good extensibility.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Computer hardware description languages},
  keywords  = {Hardware;HIgh speed networks;Scheduling;Scheduling algorithms;Software testing;Test facilities;Testing;},
  language  = {Chinese},
}

@InProceedings{Rodrigues2014a,
  author    = {Rodrigues, Elder M. and Oliveira, Flavio M. and Bernardino, Maicon and Saad, Rodrigo S. and Costa, Leandro T. and Zorzo, Avelino F. and Guarienti, Priscila},
  title     = {Evaluating capture and replay and model-based performance testing tools: An empirical comparison},
  year      = {2014},
  pages     = {IEEE Software; Microsoft Research; Politecnico di Torino; Telecom Italia JOL (Joint Open Lab); Telecom Italia Lab -},
  address   = {Torino, Italy},
  note      = {Collaboration projects;Empirical - comparisons;Empirical experiments;Model based testing;Performance testing;Software performance testing;Testing complexity;Testing tools;},
  abstract  = {[Context] A variety of testing tools have been developed to support and automate software performance testing activities. These tools may use different techniques, such as Model-Based Testing (MBT) or Capture and Replay (CR). [Goal] For software companies, it is important to evaluate such tools w.r.t. the effort required for creating test artifacts using them; despite its importance, there are few empirical studies comparing performance testing tools, specially tools developed with different approaches. [Method]We are conducting experimental studies to provide evidence about the required effort to use CR-based tools and MBT tools. In this paper, we present our first results, evaluating the effort (time spent) when using LoadRunner and Visual Studio CRbased tools, and the PLeTsPerf MBT tool to create performance test scripts and scenarios to test Web applications, in the context of a collaboration project between Software Engineering Research Center at PUCRS and a technological laboratory of a global IT company. [Results] Our results indicate that, for simple testing tasks, the effort of using a CR-based tool was lower than using an MBT tool, but as the testing complexity increases tasks, the advantage of using MBT grows significantly. [Conclusions] To conclude, we discuss the lessons we learned from the design, operation, and analysis of our empirical experiment. Copyright 2014 ACM.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {19493770},
  journal   = {International Symposium on Empirical Software Engineering and Measurement},
  key       = {Software testing},
  keywords  = {Application programs;Experiments;Model checking;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2652524.2652587},
}

@InProceedings{DaSilveira2011,
  author    = {Da Silveira, Maicon B. and Rodrigues, Elder M. and Zorzo, Avelino F. and Costa, Leandro T. and Vieira, Hugo V. and De Oliveira, Flavio M.},
  title     = {Generation of scripts for performance testing based on UML models},
  year      = {2011},
  pages     = {258 - 263},
  address   = {Miami, FL, United states},
  note      = {Academic environment;Automatic Generation;Model based testing;Performance testing;Software artifacts;Software Product Line;Software product line (SPL);Testing automation;},
  abstract  = {Software testing process has a high cost when compared to the other stages of software development. Automation of software testing through reuse of software artifacts (e.g. models) is a good alternative for mitigating these costs and making the process much more efficient and efficacious. Model-Based Testing (MBT) is a technique to automatic generation of testing artifacts based on software models. For software development, the most spread modeling language in either the industrial or academic environments is UML. In such environments, it is desirable to reuse UML models also for MBT. avoiding re-building a different model exclusively for testing automation. These are the main reasons that make these semi-formal models an alternative to implementing MBT. Even though there are a lot of testing tools available commercially, to the best of our knowledge, none of them fully uses MBT. Therefore, this paper describes a case study showing how to implement the MBT process to automate test scripts generation and execution in a real-world, context. Furthermore, our solution is generated automatically by a Software Product Line (SPL).<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {SEKE 2011 - Proceedings of the 23rd International Conference on Software Engineering and Knowledge Engineering},
  key       = {Software testing},
  keywords  = {Computer software reusability;Formal methods;Knowledge engineering;Model checking;Software design;Unified Modeling Language;},
  language  = {English},
}

@InProceedings{Srinivasa2013,
  author    = {Srinivasa, Lakshmi N. and Anbalagan, Jagadeesh and Meenakshisundaram, Sriganesh},
  title     = {Performance testing approach for services and applications using MQ-Series},
  year      = {2013},
  volume    = {2},
  pages     = {1151 - 1162},
  address   = {London, United kingdom},
  note      = {Distributed service;Messaging services;Performance testing;Services and applications;Software industry;Standard loads;Testing tools;Web-based applications;},
  abstract  = {Performance Testing of web-based applications in general is accomplished with the help of standard load testing tools and their methodology is well established and adopted by the Software Industry. With the advent of distributed Service Oriented Architecture (SOA) applications, load testing of services poses its own challenge to performance Testers and Engineers. In particular, this paper presents an approach and a tool by which the challenges for performance testing a messaging service (services using SOAP over MQ) can be overcome. Further, the paper illustrates how the existing tools can be adapted or new tools can be used to test them. In addition, it also specifies the testing, monitoring and tuning aspects of Messaging services.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Annual International Conference of the Computer Measurement Group, CMG 2013},
  key       = {Software testing},
  keywords  = {Application programs;Information services;Load testing;Service oriented architecture (SOA);},
  language  = {English},
}

@Article{Thijssen2007,
  author    = {Thijssen, Johan M. and Weijers, Gert and de Korte, Chris L.},
  title     = {Objective performance testing and quality assurance of medical ultrasound equipment},
  journal   = {Ultrasound in Medicine and Biology},
  year      = {2007},
  volume    = {33},
  number    = {3},
  pages     = {460 - 471},
  issn      = {03015629},
  note      = {Computational observer;Contrast resolution;Objective assessment;Performance testing;Spatial resolution;},
  abstract  = {There is an urgent need for a measurement protocol and software analysis for objective testing of the imaging performance of medical ultrasound equipment from a user's point of view. Methods for testing of imaging performance were developed. Simple test objects were used, which have a long life expectancy. First, the elevational focus (slice thickness) of the transducer was estimated and the in-plane transmit focus was positioned at the same depth. Next, the postprocessing look-up-table (LUT) was measured and linearized. The tests performed were echo level dynamic range (dB), contrast resolution (i.e., gamma of display, number of gray levels/dB) and sensitivity, overall system sensitivity, lateral sensitivity profile, dead zone, spatial resolution and geometric conformity of display. The concept of a computational observer was used to define the lesion signal-to-noise ratio, SNR<inf>L</inf> (or Mahalanobis distance), as a measure for contrast sensitivity. All the measurements were made using digitized images and quantified by objective means, i.e., by image analysis. The whole performance measurement protocol, as well as the quantitative measurements, have been implemented in software. An extensive data-base browser was implemented from which analysis of the images can be started and reports generated. These reports contain all the information about the measurements, such as graphs, images and numbers. The approach of calibrating the gamma by using a linearized LUT was validated by processing simultaneously acquired rf data. The contrast resolution and echo level of the rf data had to be compressed by a factor of two and amplified by a gain factor corresponding to 12 dB. This resulted in contrast curves that were practically identical to those obtained from DICOM image data. The effects of changing the transducer center frequency on the spatial resolution and contrast sensitivity were estimated to illustrate the practical usefulness of the developed approach of quality assurance by measuring objective performance characteristics. The developed methods might be considered as a minimum set of objective quality assurance measures. This set might be used to predict clinical performance of medical ultrasound equipment, taking into account the performance at a unique point in space i.e., the coinciding depths of the elevation and in-plane (azimuth) foci. Furthermore, it should be investigated whether the approach might be used to compare objectively various brands of equipment and to evaluate the performance specifications given by the manufacturer. Last but not least, the developed approach can be used to monitor, in a hospital environment, the medical ultrasound equipment during its life cycle. The software package may be viewed and downloaded at the website http://www.qa4us.eu. (E-mail: j.thijssen@cukz.umcn.nl). &copy; 2007 World Federation for Ultrasound in Medicine &amp; Biology.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Ultrasonic equipment},
  keywords  = {Computer software;Database systems;Image analysis;Medical imaging;Quality assurance;Signal to noise ratio;Ultrasonic transducers;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.ultrasmedbio.2006.09.006},
}

@InProceedings{Kim2009c,
  author    = {Kim, Heejin and Choi, Byoungju and Wong, W. Eric},
  title     = {Performance testing of mobile applications at the unit test level},
  year      = {2009},
  pages     = {171 - 180},
  address   = {Shanghai, China},
  note      = {Benchmark testing;Competitive advantage;Development environment;Innovative method;Mobile applications;Performance testing;Performance tests;Quality improvement;},
  abstract  = {With the rapid growth of the wireless market and the development of various mobile devices, innovative methods and technologies to produce high-quality mobile applications and reduce time to market have been emerging. Mobile applications are often characterized by an array of limitations such as the short development lifecycle to gain a competitive advantage and difficulties to update once released. Hence, rigorous testing on the applications is required before distribution to the market, including structural white-box, functional black-box, integration and system testing. Although recently performance testing at the system test level has become crucial given its direct connection with the product quality improvement, most such tests are confined to the areas of load, usability, and stress testing. Moreover, the implementation itself is insufficient due to the limitations of the development environment. This paper proposes a method to support performance testing utilizing a database established through benchmark testing in emulator-based test environment at the unit test level. It also presents the tool that supports the proposed method of performance testing and verifies the reliability of performance test results through experiments. &copy; 2009 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {SSIRI 2009 - 3rd IEEE International Conference on Secure Software Integration Reliability Improvement},
  key       = {Integration testing},
  keywords  = {Benchmarking;Black-box testing;Commerce;Competition;Integration;Load testing;Mobile computing;Software reliability;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/SSIRI.2009.28},
}

@InProceedings{Hughes2017,
  author    = {Hughes, Niav and DAgostino, Amy and Reinerman-Jones, Lauren},
  title     = {The NRC human performance test facility: An approach to data collection using novices and a simplified environment},
  year      = {2017},
  volume    = {495},
  pages     = {183 - 192},
  address   = {Walt Disney World, FL, United states},
  note      = {Digital representations;Human performance;Information gathering;Main control room;Nuclear regulatory commission;Physiological measures;U.S. Nuclear Regulatory Commission;University of Central Florida;},
  abstract  = {In the spring of 2012, as part of a &lsquo;hub and spoke&rsquo; model of research to address the human performance concerns related to current as well as new and advanced control room designs and operations, the U.S. Nuclear Regulatory Commission (NRC) sponsored a project to procure a low cost simulator to empirically measure and study human performance aspects of control room operations. Using this simulator, the Human Factors and Reliability Branch (HFRB) in the Office of Nuclear Regulatory Commission (NRC) began a program of research known as the NRC Human Performance Test Facility (HPTF) to collect empirical human performance data with the purpose of measuring and ultimately better understanding the various cognitive and physical elements that support safe control room operation. To accomplish this, HFRB first procured two 3-loop Westinghouse pressurized water reactor simulators with the capability to run a full range of power operation scenarios. HFRB staff work as co-investigators along with a team of researchers at the University of Central Florida (UCF) to design and carry-out a series of experiments aimed at measuring and understanding the human performance aspects of common control room tasks through the use of a variety of physiological and self-report metrics. The intent was to design experiments that balanced domain realism and laboratory control sufficiently to collect systematic, yet meaningful human performance data related to execution of common main control room (MCR) tasks. Investigators identified and defined three types of tasks that are examined in the present project: Checking, Detection, and Response Implementation. Task type presentation was partially counterbalanced to maintain ecologic validity with experimental control. A variety of subjective and physiological measures were used to understand performance of those tasks in terms ofworkload. The simulator used to collect these data was a digital representation of a generic analog NPP MCR interface. The data resulting from this experimentation enhances the current information gathering process, allowing for more robust technical bases to support regulatory guidance development and decision making. The present paper describes the approach behind this research effort. &copy; Springer International Publishing Switzerland 2017.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {21945357},
  journal   = {Advances in Intelligent Systems and Computing},
  key       = {Data acquisition},
  keywords  = {Decision making;Design;Electric industry;Human computer interaction;Human engineering;Nuclear energy;Physiology;Pressurized water reactors;Simulators;Software testing;Test facilities;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-41950-3_16},
}

@InProceedings{Robertson2017,
  author    = {Robertson, Seth O. and Paikowsky, Samuel G.},
  title     = {Drop weight dynamic load testing for construction monitoring and quality control of offshore drilled foundations},
  year      = {2017},
  number    = {GSP 279},
  pages     = {143 - 153},
  address   = {Orlando, FL, United states},
  note      = {Construction monitoring;Construction quality;Drilled foundations;One-dimensional wave equations;Signal matching analysis;Subsurface conditions;Three dynamic loads;Verification tests;},
  abstract  = {High strain drop weight dynamic load testing is an effective tool when evaluating the construction quality and axial capacity of offshore drilled deep foundations. This is a result of the complexity and cost of the alternative conventional static load tests. Drop weight systems can be designed for project specific needs, providing sufficient energy to mobilize the required resistance while permitting ease in transporting the device. Test shafts/piles can be instrumented and analyzed using the same dynamic testing techniques used for driven pile foundations. A case study is presented where drop weight dynamic load tests were utilized for offshore drilled shaft foundations. The project includes the design, construction, and quality control for a cement unloading pier at the Tema port in Ghana, Africa. The foundations are unique, consisting of 0.8m outer diameter steel pipes embedded in 1.0m rock-socketed drilled shafts. Three dynamic load tests to failure and six load verification tests were performed offshore. The load verification tests were carried out due to construction difficulties and/or complex subsurface conditions. The piles' integrity and mobilized resistances were assessed using the signal matching analysis software CAPWAP. The underlying assumptions in the one-dimensional wave equation formulation on which CAPWAP is based are violated in these complex cases. Finite element analyses were therefore performed using the PLAXIS 2D software in order to examine the validity of the one-dimensional wave equation application under such conditions. This paper briefly describes the project, the associated difficulties, the unique foundations, example load tests and their analyses, as well as some initial processing in examining the validity of the one-dimensional wave equation analyses under the tested conditions. &copy; ASCE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {08950563},
  journal   = {Geotechnical Special Publication},
  key       = {Load testing},
  keywords  = {Application programs;Drops;Dynamic loads;Finite element method;Foundations;Pile foundations;Piles;Quality control;Shaft sinking;Unloading;Wave equations;},
  language  = {English},
  url       = {http://dx.doi.org/10.1061/9780784480465.015},
}

@InProceedings{Ding2010,
  author    = {Ding, Yan and Qi, Feng},
  title     = {Apply automation testing in enterprises},
  year      = {2010},
  volume    = {20-23},
  pages     = {337 - 341},
  address   = {Macao, China},
  note      = {Automation testing;Capture/replay;Software test;Test Automation;Test automation frameworks;Test efficiency;Test framework;},
  abstract  = {In order to keep pace of product development and delivery, it is essential to implement an effective and reusable automation test framework. The traditional capture/replay framework is not only out of date but hard to use. Much more robust automation framework must be found otherwise automation test will only end up with failure forever. Success comes when clear concept of automation test is in managers' mind and full preparation is made. The paper first make it clear what is test automation and how it should be used and then list some approaches and tools popular in automation test. Then, it describes details of a framework. A model is given after it. It has been proved that this flow is reliable and greatly improves test efficiency in a company. &copy; (2010) Trans Tech Publications.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {16609336},
  journal   = {Applied Mechanics and Materials},
  key       = {Testing},
  keywords  = {Automation;Computer software;Information technology;Product development;},
  language  = {English},
}

@InProceedings{Johnson2008,
  author    = {Johnson, Peter},
  title     = {Load testing on a budget},
  year      = {2008},
  address   = {Las Vegas, NV, United states},
  note      = {Load test;Open sources;Testing software;},
  abstract  = {Load testing your application before placing it into production is always a good idea. Load testing during development is an even better idea. But commercial load testing software tends to be expensive and thus placing copies into the hands of every developer might not be feasible. This paper examines JMeter, a popular free, open source load testing tool. This paper is written as a tutorial showing how to use JMeter to load test an example application.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {34th International Conference Computer Measurement Group},
  key       = {Measurements},
  language  = {English},
}

@InProceedings{Arnold2015,
  author    = {Arnold, T. and Adewole, A.C. and Tzoneva, R.},
  title     = {Performance testing and assessment of multi-vendor protection schemes using proprietary protocols and the IEC 61850 standard},
  year      = {2015},
  volume    = {2015-September},
  pages     = {284 - 290},
  address   = {Cape Town, South africa},
  note      = {Distance protection;GOOSE;IEC 61850;Intelligent electronic device;POTT;Real time digital simulation;},
  abstract  = {The International Electrotechnical Commission (IEC) developed a global standard for power system communication permitting Intelligent Electronic Devices (IEDs) to interoperate within the smart grid environment. However, in order for electric power utility companies to adopt IEC 61850 standard-based devices with confidence, it is necessary to carry out performance tests and evaluations to allay their fears. This paper presents an evaluation of the performance of IEC 61850 standard-based devices with respect to their speed, security, and dependability of operation. The study was implemented using multi-vendor IEDs configured for a Permissive Overreaching Transfer Trip (POTT) communication scheme with conventional proprietary protocols and the IEC 61850 Generic Object Oriented Substation Events (GOOSE) messages based on hardware-in-the-loop simulations with the Real-Time Digital Simulator (RTDS). RSCAD software was used in the modelling of a typical power system network protected by two multi-vendor distance protection IEDs using a lab-scale testbed designed and implemented for the investigations relating to this paper. Real-time simulations for various fault locations and fault resistances were carried out. The results obtained demonstrated the dependability and security of the operation of the IEC 61850-based POTT communication scheme with faster operating times compared with the conventional POTT communication scheme based on vendor-specific proprietary protocols. This paper could serve as a reference to electric power utility companies as they adopt IEC 61850 standard-based devices in their networks. &copy; 2015 CPUT.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {21660581},
  journal   = {Proceedings of the Conference on the Industrial and Commercial Use of Energy, ICUE},
  key       = {Electric power system protection},
  keywords  = {Digital devices;Electric fault currents;Electric power systems;Electric power transmission networks;Electric substations;Electron devices;Electronic equipment;Object oriented programming;Smart power grids;Standards;Thermoelectric equipment;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICUE.2015.7280280},
}

@Article{Chen2009,
  author    = {Chen, Ying-Hui and Qiu, Xue-Song and Liu, Yi-Chang and Tang, Fan and Gao, Zhi-Peng},
  title     = {Model-based method for web service performance testing},
  journal   = {Beijing Youdian Daxue Xuebao/Journal of Beijing University of Posts and Telecommunications},
  year      = {2009},
  volume    = {32},
  number    = {SUPPL.},
  pages     = {44 - 48},
  issn      = {10075321},
  note      = {Model-based method;Performance testing;Quality of web services;Service performance;Software performance testing;Testing modeling;Testing tools;Transaction model;},
  abstract  = {Software performance testing is one of the important techniques used to assure the quality of web services. In order to improve the efficiency and automatization of web service performance testing, a model-based method for web service performance testing is proposed. Web service performance testing models built by distinct layers are presented. The layers of testing models includes test step model layer, test transaction model layer and test scenario model layer from the bottom up. The lower layer models were reusable for the higher layer model building. Furthermore, a web service performance testing tool is implemented, and an efficient solution is provided for model-based automatic performance testing.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Web services},
  keywords  = {Software testing;Websites;},
  language  = {Chinese},
}

@InProceedings{Halfawy2002,
  author    = {Halfawy, M.R. and Wipf, T. and Wood, D. and Abu-Hawash, A. and Phares, B.},
  title     = {Bridge load rating using an integrated load testing and finite element analysis approach: A case study},
  year      = {2002},
  volume    = {2002},
  pages     = {1371 - 1379},
  address   = {Montreal, QB, Canada},
  note      = {Bridge load rating;Bridge performance;Decision tool;Instrumentation;},
  abstract  = {Bridge load rating is the primary decision tool that is currently in use to evaluate and predict bridge performance under various loading conditions. Traditional bridge rating calculations involve calculating the load carrying capacity of the structural elements based on design plans, field inspection reports, and engineering judgment. Experience shows that bridge performance is always under-estimated using this simplified approach and in many cases results in placing unnecessary load restrictions on bridges. Bridge diagnostic load testing has been widely recognized as a more reliable and accurate method for bridge rating. However, the time and cost involved in conducting bridge load testing has been a major impediment to employing this valuable tool on a large scale. Bridge owners can typically only afford to perform load testing for major bridges and under critical circumstances. The need for more cost-effective and easy-to-implement methods to perform bridge load testing and rating analysis is well evident. In this paper, the use of an integrated system to conduct bridge load testing, finite element analysis, and rating is demonstrated. The system consists of load testing instrumentation and data acquisition hardware as well as four software components to perform structural analysis and rating calculations. A case study of a prestressed concrete bridge is presented to demonstrate the seamless integration of the load testing and analysis processes.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings, Annual Conference - Canadian Society for Civil Engineering},
  key       = {Load testing},
  keywords  = {Bridges;Data acquisition;Finite element method;Loading;Prestressed concrete;},
  language  = {English},
}

@InProceedings{Guo2010,
  author    = {Guo, Xiao-Yang and Qiu, Xue-Song and Chen, Ying-Hui and Tang, Fan},
  title     = {Design and implementation of performance testing model for web services},
  year      = {2010},
  volume    = {1},
  pages     = {353 - 356},
  address   = {Wuhan, China},
  note      = {Design and implementations;Load balance;Multi-machines;Performance testing;Strategy modeling;Testing efficiency;Testing modeling;Testing software;},
  abstract  = {The performance testing model for Web Services is proposed. Aiming to enhance testing efficiency and automation, the model provides a multi-machine joint testing model and strategy model. The former is used to share the heavy load to multiple units, which could also be called load balance model, and the latter is used to simulate a realistic Web Services running environment. The model has been applied to an original web services testing software, and proved to be a feasible way for performance testing for web services. &copy;2010 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {CAR 2010 - 2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics},
  key       = {Web services},
  keywords  = {Automation;Load testing;Robotics;Software testing;Websites;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/CAR.2010.5456825},
}

@InProceedings{Draheim2006,
  author    = {Draheim, Dirk and Grundy, John and Hosking, John and Lutteroth, Christof and Weber, Gerald},
  title     = {Realistic load testing of web applications},
  year      = {2006},
  pages     = {57 - 67},
  address   = {Bari, Italy},
  note      = {Existing architectures;Form-oriented analysis;New approaches;Performance evaluation tools;Sample data;User behaviour;WEB application;Web site navigation;},
  abstract  = {We present a new approach for performing load testing of web applications by simulating realistic user behaviour with stochastic form-oriented analysis models. Realism in the simulation of user behaviour is necessary in order to achieve valid testing results. In contrast to many other user models, web site navigation and time delay are modelled stochastically. The models can be constructed from sample data and can take into account effects of session history on user behaviour and the existence of different categories of users. The approach is implemented in an existing architecture modelling and performance evaluation tool and is integrated with existing methods for forward and reverse engineering. &copy; 2006 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {15345351},
  journal   = {Proceedings of the European Conference on Software Maintenance and Reengineering, CSMR},
  key       = {Behavioral research},
  keywords  = {Computer software maintenance;Load testing;Reengineering;Reverse engineering;Stochastic models;Stochastic systems;Websites;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/CSMR.2006.43},
}

@InProceedings{Li2018,
  author    = {Li, Nanxi and Li, Ting},
  title     = {Design and performance test of NIRS-based spinal cord lesion detector},
  year      = {2018},
  volume    = {10484},
  pages     = {The Society of Photo-Optical Instrumentation Engineers (SPIE) -},
  address   = {San Francisco, CA, United states},
  note      = {Design of hardwares;feasibility;Imaging modality;Instrument systems;NIRS;Non-invasive monitoring;Performance tests;Spinal cords;},
  abstract  = {Spinal cord lesions can cause a series of severe complications, which can even lead to paralysis with high mortality. However, the traditional diagnosis of spinal cord lesion relies on complicated imaging modalities and other invasive and dangerous methods. Here, we have designed a small monitor based on NIRS technology for noninvasive monitoring for spinal cord lesions. The development of the instrument system includes the design of hardware circuits and the program of software. In terms of hardware, OPT101<sup>1</sup>is selected as the light detector, and the appropriate probe distribution structure is selected according to the simulation result of Monte Carlo Simulation. At the same time, the powerful controller is selected as our system's central processing chip for the circuit design, and the data is transmitted by serial port to the host computer for post processing. Finally, we verify the stability and feasibility of the instrument system. It is found that the spinal signal could be obviously detected in the system, which indicates that our monitor based on NIRS technology has the potential to monitor the spinal lesion.<br/> &copy; 2018 SPIE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {16057422},
  journal   = {Progress in Biomedical Optics and Imaging - Proceedings of SPIE},
  key       = {Monte Carlo methods},
  keywords  = {Computer hardware;Convergence of numerical methods;Detectors;Hardware;Integrated circuit manufacture;Intelligent systems;Printed circuit design;Remote control;Surgery;},
  language  = {English},
  url       = {http://dx.doi.org/10.1117/12.2287071},
}

@Article{Abdel-Aal1990,
  author    = {Abdel-Aal, R.E.},
  title     = {Computerised performance testing of data acquisition facilities},
  journal   = {Measurement Science and Technology},
  year      = {1990},
  volume    = {1},
  number    = {3},
  pages     = {216 - 219},
  issn      = {09570233},
  note      = {CAMAC Pulse Generator;Performance Testing;Time-to-Digital Converters;},
  abstract  = {This paper describes a low-cost approach to performing automatic performance measurements on data acquisition modules and systems employed in physics research. A versatile programmable CAMAC pulse generator is described which produces accurately timed repetitive logic pulses whose width and repetition rate are set by software. The variable rate is useful in determining the performance of data acquisition systems over a wide range of data rates, while the variable width may be used in the automatic measurement of the characteristics of modules such as time-to-digital converters (TDCS). Using a time-to-amplitude converter (TAC), this width can be converted into a variable amplitude for testing analogue-to-digital converter (ADC) modules. Hardware and software aspects are described. Typical applications are discussed including automated performance measurements on a VAX 11/785 data acquisition system and on a TAC/ADC combination.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Data Processing},
  keywords  = {Data Conversion, Analog to Digital;Physics--Research;Pulse Generators;},
  language  = {English},
  url       = {http://dx.doi.org/10.1088/0957-0233/1/3/002},
}

@InProceedings{Li2012,
  author    = {Li, Li and Zhu, Lei-Lei and Zhai, Hongyu and Liu, Dan and Wang, Hai-Fang},
  title     = {Study on performance test of storage structure base on state scene performance},
  year      = {2012},
  pages     = {570 - 573},
  address   = {Nanjing, China},
  note      = {Automated testing;Automated tools;Data storage systems;Monitor software;Performance tests;Quality performance;Software performance;SQL servers;Storage structures;Storage systems;XML storage;},
  abstract  = {This paper is an introduction to software performance automated testing and theory. It introduces the features of Open Xml storage and SQL Server storage. Then this paper sets three state scenes and chooses different test automated tools respectively. Finally, it uses tools to monitor software performance index from these two data storage systems. Results are then analyzed, comparing the quality performance of different storage systems to the same state scene. &copy; 2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - 2012 International Conference on Computer Science and Service System, CSSS 2012},
  key       = {Computer science},
  keywords  = {Data storage equipment;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/CSSS.2012.148},
}

@InProceedings{Mayer2012,
  author    = {Mayer, Daniel A. and Steele, Orie and Wetzel, Susanne and Meyer, Ulrike},
  title     = {CaPTIF: Comprehensive performance testing framework},
  year      = {2012},
  volume    = {7641 LNCS},
  pages     = {55 - 70},
  address   = {Aalborg, Denmark},
  note      = {Comprehensive performance;Comprehensive performance evaluation;Cryptographic protocols;Secure multi-party computation;Test inputs;User interaction;Web-based interface;},
  abstract  = {In this paper we present the design and implementation of a framework for comprehensive performance evaluation of algorithms, modules, and libraries. Our framework allows for the definition of well-defined test inputs and the subsequent scheduling and execution of structured tests. In addition, the framework provides a web-based interface for user interaction and allows for the convenient browsing, plotting, and statistical analysis of test results. We furthermore report on our experience in using the new framework in the development of cryptographic protocols and algorithms-specifically in the context of secure multi-party computation. &copy; 2012 IFIP International Federation for Information Processing.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Software testing},
  keywords  = {Algorithms;Multimedia systems;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-34691-0_6},
}

@InProceedings{Liu2012,
  author    = {Liu, Zhihai and Zeng, Qingliang and Kang, Hongxi and Wang, Chenglong},
  title     = {Design of performance testing bed for hydraulic products of engineering machinery},
  year      = {2012},
  volume    = {590},
  pages     = {427 - 430},
  address   = {Qingdao, China},
  note      = {Composition structure;Data acquisition system;Engineering machinery;Hydraulic pump;Hydraulic system;Hydraulic tests;Hydraulic valves;Labwindows;LabWindows/CVI;Performance testing;Signal flow;Structure design;Testing tools;},
  abstract  = {Hydraulic test platform is a very important testing tool for hydraulic products of engineering machinery. In this paper, a new type of hydraulic test bed is developed which can be used for performance testing of hydraulic valves, hydraulic motor and hydraulic pump. The composition structure diagram of hydraulic system, power supply system, and the signal flow diagram of data acquisition system were designed. The communication between sensors and computer via RS232 were researched. At last, the hydraulic test software is developed by using Labwindows/CVI and Simense PLC. &copy; (2012) Trans Tech Publications, Switzerland.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {10226680},
  journal   = {Advanced Materials Research},
  key       = {Hydraulic machinery},
  keywords  = {Communication;Electric power systems;Equipment testing;Hydraulic equipment;Hydraulic motors;Machine design;Mechatronics;Product design;Systems analysis;},
  language  = {English},
  url       = {http://dx.doi.org/10.4028/www.scientific.net/AMR.590.427},
}

@InProceedings{Han2013,
  author    = {Han, Ji-Woong and Ko, Bock Seong and Park, Sang-Jun and Lee, Yoon Sang and Jeong, Ji-Young and Lee, Yong Bum},
  title     = {Preliminary performance test of mechanical pump for a STELLA-1},
  year      = {2013},
  volume    = {15},
  pages     = {ASME -},
  address   = {San Diego, CA, United states},
  note      = {Demonstration reactor;Korea Atomic Energy Research Institute;Performance tests;Primary heat transport systems;Scaling parameter;Sodium cooled fast reactors (SFR);Thermo-hydraulic performance;Water environments;},
  abstract  = {In the process of sodium-cooled fast reactor (SFR) design, it is very important to verify thermo-hydraulic performance of each component in the sodium environment. In KAERI (Korea Atomic Energy Research Institute) STELLA (Sodium Integral Effect Test Loop for Safety Simulation and Assessment) project is under a Mid- and Long-term Nuclear R&amp;D Program. The STELLA project is composed of two stages. In the 1st stage the performance for heat exchangers such as DHX (Decay heat exchanger) and AHX (Air heat exchanger) and for PHTS (Primary heat transport system) mechanical pump will be evaluated. The detailed design of each component is based on that of a 600MWe demonstration reactor. Since full-scale components could not be installed in STELLA-1 [1], the model pump is designed to be scaled-down based on the scaling law. Various pump tests have been done in water environment by using model pump. In this study the design features of model pump were described and the scaling parameters were examined. The results of pump performance tests have been also introduced which is essential to perform safety analysis. Copyright &copy; 2013 by ASME.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE)},
  key       = {Pumps},
  keywords  = {Heat exchangers;Safety engineering;Sodium-cooled fast reactors;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1115/IMECE2013-65654},
}

@InProceedings{Huo2008,
  author    = {Huo, Xiao-Jing and Zhang, Rui-Qing and Wang, Hui and Qian, Dong-Ping and Teng, Jia-Xu},
  title     = {Real- time measurement of friction coefficient in the frictional performance test of brake disk},
  year      = {2008},
  volume    = {373-374},
  pages     = {484 - 487},
  note      = {Brake disks;Friction coefficient;Virtual instrumentation;},
  abstract  = {Development and optimizing of friction material formula, oriented to improve the service life and security of brake disk, is largely based on advanced measurement method to accurately provide the friction coefficient. In this study, virtual instrumentation technique was used to design an automation measurement system of friction coefficient. With proper sensors, data of four measured variables such as temperature, rotation speed, pressure and friction torque are acquired by the computer combined with a plug-in data acquisition board. The system work principle, selection of sensors, multi-channel sampling, signal processing and anti-jamming measures have been presented in detail. Those functions of the software such as real-time data acquisition, dynamic wave displaying, high-speed report saving and inquiry, and so on, have been realized by LabWindows/CVI 7.1. The system works safely with high accuracy and friendly user interface in practical operation.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {10139826},
  journal   = {Key Engineering Materials},
  key       = {Friction materials},
  keywords  = {Disks (machine components);Measurement theory;Optimization;Real time systems;},
  language  = {English},
}

@InProceedings{Nwakuba2017,
  author    = {Nwakuba, Nnaemeka R. and Chukwuezie, Collins O. and Asoegwu, Sabbas N. and Nwaigwe, Kevin N.},
  title     = {No-load performance testing of an arduino-primed hybrid solar-electric crop dryer},
  year      = {2017},
  pages     = {ASABE -},
  address   = {Spokane, WA, United states},
  note      = {Ambient air temperature;Arduino processor;Heat profiles;Heat-up time;Hybrid dryers;Integrated development environment;Liquid crystal display(LCD);Programmable circuits;},
  abstract  = {This work presents the performance testing of an arduino-controlled hybrid solar-electric cabinet dryer under no-load condition. The integral hybrid system mainly consists of solar and electric heat components which are connected to a programmable circuit board (micro-controller) with a piece of software (integrated development environment, IDE) known as arduino micro-processor which controls and automates the overall operation of the dryer system through its relay and receives signals from transducer sensors (a capacitive humidity and thermistor sensors) placed at different locations on the dryer. Through the use of a 4 X 4 matrix keypad, preset chamber temperature threshold and chamber air flow rates were inputted; relative humidities of the different locations, tray and chamber temperatures and energy consumption from both solar and electric energy sources were measured, recorded, displayed on the liquid crystal display (LCD) and transferred to a microcomputer via a universal serial board (USB) cord. With the arduino platform, the quantity of moisture loss per given time and energy required for drying as well as other basic drying parameters can be effectively measured with minimum human supervision, thus making the entire operation automated and efficient. No-load tests were conducted to evaluate the thermal profile of the dryer, which involved running the dryer at five different air velocities (0.1, 0.5, 1.0, 1.5, and 2.0 m/s) in order to determine the required time to reach the preset optimum drying temperatures of 50, 55, 60, 65, 70oC. Results obtained show that an average minimum drying chamber heat-up times of 9.8 and 6.2 minutes were required by the electrical and hybrid heat sources at a temperature and air velocity of 70oC and 2 m/s respectively. Ambient air temperature, relative humidity and air velocity were observed to have significant influence on the dryer heat-up time and tray temperatures. Drying time had significant effect on the energy consumption of the dryer mainly due to hourly solar heat. The hybrid and electric heat sources developed a maximum chamber temperature of about 92.5 and 84oC respectively after 210 minutes. Peak energy of 1946 and 1485kW-hr were developed by the hybrid and electric heat units respectively and 784kW/m<sup>2</sup>was developed by the solar collector. The solar component contributed a maximum drying chamber temperature of 30 to 31.7oC which is about 50 to 55% of the required drying chamber temperature. Energy regression equation models were developed in terms of time for each heat source as well as the hybrid with an average R<sup>2</sup>-value of 0.99. The general performance of the dryer was attributed to the heat contribution of the solar collector and that of the electric heater as well as its negligible thermal losses. Good prospects for future applications as well as recommendations were stated.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {2017 ASABE Annual International Meeting},
  key       = {Dryers (equipment)},
  keywords  = {Air;Atmospheric humidity;Capacitive sensors;Drying;Electric heating;Electric losses;Energy utilization;Humidity control;Hybrid systems;Liquid crystal displays;Load testing;Solar collectors;},
  language  = {English},
  url       = {http://dx.doi.org/10.13031/aim.201700079},
}

@InProceedings{Battersby1992,
  author    = {Battersby, Glynis and De Rossett, Margaret},
  title     = {DB2 Version 2 Release 3 multi-user performance test results},
  year      = {1992},
  pages     = {542 - 549},
  address   = {Reno, NV, USA},
  note      = {DB2;},
  abstract  = {A series of tests designed to determine the performance and resource consumption characteristics of DB2 Version 2 Release 3 as compared with DB2 Version 2 Release 2 was executed in a multi-user environment. The purpose of this paper is to describe the results of experiences using DB2 2.3 and DB2 2.2. The workload presented in the paper is synthetic and does not represent any known workload deployed at any site. No endorsement of IBM of its products is expressed, and none should be implied. No recommendation is made regarding the purchase DB2 or any other IBM products. A network of 300 terminals was simulated using IBM's Teleprocessing Network Simulator (TPNS), and test scripts were executed at various transaction rates to measure the system performance under both peak and non-peak conditions. The basic workload was then restructured to take advantage of DB2 2.3's new package feature and additional volume testing was conducted. The reader of this paper is assumed to have a basic knowledge of DB2 principles and MVS performance terminology and concepts. The reader may wish to read the provided glossary before proceeding, or may reference it as needed.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {CMG Proceedings},
  key       = {Database systems},
  keywords  = {Computer software selection and evaluation;Performance;},
  language  = {English},
}

@InProceedings{Mai1994,
  author    = {Mai, T.D. and Sifuentes, R.T. and Chen, A.L. and Cornwell, J.D.},
  title     = {Space constructible radiator (SCR) life test heat pipe performance testing and evaluation},
  year      = {1994},
  address   = {Friedrichshafen, Germany},
  note      = {Advanced technology development;Large amounts;Life-tests;Lightweight design;Overall heat transfer coefficient;Pipe performance;Space centers;Thermal control systems;},
  abstract  = {The Space Constructible Radiator (SCR) Life Test heat pipe performance testing is currently conducted at NASA/Johnson Space Center as part of the Advanced Technology Development Program. The SCR is a dual passage, monogroove heat pipe radiator designed and manufactured by Grumman Aerospace for NASA. The heat pipe has many aerospace applications since it can transport a large amount of heat with a compact lightweight design. As the micro-meteoroid/orbital debris environment worsens, it may be advantageous to add the heat pipe radiator to the Space Station's thermal control system. The SCR Life Test has been operating over the last 10 years and will continue until the year 2000. The overall heat transfer coefficient has decreased from 792 W/K (1500 Btu/Hr-&deg;F) to 475 W/K (900 Btu/Hr-&deg;F) but appears to have stabilized. This paper summarizes the SCR Life Test setup and the test results to date. &copy; Copyright 1994 Society of Automotive Engineers, Inc.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {01487191},
  journal   = {SAE Technical Papers},
  key       = {Heat pipes},
  keywords  = {Aerospace applications;Control systems;Environmental management;Heat transfer;NASA;Radiators;Slip forming;Software testing;Space debris;Space platforms;Space stations;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.4271/941437},
}

@InProceedings{Fan2016,
  author    = {Fan, Yamei and Qing, Liao and Qi, He},
  title     = {Research and comparative analysis of performance test on SDN controller},
  year      = {2016},
  pages     = {207 - 210},
  address   = {Wuhan, China},
  note      = {Comparative analysis;Implementation architecture;Model framework;ONOS;OpenDaylight;Performance parameters;Performance tests;Test instruments;},
  abstract  = {The emergence of Software Defined Network(SDN) gives the demand of big data and network management a chance. SDN separates the control and forwarding in traditional network through OpenFlow protocol. In the software-defined network, SDN controller is an important integral part that is the core of SDN. In this paper, firstly we summarize the common SDN controller, and choose two popular, wider using open-source controllers(OpenDaylight and ONOS), analyze the implementation architecture and model framework of the two controllers. Then build the controller platform, simulate the underlying topology using IXIA test instruments, Cbench and Mininet to get the performance parameters and furthermore analyze the data. &copy; 2016 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {2016 1st IEEE International Conference on Computer Communication and the Internet, ICCCI 2016},
  key       = {Information management},
  keywords  = {Big data;Controllers;Open source software;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/CCI.2016.7778909},
}

@Article{Wang2015,
  author    = {Wang, Lixin and Huang, Fengshan and Zhou, Qiang},
  title     = {Surface structure biomimetic design and performance testing of slippery trapping plate used for controlling agricultural insect},
  journal   = {Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering},
  year      = {2015},
  volume    = {31},
  number    = {20},
  pages     = {34 - 40},
  issn      = {10026819},
  note      = {Agricultural productions;Biomimetic design;Environment pollution;Laser micro-fabrication;Nepenthes pitcher;Scanning white light interferometers;Signal conditioning module;Structural information;},
  abstract  = {The technology of photoelectric inducing-trapping can kill agricultural insect (locust, ant, etc.) and protect the agricultural production from being destroyed effectively, and avoid the environment pollution caused by spraying pesticide. The key factor of this technology is to develop a kind of slippery trapping plate which can restrict insects' excellent attachment ability generated by rigid claw and adhesive pad. To obtain structural information for biomimetic developing the slippery trapping plate, surface morphology of bionic prototype (slippery zone of Nepenthes alata pitcher) was detailedly examined in August and September of 2013. Several sections (1 cm<sup>2</sup>) were cut from the slippery surface and rinsed in distilled water before being air-dried, then mounted on aluminum blocks and sputter coated, and observed with a scanning electron microscope (SEM). Fresh sample (2 cm<sup>2</sup>) was cut from slippery surface and glued to an aluminum block, and examined with a scanning white-light interferometer (SWLI). The structural parameters of slippery surface were statistically acquired via analyzing the saved images with the software belonging to the SEM and SWLI equipment. The results showed that the slippery surface is covered by a layer of dense and irregular wax crystals, along with numerous downward-directed lunate cells. Length and thickness of the platelet-shaped wax crystals was 1109.6&plusmn;68.5 nm and 89.11&plusmn;5.17 nm, respectively; the height and interval distance of the lunate cells was 20.41&plusmn;1.73 &mu;m and 71.53&plusmn;3.86 &mu;m, respectively; the angles of the lunate cell's slope and precipice was 23.1&plusmn;2.4&deg; and 76.1&plusmn;4.0&deg;, respectively. These obtained parameters suggested that the slippery zone bears micro-nano scaled surface architectures. Based on acquired structural parameters, biomimetic model of the slippery trapping plate was designed with CAXA software. The biomimetic model consisted of a substrate and an epicuticular layer, the substrate was covered by micro-scaled triangular prisms (simplified lunate cells) and numerous blind holes, and the epicuticular layer was composed of massive flaky graphite (simplified wax coverings) possessing the physical properties of lubrication and slippage. To prepare the slippery trapping plate, laser micro-fabrication technology was adopted to machine the micro-scaled architectures (triangular prisms and blind holes) of the substrate (alloy steel, 100 mm&times;50 mm&times;5 mm, length&times;width&times;thickness), and high voltage electrostatic incorporation technology was used to attach the flaky graphite (mesh number 1500-2000, dimension 6.5-10 &mu;m) to the machined substrate. The flaky graphite was put on an organic glass box (95 mm&times;45 mm&times;30 mm, length&times;width&times;height); and put the laser-machined substrate and an alloy plate on the top and bottom of the box, respectively. The positive and negative electrode of high voltage electrostatic source was respectively connected to the substrate and alloy plate, and applied high voltage electrostatic (16.0-18.0 KV) for 100-120 s. With the incorporation of the high voltage electrostatic, the flaky graphite was absorbed to the blind holes of substrate and attached tightly. To test the function of the biomimetic slippery trapping plate, attachment forces of adult locust (Locusta migratoria manilensis) were measured with an insect micro-force measurement system in July 2015. The system mainly consisted of a force transducer (1-PW4C3), a signal conditioning module (SCXI-1520), a data acquisition platform (PCI-6221), and data-processing &amp; displaying software. The locust was connected to the force transducer (along load direction) using a thin thread (12 cm long) fastened its neck position, and then put on the tested surface. The locust climbed on the tested surface along the load direction of the force transducer. When the thin thread started to pull, the locust crawled ahead frantically to attempt to break away from this restriction, so generated attachment forces and their maximal values were recorded. The results showed that values of attachment force provided by locust on bionic slippery trapping plate ranged from 328.7 mN to 458.3 mN, whereas on slippery surface ranged from 307.3 mN to 397.1 mN. Attachment force of locust on bionic slippery trapping plate (402.9&plusmn;26.1 mN) was barely 1.1 times than that on slippery surface (361.9&plusmn;25.5 mN), suggesting the biomimetic slippery trapping plate bore rather similar function as the slippery surface, thereby achieved the protected biomimetic results. The obtained conclusion provides theoretical and technical references to biomimetic development of slippery trapping plate used for controlling agricultural insect.<br/> &copy;, 2015, Chinese Society of Agricultural Engineering. All right reserved.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Plates (structural components)},
  keywords  = {Agricultural machinery;Agriculture;Alloy steel;Aluminum;Aluminum coatings;Binary alloys;Biomimetics;Bionics;Crystal structure;Crystals;Data acquisition;Data handling;Electrostatics;Force measurement;Graphite;Organic lasers;Pest control;Potassium alloys;Prisms;Scanning electron microscopy;Substrates;Transducers;Vanadium alloys;},
  language  = {Chinese},
  url       = {http://dx.doi.org/10.11975/j.issn.1002-6819.2015.20.005},
}

@InProceedings{Esquiagola2017,
  author    = {Esquiagola, John and Costa, Laisa and Calcina, Pablo and Fedrecheski, Geovane and Zuffo, Marcelo},
  title     = {Performance testing of an internet of things platform},
  year      = {2017},
  pages     = {309 - 314},
  address   = {Porto, Portugal},
  note      = {Embedded electronics;Hardware platform;Internet of thing (IOT);IOT applications;Machine to machines;Network environments;Performance;Performance testing;},
  abstract  = {The Internet of Things (IoT) is a network of physical objects, or things, with embedded electronics, software, sensors, and connectivity. The connection of all these things leverages value generation, by offering new services and strategic information. In order to make the Internet of Things possible, the integration of many technologies is necessary, such as machine-To-machine and cyber-physical systems. The process of testing IoT applications introduces new challenges because it does not only includes typical test strategies and methodologies. Testing an IoT system depends on its the specific configuration, and it also needs to consider the hardware platform and the network environment. Currently, industry and academy efforts are focusing on usability and connectivity tests, such as: simulating the environment where the device is to be used, and ensuring information is exchanged in a secure manner. In this paper, we use the current version of our IoT platform to perform stress testing of our IoT platform under different conditions. Our test methodology for IoT applications is also presented. Three different hardware platforms have been used for performing the stress testing of our platform. Copyright &copy; 2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {IoTBDS 2017 - Proceedings of the 2nd International Conference on Internet of Things, Big Data and Security},
  key       = {Internet of things},
  keywords  = {Big data;Cyber Physical System;Embedded systems;Hardware;Testing;},
  language  = {English},
}

@InProceedings{Sholapurwalla2009,
  author    = {Sholapurwalla, Adi and Scott, Sam},
  title     = {Bridging the gap between manufacturing reality and design assumptions: Chaining manufacturing analyses and defects with performance testing},
  year      = {2009},
  pages     = {101 - 109},
  address   = {Vancouver, BC, Canada},
  note      = {Chaining casting and impact;Competitive environment;High pressure die casting;Impact;Porosity distributions;Predictive engineering;Strength;Structural simulations;},
  abstract  = {In today's competitive environment it has become commonplace for foundries to incorporate capabilities such as component design, part assembly and other non-traditional foundry operations. To predict the behavior of a casting component under service conditions, value-added functionality has also been integrated into engineering software by linking solutions together and adding multi-physics analyses into the design cycle. The structural simulation of safety components made of die cast alloys is frequently based on the assumption of a homogenous distribution of mechanical properties. In reality defects caused by the production process like porosity is one of the most degrading factors leading to non-homogenous mechanical properties. In order to predict the behavior of the part under service conditions, it is necessary to take into account the influence of the porosity distribution resulting from the casting process into the structural simulation. This production part is then used in a performance analysis, such as crash or impact, to observe how the as-cast part will perform in its actual usage. This paper describes a methodology to model the complete High Pressure Die Casting (HPDC) process, determine macro and micro porosity results and then map these porosity results onto a geometry which can be used for a crash/impact analysis. The porosity map leads to a more correct description of the mechanical strength of the component, which then leads to more accurate virtual component testing. These results will be compared to the experimentally measured porosity distribution in the actual part, as well as actual loading cases to observe the deflection and failure of the component. This type of advanced technology and predictive engineering is the next giant step in the software industry.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings from the 12th International Conference on Modeling of Casting, Welding, and Advanced Solidification Processes},
  key       = {Porosity},
  keywords  = {Casting;Defects;Die casting;Foundries;Manufacture;Mechanical properties;Software engineering;Solidification;Welding;},
  language  = {English},
}

@InProceedings{Kadam2016,
  author    = {Kadam, Arvind H. and Menon, Rishi and Williamson, Sheldon S.},
  title     = {Traction inverter performance testing using mathematical and real-time controller-in-the-loop Permanent Magnet Synchronous Motor emulator},
  year      = {2016},
  pages     = {6651 - 6656},
  address   = {Florence, Italy},
  abstract  = {In the development stage of electric vehicle drive, simulation plays a vital role. It's a powerful tool which allows the developer to investigate various control strategies and test hardware systems in harmless work environment. The software simulations platform does have constraints. In that the complex mathematical operations take longer time to solve and eventually increases the overall simulation time and cannot perform the real-time operation. This simulation further needs to be converted to the target processor's language, either assembly or C-language, which will operate in the drive system. However, if a real-time simulation environment could be comprehended, then the real processor used in the system could be incorporated in the simulation. This eventually will eliminate the chance of introducing error during code translation as well as reduce simulation time. Also, the target controller could be tested within the simulation before introducing it the actual system. This paper discuss a concept of controller-in-loop simulation, which can be used to simulate the entire system in real-time. A simple dynamic model of Permanent Magnet Synchronous Motor is simulated with MATLAB/Simulink as well as on a TMS320F28069 digital signal processor from Texas Instruments Inc. Comparative study of simulation results of both the platforms, demonstrate that although MATLAB/Simulink provides excellent GUI and functionality, it fails to performs real-time simulation which can be accomplished with controller-in-simulation. &copy; 2016 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {IECON Proceedings (Industrial Electronics Conference)},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/IECON.2016.7793156},
}

@Article{Kahlmeyer1998,
  author    = {Kahlmeyer, H. and Haucler, C. and Lyngsmo, K.O. and Berg, S. and Schipper, K.P.},
  title     = {Results of the performance testing of purpose-built and PC-based electrocardiographs using a simple evaluation procedure},
  journal   = {Journal of Medical Engineering and Technology},
  year      = {1998},
  volume    = {22},
  number    = {2},
  pages     = {73 - 81},
  issn      = {03091902},
  note      = {Electrocardiographs;},
  abstract  = {This paper presents the results of the evaluation testing of six 12-lead electrocardiographs, three purpose-built instruments and three of the recently introduced personal computer-based type (PC-based). As for PC-based electrocardiographs, three examples of the MRT systems, two examples of the 300 Hz CardioScope model and one prototype of the 1200 Hz CardioScope were examined but only results for one representative example of each are given here. It was of particular interest to compare the performance advantages and limitations of the PC-based electrocardiographs with that of instruments currently in use. A test procedure was developed that can be used by a medical technical department to evaluate an electrocardiograph before making a purchase decision. The procedure includes tests of frequency response, sampling rate, 50 Hz filter attenuation, gain and common mode rejection ratio (CMRR) plus tests based upon simulated electrocardiograms (ECGs). The procedure takes account of the AHA and ECRI recommendations for electrocardiograph checks and can be completed in less than two hours. The only equipment required being an ECG simulator and a signal generator. The results of this work show that purpose-built electrocardiographs meet all normal performance requirements, whereas the PC-based types, whilst having the potential to at least equal these requirements, currently exhibit software and hardware related problems.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Electrocardiography},
  keywords  = {Cardiovascular system;Computer aided diagnosis;Electrophysiology;Equipment testing;Personal computers;},
  language  = {English},
  url       = {http://dx.doi.org/10.3109/03091909809010002},
}

@InProceedings{Abdallah2015,
  author    = {Abdallah, Youmna and Najjar, Shadi and Saad, George},
  title     = {Impact of proof load test programs on the reliability of foundations},
  year      = {2015},
  volume    = {GSP 256},
  pages     = {1850 - 1860},
  address   = {San Antonio, TX, United states},
  note      = {Bayesian approaches;Capacity distribution;Construction procedures;Decision framework;Factors of safeties;Probability of failure;Reliability based design;Value of information;},
  abstract  = {Traditionally, proof-load tests have been utilized to validate design methods and construction procedures. There is currently an inconsistency in the recommendations that are available in pile design codes and practices regarding the required number of proof-load tests and the level of the proof loads. Recently, and in the framework of reliability-based design, researchers have shown that information from pile load tests may have a considerable impact on reducing the probability of failure of piles at a site, thus allowing for the use of lower factors of safety for the piles. This paper presents the results of a thorough investigation that is conducted to study the effect of choosing different proof-load test programs on the reliability of piles. This is achieved by utilizing a Bayesian approach to update the capacity distributions of piles at a site given the results of the proof-load test program. In the updating exercise, an effort is made to update both the mean and the lower-bound capacity to maximize the benefit of the collected proof load data. The significance of the results presented lies in the fact that these results constitute necessary input to any practical decision framework for choosing the number and the magnitude of the proof load test that would maximize the value of information of the test program.<br/> &copy; ASCE 2015.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {08950563},
  journal   = {Geotechnical Special Publication},
  key       = {Piles},
  keywords  = {Bayesian networks;Reliability;Software testing;Statistical tests;Test facilities;},
  language  = {English},
  url       = {http://dx.doi.org/10.1061/9780784479087.169},
}

@Article{Abdallah2015a,
  author    = {Abdallah, Y. and Najjar, S.S. and Saad, G.},
  title     = {Reliability-based design of proof load test programs for foundations},
  journal   = {Geotechnical Engineering},
  year      = {2015},
  volume    = {46},
  number    = {2},
  pages     = {94 - 101},
  issn      = {00465828},
  note      = {Bayesian approaches;Bayesian updating;Capacity distribution;Decision framework;Lower bounds;Reliability based design;Test program;Value of information;},
  abstract  = {There is currently an inconsistency in the recommendations that are available in pile design codes and practices regarding the required number of proof-load tests and the level of the proof loads. This paper presents the results of a comprehensive investigation that is conducted to study the effect of choosing different proof-load test programs on the reliability of piles. This is achieved by utilizing a Bayesian approach to update the capacity distribution of piles at a site given the results of the proof-load test program. In the updating exercise, an effort is made to update both the mean and the lower-bound capacity to maximize the benefit of the collected proof load data. The significance of the results presented lies in the fact that these results constitute necessary input to any practical decision framework for choosing the number and the magnitude of the proof load test that would maximize the value of information of the test program.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Statistical tests},
  keywords  = {Bayesian networks;Piles;Reliability;Software testing;Test facilities;},
  language  = {English},
}

@Article{MacedoRodrigues2015,
  author    = {Macedo Rodrigues, Elder and Moreira de Oliveira, Flavio and Teodoro Costa, Leandro and Bernardino, Maicon and Zorzo, Avelino Francisco and do Rocio Senger Souza, Simone and Saad, Rodrigo},
  title     = {An empirical comparison of model-based and capture and replay approaches for performance testing},
  journal   = {Empirical Software Engineering},
  year      = {2015},
  volume    = {20},
  number    = {6},
  pages     = {1831 - 1860},
  issn      = {13823256},
  note      = {Empirical studies;Experimental study;Model based testing;Performance testing;Script generation;Testing automation;},
  abstract  = {A variety of testing tools has been developed to support and automate the software testing activity. Some of them may use different techniques such as Model-based Testing (MBT) or Capture and Replay (CR). Model-based Testing is a technique for automatic generation of testing artifacts based on software models. One of the main benefits of using MBT is related to the easiness of maintaining models over code; hence, it is likely that using models as a source for automatic generation of scripts requires less effort and reduces the number of faults. Otherwise, CR-based tools basically record the user interaction with the System Under Test (SUT) and then playback the recorded test. This paper presents our effort on setting up and running an experimental study performed in order to evaluate the effort to use MBT and CR-based tools to generate performance scripts. Thus, we apply an MBT and a CR approaches for the purpose of evaluation with respect to the effort to generate scripts and scenarios from the perspective of the performance testers and the performance test engineers in the context of undergraduates, M.Sc. and Ph.D. students, performance testers and performance test engineers for the generation of performance test scripts and scenarios. Our results indicate that, for simple testing tasks, the effort of using a CR-based tool was lower than using an MBT tool, but as the complexity or size of the activities of the testing tasks increases, the advantage of using MBT increased significantly.<br/> &copy; 2014, Springer Science+Business Media New York.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Software testing},
  keywords  = {Automatic programming;Model checking;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/s10664-014-9337-5},
}

@Article{Liu2014a,
  author    = {Liu, Zhenyu and Chen, Qiang and Cai, Lizhi},
  title     = {Research on GUI-based automation test technology driven by separated definition data},
  journal   = {International Journal of Control and Automation},
  year      = {2014},
  volume    = {7},
  number    = {6},
  pages     = {421 - 432},
  issn      = {20054297},
  note      = {Automated test;Automated testing;Automated testing tools;Automation software;Automation tests;Definition data;Functional test;Test Automation;},
  abstract  = {GUI-based software is often developed a complicated test script with existing traditional automation software testing tools. The software automated test development technology consequently carried out some study of existing automated testing with current automated testing tools to simplify the script. The paper proposed a novel test automation technology with separated definition data, which replaced by script development or modification. The definition data are depicted for script driven, page description and test data separately. The test automation technology provided completed function and interface between this method and actual test tool. The test engineers is not need to write the any test script, but modify the definition files for test developing to some extent. The automation functional test technology has support the typical test tool and proved effective in the specific cases. &copy; 2014 SERSC.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Software testing},
  keywords  = {Automation;Graphical user interfaces;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.14257/ijca.2014.7.6.39},
}

@InProceedings{Hwang2014,
  author    = {Hwang, Gwan-Hwan and Wu-Lee, Chi and Tung, Yuan-Hsin and Chuang, Chih-Ju and Wu, Syz-Feng},
  title     = {Implementing TaaS-based stress testing by MapReduce computing model},
  year      = {2014},
  pages     = {137 - 140},
  address   = {Beijing, China},
  note      = {Computation power;Computing model;Computing system;Hadoop;Map-reduce;Network transactions;Stress Testing;Testing as a services;},
  abstract  = {In this paper we propose to employ the MapReduce computing model to implement a Testing as a Service (TaaS) for stress testing. We focus on stress testing for heavy-weight network transactions. The computation power of MapReduce computing system is used to simulate concurrent network transactions issued by a lot of users. The user first describes the testing scenario which he wants to be simulate in a testing script. The TaaS platform analyzes the testing script and then automatically distributes required testing data including details of transactions and files into a MapReduce computing system. We propose three different schemes to distribute testing data and measure their performances. We compare them with the popular stress testing tool JMeter and find out that our scheme can always have the tested system deliver higher error rate during the stress testing.<br/> &copy; 2014 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {23270586},
  journal   = {Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS},
  key       = {Software engineering},
  keywords  = {Electrical engineering;Engineering;Industrial engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICSESS.2014.6933530},
}

@InProceedings{Kanstren2015,
  author    = {Kanstren, Teemu and Aho, Pekka and Lamsa, Arttu and Martin, Henar and Liikka, Jussi and Seppanen, Miska},
  title     = {Robot-assisted smartphone performance testing},
  year      = {2015},
  volume    = {2015-August},
  address   = {15 Middlesex Canal Park, Woburn, MA, United states},
  note      = {Collaboration with industries;Device performance;Hardware and software;Performance evaluations;Performance testing;Robot kinematics;Service robots;Software/hardware;},
  abstract  = {This paper describes experiences and lessons learned in applying an approach of using a physical robot for testing overall smartphone device performance based on user profiles. The process consists of capturing user actions, abstracting them to usage profiles, transforming these into test models, and generating test cases from the models. The goal is to support performance testing of touch screen devices and applications in a realistic test environment. To achieve this, the tests are based on real-world generated user profiles and executed using a real physical robot, simulating the actual user. Our performance testing targets different attributes of performance such as response times, power and resource usage, and software/hardware aging. Use of different hardware and software configurations in the test scenarios is considered. This work has been performed in close collaboration with industry partners in robotics provider and user industries.<br/> &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {23250526},
  journal   = {IEEE Conference on Technologies for Practical Robot Applications, TePRA},
  key       = {Software testing},
  keywords  = {Electronic mail;Human computer interaction;Markov processes;Robot applications;Robots;Smartphones;Testing;Touch screens;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/TePRA.2015.7219669},
}

@InProceedings{DeSousaSantos2011,
  author    = {De Sousa Santos, Ismayle and Santos, Alcemir Rodrigues and Neto, Pedro De Alcantara Dos S.},
  title     = {Reusing functional testing in order to decrease performance and stress testing costs},
  year      = {2011},
  pages     = {470 - 474},
  address   = {Miami, FL, United states},
  note      = {Automatic Generation;Data generation;Experimental study;Functional testing;Non-functional requirements;Stress Testing;Test efforts;Test quality;},
  abstract  = {This work presents an experimental study of an idea related to the automatic generation of performance and stress testing by reusing functional testing. The idea was implemented in a tool named FERRARE GT. This tool is able to generate both test scripts as well as the data required for their execution. In this study we verified that the use of the method can generate benefits related to cost reduction, from the reduction of test effort and, at the same time, benefits related to test quality, from the improvement of the test relevance for the software development.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {SEKE 2011 - Proceedings of the 23rd International Conference on Software Engineering and Knowledge Engineering},
  key       = {Software testing},
  keywords  = {Cost reduction;Knowledge engineering;Software design;},
  language  = {English},
}

@Article{Omidshafiei2016,
  author    = {Omidshafiei, Shayegan and Agha-Mohammadi, Ali-Akbar and Chen, Yu Fan and Ure, Nazim Kemal and Liu, Shih-Yuan and Lopez, Brett T. and Surati, Rajeev and How, Jonathan P. and Vian, John},
  title     = {Measurable Augmented Reality for Prototyping Cyberphysical Systems: A Robotics Platform to Aid the Hardware Prototyping and Performance Testing of Algorithms},
  journal   = {IEEE Control Systems},
  year      = {2016},
  volume    = {36},
  number    = {6},
  pages     = {65 - 87},
  issn      = {1066033X},
  note      = {Complex environments;Cyber physical systems (CPSs);Hardware prototyping;Prototyping platform;Real time visualization;Research challenges;Sources of uncertainty;Visualization tools;},
  abstract  = {Planning, control, perception, and learning are current research challenges in multirobot systems. The transition dynamics of the robots may be unknown or stochastic, making it difficult to select the best action each robot must take at a given time. The observation model, a function of the robots' sensor systems, may be noisy or partial, meaning that deterministic knowledge of the team's state is often impossible to attain. Moreover, the actions each robot can take may have an associated success rate and/or a probabilistic completion time. Robots designed for real-world applications require careful consideration of such sources of uncertainty, regardless of the control scheme or planning or learning algorithms used for a specific problem. Understanding the underlying mechanisms of planning algorithms can be challenging due to the latent variables they often operate on. When performance testing such algorithms on hardware, the simultaneous use of the debugging and visualization tools available on a workstation can be difficult. This transition from experimentation to implementation becomes especially challenging when the experiments need to replicate some feature of the software tool set in hardware, such as simulation of visually complex environments. This article details a robotics prototyping platform, called measurable augmented reality for prototyping cyberphysical systems (MAR-CPS), that directly addresses this problem, allowing for the real-time visualization of latent state information to aid hardware prototyping and performance testing of algorithms. &copy; 2016 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Robot programming},
  keywords  = {Augmented reality;Computer aided software engineering;Computer debugging;Computer software;Embedded systems;Hardware;Learning algorithms;Program debugging;Real time systems;Robotics;Robots;Stochastic systems;Visualization;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/MCS.2016.2602090},
}

@InProceedings{Mukherjee2014,
  author    = {Mukherjee, Joydeep and Wang, Mea and Krishnamurthy, Diwakar},
  title     = {Performance testing web applications on the cloud},
  year      = {2014},
  pages     = {363 - 369},
  address   = {Cleveland, OH, United states},
  note      = {Amazon web services;Cloud environments;Cloud platforms;Elastic compute clouds;Performance effect;Performance issues;Performance testing;WEB application;},
  abstract  = {Web applications are increasingly resorting to public cloud platforms such as the Amazon Web Services (AWS) Elastic Compute Cloud (EC2). However, previous studies have shown that the virtualized infrastructures used in a cloud environment can introduce performance issues. Hence, it is crucial to test the performance of the cloud to support Web applications. This is challenging because the performance effect of the cloud platform cannot be easily isolated from other extraneous factors. In this paper, we present a systematic experimental process to address this challenge. Following our proposed process, we test the performance of Web applications running on different types of AWS EC2 instances. Results suggest that Web server response times can fluctuate up to 1000% for the same workload under certain circumstances such as instance type, time-of-the-day, and day-of-the-week. &copy; 2014 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - IEEE 7th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2014},
  key       = {Software testing},
  keywords  = {Verification;Web services;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICSTW.2014.57},
}

@Article{Johnson2007,
  author    = {Johnson, Michael J. and Maximilien, E. Michael and Ho, Chih-Wei and Williams, Laurie},
  title     = {Incorporating performance testing in test-driven development},
  journal   = {IEEE Software},
  year      = {2007},
  volume    = {24},
  number    = {3},
  pages     = {67 - 73},
  issn      = {07407459},
  note      = {Test execution;Test-driven design;Test-driven development;},
  abstract  = {Performance design and performance testing are necessarily different from functional test case design. A rigorous test-driven design methodology isn't practical for all performance measurement. A test-first approach to performance provides some advantages in a TDD environment. Experience with applying early performance testing in a TDD framework for a device-driver development project provides insight into the test-first approach. The results show a trend of performance improvement throughout the development life cycle, and better performance compared to an earlier release. Lessons learned include the benefit of having a performance architect on the development team and of tracking performance measurements throughout the development life cycle.This article is part of a special issue on test-driven development. &copy; 2007 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Software engineering},
  keywords  = {Software design;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/MS.2007.77},
}

@Article{Ouyang2006,
  author    = {Ouyang, Rongbin and Guo, Zhi and Gu, Ming},
  title     = {Research on queuing-model-based framework for software performance testing},
  journal   = {Jisuanji Gongcheng/Computer Engineering},
  year      = {2006},
  volume    = {32},
  number    = {3},
  pages     = {73 - 75},
  issn      = {10003428},
  abstract  = {This paper presents a new performance testing framework which uses simulation and modeling techniques based on queuing model. For the framework, it presents an algorithm to estimate the simulation model's parameters. With the framework, it can generate volumes of simulated test data according to a small quantity of real data. The framework is practiced on the performance testing of Beijing one-card-multiple-services system.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  language  = {Chinese},
}

@Article{Tan2014,
  author    = {Tan, Yong and Lin, Guoming},
  title     = {Comprehensive load test on prestressed concrete piles in alluvial clays and marl in Savannah, Georgia},
  journal   = {Journal of Performance of Constructed Facilities},
  year      = {2014},
  volume    = {28},
  number    = {1},
  pages     = {178 - 190},
  issn      = {08873828},
  note      = {Alluvial clay;Axial compression load;Bearing capacity formulas;Cyclic lateral loading;Lateral load tests;Lateral loading conditions;Marl formation;Pile driving analyzers;},
  abstract  = {This paper introduces a comprehensive full-scale pile load test program on 457-mm (18-in.) square prestressed concrete (PSC) piles in Savannah, Georgia. The program consisted of pile driving analyzer testing during initial pile driving and restrikes, Statnamic tests, static axial compression load tests, and reciprocal lateral load tests. On the basis of the interpretation of the test data, some important findings were obtained: (1) the alluvial clays in Savannah can only provide very limited resistance; (2) the time-dependent pile capacity gain after pile driving (i.e., setup effect) was approximately proportional to the pile embedment length into the Marl formation; (3) the estimated equivalent static pile capacities from the Statnamic tests were comparable to those from the static axial load tests; (4) the Marl formation is a competent bearing stratum for piles; (5) the potential degradation of pile concrete stiffness caused by pile driving should be accounted for in pile capacity analysis; and (6) the piles exhibited stiffer response under the monotonic lateral loading condition than the cyclic lateral loading condition. Finally, predictions on both axial and lateral pile capacities, using the soil parameters derived from the instrumentation data and back-analysis of the pile load tests, were compared with the corresponding pile load test results. The comparisons demonstrate that in combination of the static-bearing capacity formulas and the LPILE program, the developed soil models can make reliable predictions on both the vertical and lateral behaviors of the PSC piles driven through the soft alluvial clays to end bearing in the Marl formation. &copy; 2014 American Society of Civil Engineers.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Piles},
  keywords  = {Axial loads;Concrete beams and girders;Fertilizers;Load testing;Pile driving;Prestressed concrete;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1061/(ASCE)CF.1943-5509.0000305},
}

@InProceedings{ToledoRodriguez2013,
  author    = {Toledo Rodriguez, Federico and Reina, Matias and Baptista, Fabian and Polo Usaola, Macario and Perez Lamancha, Beatriz},
  title     = {Automated Generation of Performance Test Cases from Functional Tests for Web Applications},
  year      = {2013},
  volume    = {417 CCIS},
  pages     = {164 - 173},
  address   = {Angers, France},
  note      = {Automated generation;Functional testing;Modernization projects;Non functional properties;Non-functional;Performance tests;Record and playback;Testing automation;},
  abstract  = {When modernizing systems there are big risks concerning functional and non-functional properties. It is expected that the functionality, the performance and the dependability are the same (or better) in the new version. Therefore, the preventive workload simulation (to verify non-functional properties) is crucial to guarantee the success of the modernization project. Since tools for load simulation work at protocol level, the automation of tasks for workload simulation demand much more effort than functional testing, whose test cases are designed using record and playback techniques on the GUI: these tools are more intuitive and they have to handle less variables and technical issues. In this article we present a tool to automatically generate workload simulation scripts from automated functional tests. The tool has been used in several projects in the industry, achieving important cost savings and improving flexibility when verifying non-functional properties of a migrated system. &copy; Springer-Verlag Berlin Heidelberg 2013.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {18650929},
  journal   = {Communications in Computer and Information Science},
  key       = {Software testing},
  keywords  = {Automation;Load testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-54092-9_12},
}

@Article{Pei2009,
  author    = {Pei, K.C. and Kan, Y.C. and Yen, T. and Lin, D.W.},
  title     = {A preliminary study on the fracture behaviors of reinforced concrete slabs by monitoring the load test using acoustic emission method},
  journal   = {Journal of the Chinese Institute of Civil and Hydraulic Engineering},
  year      = {2009},
  volume    = {21},
  number    = {2},
  pages     = {155 - 168},
  issn      = {10155856},
  note      = {Acoustic emission method;Acoustic emission techniques;Composite behavior;Concrete strength;Experimental program;Kaiser effect;RC slab;Reinforcement arrangements;},
  abstract  = {This paper presents the use of Acoustic Emission Technique (AE) to evaluate the fracture behavior of different RC slabs under the load test. During the load test, AE inspection was applied using a self-developed instrument to record/monitor the emitted ultrasonic waves within the 2 &times; 2 m slab-type specimens. AE records for three RC slabs were demonstrated here for analyzing in hit-count, frequency and wave-form. These results revealed the "Kaiser effect" and the "intermittent" characteristic due to the concrete-rebar mechanism and other composite behaviors. The experimental program is based on monitoring the load tests of three RC slabs with 280 kg/cm<sup>2</sup>concrete strength. The Kaiser effect was validated and the characteristics of various reinforcement arrangements of slab were found while the load tests were being performed.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Acoustic emission testing},
  keywords  = {Acoustic emissions;Concrete slabs;Fracture;Fracture mechanics;Load testing;Reinforced concrete;Software testing;Ultrasonic applications;},
  language  = {Chinese},
}

@Article{Au2009,
  author    = {Au, Alexander and Lam, Clifford and Tharmabala, Bala},
  title     = {Investigation of shear resistance of steel bridge girders by load testing and monitoring of load response data under highway traffic conditions},
  journal   = {Canadian Journal of Civil Engineering},
  year      = {2009},
  volume    = {36},
  number    = {3},
  pages     = {449 - 462},
  issn      = {03151468},
  note      = {Bridge testing;Field measurement;Live-load capacity;Shear resistances;Steel bridge girders;Strength evaluation;Traffic loads;Transverse stiffener;},
  abstract  = {A recent strength evaluation of the Hogg's Hollow Bridge on Highway 401 in Ontario revealed a significant deficiency in the shear resistance of the existing girders at support locations. This was attributed to the absence of transverse stiffeners at the extreme ends of the girders. However, none of the bridge girders showed any signs of distress. The Ontario Ministry of Transportation recently conducted a field study to investigate this shear issue in greater detail. To that end, a test program was devised to (a) monitor the real stresses in the end panels of two selected girders in the Hogg's Hollow Bridge when subjected to (i) a test truck with known axle loads and (&laquo;) normal highway traffic loading, and (b) calibrate the observed stresses against theoretically expected responses in the girders and calculate the live load capacity factor using the shear data derived from the field measurements.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Highway bridges},
  keywords  = {Automobile testing;Load testing;Plate girder bridges;Software testing;Steel bridges;Steel testing;Traffic surveys;},
  language  = {English},
  url       = {http://dx.doi.org/10.1139/L09-009},
}

@InProceedings{Mandracchia1996,
  author    = {Mandracchia, Efrain A.},
  title     = {Ultrasonic diagnostic load testing of steel highway bridges},
  year      = {1996},
  volume    = {2946},
  pages     = {17 - 25},
  address   = {Scottsdale, AZ, United states},
  note      = {Applied strain;Bridge diagnostics;Civil and structural engineerings;EMAT;Measurement techniques;Rainflow;Resistance strain gauges;Ultrasonic diagnostics;},
  abstract  = {This paper presents a new product, the SonicForce&trade; Acoustic Strain Gauge (ASG), that utilizes a non-contact ultrasonic technology to measure applied strain requiring no paint removal and minimal surface preparation. After an overview of the ultrasonic technology is presented the results of a diagnostic test utilizing a prototype of the ASG will be discussed. The purpose of this test was to validate the Acoustic Strain Gauge as being functionally equivalent to the resistance strain gauge, and to demonstrate a cost effective enabling technology to the civil and structural engineering communities. The diagnostic tests program was supervised by Dr. Abba Lichtenstein in accordance with accepted guidelines contained in the manual for "Rating Bridges Through Testing" For the purpose of this study the bridge superstructure was modeled and structural loading profiles were determined using both resistive and acoustic strain measurement techniques. Measured strains as determined by the ASG (correlation between the ASG and the resistance strain gauge was 0.998) were compared to theoretical loads in order to determine if the Rodeo Gulch superstructure was operating in a safe and reliable manner. Additionally, under the direction of Phil Fish (Wisconsin DOT), two pre-production ASGs were used to monitor accumulated cyclic loading. These test data presented as a time series strip chart and rainflow histogram. &copy;2005 Copyright SPIE - The International Society for Optical Engineering.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {0277786X},
  journal   = {Proceedings of SPIE - The International Society for Optical Engineering},
  key       = {Ultrasonic testing},
  keywords  = {Cost effectiveness;Cost engineering;Highway bridges;Load testing;Nondestructive examination;Program diagnostics;Software testing;Steel testing;Strain;Strain gages;Ultrasonics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1117/12.259142},
}

@InProceedings{Canfora2013,
  author    = {Canfora, Gerardo and Mercaldo, Francesco and Visaggio, Corrado Aaron and D'Angelo, Mauro and Furno, Antonio and Manganelli, Carminantonio},
  title     = {A case study of automating user experience-oriented performance testing on smartphones},
  year      = {2013},
  pages     = {66 - 69},
  address   = {Luxembourg, Luxembourg},
  note      = {Advanced tests;android;Android smart phones;Mobile applications;Objective metrics;Performance testing;usability;User experience;},
  abstract  = {We have developed a platform named Advanced Test Environment (ATE) for supporting the design and the automatic execution of UX tests for applications running on Android smart phones. The platform collects objective metrics used to estimate the UX. In this paper, we investigate the extent that the metrics captured by ATE are able to approximate the results that are obtained from UX testing with real human users. Our findings suggest that ATE produces UX estimations that are comparable to those reported by human users. We have also compared ATE with three widespread benchmark tools that are commonly used in the industry, and the results show that ATE outperforms these tools. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - IEEE 6th International Conference on Software Testing, Verification and Validation, ICST 2013},
  key       = {Smartphones},
  keywords  = {Design;Robots;Software testing;Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICST.2013.16},
}

@InProceedings{Diaz-Tous1994,
  author    = {Diaz-Tous, I.A. and Mateos, M.A.},
  title     = {Condenser and feedwater heater computerized performance testing and diagnostic programs},
  year      = {1994},
  volume    = {25},
  pages     = {165 - 172},
  address   = {Phoenix, AZ, USA},
  note      = {Computerized performance test program (CTCP);Diagnostic programs;},
  abstract  = {Accurate interpretation of performance-test results can lead to improved unit heat-rate and reduced equipment failure or damage when appropriate and timely corrective actions are taken. Aware of the difficulties inherent in performance testing as well as the need for a PC-based tool to support performance engineers in power plant problem diagnosis, NYSEG and ENCOR commenced developing (in 1990) the Computerized Performance Test Program (CPTP). CPTP is designed to ease performance testing, enhance the quality of performance-test results and provide correct diagnostics and recommendations for actions to the performance-test engineer and power-operations management. To accomplish these goals, CPTP utilizes expert algorithms based on the years of experience accumulated by the engineering staffs at NYSEG and ENCOR. Such experience is demonstrated by the extensive guidance provided by CPTP regarding the prioritization of equipment testing and the preparation and execution of the proper test procedures. Equally insightful are the interpretation of the test results and the corrective actions prescribed to solve diagnosed problems. For all these reasons, CPTP is an effective training tool for plant personnel to improve the performance of the condenser and feedwater heaters and plan the maintenance of any power plant. Currently, NYSEG and Portland General Electric (PGE) are using CPTP modules for performance testing, diagnostic and training purposes.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {American Society of Mechanical Engineers, Power Division (Publication) PWR},
  key       = {Feedwater heaters},
  keywords  = {Algorithms;Computer aided analysis;Computer software;Condensers (liquefiers);Performance;},
  language  = {English},
}

@InProceedings{Cho2010,
  author    = {Cho, Chang-Sik and Lee, Dong-Chun and Sohn, Kang-Min and Park, Chang-Joon and Kang, Ji-Hoon},
  title     = {Scenario-based approach for blackbox load testing of online game servers},
  year      = {2010},
  pages     = {259 - 265},
  note      = {Description languages;On-line games;Scenario-based testing;Virtual games;Virtual users;},
  abstract  = {Simply having a large beta test cannot consistently provide stability and performance to game servers, which are major issues in online game development. Therefore, test automations have been used in order to reduce the testing time of online games by simulating highly repetitive tasks and emulating server loads. However, in previous approaches, blackbox testing and scenario-based testing are not supported because they use prerecorded packets of real players as templates, or reuse a subset of the main game client for the test client. In this paper, we propose blackbox testing and scenario-based testing of online games as well as simple load testing. Instead of rewriting the virtual client dummy code, only the game description language and virtual game map are redefined when a new game is to be tested. In addition, an actual testing environment can be mimicked more closely, because complex and various scenarios such as attack, party play, and waypoint movement can be tested through combining actions. We have applied our tools on several online games to verify the effectiveness of our method. &copy; 2010 IEEE.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {Proceedings - 2010 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery, CyberC 2010},
  key       = {Black-box testing},
  keywords  = {Computer aided software engineering;Distributed computer systems;Load testing;Social networking (online);Software design;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/CyberC.2010.54},
}

@InProceedings{Chan1994,
  author    = {Chan, H.Anthony},
  title     = {Formulation to optimize stress testing},
  year      = {1994},
  pages     = {1020 - 1027},
  address   = {Washington, DC, USA},
  note      = {Contour maps;Operator model;Product reliability;Product robustness;Product yield strength;Stress testing;},
  abstract  = {Although hard-defects may be detectable in factory tests, weak products may exhibit failures or degrade only under certain stress conditions. Without stress testing, these weak products may often be shipped to customers causing early failures in the field. A candidate product for stress testing needs to get more business benefits to more than pay off the cost of stress testing. A business measure of the success of the stress testing program is the net benefit, which is the total benefit minus the total cost of the program. The optimum stress testing program maximizes this net benefit. A given unit of a product has a probability of encountering a maximum stress X during its product life. It also has a probability of possessing a product yield strength Y, which is the maximum stress the unit can survive without failure. While the strength distribution depends on the design and manufacture processes, the distribution of the maximum stress is determined by the customers' environment. A convenient picture is to construct the contour map of the joint probability distribution of X and Y. In this contour map, a unit falling in the Y &lt; X region will fail during its product life, whereas one falling in the Y &gt; X region will not result in field failure. The effects of stress testing at a given maximum stress level, X<sup>ST</sup>, are shown by a dividing line on the product strength into stress test failure and stress test pass. The units in the contour map are then divided into four regions by the Y = X line and the X<sup>ST</sup> line. The cost and benefits may now be evaluated for each region. Now the value of X<sup>ST</sup> is a free parameter that determines the relative size of each region. The second free parameter is the fraction of units going through stress testing. These two parameters may be adjusted to maximize the net benefit of the stress testing program.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {05695503},
  journal   = {Proceedings - Electronic Components and Technology Conference},
  key       = {Stress analysis},
  keywords  = {Computer software;Electron device testing;Failure (mechanical);Mathematical models;Optimization;Product design;Reliability;Robustness (control systems);},
  language  = {English},
}

@InProceedings{Zhang2015a,
  author    = {Zhang, Junbin and Huang, Xueying and Ma, Li and Xu, Youliang and Li, Hongkui},
  title     = {Performance testing program design and assessment methods of small arms},
  year      = {2015},
  address   = {Moscow, Russia},
  note      = {Battlefield environments;Construction method;Environment simulation;Operational performance;Performance evaluations;Performance testing;Performance tests;Small arms;},
  abstract  = {In this paper, a comprehensive identification on the overall performance of light weapons is as a starting point, and it proposed simulated combat background, operational performance testing program of light weapons with a typical combat mission, and to build simulated battlefield environment and simulate human testing apparatus to establish methods are discussed, proposed the construction methods and technical approach. On the basis of analysis of the various performance evaluation methods, mathematical model of light weapons and tactical performance test evaluation is established.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {2015 5th International Workshop on Computer Science and Engineering: Information Processing and Control Engineering, WCSE 2015-IPCE},
  key       = {Software testing},
  keywords  = {Testing;},
  language  = {English},
}

@InProceedings{Miljkovic2012,
  author    = {Miljkovic, Dorde and Bojic, Sasa and Dukic, Miodrag and Jovanovic, Miladin},
  title     = {Automation testing of Graphical User Interface},
  year      = {2012},
  pages     = {1609 - 1612},
  address   = {Belgrade, Serbia},
  note      = {Automation testing;Graphical tools;GUIPlayer;ispitivanje;Lua;},
  abstract  = {In this paper is explained one solution for automation of testing Graphical User Interface. The paper gives a description of the problem, the concept of a solution and a description of the implementation of such a solution in order to confirm the above concept. Validation of the implementation was carried out on graphical tool for the development of software for audio target platform. &copy; 2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {2012 20th Telecommunications Forum, TELFOR 2012 - Proceedings},
  key       = {Graphical user interfaces},
  keywords  = {XML;},
  language  = {Bosnian},
  url       = {http://dx.doi.org/10.1109/TELFOR.2012.6419531},
}

@Article{Jiang2010a,
  author    = {Jiang, Chong and Huang, Yin-Sheng and Duan, Jin-Jun and Li, Jin-Tao},
  title     = {Study of igniter composition design and its performance test of base bleed},
  journal   = {Dandao Xuebao/Journal of Ballistics},
  year      = {2010},
  volume    = {22},
  number    = {4},
  pages     = {107 - 110},
  issn      = {1004499X},
  note      = {Base bleed;Combustion performance;Combustion temperatures;Combustion velocities;Composition design;Formula design;Thermodynamic calculations;Work environments;},
  abstract  = {Five kinds of pyrotechnic formulas were designed by thermodynamic calculation software CEA2 based on the work environment of base bleed igniter. The combustion velocity, flame size, combustion temperature and heat release were measured, and the experiment of semi-closed bomb was carried out. The combustion performance of these pyrotechnics formulas was compared. The results show that the combustion temperature of ignition powder is higher while the oxidant content is 45%, and the fire areas and higher heat release of formulas containing KNO<inf>3</inf>are larger than those of formulas containing Ba(NO<inf>3</inf>)<inf>2</inf>. The formula that KNO<inf>3</inf>:Mg:Zr:fluoro rubber(ratio of quality) equals 45:30:25:5 is the better pyrotechnic formula, and the formula is fit for the ignition of base bleed projectile.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  key       = {Ignition},
  keywords  = {Barium compounds;Potash;Potassium Nitrate;Thermodynamics;},
  language  = {Chinese},
}

@InProceedings{Che2013,
  author    = {Che, Xiaoping and Maag, Stephane},
  title     = {A formal passive performance testing approach for distributed communication systems},
  year      = {2013},
  pages     = {74 - 84},
  address   = {Angers, France},
  note      = {Communicating protocols;Conformance testing;Distributed communication systems;Distributed framework;Logic-based approach;Performance requirements;Performance testing;Protocol performance;},
  abstract  = {Conformance testing of communicating protocols is a functional test which verifies whether the behaviors of the protocol satisfy defined requirements, while the performance testing of communicating protocols is a qualitative and quantitative test, aiming at checking whether the performance requirements of the protocol have been satisfied under certain conditions. It raises the interesting issue of converging these two kinds of tests by using the same formal approach. In this paper, we present a novel logic-based approach to test the protocol performance through real execution traces and formally specified properties. In order to evaluate and assess our methodology, we have developed a prototype and present experiments with a set of IMS/SIP properties. Finally, the relevant verdicts and discussions are provided. Copyright &copy; 2013 SCITEPRESS.},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  journal   = {ENASE 2013 - Proceedings of the 8th International Conference on Evaluation of Novel Approaches to Software Engineering},
  key       = {Software engineering},
  keywords  = {Engineering;Formal methods;Industrial engineering;},
  language  = {English},
}

@InProceedings{ScottKeller1992,
  author    = {Scott Keller, A. and Whitehead, Gerald D.},
  title     = {Performance testing of the extended-range (hybrid) electric G van},
  year      = {1992},
  address   = {Detroit, MI, United states},
  note      = {Constant speed;Electric Power Research Institute;Gasoline engines;Gasoline operations;Performance characterization;Performance testing;Powertrain components;States of charges;},
  abstract  = {This paper presents the results of performance characterization testing of the extended-range Conceptor G Van electric vehicle (EV). Testing was performed at the Electrotek Electric Vehicle Test Facility (EVTF) as part of the Electric Power Research Institute (EPRI)/Electrotek EV Program. This extended-range EV (XREV) is based on the electric G Van, which is a GMC full-sized van converted to electric propulsion by Conceptor Industries of Newmarket (Toronto), Ontario. A 7-kW Onan gasoline engine/generator (E/G) set was retrofitted into the vehicle by McKee Engineering of Lake Zurich, Illinois. The XREV utilizes tubular-plate lead-acid batteries and dc powertrain components furnished by Chloride EV Systems of Redditch, England. Testing was conducted according to the EPRI/Electrotek EV Test Plan and included measurement of driving range on the SAE J227a C Cycle, on the Electrotek-defined Chattanooga City Cycle (CCC), and at four constant speeds from 56 km/h to 80 km/h. The C Cycle and CCC tests were performed with the E/G switched on at different battery states of charge (SOC) from 100% to 25% to determine the effects of the E/G on driving range and battery behavior. Limp-home tests were also conducted over these cycles by driving the XREV on pure-electric power to 0% SOC, turning on the E/G for a one-hour battery charge, and then continuing the cycle under both battery and E/G power. It was found that use of the E/G increased driving range significantly for all cases. Additional tests were performed to determine the dc energy consumption of the XREV over the C cycle and at various constant speeds. Data is presented which includes driving test results as well as calculated costs for different combinations of electric and gasoline operation. &copy; Copyright 1992 Society of Automotive Engineers, Inc.<br/>},
  copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
  issn      = {01487191},
  journal   = {SAE Technical Papers},
  key       = {Software testing},
  keywords  = {Charging (batteries);Chlorine compounds;Energy utilization;Gasoline;Lead acid batteries;Vehicles;},
  language  = {English},
  url       = {http://dx.doi.org/10.4271/920439},
}

@InProceedings{Schubert2007,
  author    = {L. Schubert and M. Kuttner and B. Frankenstein and D. Hentschel},
  title     = {Structural Health Monitoring of a rotor blade during statical load test},
  booktitle = {18th International Workshop on Database and Expert Systems Applications (DEXA 2007)},
  year      = {2007},
  pages     = {297-301},
  month     = {Sept},
  abstract  = {The paper describes a structural health monitoring concept based on the evaluation of acoustic Lamb waves. Using a suitable damage indicator like the correlation coefficient it is possible to detect and localize defects in the observed structure. The functional capability was shown in statical test of a part of a rotor blade.},
  doi       = {10.1109/DEXA.2007.151},
  issn      = {1529-4188},
  keywords  = {blades;condition monitoring;correlation methods;fault diagnosis;rotors;statistical testing;surface acoustic waves;acoustic Lamb waves;correlation coefficient;damage indicator;defect detection;defect localization;rotor blade;statical load test;structural health monitoring;Acoustic emission;Acoustic sensors;Acoustic signal detection;Acoustic testing;Acoustic waves;Blades;Electronic mail;Monitoring;Sensor systems;Wind energy;acoustic signature;acousto ultrasonics;correlation coefficient;rotor blade;statical load test;structural health monitoring},
}

@InProceedings{Kiamilev1996,
  author    = {F. Kiamilev and R. Rozier and J. Rieve},
  title     = {A compact, low-cost, high-performance test fixture for electrical test and control of smart pixel integrated circuits},
  booktitle = {Digest IEEE/Leos 1996 Summer Topical Meeting. Advanced Applications of Lasers in Materials and Processing},
  year      = {1996},
  pages     = {63-64},
  month     = {Aug},
  abstract  = {We have developed a low-cost, compact test fixture that can supply and monitor high-speed electrical signals for smart pixel ICs packaged in an 84-pin PGA chip carrier.},
  doi       = {10.1109/LEOSST.1996.540746},
  keywords  = {field programmable gate arrays;integrated circuit packaging;integrated circuit testing;integrated optoelectronics;monitoring;smart pixels;test equipment;PGA chip carrier;compact low-cost high-performance test fixture;electrical test;high-speed electrical signal monitoring;smart pixel IC packaging;smart pixel integrated circuit control;smart pixel integrated circuit testing;Circuit testing;Clocks;EPROM;Electronics packaging;Field programmable gate arrays;Fixtures;Hardware design languages;Integrated circuit testing;Smart pixels;Sockets},
}

@Article{Demirkaya2007,
  author   = {O. Demirkaya and R. Al Mazrou},
  title    = {Performance Test Data Analysis of Scintillation Cameras},
  journal  = {IEEE Transactions on Nuclear Science},
  year     = {2007},
  volume   = {54},
  number   = {5},
  pages    = {1506-1515},
  month    = {Oct},
  issn     = {0018-9499},
  abstract = {In this paper, we present a set of image analysis tools to calculate the performance parameters of gamma camera systems from test data acquired according to the National Electrical Manufacturers Association NU 1-2001 guidelines. The calculation methods are either completely automated or require minimal user interaction; minimizing potential human errors. The developed methods are robust with respect to varying conditions under which these tests may be performed. The core algorithms have been validated for accuracy. They have been extensively tested on images acquired by the gamma cameras from different vendors. All the algorithms are incorporated into a graphical user interface that provides a convenient way to process the data and report the results. The entire application has been developed in MATLAB programming environment and is compiled to run as a stand-alone program. The developed image analysis tools provide an automated, convenient and accurate means to calculate the performance parameters of gamma cameras and SPECT systems. The developed application is available upon request for personal or non-commercial uses. The results of this study have been partially presented in Society of Nuclear Medicine Annual meeting as an InfoSNM presentation.},
  doi      = {10.1109/TNS.2007.906162},
  keywords = {cameras;gamma-ray apparatus;scintillation counters;single photon emission computed tomography;MATLAB programming;SPECT systems;gamma camera systems;graphical user interface;image analysis;scintillation cameras;Cameras;Data analysis;Graphical user interfaces;Guidelines;Humans;Image analysis;Performance evaluation;Pulp manufacturing;Robustness;System testing;Acceptance testing;SPECT;gamma cameras;performance measurement},
}

@InProceedings{Li2013,
  author    = {P. Li and D. Shi and J. Li},
  title     = {Performance test and bottle analysis based on scientific research management platform},
  booktitle = {2013 10th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)},
  year      = {2013},
  pages     = {218-221},
  month     = {Dec},
  abstract  = {The performance and service quality of a Web system become more and more important along with the development of Web application technology and popularization of Web application rapidly. There are many particularities and difficulties in the testing of web applications as to traditional application, especially in performance testing, such as unpredictable load, reality of designing scenario and veracity of analysis bottleneck. This paper which based on traditional Web system performance testing theory and used the testing tool named LoadRunner to analyze how to detect the shortage of Web system performance precisely. The method has been implemented in System of scientific research management platform, and has been obtained anticipative result. This paper has divide the web system method into six processes based on the Web system performance testing: Making performance testing plan, build performance testing environment, record and develop testing script, foundation testing scene, play the monitor scene and analysis testing result. And also gives Web performance test the general step.},
  doi       = {10.1109/ICCWAMTIP.2013.6716635},
  keywords  = {Web services;program testing;scientific information systems;software performance evaluation;software tools;LoadRunner;Web application popularization;Web application technology development;Web applications testing;Web system performance testing tool;bottleneck analysis;foundation testing scene;performance testing environment;performance testing plan;performance testing script;scene monitoring;scientific research management;service quality;Generators;Monitoring;Software systems;System performance;Testing;Throughput;Time factors;Bottleneck analysis;LoadRunner;Scientific Research Management Platform;Web Performance Testing},
}

@InProceedings{Malandruccolo2009,
  author    = {V. Malandruccolo and M. Ciappa and W. Fichtner and H. Rothleitner},
  title     = {Novel Solution for the Built-in Gate Oxide Stress Test of LDMOS in Integrated Circuits for Automotive Applications},
  booktitle = {2009 14th IEEE European Test Symposium},
  year      = {2009},
  pages     = {67-72},
  month     = {May},
  abstract  = {Efficient screening procedures for the control of the gate oxide defectivity are vital to limit early failures especially in critical automotive applications. Traditional strategies based on burn-in and in-line tests are able to provide the required level of reliability but they are expensive and time consuming. This paper presents a novel approach to the gate stress test of Lateral Diffused MOS transistors based on an embedded circuitry that includes logic control, high voltage generation, and leakage current monitoring. The concept, advantages and the circuit for the proposed built-in gate stress test procedure are described in very detail and illustrated by circuit simulation.},
  doi       = {10.1109/ETS.2009.18},
  issn      = {1530-1877},
  keywords  = {automotive electronics;circuit simulation;integrated circuit testing;power MOSFET;power semiconductor switches;semiconductor device reliability;automotive applications;built-in gate oxide stress test;circuit simulation;embedded circuitry;gate oxide defectivity;high voltage generation;lateral diffused MOS transistors;leakage current monitoring;logic control;power FET-switches;Application specific integrated circuits;Automotive applications;Circuit testing;Integrated circuit reliability;Integrated circuit testing;Logic circuits;Logic testing;MOSFETs;Stress control;Voltage control;Burn-In;Gate Oxide Reliability;Gate Stress Test;Low Side Switch},
}

@InProceedings{He2016,
  author    = {H. He and E. Wang and T. Pang},
  title     = {Research and analysis of GNSS performance test methods},
  booktitle = {2016 IEEE 11th Conference on Industrial Electronics and Applications (ICIEA)},
  year      = {2016},
  pages     = {2096-2100},
  month     = {June},
  abstract  = {GNSS performance test is necessary at various stages such as initial design, full operational capability and system modernization, and is also the important guarantee of GNSS continuous and reliable operation. At present, China's BeiDou navigation satellite system (BDS) is in the construction stage of developing from the regional navigation system to the global navigation system, which is quite vital to carry out the study on relevant performance test methods. Firstly, this paper systematically studies the GNSS performance test projects carried out in the different stages of development in view of GPS, Galileo and some augmentation systems including WAAS, GBAS, EGNOS. And the test purpose, test content, test method, the experimental reference and test results are analyzed in detailed. Then, based on the status of China's BeiDou navigation satellite system, the related suggestions for performance test methods of BDS are put forward. The study is of great reference value to establishing BDS performance test environment and developing test methods.},
  doi       = {10.1109/ICIEA.2016.7603935},
  keywords  = {Global Positioning System;telecommunication equipment testing;BDS;BeiDou navigation satellite system;China;EGNOS;GBAS;GNSS performance test method;GPS;Galileo;WAAS;augmentation system;global navigation system;regional navigation system;system modernization;Aerospace electronics;Global Positioning System;Military aircraft;Receivers;Satellite broadcasting;Satellites;BeiDou navigation satellite system (BDS);Global Positioning System (GPS);global navigation satellite system (GNSS);performance test;test methods},
}

@InProceedings{Chunqiu2011,
  author    = {Tang Chunqiu and Mo Yimin and Zhou Wen},
  title     = {Application of fuzzy and binary algorithm to regulation of load in locomotive load test},
  booktitle = {2011 Second International Conference on Mechanic Automation and Control Engineering},
  year      = {2011},
  pages     = {96-99},
  month     = {July},
  abstract  = {The purpose of locomotive load test is to examine and adjust the capability of locomotive often in its non-driving state, and it is a kind of important standard and means to estimate the quality of repairing locomotive in railway locomotive depot. There are two ways of load test at present. One is the water-resistor load test, the other is the dry resistor load test. Because the dry resistor-load test means does not pollute the environment and needs area less, its developing foreground is immense. To solve the difficulty that the current cannot be freely regulated continuously, for the first time, the model of weightier resistor network in digital circuit is applied to the locomotive dry resistor-load test system, which solves the problem of dry resistor-load test theoretically. It is proved by theory and test that the precision of dry resistor means can meet the request of locomotives constant power load test and reach the standard of water-resistor, so it can serve the application of the dry resistor-load test system. During the locomotive load test, the load of locomotive may be regulated so that the locomotive can be adapted run on all kinds of actual work state. According to the characteristic of weightier resistor, the control arithmetic, which is made up of fuzzy algorithm and binary algorithm, realizes the fast and exact regulation on locomotive load. This paper introduces how to apply fuzzy and binary algorithm to regulate the dry resistor-load and explains the realization of the fuzzy and binary algorithm.},
  doi       = {10.1109/MACE.2011.5986866},
  keywords  = {digital circuits;electric locomotives;fuzzy set theory;load regulation;mechanical testing;railways;resistors;binary algorithm;digital circuit;dry resistor load test;fuzzy algorithm;load regulation;locomotive constant power load test;nondriving state;railway locomotive depot;resistor network;water-resistor load test;Digital circuits;Fuzzy control;Generators;Insulated gate bipolar transistors;Niobium;Resistors;Water pollution;dry resistor-load;fuzzy and binary algorithm;regulation;weightier resistor},
}

@InProceedings{Reuther2018,
  author    = {G. M. Reuther and R. Pufall and B. Wunderle},
  title     = {Low cycle fatigue of aluminium thin films on vibrating silicon MEMS cantilevers: Highly accelerated stress test and finite element modelling},
  booktitle = {2018 19th International Conference on Thermal, Mechanical and Multi-Physics Simulation and Experiments in Microelectronics and Microsystems (EuroSimE)},
  year      = {2018},
  pages     = {1-7},
  month     = {April},
  abstract  = {We present a novel, highly accelerated stress test method that addresses disruption of metallisation layers in standard microelectronic components, a major reliability risk. This failure mode typically arises from large time-dependent temperature gradients due to strong cyclic current pulses. The test vehicle behind is a Silicon-based micro-cantilever beam with aluminium (Al) metallisation meander on top. By resonant excitation of the beam the metallisation is exposed to disruption via large cyclic plastic strains. Decoupling strain from temperature, a few million cycles can be reached within short time. Degradation of the metallisation reflects in measurable increase of resistance across the meander lines. Furthermore we characterise the progress of disruption by means of several failure imaging techniques. Our test method principally paves the way towards Health Monitoring concepts that allow tracking the integrity of microelectronic components subject to harsh application and environmental conditions.},
  doi       = {10.1109/EuroSimE.2018.8369941},
  keywords  = {Aluminum;Electrical resistance measurement;Fatigue;Metallization;Resistance;Strain;Temperature measurement},
}

@InProceedings{Qi2011,
  author    = {X. Qi and X. Wei and G. Qimin and X. Huigang},
  title     = {Design of Comprehensive Performance Test System for Residual Current Fire Monitoring Detector Based on Virtual Instrument Technology},
  booktitle = {2011 Third International Conference on Measuring Technology and Mechatronics Automation},
  year      = {2011},
  volume    = {1},
  pages     = {950-953},
  month     = {Jan},
  abstract  = {Aiming at the need of detecting the residual current fire monitoring detector, an intelligent test system based on virtual instrument technology was designed. This system was composed of industrial computer, data acquisition card, signal conditioning circuit, three-phase great current generator and pneumatic fixture, etc. Using Lab VIEW virtual instrument technology platform, the related test and data processing program codes were developed, and its high speed data acquisition and data processing satisfied the needs of ex-factory comprehensive performance test for residual current fire monitoring detector. The hardware design was given and the working principles of this generator were introduced, the module design of system software was also introduced in detail. Practical application shows that the intelligent test system features with stable and reliable, easy to operate and maintain, high precision and can improve the design and performance of products, which can be widely used.},
  doi       = {10.1109/ICMTMA.2011.238},
  issn      = {2157-1473},
  keywords  = {data acquisition;residual current devices;signal conditioning circuits;virtual instrumentation;Lab VIEW;data acquisition card;data processing;fire monitoring detector;high speed data acquisition;industrial computer;intelligent test system;performance test system;residual current;signal conditioning circuit;three-phase great current generator;virtual instrument technology;Current measurement;Detectors;Fires;Instruments;Monitoring;Voltage measurement;Comprehensive performance;Residual current fire monitoring detector;Virtual instrument technology;intelligent test},
}

@InProceedings{Kim2012a,
  author    = {H. Kim and Y. Lee and E. Lim},
  title     = {Fabrication and performance test of a compact-type magasonic waveguide for nano-particle cleaning},
  booktitle = {2012 12th IEEE International Conference on Nanotechnology (IEEE-NANO)},
  year      = {2012},
  pages     = {1-4},
  month     = {Aug},
  abstract  = {In this work, a compact-type megasonic cleaning system for semiconductor manufacturing was developed and its performance was verified. To design this megasonic system, firstly, an impedance analysis for a quartz megasonic waveguide with the piezoelectric actuator was performed with finite element method (FEM) software ANSYS. The obtained peak value of the anti-resonance frequency was 983 kHz, which showed good agreement with the design value of 982 kHz. In addition, acoustic pressures of the developed system was assessed by measuring acoustic pressures and comparing standard deviation values of them with a conventional megasonic system to evaluate the system performance. The analysis results showed that the standard deviation of the developed system was decreased by 38% compared to the commercial system. For another evaluation, the particle removal efficiency (PRE) test was performed with 80 nm particles. The experimental result revealed that the system has PRE of 91%. Based on the results, the developed megasonic system is regarded as an improved cleaning system which can irradiate more uniform acoustic pressures. As a consequence, it is thought to have higher energy efficiency and save the consumption of chemical and ultra pure water (UPW) in nano-particle cleaning.},
  doi       = {10.1109/NANO.2012.6321990},
  issn      = {1944-9399},
  keywords  = {acoustic intensity;acoustic waveguides;finite element analysis;nanoparticles;semiconductor technology;ultrasonic applications;ultrasonic waves;ANSYS FEM software;PRE test;antiresonance frequency;cleaning system;compact type megasonic waveguide;finite element method;frequency 938 kHz;frequency 982 kHz;impedance analysis;megasonic waveguide fabrication;megasonic waveguide performance test;nanoparticle cleaning;particle removal efficiency;piezoelectric actuator;quartz megasonic waveguide;semiconductor manufacturing;standard deviation;uniform acoustic pressure;Atmospheric measurements;Generators;Particle measurements;Megasonic;Nano-particle cleaning;Waveguide},
}

@InProceedings{Ping2012,
  author    = {C. Ping and H. Hongwei and Z. Yonghui},
  title     = {The performance test of U-shape antenna applied in tunnel detection},
  booktitle = {2012 14th International Conference on Ground Penetrating Radar (GPR)},
  year      = {2012},
  pages     = {109-114},
  month     = {June},
  abstract  = {Owing to the growth of population, thus increased land scarcity for normal surface road construct and improper city council planning it inflict more tunnel and underground structure constructed. As most of the constructed underground structures are subjected to severe adverse condition which need thorough inspection. To maintain the good inhabitable tunnel structure ground penetrating radar (GPR) always use as a measuring tools. GPR as an inspection tools in tunnel has been plague with series of setback. In this case a new type of antenna has been introduced in order to improve the performance in tunnel inspection. An emphasize part of the antenna design must be ensuring the directivity, bandwidth characteristic, radiation efficiency and the penetration depth. This research has been divided into three cases and those cases were performed in order to signify the characteristic of the antenna. Laboratory test and numerical simulation were carried out for the comparison and urged to the optimize solution. In this paper, Agilent E5060A ENA has been used for the laboratory test to examine the performance of the antenna. The FDTD method for numerical simulation is to prove the authenticity of the result of laboratory test. The test result illustrates that; the new designed antenna is suitable for tunnel inspection. The important improvement should be further carried out. Further studies must investigate the application of this type of antenna for the inspection of tunnel lining.},
  doi       = {10.1109/ICGPR.2012.6254843},
  keywords  = {antenna testing;ground penetrating radar;radar antennas;tunnels;U-shape antenna design;adverse condition;bandwidth characteristic;city council planning;ground penetrating radar;inhabitable tunnel structure;inspection tool;laboratory test;land scarcity;numerical simulation;penetration depth;radiation efficiency;surface road construct;tunnel detection;tunnel inspection;tunnel lining;underground structure;Antenna measurements;Antennas;Finite difference methods;Ground penetrating radar;Inspection;Laboratories;Numerical simulation;Antenna;ENA;FDTD;Ground Penetrating Radar;lining;tunnel},
}

@InProceedings{Gao2008,
  author    = {Jianqiang Gao and Xiaoying Fan and Junyou Zhao},
  title     = {Online performance test software and its application for Large Capacity Combined-cycle Units},
  booktitle = {2008 International Conference on Condition Monitoring and Diagnosis},
  year      = {2008},
  pages     = {192-195},
  month     = {April},
  abstract  = {The paper introduces an online performance test software for large capacity combined-cycle units. The software is composed of four parts, i.e. the integrated modular modeling software (IMMS), real time database software, client browser software and communication software. The results of the model are displayed in B/S mode on the userpsilas terminals. With IMMS, on-line performance calculating model is developed by means of modular modeling method, which follows the guidelines of ldquoPerformance Test Code on Overall Plant Performancerdquo (PTC46-1996). All the primary parameters used for model calculation are from DCS of the unit. The software has been successfully applied to a 395 MW combined-cycle power unit for a year. It runs stably and reliably. It can provide the economic indicator on line, such as gross equipment power output and gross equipment heat rate etc., so as to help operators monitoring and adjusting the operation of unit more efficiently.},
  doi       = {10.1109/CMD.2008.4580261},
  keywords  = {combined cycle power stations;condition monitoring;power engineering computing;power generation reliability;power system stability;testing;client browser software;communication software;integrated modular modeling software;large capacity combined-cycle unit;online performance test software;real time database software;Application software;Cogeneration;Databases;Distributed control;Economic indicators;Guidelines;Monitoring;Performance evaluation;Software performance;Software testing;combined-cycle;condition monitoring;modeling;online;power generation testing;programming},
}

@InProceedings{Kudomi2002,
  author    = {N. Kudomi and Eunjoo Choi and S. Yamamoto and H. Watabe and Kyeong-Min Kim and T. Hayashi and M. Ogawa and N. Teramoto and E. Sakamoto and H. Iida},
  title     = {Performance test and application of GSO detector assembly for a continuous blood sampling system},
  booktitle = {2002 IEEE Nuclear Science Symposium Conference Record},
  year      = {2002},
  volume    = {3},
  pages     = {1648-1651 vol.3},
  month     = {Nov},
  abstract  = {A new input function monitoring system has been developed using a GSO detector for both PET and SPECT quantitative studies. The paired assembly of crystals provided an absolute sensitivity of approximately 7% for PET tracers and 70% for 99mTc and 201Tl (SPECT tracers). This system was applied to clinical use and animal study such as monkey and rat. This study demonstrates that the present system can he of use in both clinical and small animal studies using SPECT and PET tracers.},
  doi       = {10.1109/NSSMIC.2002.1239640},
  keywords  = {haemodynamics;positron emission tomography;single photon emission computed tomography;solid scintillation detectors;201Tl;99mTc;GSO detector;Gd-Si-O;PET;SPECT;Tc;Tl;blood sampling system;monkey;rat;sensitivity;Animals;Assembly systems;Blood;Detectors;Monitoring;Photonic crystals;Positron emission tomography;Sampling methods;Single photon emission computed tomography;System testing},
}

@InProceedings{Jang2006,
  author    = {S. h. Jang and J. w. Kim and S. k. Shin},
  title     = {API Automation Test with API Relation Diagram},
  booktitle = {2006 International Conference on Hybrid Information Technology},
  year      = {2006},
  volume    = {2},
  pages     = {175-177},
  month     = {Nov},
  abstract  = {The automation test is a useful method for test the standard platform that is equipped with APIs (application program interface) that observe the standard. But their test case codes use APIs that is the test target. And that is the reason that test of APIs can not be realized more efficient and more trust than now. We suggest API relation diagram that shows the dependency of the result of APIs execution. That prevents the incorrect decisions from the bad APIs in test cases and the code of test case is simpler because consideration about the bed API exception is needless. Keyword: API, Automation test.},
  doi       = {10.1109/ICHIT.2006.253608},
  keywords  = {Automatic testing;Automation;Embedded software;Embedded system;Life testing;Microprogramming;Monitoring;Software testing;System testing;Telecommunication standards},
}

@InProceedings{Gondokaryono2011,
  author    = {Y. S. Gondokaryono and Y. Bandung and J. A. Wibowo and A. A. Nugraha and B. Yonathan and D. Ramadhianto},
  title     = {Performance evaluation of audio-video streaming service in Keerom, Papua using integrated audio-video performance test tool},
  booktitle = {2011 6th International Conference on Telecommunication Systems, Services, and Applications (TSSA)},
  year      = {2011},
  pages     = {145-148},
  month     = {Oct},
  abstract  = {This study compared some video codec, audio codec, audio bit rate, video bit rate to determine the quality of the audio-video streaming service on the network Keerom, Papua. Average capacity in this network is 1.5Mbps. Mpeg audio and ac3 are choosen because of its characteristic, while the video codec is mpeg4 and H.264. Audio bit rate used 64 and 128kbps, while the video bit rate 64, 128 and 256kbps. The experiments result show the quality of the audio-video streaming service was better when the audio codec used mpeg audio 64kbps-mpeg4 256kbps. The test results will be used as a reference implementation of audio-video streaming service later in the network Keerom, Papua.},
  doi       = {10.1109/TSSA.2011.6095423},
  keywords  = {audio coding;audio streaming;video codecs;video coding;video streaming;AC3;H.264;Mpeg audio;Mpeg4;audio bit rate;audio codec;audio-video streaming service;bit rate 1.5 Mbit/s;bit rate 128 kbit/s;bit rate 256 kbit/s;bit rate 64 kbit/s;integrated audio-video performance test tool;performance evaluation;video bit rate;video codec;Bit rate;MPEG 4 Standard;PSNR;Streaming media;Transform coding;Video codecs;PESQ;PSNR;performance;streaming;test tool},
}

@InProceedings{Fan2015,
  author    = {J. Fan and W. He and C. Hendricks and M. Pecht and K. C. Yung},
  title     = {A practical design of reliability and performance test for portable lithium-ion batteries},
  booktitle = {2015 IEEE International Conference on Information and Automation},
  year      = {2015},
  pages     = {142-147},
  month     = {Aug},
  abstract  = {Lithium-ion batteries are increasingly used in industry as an energy storage system for applications ranging from portable electronics to high-energy electric vehicle systems. Their reliability and performance in the field can be affected by variations in environmental and loading conditions. Performance characterization testing provides health and performance features that can be used to assess a battery's performance and reliability under a variety of field environments and usage conditions. This paper presents and discusses the performance characterization tests for lithium-ion batteries in portable electronic applications. A case study is also presented where beginning, operational, and end-of-life characterization tests are performed.},
  doi       = {10.1109/ICInfA.2015.7279274},
  keywords  = {electric vehicles;reliability;secondary cells;end-of-life characterization test;energy storage system;high-energy electric vehicle system;portable electronic;portable lithium-ion battery reliability;Batteries;Degradation;Discharges (electric);Impedance;Resistance;Temperature measurement;Testing;Lithium-ion;performance testing;reliability;state of charge},
}

@InProceedings{Wang2010,
  author    = {Z. Wang and L. Xu and Z. Wang and H. Zhao and R. Song and W. Lou},
  title     = {Framework of MEMS high accelerated stress test},
  booktitle = {2010 IEEE 5th International Conference on Nano/Micro Engineered and Molecular Systems},
  year      = {2010},
  pages     = {280-283},
  month     = {Jan},
  abstract  = {Given the reliability principles and failure mechanism of MEMS, this paper discussed the accelerated test from three aspects as follows: the connotation of the test including concept and meaning; the scope of application concerned with product levels for applicants in types of stress; test process includes the test objective determination, test stressing selection, the test profile designing, the implementation scheme determining, analysis and improvement measures.},
  doi       = {10.1109/NEMS.2010.5592211},
  keywords  = {failure analysis;micromechanical devices;reliability;stress analysis;MEMS;failure mechanism;reliability principle;test objective determination;test profile designing;test stressing selection;HAST;MEMS;reliability},
}

@InProceedings{Trommer2016,
  author    = {R. Trommer and P. Quednau and L. P. Schmidt},
  title     = {Application of selected performance test scenarios on multi-channel UHF receivers},
  booktitle = {2016 German Microwave Conference (GeMiC)},
  year      = {2016},
  pages     = {73-76},
  month     = {March},
  abstract  = {In a preceding paper a multi-channel test signal generator for UHF radar applications was presented. The present contribution shows the application of this generator to test the performance of multi-channel receivers in selected scenarios. Exemplary measurement results are presented showing the usable dynamic range and the maximum packet reception rate for a secondary surveillance radar receiver and a smart meter data collector. Furthermore the direction-of-arrival estimation precision and the source separation capabilities of the receivers are tested under various conditions.},
  doi       = {10.1109/GEMIC.2016.7461559},
  keywords  = {UHF devices;direction-of-arrival estimation;radar receivers;search radar;signal generators;smart meters;source separation;UHF radar applications;direction-of-arrival estimation precision;maximum packet reception rate;multichannel UHF receivers;multichannel test signal generator;secondary surveillance radar receiver;selected performance test scenarios;smart meter data collector;source separation capabilities;usable dynamic range;Antenna arrays;Direction-of-arrival estimation;Estimation error;Radar;Receivers;Sensitivity;Signal generators},
}

@InProceedings{Liu2014b,
  author    = {Z. Liu},
  title     = {Research of performance test technology for big data applications},
  booktitle = {2014 IEEE International Conference on Information and Automation (ICIA)},
  year      = {2014},
  pages     = {53-58},
  month     = {July},
  abstract  = {This paper studies the performance test in big data application. The existing performance testing technology is not suitable for the big data application. The paper proposed test technology for performance testing. The technology provided test goal analysis, test design, load design for big data application. The character for different application could be supported to consider specific multiple test data design method under this framework. The performance technology is used to test some applications and proved effective.},
  doi       = {10.1109/ICInfA.2014.6932625},
  keywords  = {Big Data;program testing;software performance evaluation;big data application;load design;multiple test data design method;performance testing technology;test goal analysis;Big data;Business;Data models;Monitoring;Servers;Testing;Time factors;Big Data;Performance Test;Software Test},
}

@InProceedings{Du2011,
  author    = {Y. Du and Z. Xiao},
  title     = {Management information system for shock absorber performance test},
  booktitle = {2011 International Conference on Electronics, Communications and Control (ICECC)},
  year      = {2011},
  pages     = {2123-2126},
  month     = {Sept},
  abstract  = {Management information system for shock absorber performance test consolidates isolated islands of information separated in different application systems. It integrates such functions as product, manufacture process and quality control information management, remote monitoring, data statistics and reporting, and centralized data management. Combined B/S and C/S structure are realized in the system. Detail information and UIs of web service, damp tester, real-time monitoring and reporting sub-systems are given. The application of such a system can greatly improve the quality and productivity, thus enhance the competitiveness of shock absorber manufacturers.},
  doi       = {10.1109/ICECC.2011.6067637},
  keywords  = {Web services;management information systems;process monitoring;production engineering computing;production testing;quality control;shock absorbers;statistics;Web service;centralized data management;damp tester;data statistics;management information system;manufacture process;quality control information management;real time monitoring;remote monitoring;shock absorber manufacturers;shock absorber performance test;Educational institutions;Helium;Industrial control;Information systems;Motorcycles;Shock absorbers;Testing;management information system;performance testing;shock absorber},
}

@Article{Wen2009a,
  author   = {H. Wen and W. Bailey and K. Goddard and M. Al-Mosawi and C. Beduz and Y. Yang},
  title    = {Performance Test of a 100 kW HTS Generator Operating at 67 K #x2013;77 K},
  journal  = {IEEE Transactions on Applied Superconductivity},
  year     = {2009},
  volume   = {19},
  number   = {3},
  pages    = {1652-1655},
  month    = {June},
  issn     = {1051-8223},
  abstract = {A systematic test program is in progress to fully characterize a 100 kW HTS synchronous generator which was successfully constructed in 2004. The machine was one of the first HTS synchronous generator/motors to operate at liquid nitrogen temperatures while achieving a power rating relevant to practical application. It has a conventional 3-phase stator and a cold rotor with a magnetic core and a superconducting winding consisting of 10 HTS Bi2223 pancake coils separated by magnetic flux diverters. The test program includes a series of tests at various speeds, field currents and temperatures (65 K-77 K) with the machine in open circuit to determine the critical currents of the HTS rotor, the waveform and harmonic characteristics of generated voltage at different levels of iron saturation. Stationary measurements of the rotor critical current are carried out using dc current in the stator windings to quantify the influence of stator field on the performance of the superconducting winding. The voltages and temperatures of the rotor are measured using a radio frequency telemetry system.},
  doi      = {10.1109/TASC.2009.2017832},
  keywords = {bismuth compounds;high-temperature superconductors;machine windings;superconducting machines;synchronous generators;Bi2223 pancake coils;BiSr2CanCun+1O2n+6-d;cold rotor;high-temperature superconducting generator;magnetic core;magnetic flux diverter;power 100 kW;superconducting winding consisting;synchronous generator;temperature 67 K to 77 K;three phase stator;BSCCO coils;HTS motor;high temperature superconducting generator;rotating superconducting machine},
}

@InProceedings{Chunye2017a,
  author    = {D. Chunye and S. Wei and W. Jianhua},
  title     = {Based on the analysis of mobile terminal application software performance test},
  booktitle = {2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)},
  year      = {2017},
  pages     = {391-395},
  month     = {June},
  abstract  = {With the rapid development of mobile terminal, mobile applications are gradually penetrated into all aspects of people's life and work. Mobile games, mobile streaming media, location services, mobile Internet news, instant messaging, mobile music and other rich and colorful information era are changing the social life. In view of this, we propose the application software performance test based on the mobile terminal, and analyze the performance test technology and method of the mobile application. Experimental results show that the performance test of the application system can predict the pressure in real environment, the system will be applied in the problems exposed, through the analysis of the data of the test, it will provide help for performance optimization of application system.},
  doi       = {10.1109/SNPD.2017.8022751},
  keywords  = {mobile computing;program testing;information era;instant messaging;location services;mobile Internet news;mobile games;mobile music;mobile streaming media;mobile terminal application software;software performance test;LoadRunner;Mobile application;Mobile terminal;Performance test;Test method;Test technology},
}

@InProceedings{Lee2013,
  author    = {H. Y. Lee and J. A. Jeon and S. K. Yang and J. Lee and I. H. Park},
  title     = {Fabrication of Silicon-Photomultiplier multi arrays and the performance test},
  booktitle = {2013 IEEE Nuclear Science Symposium and Medical Imaging Conference (2013 NSS/MIC)},
  year      = {2013},
  pages     = {1-2},
  month     = {Oct},
  abstract  = {SiPM (Silicon Photomultiplier) is a semiconductor light diode comprised of many micropixels. Due to its positive characteristics, SiPM is considered as the next generation model of silicon photo amplifier. A photo-sensor made by multi arrays of SiPM sensors can even takes an image at the environment of old(dark) moon. Array of SiPMs with a minimum gap between the sensors is needed for some applications where a fine imaging of sources with low intensity radiations is required. We have attempted to fabricate SiPM sensors in various forms of arrays from the lithographic process in order to apply them in imaging astrophysical objects with low intensity. In the first process of the fabrication, we have produced various sizes of single SiPM sensors and also the arrays. The design includes unit sensors in the size of 0.5mm × 0.5mm, consisting of 103 micropixles with the maximum geometric efficiency of 70%. One of the arrays produced is 8 × 8 matrix of the unit sensors with the sensors gap of 60 um. We have tested the sensor arrays for the electrical characteristics and the dark rates. Details in the sensor and array design, the fabrication procedure, and the results of the performance test with the output from the first production are presented.},
  doi       = {10.1109/NSSMIC.2013.6829673},
  issn      = {1082-3654},
  keywords  = {amplifiers;elemental semiconductors;lithography;optical fabrication;photodetectors;photomultipliers;sensor arrays;silicon;Si;SiPM sensors;astrophysical object imaging;dark rates;electrical characteristics;lithographic process;next generation model;photosensor fabrication;semiconductor light diode;silicon photoamplifier;silicon photomultiplier multiarray fabrication;size 0.5 mm;Fabrication;Image sensors;Photonics;Sensor arrays;Sensor phenomena and characterization;Silicon},
}

@InProceedings{Sucar1989,
  author    = {H. Sucar and S. J. Chandra and D. J. Wharton},
  title     = {High performance test generation for accurate defect models in CMOS gate array technology},
  booktitle = {1989 IEEE International Conference on Computer-Aided Design. Digest of Technical Papers},
  year      = {1989},
  pages     = {166-169},
  month     = {Nov},
  abstract  = {A brief description is given of the CrossCheck test technology which provides the fundamental basis for this work. The authors present a practical analysis of transistor-level defects which result in accurate defect models in comparison to conventional fault models. The embedded test technology and accurate defect models are combined to form a high-quality test environment which is used to implement a high-performance test generation system. The authors present results on five ISCAS sequential benchmark circuits and two real designs. These results indicate that, in the presence of the embedded test electronics, test generation and fault simulation are considerably faster and test quality is substantially improved.<>},
  doi       = {10.1109/ICCAD.1989.76928},
  keywords  = {CMOS integrated circuits;automatic testing;fault location;logic arrays;logic testing;sequential circuits;CMOS gate array technology;CrossCheck test technology;ISCAS sequential benchmark circuits;defect models;embedded test technology;fault simulation;test generation;transistor-level defects;Application specific integrated circuits;Automatic testing;CMOS technology;Circuit faults;Circuit testing;Computational modeling;Costs;Electronic equipment testing;Semiconductor device modeling;System testing},
}

@InProceedings{Yuhui2010,
  author    = {W. Yuhui and L. Xiaohui and J. Yunzhong and S. Xinshan},
  title     = {Parallelization and Performance Test to Multiple Objective Particle Swarm Optimization Algorithm},
  booktitle = {2010 International Forum on Information Technology and Applications},
  year      = {2010},
  volume    = {1},
  pages     = {216-223},
  month     = {July},
  abstract  = {In recent years, Model calibration and parameter estimation with high complexity is a common problem in many areas of researches, especially in environmental modeling. This paper proposes a comparatively simple technique on the parallel implement of Multi-objective Particle Swarm Optimization algorithm (MOPSO). The transformation of the sequential objective evaluation in the MOPSO is based on the Matlab parallel computing tool box. Two study cases of different complexity demonstrate that the parallel implementation resulted in a considerable time saving. The deviation of computational time indicates that MOPSO has the characteristic of randomness because of the crowding distance and the dominant ranking. The proposed parallel MOPSO therefore, provides an ideal means to solve global optimization problems that are comparatively with high complexity.},
  doi       = {10.1109/IFITA.2010.109},
  keywords  = {calibration;parallel processing;particle swarm optimisation;performance evaluation;Matlab;dominant ranking;global optimization problems;model calibration;multiple objective particle swarm optimization;parallel computing tool box;parallelization;parameter estimation;performance test;sequential objective evaluation;Algorithm design and analysis;Calibration;Complexity theory;Computational modeling;Mathematical model;Optimization;Program processors;MOPSO;Pareto front;Xinanjiang model;multi-processor;parallel},
}

@InProceedings{Kang2017,
  author    = {P. Z. Kang and T. Y. Yew and K. W. Shih and M. H. Hsieh and W. S. Chou and C. M. Fu and Y. C. Huang and W. Wang and Y. C. Peng and Y. H. Lee},
  title     = {A novel on-die GHz AC stress test methodology for high speed IO application},
  booktitle = {2017 IEEE International Reliability Physics Symposium (IRPS)},
  year      = {2017},
  pages     = {4C-3.1-4C-3.5},
  month     = {April},
  abstract  = {A new methodology and test circuit for evaluation of device reliability are presented. The stress conditions must emulate the real circuit operation, or similar to product-like environment. Existing methodology might not archive this purpose. In this paper, an on-die wave front generator was established in circuit level. Experiments in this study cover from mechanisms of off state, Bias Temperature Instability (BTI) and Hot Carrier Injection (HCI). Based on the extensive results, strong dependence of reliability to layout effect can be concluded. And the reliability guidelines and recommendations for high speed IO circuit design can be made.},
  doi       = {10.1109/IRPS.2017.7936314},
  keywords  = {high-speed integrated circuits;hot carriers;integrated circuit layout;semiconductor device reliability;semiconductor device testing;stress effects;BTI;HCI;bias temperature instability;device reliability evaluation;high speed IO circuit design;hot carrier injection;layout effect;on-die GHz AC stress test methodology;on-die wave front generator;stress conditions;test circuit;Clocks;Degradation;Human computer interaction;Integrated circuit reliability;Logic gates;Stress;AC Stress;BTI;HCI;High Speed IO Application;Off-State},
}

@InProceedings{Chengqing2007,
  author    = {Y. Chengqing and W. Yinglong and W. Jizhi},
  title     = {A IPv6 Network Performance Test System using Multi-Agent},
  booktitle = {2007 8th International Conference on Electronic Measurement and Instruments},
  year      = {2007},
  pages     = {2-113-2-118},
  month     = {Aug},
  abstract  = {The Internet Engineering Task Force (IETF) has introduced IPv6 with a mission to meet the growing demands of the future Internet. IPv6 is more and more emphasized and moving from the pilot phase to the practical application. In the process of deploying IPv6, performance is one of the key issues to be considered. Test is an effective method to understand IPv6 network performance. We need scalable and available tools to measure IPv6 network performance, but the few existing network performance test software support IPv6. So through the introduction of multi-agent technology, a distributed IPv6 network performance test model integrated with centralized control is proposed. We describe architecture and workflow of the model thoroughly, and a IPv6 network performance test system is designed and implemented based on the model. Finally, using our system, we measure IPv6 performance metrics on CERNET2 which is the largest pure IPv6 network in the world presently. The final experiments show that it is necessary to implement a IPv6 network performance test system and that our system is scalable and available for IPv6 network performance test.},
  doi       = {10.1109/ICEMI.2007.4350633},
  keywords  = {IP networks;multi-agent systems;performance evaluation;CERNET2;IPv6 network performance;IPv6 performance metrics;Internet Engineering Task Force;multiagent;software support;Application software;Electronic equipment testing;IP networks;Instruments;Internet;Measurement;Performance analysis;Protocols;System testing;Throughput;IPv6;agent;multi-agent;network performance test},
}

@InProceedings{Malik2010b,
  author    = {H. Malik and B. Adams and A. E. Hassan},
  title     = {Pinpointing the Subsystems Responsible for the Performance Deviations in a Load Test},
  booktitle = {2010 IEEE 21st International Symposium on Software Reliability Engineering},
  year      = {2010},
  pages     = {201-210},
  month     = {Nov},
  abstract  = {Large scale systems (LSS) contain multiple subsystems that interact across multiple nodes in sometimes unforeseen and complicated ways. As a result, pinpointing the subsystems that are the source of performance degradation for a load test in LSS can be frustrating, and might take several hours or even days. This is due to the large volume of performance counter data collected such as CPU utilization, Disk I/O, memory consumption and network traffic, the limited operational knowledge of analysts about all subsystems of an LSS and the unavailability of up-to-date documentation in a LSS. We have developed a methodology that automatically ranks the subsystems according to the deviation of their performance in a load test. Our methodology uses performance counter data of a load test to craft performance signatures for the LSS subsystems. Pair-wise correlations among the performance signatures of subsystems within a load test are compared with the corresponding correlations in a baseline test to pinpoint the subsystems responsible for the performance violations. Case studies on load test data obtained from a large telecom system and that of an open source benchmark application show that our approach provides an accuracy of 79% and do not require any instrumentation or domain knowledge to operate.},
  doi       = {10.1109/ISSRE.2010.43},
  issn      = {1071-9458},
  keywords  = {large-scale systems;performance evaluation;program testing;craft performance signature;domain knowledge;large scale system;load test;open source benchmark;operational knowledge;pair wise correlation;performance deviation;user performance counter data;Correlation;Databases;Generators;Principal component analysis;Radiation detectors;Servers;Testing;Load Testing;Performance Counters;Pinpointing},
}

@InProceedings{Jiang2011,
  author    = {D. Jiang and M. Fei and H. Wang and T. Li},
  title     = {Wireless network performance test in hybrid wired/wireless network system},
  booktitle = {2011 9th World Congress on Intelligent Control and Automation},
  year      = {2011},
  pages     = {1029-1034},
  month     = {June},
  abstract  = {Recently, considerable researches on wireless networks have been carried in industrial automation. A great deal of wireless control and monitoring systems are introduced in certain problematic parts of the process industry to improve the productivity and efficiency. However, the control and monitor application requires high standard performances, such as reliability, real-timing and accuracy. Therefore a comprehensive performance assessment is needed to test the property of the wireless network so as to optimize the network protocol and improve the network communication quality. This paper studies the wireless network in the integrated wired/wireless fieldbus system and proposes a method to acquire a set of key indicators of wireless networks. Then, a test device is designed to acquire the performance indicators of the system. The wireless protocols are analysed according to the performance indicators. The results show that the test for the performance of wireless networks can be realized by the method mentioned.},
  doi       = {10.1109/WCICA.2011.5970672},
  keywords  = {field buses;performance evaluation;protocols;radio networks;hybrid wired/wireless network system;network communication quality;network protocol;performance assessment;process industry;productivity improvement;wireless control system;wireless network performance test;wireless protocol;Computers;Control systems;Performance evaluation;Protocols;Real time systems;Wireless networks;IEEE802.15.4A;Performance indicators;Protocol conversion;hybrid Wired/wireless networks},
}

@InProceedings{Quan2010,
  author    = {X. Quan and L. Lu},
  title     = {Session-based performance test case generation for Web applications},
  booktitle = {2010 8th International Conference on Supply Chain Management and Information},
  year      = {2010},
  pages     = {1-7},
  month     = {Oct},
  abstract  = {There are many techniques and tools for Web application testing, but few of these address the procedure for gathering user session data accessed in a production environment to assist in testing Web application performance. In this paper, we present a session-based approach to automatically generate performance test cases by exploiting user session information taken from server logs. Such test cases are used for generating synthetic workload to evaluate performance. This paper illustrates the prototype implementation of our session-based performance test case generation approach.},
  keywords  = {Internet;program testing;Web application testing;server logs;session-based performance test case generation;user session information;Classification algorithms;Classification tree analysis;Entropy;Servers;Testing;Training;Web applications;decision tree;performance test;user session},
}

@InProceedings{Plitschka1989,
  author    = {R. Plitschka},
  title     = {How to treat transmission line effects when testing high speed devices with a high performance test system},
  booktitle = {[1989] Proceedings of the 1st European Test Conference},
  year      = {1989},
  pages     = {78-85},
  month     = {Apr},
  abstract  = {State-of-the-art digital ASICs have even faster clock rates and signal transition times; testing these devices may cause problems regarding delivering the signals to the device under test (DUT) and precisely measuring the response of the DUT. Transmission-line techniques have to be applied to the tester-to-DUT interconnection in order to maintain signal fidelity. The author illustrates how to implement this critical signal path in a high-speed test system to get high-precision timing and level measurements, particularly for CMOS devices. The solution suggested to embed a CMOS device in a transmission-line environment is the resistive divider. The operating principle of the resistive divider is to apply a definable DC load to the DUT. This maintains signal fidelity, as the signal is fed into a parallel terminated system. Therefore no reflections occur},
  doi       = {10.1109/ETC.1989.36223},
  keywords  = {CMOS integrated circuits;application specific integrated circuits;automatic test equipment;automatic testing;digital integrated circuits;integrated circuit testing;CMOS devices;DC load;DUT;critical signal path;digital ASIC;digital ASICs;high performance test system;high speed devices;high-precision timing;high-speed test system;resistive divider;response;transmission line effects;Circuit testing;Coaxial components;Delay effects;Electronic equipment testing;Impedance;Integrated circuit interconnections;Low pass filters;Microstrip;System testing;Transmission lines},
}

@InProceedings{Wu2010,
  author    = {P. Wu and B. Wu},
  title     = {Performance Test of Network Simulation Based on Split-Object Model},
  booktitle = {2010 International Forum on Information Technology and Applications},
  year      = {2010},
  volume    = {1},
  pages     = {189-192},
  month     = {July},
  abstract  = {The network simulation (NS) is an important issue in the study of network technology. However, The error between the network performance simulation on split-object model and the true network environment is considerable apparent. In order to obtain the NS result approaching the reality, in this paper, we analyze the structure of split-object mode and find reasons to cause the error. According to the definition of NS performance's index, we remodel the split-object model by choosing the proper function and equation in the control theory and deducing the logical coefficent in them. We further evaluate the efficiency and the availability of the new model under NS-2 platform. The results show that the new mode is more suitable for network simulation with higher accuracy.},
  doi       = {10.1109/IFITA.2010.10},
  keywords  = {computer network performance evaluation;mathematical analysis;NS performance index;NS-2 platform;control theory;logical coefficent;network simulation;network technology;performance test;split object model;true network environment;Analytical models;Computational modeling;Data models;Hardware;Indexes;Mathematical model;Runtime;mathematical analysis;network simulation;performance test;split-object model},
}

@InProceedings{Tada2017,
  author    = {K. Tada and A. Satake and K. Hashimura and Y. Ogashi and H. Masuda and T. Oka},
  title     = {Study of full load test method for large VSDS driven by non-regenerative VSI},
  booktitle = {2017 Petroleum and Chemical Industry Conference Europe (PCIC Europe)},
  year      = {2017},
  pages     = {1-9},
  month     = {May},
  abstract  = {Full load back-to-back test of VSDS's (Variable Speed Drive Systems) are sometimes required for oil and gas projects. VSI (Voltage Source Inverter) technology is becoming the drive system of choice for super large compressor drives, up to 100 MW. Special consideration /facilities are necessary to perform back-to- back tests for VSDS driven by VSI, because the type of converter used for such large VSI's is usually a diode rectifier without regenerative capability. To realize a back-to-back test for this type of VSDS, a VSI with regenerative converter, (usually adopting PWM converter topology), is necessary. But it is a heavy burden to prepare such super large VSI with regeneration capability purely as a test facility. This paper proposes a test method to increase the load test capacity of a back-to-back test facility up to two times the regenerative converter capacity. This idea is to apply a VSI with regenerative converter as a soft starter during start-up of back-to-back connected motor and generator system and as a constant voltage and constant frequency power supply during testing of VSDS. The proposed test facility is configured by direct connection of the load machine output to the input transformer of tested VSDS to circulate the load power directly. Only loss power and reactive power is supplied by VSI with regenerative converter.},
  doi       = {10.23919/PCICEurope.2017.8015057},
  keywords  = {PWM power convertors;starting;variable speed drives;voltage-source convertors;PWM converter topology;VSDS;VSI technology;back-to-back connected motor;constant frequency power supply;constant voltage power supply;diode rectifier;full load back-to-back test;generator system;load test capacity;loss power;reactive power;regenerative capability;regenerative converter;soft starter;super large compressor drives;variable speed drive systems;voltage source inverter technology;Generators;Inverters;Load modeling;Power supplies;Rectifiers;Synchronous motors;Test facilities},
}

@InProceedings{Li2013a,
  author    = {S. Li and X. Li and Y. Wu and K. Zhang},
  title     = {A Research on Comprehensive Performance Test System of High-Speed Motorized Spindle},
  booktitle = {2013 Third International Conference on Instrumentation, Measurement, Computer, Communication and Control},
  year      = {2013},
  pages     = {613-617},
  month     = {Sept},
  abstract  = {In order to produce the motorized spindle unit with high quality and performance and further improve its level of design and produce, a comprehensive performance test system for high-speed motorized spindle is built successfully, it can analyze the load characteristics, temperature rise, vibration, noise, accuracy and rigidity of high-speed motorized spindle unit in different working conditions. Experiments of above characteristics were also completed for a full-ceramic motorized spindle, and a series of results were attained, it supplies technical support to enhance its comprehensive performance and the manufacture technical level.},
  doi       = {10.1109/IMCCC.2013.137},
  keywords  = {ceramics;electric motors;machine bearings;machine testing;machine tool spindles;mechanical testing;shear modulus;comprehensive performance test system;full-ceramic motorized spindle;high-speed motorized spindle unit;manufacture technical level;rigidity;Accuracy;Ceramics;Lubrication;Noise;Temperature measurement;Temperature sensors;Vibrations;comprehensive performance test system;high-speed motorized spindle;temperature rise experiment;vibration experiment},
}

@InProceedings{Xin2011,
  author    = {Zhang Xin and Cai Ling},
  title     = {Study of integrative performance test system for the automobile engine control unit},
  booktitle = {2011 International Conference on Electric Information and Control Engineering},
  year      = {2011},
  pages     = {4495-4498},
  month     = {April},
  abstract  = {Aiming at the control complex of automobile engine control unit (ECU), a test system of the automobile engine control unit was designed . The system is composed of the input signal simulate module, measurement and control module, signal collection and disposal module, communication module etc. By means of simulating the signal of sensors, such as the crankshaft position sensor, the throttle position sensor, and the air temperature sensor, the engine operation environment and the real time condition were simulated and tested. The collected signal of the fuel injection and the ignition signal were analyzed. The development and testing of engine ECU were facilitated.},
  doi       = {10.1109/ICEICE.2011.5777060},
  keywords  = {automobiles;internal combustion engines;air temperature sensor;automobile engine control unit;communication module;control module;crankshaft position sensor;disposal module;engine operation environment;fuel injection;ignition signal;integrative performance test system;signal collection;throttle position sensor;Automobiles;Internal combustion engines;Motorcycles;Sensor systems;Temperature sensors;data collecting;engine ECU;performance test;sensor simulation},
}

@InProceedings{Wang2017,
  author    = {Y. Wang and L. Zhu and H. Zhao},
  title     = {Handover performance test and analysis in TD-LTE based CBTC train ground communication systems},
  booktitle = {2017 Chinese Automation Congress (CAC)},
  year      = {2017},
  pages     = {3655-3660},
  month     = {Oct},
  abstract  = {Most of the existing urban rail CBTC train ground communication systems are based on Wireless Local Networks (WLAN) technologies. With frequency interference and the increase of train speed, WLAN is incapable of meeting the requirements of CBTC train ground communication systems. Time Division-Long Term Evolution (TD-LTE) technology begins to be considered in urban rail transit systems. In this paper, we first design a TD-LTE based urban rail CBTC train ground communication systems, the handover procedure and handover requirements according to CBTC system principle are analyzed next. For verifing whether the designed TD-LTE based system meet the handover performance demands when trains travel in high speed CBTC systems, a laboratory test environment and a real field test environment are set up. Massive test results show that the handover performance of TD-LTE based urban rail CBTC train ground communication systems meets the demands of urban rail transit systems.},
  doi       = {10.1109/CAC.2017.8243415},
  keywords  = {Long Term Evolution;mobility management (mobile radio);railway communication;time division multiplexing;wireless LAN;CBTC system principle;CBTC train ground communication systems;TD-LTE based urban rail CBTC train ground communication systems;Time Division-Long Term Evolution technology;Wireless Local Networks technologies;handover procedure;handover requirements;high speed CBTC systems;train speed;urban rail transit systems;Handover;Long Term Evolution;Rails;Wireless LAN;Wireless communication;CBTC;TD-LTE;handover;train ground communication},
}

@InProceedings{Wang2015a,
  author    = {H. Wang and J. Hu and L. Gao},
  title     = {Design and performance test of a test rig for grain flow sensor},
  booktitle = {2015 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)},
  year      = {2015},
  pages     = {1442-1445},
  month     = {June},
  abstract  = {In order to develop a grain flow sensor, a test rig was built. Three weighting sensors were mounted on the weighting bin in the test rig to calibrate grain flow sensor and verify the accuracy of grain flow sensor. A valve plate was inserted in the bottom of the feed bin. The feed flow could be controlled by adjusting opening of the valve plate. A weighting measurement model and a feed flow model were established respectively according to user manual and calibration experiments. Weighting accuracy and feed rate for the test rig was analyzed through experiments. Results showed that the maximum relative error of weighting was 1.12%, the minimum relative error was 0.36%, and the average relative error was 0.61%. The average relative error of feed flow ranging from 0.5 to 2.4 kg/s was less than 4%. The test rig developed is stable and reliable, and meets the requirements for development and testing of the grain flow sensor.},
  doi       = {10.1109/CYBER.2015.7288156},
  keywords  = {agriculture;calibration;crops;design engineering;flow sensors;precision engineering;test equipment;calibration;design;grain flow sensors;performance testing;test rig;weighting sensors;Accuracy;Calibration;Elevators;Feeds;Monitoring;Valves;Weight measurement;grain flow sensor;performance test;precision farming;test rigs},
}

@InProceedings{Matthys2002,
  author    = {K. Matthys and D. Vanhercke and S. Van Aken and K. De Groote and I. Coomans and P. Verdonck},
  title     = {Non-invasive assessment of hemodynamics in adolescents with arterial tonometry and Doppler ultrasound during a conventional stress test},
  booktitle = {Computers in Cardiology},
  year      = {2002},
  pages     = {517-520},
  month     = {Sept},
  abstract  = {Aiming to improve early diagnosis of people at cardiovascular risk, we are developing a custom set-up to allow an adequate hemodynamic analysis of heart function and arterial circulation properties, based on non-invasive acquisition of pressure (arterial tonometry) and flow (Doppler ultrasound techniques) waveforms. In an experimental setting 15 healthy volunteers were examined on a custom made supine bicycle. Able to record usable data throughout the bicycle test and automatically analyse derived hemodynamic parameters such as compliance, peripheral resistance, etc., we also applied the set-up in a real clinical environment. This research contributes to a more complete cardiovascular examination without significant additional discomfort for the patient or prolongation of the test protocol.},
  doi       = {10.1109/CIC.2002.1166823},
  issn      = {0276-6547},
  keywords  = {biomedical ultrasonics;blood flow measurement;blood pressure measurement;blood vessels;cardiovascular system;medical signal processing;Doppler ultrasound;adolescents;arterial circulation properties;arterial tonometry;automatic analysis;cardiovascular risk;clinical environment;compliance;data recording;diagnosis;healthy volunteers;heart function;noninvasive flow waveform acquisition;noninvasive hemodynamics assessment;noninvasive pressure waveform acquisition;peripheral resistance;stress test;supine bicycle;Bicycles;Cardiology;Heart;Hemodynamics;Hospitals;Laboratories;Probes;Stress;Testing;Ultrasonic imaging},
}

@InProceedings{Zhaohui2014,
  author    = {H. Zhaohui and L. Jixun and Y. Liu},
  title     = {Research on Anti-jamming Performance Test Planning of Active Radar Guided Air-to-Air Missile},
  booktitle = {2014 Seventh International Symposium on Computational Intelligence and Design},
  year      = {2014},
  volume    = {1},
  pages     = {15-17},
  month     = {Dec},
  abstract  = {With the air fight environment getting more and more complex, the anti-jamming performance of active radar guided air-to-air missile (ARGAAM) is noticed by all countries worldwide. This paper develops a new method to plan the anti-jamming performance test for ARGAAM characteristic. The method plans the missile anti-jamming performance test by flight test and digital simulation. Finally, the anti-jamming performance of ARGAAM is evaluated by example.},
  doi       = {10.1109/ISCID.2014.10},
  keywords  = {aerospace testing;interference suppression;jamming;missiles;radar interference;ARGAAM characteristics;active radar guided air-to-air missile;air fight environment;antijamming performance flight test planning;digital simulation;Atmospheric modeling;Data models;Global Positioning System;Jamming;Missiles;Performance evaluation;Planning;active radar guided air-to-air missile;anti-jamming performance;estimation;test planning},
}

@Article{Chen2018,
  author   = {T. Chen and F. Meng},
  title    = {Development and Performance Test of a Height-Adaptive Pesticide Spraying System},
  journal  = {IEEE Access},
  year     = {2018},
  volume   = {6},
  pages    = {12342-12350},
  abstract = {This paper investigate an adaptive pesticide spraying system according to the plants height. The system including a depth sensor and a spraying system with multiple nozzles at different height in vertical direction. The entire system is installed on an automatic guided vehicle. In order to implement precision spraying or automatic targeting, plant identification, and plant height calculation are critical for the system with fixed height of nozzles. The designed system will open one or combination of the nozzles of the spraying system since the plant height is identified. To address the plant height-adaptive challenge, a pesticide spraying system with plant height-adaptive is proposed based on a camera sensor to dealt with the figure of the plant. Both of the depth and color data of the figure are obtained and analyzed, the open or close state of the spraying system is optimized for different plants with different height. Various experimental results have demonstrated that the proposed system is considered as well.},
  doi      = {10.1109/ACCESS.2018.2813667},
  keywords = {agrochemicals;automatic guided vehicles;cameras;image sensors;nozzles;robot vision;spraying;sprays;automatic targeting plant identification;fixed height;height-adaptive pesticide spraying system;nozzles;plant height calculation;plant height-adaptive challenge;precision spraying;Acoustics;Cameras;Colored noise;Data processing;Image color analysis;Robot sensing systems;Spraying;Automatic guided vehicle;depth sensor;height-adaptive;precision spraying;signal processing},
}

@InProceedings{Yuanlou2010,
  author    = {G. Yuanlou and F. Xiaoxing},
  title     = {A Research on the Torque Converter Performance Test-Bed Control System},
  booktitle = {2010 International Conference on Electrical and Control Engineering},
  year      = {2010},
  pages     = {3224-3226},
  month     = {June},
  abstract  = {According to the characteristics of test bed, using a motor driven program based on inverter with a speed sensor, and an eddy current dynamometer constant torsional loading scheme, it implements the stability of constant speed drive and torsional load for the torque converter test-bed, providing a good test environment for the performance test. This method is economical and practical, energy saving and environmental protective. The constant voltage-frequency ratio of frequency control method is applied in motor speed control, and a way of changing the excitation voltage to change the output torque of the eddy current dynamometer is used. The results show that the system achieve good control results.},
  doi       = {10.1109/iCECE.2010.787},
  keywords  = {drives;dynamometers;eddy currents;frequency control;invertors;machine control;stability;three-term control;torque convertors;velocity measurement;PID;constant speed drive stability;constant voltage-frequency ratio;eddy current dynamometer constant torsional loading scheme;excitation voltage;frequency control method;inverter;motor driven program;motor speed control;performance test;speed sensor;test-bed control system;torque converter;Automation;Control engineering;Eddy currents;Educational institutions;Torque converters;Voltage control;PID;eddy current dynamometer;hydraulic torque converter},
}

@InProceedings{Chae2012,
  author    = {Eunkyung Chae and Kangmi Lee and Kyung-hee Kim and Jaeho Lee},
  title     = {Performance test on radio communication device for train control system},
  booktitle = {2012 7th International Conference on Computing and Convergence Technology (ICCCT)},
  year      = {2012},
  pages     = {462-465},
  month     = {Dec},
  abstract  = {Train control system controls the headway and train route to prevent collisions and derailment of train on the basis of the train location. Radio communication based train control system can enhance the headway and safety of train in the manner of using radio communications instead of the wayside equipment such as the track circuit installed in the track. Radio communication based train control system uses the standard of IEEE 802.11 which uses an unlicensed frequency band because there is no dedicated frequency for railways. Since there is the risk where the frequency interference and other interference problems can be occurred because the unlicensed band might be used by various wireless devices, we analyzed wireless environments of Daebul Line which was selected as the test section, and in this paper, we measured the performance of radio communication device to be applied to the radio communication network and selected a optimized location which has no shaded area.},
  keywords  = {collision avoidance;radio equipment;rail traffic control;railway safety;wireless LAN;Daebul Line;IEEE 802.11standard;collision prevention;frequency interference;radio communication based train control system;radio communication device;radio communication network;train derailment prevention;train route control;unlicensed frequency band;wireless devices;Train control system;radio communications},
}

@InProceedings{Lee2007,
  author    = {Young-Ho Lee and Hae-Young Park and Eui-Cheol Nho and In-Dong Kim and Tae-Won Chun and Heung-Geun Kim and Nam-Sup Choi},
  title     = {Improved voltage disturbance generator for the performance test of the custom power devices},
  booktitle = {2007 International Conference on Electrical Machines and Systems (ICEMS)},
  year      = {2007},
  pages     = {175-179},
  month     = {Oct},
  abstract  = {An improved voltage disturbance generator is proposed. To test the performance of the custom power devices such as DVR, SSTS, dynamic UPS, etc., a voltage disturbance generator is necessary. The proposed generator has good features of high reliability, low cost, simple structure, high efficiency, and reduced voltage drop. The main switching device is SCR thyristor, and all the thyristors have natural commutation characteristics, which provides reliable system. The circuit analysis and operating principle of the proposed scheme are described in each mode of voltage sag, swell, outage, and unbalance. Simulation and experimental results show the usefulness of the proposed scheme.},
  keywords  = {network analysis;power supply quality;thyristors;SCR thyristor;circuit analysis;custom power devices;reduced voltage drop;reliability;voltage disturbance generator;Automation;Circuit simulation;Costs;Electronic equipment;Power generation;Switches;Testing;Thyristors;Uninterruptible power systems;Voltage fluctuations},
}

@InProceedings{Park1997,
  author    = {Jang-Hyun Park and Yea-Chul Rho},
  title     = {Performance test of Viterbi decoder for wideband CDMA system},
  booktitle = {Design Automation Conference, 1997. Proceedings of the ASP-DAC '97 Asia and South Pacific},
  year      = {1997},
  pages     = {19-23},
  month     = {Jan},
  abstract  = {This paper describes the design, the implementation, and the performance test of the Serial Viterbi decoder (SVD) using VHDL and FPGAs. The decoding scheme assumes the transmitted symbols were coded with a K=9, 32 Kbps, and rate 1/2 convolutional encoder with generator function g0=(753)8 and g1=(561)8 as defined in the JTC TAG-7 W-CDMA PCS standard. The SVD is designed using VHDL and implemented using FPGAs. The main algorithm is implemented in two Altera FLEX81500 FPGAs. The performance test results with 3DB Gaussian noise show that the SVD works well},
  doi       = {10.1109/ASPDAC.1997.600052},
  keywords  = {Gaussian noise;Viterbi decoding;broadband networks;code division multiple access;field programmable gate arrays;hardware description languages;logic CAD;telecommunication computing;telecommunication standards;testing;32 kbit/s;Altera FLEX81500;CDMA PCS standard;FPGA;Gaussian noise;Serial Viterbi decoder;VHDL;Viterbi decoder performance testing;convolutional encoder;decoding scheme;generator function;symbols;wideband CDMA system;Code standards;Convolutional codes;Decoding;Field programmable gate arrays;Gaussian noise;Multiaccess communication;Personal communication networks;System testing;Viterbi algorithm;Wideband},
}

@InProceedings{Tian2017,
  author    = {Y. Tian and J. Wei and M. Jiang and L. Zhang and F. Zhang and Q. Sui and W. Sun},
  title     = {Drive design and performance test of a tunable DFB laser},
  booktitle = {2017 Chinese Automation Congress (CAC)},
  year      = {2017},
  pages     = {4024-4027},
  month     = {Oct},
  abstract  = {In order to meet the requirements of TDLAS technology and to ensure the optical wavelength stability and the optical power stability of the laser light source, we design the DFB (distributed feedback) laser drive system using STM32 as the controller. The hardware circuit mainly includes drive current control circuit, constant temperature control circuit and laser optical power monitoring circuit. Then, the performance test of 1550nm DFB laser is carried out. Test condition is under the normal atmospheric temperature and ensuring constant control current. The test shows that the range of the laser output wavelength is 3pm and the optical power fluctuation is less than 0.005mW after preheating an hour. The stability of the optical wavelength and optical power is excellent.},
  doi       = {10.1109/CAC.2017.8243484},
  keywords  = {distributed feedback lasers;electric current control;laser beams;laser noise;laser stability;laser tuning;light sources;optical testing;semiconductor lasers;temperature control;DFB laser drive system;STM32;TDLAS technology;constant control current;constant temperature control circuit;distributed feedback;drive current control circuit;drive design;hardware circuit;laser light source;laser optical power monitoring circuit;laser output wavelength;normal atmospheric temperature;optical power fluctuation;optical power stability;optical wavelength stability;performance test;power 0.005 mW;test condition;tunable DFB laser;wavelength 1550.0 nm;wavelength 3.0 pm;Distributed feedback devices;Laser stability;Optical reflection;Power lasers;Semiconductor lasers;Temperature control;Constant current control;DFB Laser;Optical power stability;Optical wavelength stability;temperature control},
}

@InProceedings{Zhu2011,
  author    = {Xingwang Zhu and Xueli Nie and Yanli Lv and Fenying Guo and Yugui Su},
  title     = {Performance test of compound system for air conditioning and hot water},
  booktitle = {2011 International Conference on Materials for Renewable Energy Environment},
  year      = {2011},
  volume    = {2},
  pages     = {1153-1161},
  month     = {May},
  abstract  = {Air conditioning and hot water compound system in which air-cooling heat exchanger is connected with heat recovery heat exchanger in series is studied, system fundamentals and five running modes including single refrigerating mode, single heating mode, hot water mode, refrigerating and hot water mode and heating and hot water mode are introduced, and experimental research is developed. Experimental research on operation characteristics of refrigerating capacity, heating capacity and suction and discharge temperature and pressure show that the unit operates reliably long in different operation conditions and that the variation of characteristics is within a reasonable range. Coefficient of performance of the system in refrigerating and hot water mode and in heating and hot water mode is highest with the minimal value approximately 3.2 when the temperature of water tank climbs up to 55°C, as the service efficiency of the unit is improved by recovering the condenser heat to heat hot water. The system is avoided to operate in the region of maximum power, and had better operate in the variable flow region of capillary and large air volume and small temperature difference region as much as possible.},
  doi       = {10.1109/ICMREE.2011.5930543},
  keywords  = {air conditioning;cooling;heat exchangers;heat recovery;refrigeration;water;air conditioning;air cooling heat exchanger;coefficient of performance;compound system performance test;condenser heat recovery;discharge temperature;heat suction;heating capacity;hot water mode;hot water system;refrigeration capacity;single heating mode;single refrigerating mode;water tank;Discharges;Electromagnetic heating;Heat pumps;Heat recovery;Legged locomotion;Water heating;compound system for air conditioning and hot water;condenser heat recovery;energy-savingcomponent},
}

@InProceedings{Yongjie2017,
  author    = {F. Yongjie and C. Ying},
  title     = {Performance test of laser power meter verification system},
  booktitle = {2017 13th IEEE International Conference on Electronic Measurement Instruments (ICEMI)},
  year      = {2017},
  pages     = {132-135},
  month     = {Oct},
  abstract  = {Aimed at the requirements of laser equipment, a verification system of laser power meter is established. The system can realize the verification and calibration of laser power meter with wavelength of 532nm, 633nm, 1064nm and power measurement range of 0.1mW to 20W. The relative expanded uncertainty of the system reaches 2% (k=2). The composition and working principle of the system are described in detail. The test methods and measurement data are given for the main parameters of system performance test, such as power stability of laser, power monitoring ratio stability of laser power beam splitter monitoring and correcting device, correction factor of standard laser power meter. After the system test, the performance of the laser power meter verification system has been more perfectly examined.},
  doi       = {10.1109/ICEMI.2017.8265741},
  keywords  = {calibration;laser variables measurement;measurement uncertainty;optical beam splitters;optical testing;power measurement;power meters;calibration;laser equipment;laser power beam splitter monitoring;laser power correcting device;laser power meter verification system;power 0.1 mW to 20 W;power measurement;power monitoring ratio stability;system performance test;wavelength 1064.0 nm;wavelength 532.0 nm;wavelength 633.0 nm;Laser beams;Laser stability;Measurement by laser beam;Meters;Power lasers;Power measurement;Standards;Laser power meter;Optical metrology;Performance Test;Verification/Calibration},
}

@Article{Ruan2012,
  author   = {J. J. Ruan and N. Monnereau and D. Trémouilles and N. Mauran and F. Coccetti and N. Nolhier and R. Plana},
  title    = {An Accelerated Stress Test Method for Electrostatically Driven MEMS Devices},
  journal  = {IEEE Transactions on Instrumentation and Measurement},
  year     = {2012},
  volume   = {61},
  number   = {2},
  pages    = {456-461},
  month    = {Feb},
  issn     = {0018-9456},
  abstract = {This paper addresses an innovative solution to develop a circuit to perform accelerated stress tests of capacitive microelectromechanical-system (MEMS) switches and shows the use of instruments and equipment to monitor physical aging phenomena. A dedicated test circuit was designed and fabricated in order to meet the need for accelerated techniques for those structures. It integrated an in-house miniaturized circuit connected to additional test equipment (e.g., oscilloscopes and capacitance meters) that enabled the reliability characterization of capacitive switches. The accelerated stress test (AST) circuit generated an electrostatic-discharge-like impulse that stressed the device. This setup allowed the simultaneous measurement of the current and voltage waveforms, and the capacitance variation of the device under test after each stress. The results obtained using the miniature AST circuit were discussed and were correlated with results obtained using a commercial human-body-model tester as well as data from a cycling benchmark. The scope of this paper encompasses the theory, methodology, and practice of measurement; the development of a testing miniaturized board; and the analysis and representation of the information obtained from a set of measurements. As a result, it may contribute to the scientific and technical standards in the field of instrumentation and measurement of electrostactically actuated devices having insulating layers.},
  doi      = {10.1109/TIM.2011.2161937},
  keywords = {circuit reliability;circuit testing;electric current measurement;electrostatic discharge;life testing;microswitches;network synthesis;semiconductor device measurement;semiconductor device testing;test equipment;voltage measurement;MEMS switches;accelerated stress test circuit;accelerated stress test method;accelerated techniques;additional test equipment;capacitance variation;capacitive microelectromechanical-system switches;capacitive switches;current waveforms;cycling benchmark;device under test;electrostactically actuated devices;electrostatic-discharge-like impulse;electrostatically driven MEMS devices;human-body-model tester;in-house miniaturized circuit;innovative solution;insulating layers;miniature AST circuit;physical aging phenomena;reliability characterization;testing miniaturized board;voltage waveforms;Discharges;Life estimation;Micromechanical devices;Radio frequency;Reliability;Stress;Testing;Accelerated testing;charging;dielectric breakdown;electrostatic discharges (ESDs);microelectromechanical devices;reliability testing},
}

@InProceedings{Yamei2016,
  author    = {F. Yamei and L. Qing and H. Qi},
  title     = {Research and comparative analysis of performance test on SDN controller},
  booktitle = {2016 First IEEE International Conference on Computer Communication and the Internet (ICCCI)},
  year      = {2016},
  pages     = {207-210},
  month     = {Oct},
  abstract  = {The emergence of Software Defined Network(SDN) gives the demand of big data and network management a chance. SDN separates the control and forwarding in traditional network through OpenFlow protocol. In the software-defined network, SDN controller is an important integral part that is the core of SDN. In this paper, firstly we summarize the common SDN controller, and choose two popular, wider using open-source controllers(OpenDaylight and ONOS), analyze the implementation architecture and model framework of the two controllers. Then build the controller platform, simulate the underlying topology using IXIA test instruments, Cbench and Mininet to get the performance parameters and furthermore analyze the data.},
  doi       = {10.1109/CCI.2016.7778909},
  keywords  = {protocols;software defined networking;telecommunication network management;telecommunication network topology;Cbench;IXIA test instruments;Mininet;ONOS;OpenDaylight;OpenFlow protocol;SDN;network management;open-source controllers;software defined network;Network topology;Protocols;Switches;Throughput;Time factors;Topology;ONOS;OpenDaylight;SDN;Test},
}

@InProceedings{Lu2008,
  author    = {Y. Lu and D. Yan and S. Nie and C. Wang},
  title     = {Development of an Improved GUI Automation Test System Based on Event-Flow Graph},
  booktitle = {2008 International Conference on Computer Science and Software Engineering},
  year      = {2008},
  volume    = {2},
  pages     = {712-715},
  month     = {Dec},
  abstract  = {A more highly automated graphic user interface (GUI) test model, which is based on the event-flow graph, is proposed. In the model, an automation tool is first used to carry out reverse engineering for a GUI test sample so as to obtain the event-flow graph. Then an improved ant colony optimization algorithm and a goal-directed searching approach are adopted to create GUI test sample cases. Moreover, a corresponding prototype system based on Microsoft UI automation framework is developed.},
  doi       = {10.1109/CSSE.2008.1336},
  keywords  = {graph theory;graphical user interfaces;optimisation;program testing;search problems;GUI automation test system;ant colony optimization algorithm;event-flow graph;goal-directed searching;graphic user interface;reverse engineering;Ant colony optimization;Artificial intelligence;Automatic testing;Automation;Graphical user interfaces;Prototypes;Reverse engineering;Software engineering;Software testing;System testing},
}

@InProceedings{Yuqing2012,
  author    = {L. Yuqing and X. Hao and L. Xiaohui},
  title     = {The Research of Performance Test Method for Linux Process Scheduling},
  booktitle = {2012 Fourth International Symposium on Information Science and Engineering},
  year      = {2012},
  pages     = {216-219},
  month     = {Dec},
  abstract  = {Performance test plays a fundamental and irreplaceable role in the field of software test, especially in guaranteeing the quality and reliability of an operating system. The performance of the process scheduling subsystem directly affects the accuracy and stability of the whole operating system. Linux operating system vendors execute performance test almost in every period of the Linux operating system research and development to enhance their products' competitiveness. However, the lack of methods and tools for the Linux process scheduling performance test has caused great difficulties for Linux operating system vendors to evaluate and tune the Linux kernel performance. Therefore, in order to solve the issues mentioned above, this paper, based on the analysis of Linux process scheduling mechanism, proposes a Linux process scheduling performance test method, implements a Linux process scheduling performance test tool as well, and finally validates the tool experimentally.},
  doi       = {10.1109/ISISE.2012.54},
  issn      = {2160-1283},
  keywords  = {Linux;operating system kernels;program testing;scheduling;software performance evaluation;software reliability;Linux kernel performance;Linux operating system vendors;Linux process scheduling performance test tool;operating system accuracy;operating system quality;operating system reliability;operating system stability;process scheduling subsystem;software test;benchmark test;linux;performance analysis;performance testing;process scheduling},
}

@InProceedings{Lin2010,
  author    = {W. K. Lin and P. C. Wang and H. P. Wang},
  title     = {Using Thermoelectric Cooling Chip (T.E.C.) to improve the stability of the Heat Pipe Performance Test Instrument},
  booktitle = {2010 5th International Microsystems Packaging Assembly and Circuits Technology Conference},
  year      = {2010},
  pages     = {1-4},
  month     = {Oct},
  abstract  = {Heat pipe is a device of high heat-conduction. It mainly uses inside fluid to carry heat energy while the phase is changing. It's a tool which can transmit a large amount of heat energy in operating temperature while phase is changing. Therefore, heat pipe also named the superconductor. The major purpose of this study is to analyze the affect of the condenser parameters to Heat Pipe Performance. A T.E.C. controller (Thermoelectric Cooling Chip Controller) to measure the condenser section of HPPTI (Heat Pipe Performance Test Instrument) is developed in this study, which can exactly control the temperature in adiabatic section and condenser section very accurately. The experimental results show the maximum heat loading controlled by T.E.C. is the same as that of controlled by water cooling, but the test time is reduce from 7 hours to 3.5 hour, and the final target for test time we expected will be achieved within 20 minutes.},
  doi       = {10.1109/IMPACT.2010.5699661},
  issn      = {2150-5934},
  keywords  = {cooling;heat conduction;heat losses;heat pipes;thermoelectric devices;condenser parameters;heat energy;heat pipe performance test instrument;heat-conduction;stability;thermoelectric cooling chip;Heat Pipe;Maximum Heat Loading;Thermoelectric Chip;heat loss},
}

@InProceedings{Han2015,
  author    = {S. Han and G. Park and G. Lyu and Y. Lee and H. Kim},
  title     = {Performance test and analysis of infrared gas sensors and a combustible gas detector},
  booktitle = {2015 15th International Conference on Control, Automation and Systems (ICCAS)},
  year      = {2015},
  pages     = {1413-1416},
  month     = {Oct},
  abstract  = {Recently, we can find news about toxic and combustible gas accident. So, we have to develop gas detector that can measure gas safely at dangerous area and be possible to monitor gas detection at remote area. In this paper, we analyze and estimate gas sensor modules and combustible gas detectors that is already developed, by using standard gas sample manufactured Korea Gas Safety. We apply result analyzed data from experience for developing next generation combustible gas detector.},
  doi       = {10.1109/ICCAS.2015.7364862},
  issn      = {2093-7121},
  keywords  = {combustion;gas sensors;infrared detectors;Korea Gas Safety;combustible gas detector;gas measurement;infrared gas sensor module;toxic;Detectors;Gas detectors;Least squares approximations;Standards;Testing;Combustible;Detector;Gas;Infrared;Sensor},
}

@InProceedings{Qiu2011,
  author    = {Q. Qiu and L. Zhu and T. Zhao and Z. Liang and X. Yang},
  title     = {A Distributed Storage Performance Test System: Design, Implementation, and Experience},
  booktitle = {2011 Fourth International Joint Conference on Computational Sciences and Optimization},
  year      = {2011},
  pages     = {783-786},
  month     = {April},
  abstract  = {With the rapid development of storage technology, many kinds of storage products and systems have been released, but these products and systems always have some problems such as the performance is not credible, the reliability is not high and so on. In order to better test and evaluate the performance of storage products and systems, we design and implement a distributed Storage Performance Test System called SPTS, which can test the IO performance of file system and disk array. The experience of testing disk array's IOPS and data transfer rate shows that SPTS can provide certain value when customers purchase and use storage products or storage systems.},
  doi       = {10.1109/CSO.2011.28},
  keywords  = {RAID;performance evaluation;storage management;data transfer rate;disk array;distributed storage performance test system;file system;reliability;storage products;storage technology;Arrays;Bandwidth;Benchmark testing;File systems;Monitoring;Throughput;IO performance;IOPS;data rate;disk array;file system;storage test},
}

@InProceedings{Hackenberg2013,
  author    = {D. Hackenberg and R. Oldenburg and D. Molka and R. Schöne},
  title     = {Introducing FIRESTARTER: A processor stress test utility},
  booktitle = {2013 International Green Computing Conference Proceedings},
  year      = {2013},
  pages     = {1-9},
  month     = {June},
  abstract  = {Processor stress test utilities are important tools for a number of different use cases. In particular, cooling systems need to be tested at maximum load in order to ensure that they fulfill their specifications. Additionally, a test system characterization in terms of idle and maximum power consumption is often a prerequisite for energy efficiency research. This creates the need for a simple yet versatile tool that generates near-peak power consumption of compute nodes. While in different research areas tools such as LINPACK and Prime95 are commonly used, these tools are just highly optimized and compute intense routines that solve specific computational problems. As stress test utilities they are unnecessarily hard to use and in many cases unreliable in terms of power consumption maximization. We propose FIRESTARTER, an Open Source tool that is specifically designed to create near-peak power consumption. Our experiments show that this task cannot be achieved with generic high-level language code. We therefore use highly optimized assembly routines that take the specific properties of a given processor microarchitecture into account. A study on four compute nodes with current or last generation x86_64 processors shows that we reliably exceed the power consumption of other stress tests and create very steady power consumption patterns.},
  doi       = {10.1109/IGCC.2013.6604507},
  keywords  = {microprocessor chips;performance evaluation;power aware computing;Firestarter open source tool;assembly routines;cooling systems;energy efficiency research;high-level language code;near-peak power consumption;power consumption patterns;processor stress test utility;test system characterization;x86_64 processors;Bridges;Microarchitecture;Out of order;Ports (Computers);Power demand;Registers;Stress;FIRESTARTER;LINPACK;Prime95},
}

@Article{Foote1992,
  author   = {S. A. Foote and D. B. Grindeland},
  title    = {Model QA3000 Q-Flex accelerometer high performance test results},
  journal  = {IEEE Aerospace and Electronic Systems Magazine},
  year     = {1992},
  volume   = {7},
  number   = {6},
  pages    = {59-67},
  month    = {June},
  issn     = {0885-8985},
  abstract = {Q-Flex quartz flexure suspension technology has evolved to produce a world class accelerometer with thousands of units delivered in 1991. The Sundstrand Model QA3000 Q-Flex design achieves a new level of inertial grade performance while maintaining a competitive market price. The specification for the QA3000, supported by actual performance data, depicts performance characteristics superior in both bias and scale factor. Long term measurements display bias and scale factor repeatability obtained across temperature over a period of three years. These data exhibit improved thermal behavior with reduced errors. Reaction time and radiation data highlight the performance of the hybrid position detector circuit.<>},
  doi      = {10.1109/62.145120},
  keywords = {accelerometers;aerospace instrumentation;aircraft instrumentation;Q-Flex quartz flexure suspension technology;Sundstrand Model QA3000;accelerometer;bias;errors;hybrid position detector circuit;performance characteristics;quartz flexure;radiation data;radiation tolerance;reaction time;scale factor;seismic environment;thermal behavior;time stability;Acceleration;Accelerometers;Aircraft navigation;Automatic testing;Coils;Extraterrestrial measurements;Magnetic levitation;Magnetic sensors;Temperature;Voltage},
}

@InProceedings{Huey-Der2010,
  author    = {C. Huey-Der and J. F. Yang},
  title     = {The Lesson Learned of a System's Performance Test},
  booktitle = {2010 Second World Congress on Software Engineering},
  year      = {2010},
  volume    = {2},
  pages     = {270-276},
  month     = {Dec},
  abstract  = {This paper, by mirroring the performance testing of a given company's merchandising distribution information system, has attempted to resolve the demands in function testing without the aid of any market-sold automated testing tools, to decipher a system's loading response time in an effort to help improve the system functions.},
  doi       = {10.1109/WCSE.2010.153},
  keywords  = {management information systems;performance evaluation;resource allocation;company merchandising distribution information system;performance testing;system loading response time;Databases;Load modeling;Loading;Servers;Software;Testing;Time factors;Client/Server;Loading;Performance Testing},
}

@InProceedings{Hosseinizadeh2009,
  author    = {P. Hosseinizadeh and A. Guergachi},
  title     = {Using heavy-tailed distributions to stress-test kernel methods for segregating the firms that are likely to survive},
  booktitle = {2009 IEEE International Conference on Systems, Man and Cybernetics},
  year      = {2009},
  pages     = {1464-1469},
  month     = {Oct},
  abstract  = {While kernel-based learning methods have emerged during the last two decades as major tools to effectively manage uncertainty, heavy-tailed distributions remain a major challenge for modelers who aim to predict the future behavior of complex systems. In this article, Weibull distribution has been used to stress-test kernel-based methods and study more specifically the impact of heavy-tailed distributions on the performance of Fisher kernels in identifying the potential for collapse of an enterprise based on its stock price.},
  doi       = {10.1109/ICSMC.2009.5346298},
  issn      = {1062-922X},
  keywords  = {Weibull distribution;corporate modelling;learning (artificial intelligence);Fisher kernels;Weibull distribution;complex systems;enterprise;heavy-tailed distributions;kernel-based learning;stock price;stress-test kernel methods;Computational modeling;Gaussian distribution;Kernel;Learning systems;Mathematical model;Predictive models;Probability distribution;Statistical learning;Uncertainty;Weibull distribution;Fisher kernel;Weibull distribution;financial time series;heavy-tailed distributions;modelling;prediction},
}

@InProceedings{Xiaoqin2011,
  author    = {Zhang Xiaoqin and Li Zhihong and Wang Baoliang and Wang Lianchuan},
  title     = {Performance test and data acquisition of voltage regulator for automotive alternator},
  booktitle = {Proceedings 2011 International Conference on Transportation, Mechanical, and Electrical Engineering (TMEE)},
  year      = {2011},
  pages     = {707-710},
  month     = {Dec},
  abstract  = {The dynamic testing system of voltage regulator must be assembled with the automotive alternator, so it's large, expensive, power consumption and operation complexity. A static testing system was developed by using electronic analog generator in place of automotive alternator sets. The system communicated with the computer can carry out performance test and data acquisition, in turn to analysis performance for large quantities of products. The paper described the methods of static testing and the principles of data acquisition. By comparison, it's proved that the static testing system is simple, reliable, easy to operate, cheap and accurate. Its accuracy came to 0.1 relative to dynamic testing system.},
  doi       = {10.1109/TMEE.2011.6199300},
  keywords  = {alternators;automotive electronics;data acquisition;dynamic testing;voltage regulators;automotive alternator sets;data acquisition;dynamic testing system;electronic analog generator;operation complexity;power consumption;static testing system;voltage regulator;Alternators;Data acquisition;Regulators;Testing;Vehicle dynamics;Voltage control;automotive alternator;data acquisition;electrical performance;static test;voltage regulator},
}

@InProceedings{Liao2011,
  author    = {Huaiwei Liao and M. Ilic},
  title     = {Stress test model of cascading failures in power grids},
  booktitle = {2011 North American Power Symposium},
  year      = {2011},
  pages     = {1-5},
  month     = {Aug},
  abstract  = {Cascading failures in electric power systems are one of the major causes of large power blackouts. The operators in control centers of electric power systems need an online tool to monitor the risk of cascading failures when transferring large quantities of power over long distances. In this paper, we propose a two-stage stress test model of cascading failures. The stress test model is intended to emulate the effect of security-constrained economic dispatch (SCED) in support of the required power transfer level, and at the same time, to account for relay actions in response to a given set of severe disturbances, called maximum credible disturbances. The model includes an inner stage, which simulates cascading outages due to relay actions in the system at a given state under disturbances, and an outer stage, which moves the operating point of the system as the power transfer increases as a result of SCED. We use the stress test model to simulate cascading failures in a real 3000-bus power system when increasing its power transfer level in different directions.},
  doi       = {10.1109/NAPS.2011.6025200},
  keywords  = {failure analysis;load dispatching;power grids;power system security;power transmission control;power transmission economics;power transmission reliability;risk analysis;SCED;cascading failures;cascading outages;electric power system control;power blackouts;power grids;power transfer level;risk analysis;security-constrained economic dispatch;stress test model;Load modeling;Power system faults;Power system protection;Protective relaying;Stress},
}

@InProceedings{Yujie2011,
  author    = {Zhang Yujie and Zhang Yuanyuan},
  title     = {Design and implementation of OLED optical performance test system},
  booktitle = {IEEE 2011 10th International Conference on Electronic Measurement Instruments},
  year      = {2011},
  volume    = {2},
  pages     = {38-41},
  month     = {Aug},
  abstract  = {For the defects of the manual measurement of OLED optical performance by using discrete devices, this paper presented a platform which can measure the optical and electrical property of the light-emitting device of the OLED at the same time. It drew the real-time curve via the host computer to monitor and compare the performance data. It implemented a rapid, accurate and reliable automatic measurement system. And it improved the measure efficiency and accuracy greatly. It plays an important role in the study of the optical carriers transport properties, luminescence properties, luminous efficiency of OELD devices.},
  doi       = {10.1109/ICEMI.2011.6037760},
  keywords  = {automatic test equipment;luminescence;optical properties;organic light emitting diodes;OLED;automatic measurement system;discrete devices;electrical property;luminescence properties;luminous efficiency;optical carriers transport properties;optical performance test system;real time curve;Computers;Integrated optics;Optical sensors;Optical switches;Optical variables measurement;OLED;optical properties;test simultaneously},
}

@InProceedings{Dong2015,
  author    = {Y. Dong and J. Huang and M. Ding and H. Li and S. Zhang},
  title     = {Performance test and evaluation of photovoltaic system},
  booktitle = {International Conference on Renewable Power Generation (RPG 2015)},
  year      = {2015},
  pages     = {1-4},
  month     = {Oct},
  abstract  = {In this paper, the performance ratio (PR) of PV system is evaluated by field testing. The sampling strategy of efficiency chain for PV system is determined by analyzing long-term operation monitoring data of PV system. The efficiency parameters of components are extracted. The efficiency model of components in PV system is established in PVsyst software. Combining efficiency models, geographic information and the long time weather information, the PR of PV system and the yield over the next twenty-five years can be evaluated.},
  doi       = {10.1049/cp.2015.0500},
  keywords  = {photovoltaic power systems;PV system;PVsyst software;efficiency models;geographic information;long time weather information;long-term operation monitoring data;performance ratio;photovoltaic system;sampling strategy;PV inverter efficiency;PV system;PV system power generation;Performance ratio (PR)},
}

@InProceedings{Yeom2008,
  author    = {Hankil Yeom and Seung Woo Lee},
  title     = {Performance test of gas by-pass type thermal error controller},
  booktitle = {2008 International Conference on Control, Automation and Systems},
  year      = {2008},
  pages     = {1471-1474},
  month     = {Oct},
  abstract  = {In accordance with the trend for high-speed and multi-axes of machine tools, thermal deformation has become an important factor in the accuracy of machine tools. It was analyzed that thermal deformation error accounts for about 70% of all errors made with machine tools. For precise temperature control, both cooling and heating should be done. A hot gas by-pass type of cooling method has a simplified structure and temperature control accuracy to with in plusmn0.1 degC. In this study, the operational characteristics of the thermal error controller, including temperature controllability according to hot gas flow and preset temperature sustainability according to heat load, were tested. It is expected that this study will contribute to the development and performance assessment of thermal error controllers, which could minimize thermal errors and improve the quality of semiconductor equipment, precision injection molds, and precision machine tools.},
  doi       = {10.1109/ICCAS.2008.4694374},
  keywords  = {cooling;heating;machine tools;temperature control;cooling;gas by-pass type thermal error controller;heating;machine tools;temperature control;temperature sustainability;thermal deformation;Controllability;Cooling;Error correction;Fluid flow;Heating;Machine tools;Temperature control;Testing;Thermal factors;Thermal loading;cooling cycle;hot gas by-pass;thermal error controller},
}

@InProceedings{Kato2016,
  author    = {Y. Kato and M. Koike and K. Kurabe and K. Jinno and K. Yamashita and K. Tatsuno},
  title     = {Task performance test on grasping the bolt by a power distribution line maintenance experimental robot system},
  booktitle = {2016 International Symposium on Micro-NanoMechatronics and Human Science (MHS)},
  year      = {2016},
  pages     = {1-7},
  month     = {Nov},
  abstract  = {We have been developing a power distribution line maintenance robot system. This system will autonomously carry out basic tasks in the maintenance work. For examples, “Grasping a bolt”, “Inserting a bolt”, “Tightening a nut” and so on. We perform a task performance test “Grasp the bolt on the tool box”. The system grasps the bolt on tool box under visual feedback from the hand-eye camera. Applied visual feedback control does not require camera calibration and arm calibration because this visual feedback adjusts the bolt and the gripper in one image plane using the hand-eye camera.},
  doi       = {10.1109/MHS.2016.7824232},
  keywords  = {calibration;fasteners;maintenance engineering;power distribution lines;robots;arm calibration;bolt grasping;camera calibration;hand-eye camera;image plane;power distribution line maintenance experimental robot system;task performance test;visual feedback control;Cameras;Fasteners;Grippers;Manipulators;Robot sensing systems;Visualization},
}

@InProceedings{Si2016,
  author    = {Chaogang Si and Changmin Teng and Li Wang},
  title     = {Design and performance test in an interconnected TD-LTE train-ground communication for urban rail transit system},
  booktitle = {2016 IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)},
  year      = {2016},
  pages     = {1734-1737},
  month     = {Oct},
  abstract  = {In existing urban rail transit system, because of long construction period, train-ground communication system for different rail lines may use equipment from different manufacturer, that will bring challenges for management of metro company, even, it may result in emergency brake of train or traffic safety when a train is going across different lines. In this paper, we first study relevant demands of TD-LTE train-ground communication interconnection, an interconnected TD-LTE train-ground communication system for the urban rail transit system is designed next, in order to test the interconnected TD-LTE based train-ground communication system performance, an indoor testing environment is set up. The programmable attenuators and EIT-Monitor are used to simulate the real urban rail transit environment and monitor signal from different network equipment. Final test results prove that the designed interconnected TD-LTE train-ground communication can be applied to current train control system, which completely satisfies the demand of subway operation in urban rail transit system.},
  doi       = {10.1109/IMCEC.2016.7867515},
  keywords  = {Long Term Evolution;electric impedance imaging;rail traffic control;railway communication;railway safety;EIT-monitor;interconnected TD-LTE train-ground communication system;metro company management;programmable attenuators;signal monitoring;subway operation;traffic safety;train control system;train emergency brake;urban rail transit system;Attenuators;Chaotic communication;Coaxial cables;Long Term Evolution;Monitoring;Power dividers;Rails;TD-LTE;interconnection;test;train-ground communication system},
}

@InProceedings{Shengbing2015,
  author    = {Shi Shengbing and Song Chunyan and Wu Yanlin},
  title     = {CAN bus performance test technology},
  booktitle = {2015 12th IEEE International Conference on Electronic Measurement Instruments (ICEMI)},
  year      = {2015},
  volume    = {03},
  pages     = {1395-1399},
  month     = {July},
  abstract  = {With the development of high and new technology, the degree of weapon equipments' integration, digitization and information became more and more higher. CAN bus technology is also used more and more widely. The self-performance of CAN bus effects weapon equipments' information interaction such as instructs convey, default detection and so on. It also has vital influence on weapon equipments to carry out fight tasks. In this paper, through analyzing CAN bus architecture of certain weapon and data transmission characteristic on CAN bus, analyses several problems on CAN bus performance test, including test system structure, test data capacity analysis and data processing. Through constructing one test environment, proves this method is scientific and logical, lays the technological foundation of implementing CAN bus performance test.},
  doi       = {10.1109/ICEMI.2015.7494507},
  keywords  = {Computers;Constitution;Data processing;Monitoring;Weapons;CAN bus;performance test;weapon equipments},
}

@InProceedings{Yao2007,
  author    = {N. Yao and F. Gao and S. Cai and W. Yao},
  title     = {A New Method of Performance Test for Network Storage},
  booktitle = {Second International Multi-Symposiums on Computer and Computational Sciences (IMSCCS 2007)},
  year      = {2007},
  pages     = {416-420},
  month     = {Aug},
  abstract  = {Network storages are used widely in many fields of our society. But their testing performances are not as expected. Most of the tools being used to test the performance of network storage comes from the tools used to test the traditional storage system because the storage devices connected to the net act as the local storage devices. So these tools inevitably miss the effects exerted by the networks which connect the hosts to the storage devices. For example, these tools can hardly generate requests which exceed the maximum loading of storage devices. In this paper, we propose one new method to test the performance of network storage which can easily generate requests that exceed the maximum loading of storage devices. In this method, the test program sends the requests by fixed frequency and the initiator will not be restrained by the targeter when the quantity of requests is close to the maximum load. The load simulated by the new method is more like the load in the real world, especially when the load is very high.},
  doi       = {10.1109/IMSCCS.2007.36},
  keywords  = {program testing;software performance evaluation;storage management;network storage;performance test;storage system;testing performance;Computer networks;Data warehouses;Educational institutions;Frequency;Internet;Network servers;Performance evaluation;Protocols;System testing;Web server},
}

@Article{Dougherty1981,
  author   = {J. W. Dougherty and S. H. Minnich},
  title    = {Finite Element Modeling of Large Turbine Generators; Calculations Versus Load Test Data},
  journal  = {IEEE Power Engineering Review},
  year     = {1981},
  volume   = {PER-1},
  number   = {8},
  pages    = {50-50},
  month    = {Aug},
  issn     = {0272-1724},
  abstract = {Summary form only given, as follows.},
  doi      = {10.1109/MPER.1981.5511784},
  keywords = {Finite element methods;Particle measurements;Power system interconnection;Power system stability;Power system transients;Reactive power;Turbines},
}

@InProceedings{Lumyong2000,
  author    = {Pichit Lumyong and Chaiwut Chat-Uthai},
  title     = {Power minimization technique for induction motor load test},
  booktitle = {Proceedings IPEMC 2000. Third International Power Electronics and Motion Control Conference (IEEE Cat. No.00EX435)},
  year      = {2000},
  volume    = {2},
  pages     = {570-573 vol.2},
  abstract  = {This paper presents the technique of how to minimize power from the supply when a three-phase induction motor is under the load test. The load test enables the determination of the value of load power, current and power factor of the induction motor. In practice, a DC generator or eddy current brake is applied for the mechanical test. The objective of this paper is to propose a load test method using two pulleys for changing speed of an induction motor. The second induction machine is controlled to operate as an induction generator in order to transfer the energy to the supply, therefore the power required during the test is obviously reduced. The study of how to control the induction motor operated as generator will be the useful information for developing the induction generator system (IG) to work with variable speed and load, and to make it work as a stand alone generator},
  doi       = {10.1109/IPEMC.2000.884551},
  keywords  = {asynchronous generators;induction motors;machine testing;power factor;DC generator;eddy current brake;energy transfer;induction generator;induction motor load test;load power;load test method;mechanical test;power factor;power minimization technique;pulleys;three-phase induction motor;variable load;variable speed;Control systems;DC generators;Eddy current testing;Eddy currents;Induction generators;Induction machines;Induction motors;Power supplies;Pulleys;Reactive power},
}

@InProceedings{Chu2007,
  author    = {L. Chu and J. Gu and M. Liu and J. Li and Y. Gao and M. Ehsani},
  title     = {Study on CAN Communication of EBS and Braking Performance Test for Commercial Vehicle},
  booktitle = {2007 IEEE Vehicle Power and Propulsion Conference},
  year      = {2007},
  pages     = {849-852},
  month     = {Sept},
  abstract  = {EBS (electronic brake system) can effectively control and adjust braking force acting on every wheel, reduce braking response time and braking distance, and make vehicle achieve much more braking stability. It is featured with CAN (Controller Area Network) communication by which the sensor signals and control command signals can be transmitted and received. In the braking performance test of EBS, conventional test methods have some inconvenience in existence. For example, the fixing of pressure sensors and wheel speed sensors is restrained by the installation position, and the precision of measuring is prone to be affected by the environment conditions. But based on CAN communication technology, the special testing instrument can be connected with CAN bus, monitoring and recording signals on the bus. Thus signals representing braking performance can be acquired through CAN bus.},
  doi       = {10.1109/VPPC.2007.4544242},
  issn      = {1938-8756},
  keywords  = {braking;controller area networks;pressure sensors;road vehicles;test equipment;CAN communication;EBS;braking distance;braking force;braking performance;braking stability;commercial vehicle;control command signals;controller area network communication;electronic brake system;pressure sensors;sensor signals;wheel speed sensors;Communication system control;Control systems;Delay;Force control;Force sensors;Position measurement;Stability;Testing;Vehicles;Wheels;CAN;Electronic Brake System (EBS)},
}

@InProceedings{Li2013c,
  author    = {T. Li and X. Liu and Y. Tan and G. Huang and K. Zheng},
  title     = {Design of EBS performance test system based on LabVIEW},
  booktitle = {2013 Chinese Automation Congress},
  year      = {2013},
  pages     = {637-642},
  month     = {Nov},
  abstract  = {In the past, EBS performance test was conducted with traditional instruments, which was tedious and costly. This study is made on the system of EBS performance test developed based on LabVIEW. This system, which is easy to operate and quite practicable, can achieve simultaneous monitoring, recording and display of analog signal, digital signal and GPS communication signals. Experiment showed that the good stability and reliability of the system was very helpful for the operators to evaluate and analyse EBS performance.},
  doi       = {10.1109/CAC.2013.6775813},
  keywords  = {Global Positioning System;braking;signal processing;traffic engineering computing;virtual instrumentation;EBS performance test system design;GPS communication signals;LabVIEW;analog signal;digital signal;electronic braking system;system reliability;system stability;Decision support systems;Erbium;Brake System;EBS;GPS;LabVIEW},
}

@InProceedings{Qiao2011,
  author    = {J. Qiao},
  title     = {The acceleration stress test of the brake system on an airplane},
  booktitle = {The Proceedings of 2011 9th International Conference on Reliability, Maintainability and Safety},
  year      = {2011},
  pages     = {1067-1072},
  month     = {June},
  abstract  = {The test method is discussed which increases the environment stress and the working stress to stimulate failures in products without damage, besides, the method which converts the acceleration stress test time to working time is put forward to evaluate the MTBF and first overhaul period of the product. In order to stimulate potential failures, the technology of colligating reliability test and life test is studied in the brake system of a certain aircraft, in which the environment stress is not statistical stress but its kind and magnitude are established in allusion to the weak links. Rated working stress which corresponds to antiskid brake rule is brought into the test profile and the contamination tolerance test of hydraulic system is conducted. As a result, latent failures of the break system are activated in a short time; the test which needs 5200 working hours to finish is ended in 200 hours; reliability growth rate achieves 0.65; the MTBF of the brake system increases to 848h from 28h in the beginning, and the first overhaul period of new developed products in the break system attains 1250 takeoff-landing times.},
  doi       = {10.1109/ICRMS.2011.5979426},
  keywords  = {aerospace engineering;aircraft;braking;hydraulic systems;internal stresses;mechanical testing;reliability;acceleration stress test;airplane;brake system;contamination tolerance test;environment stress;hydraulic system;life test;mean time between failure;rated working stress;reliability test;Acceleration;Pollution measurement;Reliability;Servomotors;Stress;Temperature measurement;Valves;design improvement of products;failure excitation;life evaluation;reliability evaluation;reliability growth;test method improvement},
}

@InProceedings{Belloni2017,
  author    = {F. Belloni and R. Chiumeo and C. Gandolfi and A. Villa},
  title     = {Performance test of a PQ universal compensator through Control Hardware in the Loop simulation},
  booktitle = {2017 6th International Conference on Clean Electrical Power (ICCEP)},
  year      = {2017},
  pages     = {502-508},
  month     = {June},
  abstract  = {Distributed Energy Resources (DER) connected to distribution grids through static power converters may have major impacts on Power Quality (PQ). For this reason, power converters used as Universal Compensators (UC) are gaining more and more interest. This paper describes the design, modeling and study of a shunt static compensator for Low Voltage distribution grids. The proposed device can be used for interfacing Distributed Generators (DG) or Energy Storage Systems (ESS) to the grid and can be connected close to disturbing loads. This device can compensate harmonic currents, reactive power and unbalances of disturbing loads, and it can also supply sensitive loads in island operation. Performances of the proposed device, with different control schemes and with different harmonic compensation strategies, are assessed through Control Hardware in the Loop (CHIL) Real Time simulations.},
  doi       = {10.1109/ICCEP.2017.8004734},
  keywords  = {compensation;energy resources;power convertors;power grids;power supply quality;reactive power;CHIL;DER;PQ universal compensator;UC;control hardware in the loop real time simulations;distributed energy resources;disturbing loads;harmonic compensation strategies;harmonic currents;island operation;low voltage distribution grids;performance test;power quality;reactive power;static power converters;Hardware;Harmonic analysis;Integrated circuit modeling;Power harmonic filters;Real-time systems;Voltage control;Voltage measurement;Digital Real Time simulations (DRTS);Distributed Generator;Hardware in the loop (HIL);Power Quality;Universal Compensator},
}

@InProceedings{Gara2016,
  author    = {F. Gara and V. Nicoletti and D. Roia and L. Dezi and A. Dall'Asta},
  title     = {Dynamic monitoring of an isolated steel arch bridge during static load test},
  booktitle = {2016 IEEE Workshop on Environmental, Energy, and Structural Monitoring Systems (EESMS)},
  year      = {2016},
  pages     = {1-6},
  month     = {June},
  abstract  = {This paper describes the dynamic monitoring carried out by means of vibration measurements during the standard static load test of a half-through steel arch bridge on the Potenza river. The structural design of the bridge is characterized by some notable aspects: the river crossing is obtained by two coupled steel arches, having a span length around 115 m, and a steel-concrete composite deck sustained by thirty couples of steel hangers; the approaching spans are realized with continuous girders on intermediate supports, having cross section with variable height; the arches are supported on rubber bearing seismic isolators. The vibration measurements were nearly continuously acquired during the loading tests to detect the occurrence of anomalies in the structural behavior. In particular, the global dynamic characteristics of the structure, in terms of modal parameters, were determined using the data set of measurements at specific phases of the load test: first on the unloaded configuration, then on two different loaded configurations and finally after the bridge unloading. Measurements of vibrations due both to the ambient and to the impulse produced by a fully loaded truck passing over a bump, were carried out. The experimental results, in terms of modal parameters of the bridge, are in agreement with the theoretical results obtained with the predictive finite element model developed for design purposes and opportunely modified to account for the real conditions of the bridge during the tests.},
  doi       = {10.1109/EESMS.2016.7504823},
  keywords  = {bridges (structures);condition monitoring;design engineering;dynamic testing;finite element analysis;modal analysis;seismology;steel;structural engineering;vibration measurement;Potenza river;bridge unloading;continuous girders;coupled steel arches;dynamic monitoring;fully-loaded truck;global dynamic characteristics;half-through steel arch bridge;intermediate supports;isolated steel arch bridge;loaded configurations;modal parameters;predictive finite element model;rubber bearing seismic isolators;standard static load test;steel hangers;steel-concrete composite deck;structural behavior;structural design;unloaded configuration;variable height;vibration measurement;Accelerometers;Bridges;Monitoring;Shape;Steel;Structural beams;Vibration measurement;dynamic testing;modal identification;monitoring;operational modal analysis;steel arch bridge;vibration measurement},
}

@InProceedings{Zhang2016d,
  author    = {H. Zhang and J. Nie},
  title     = {Performance test of Taurus HPC system},
  booktitle = {2016 IEEE International Conference of Online Analysis and Computing Science (ICOACS)},
  year      = {2016},
  pages     = {185-188},
  month     = {May},
  abstract  = {High performance computing system has become the strong support of scientific research due to the good cost performance ratio and scalability after pure science and experimental science, the performance tests help to find out the performance bottlenecks of HPC systems. How to evaluate the performance of a HPC system is the main purpose of this paper. A high-performance computing system with 16 CPU+GPU compute nodes has been constructed. HPL benchmark was used to evaluate the performance of CPU, GPU under different matrix scale Ns, computational nodes, block size NB of matrix etc, and an empirical formula of Ns value calculation was presented through lots of testings. A comprehensive storage I/O performance was tested with IOZone which is a professional file system's standard testing tool. The performance of CPU cluster reaches 93.5% of the system theoretical value and GPU cluster gets 80% of the theoretical value.},
  doi       = {10.1109/ICOACS.2016.7563076},
  keywords  = {graphics processing units;microprocessor chips;parallel processing;CPU;GPU;IOZone;Taurus HPC system;cost performance ratio;high performance computing system;performance test;professional file systems;standard testing tool;storage I/O performance;Decision support systems;Graphics processing units;Servers;CPU;GPU;HPC;IOZone;Linpack},
}

@Article{Avritzer1995,
  author   = {A. Avritzer and E. R. Weyuker},
  title    = {The automatic generation of load test suites and the assessment of the resulting software},
  journal  = {IEEE Transactions on Software Engineering},
  year     = {1995},
  volume   = {21},
  number   = {9},
  pages    = {705-716},
  month    = {Sep},
  issn     = {0098-5589},
  abstract = {Three automatic test case generation algorithms intended to test the resource allocation mechanisms of telecommunications software systems are introduced. Although these techniques were specifically designed for testing telecommunications software, they can be used to generate test cases for any software system that is modelable by a Markov chain provided operational profile data can either be collected or estimated. These algorithms have been used successfully to perform load testing for several real industrial software systems. Experience generating test suites for five such systems is presented. Early experience with the algorithms indicate that they are highly effective at detecting subtle faults that would have been likely to be missed if load testing had been done in the more traditional way, using hand-crafted test cases. A domain-based reliability measure is applied to systems after the load testing algorithms have been used to generate test data. Data are presented for the same five industrial telecommunications systems in order to track the reliability as a function of the degree of system degradation experienced},
  doi      = {10.1109/32.464549},
  keywords = {Markov processes;automatic test software;program testing;resource allocation;software reliability;telecommunication computing;Markov chain;automatic test case generation algorithms;domain-based reliability measure;fault detection;industrial software systems;load test suites;load testing;reliability;resource allocation mechanisms;software testing;system degradation;telecommunications software;Automatic testing;Communication industry;Computer industry;Fault detection;Performance evaluation;Resource management;Software algorithms;Software systems;Software testing;System testing},
}

@InProceedings{Krejcar2010,
  author    = {O. Krejcar and M. Penhaker and D. Janckulik and L. Motalova},
  title     = {Performance test of multiplatform real time processing of biomedical signals},
  booktitle = {2010 8th IEEE International Conference on Industrial Informatics},
  year      = {2010},
  pages     = {825-830},
  month     = {July},
  abstract  = {The paper deal with a problem of a data collecting and visualization of several biomedical signals from patients by mobile embedded monitoring stations. Measurement devices were used in real tests. Due to a problem of real time processing a 12 channels ECG from ECG device by Bluetooth to mobile stations, packet parsing as the one problem part of data processing chain, is presented and solved by two possible solutions. Mobile embedded monitoring stations are based on Microsoft Windows Mobile operating system. The whole system is based on the architecture of .NET Framework, .NET Compact Framework, .NET Micro Framework and Microsoft SQL Server.},
  doi       = {10.1109/INDIN.2010.5549635},
  issn      = {1935-4576},
  keywords  = {data visualisation;electrocardiography;medical signal processing;real-time systems;ECG;Microsoft Windows mobile operating system;NET Micro Framework;NET compact framework;biomedical signals;data collection;data processing chain;data visualization;embedded monitoring stations;measurement devices;microsoft SQL server;mobile stations;multiplatform real time processing;packet parsing;Biomedical measurements;Biomedical monitoring;Bluetooth;Data processing;Data visualization;Electrocardiography;Operating systems;Patient monitoring;Signal processing;Testing;ECG;biotelemetry;mobile;processing},
}

@InProceedings{Srinivasan2007,
  author    = {G. Srinivasan and A. Chatterjee},
  title     = {Fourier Spectrum-Based Signature Test: A Genetic CAD Toolbox for Reliable RF Testing Using Low-Performance Test Resources},
  booktitle = {16th Asian Test Symposium (ATS 2007)},
  year      = {2007},
  pages     = {139-142},
  month     = {Oct},
  abstract  = {At the present time, coordinated EDA tools for RF/mixed-signal pin test do not exist. In this paper, a CAD tool for efficient production testing of high- performance RF systems using low-cost baseband ATE is presented The CAD tool consists of a custom developed genetic ATPG for spectral (Fourier spectrum) signature-based alternate (to full specification-based tests) test of RF systems and involves co-simulation of scalable behavioral-level models of the RF System-Under-Test, baseband ATE test instrumentation, loadboard resources, and DfT resources for fast test vector optimization/generation. The CAD tool also enables the evaluation of various low-cost ATE architectures on the impact of the generated tests to provide a cost-effective solution.},
  doi       = {10.1109/ATS.2007.98},
  issn      = {1081-7735},
  keywords  = {automatic test equipment;automatic test pattern generation;circuit CAD;integrated circuit testing;radiofrequency integrated circuits;ATE;ATPG;Fourier spectrum;RF system under test;genetic CAD toolbox;loadboard resources;low performance test resources;reliable RF testing;signature test;test instrumentation;Automatic test pattern generation;Baseband;Circuit testing;Costs;Electronic design automation and methodology;Genetics;Instruments;Radio frequency;Sequential analysis;System testing},
}

@InProceedings{Hong2007,
  author    = {S. B. Hong and S. H. Han and C. E. Chung},
  title     = {Performance test of an environmental radiation monitoring system},
  booktitle = {2007 IEEE Nuclear Science Symposium Conference Record},
  year      = {2007},
  volume    = {1},
  pages     = {754-755},
  month     = {Oct},
  abstract  = {A Portable environmental radiation monitoring system which is able to monitor both a scintillation detector and a high pressure ion chamber was developed. We applied Mourich's spectrum-dose rate conversion(G(E) method) for measurement of dose rate and Beck's energy band for natural radiation dose rate of Nal(Tl) Detector. Also man-made radiation dos rate against nuclear power plant such as Cs-137, Mn-54, C0- 58, Co-60, Ir-192 was measured.},
  doi       = {10.1109/NSSMIC.2007.4436438},
  issn      = {1082-3654},
  keywords  = {dosimetry;ionisation chambers;radiation monitoring;solid scintillation detectors;Beck energy band;Co-58;Co-60;Cs-137;G(E) method;Ir-192;Mn-54;Mourich spectrum-dose rate conversion;NaI(Tl) detector;environmental radiation monitoring system;high pressure ion chamber;man-made radiation dose rate;natural radiation dose rate;nuclear power plant;scintillation detector;Connectors;Detectors;Energy measurement;Power generation;Pressure measurement;Radiation monitoring;Scintillation counters;Spectroscopy;System testing;Universal Serial Bus},
}

@InProceedings{Tan2012,
  author    = {Y. Tan and C. Yu},
  title     = {New Device Design and Performance Test on Gas Generator in Automobile Airbag},
  booktitle = {2012 International Conference on Control Engineering and Communication Technology},
  year      = {2012},
  pages     = {484-487},
  month     = {Dec},
  abstract  = {An new test device to test gas generator performance in automobile airbag is built. It is made up of inflator jar, sliding track, lifting device and data acquisition system. This system can produce an analog signal which is similar to the impact signal of automobile crash. For get suitable data of acceleration and the duration of impact, lots of experiments have been done. When lifting height of inflator jar is 280mm, acceleration peak value is from 80.5g to 90.2g and dash duration is from 6ms to 8ms. They can meet require to detonate gas generator. There were five groups gas generators from SHANXI Jinheng auto-parts Co., LTD was tested and changing track of pressure and acceleration can be known clearly. Then forty-four gas generators contrast test were done separately in China and in USA. Test results from our designed device were very similar to USA device. It was confirmed that the device designed to test gas generator performance by ourselves was successful.},
  doi       = {10.1109/ICCECT.2012.77},
  keywords  = {acceleration;automotive components;automotive engineering;data acquisition;design engineering;impact (mechanical);pressure;signal processing;test equipment;China;USA;United States of America;acceleration track;analog signal;automobile airbag;automobile crash impact signal;data acquisition system;gas generator;gas generator contrast test;impact acceleration;impact duration;inflator jar;lifting device;performance test;pressure track;sliding track;test device design;Acceleration;Automobiles;Generators;Performance evaluation;Safety;Tracking;USA Councils;airbag;automobile;gas generator;mechanical design;pressure test},
}

@InProceedings{Lazzaroni2015,
  author    = {M. Lazzaroni and M. Citterio and S. Latorre},
  title     = {Points of Load: Performance test in high-B environment},
  booktitle = {2015 IEEE International Instrumentation and Measurement Technology Conference (I2MTC) Proceedings},
  year      = {2015},
  pages     = {1320-1325},
  month     = {May},
  abstract  = {The performance in magnetic field (B-field) of a DC-DC converter ad hoc designed for LHC operation has been evaluated. The tests have been carried out at the Laboratorio Acceleratori e Superconduttività Applicata (LASA), in Milan (Italy), in the first months of 2014 and the experimental results are here presented and discussed. The ability to operate in hostile environment of the tested DC-DC converter is very interesting in particular when used in measuring system for physics experiments. In this case, in fact, the presence of radiation and strong magnetic field make electronic devices challenged to function. In particular, in this paper the operation in high B-field environment has been investigated and discussed.},
  doi       = {10.1109/I2MTC.2015.7151464},
  issn      = {1091-5281},
  keywords  = {DC-DC power convertors;cyclic accelerators;magnetic field effects;testing;DC-DC converter;LASA;LHC operation;Laboratorio Acceleratori e Superconduttività Applicata;Milan;high-B environment;magnetic field performance;performance test;points of load;Current measurement;Detectors;Instruments;Large Hadron Collider;Magnetic field measurement;Magnetic fields;Physics;Dependability;High-B tolerance;Hostile environment;LHC;Measurement;Points of Load;Reliability},
}

@InProceedings{Mu-qing2010,
  author    = {C. Mu-qing and L. R. Xu Jiang-ning and L. Ping},
  title     = {Fiber-optic gyrocompass performance test and combined dead reckoning (DR) navigation scheme design},
  booktitle = {2010 2nd International Conference on Signal Processing Systems},
  year      = {2010},
  volume    = {3},
  pages     = {V3-594-V3-596},
  month     = {July},
  abstract  = {Different test schemes are designed in the paper, which fully aware of the characteristics and important indicators of fiber-optic gyro compass OCTANS. After analysis the towed system working environment, this paper propose the towed system to use part of OCTANS heave compensation outputs for combined DR navigation system.},
  doi       = {10.1109/ICSPS.2010.5555842},
  keywords  = {compasses;compensation;fibre optic gyroscopes;inertial navigation;DR navigation system;OCTANS;dead reckoning;fiber-optic gyro compass;heave compensation;performance test;Accuracy;Convergence;Navigation;Optical fiber filters;Signal processing;Surges;Three dimensional displays;combined navigation system;heave compensation;towd system},
}

@InProceedings{Peng2011,
  author    = {X. Peng and Q. Ge and F. Xiong},
  title     = {Stress test and finite element analysis of a 10 #x00D7;104 m3 crude oil tank},
  booktitle = {2011 International Conference on Multimedia Technology},
  year      = {2011},
  pages     = {1734-1737},
  month     = {July},
  abstract  = {The large crude oil storage tank with a capacity of 10×104 m3 has been widely used in China currently. In order to obtain the stress distribution in the wall board, bottom board, big fillet weld and manhole, and to verify the rationality of tank design, a stress test which combining the method of static resistance strain test (SRST) and optical fiber strain test (OFST) is conducted during water filling test for the tank. Software ANSYS is employed to construct a three-dimensional (3d) space finite element model under hydraulic test loading. And then theoretically calculated and measured values are compared and a good agreement between them is achieved.},
  doi       = {10.1109/ICMT.2011.6003255},
  keywords  = {crude oil;finite element analysis;fuel storage;internal stresses;mechanical testing;optical fibres;stress analysis;tanks (containers);walls;welding;3D space finite element model;China;big fillet weld;bottom board;crude oil tank;finite element analysis;hydraulic test loading;large crude oil storage tank;manhole;optical fiber strain test;software ANSYS;static resistance strain test;stress distribution;stress test;tank design;wall board;water filling test;Finite element methods;Floors;Fuel storage;Solid modeling;Strain;Stress;Welding;finite element analysis (FEA);oil tank;stress test},
}

@InProceedings{Palacios1990,
  author    = {H. Palacios and D. Rodriguez and J. Castro and V. Gomez and J. Jorquera and T. Magdhal},
  title     = {Signal averaging in stress test and Holter systems},
  booktitle = {Proceedings of the 1990 IEEE Colloquium in South America},
  year      = {1990},
  pages     = {16-21},
  abstract  = {A signal averaging technique is presented as a high quality alternative for filtering and cleaning ECG signals. A basic mathematical approach is first presented, with emphasis on the bandwidth reduction due to imperfect synchronism, when the QRS complex and R wave peak are used for synchronizing and alignment. A very reliable method is presented, especially designed for noisy ECG signals; in this method several thresholds are generated, based on the history of the successive cycles; thresholds for the amplitude of high pass filtered ECG signals and their first derivatives are generated in an adaptive and stable way. Finally, results are shown for several typical cases, including static averaging and dynamic real-time averaging},
  doi       = {10.1109/COLLOQ.1990.152786},
  keywords  = {electrocardiography;patient monitoring;signal processing;Holter systems;QRS complex;R wave peak;amplitude thresholds;bandwidth reduction;cleaning ECG signals;dynamic real-time averaging;electrocardiograms;imperfect synchronism;noisy ECG signals;signal averaging technique;static averaging;stress test;Bandwidth;Cleaning;Electrocardiography;Filtering;Noise generators;Noise level;Signal design;Signal generators;Stress;System testing},
}

@Article{Dougherty1981a,
  author   = {J. W. Dougherty and S. H. Minnich},
  title    = {Finite Element Modeling of Large Turbine Generators; Calculations Versus Load Test Data},
  journal  = {IEEE Transactions on Power Apparatus and Systems},
  year     = {1981},
  volume   = {PAS-100},
  number   = {8},
  pages    = {3921-3929},
  month    = {Aug},
  issn     = {0018-9510},
  abstract = {In support of EPRI Program 1288-1, Improvement in Accuracy of Prediction of Electrical Machine Constants, generator parameters at load have been calculated by the finite element method, in two dimensions. These calculated parameters are compared with test data obtained under EPRI Program RP 997-2, Determination of Synchronous Machine Stability Study Constants. An iterative procedure was used to match the calculated terminal voltage with the test value, for a given armature current and power factor. The test/calculated values for field current, the various angles, and Xq are then compared. Good agreement in all the above parameters is obtained for six diverse load points. Reactances are also compared. Considerable saturation effect is found, and is confirmed by test data in the case of X4. The results of this systematic comparison are judged to be a confirmation of the power of the finite element method.},
  doi      = {10.1109/TPAS.1981.316987},
  keywords = {Accuracy;Finite element methods;Personnel;Power measurement;Reactive power;Stability;Synchronous machines;System testing;Turbines;Voltage},
}

@InProceedings{Vlastaras2015,
  author    = {D. Vlastaras and S. Malkowsky and F. Tufvesson},
  title     = {Stress Test of Vehicular Communication Transceivers Using Software Defined Radio},
  booktitle = {2015 IEEE 81st Vehicular Technology Conference (VTC Spring)},
  year      = {2015},
  pages     = {1-4},
  month     = {May},
  abstract  = {Wireless vehicular communication is, in contrast to other terrestrial types of wireless communications, more dynamic in nature. Both the transmitter and the receiver are moving at high speeds relative to each other, which generates highly dynamic wireless channels. Such channels are characterized by short stationarity regions and large Doppler spreads. Modem manufacturers face a challenge when designing and implementing equipment for such environments. Similarly, for testing and evaluation real-life measurements with vehicles are required, which often is an expensive and slow process. This paper tackles this problem by proposing a method for stress testing transceivers based on the design and implementation of a real-time wireless channel emulator for wireless vehicular communications using a software defined radio (SDR). The emulator together with the proposed test methodology enable quick on-bench evaluation of wireless modems. In the paper we also apply the test on two different IEEE 802.11p modem implementations and characterize the packet error rate performance for different Doppler-delay combinations.},
  doi       = {10.1109/VTCSpring.2015.7146111},
  issn      = {1550-2252},
  keywords  = {modems;software radio;transceivers;wireless LAN;wireless channels;Doppler-delay combinations;IEEE 802.11p modem implementations;packet error rate performance;real-time wireless channel emulator;software defined radio;stress testing transceivers;vehicular communication transceivers;wireless modems;wireless vehicular communications;Ad hoc networks;Delays;Doppler shift;Error analysis;Modems;Stress;Wireless communication},
}

@InProceedings{Kennel2002,
  author    = {R. Kennel and G. Nicastro and R. Roesner and R. Rohlfing},
  title     = {High performance test equipment for 12 V and 42 V automotive components},
  booktitle = {IEEE 2002 28th Annual Conference of the Industrial Electronics Society. IECON 02},
  year      = {2002},
  volume    = {3},
  pages     = {1746-1751 vol.3},
  month     = {Nov},
  abstract  = {Many industrial branches refer to officially defined standards or recommendations concerning their products. Companies of automotive industry, however, define their own technical requirements. As a consequence technical issues like quality of voltage in vehicle power supply systems are different between the companies. A test generator coping with the requirements of most automotive companies at the same time is not available in the market so far. Consequently automotive suppliers use different test equipment depending on the respective customer. A power function generator for testing of 12 V and 42 V components was developed as a co-operation project between university and industry. The generator is able to feed supply currents of 30 A. The output voltage shape can be defined with a high degree of freedom and is repeated cyclically. Voltage rise times of 3 μs and short time voltage drops and/or voltage interrupts can be produced. Of course, slow rise and decrease of the voltage can be realized as well. Additional oscillations of 100 kHz can be superposed to the output voltage. These features make the "voltage ripple generator" superior to commercial products available on market today.},
  doi       = {10.1109/IECON.2002.1185234},
  keywords  = {automotive electronics;electromagnetic compatibility;electronic equipment testing;immunity testing;power supplies to apparatus;test equipment;100 kHz;12 V;3 mus;30 A;42 V;EMC testing;automotive companies;automotive components;automotive industry;co-operation project;high performance test equipment;power function generator;short time voltage drops;supply currents;technical issues;technical requirements;test generator;vehicle power supply systems;voltage interrupts;voltage quality;voltage ripple generator;voltage rise times;Automotive components;Automotive engineering;Electricity supply industry;Feeds;Power supplies;Signal generators;Test equipment;Testing;Vehicles;Voltage},
}

@InProceedings{Yun2009,
  author    = {S. Yun and S. Sung and Y. J. Lee},
  title     = {Design and performance test of relative navigation of a low cost inertial SLAM},
  booktitle = {2009 ICCAS-SICE},
  year      = {2009},
  pages     = {4217-4221},
  month     = {Aug},
  abstract  = {Despite its precise positioning performance, a GPS based navigation system may require the reference or augmentation station in close boundaries and is liable to be affected by satellite observation environments. Thus, this paper presents an INS/vision sensor integrated system, which in principle uses purely unknown feature points in previous epochs in order to cope with the limited GPS/INS integration environment. For the implementation of three-dimensional navigation using feature points, the presented system takes advantage of a robust image extraction and tracking algorithm, data association, and inertial SLAM filter algorithm. Finally, experimental results verified the performance of integrated navigation system, through which the performance enhancement in estimating relative position of the vehicle is demonstrated effectively.},
  keywords  = {SLAM (robots);feature extraction;helicopters;inertial navigation;mobile robots;particle filtering (numerical methods);path planning;remotely operated vehicles;robot vision;sensor fusion;INS-vision sensor integrated system;UAV;data association;distributed particle filter;image extraction;inertial SLAM filter algorithm;integrated navigation system;relative navigation;three-dimensional navigation;tracking algorithm;vision-based inertial system;Costs;Data mining;Filters;Global Positioning System;Machine vision;Robustness;Satellite navigation systems;Sensor systems;Simultaneous localization and mapping;Testing;GPS/INS;SLAM;integrated navigation;positioning;vision sensor},
}

@InProceedings{Chen2016,
  author    = {Q. Chen and Run Hu and Bin Xie and Xingjian Yu and Jingjing Cheng and X. Luo},
  title     = {Effect study of silicone amount on the lumen maintenance of high power LED under accelerated stress test},
  booktitle = {2016 15th IEEE Intersociety Conference on Thermal and Thermomechanical Phenomena in Electronic Systems (ITherm)},
  year      = {2016},
  pages     = {836-840},
  month     = {May},
  abstract  = {In our previous study, we investigated the effects of different packaging materials (silicone and phosphor layer) on the reliability of high power light-emitting diodes (HPLEDs) by highly accelerated stress test (HAST). The experimental results showed that the LED samples' lumen maintenance property might have dependence on the silicone amount in the package. In this paper, we further studied the effect of silicone amount on the lumen maintenance under HAST. Five categories of LED specimens specified by silicone amount were prepared and subjected to an isothermal chamber whose temperature was set at 125 °C. An online testing system was used to monitor and record the light outputs in real time during the experimental process. After 400 hours of aging, the largest attenuating range reached 6.17% and different groups display different degradation behaviors. An exponential decay model was adopted to calculate the decay rate of each lumen maintenance curve. The decay rate differs as the silicone amount inside the package modules changes. This phenomenon is well explained and Monte Carlo ray-tracing simulations are carried out to validate the explanation. The interaction effect of both silicone amount and temperature is also found and more researches need to be done for further study.},
  doi       = {10.1109/ITHERM.2016.7517633},
  issn      = {1087-9870},
  keywords  = {Monte Carlo methods;life testing;light emitting diodes;maintenance engineering;ray tracing;silicones;HAST;HPLED reliability;Monte Carlo ray tracing simulation;high power LED lumen maintenance;high power light emitting diode reliability;highly accelerated stress test;isothermal chamber;online testing system;package module;silicone amount effect;Aging;Degradation;Light emitting diodes;Maintenance engineering;Reliability;Temperature measurement;Testing;Light-emitting diode (LED);Online testing system;Reliability;Silicone amount},
}

@InProceedings{Eom2015,
  author    = {D. Y. Eom and S. L. Hong and C. H. Kim and S. J. Roh and J. D. Kong and K. R. Park},
  title     = {The power characteristic results according to the superconducting magnet coil load test of the motor generator system},
  booktitle = {2015 IEEE 26th Symposium on Fusion Engineering (SOFE)},
  year      = {2015},
  pages     = {1-5},
  month     = {May},
  abstract  = {When the poloidal field (PF) magnet power supplies (MPS) of 11 units are operated, max power of 200 MVA is required to achieve long pulse operation of Korea Superconducting Tokamak Advanced Research (KSTAR). Motor Generator (MG) system was installed to resolve power shortage because the available grid power is only 100 MVA at the National Fusion Research Institute (NFRI) site. MG system is composed of mechanical devices (stator, rotor, bearings, etc.), power control devices (VVVF, exciter), power facilities (transformers, switchboard, UPS, filter, dynamic brake, etc.), utilities (cooling water pump, heat exchangers, cooling fans, oil circulation pump, mechanical brake, etc.) and control system. MG system supplies power to the PF MPS of 11 units. And we configure the Reactive Power Compensator (RPC) & Harmonic Filter (HF) system to stabilize the MG power system. After installing the MG system, individual tests and dummy coil tests were conducted to determine the safety and performance of MG system. And we completed the commissioning of the MG system by carrying out the superconducting magnet coil load test for 2014 KSTAR experiment. MG system was operated up to 150 MVA of PF MPS with RPC & HF system. And the maximum operating duration was about 100 seconds. In this paper, we discuss about the power characteristic results of the MG system according to the superconducting magnet coil load test.},
  doi       = {10.1109/SOFE.2015.7482394},
  keywords  = {Tokamak devices;plasma toroidal confinement;superconducting coils;superconducting magnets;2014 KSTAR experiment;Korea Superconducting Tokamak Advanced Research;NFRI;National Fusion Research Institute;RPC;control system;dummy coil tests;grid power;harmonic filter system;mechanical devices;motor generator system;poloidal field magnet power supplies;power control devices;power facilities;reactive power compensator;superconducting magnet coil load test;Fluctuations;Generators;Power system stability;Reactive power;Superconducting magnets;Voltage control;Voltage measurement;KSTAR;motor generator system;power system},
}

@InProceedings{Yueksel2015,
  author    = {M. Yüksel and S. Losch and S. Kroffke and M. Rohn and F. Kirchner},
  title     = {BLDC wheel hub motor and motor controller performance test of a concept electric robotic vehicle in HIL according to real driving characteristics},
  booktitle = {2015 9th International Conference on Electrical and Electronics Engineering (ELECO)},
  year      = {2015},
  pages     = {613-617},
  month     = {Nov},
  abstract  = {In this paper we are presenting a method, which is developed as a part of our framework for designing complex robotic vehicle systems, to test a power train of a robotic concept car according to the real driving characteristic from telemetry data gathered from a subset of a pilot electric vehicle fleet in northern Germany in Hardware-in-the-Loop. Our aim is to investigate the driving performance of our modified BLDC wheel hub motor and its motorcontroller under urban area traffic conditions.},
  doi       = {10.1109/ELECO.2015.7394578},
  keywords  = {automobiles;brushless DC motors;control engineering computing;electric vehicles;machine control;mechanical engineering computing;mechanical testing;mobile robots;power transmission (mechanical);telemetry;vehicle dynamics;BLDC wheel hub motor;HIL;complex robotic vehicle systems;concept electric robotic vehicle;hardware-in-the-loop;motor controller performance test;northern Germany;power train test;telemetry data;urban area traffic conditions;Brushless DC motors;Robots;Torque;Vehicles;Wheels},
}

@InProceedings{Moghadam2015,
  author    = {M. Moghadam and M. H. Moradi},
  title     = {Systolic and diastolic blood pressure estimation during exercise stress test using GK-MARS fuzzy function approach},
  booktitle = {2015 23rd Iranian Conference on Electrical Engineering},
  year      = {2015},
  pages     = {109-114},
  month     = {May},
  abstract  = {Exercise test is a screening test which is used to investigate and diagnosis cardiovascular disease. Measuring Blood Pressure (BP) during exercise test is an important issue. Because an individual experiences a great amount of physical stress and the vital signs should be carefully monitored. Using cuff and barometer leads to low accuracy of measuring BP. Moreover, vessel crush encounters the continuous measurements with crucial limitations. Hence, measuring systolic and diastolic BP values with desired accuracy in a cuff-less approach is of challenges in this context. This could be achieved by using features extracted from ECG and PPG signals. BP is highly correlated with parameters such as PTT and HR, but not necessarily linear. The correlation could be nonlinear, multimode and vague. Therefore, using intelligent approaches could be very effective in such modeling issue. In this context, using Fuzzy Function (FF) technique is proposed in this paper. Gustafson-Kessel (GK) clustering method instead of the FCM, because of considering correlation between data points, and MARS, due to its great ability in multimode and nonlinear modeling, are used to produce the antecedent and consequence of the rules respectively. GK-MARS structure, especially in cases with limited datasets as this study, could be very effective. In order to evaluation, the performance of this structure in BP estimation is compared with other intelligent methods including GRNN, fuzzy systems based on GD and RLS training methods and other structures of FF. Results indicate better performance of FF with GK-MARS structure in satisfying AAMI (SP10) standard in systolic and diastolic BP estimation of all stages.},
  doi       = {10.1109/IranianCEE.2015.7146192},
  issn      = {2164-7054},
  keywords  = {blood pressure measurement;cardiovascular system;diseases;electrocardiography;fuzzy set theory;AAMI(SP10) standard;ECG signals;GD training methods;GK-MARS fuzzy function approach;GK-MARS structure;GRNN fuzzy systems;Gustafson-Kessel clustering method;PPG signals;RLS training methods;barometer;cardiovascular disease;diastolic blood pressure estimation;fuzzy function technique;intelligent methods;multimode nonlinear modeling;Conferences;Decision support systems;Electrical engineering;Phase shift keying;MAR S;blood pressure;estimation;exercise test;fuzzy function},
}

@InProceedings{Takahashi2002,
  author    = {N. Takahashi},
  title     = {IP traffic performance test for video system/43.5Gbps BERT system},
  booktitle = {Workshop on High Performance Switching and Routing, Merging Optical and IP Technologie},
  year      = {2002},
  pages     = {343-343},
  abstract  = {Not Available},
  doi       = {10.1109/HPSR.2002.1024625},
  keywords  = {Analytical models;Bit error rate;IP networks;Instruments;Marketing and sales;Monitoring;Performance evaluation;System testing;Telecommunication traffic;Traffic control},
}

@Article{Qian2010,
  author   = {J. Qian and P. Weng and J. Luo and Z. Chen and Y. Wu},
  title    = {Measurement System in Large-Scale Superconducting Magnet Performance Test},
  journal  = {IEEE Transactions on Applied Superconductivity},
  year     = {2010},
  volume   = {20},
  number   = {5},
  pages    = {2312-2316},
  month    = {Oct},
  issn     = {1051-8223},
  abstract = {A cryogenic test facility for a superconducting magnet has been constructed at the Institute of Plasma Physics, Chinese Academy of Science. A measurement system was set up to obtain quench signals and parameters in the test program, such as cryogenic hydraulic performances and electromagnetic characteristics. Thirty superconducting magnets in the Experimental Advanced Superconducting Tokamak device and a number of other magnets have been tested in the test system successfully. The design of the measurement system is introduced from the point of view of engineering practice. The measurement method of some parameters is also discussed in detail. The highlight lies in type selection installation techniques and instrumentation of sensors.},
  doi      = {10.1109/TASC.2010.2053925},
  keywords = {cryogenics;displacement measurement;installation;measurement systems;sensors;superconducting magnets;advanced superconducting tokamak device;cryogenic hydraulic performances;cryogenic test facility;displacement measurement;electromagnetic characteristics;large-scale superconducting magnet;measurement system;quench signals;sensor instrumentation;type selection installation techniques;Cryogenics;Electromagnetic measurements;Large-scale systems;Nuclear and plasma sciences;Plasma devices;Plasma measurements;Plasma properties;Superconducting magnets;System testing;Test facilities;Data monitoring system;instrumentation;large-scale cryogenic test facility},
}

@InProceedings{Ruther2003,
  author    = {R. Ruther and G. Tamizh-Mani and J. del Cueto and J. Adelstein and A. A. Montenegro and B. von Roedern},
  title     = {Performance test of amorphous silicon modules in different climates: higher minimum operating temperatures lead to higher performance levels},
  booktitle = {3rd World Conference onPhotovoltaic Energy Conversion, 2003. Proceedings of},
  year      = {2003},
  volume    = {2},
  pages     = {2011-2014 Vol.2},
  month     = {May},
  abstract  = {To assess the performance of thin-film amorphous silicon (a-Si) devices operating in different climatic conditions, three identical sets of commercially available a-Si PV modules from five different manufacturers were simultaneously deployed outdoors in three sites with distinct climates (Arizona-USA, Colorado-USA and Florianopolis-Brazil) in a round robin exposure experiment. The four-year experiment aims to determine the light-induced degradation and stabilization characteristics of a-Si regarding specific history of exposure, and to monitor and compare degradation rates in different climates. We present results from the first year of measurements, showing that modules deployed at the site with the highest minimum operating temperature experienced the highest stabilized output level.},
  keywords  = {Staebler-Wronski effect;amorphous semiconductors;elemental semiconductors;modules;photovoltaic power systems;semiconductor thin films;silicon;solar power stations;thin film devices;Arizona;Brazil;Colorado;Florianopolis;Si;Staebler-Wronski effect;USA;amorphous silicon modules;climatic condition;degradation rate;light induced degradation;minimum operating temperatures;photovoltaic modules;round robin exposure experiment;solar power stations;stabilization properties;thin film amorphous silicon devices},
}

@InProceedings{Nho2004,
  author    = {Eui-Cheol Nho and In-Dong Kim and Tae-Won Chun and Heung-Geun Kim},
  title     = {Cost-effective power quality disturbance generator for the performance test of custom power devices},
  booktitle = {30th Annual Conference of IEEE Industrial Electronics Society, 2004. IECON 2004},
  year      = {2004},
  volume    = {2},
  pages     = {1606-1610 Vol. 2},
  month     = {Nov},
  abstract  = {This paper describes a new sag-swell generator for the test of custom power devices such as UPS, DVR, DSTATCOM, SSTS, etc. The proposed scheme has good features of simple structure, high reliability, wide range of voltage sag and swell variation, and easy control. Outage, harmonic distortion, notches, and voltage unbalance also can be generated. The operation principle of the proposed scheme is described and the characteristics are analyzed through simulation. The usefulness of the scheme is verified through experiments.},
  doi       = {10.1109/IECON.2004.1431821},
  keywords  = {harmonic distortion;power generation faults;power generation reliability;power supply quality;static VAr compensators;cost-effective power quality disturbance generator;custom power devices;harmonic distortion;performance test;sag-swell generator;voltage unbalance;Analytical models;Power generation;Power quality;Power system harmonics;Power system simulation;Power transformers;Testing;Uninterruptible power systems;Voltage control;Voltage fluctuations},
}

@InProceedings{Kim2017,
  author    = {Y. D. Kim and S. H. Jung and D. Y. Gu and H. K. Kim and C. H. Song},
  title     = {IoT Sensor Based Mobility Performance Test-Bed for Disaster Response Robots},
  booktitle = {2017 6th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)},
  year      = {2017},
  pages     = {990-991},
  month     = {July},
  abstract  = {Recently, thanks to development of advanced IoT technology, the disaster prevention service that helps to search and rescue survivors in the disaster site using robots and special equipment is greatly increased. The introduction of these advanced equipments will help to improve rescue operations within golden time and also ensure the safety of firefighters. However, the disaster environment is still very difficult to approach and pass through it due to collapses, obstacles and dangerous materials. In this paper, we design and implement a mobility performance evaluation test-bed which can overcome various risk situations where a robot and special equipment may encounter while driving and passing them. In addition, the test-bed adopts various Internet of Things (IoT) sensors in order to quantitatively evaluate the performance. The test-bed is consists of gaps, continuous ramp, crossing ramp, inclined planes, stairs, vertical climbing, narrow passage, pipe passage, water passage and etc. The level of difficulty for each track can be adjusted to provide a basis for the performance rating of the target robots.},
  doi       = {10.1109/IIAI-AAI.2017.32},
  keywords  = {Internet of Things;emergency management;emergency services;rescue robots;sensors;Internet;Internet of Things;IoT sensor based mobility performance evaluation test-bed;advanced IoT technology;dangerous materials;disaster environment;disaster prevention service;disaster response robots;performance rating;Fires;Rescue robots;Robot sensing systems;Standards;Wheels;Disaster Simulation;IoT sensors;Mobility Performance;Test-bed},
}

@Article{Okada1985,
  author   = {T. Okada and T. Nitta and T. Shintani},
  title    = {On-load test of the 20kVA superconducting generator},
  journal  = {IEEE Transactions on Magnetics},
  year     = {1985},
  volume   = {21},
  number   = {2},
  pages    = {668-671},
  month    = {Mar},
  issn     = {0018-9464},
  abstract = {The on-load tests are carried out on an experimental power system, where the 20 kVA superconducting synchronous generator is connected to the regional power system through reactors (artificial transmission lines). The cooling characteristics of the rotor, especially, the cold damper, are obtained. On the on-load tests, active power vs. reactive power, active power vs. load angle, field current vs. active power characteristics at the constant terminal voltage, and so on are obtained. The transient behavior of the generator for a small variation of the input power is obtained. A transient analysis for the above test was carried out. Good agreement between the measured and calculated values is confirmed. From the results, the characteristics of superconducting generators are compared with those of the conventional ones and discussed.},
  doi      = {10.1109/TMAG.1985.1063807},
  keywords = {Rotating machine testing;Superconducting rotating machines;Synchronous generators;Cooling;Inductors;Power system transients;Power systems;Power transmission lines;Reactive power;Rotors;Superconducting transmission lines;Synchronous generators;System testing},
}

@InProceedings{Akin2004,
  author    = {B. Akin and U. Orguner and A. Ersak},
  title     = {An experimental performance test of a derivative-free non-linear state observer designed for sensorless AC drives},
  booktitle = {Mechatronics, 2004. ICM '04. Proceedings of the IEEE International Conference on},
  year      = {2004},
  pages     = {432-438},
  month     = {June},
  abstract  = {In this paper, a new Kalman filtering technique, unscented Kalman filter (UKF) is utilized both experimentally and theoretically as a state estimation tool in field-oriented control (FOC) of sensorless AC drives. Using the advantages of this recent derivative-free nonlinear estimation tool, rotor speed and dq-axis fluxes of an induction motor are estimated only with the sensed stator currents and voltages information. In a previous study, simulations has shown that, UKF, whose several intrinsic properties suggest its use over EKF in highly nonlinear systems, has highly satisfactory rotor speed and flux estimates, which are the most critical states for FOC. In this new work, those simulation results are supported with experimental results.},
  doi       = {10.1109/ICMECH.2004.1364478},
  keywords  = {AC motor drives;Kalman filters;induction motors;machine vector control;nonlinear control systems;observers;Kalman filtering technique;experimental performance test;field-oriented control;induction motor;nonlinear state observer;nonlinear systems;sensed stator currents;sensorless AC drives;state estimation;unscented Kalman filter;Filtering;Induction motors;Kalman filters;Observers;Rotors;Sensorless control;State estimation;Stators;Testing;Voltage},
}

@InProceedings{Wang2013,
  author    = {Z. Wang and Z. Tong},
  title     = {The performance test of heat exchanger under low-temperature frosting conditions},
  booktitle = {Proceedings of the 2013 International Conference on Advanced Mechatronic Systems},
  year      = {2013},
  pages     = {286-289},
  month     = {Sept},
  abstract  = {The heat exchanger performance test bench under the frosting condition has been designed and structured, and the various parameters measuring instrument and sensor have been installed. The test bench consists of refrigeration cycle and air duct cycle which can simulate low temperature condition. With the assistance of C# programming language and .NET Framework, a multi-function remote measurement and control system is developed, which can be used for environmental simulation, data acquisition, display and data processing, real-time curve and video display. The performance test of heat exchanger under different conditions could be completed by the test system. The influence of external environment factors on the heat exchanger under frosting condition can be studied. This test system could provide more experimental reference and calculation basis for the study of heat exchanger under frosting condition at low temperature.},
  doi       = {10.1109/ICAMechS.2013.6681795},
  issn      = {2325-0682},
  keywords  = {C language;air conditioning;heat exchangers;ice;mechanical engineering computing;refrigeration;.NET Framework;C# programming language;air duct cycle;control system;data acquisition;data processing;environmental simulation;external environment factors;heat exchanger performance test;low-temperature frosting conditions;multifunction remote measurement;real-time curve display;refrigeration cycle;video display;Data models;Educational institutions;Heating;Temperature distribution;Temperature measurement;Heat exchanger;Low-temperature frosting;Performance test},
}

@InProceedings{Xiao2009,
  author    = {J. Xiao and H. Jiang and C. Tang and Y. Mo and J. Xie},
  title     = {Research on Dry Resistance Load Test of Diesel Locomotive for Energy Saving},
  booktitle = {2009 Asia-Pacific Power and Energy Engineering Conference},
  year      = {2009},
  pages     = {1-4},
  month     = {March},
  abstract  = {A method of dry resistance load test of diesel locomotive is introduced. The electric power generated by a dynamotor, which is driven by the diesel, is converted to DC and consumed on the dry resistances. As the heat dissipation of the resistances is about several thousand kilowatts, DC motor fans are used for air cooling the resistances. In order to save energy, the energy for driven the motor fans is come from the electric power of the DC power. A constant current speed regulating system for the motor fans is presented, which bases on a kind of high-power switch component (IGBT). The experimental results are discussed.},
  doi       = {10.1109/APPEEC.2009.4918682},
  issn      = {2157-4839},
  keywords  = {DC motors;cooling;diesel-electric locomotives;fans;DC motor fans;air cooling;constant current speed regulating system;diesel locomotive;dry resistance load test;dynamotor;energy saving;heat dissipation;high-power switch component;Cooling;DC generators;DC motors;Electric resistance;Fans;Insulated gate bipolar transistors;Power generation;Resistance heating;Switches;Testing},
}

@InProceedings{Dixon2016,
  author    = {J. Dixon and V. Rajamani and C. Bunting},
  title     = {Performance test of unmanned aerial systems communication links in a severe multipath environment},
  booktitle = {2016 IEEE International Symposium on Electromagnetic Compatibility (EMC)},
  year      = {2016},
  pages     = {862-867},
  month     = {July},
  abstract  = {This paper discusses the results of exploratory research in analyzing the electromagnetic compatibility (EMC) of commercially available radio frequency transceivers co-located within the chassis of an Unmanned Air System (UAS). Tests were performed on a UAS with multiple communication systems onboard encompassing frequency bands with center frequencies of 915 MHz, 2.4 GHz, and 5.8 GHz. These tests were performed in a normal operational environment a.k.a free space and also inside a multipath environment where the UAS was subjected to performance evaluation i.e. the status of the communication systems of the UAS were monitored while there is no external EM threat and also while applying an external EM field.},
  doi       = {10.1109/ISEMC.2016.7571763},
  keywords  = {aircraft communication;autonomous aerial vehicles;electromagnetic compatibility;radio links;radio transceivers;EMC;UAS;electromagnetic compatibility;external EM field;frequency 2.4 GHz;frequency 5.8 GHz;frequency 915 MHz;multipath environment;multiple communication systems;performance evaluation;performance test;radiofrequency transceivers;unmanned aerial system communication links;Decision support systems;Drones;Electromagnetic Compatibility (EMC);Electromagnetic Interference (EMI);Unmanned Air System (UAS);Unmanned Air Vehicle (UAV)},
}

@InProceedings{Lin2011,
  author    = {Z. Lin and Y. Liu and Y. Jia and Y. Zhang and T. Xia and Y. Liu and F. Wen},
  title     = {Dynamic performance test of single-phase phasor measurement units},
  booktitle = {2011 IEEE Power and Energy Society General Meeting},
  year      = {2011},
  pages     = {1-7},
  month     = {July},
  abstract  = {Wide area measurements are becoming the norm of power system monitoring, protection and control. Frequency monitoring network (FNET) is a low-cost, easily deployable system at 120V distribution level. The frequency disturbance recorder (FDR) is actually a single-phase phasor measurement unit (PMU) in the sense that it measures the voltage phase angle, amplitude, and frequency from a single-phase voltage source. This paper discussed a calibrating and dynamic testing procedure developed for assuring the quality and accuracy of FDRs. Voltage magnitude and angle are calibrated, and two types of dynamic performance test, step and ramp, are performed for verifying the dynamic performance of FDRs. A detailed FDR calibrating and testing case is given. The test results demonstrate that the quality and accuracy of FDRs can satisfy the requirement of wide area measurement system.},
  doi       = {10.1109/PES.2011.6039495},
  issn      = {1932-5517},
  keywords  = {calibration;phase measurement;power system control;power system measurement;power system protection;FDR;calibration;dynamic performance test;frequency disturbance recorder;frequency monitoring network;phasor measurement units;power system control;power system monitoring;power system protection;voltage 120 V;voltage magnitude;voltage source;wide area measurement system;Accuracy;Calibration;Frequency measurement;Phasor measurement units;Power system dynamics;Testing;Voltage measurement;Power system measurement;calibration;dynamic performance;frequency disturbance recorder;phasor measurement unit;wide area measurement system},
}

@InProceedings{Yun2010,
  author    = {S. Yun and B. J. Lee and Y. J. Lee and S. Sung},
  title     = {Real-time performance test of an vision-based inertial SLAM},
  booktitle = {ICCAS 2010},
  year      = {2010},
  pages     = {2423-2426},
  month     = {Oct},
  abstract  = {Despite its precise positioning performance, a GPS based navigation system may require the reference or augmentation station in close boundaries and is liable to be affected by satellite observation environments. Thus, this paper presents a vision-based inertial SLAM navigation system which can operate in a real-time manner and uses purely unknown feature points in order to cope with the limited GPS/INS integration environment. And real-time performance of the presented system is verified via indoor test.},
  doi       = {10.1109/ICCAS.2010.5670282},
  keywords  = {Global Positioning System;SLAM (robots);aerospace robotics;inertial navigation;real-time systems;robot vision;GPS based navigation system;GPS/INS integration environment;augmentation station;indoor test;positioning performance;real-time manner;real-time performance test;reference station;satellite observation environments;vision-based inertial SLAM navigation system;Estimation;Machine vision;Navigation;Real time systems;Simultaneous localization and mapping;Heterogeneous sensor integration;IMU;Real-Time;Relative positioning;Vision sensor},
}

@InProceedings{Mainardi1994,
  author    = {L. T. Mainardi and E. Petrucci and A. M. Bianchi and V. Balian and M. Bertinelli and M. Mainardi and S. Cerutti},
  title     = {Time-variant spectral analysis for the studying of transient ischemia during dipyridamole stress test},
  booktitle = {Computers in Cardiology 1994},
  year      = {1994},
  pages     = {13-16},
  month     = {Sep},
  abstract  = {The effects of dipyridamole and dipyridamole induced ischemia on the traditional spectral parameters of heart rate variability (HRV) were investigated in normal and coronary artery disease (CAD) patients, who underwent a dipyridamole echocardiography test (DET). The relevant spectral parameters (LF and NF powers, LF/HF ratio) were monitored on a beat-to-beat basis and their variations were linked to the different test epochs and the different pathological events as detected by echocardiographic and electrocardiographic changes. A recursive least square (RLS) identification algorithm was used to this purpose, which is able to track the dynamical changes in nonstationary signals. Spectral parameters were obtained by means of a pole-tracking algorithm which fulfils an efficient extraction of these parameters on a beat-to-beat basis. The estimated parameters allow one, to achieve more information on the autonomic nervous system (ANS) status during drug infusion and the correspondence with the induced ischemia},
  doi       = {10.1109/CIC.1994.470261},
  keywords  = {echocardiography;electrocardiography;medical signal processing;neurophysiology;spectral analysis;HRV;LF powers;LF/HF ratio;NF powers;autonomic nervous system;beat-to-beat basis;coronary artery disease;dipyridamole echocardiography test;dipyridamole induced ischemia;dipyridamole stress test;drug infusion;dynamical changes;electrocardiographic changes;heart rate variability;nonstationary signals;normal patients;pathological events;pole-tracking algorithm;recursive least square identification algorithm;spectral parameters;time-variant spectral analysis;transient ischemia;Coronary arteriosclerosis;Echocardiography;Hafnium;Heart rate variability;Ischemic pain;Noise measurement;Patient monitoring;Spectral analysis;Testing;Transient analysis},
}

@InProceedings{Roberts1997,
  author    = {D. C. Roberts and D. A. Grossman and O. Frieder and R. Bernstein and E. Bisfiop},
  title     = {Performance testing of communication protocols for three-tier computing: results for ICA and X window protocols},
  booktitle = {Proceedings of Sixth International Conference on Computer Communications and Networks},
  year      = {1997},
  pages     = {450-455},
  month     = {Sep},
  abstract  = {We present the results of performance tests to compare two protocols for three-tier computing using the Windows NT operating system. Three-tier computing features a data server for stored databases (Tier 1), an application server that runs applications (Tier 2), and a simple client program that runs on desktop machines that presents the user interface (Tier 3). Three protocols are available to communicate between Tier 2 and 3: intelligence computer architecture (ICA) with and without data compression, and X Window. We measured the performance of the three protocols in a multi-user environment in which we simulated the workload imposed by typical users. We found that, for Microsoft Office 97 and Lotus Notes applications, the X Window protocol uses approximately twice the network bandwidth of ICA, without compression. We also found that compressed ICA generates roughly one third less network traffic than uncompressed ICA at a cost of 20% of additional processor utilization},
  doi       = {10.1109/ICCCN.1997.623350},
  issn      = {1095-2055},
  keywords  = {client-server systems;computer architecture;data compression;network servers;performance evaluation;program testing;protocols;testing;ICA protocols;Lotus Notes applications;Microsoft Office 97;Tier 1;Tier 2;Tier 3;Windows NT operating system;X window protocols;application server;client program;communication protocols;data compression;data server;desktop machines;intelligence computer architecture;multi-user environment;network bandwidth;network traffic;performance testing;stored databases;three-tier computing;user interface;Application software;Computer architecture;Computer interfaces;Independent component analysis;Machine intelligence;Operating systems;Protocols;Spatial databases;System testing;User interfaces},
}

@InProceedings{Kiran2015,
  author    = {S. Kiran and A. Mohapatra and R. Swamy},
  title     = {Experiences in performance testing of web applications with Unified Authentication platform using Jmeter},
  booktitle = {2015 International Symposium on Technology Management and Emerging Technologies (ISTMET)},
  year      = {2015},
  pages     = {74-78},
  month     = {Aug},
  abstract  = {Unified Authentication platform is a Single sign-on (SSO) mechanism which is integrated into Web applications to remove the necessity for multiple application-specific login credentials. Unified Authentication platform (UAP) is a unique platform developed by MIMOS with capability to support multiple authentication mechanism and can be integrated to any Web application to provide Single Sign On (SSO) solution. Performance testing of such web applications using UAP poses some unique challenges because the Jmeter script does not capture all the dynamic values, such as SAML Request, Relay State, Signature Algorithm, Authorization State, Cookie Time, Persistent ID (PID), JSession ID and Shibboleth, generated using single sign-on mechanism of Unified Authentication Platform. This paper explains some of the challenges & experiences to identify an appropriate solution for conducting performance testing on such web application.},
  doi       = {10.1109/ISTMET.2015.7359004},
  keywords  = {Internet;authorisation;program testing;software performance evaluation;Jmeter script;MIMOS;SSO mechanism;UAP;Web applications;performance testing;single sign-on mechanism;unified authentication platform;Authentication;Browsers;Computer architecture;Generators;MIMO;Servers;Testing;Jmeter;Performance Testing;Single Sign-On;Unified Authentication Platform},
}

@InProceedings{Draheim2006a,
  author    = {D. Draheim and J. Grundy and J. Hosking and C. Lutteroth and G. Weber},
  title     = {Realistic load testing of Web applications},
  booktitle = {Conference on Software Maintenance and Reengineering (CSMR'06)},
  year      = {2006},
  pages     = {11 pp.-70},
  month     = {March},
  abstract  = {We present a new approach for performing load testing of Web applications by simulating realistic user behaviour with stochastic form-oriented analysis models. Realism in the simulation of user behaviour is necessary in order to achieve valid testing results. In contrast to many other user models, Web site navigation and time delay are modelled stochastically. The models can be constructed from sample data and can take into account effects of session history on user behaviour and the existence of different categories of users. The approach is implemented in an existing architecture modelling and performance evaluation tool and is integrated with existing methods for forward and reverse engineering},
  doi       = {10.1109/CSMR.2006.43},
  issn      = {1534-5351},
  keywords  = {Web sites;delays;human factors;resource allocation;reverse engineering;software architecture;software performance evaluation;stochastic processes;Web application;Web site navigation;architecture modelling;forward engineering;load testing;performance evaluation tool;reverse engineering;stochastic form-oriented analysis models;time delay;user behaviour;Analytical models;Application software;Computational modeling;Computer science;Delay effects;Navigation;Performance evaluation;Software testing;Software tools;Stochastic processes},
}

@InProceedings{Kamra2012,
  author    = {M. Kamra and R. Manna},
  title     = {Performance of Cloud-Based Scalability and Load with an Automation Testing Tool in Virtual World},
  booktitle = {2012 IEEE Eighth World Congress on Services},
  year      = {2012},
  pages     = {57-64},
  month     = {June},
  abstract  = {The development in cloud computing provides limitless capacity which provides opportunity to evaluate an application performance based on its nature to scale. This paper aims at the analysis of Performance using the Google App Engine(cloud computing paradigm). Virtual Office application is chosen as example to perform experiment of testing the scalability in turn maintaining the performance. An Automation Testing Tool - Test Harness has been used to perform the scale testing of the application while being deployed on the cloud. Results have seen shown in the form of request type and response times(Average time taken/request). Taken into account the consideration that when the application load goes up the Google Cloud expands(increases instance hours) without affecting the running application.},
  doi       = {10.1109/SERVICES.2012.54},
  issn      = {2378-3818},
  keywords  = {Web sites;cloud computing;program testing;software performance evaluation;Google App Engine;application performance;automation testing tool;cloud computing;cloud-based scalability;scale testing;test harness;virtual office application;virtual world;Automation;Cloud computing;Google;Scalability;Servers;Teleworking;Testing;API;CPU;GAE;QPS},
}

@InProceedings{Tang2008,
  author    = {Jingfan Tang and Xiaohua Cao and A. Ma},
  title     = {Towards adaptive framework of keyword driven automation testing},
  booktitle = {2008 IEEE International Conference on Automation and Logistics},
  year      = {2008},
  pages     = {1631-1636},
  month     = {Sept},
  abstract  = {This paper presents an adaptive framework of keyword-driven automation testing to support the conversion of the keyword-based test cases into different kinds of test scripts automatically to be executed by different test applications under different test environments (such as GUI environment, database environment, etc.). XML is used to describe the keyword-based commands for the test case. An engine is provided in this framework to parse the XML file and dispatch the command sequences to the different test drivers according to the driver type pre-defined in the command. The test driver is responsible for dispatching the commands to the corresponding test applications to generate the test scripts automatically according to the keywords in the commands. The test scripts will be executed by the test applications on the system-under-test under different test environments. All the test results will be recorded into a log repository for generating all kinds of the test reports.},
  doi       = {10.1109/ICAL.2008.4636415},
  issn      = {2161-8151},
  keywords  = {XML;program compilers;program testing;XML file parsing;adaptive framework;automation engine layer;keyword driven automation testing;keyword-based command sequence;keyword-based test case conversion;log repository;test driver layer;test execution layer;test report;test script;Application software;Automatic testing;Databases;Educational institutions;Graphical user interfaces;Logistics;Robotics and automation;Software testing;System testing;XML;Keyword Driven;adaptive;automation testing},
}

@InProceedings{Yan2017,
  author    = {B. Yan and D. Teng and L. Liu and G. Wang},
  title     = {The degradation behaviors of white LEDs under highly accelerated stress testing (HAST)},
  booktitle = {2017 18th International Conference on Electronic Packaging Technology (ICEPT)},
  year      = {2017},
  pages     = {759-763},
  month     = {Aug},
  abstract  = {Reliability of GaN-based LEDs is attracting researchers to engage in actively. At present, evaluating the lifetime of GaN-based LEDs in a short testing duration is still open question. Thermal and humidity stresses are two main environmental stresses that LED products will suffer infield applications. At the level of devices, LEDs are non-sensitive to vibration. In order to evaluate the reliabilities (including the lifetime and failure rate)of white LED devices in a short period, highly accelerated stress testing (HAST) method is attempted boldly in the present paper. A series of HAST conditions are designing through different combinations of thermal, electrical and humidity stresses. The temperatures fixed at 120°C, the biased currents vary between 20mA-350mA, and the humidities vary between 65%RH-95%RH, which imply the pressure inside the furnace is high than 1atm. The forward voltage and light intensity are monitored in-situ with a time step of 1min. Preliminary results indicate that the white LED devices' lifetime of L70 obeys Gaussian distribution under HAST humidity conditions, while the L70 lifetime obeys Inverse power distribution with the injection current density variation. Based on the Arrhenius equation, Inverse power law equation and Gauss equation, the copula acceleration model equation is established with respect to thermal, electrical and humidity stresses. As an example, under the condition of 20mA&85%RH&120°C the accelerating factor is estimated as 118.0 and 109.2. The general lifetime of L70 for white LED devices are estimated as 16926.9h and 5722.5h, respectively.},
  doi       = {10.1109/ICEPT.2017.8046559},
  keywords  = {Gaussian distribution;III-V semiconductors;LED displays;gallium compounds;life testing;thermal stresses;wide band gap semiconductors;Arrhenius equation;GaN;Gauss equation;Gaussian distribution;HAST conditions;L70 lifetime;copula acceleration model equation;degradation behaviors;environmental stresses;failure rate;highly accelerated stress testing;humidity conditions;humidity stresses;injection current density variation;inverse power distribution;inverse power law equation;lifetime rate;temperature 120 degC;thermal stresses;white LED;Gallium;Humidity measurement;Ions;RNA;Stress;Urban areas;Vibrations;Accelerating factor;Copula acceleration model;HAST},
}

@InProceedings{Fahmi2017,
  author    = {F. Z. Fahmi and M. Abdurohman},
  title     = {Performance testing of M2M middleware platform},
  booktitle = {2017 3rd International Conference on Science in Information Technology (ICSITech)},
  year      = {2017},
  pages     = {378-382},
  month     = {Oct},
  abstract  = {Machine to Machine Communication (M2M) is an enabler of Internet of Things (IoT) ecosystem. One of representative implemetation of M2M middleware platform is OpenMTC based on 3gpp standard. OpenMTC is horisontal M2M Platform that connect sensors and devices to user application. It support scalability by providing gateway capability layer for connecting to sensors and devices and network capability layar for supporting user application. This platform will handle large data from hundreds to thousands of sensors and devices and send the data to the suitable application. This paper has tested OpenMTC platform performance regarding its capability to handle large data. Utility and response time are measured parameters of middleware server performance. The result shows that server utilization increases when the number of nodes is less than 30. The utilization of the server shows a constant value of 70% when the number of nodes over 30. Response time to increase in line with the increase of node number. Response time is still on target while the number of nodes is less than 30.},
  doi       = {10.1109/ICSITech.2017.8257142},
  keywords  = {3G mobile communication;Internet of Things;machine-to-machine communication;middleware;mobile computing;3gpp standard;Internet of Things ecosystem;IoT ecosystem;M2M middleware platform;OpenMTC platform performance;gateway capability layer;machine to machine communication;middleware server performance;network capability layar;response time;Machine-to-machine communications;Monitoring;Sensors;Servers;Stability criteria;Stress;Testing;M2M;middleware;openMTC;performance test;stability},
}

@InProceedings{Putri2017,
  author    = {M. A. Putri and H. N. Hadi and F. Ramdani},
  title     = {Performance testing analysis on web application: Study case student admission web system},
  booktitle = {2017 International Conference on Sustainable Information Engineering and Technology (SIET)},
  year      = {2017},
  pages     = {1-5},
  month     = {Nov},
  abstract  = {Websites usage for universities selection entrance (admission) are most visited websites in daily activity, thus its performance is critical. The ability of web applications either to control or to process users' requests determines its reliability. Furthermore, those websites which process students admission in Universitas Brawijaya and Politeknik Negeri Malang certainly engage massive volume of data and information that requires the highest level of reliability. Therefore, there is absolutely needed appropriate testing performances to measure the level of a certain application based on reliability rate. This measurement is used to determine responses, throughput, capability, and system scalability upon workload given. This research has a contribution to present testing performance concepts, goals, targets, types, and tools of Apache JMeter which is engaged for web assessment including detects mistake and error that relates to application performance and helps to improve the level of application performance as expected.},
  doi       = {10.1109/SIET.2017.8304099},
  keywords  = {Internet;Web services;Web sites;educational institutions;Politeknik Negeri Malang;Universitas Brawijaya;application performance;appropriate testing performances;daily activity;performance testing analysis;process students admission;reliability rate;student admission web system;system scalability;testing performance concepts;universities selection entrance;users;web application;websites usage;Computer science;Reliability;Servers;Software;Stress;Testing;Tools;jmeter;performance testing;testing;website},
}

@InProceedings{Duttagupta2011,
  author    = {S. Duttagupta and R. Mansharamani},
  title     = {Extrapolation tool for load testing results},
  booktitle = {2011 International Symposium on Performance Evaluation of Computer Telecommunication Systems},
  year      = {2011},
  pages     = {69-76},
  month     = {June},
  abstract  = {Load testing of IT applications is fraught with the challenges of time to market, quality of results, high cost of commercial tools, and accurately representing production like scenarios. It would help IT projects to be able to test with a small number of users and extrapolate to scenarios with much larger number of users. This in turn will cut down cycle times and costs and allow for a variety of extrapolations closer to production. We present a simple extrapolation technique based on statistical empirical modeling, which we have found to be more than 90% accurate across a range of applications running across a number of hardware servers. The technique has currently been validated for scenarios where the hardware is the bottleneck and is extensible to a wider range of scenarios as well.},
  keywords  = {extrapolation;program testing;statistical analysis;IT applications;IT projects;extrapolation tool;load testing results;statistical empirical modeling;Extrapolation;Linear regression;Load modeling;Servers;Testing;Throughput;Time factors;Extrapolation;S-Curves;load testing;regression},
}

@InProceedings{Parker1992,
  author    = {T. P. Parker and C. W. Webb},
  title     = {A study of failures identified during board level environmental stress testing},
  booktitle = {1992 Proceedings 42nd Electronic Components Technology Conference},
  year      = {1992},
  pages     = {177-184},
  month     = {May},
  abstract  = {AT&T has investigated and implemented environmental stress testing (EST) in the production of a variety of circuit board designs as a means of reducing the incidence of early life failures. EST techniques include thermal cycling, random vibration, and others. These techniques have proven more effective than traditional burn-in techniques. In addition, studies have revealed that functional monitoring during thermal stressing of circuit cards more than doubles the effectiveness of EST. Outgoing quality audits and customer first month failure rates have improved by factors of two to four since the implementation of EST},
  doi       = {10.1109/ECTC.1992.204204},
  keywords  = {environmental testing;failure analysis;life testing;printed circuit testing;production testing;EST techniques;board level environmental stress testing;circuit board designs;early life failures;first month failure rates;functional monitoring;random vibration;thermal cycling;Application software;Assembly;Circuit testing;Failure analysis;Life testing;Manufacturing processes;Printed circuits;Production;Thermal stresses;Total quality management},
}

@InProceedings{Chen2015,
  author    = {Xi Chen and Hao Guo and P. Crossley},
  title     = {Performance testing of IEC 61850 based architecture for UK National Grid standardised Substation automation solutions},
  booktitle = {2015 IEEE Power Energy Society General Meeting},
  year      = {2015},
  pages     = {1-5},
  month     = {July},
  abstract  = {Traditional protection and control systems in many UK National Grid Substations are reaching the end of their asset design life. This provides an opportunity to investigate whether new architecture that deploys Intelligent Electronic Device (IED) technology can deliver a reliable solution that is economically appropriate and delivers long life. The application of IEDs that utilize the IEC61850 based process bus reduces the life-time cost of the secondary systems and improves flexibility and functionality by accommodating high-speed peer-to-peer communications. The interconnectivity of devices on a single network offers significant benefits including a plug and play approach to future system changes. However, it requires interoperability among multi-vendor protection relays and control devices over an operating life of many decades. The realisation of this requires significant and detailed testing to help National Grid gain confidence in the use of these technologies. In this paper the substation architecture and the associated Power Networks are modelled in RTDS with faults applied at different locations on the transmission lines. The paper presents the results of interoperability tests involving multi-vendor Merging Unit (MU) and IED devices, which are then used to evaluate the functional performance of distance protection schemes.},
  doi       = {10.1109/PESGM.2015.7286553},
  issn      = {1932-5517},
  keywords  = {open systems;power grids;relay protection;substation automation;substation protection;IEC61850 based process bus;IED technology;RTDS;UK National Grid Standardised Substation automation solutions;asset design life;control devices;distance protection schemes;high-speed peer-to-peer communications;intelligent electronic device technology;interoperability tests;lifetime cost;multi-vendor merging unit;multi-vendor protection relays;plug and play approach;power networks;secondary systems;transmission lines;Circuit faults;IEC Standards;Interoperability;Merging;Substations;Tagging;IEC61850;Interoperability;Power System Reliability;Substation Automation;Substation Protection},
}

@InProceedings{Mahmoudi1997,
  author    = {R. Mahmoudi and J. L. Tauritz},
  title     = {Performance testing of the North American CDMA system, using an envelope simulator},
  booktitle = {Proceedings of 1997 Wireless Communications Conference},
  year      = {1997},
  pages     = {84-88},
  month     = {Aug},
  abstract  = {The growing use of spread spectrum techniques for personal communications (PCS) in Japan and USA is proving to be an enormous stimulus for the study of system impact on component design. New and innovative techniques are required to translate system criteria into component specifications. In this paper we have studied the performance of the “North American Digital Cellular IS-95” system proposed by QUALCOMM, under the influence of spurious signals using the new “Circuit Envelope Simulator” in HP-EESOF's Microwave Design System, MDS. The implemented functional blocks facilitate the generation of proper (noisy) CDMA (reverse and forward) signals, which are then used to program an arbitrary wave generator in order to create actual test signals. Additionally, these functional blocks can be replaced with equivalent circuits, consisting of passive and active elements, etc. For illustrative purposes, we discuss the application of these signals to two real amplifiers, one linear and one nonlinear. The measured results are critically compared with the simulation results},
  doi       = {10.1109/WCC.1997.622253},
  keywords  = {cellular radio;code division multiple access;digital radio;digital simulation;personal communication networks;spread spectrum communication;telecommunication equipment testing;Circuit Envelope Simulator;HP-EESOF's Microwave Design System;North American CDMA system;North American Digital Cellular IS-95;QUALCOMM;equivalent circuits;functional blocks;linear amplifiers;nonlinear amplifier;performance testing;personal communications;spread spectrum techniques;Circuit noise;Circuit simulation;Circuit testing;Multiaccess communication;Noise generators;Personal communication networks;Signal design;Signal generators;Spread spectrum communication;System testing},
}

@InProceedings{Yan2012,
  author    = {M. Yan and H. Sun and X. Wang and X. Liu},
  title     = {Building a TaaS Platform for Web Service Load Testing},
  booktitle = {2012 IEEE International Conference on Cluster Computing},
  year      = {2012},
  pages     = {576-579},
  month     = {Sept},
  abstract  = {Web services are widely known as the building blocks of typical service oriented applications. The performance of such an application system is mainly dependent on that of component web services. Thus the effective load testing of web services is of great importance to understand and improve the performance of a service oriented system. However, existing Web Service load testing tools ignore the real characteristics of the practical running environment of a web service, which leads to inaccurate test results. In this work, we present WS-TaaS, a load testing platform for web services, which enables load testing process to be as close as possible to the real running scenarios. In this way, we aim at providing testers with more accurate performance testing results than existing tools. WS-TaaS is developed on the basis of our existing Cloud PaaS platform: Service4All. First, we provide detailed analysis of the requirements of Web Service load testing and present the conceptual architecture and design of key components. Then we present the implementation details of WS-TaaS on the basis of Service4All. Finally, we perform a set of experiments based on the testing of real web services, and the experiments illustrate that WS-TaaS can efficiently facilitate the whole process of Web Service load testing.},
  doi       = {10.1109/CLUSTER.2012.20},
  issn      = {1552-5244},
  keywords  = {Web services;cloud computing;program testing;software tools;Cloud PaaS platform;Service4All;TaaS platform;WS-TaaS;Web service load testing tools;load testing platform;service oriented system;typical service oriented applications;Cloud computing;Computer architecture;Monitoring;Testing;cloud computing;load testing;testing as a service;web services},
}

@InProceedings{Xu2010a,
  author    = {L. Xu and W. Zhang and L. Chen},
  title     = {Modeling Users' Visiting Behaviors for Web Load Testing by Continuous Time Markov Chain},
  booktitle = {2010 Seventh Web Information Systems and Applications Conference},
  year      = {2010},
  pages     = {59-64},
  month     = {Aug},
  abstract  = {Virtual users with high quality are the preconditions to ensure the effect of load testing for Web applications. The existed tools for load testing usually generate virtual users with randomly choosing user sessions, manually generating user sessions or mining Log files, which causing such problems as non-real workload, subjectivity or difficult to update. Therefore we set each virtual user with a corresponding configure file, and these files determine the visiting paths, visiting moments and stay time of virtual users based on the Continuous Time Markov Chain. So we firstly finish the pretreatment for Log files, then construct the user visiting model, and next generate the virtual users, lastly carry out the load testing. In this way, we can obtain more reliable results for Web application load testing than the existed methods.},
  doi       = {10.1109/WISA.2010.47},
  keywords  = {Markov processes;Web services;data mining;program testing;virtual reality;Web load testing;continuous time Markov chain;log files mining;user visiting model;virtual users;Electromagnetic compatibility;Load modeling;Markov processes;Testing;Time factors;Web pages;Continuous Time Markov Chain;load testing;virtual user},
}

@InProceedings{Amirante2016,
  author    = {A. Amirante and T. Castaldi and L. Miniero and S. P. Romano},
  title     = {Jattack: a WebRTC load testing tool},
  booktitle = {2016 Principles, Systems and Applications of IP Telecommunications (IPTComm)},
  year      = {2016},
  pages     = {1-6},
  month     = {Oct},
  abstract  = {We present Jattack, an automated stressing tool for the analysis of the performance of WebRTC-enabled server-side components. Jattack has been initially conceived with the primary objective of performing a thorough scalability analysis of the well-known Janus WebRTC gateway. As such, it re-uses most of the Janus core stack components in order to reliably emulate the behavior of a dynamically adjustable number of WebRTC clients. The specific testing .scenario can indeed be programmatically reproduced by writing a small "controller" component, which takes on the responsibility of properly orchestrating the scenario itself. The general-purpose nature of the tool, together with its flexibility deriving from the controller-based programmable approach, makes Jattack also suitable for stress-testing other WebRTC-enabled servers.},
  keywords  = {Internet;program testing;Jattack;WebRTC load testing tool;WebRTC-enabled server-side components;automated stressing tool;stress-testing;Browsers;Media;Scalability;Servers;Stress;Testing;WebRTC},
}

@InProceedings{Barros2007,
  author    = {M. D. Barros and J. Shiau and C. Shang and K. Gidewall and H. Shi and J. Forsmann},
  title     = {Web Services Wind Tunnel: On Performance Testing Large-Scale Stateful Web Services},
  booktitle = {37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)},
  year      = {2007},
  pages     = {612-617},
  month     = {June},
  abstract  = {New versions of existing large-scale web services such as Passport.comcopy have to go through rigorous performance evaluations in order to ensure a high degree of availability. Performance testing (such as benchmarking, scalability, and capacity tests) of large-scale stateful systems in managed test environments has many different challenges, mainly related to the reproducibility of production conditions in live data centers. One of these challenges is creating a dataset in a test environment that mimics the actual dataset in production. Other challenges involve the characterization of load patterns in production based on log analysis and proper load simulation via reutilization of data from the existing dataset. The intent of this paper is to describe practical approaches to address some of the aforementioned challenges through the use of various novel techniques. For example, this paper discusses data sanitization, which is the alteration of large datasets in a controlled manner to obfuscate sensitive information, preserving data integrity, relationships, and data equivalence classes. This paper also provides techniques for load pattern characterization via the application of Markov chains to custom and generic logs, as well as general guidelines for the development of cache-based load simulation tools tailored for the performance evaluation of stateful systems.},
  doi       = {10.1109/DSN.2007.102},
  issn      = {1530-0889},
  keywords  = {Web services;program testing;security of data;software performance evaluation;Markov chains;Web services wind tunnel;cache-based load simulation tools;data integrity;data sanitization;log analysis;performance testing;Availability;Benchmark testing;Environmental management;Large-scale systems;Pattern analysis;Production systems;Reproducibility of results;Scalability;System testing;Web services},
}

@InProceedings{Rodrigues2015a,
  author    = {E. Rodrigues and M. Bernardino and L. Costa and A. Zorzo and F. Oliveira},
  title     = {PLeTsPerf - A Model-Based Performance Testing Tool},
  booktitle = {2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)},
  year      = {2015},
  pages     = {1-8},
  month     = {April},
  abstract  = {Performance testing is a highly specialized task, since it requires that a performance engineer knows the application to be tested, its usage profile, and the infrastructure where it will execute. Moreover, it requires that testing teams expend a considerable effort and time on its automation. In this paper, we present the PLeTsPerf, a model-based performance testing tool to support the automatic generation of scenarios and scripts from application models. PLetsPerf is a mature tool, developed in collaboration with an IT company, which has been used in several works, experimental studies and pilot studies. We present an example of use to demonstrate the process of generating test scripts and scenarios from UML models to test a Web application. We also present the lessons learned and discuss our conclusions about the use of the tool.},
  doi       = {10.1109/ICST.2015.7102628},
  issn      = {2159-4848},
  keywords  = {Internet;program testing;PLeTsPerf tool;UML model;Unified Modeling Language;Web application;model-based performance testing tool;scenario generation;script generation;Companies;Generators;Load modeling;Software;Testing;Unified modeling language;Visualization},
}

@InProceedings{Mercer2011,
  author    = {A. J. Mercer and R. K. James and G. Bennett and P. Patel and C. Johnston and J. Cai},
  title     = {Performance testing of RFID systems with RF-harsh materials},
  booktitle = {2011 IEEE International Conference on RFID-Technologies and Applications},
  year      = {2011},
  pages     = {537-543},
  month     = {Sept},
  abstract  = {Radio Frequency Identification (RFID) has been adopted to track items in supply chain, healthcare, and manufacturing applications. Hospitals and factories, however, are difficult environments for radiowave propagation. Cinder block walls with steel rebar, metal obstructions, and RF noise present significant obstacles to RFID system performance. Tagging lossy materials in these environments, such as metals and liquids, can also degrade the performance of RFID systems. In a previous paper [1] we simulated the RF-harsh conditions prevalent in these environments to evaluate UHF RFID system performance. In this paper, we utilize the same laboratory environment to measure RFID system performance when RF-harsh materials are tagged. These tests serve to examine the effect of water and plastic car parts on RFID system performance in an RF harsh environment. We show that the problems posed when tagging RF-harsh materials can be mitigated with either the strategic placement of tags on the item, or the careful choice of tags. While UHF RFID systems can be used in the presence of RF-harsh circumstances, the system architecture must be carefully tested in order to minimize the effects of performance-hindering RF obstacles.},
  doi       = {10.1109/RFID-TA.2011.6068597},
  keywords  = {radiofrequency identification;radiowave propagation;RF-harsh materials;UHF RFID system;performance testing;radio frequency identification;radiowave propagation;Antennas;Belts;Materials;Metals;Radio frequency;Radiofrequency identification;RFID;UHF (Ultra High Frequency);automotive materials;liquids;manufacturing;materials testing;multipath;performance evaluation;radio;radiowave propagation},
}

@InProceedings{Sidhu2011,
  author    = {T. Sidhu and M. Kanabar and P. Parikh},
  title     = {Configuration and performance testing of IEC 61850 GOOSE},
  booktitle = {2011 International Conference on Advanced Power System Automation and Protection},
  year      = {2011},
  volume    = {2},
  pages     = {1384-1389},
  month     = {Oct},
  abstract  = {The IEC 61850 standard part 8-1 proposes Generic Object Oriented Substation Event (GOOSE) message for time critical applications over the Ethernet network. In order to cover the wide range of applications and achieve flexibility in implementation, GOOSE messages are kept generic in the standard. However, this flexibility leads to configuration problem achieving multi-vendor interoperability. Therefore, some efforts have been carried out in this work to present a systematic GOOSE configuration approach, as well as, verification and performance testing of the GOOSE. First part of this paper configuration of Ethernet switched network, including IEEE 1588 based time synchronization, Rapid Spanning Tree Protocol (RSTP), and IEEE 802.1Q based Quality of Services (QoS). In the second part, the paper leads to step-by-step configuration process comprising IEC 61850 data modeling, datasets of GOOSE within individual IEDs, and system integration of GOOSE. Finally, the verification of configured GOOSE messages is presented using network analyzer tools, and performance testing time delay) over the network is carried out for various network scenarios.},
  doi       = {10.1109/APAP.2011.6180593},
  keywords  = {local area networks;object-oriented methods;open systems;power engineering computing;quality of service;substation automation;synchronisation;Ethernet switched network;IEC 61850 GOOSE performance testing;IEC 61850 data modeling;IEEE 1588 based time synchronization;IEEE 802.1Q based quality of services;QoS;RSTP;generic object oriented substation event message;multivendor interoperability;network analyzer tools;rapid spanning tree protocol;substation automation systems;systematic GOOSE configuration approach;Automation;Bridges;Data models;IEC standards;Power systems;Switches;Testing;Ethernet switched networks;GOOSE;IEC 61850;substation automation systems},
}

@InProceedings{Naheman2013,
  author    = {W. Naheman and Jianxin Wei},
  title     = {Review of NoSQL databases and performance testing on HBase},
  booktitle = {Proceedings 2013 International Conference on Mechatronic Sciences, Electric Engineering and Computer (MEC)},
  year      = {2013},
  pages     = {2304-2309},
  month     = {Dec},
  abstract  = {NoSQL (Not Only SQL) is the generic term of a kind of non-relational database products. This paper, firstly, lists the disadvantages of traditional relational databases, introduces NoSQL databases including their advantages, disadvantages and their application status. Then, a comparison is made between NoSQL databases and SQL database, also another comparison between different NoSQL products. Finally, we introduce the architecture and data model of HBase database, which is a representative of NoSQL databases, and did some performance tests on HBase database, including the column family test, the sort test, the random read/write test and the query test. Test results show that written and query speed of HBase is slow under a single machine environment, but can be significantly improved in multimachine cluster environment.},
  doi       = {10.1109/MEC.2013.6885425},
  keywords  = {SQL;data models;relational databases;software performance evaluation;HBase database;HBase performance testing;NoSQL databases;Not Only SQL database;SQL database;column family test;data model;machine cluster environment;nonrelational database products;query test;random read-write test;single machine environment;sort test;Availability;Blogs;Computer architecture;Distributed databases;Manuals;HBase;NoSQL databases;performance testing;relational database},
}

@InProceedings{Kreit2010,
  author    = {F. Kreit and G. Barberio and C. Subramanian and I. Kostanic and J. P. Pinelli},
  title     = {Performance Testing of the Wireless Sensor Network System for Hurricane Monitoring},
  booktitle = {2010 First International Conference on Sensor Device Technologies and Applications},
  year      = {2010},
  pages     = {63-72},
  month     = {July},
  abstract  = {A wireless pressure monitoring system was developed by Florida Institute of Technology to measure wind induced pressure on low-rise structures during hurricanes. This study presents tests made to evaluate the performance of the sensors and their ability to measure accurate pressure variations. To test the reliability of the pressure sensors, a series of tests were designed. The resulting measurements were then compared to secondary references. The measurements were also compared to the basic Bernoulli theory. Further, the wind tunnel measurement allowed for the development of the first comparative computational fluid dynamics simulation and experimental results. Due to the components packaging in the remote, the sensor case cannot be completely streamlined. The resulting shape caused some aerodynamic disturbances. In order to study the sensor shape's influence on the pressure measurements, different experiments were set up. Specifically, by using a roof shaped ramp model mounted on a van, a highway test was performed, allowing examination of the error caused by the sensor's shape. Another test was performed at the University of Florida Hurricane Simulator to study the gust (unsteady) effects. This test revealed that the sensors were sensitive to mechanical vibrations. The paper addresses the sensor network systems topic of the conference.},
  doi       = {10.1109/SENSORDEVICES.2010.19},
  keywords  = {atmospheric measuring apparatus;atmospheric pressure;computational fluid dynamics;geophysical fluid dynamics;pressure measurement;pressure sensors;storms;wind;wireless sensor networks;Bernoulli theory;Florida Institute of Technology;University of Florida Hurricane Simulator;comparative CFD simulation;computational fluid dynamics;hurricane monitoring;low rise structures;pressure variation measurement;roof shaped ramp model;sensor case shape;sensor performance;wind induced pressure;wind tunnel measurement;wireless pressure monitoring system;wireless sensor network performance testing;Atmospheric measurements;Electron tubes;Fluid flow measurement;Pressure measurement;Sea measurements;Semiconductor device measurement;Wind speed;Multi-sensors;Performance testing;Wireless network},
}

@InProceedings{Habul2008,
  author    = {A. Habul and E. Kurtovic},
  title     = {Load testing an AJAX application},
  booktitle = {ITI 2008 - 30th International Conference on Information Technology Interfaces},
  year      = {2008},
  pages     = {729-732},
  month     = {June},
  abstract  = {This paper presents a methodology for load testing an Ajax application. WebLOAD, an open source tool for performance testing, is used to simulate a huge number of client requests to the server. The load testing is used to evaluate and compare different scenarios on the system performance. In order to avoid misleading results, load testing of Ajax applications should incorporate not only server-side but also client-side code, because it can have a significant impact in determining the generated load.},
  doi       = {10.1109/ITI.2008.4588501},
  issn      = {1330-1012},
  keywords  = {Java;XML;performance evaluation;program testing;public domain software;AJAX;WebLOAD;client- side code;load testing;open source tool;performance testing;server-side code;Databases;Delay;Frequency;HTML;Java;Load modeling;Network servers;System performance;System testing;XML;Ajax;load testing;workload model},
}

@Article{Parker1992a,
  author   = {T. P. Parker and C. W. Webb},
  title    = {A study of failures identified during board level environmental stress testing},
  journal  = {IEEE Transactions on Components, Hybrids, and Manufacturing Technology},
  year     = {1992},
  volume   = {15},
  number   = {6},
  pages    = {1086-1092},
  month    = {Dec},
  issn     = {0148-6411},
  abstract = {AT&T has investigated and implemented environmental stress testing (EST) in the production of a variety of circuit board designs as a means of reducing the incidence of early life failures. EST techniques include thermal cycling (TC), random vibration, etc. These techniques have proven more effective than traditional burn-in techniques. In addition, studies have revealed that functional monitoring during thermal stressing of circuit cards more than doubles the effectiveness of EST. Outgoing quality audits and customer first month failure rates have improved by factors of two to four since the implementation of EST},
  doi      = {10.1109/33.206935},
  keywords = {environmental testing;failure analysis;life testing;printed circuit testing;quality control;AT&T;EST;board level environmental stress testing;burn-in techniques;circuit board designs;customer first month failure rates;early life failures;environmental stress testing;functional monitoring;outgoing quality audits;random vibration;study of failures;temperature cycling;thermal cycling;thermal stressing;Application software;Assembly;Circuit testing;Failure analysis;Human factors;Life testing;Manufacturing processes;Production;Thermal stresses;Total quality management},
}

@InProceedings{Gao2010a,
  author    = {T. Gao and Y. Ge and G. Wu and J. Ni},
  title     = {A Reactivity-based Framework of Automated Performance Testing for Web Applications},
  booktitle = {2010 Ninth International Symposium on Distributed Computing and Applications to Business, Engineering and Science},
  year      = {2010},
  pages     = {593-597},
  month     = {Aug},
  abstract  = {To improve the reliability and feasibility of web applications, performance testing is very important for satisfying users. For reducing the cost and improve the efficiency of performance testing, we propose a new reactivity-based performance testing framework in this paper. We also provide a complete approach to generate test cases automatically from original web logs. First our approach retrieves user patterns through logs at the server side. Then, metrics derived from users' perspective are applied and usage pattern from client side are gained. At last test case can be generated automatically by solving an optimization problem through an evolutionary algorithm.},
  doi       = {10.1109/DCABES.2010.127},
  keywords  = {Internet;automatic test pattern generation;client-server systems;evolutionary computation;performance evaluation;Web application;Web logs;automated reactivity-based performance testing framework;evolutionary algorithm;optimization problem;test case generation;user pattern retrieval;Load modeling;Measurement;Servers;Software;Testing;Time factors;Unified modeling language;automated test case generation;performance testing;testing framework;web applications},
}

@Article{Dhote2013,
  author   = {M. R. Dhote and G. G. Sarate},
  title    = {Performance Testing Complexity Analysis on Ajax-Based Web Applications},
  journal  = {IEEE Software},
  year     = {2013},
  volume   = {30},
  number   = {6},
  pages    = {70-74},
  month    = {Nov},
  issn     = {0740-7459},
  abstract = {The Ajax model of Web applications development has rapidly gained popularity because it promises to bring the richness and responsiveness of desktop applications to the Web. Ajax implementations differ fundamentally from other Web implementations - mainly in making asynchronous requests for parts of a Webpage. Techniques routinely used for performance testing traditional Web applications must be modified and enhanced to suit the needs of Ajax-based applications. Using a general example, the authors of this article examine the unique challenges of carrying out performance testing for Ajax-based applications and offer approaches and tools for overcoming them.},
  doi      = {10.1109/MS.2012.132},
  keywords = {Internet;program testing;software metrics;Ajax-based Web applications;Webpage;performance testing complexity analysis;Browsers;Complexity theory;Internet;Servers;Software measurement;Statistical analysis;Testing;Ajax;performance testing;performance testing and tools;software quality and testing;stress testing},
}

@InBook{Chan2001,
  pages     = {372-},
  title     = {Production AST with Computers Using the Taguchi Method - Reprinted from Environmental Stress Testing Experiment Using the Taguchi Method, IEEE Transactions on Components, Packaging, and Manufacturing Technology, Part A, Vol. 18, No.1, pp. 39, with permission from the author and the IEEE, 1995.},
  publisher = {Wiley-IEEE Press},
  year      = {2001},
  author    = {H. Anthony Chan},
  isbn      = {9780470544051},
  abstract  = {
Manufacturing process improvements which increase productivity, decrease test process time, and improve customer satisfaction are highly desirable in today's marketplace. The application of environmental stress screening (ESS), i.e, Production AST, is a method of achieving these improvements. ESS is the application of stresses applied beyond product specification limits in order to find latent product defects. Utilizing ESS achieves increased robustness and lowers infant mortality.

An experiment was performed to identify the significance or relevancy of the selected stresses for application in the printed wiring assembly (PWA) production process by using a statistically significant controlled method. The design of experiments statistical approach (analysis of variance) is applied, combined with the Taguchi two-level, seven-factor design method.

This experiment concentrated on three stresses?-?temperature cycling, random vibration, and power cyling?-?and two diagnostic levels?-?a prom-based (programmable memory chip), power-on self test (POST), and a functional diagnostic test suite, contained on disk storage.

This was not an optimization experiment. Once the significance to the production process is identified, future optimizing of temperature cycling, power cycling, and vibration screens will be conducted. Also, voltage margining was not included to reduce the complexity of the experiment-treatment factors and interactions. Experimental results and conclusions on the effectiveness of different stress regimens are presented in this chapter.

Introduction

Objectives

Stress Overview

Stress Screen Designs

Experiment Overview

The Taguchi Method

Response Variable Results and Conclusions of the Taguchi Experiment

< LI>
Intra-Experiment Summary

Taguchi Method Conclusion

Terms

Acknowledgments

References

},
  booktitle = {Accelerated Stress Testing Handbook:Guide for Achieving Quality Products},
  doi       = {10.1109/9780470544051.ch15},
  url       = {https://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5270481},
}

@InProceedings{Dong2016,
  author    = {L. Dong and X. Jing and Y. Chunhui},
  title     = {Study of Performance Testing of Information System Based on Domestic CPU and OS},
  booktitle = {2016 Third International Conference on Trustworthy Systems and their Applications (TSA)},
  year      = {2016},
  pages     = {112-116},
  month     = {Sept},
  abstract  = {In order to evaluate the performance of of information system based on domestic CPU and OS, through the introduction of the background of basic hardware and software based on domestic, we expound the domestic information system performance testing principle and method, according to the testing results of existing mature commercial performance testing tool LoadRunner can not reflect the user experience of time, and can not be directly used for testing the information system which based on domestic CPU/OS, this paper put forward the two kinds of testing schemes that base on user experience of LoadRunner and JMeter domestic information system performance test, and test two kinds of improved schemes, through the comparison of the test data and the user experience time of the two schemes, the variance of the test scheme based on JMeter is smaller than LoadRunner test scheme 70.49%. The results show that the test results of the JMeter scheme are more close to the user experience than LoadRunner.},
  doi       = {10.1109/TSA.2016.27},
  keywords  = {information systems;microprocessor chips;operating systems (computers);performance evaluation;JMeter domestic information system performance test;LoadRunner domestic information system performance test;OS;domestic CPU;domestic information system performance testing method;domestic information system performance testing principle;performance evaluation;Browsers;Hardware;Information systems;Operating systems;Rendering (computer graphics);Servers;Testing;JMeter test tool;LoadRunner test tool;domestic CPU;domestic infrastructure software;domistic Operating System(OS);information system;performance test},
}

@InProceedings{Yan2012a,
  author    = {M. Yan and H. Sun and X. Wang and X. Liu},
  title     = {WS-TaaS: A Testing as a Service Platform for Web Service Load Testing},
  booktitle = {2012 IEEE 18th International Conference on Parallel and Distributed Systems},
  year      = {2012},
  pages     = {456-463},
  month     = {Dec},
  abstract  = {Web services are widely known as the building blocks of typical service oriented applications. The performance of such an application system is mainly dependent on that of component web services. Thus the effective load testing of web services is of great importance to understand and improve the performance of a service oriented system. However, existing Web Service load testing tools ignore the real characteristics of the practical running environment of a web service, which leads to inaccurate test results. In this work, we present WS-TaaS, a load testing platform for web services, which enables load testing process to be as close as possible to the real running scenarios. In this way, we aim at providing testers with more accurate performance testing results than existing tools. WS-TaaS is developed on the basis of our existing Cloud PaaS platform: Service4All. First, we briefly introduce the functionalities and main components of Service4All. Second, we provide detailed analysis of the requirements of Web Service load testing and present the conceptual architecture and design of key components. Third, we present the implementation details of WS-TaaS on the basis of Service4All. Finally, we perform a set of experiments based on the testing of real web services, and the experiments illustrate that WS-TaaS can efficiently facilitate the whole process of Web Service load testing. Especially, comparing with existing testing tools, WS-TaaS can obtain more effective and accurate test results.},
  doi       = {10.1109/ICPADS.2012.69},
  issn      = {1521-9097},
  keywords  = {Web services;cloud computing;performance evaluation;program testing;service-oriented architecture;Service4All;WS-TaaS;Web service load testing tools;building blocks;cloud PaaS platform;component Web services;service oriented applications;service oriented system performance;testing as a service platform;Cloud computing;Monitoring;Runtime;Testing;cloud computing;load testing;testing as a service;web services},
}

@Article{Fang2018,
  author   = {P. Fang and X. Ma and X. Li and X. Qiu and R. Gerhard and X. Zhang and G. Li},
  title    = {Fabrication, Structure Characterization, and Performance Testing of Piezoelectret-Film Sensors for Recording Body Motion},
  journal  = {IEEE Sensors Journal},
  year     = {2018},
  volume   = {18},
  number   = {1},
  pages    = {401-412},
  month    = {Jan},
  issn     = {1530-437X},
  abstract = {During muscle contractions, radial-force distributions are generated on muscle surfaces due to muscle-volume changes, from which the corresponding body motions can be recorded by means of so-called force myography (FMG). Piezo-or ferroelectrets are flexible piezoelectric materials with attractive materials and sensing properties. In addition to several other applications, they are suitable for detecting force variations by means of wearable devices. In this paper, we prepared piezoelectrets from cellular polypropylene films by optimizing the fabrication procedures, and developed an FMG-recording system based on piezoelectret sensors. Different hand and wrist movements were successfully detected on able-bodied subjects with the FMG system. The FMG patterns were evaluated and identified by means of linear discriminant analysis and artificial neural network algorithms, and average motion-classification accuracies of 96.1% and 94.8%, respectively, were obtained. This paper demonstrates the feasibility of using piezoelectret-film sensors for FMG and may thus lead to alternative methods for detecting body motion and to related applications, e.g., in biomedical engineering or structural-health monitoring.},
  doi      = {10.1109/JSEN.2017.2766663},
  keywords = {biomedical measurement;biomedical transducers;cellular biophysics;computerised instrumentation;electrets;force measurement;force sensors;medical computing;motion measurement;muscle;neural nets;piezoelectric thin films;piezoelectric transducers;polymer films;polymer foams;recorders;thin film sensors;FMG-recording system;artificial neural network algorithm;biomedical engineering;body motion detection;body motion recording;cellular polypropylene film;ferroelectret;force myography;force sensor;linear discriminant analysis;muscle contraction;muscle surface generation;performance testing;piezoelectret-film sensor;piezoelectric material;radial-force distribution;structural-health monitoring;structure characterization;wearable device;Accelerometers;Dynamics;Electrodes;Films;Force;Muscles;Sensors;Forcemyography;film sensor;motion registration;piezoelectret;wearable},
}

@InProceedings{Knauss2012,
  author    = {J. P. H. Knauss and C. Warren and D. Kearns},
  title     = {An innovative approach to smart automation testing at National Grid},
  booktitle = {PES T D 2012},
  year      = {2012},
  pages     = {1-8},
  month     = {May},
  abstract  = {Upon completion of a successful Distribution Automation (DA) Pilot Project centered in National Grid's upstate New York service territory, it was determined that the reliability improvements delivered by the pilot demonstration justified a much more comprehensive effort to further evaluate additional Smart Grid technologies. The vision was to conduct experiments with a full suite of Smart Grid technologies including: AMI; Home Area Network and energy management systems; Automatic Fault Isolation & System Restoration; advanced feeder monitoring; distribution transformer monitoring; single pole tripping and Pulse Closing technology on distribution line reclosers; advanced capacitor control with independent pole operation; faulted circuit indicators with 2-way communication capability; and distribution fault locating capability. This vision came to be known as National Grid's Smart Grid Pilot proposal. Many challenges exist with such a comprehensive approach from public and personnel safety, to ensuring interoperability between devices and systems of different manufacture. In order to determine which technologies would provide the most benefit to National Grid's customer base, a means was needed to prequalify the various types of products available before large scale deployments were initiated. Looking at the large number of Smart Grid device suppliers, architectures and products available, we realized that the optimum solution would be to build a facility wherein a wide range of Smart Grid technologies could be installed and systematically put through their paces; i.e. actually tested in as near a real-world atmosphere as practical. Thus was born the National Grid “Smart Technology Centre” or STC. Soon thereafter, National Grid's Utility of the Future engineering team designed, engineered, and constructed a truly innovative test fixture that enabled system level testing on complex distribution networks to ensure process safety during field de- loyment. One of only a few known organizations in the U.S., National Grid has in-house capability to truly test and evaluate an end-to-end Smart distribution system architecture where systems such as automated fault isolation and system restoration can be evaluated. This paper will discuss interoperability testing that National Grid embarked upon to prepare for its proposed Smart Grid Pilot demonstration and will detail the lengths that were taken in creating a test site where medium voltage Smart Grid technologies could be fully evaluated to ensure that the various applications would play well with each other prior to actually being deployed in the field. Furthermore, this paper will focus on providing an overview of the system level testing and technical evaluation of distribution protection and control equipment with automated fault isolation and system restoration capabilities. It will also detail a number of lessons learned from this effort and discuss future plans for smart technology evaluation as a basis for an educational platform and workforce training tool.},
  doi       = {10.1109/TDC.2012.6281507},
  issn      = {2160-8555},
  keywords  = {automatic testing;control equipment;electrical safety;fault location;open systems;power distribution control;power distribution protection;power distribution reliability;power engineering computing;power system restoration;smart power grids;2-way communication capability;AMI;DA Pilot Project;National Grid;New York service territory;STC;Smart Technology Centre;advanced capacitor control;advanced feeder monitoring;automatic fault isolation;automatic system restoration;complex distribution network testing;control equipment;distribution automation;distribution fault locating capability;distribution line reclosers;distribution protection;distribution transformer monitoring;educational platform;end-to-end smart distribution system architecture;energy management systems;faulty circuit indicators;home area network;interoperability;large scale deployments;medium voltage smart grid technologies;personnel safety;process safety;public safety;pulse closing technology;reliability improvements;single pole tripping;smart automation testing;smart grid device suppliers;smart grid pilot demonstration;smart technology evaluation;system level testing;workforce training tool;Automation;Circuit faults;Control systems;Monitoring;Safety;Smart grids;Testing},
}

@InProceedings{Liu2010,
  author    = {Y. Liu and B. Du and S. Wang and H. Yang and X. Wang},
  title     = {Design and Implementation of Performance Testing Utility for RTSP Streaming Media Server},
  booktitle = {2010 First International Conference on Pervasive Computing, Signal Processing and Applications},
  year      = {2010},
  pages     = {193-196},
  month     = {Sept},
  abstract  = {RTSP has been widely used in a variety of streaming media applications and streaming service providers hope to choose a high-performance streaming media server to meet their needs, so it is an important research topic about how to evaluate the serving performance of RTSP streaming media server. This paper analyzes the performance metric of streaming media applications comprehensively, and proposes an approach to design and implement a Performance Testing Utility for RTSP Streaming Server. According to different stress test, the utility mainly evaluates a streaming server's performance in the case of delivering a large number of concurrent streams and quantifies the statistics of various performance metrics. The tool utilizes multi-thread mechanism to create multiple pseudo-terminal instances to simulate a certain number of concurrent users for sending RTSP signals, receives media flow by a special IP address, analyzes RTP packets, and counts the related performance metrics value of the server. Experiments validate the efficiency and accuracy of the tool.},
  doi       = {10.1109/PCSPA.2010.55},
  keywords  = {media streaming;multi-threading;multimedia servers;performance evaluation;protocols;IP address;RTP packets;RTSP streaming media server;multiple pseudo-terminal instances;multithread mechanism;performance metric;performance testing utility;real-time streaming protocol;streaming server performance evaluation;streaming service providers;Measurement;Media;Protocols;Real time systems;Servers;Streaming media;Testing;Concurrent streams;Media flow;Performance metrics;Streaming media server;Testing utility},
}

@InProceedings{Schloegl2016,
  author    = {F. Schloegl and M. Buescher and K. Diwold and S. Lehnhoff and L. Fischer and F. Zeilinger and T. Gawron-Deutsch},
  title     = {Performance testing Smart Grid applications using a distributed co-simulation approach},
  booktitle = {IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society},
  year      = {2016},
  pages     = {6305-6310},
  month     = {Oct},
  abstract  = {Co-simulation is an established approach for Smart Grid simulations as it allows to break down the very complex system into sub-systems. The modularity of co-simulation environments makes easy to distribute it across different sites. One reason for such a distribution may be, that this way confidential software can stay within its secure domain. However the transmission of data between the sites is time consuming. This paper demonstrates how Smart Grid applications can be tested using a co-simulation approach. It investigates the costs of such an approach by measuring the time required for data transmission in a case study.},
  doi       = {10.1109/IECON.2016.7793853},
  keywords  = {data communication;power system security;smart power grids;data transmission;distributed cosimulation;smart grid;Computational modeling;Data models;Hardware;Load modeling;Smart grids;Software;Topology},
}

@InProceedings{Zhou2014,
  author    = {J. Zhou and B. Zhou and S. Li},
  title     = {LTF: A Model-Based Load Testing Framework for Web Applications},
  booktitle = {2014 14th International Conference on Quality Software},
  year      = {2014},
  pages     = {154-163},
  month     = {Oct},
  abstract  = {Performance evaluation is an important approach for various systems to guarantee the quality of their services. However, most performance evaluation tasks face a problem: how to model the system workload? Traditional workload models have limitations when it comes to modeling different workloads. In this paper, we propose a workload model for characterizing and generating synthetic web workloads. First, we introduce a Context-based Sequential Action Model to describe users that exhibit similar access patterns. Next, we present a Workload Parameter Specification Language to describe workload parameters for workload generation. Then, we introduce our load-testing framework based on the proposed model. The representativeness and features of our model are demonstrated by comparing it to other models. Experiments show that our framework can generate accurate and stable synthetic workloads.},
  doi       = {10.1109/QSIC.2014.53},
  issn      = {1550-6002},
  keywords  = {Internet;software performance evaluation;specification languages;LTF;Web applications;context-based sequential action model;model-based load testing framework;performance evaluation;synthetic Web workloads;workload generation;workload model;workload parameter specification language;Computational modeling;Context;Context modeling;Load modeling;Testing;Unified modeling language;load testing;model;performance;workload characterization},
}

@InProceedings{Roy1995,
  author    = {K. Roy and R. K. Roy and A. Chatterjee},
  title     = {Stress testing of combinational VLSI circuits using existing test sets},
  booktitle = {1995 International Symposium on VLSI Technology, Systems, and Applications. Proceedings of Technical Papers},
  year      = {1995},
  pages     = {93-98},
  month     = {May},
  abstract  = {We present a stress testing method which can provide an attractive low-cost alternative to burn-in. The technique is based on reordering of test vectors such that a desired circuit activity or electrical stress is generated across the VLSI chip while achieving a high coverage for stuck-at defects. The test methodology can also be used to generate localized electrical or thermal stress in a circuit. Such testing procedure can be important for weeding out circuits with infant mortality problems. Experimental results on benchmark circuits show that the stress requirements can be changed by more than a factor of 4 by reordering the stuck-at test vectors},
  doi       = {10.1109/VTSA.1995.524640},
  issn      = {1524-766X},
  keywords  = {CMOS logic circuits;VLSI;combinational circuits;integrated circuit testing;integrated logic circuits;logic testing;combinational VLSI circuits;infant mortality problems;localized electrical stress;localized thermal stress;stress testing method;stuck-at defects;test vectors reordering;Circuit faults;Circuit testing;Costs;Current density;Monitoring;National electric code;Ovens;Temperature;Thermal stresses;Very large scale integration},
}

@InProceedings{Shojaee2015,
  author    = {A. Shojaee and N. Agheli and B. Hosseini},
  title     = {Cloud-based load testing method for web services with VMs management},
  booktitle = {2015 2nd International Conference on Knowledge-Based Engineering and Innovation (KBEI)},
  year      = {2015},
  pages     = {170-176},
  month     = {Nov},
  abstract  = {Due to the increased loading the large number of users connected to pervasive web services during the past decade, their load testing and providing the needed resources in low time and cost, requires more attention. In this context cloud computing technology offers new ideas to solve such problems and has reduced the concern of large and complex testing systems. In this research in order to improve the quality and performance of web applications load testing, we proposed a method for web applications load testing based on cloud computing. The proposed method uses the existing facilities in the cloud including pool of computing resources without initial cost, unlimited data storage and cloud computing managerial procedures, containing the actual load generating and multi-user concurrency testing, that lead to improved load testing flexibility, time and operational costs. Moreover, in this load testing method, in order to manage resources and virtual machines, significant improvement is achieved by use of appropriate allocation, reducing performance and unnecessary migration avoiding methods. Through evaluation section of the proposed method through a simulated test environment, it is shown that cloud-based load testing in comparison with traditional methods of load testing, improves factors such as effort, cost and time.},
  doi       = {10.1109/KBEI.2015.7436040},
  keywords  = {Web services;cloud computing;program testing;resource allocation;ubiquitous computing;virtual machines;VM management;Web applications load testing performance;Web applications load testing quality;cloud computing technology;cloud-based load testing method;computing resources pool;load generation;multiuser concurrency testing;pervasive Web services;resource management;virtual machines;Cloud computing;Decision support systems;Handheld computers;Systems architecture;Testing;Virtual machining;Cloud Computing;Load Testing;VMs;Web Service},
}

@InBook{Chan2001a,
  pages     = {372-},
  title     = {Manufacturing AST with Telecommunication Products - Reprinted from Quality Improvement Using Environmental Stress Testing, in the AT T Technical Journal, pp. 1023, with permission from the authors and the AT T Technical Journal 1992.},
  publisher = {Wiley-IEEE Press},
  year      = {2001},
  author    = {H. Anthony Chan},
  isbn      = {9780470544051},
  abstract  = {
AT&T and other leading manufacturers have developed techniques that use environmental stress testing to enhance the quality and reliability of electronics assemblies. These techniques consist primarily of applying thermal, vibration, and voltage stresses to components or assemblies during design and manufacturing. Environmental stress testing is a tool that is used to accelerate the detection of product weaknesses. When coupled with corrective-action programs, this tool also enhances product quality and reliability. This chapter discusses applications of environmental stress testing in the electronics industry. It also reviews the results of environmental stress testing at AT&T's Little Rock Operations Center in Arkansas as applied primarily to the manufacture of circuit-card assemblies.

Introduction

EST During Product Design (Design AST)

Production EST (AST)

Production EST (AST) Studies at AT&T

Results of the Thermal Cycling Studies

Acknowledgments

References

},
  booktitle = {Accelerated Stress Testing Handbook:Guide for Achieving Quality Products},
  doi       = {10.1109/9780470544051.ch20},
  url       = {https://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5270486},
}

@InProceedings{Gavrila2016,
  author    = {C. Gavrilă and C. Z. Kertész},
  title     = {Automated performance testing of end-to-end streaming solutions over HbbTV architecture},
  booktitle = {2016 International Conference on Development and Application Systems (DAS)},
  year      = {2016},
  pages     = {135-138},
  month     = {May},
  abstract  = {This paper presents an automated test execution environment designed to analyze the accessibility, reliability and streaming performance of an end-to-end Hybrid broadcast broadband TV (HbbTV) solution. Its purpose is to provide the means for the TV providers to test their HbbTV solution by simulating real-world scenarios and online functioning in a local, offline environment, before making it available for the end users. This way, common problems like server overload, poor streaming quality and HbbTV incorrect functionality can be foreseen and corrected.},
  doi       = {10.1109/DAAS.2016.7492562},
  keywords  = {Computer architecture;Digital TV;Measurement;Servers;Simple object access protocol;Testing;Automated testing;HbbTV;Network conditions simulation;Streaming media;Web services},
}

@InProceedings{Chen1994,
  author    = {Chih-Ang Chen and S. K. Gupta},
  title     = {BIST/DFT for performance testing of bare dies and MCMs},
  booktitle = {Electro/94 International. Conference Proceedings. Combined Volumes.},
  year      = {1994},
  pages     = {803-812},
  month     = {May},
  abstract  = {High emphasis on performance and high cost of MCM repairs necessitates a frame work for performance testing of dies, substrates, and final MCMs. Application of performance tests to bare dies is very expensive due to the need for small and high speed probes and ATE, BIST, scan, and boundary scan can provide a framework to accomplish performance testing in a cost effective manner. It has been shown that traditional BIST, scan, and boundary scan techniques do not provide the framework for performance testing. Special BIST and scan design techniques that can be employed to guarantee high coverage of delay faults are described. Typically, these techniques produce BIST test pattern generators and scan chain designs that require slightly increased hardware overhead over conventional BIST/scan. However, they can drastically decrease the complexity of bare die performance testing. Furthermore, when used in combination with the proposed enhanced boundary scan design, they provide a framework for detection and diagnosis of dynamic failures},
  doi       = {10.1109/ELECTR.1994.472644},
  keywords  = {built-in self test;fault diagnosis;multichip modules;substrates;BIST;MCMs;bare dies;boundary scan;delay faults;dynamic failures;performance testing;scan;Built-in self-test;Circuit faults;Costs;Delay;Economic forecasting;Integrated circuit interconnections;Logic testing;Parasitic capacitance;Probes;System testing},
}

@Article{Wayman2013,
  author   = {J. L. Wayman and A. Possolo and A. J. Mansfield},
  title    = {Modern statistical and philosophical framework for uncertainty assessment in biometric performance testing},
  journal  = {IET Biometrics},
  year     = {2013},
  volume   = {2},
  number   = {3},
  pages    = {85-96},
  month    = {September},
  issn     = {2047-4938},
  abstract = {The question of estimating uncertainty in measurement is fundamental to all scientific fields. In the field of automated human recognition, lack of repeatability and reproducibility of measurements has been noted since at least the 1970s. This study discusses current approaches to estimation of measurement uncertainty within the broader context of scientific philosophy and measurement science. The authors discuss the Duhem-Quine thesis on testing holism and international standards on estimating and reporting uncertainty in laboratory measurements, then apply these concepts to the estimation of uncertainty in technology, scenario and operational testing in biometrics. The authors advocate for moving beyond the calculation of `coverage' intervals as defined in the ISO/IEC `guidelines for the expression of uncertainty in measurement' to full application of the concepts of uncertainty assessment.},
  doi      = {10.1049/iet-bmt.2013.0009},
  keywords = {IEC standards;ISO standards;biometrics (access control);computerised instrumentation;measurement standards;measurement uncertainty;philosophical aspects;statistical analysis;Duhem-Quine thesis;ISO-IEC guidelines;biometric performance testing;coverage intervals;international standards;laboratory measurements;measurement science;measurement uncertainty estimation;operational testing;philosophical framework;scenario testing;scientific philosophy;statistical framework;technology testing},
}

@InProceedings{Lee2014,
  author    = {S. Lee and J. Y. Jo and Y. Kim},
  title     = {Performance testing of web-based data visualization},
  booktitle = {2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  year      = {2014},
  pages     = {1648-1653},
  month     = {Oct},
  abstract  = {Many scientific applications generate massive data that requires visualization. For example, the Nevada Solar Energy-Water-Environmental Nexus project has been generating a large amount of environmental monitoring data in textual format. As the data is available on the web, a web-based visualization tool is desirable for the project rather than a standalone tool. This research analyzes the processing mechanisms of four popular web-based data visualization tools, that is, Google Charts, Flex, OFC, D3, and compares their performances. A standalone visualization tool, JfreeChart, have been also used for comparison. The processing times have been divided into three segments, layout time, data transformation time, and rendering time, and separately measured. The actual temperature data from the Nevada Nexus project has been used for testing in different scales ranging from 100 to 100,000 data points. The result shows that each visualization tool has its own ideal environment.},
  doi       = {10.1109/SMC.2014.6974152},
  issn      = {1062-922X},
  keywords  = {Internet;data visualisation;environmental monitoring (geophysics);rendering (computer graphics);scientific information systems;D3;Flex;Google Charts;JfreeChart;Nevada Solar Energy-Water-Environmental Nexus project;OFC;Web-based data visualization tools;data transformation time;environmental monitoring data;layout time;performance testing;rendering time;scientific applications;standalone visualization tool;textual format;Browsers;Data visualization;Flexible printed circuits;Google;Libraries;Rendering (computer graphics);Servers;D3.js;Data Visualization;Flex;Google Charts;JFreeChart;Open Flash Chart;Sensor Data},
}

@InProceedings{Lim2006,
  author    = {B. H. Lim and J. R. Kim and K. H. Shim},
  title     = {Hierarchical Load Testing Architecture using Large Scale Virtual Clients},
  booktitle = {2006 IEEE International Conference on Multimedia and Expo},
  year      = {2006},
  pages     = {581-584},
  month     = {July},
  abstract  = {In this work, we develop a hierarchical load testing architecture using large scale virtual clients to reduce the testing time and ensure the stability of the server for distributed applications. It explicitly secures the stability of the servers for networked virtual environment and at the same time, it elaborately generates actual loads for testing the performance of the servers. Our agent based load testing architecture provides variety of interactions of virtual entities in the virtual worlds to perform realistic simulations. Simulation results illustrate that our proposed architecture ensures the stability and capacity of the servers for both massively multiplayer online games and peer-to-peer network games},
  doi       = {10.1109/ICME.2006.262475},
  issn      = {1945-7871},
  keywords  = {client-server systems;computer games;peer-to-peer computing;performance evaluation;software agents;distributed application;hierarchical agent based load testing architecture;large scale networked virtual client-server environment;multiplayer online games;peer-to-peer network games;Computational modeling;Computer architecture;Computer industry;Electronic equipment testing;Large-scale systems;Network servers;Pervasive computing;Stability;System testing;Virtual environment},
}

@InProceedings{Zhou2014a,
  author    = {J. Zhou and B. Zhou and S. Li},
  title     = {Automated Model-Based Performance Testing for PaaS Cloud Services},
  booktitle = {2014 IEEE 38th International Computer Software and Applications Conference Workshops},
  year      = {2014},
  pages     = {644-649},
  month     = {July},
  abstract  = {Recently, cloud computing has become popular for its unique advantages. Many applications have been migrated to cloud as web services. However, evaluating the performance of cloud services is non-trivial. Performance testing is one of the dominant techniques for evaluating system performance. In this paper, we present a model and template-based approach that automatically generates test scripts and test cases to measure service performance in an enterprise private cloud. We describe how load is generated automatically from our tool. Our empirical study shows the proposed approach can significantly decrease the cost of performance testing and help reveal potential performance issues.},
  doi       = {10.1109/COMPSACW.2014.108},
  keywords  = {Web services;cloud computing;program testing;software performance evaluation;PaaS cloud services;Web services;automated model;cloud computing;enterprise private cloud;performance testing;Automation;Cloud computing;Computational modeling;Context;Load modeling;Testing;automated;cloud;performance testing;web service},
}

@InProceedings{Xie2008a,
  author    = {J. Xie and X. Ye and B. Li and F. Xie},
  title     = {A Configurable Web Service Performance Testing Framework},
  booktitle = {2008 10th IEEE International Conference on High Performance Computing and Communications},
  year      = {2008},
  pages     = {312-319},
  month     = {Sept},
  abstract  = {More and more softwares based on web service technologies are developed. Before their releases on the Internet, it is necessary to evaluate these systems' performance, especially their response time under different workload pressures. However, existing performance testing benchmarks and tools for web service applications are difficult to adapt to various user-specific testing purposes. This paper proposes a configurable web service performance testing framework which contains client module, application server module and database module. Client module, by using the network cooperation method that one central client drives several other clients, adapts to a great number of concurrent customers to request web services. Application server module contains web services under testing and external supporting web services, each of which is configured as a plug-in. The process to realize mixed ratio of web service interactions is similar to dealing cards and adapts to different commercial application characteristics. In database module, the data model including table and attribute dependence can be customized, and the data scale initialization can be resized according to the topology of above dependence. As such, this framework allows testers to dynamically define their data model, customize their scale of database, configure their transaction characteristics, deploy their application strategies and confirm their performance metrics..},
  doi       = {10.1109/HPCC.2008.53},
  keywords  = {Web services;client-server systems;data models;program testing;Internet;attribute dependence;client-server module;configurable Web service performance testing;data model;database module;table dependence;user-specific testing purpose;Application software;Benchmark testing;Data models;Delay;Internet;Measurement;Network servers;Topology;Transaction databases;Web services;benchmark;framework;performance testing;web service},
}

@InProceedings{Masud2006,
  author    = {M. Z. Mas'ud and A. H. Yaacob and N. M. Ahmad},
  title     = {Network performance testing on VM based autonomous web server},
  booktitle = {2006 International Conference on Computing Informatics},
  year      = {2006},
  pages     = {1-6},
  month     = {June},
  abstract  = {As online services increasingly play vital roles in modern society, the possibilities and opportunities offered are limitless, unfortunately, so too are the risks and chances of malicious intrusions. Intrusion detection systems (IDSs) has been widely used as an important component in protecting online service towards Web attacks and evasions. Yet, today's architectures for intrusion detection force the IDS designer to make a difficult choice to place IDS, so that it can protect itself from a direct attack. To address these challenges, this paper introduces a novel framework to safeguard IDS from a direct attack. Simply called zero administrative server (ZAS), the system incorporates IDS in a virtual machine (VM) environment. VM offers strong isolation for IDS from the monitored services and provides significant resistance to malicious attacks. Moreover, this VM based WWW server has the ability to monitor the network traffic to the running services; analyse the information obtained and detect the intrusion; alienate the intruder from the services; and reconstruct the corrupted data or damaged files caused by the evasion. In this paper, we demonstrate ZAS by exposing it to several attacking tools as well as to show the effects it takes on the network performance in terms of TCP throughput and application-to-application round trip time.},
  doi       = {10.1109/ICOCI.2006.5276470},
  issn      = {2166-5710},
  keywords  = {Web services;security of data;virtual machines;VM based autonomous Web server;Web attacks;intrusion detection systems;malicious attacks;network performance testing;online services;virtual machine;zero administrative server;File servers;Intrusion detection;Network servers;Protection;Testing;Virtual machine monitors;Virtual machining;Virtual manufacturing;Web server;World Wide Web;Checksum;Intrusion Detection System;Virtual Machine;WWW Server},
}

@InProceedings{Chen1999,
  author    = {Qingxin Chen and V. Sorokine},
  title     = {A fast simulation technique for performance testing of the RF/IF chain of CDMA receivers},
  booktitle = {1999 IEEE MTT-S International Topical Symposium on Technologies for Wireless Applications (Cat. No. 99TH8390)},
  year      = {1999},
  pages     = {23-28},
  month     = {Feb},
  abstract  = {We propose an improved approach to the simulation of the CDMA forward link. The simulator achieves its computational efficiency by adopting a simplified CDMA system model without compromising much of its practicality. Additional reduction in the computational complexity is obtained by implementing bit level operations for certain receiver tasks. Improved processing algorithms are also introduced, which further facilitates the simulation process. The rationale behind the development of the simulator as well as many techniques involved could prove beneficial to a CDMA receiver designer in terms of shortening the design cycle and reducing the computational power requirements.},
  doi       = {10.1109/MTTTWA.1999.755123},
  keywords  = {code division multiple access;computational complexity;digital simulation;land mobile radio;radio receivers;signal processing;telecommunication equipment testing;CDMA forward link;CDMA receivers;RF/IF chain;bit level operations;computational complexity reduction;computational efficiency;computational power requirements reduction;design cycle;fast simulation technique;mobile radio;performance testing;processing algorithms;system model;Additive white noise;Computational modeling;Context modeling;Fading;Multiaccess communication;Power system modeling;Radio frequency;Signal generators;Space technology;Testing},
}

@InProceedings{Honari2008,
  author    = {B. Honari and J. Donovan and T. Joyce and S. Wilson},
  title     = {Application of generalized linear models for optimizing production stress testing},
  booktitle = {2008 Annual Reliability and Maintainability Symposium},
  year      = {2008},
  pages     = {267-271},
  month     = {Jan},
  abstract  = {Accelerated environmental stress tests (EST) are applied during the manufacturing process to improve reliability by precipitating and detecting latent defects. This test represents an in-process manufacturing screen and the objective of performing it is to avoid early field failures that reduce the customer satisfaction level and increase warranty and compensation costs. Temperature cycling during EST is one of the most commonly used test procedures. Although it is an expensive and energy intensive procedure, usually a lengthy test is initially recommended for a new product. Based on the product test performance or a possible manufacturing process modification, the test duration and regime may be changed after some period. Even if the number of test cycles is reduced, EST continues to be an expensive test and a major process bottleneck. This paper uses generalized linear modeling (GLM) to investigate the effects of the production and EST test variables on the population under test. Both the number of units rejected and the time to failure can be modeled as a regression function of covariates representative of the test environment. The field reliability function is written as a product of the unconditional reliability in each segment of the test profile such as dwell, ramp, etc. The next step is to apply the result of the temperature cycle EST GLM to a mathematical cost model. This cost model includes both the test cost and the warranty and compensation costs of the early field failures. The optimum test regime and number of cycles, which minimizes the total cost is determined by combining the GLM and the cost model. In this way the production test regime can be optimized in terms of field reliability/test cost trade-off.},
  doi       = {10.1109/RAMS.2008.4925806},
  issn      = {0149-144X},
  keywords  = {costing;flaw detection;life testing;manufacturing processes;production testing;regression analysis;reliability;accelerated environmental stress tests;compensation cost;generalized linear model;latent defect detection;manufacturing process;mathematical cost model;product test performance;production stress testing;regression analysis;reliability;warranty cost;Cost function;Customer satisfaction;Life estimation;Manufacturing processes;Performance evaluation;Production;Stress;Temperature;Testing;Warranties;Environmental Stress Testing;Generalized Linear Models;Test Optimization},
}

@InProceedings{Kaulbars2015,
  author    = {D. Kaulbars and F. Schweikowski and C. Wietfeld},
  title     = {Spatially Distributed Traffic Generation for Stress Testing the Robustness of Mission-Critical Smart Grid Communication},
  booktitle = {2015 IEEE Globecom Workshops (GC Wkshps)},
  year      = {2015},
  pages     = {1-6},
  month     = {Dec},
  abstract  = {Resilient Smart Grids require very robust communication infrastructures, which allow to support the control of the Smart Grid even and especially in critical situations. Current network quality assurance processes, such as drive tests in wireless systems, typically focus on cell coverage and quality of service parameters (e.g., max. data rate) at a specific geographical position, without considering the impact of overload situations. Therefore, this paper introduces a methodology for stress testing a communication infrastructure for Smart Grids by synchronized, distributed so-called Smart Traffic Generators (STGs). Due to their low cost, the STGs become a permanent part of the infrastructure and enable a network operator independent, continuous network quality monitoring. A case study leveraging a LTE deployment demonstrates how the proposed approach can prove the fulfillment of Quality of Service (QoS) requirements of time critical Smart Grid applications, even in stress situations with high cell load. Although, the proposed approach has been introduced for Smart Grids, it can also be used for ensuring the communication resilience for other critical infrastructures, e.g., public safety networks.},
  doi       = {10.1109/GLOCOMW.2015.7414168},
  keywords  = {Long Term Evolution;carrier transmission on power lines;quality of service;smart power grids;telecommunication traffic;mission-critical smart grid communication;network quality monitoring;quality of service;spatially distributed traffic generation;stress testing;Generators;Long Term Evolution;Mobile communication;Mobile computing;Quality of service;Smart grids;Stress},
}

@InProceedings{Wang2010a,
  author    = {X. Wang and B. Zhou and W. Li},
  title     = {Model Based Load Testing of Web Applications},
  booktitle = {International Symposium on Parallel and Distributed Processing with Applications},
  year      = {2010},
  pages     = {483-490},
  month     = {Sept},
  abstract  = {In this paper, a usage model is proposed to simulate users' behaviors realistically in load testing of web applications, and another relevant workload model is proposed to help generate realistic load for load testing. It also demonstrates an eclipse-based load testing tool “Load Testing Automation Framework (LTAF)” which is based on these two models and can perform load testing of web applications easily and automatically. Furthermore, these models and tools were successfully applied into a representative web-based system from a big Corporation.},
  doi       = {10.1109/ISPA.2010.24},
  issn      = {2158-9178},
  keywords  = {Internet;program testing;Load Testing Automation Framework;Web applications;Web-based system;eclipse-based load testing tool;model based load testing;usage model;user behaviors;File systems;Load modeling;Markov processes;Navigation;Servers;Testing;Unified modeling language;Load Model;Load Testing;Markov Chains;Performance Engineering;Usage Model},
}

@InProceedings{Young2007,
  author    = {A. Young and T. Holt and M. Elsayed and A. Neuber and M. Kristiansen and L. L. Altgilbers and A. H. Stults},
  title     = {Fuse and load testing with mid-sized, high energy density flux compression generators},
  booktitle = {2007 16th IEEE International Pulsed Power Conference},
  year      = {2007},
  volume    = {2},
  pages     = {1165-1168},
  month     = {June},
  abstract  = {Compact Pulsed Power Systems (CPPSs) require power sources that are small in size yet can produce the necessary electrical energy required to drive a given load. Helical Flux Compression Generators (HFCGs) are attractive for single shot applications due to their rapid conversion of chemical energy to electrical energy. Mid-sized generators occupy little total volume (∼4,000-cm3 total with a compressible volume of ∼300-cm3 in the present generator design), while the high explosives used in an HFCG provide an energy density of ∼8,000 MJ/m3. Consistent output current and energy gain from shot to shot are key variables in the ability of an HFCG to drive CPPSs effectively. An investigation into the practicality of using mid-sized HFCGs as the driver for single shot CPPSs is presented. Data and waveforms from generators fired into 3 μH inductive loads are shown, with results measuring the generator’s performance as a driver for an inductive energy storage (IES) system. Results are also shown from adding a power conditioning system to the output of the HFCG, where the measurements demonstrate the ability of an HFCG to drive high impedance loads. The effectiveness of a mid-sized HFCG as drivers for these systems will be evaluated.},
  doi       = {10.1109/PPPS.2007.4652394},
  issn      = {2158-4915},
  keywords  = {Chemicals;Energy measurement;Energy storage;Explosives;Fuses;Impedance measurement;Power conditioning;Power measurement;Pulse power systems;Testing},
}

@InProceedings{Khan2016,
  author    = {R. Khan and M. Amjad},
  title     = {Web application's performance testing using HP LoadRunner and CA Wily introscope tools},
  booktitle = {2016 International Conference on Computing, Communication and Automation (ICCCA)},
  year      = {2016},
  pages     = {802-806},
  month     = {April},
  abstract  = {This paper cover the importance of performance testing of the web application. The performance of any web application has been depend on the some different type of the testing process like load testing, soak testing, smoke testing and stress testing etc. In this paper we applied smoke testing on a web application. This web application has been developed for the customer before delivering the software to the customer it is duty of tester to test all the aspects of the software and deliver error free and reliable software to the customer. Reliability has its own most important role in the software industry. In this paper performance testing has been performed using HP LoadRunner and CA Wily Introscope tools.},
  doi       = {10.1109/CCAA.2016.7813849},
  keywords  = {DP industry;Internet;program testing;software performance evaluation;software reliability;software tools;CA Wily Introscope tool;HP LoadRunner;Web application performance testing;smoke testing;software industry;software reliability;Business;Scalability;Servers;Software;Testing;Throughput;Uniform resource locators;HP LoadRunner;Load Testng;Perforamance Testing;Software Testing;Wily Introscope Tools},
}

@InProceedings{Young2007a,
  author    = {A. J. Young and T. A. Holt and M. A. Elsayed and A. A. Neuber and M. Kristiansen and L. L. Altgilbers and A. H. Stults},
  title     = {Fuse and Load Testing with Mid-Sized, High Energy Density Flux Compression Generators},
  booktitle = {2007 IEEE 34th International Conference on Plasma Science (ICOPS)},
  year      = {2007},
  pages     = {719-719},
  month     = {June},
  abstract  = {Compact pulsed power systems require power sources that are small in size yet can produce the necessary electrical energy required to drive the system. Helical magnetic flux compression generators (HFCGs) are attractive for single shot applications due to their rapid conversion of chemical energy to electrical energy. The small total volume of a generator coupled with the energy density of the fast-reacting high explosives makes mid-sized HFCGs an appealing option as sources in single shot compact pulsed power systems. Consistent output current and energy gain from shot to shot are key variables in the ability of an HFCG to drive compact pulsed power systems efficiently.},
  doi       = {10.1109/PPPS.2007.4346025},
  issn      = {0730-9244},
  keywords  = {electric fuses;pulse generators;pulsed power supplies;compact pulsed power systems;fuse testing;helical magnetic flux compression generators;high energy density flux compression generators;load testing;Electronic equipment testing;Explosives;Fuses;Impedance;Power generation;Pulse compression methods;Pulse generation;Pulse power systems;Pulse shaping methods;Switches},
}

@InProceedings{Wunderle2017,
  author    = {B. Wunderle and J. Heilmann and D. May and J. Arnold and J. Hirscheider and J. Bauer and R. Schacht and J. Vogel and M. A. Ras},
  title     = {Modelling and characterisation of a grease pump-out test stand and its use for accelerated stress testing of thermal greases},
  booktitle = {2017 23rd International Workshop on Thermal Investigations of ICs and Systems (THERMINIC)},
  year      = {2017},
  pages     = {1-6},
  month     = {Sept},
  abstract  = {Thermal greases allow a low stress bond at low bond line thicknesses (BLT) at medium thermal conductivities and simple application, all of which make it an alternative to solders, thermal adhesives or pads. It is widely used in power and microprocessor applications, most of which involve large areas to be used for heat transfer. However, for years thermal overload failure of power modules and chips has been a pressing problem due to pump-out of thermal grease as die or module thermal interface material (TIM): Most thermal greases are Bingham fluids and thus no solids, so they can be squeezed out from in between the gap, driven by thermo-mechanical action of the adjacent layers as e.g. DCB substrate or silicon chip with the heat sink. Today, thermal greases have to be qualified in lengthy stress tests in a product relevant environment which consumes substantial resources as often a system test is required. Therefore, a fast test is necessary which accelerates testing and thus allows a fast screening of market-available greases on one hand, and guidelines for material development on the other. For that purpose this paper addresses this topic in a combined simulative and experimental manner, where at the same time a novel test procedure is proposed for accelerated grease pump-out testing (GPOT) in the framework of a completely new approach, combining loading with in-situ failure analytical techniques and decoupling thermal from mechanical loading.},
  doi       = {10.1109/THERMINIC.2017.8233806},
  keywords  = {adhesion;adhesives;failure analysis;greases;heat sinks;integrated circuit packaging;integrated circuit reliability;life testing;microprocessor chips;thermal conductivity;thermal management (packaging);thermal resistance;thermal stresses;accelerated grease pump-out;accelerated stress testing;grease pump-out test;stress tests;thermal adhesives;thermal conductivities;thermal grease;thermal interface material module;thermal overload failure;Conductivity;Life estimation;Loading;Stress;Testing;Thermal conductivity;Thermal stresses},
}

@InProceedings{Sueker1997,
  author    = {K. H. Sueker},
  title     = {A static dynamometer for load testing large variable frequency motor drives},
  booktitle = {1997 IEEE International Electric Machines and Drives Conference Record},
  year      = {1997},
  pages     = {WB1/9.1-WB1/9.3},
  month     = {May},
  abstract  = {The static dynamometer, an apparent oxymoron, is a system which allows full load testing of variable frequency motor drives with no rotating equipment and only minimal demand from the power line. By inserting a reactor between the drive output and the line from which it is powered, the drive can be made to appear as a synchronous generator. This arrangement offers a practical alternative to the motor-generator sets usually employed for load testing. The required equipment consists of a set of power reactors approximating 10% of the drive rating, a contactor and a phase locked loop circuit for regulating the drive phase relative to the line. The static dynamometer is in production use on variable speed drives from 20 to 5000 hp and 480 to 4160 V. There are no intrinsic limits to either power or voltage for its application},
  doi       = {10.1109/IEMDC.1997.604303},
  keywords  = {dynamometers;machine testing;motor drives;variable speed drives;20 to 5000 hp;480 to 4160 V;drive rating;load testing;motor-generator sets;phase locked loop circuit;power reactors;production experience;static dynamometer;synchronous generator;variable frequency motor drives;variable speed drives;Circuit testing;Frequency;Inductors;Motor drives;Phase locked loops;Production;Synchronous generators;System testing;Variable speed drives;Voltage},
}

@InProceedings{Mansharamani2010,
  author    = {R. Mansharamani and A. Khanapurkar and B. Mathew and R. Subramanyan},
  title     = {Performance Testing: Far from Steady State},
  booktitle = {2010 IEEE 34th Annual Computer Software and Applications Conference Workshops},
  year      = {2010},
  pages     = {341-346},
  month     = {July},
  abstract  = {The dot com era ushered in a number of industry standard load testing tools. While there is no doubt that these tools have helped improve the quality of IT systems, performance testing in the IT industry is far from steady state. There are still severe gaps between performance test results and production systems performance in IT projects. This paper proposes a number of areas where performance testing needs to improve radically, several of which can be incorporated in to load testing tools. Examples are also provided of simple analytics during single user performance testing to demonstrate the effectiveness of this extra but necessary step in the testing process.},
  doi       = {10.1109/COMPSACW.2010.66},
  keywords  = {DP industry;Internet;electronic commerce;performance evaluation;testing;IT system quality;industry standard load testing tools;production systems;single user performance testing;Databases;Extrapolation;Industries;Testing;Throughput;Time factors;Tuning;load testing tools;performance emulation;performance testing;think time variability},
}

@InProceedings{Meira2012a,
  author    = {J. A. Meira and E. C. d. Almeida and Y. Le Traon and G. Sunye},
  title     = {Peer-to-Peer Load Testing},
  booktitle = {2012 IEEE Fifth International Conference on Software Testing, Verification and Validation},
  year      = {2012},
  pages     = {642-647},
  month     = {April},
  abstract  = {Nowadays the large-scale systems are common-place in any kind of applications. The popularity of the web created a new environment in which the applications need to be highly scalable due to the data tsunami generated by a huge load of requests (i.e., connections and business operations). In this context, the main question is to validate how far the web applications can deal with the load generated by the clients. Load testing is a technique to analyze the behavior of the system under test upon normal and heavy load conditions. In this work we present a peer-to-peer load testing approach to isolate bottleneck problems related to centralized testing drivers and to scale up the load. Our approach was tested in a DBMS as study case and presents satisfactory results.},
  doi       = {10.1109/ICST.2012.153},
  issn      = {2159-4848},
  keywords  = {Internet;peer-to-peer computing;program testing;Web applications;centralized testing drivers;large-scale systems;peer-to-peer load testing;system under test;Cloud computing;Computer architecture;Databases;Large-scale systems;Peer to peer computing;Scalability;Testing;large-scale systems;load testing;peer-to-peer},
}

@Article{Parker1992b,
  author   = {T. P. Parker and G. L. Harrison},
  title    = {Quality improvement using environmental stress testing},
  journal  = {AT T Technical Journal},
  year     = {1992},
  volume   = {71},
  number   = {4},
  pages    = {10-23},
  month    = {July},
  issn     = {8756-2324},
  abstract = {AT&T and other leading manufacturers have developed techniques that use environmental stress testing to enhance the quality and reliability of electronics assemblies. These techniques consist primarily of applying thermal, vibration, and voltage stresses to components or assemblies during design and manufacturing. Environmental stress testing is a tool that is used to accelerate the detection of product weaknesses. When coupled with corrective-action programs, this tool also enhances product quality and reliability. This paper discusses applications of environmental stress testing in the electronics industry. It also reviews the results of environmental stress testing at AT&T's Little Rock Operations Center in Arkansas as applied primarily to the manufacture of circuit-card assemblies.},
  doi      = {10.1002/j.1538-7305.1992.tb00169.x},
}

@InProceedings{Wandan2009,
  author    = {Z. Wandan and J. Ningkang and Z. Xubo},
  title     = {Design and Implementation of a Web Application Automation Testing Framework},
  booktitle = {2009 Ninth International Conference on Hybrid Intelligent Systems},
  year      = {2009},
  volume    = {2},
  pages     = {316-318},
  month     = {Aug},
  abstract  = {In this paper the problems in the automation testing of GUI based Web applications are discussed. A new automation testing framework based on the concept of object feature set and dynamic searching policy is proposed. The design and implementation of it are both given. The framework working using result shows that it makes the testing more convenient and efficient with less resources and time cost but higher testing coverage.The ability of maintenance and stability are both improved.},
  doi       = {10.1109/HIS.2009.175},
  keywords  = {Internet;graphical user interfaces;program testing;GUI;Internet technology;Web application automation testing framework;Web application maintenance;dynamic searching policy;object feature set;software development cycle;Application software;Automatic control;Automatic testing;Costs;Design automation;Graphical user interfaces;Java;Programming;Software testing;System testing;Web application testing;automation testing framework;dynamic searching technology},
}

@InProceedings{Shu2007,
  author    = {X. Shu and F. Maurer},
  title     = {A Tool for Automated Performance Testing of Java3D Applications in Agile Environments},
  booktitle = {International Conference on Software Engineering Advances (ICSEA 2007)},
  year      = {2007},
  pages     = {35-35},
  month     = {Aug},
  abstract  = {Following the agile philosophy that all core features of a system need an automated test harness, performance requirements also need such a check when they are essential for the success of a project. The purpose of this paper is to describe a tool, J3DPerfUnit, which supports automated performance testing for Java3D applications in agile environments. We elicited tool requirements from domain experts through a survey and evaluated J3DPerfUnit using code from our partner's bioinformatics project and Java3D official tutorials. The evaluation pointed out that the tool is effective in detecting performance problems and in identifying where they come from when loading/unloading a 3D object.},
  doi       = {10.1109/ICSEA.2007.11},
  keywords  = {Java;program testing;rendering (computer graphics);software metrics;Java3D application;agile environment;automated performance testing;graphics rendering;software metrics;Application software;Automatic testing;Availability;Bioinformatics;Computer science;Engines;Java;Layout;System testing;Tree graphs},
}

@InProceedings{Motalova2010,
  author    = {L. Motalova and O. Krejcar},
  title     = {Stress Testing Data Access via a Web Service for Determination of Adequate Server Hardware for Developed Software Solution},
  booktitle = {2010 Second International Conference on Computer Engineering and Applications},
  year      = {2010},
  volume    = {1},
  pages     = {329-333},
  month     = {March},
  abstract  = {The aim of this project is stress testing of the system for data management and planning of the operations developed for home care agencies which has to be upgrading of the current system based on the older database of Microsoft Access product. The part of the system is a mobile application that allows employees to edit the records of patients directly in the terrain. The whole system, including applications developed for the stress testing is based on Microsoft technology .NET. Our Stress Testing application allows testing a selected problem areas to find any limitations before the tested developing solution will be set up at customer. By the help of our test application, the hardware solution for the server was selected on the base of selected home care agency needs.},
  doi       = {10.1109/ICCEA.2010.72},
  keywords  = {Web services;file servers;information retrieval;program testing;software tools;Microsoft access product database;Microsoft technology .NET;Web service;adequate server hardware;data management system;home care agency;stress testing data access;Databases;Displays;Hardware;Random number generation;Software testing;Stress;System testing;Time factors;Time measurement;Web services;data access;software;stress testing;web services},
}

@InProceedings{Grossman1994a,
  author    = {D. Grossman and C. J. Staton and B. Bailey and M. C. McCabe and A. Latts and O. Frieder and C. Bock and D. Roberts},
  title     = {A prototype-driven approach to application-level performance testing: a case study of a large finance application},
  booktitle = {Proceedings of 3rd Symposium on Assessments of Quality Software Development Tools},
  year      = {1994},
  pages     = {125-135},
  month     = {Jun},
  abstract  = {We present an approach to application-level performance testing. This uses a popular test tool, TPNS (Teleprocessing Network Simulator) to simulate performance of an application. Our approach hinges upon a simple prototype to verify that the system performance falls within acceptable bounds. Once the initial prototype is developed, detailed tuning may take place. We present a case study in which we tested the performance of a large finance application. This approach led to critical performance tuning improvement. Due to this improvement, the average user response time in our simulations was reduced from 30 seconds to under 1.5 seconds. This simulation has been verified by actual system usage during the first two months of live operation in which the average response time has indeed been under 1.5 seconds},
  doi       = {10.1109/AQSDT.1994.315756},
  keywords  = {accounts data processing;performance evaluation;program testing;software prototyping;TPNS;Teleprocessing Network Simulator;application-level performance testing;large finance application;prototype-driven approach;system performance;test tool;user response time;Computer aided software engineering;Computer bugs;Database systems;Finance;Financial management;Information technology;Operating systems;Prototypes;System testing;Technology management},
}

@InProceedings{Schinstock1996,
  author    = {D. E. Schinstock and T. A. Haskew},
  title     = {Dynamic load testing of roller screw EMAs},
  booktitle = {IECEC 96. Proceedings of the 31st Intersociety Energy Conversion Engineering Conference},
  year      = {1996},
  volume    = {1},
  pages     = {221-226 vol.1},
  month     = {Aug},
  abstract  = {In the electromechanical actuators (EMA) laboratory at The University of Alabama, USA, a dynamic load test stand has been designed and built. This test stand uses large load, high bandwidth and hydraulic actuation to generate load profiles under force control. The test stand can accommodate EMAs up to six feet in length. It can generate dynamic loads of up to 100,000 lb at fundamental frequencies of up to 12 Hz against a stiff environment. This test stand has been used to generate severe loading conditions on a large roller screw in an attempt to qualify the effects of large, high frequency loads on roller screw. During the tests performed in the EMA laboratory the screw was fixed at one end and axial loads were applied to the roller nut at the other. Since the end opposite the nut was fixed, only a small amount of relative rotation between the nut and screw was achieved. This rotation was the result of elastic deformation (wind up) of the screw along the length between the fixed end and the nut. This simulates a severe, but likely, application of the roller screw. The results of the tests performed demonstrate that roller screws may be damaged by dynamic loading with load magnitudes that are well within the static load rating of the screw. While the damage that was observed is not catastrophic, it would be expected to substantially decrease the life of the screw},
  doi       = {10.1109/IECEC.1996.552874},
  issn      = {1089-3547},
  keywords  = {electric actuators;machine testing;mechanical testing;test equipment;test facilities;12 Hz;USA;dynamic load test stand;dynamic load testing;dynamic loading;elastic deformation;electromechanical actuators;roller screw actuators;static load rating;test laboratory;Bandwidth;Electric shock;Fasteners;Force control;Frequency;Hydraulic actuators;Laboratories;Lubrication;Performance evaluation;Testing},
}

@InProceedings{Ibhar2017,
  author    = {N. Ibhar and W. Flores and R. León},
  title     = {Design of a low-cost teleoperated robotic arm: Assembly and performance testing},
  booktitle = {2017 IEEE 37th Central America and Panama Convention (CONCAPAN XXXVII)},
  year      = {2017},
  pages     = {1-5},
  month     = {Nov},
  abstract  = {At present, robots are widely used in various tasks, whether for industrial or even domestic uses. Thus, for certain tasks it has become necessary to operate the robot in an intuitive and safe way. The vast majority of current robotic hands do not completely replace the functionality of a hand and can not be used in environments which are designed for the use of a human hand. Thus, this document shows the design of a hybrid system with robotic hand and prosthesis applications. The design of a biomechanically controlled, functional and anthropomorphic robotic arm is shown, which demonstrates that it is feasible to design a real-time, low-cost, robotic arm.},
  doi       = {10.1109/CONCAPAN.2017.8278490},
  keywords  = {biomechanics;human-robot interaction;manipulator dynamics;prosthetics;robot dynamics;telerobotics;anthropomorphic robotic arm;biomechanically controlled arm;domestic uses;functional arm;human hand;hybrid system design;industrial uses;low-cost teleoperated robotic arm;performance testing;prosthesis;robotic hand;robotic hands;robots;Manipulators;Service robots;Silicon compounds;Task analysis;Testing;Torque;Human-robot interaction;Humanoid robots;Robot control;Telerobotics},
}

@InProceedings{l.liu2007,
  author    = {l. liu and w. wei and j. li},
  title     = {Wireless Communication System Automation Testing Framework},
  booktitle = {2007 International Conference on Wireless Communications, Networking and Mobile Computing},
  year      = {2007},
  pages     = {2981-2984},
  month     = {Sept},
  abstract  = {This article intends to introduce a leading next generation wireless protocol oriented automation testing framework - WiCAT system. This framework supports multiple protocol messaging testing by simulating the wireless equipments and implementing the telecommunication system logic. WiCAT provides high-efficiency and low-cost performance basing on a distributed, expandable and extensible architecture.},
  doi       = {10.1109/WICOM.2007.740},
  issn      = {2161-9646},
  keywords  = {automatic test software;electronic messaging;mobile radio;protocols;telecommunication computing;telecommunication equipment testing;WiCAT system;multiple protocol messaging testing;next generation wireless protocol;telecommunication system logic;wireless communication system automation testing;Automatic testing;Automation;Computer architecture;Graphical user interfaces;Local area networks;System testing;User interfaces;Utility programs;Wireless application protocol;Wireless communication},
}

@InProceedings{Nie2010,
  author    = {N. Nie and J. Guo and J. Fu and Z. Feng},
  title     = {Reliability and Performance Testing Model of Web-Based User Login and Access Control},
  booktitle = {2010 2nd International Workshop on Database Technology and Applications},
  year      = {2010},
  pages     = {1-4},
  month     = {Nov},
  abstract  = {In order to test the performance, reliability and security of Web-based system, the paper generates the test scripts template and establishes testing model of system login and access control. Then some Web-based systems are tested by automation test tools. The performance, reliability and security problems of Web login process can be traced and diagnosed. The test result shows that Web-based system can be verified and improved by the test script template of multi-users secure login and resources access control.},
  doi       = {10.1109/DBTA.2010.5658927},
  issn      = {2167-1923},
  keywords  = {Internet;authorisation;computer network security;performance evaluation;Web based user login;access control;multiuser secure login;performance testing model;reliability testing model;test script template;Access control;Correlation;Driver circuits;Software reliability;Testing},
}

@InProceedings{Kapoh2016,
  author    = {H. Kapoh and E. S. Lumunon and N. A. E. Sajangbati},
  title     = {Design model material requirement of coconut flour production and performance testing based multi user in North Sulawesi},
  booktitle = {2016 International Conference on Knowledge Creation and Intelligent Computing (KCIC)},
  year      = {2016},
  pages     = {1-7},
  month     = {Nov},
  abstract  = {There has been many previous studies that discuss the control for the production of coconut flour and raw material inventory. But a system or a computer-based model for coconut flour industry in North Sulawesi has not or does not exist. For that reason, coconut flour industries also require tools on in running the business as developed in this study. The problem in this research is how to make the design of the model material production requirement of coconut flour-based multi-user to control the production of industrial centers in North Sulawesi coconut flour and how to test the model. The model generated in this study have been through a survey in the industrial district of coconut flour to get the data that will be used analysis, so that a complete picture processing system coconut flour and can describe the problem also the solution clearly in order to get the system needs a model along the test by using a test black box the program and the respondents used for the performance test in order to know the program's ability to interact with users. The collected data is then analyzed and designed using some design method that is data flow diagrams, use case diagram, entity relationship diagrams and material requirements planning methods. Results of the test will indicate that all functions on the system works well and test the respondent for 30 and 60 minutes resulting in a 60% and 63% of respondents were taken as many as 30 answered easily using the model application.},
  doi       = {10.1109/KCIC.2016.7883617},
  keywords  = {design engineering;food processing industry;materials requirements planning;production engineering computing;raw materials inventory;North Sulawesi;coconut flour industry;coconut flour production;computer-based model;data flow diagrams;design model material requirement;entity relationship diagrams;industrial centers;material requirements planning methods;model material production requirement;performance testing based multiuser;picture processing system;raw material inventory;use case diagram;Companies;Computational modeling;Industries;Planning;Production;Raw materials;Testing;coconut flour;design;model;multi-user;production;testing},
}

@InProceedings{Pu2009,
  author    = {Y. Pu and M. Xu},
  title     = {Load Testing for Web Applications},
  booktitle = {2009 First International Conference on Information Science and Engineering},
  year      = {2009},
  pages     = {2954-2957},
  month     = {Dec},
  abstract  = {The performance testing criteria was analyzed, including response time, concurrency users, throughout and performance counter. Performance testing is necessary for the system reliability. Load testing can be used for software troubleshooting and optimizing. With the LoadRunner and TestDirector testing tools, a load testing scheme based on an online examination system was designed.},
  doi       = {10.1109/ICISE.2009.720},
  issn      = {2160-1283},
  keywords  = {Internet;program testing;software performance evaluation;LoadRunner testing tools;TestDirector testing tools;Web application;concurrency users;load testing;online examination system;performance counter;performance testing criteria;response time;software troubleshooting;system reliability;Application software;Automatic testing;Computer bugs;Concurrent computing;Delay;Reliability engineering;Software performance;Software testing;System performance;System testing},
}

@InProceedings{Wu2010a,
  author    = {Q. Wu and Y. Wang},
  title     = {Performance Testing and Optimization of J2EE-Based Web Applications},
  booktitle = {2010 Second International Workshop on Education Technology and Computer Science},
  year      = {2010},
  volume    = {2},
  pages     = {681-683},
  month     = {March},
  abstract  = {J2EE-based Web applications are becoming increasingly ubiquitous and with their increasing adoption, the performance is the attention focus and the most important factor of evaluating the system by users. In this paper, we present a systematic solution for performance testing and optimization of J2EE-based Web applications. The solution helps to identify and eliminate bottlenecks in the application design and ensures that systems are designed to meet their quality of service requirements. This paper firstly analyses the architecture of J2EE-based Web applications and performance testing principle, and then improves the JMeter testing framework for meeting the more concurrent users. Lastly, performance testing for J2EE-based Web applications is done; it finds performance bottlenecks and puts forward optimum measures, and compares the performance with the former one.},
  doi       = {10.1109/ETCS.2010.583},
  keywords  = {Internet;Java;program testing;software performance evaluation;J2EE-based Web applications optimization;JMeter testing framework;concurrent users;performance testing;quality of service requirements;systematic solution;Application software;Business;Delay;Educational institutions;Nonhomogeneous media;Performance analysis;Scalability;Service oriented architecture;System performance;System testing;JMeter;Web applications;distributed;optimization;performance},
}

@InProceedings{Hamed2009,
  author    = {O. Hamed and N. Kafri},
  title     = {Performance testing for web based application architectures (.NET vs. Java EE)},
  booktitle = {2009 First International Conference on Networked Digital Technologies},
  year      = {2009},
  pages     = {218-224},
  month     = {July},
  abstract  = {Having an efficient web application is a challenge that we need to achieve when architecting web applications in the development process. This research follows a performance modeling approach that aims to utilize load testing tools to give ideas about performance issues early in the development life cycle for applications implemented using Java Enterprise Edition (Java EE) or .NET platform. Thus, it helps system architects to choose between competitive frameworks. To achieve this, the applications are subjected to artificial workload. Direct measurements are obtained on the specified application scenarios using different tools. Parasoft WebKing and Hewlett-Packard LoadRunner were used for this purpose. Later on, the obtained results indicate that, Java EE performs better than .NET. by means of response time and memory utilization.},
  doi       = {10.1109/NDT.2009.5272178},
  issn      = {2155-8728},
  keywords  = {Java;program testing;software architecture;software performance evaluation;Hewlett-Packard LoadRunner;Java Enterprise Edition;Parasoft WebKing;Web based application architectures;artificial workload;development life cycle;load testing tools;performance testing;Analytical models;Application software;Automatic testing;Computational modeling;Delay;Java;Performance analysis;Scalability;Service oriented architecture;System testing},
}

@InBook{Baura2002,
  pages     = {0-},
  title     = {Pharmacologic Stress Testing Using Closed-Loop Drug Delivery},
  publisher = {Wiley-IEEE Press},
  year      = {2002},
  author    = {Gail D. Baura},
  isbn      = {9780471683179},
  abstract  = {
This chapter contains sections titled:

Pharmacokinetics and Pharmacodynamics

Control Theory

Problem Significance

Closed-Loop Drug Infusion in Pharmacological Stress Tests

Summary

References

Peripheral Insulin Kinetics Exercises

},
  booktitle = {System Theory and Practical Applications of Biomedical Signals},
  doi       = {10.1109/9780471683179.ch14},
  keywords  = {Absorption;Biomedical monitoring;Blood flow;Drug delivery},
  url       = {https://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5444092},
}

@InProceedings{Kruseman2007,
  author    = {B. Kruseman and A. Majhi and G. Gronthoud},
  title     = {On Performance Testing with Path Delay Patterns},
  booktitle = {25th IEEE VLSI Test Symposium (VTS'07)},
  year      = {2007},
  pages     = {29-34},
  month     = {May},
  abstract  = {Application specific ICs are typically designed to meet a given performance specification. For these ICs a higher performance does not add value and less performance makes the IC useless. This class of ICs is designed based on worst-case corner analysis. It is expected that this will become area costly in more advanced technologies. An alternative is to use statistical design techniques but this implies that the performance needs to be tested with, for example, path delay testing. Our experiments in 65 nm show that the actual delay depends on the global activity within an IC as well as effects in the local neighbourhood of the path. These global and local effects can independently cause about 15% of additional delay. Hence, their impact needs to be included during test and thr authors propose to create (close to) worst-case delay patterns. Individually, the patterns have an enhanced sensitivity for the most important local effects and combined they provide coverage for global effects. This makes them better suited as speed indicators than conventional path delay patterns.},
  doi       = {10.1109/VTS.2007.45},
  issn      = {1093-0167},
  keywords  = {application specific integrated circuits;delays;integrated circuit testing;65 nm;application specific integrated circuits;path delay testing;performance testing;worst-case corner analysis;Added delay;Consumer electronics;Costs;Delay effects;Electronic equipment testing;Frequency;Libraries;Performance analysis;Ring oscillators;Test pattern generators},
}

@InProceedings{Gold2004b,
  author    = {K. Gold and A. Brown},
  title     = {Architecture and performance testing of a software GPS receiver for space-based applications},
  booktitle = {2004 IEEE Aerospace Conference Proceedings (IEEE Cat. No.04TH8720)},
  year      = {2004},
  volume    = {4},
  pages     = {2404-2416 Vol.4},
  month     = {March},
  abstract  = {Space-based GPS technology presents significant challenges over Earth-based systems. These include visibility issues for rotating platforms and tracking of GPS satellites from spacecraft that are in higher orbits than the GPS, realtime resolution of carrier phase ambiguities, and different dynamics during various mission phases. NAVSYS has developed a software GPS receiver that makes use of 3-dimensional digital beam steering technology and inertial aiding to address these issues. This approach offers several advantages including all round visibility for spinning satellites, tracking of weak GPS signals, reduction of multipath, and reprogrammability to accommodate different mission phases. Additionally, a suite of simulation tools based on the NAVSYS Matlab Toolbox and Advanced GPS Hybrid simulation products have been built to allow testing for simulated space environments. The receiver architecture and test tools are described in this paper.},
  doi       = {10.1109/AERO.2004.1368035},
  issn      = {1095-323X},
  keywords  = {Global Positioning System;aerospace computing;artificial satellites;beam steering;hybrid simulation;radio receivers;real-time systems;satellite tracking;software radio;telecommunication equipment testing;3-dimensional digital beam steering technology;Earth based systems;GPS hybrid simulation products;GPS satellite tracking;GPS signal tracking;Matlab toolbox;NAVSYS;carrier phase ambiguity;multipath reduction;realtime resolution;receiver architecture;rotating platforms;simulated space environment;software GPS receiver;space based applications;spinning satellites;Application software;Beam steering;Computer architecture;Global Positioning System;Orbits;Satellites;Software performance;Software testing;Space technology;Space vehicles},
}

@Article{Kalita2011a,
  author   = {M. Kalita and T. Bezboruah},
  title    = {Investigation on performance testing and evaluation of PReWebD: a .NET technique for implementing web application},
  journal  = {IET Software},
  year     = {2011},
  volume   = {5},
  number   = {4},
  pages    = {357-365},
  month    = {August},
  issn     = {1751-8806},
  abstract = {A prototype research web application based on Visual Studio platform is developed with .NET as framework, Internet Information Server (IIS) (Version: 5.1) as web server and Microsoft Standard Query Language (SQL) Server (Version: 2005) as database server to study the performance and evaluation of the .NET technique used for developing the web application. The authors call it the PReWebD. As the performance is one of the most important features of a web application, to evaluate the performance, testing of PReWebD has been carried out using Mercury LoadRunner (Version 8.0) for validation and to study some other attributes like scalability, reliability etc. The performance depends on parameters such as hits/s, response time, throughput, errors/s etc. These parameters for PReWebD are tested with different stress levels. The statistical testing and analysis is done to assure the stability, reliability and quality of the application. Here the authors report in details the architecture, testing procedure, result of performance testing as well as the results of statistical analysis on recorded data of PReWebD.},
  doi      = {10.1049/iet-sen.2010.0139},
  keywords = {Internet;SQL;network operating systems;program testing;software architecture;software performance evaluation;statistical testing;.NET technique;Internet Information Server;Mercury LoadRunner;Microsoft Standard Query Language;PReWebD;SQL server;Visual Studio platform;Web application;Web server;architecture;database server;performance evaluation;performance testing;statistical analysis;statistical testing;stress level},
}

@InProceedings{Heukelman2017,
  author    = {D. Heukelman},
  title     = {Measuring e-readiness: A case study: Self-assessment vs performance testing},
  booktitle = {2017 1st International Conference on Next Generation Computing Applications (NextComp)},
  year      = {2017},
  pages     = {215-219},
  month     = {July},
  abstract  = {Measuring the impact of an ICT-skills intervention can be done in different ways. Typically, one would measure before an intervention and again after the intervention. In this paper the use of self-assessment questionnaires, as opposed to performance testing, is investigated and reported on. A self-assessment questionnaire was administered to 345 first year students entering Higher Education for the first time. Students were assessed before commencing the program: 25 questions, requiring participants to assess their own level of skill, to determine their e-readiness. A subgroup of 55 of these students were subsequently given 3 tasks to perform in a computer laboratory, to assess their e-readiness skills level. The efficiency, accuracy and reliability of the two methods were compared. It was concluded that, based on the efficiency, accuracy and depth of knowledge gained, self-assessment is a valuable tool.},
  doi       = {10.1109/NEXTCOMP.2017.8016201},
  keywords  = {computer literacy;further education;ICT-skills intervention;computer laboratory;e-readiness measurement;e-readiness skills level;higher education;performance testing;self-assessment questionnaire;Atmospheric measurements;Economics;Extraterrestrial measurements;Instruments;Particle measurements;Reliability;Testing;ICT;Skills Measurement;e-Readiness},
}

@Article{Pakin2007,
  author   = {S. Pakin},
  title    = {The Design and Implementation of a Domain-Specific Language for Network Performance Testing},
  journal  = {IEEE Transactions on Parallel and Distributed Systems},
  year     = {2007},
  volume   = {18},
  number   = {10},
  pages    = {1436-1449},
  month    = {Oct},
  issn     = {1045-9219},
  abstract = {CONCEPTUAL is a toolset designed specifically to help measure the performance of high-speed interconnection networks such as those used in workstation clusters and parallel computers. It centers around a high-level domain-specific language, which makes it easy for a programmer to express, measure, and report the performance of complex communication patterns. The primary challenge in implementing a compiler for such a language is that the generated code must be extremely efficient so as not to misattribute overhead costs to the messaging library. At the same time, the language itself must not sacrifice expressiveness for compiler efficiency, or there would be little point in using a high-level language for performance testing. This paper describes the CONCEPTUAL language and the CONCEPTUAL compiler's novel code-generation framework. The language provides primitives for a wide variety of idioms needed for performance testing and emphasizes a readable syntax. The core code-generation technique, based on unrolling CONCEPTUAL programs into sequences of communication events, is simple yet enables the efficient implementation of a variety of high-level constructs. The paper further explains how CONCEPTUAL implements time-bounded loops - even those that comprise blocking communication - in the absence of a time-out mechanism as this is a somewhat unique language/implementation feature.},
  doi      = {10.1109/TPDS.2007.1065},
  keywords = {computational linguistics;high level languages;message passing;program compilers;program control structures;program testing;software performance evaluation;specification languages;CONCEPTUAL language;blocking communication;code generation;domain-specific language;high-level language;high-speed interconnection networks;messaging library;network performance testing;parallel computers;program compiler;readable syntax;time-bounded loops;time-out mechanism;workstation clusters;Computer networks;Concurrent computing;Costs;Domain specific languages;High performance computing;Libraries;Multiprocessor interconnection networks;Programming profession;Testing;Workstations;Interprocessor communications;Measurement techniques;Specialized application languages},
}

@InProceedings{Siivola2016,
  author    = {E. Siivola and S. Sierla and H. Niemistö and T. Karhela and V. Vyatkin},
  title     = {Requirement verification in simulation-based automation testing},
  booktitle = {2016 IEEE 14th International Conference on Industrial Informatics (INDIN)},
  year      = {2016},
  pages     = {740-743},
  month     = {July},
  abstract  = {The emergence of the Industrial Internet results in an increasing number of complicated temporal interdependencies between automation systems and the processes to be controlled. There is a need for verification methods that scale better than formal verification methods and which are more exact than testing. Simulation-based runtime verification is proposed as such a method, and an application of Metric temporal logic is presented as a contribution. The practical scalability of the proposed approach is validated against a production process designed by an industrial partner, resulting in the discovery of requirement violations.},
  doi       = {10.1109/INDIN.2016.7819257},
  keywords  = {Internet;automation;digital simulation;formal verification;production engineering computing;temporal logic;testing;formal verification;industrial Internet emergence;metric temporal logic;production process;requirement verification;simulation-based automation testing;simulation-based runtime verification;Automation;Leaching;Metals;Monitoring;Runtime;Slurries;Testing},
}

@InProceedings{Seth2017,
  author    = {P. Seth and N. Rane and A. Wagh and A. Katade and S. Sahu and N. Malhotra},
  title     = {Uberisation of mobile automation testing},
  booktitle = {2017 International Conference on Intelligent Computing and Control Systems (ICICCS)},
  year      = {2017},
  pages     = {181-183},
  month     = {June},
  abstract  = {Mobile phones and mobile applications have now become an essential part of everyday life. To make Mobile applications more reliable and error free, mobile application testing is important. Currently only a few techniques exist for creating automate tests of mobile applications and their functionality is very limited. In this paper, we introduce the new way of implementing a mobile test automation platform which performs mobile test automation from mobile devices itself. The main aim of automating the testing process is to develop a high quality and optimized applications to deliver efficient results to the customer.},
  doi       = {10.1109/ICCONS.2017.8250706},
  keywords  = {mobile computing;mobile handsets;program testing;Mobile phones;mobile application testing;mobile automation testing;mobile devices;mobile test automation platform;Androids;Automation;Mobile applications;Mobile communication;Mobile handsets;Testing;Tools;Device automation;Mobile app testing;Software Engineering;Software quality;Test Automation;Wireless testing},
}

@InProceedings{Lim2006a,
  author    = {Bum Hyun Lim and Jin Ryong Kim and Kwang Hyun Shim},
  title     = {A load testing architecture for networked virtual environment},
  booktitle = {2006 8th International Conference Advanced Communication Technology},
  year      = {2006},
  volume    = {1},
  pages     = {5 pp.-848},
  month     = {Feb},
  abstract  = {In this work, we develop a load testing architecture for networked virtual environment to reduce the testing time and ensure the stability of the server for distributed applications. It explicitly secures the stability of the server for networked virtual environment and at the same time, it elaborately generates actual loads for testing the performance of the server. Our agent based load testing architecture provides variety of interactions of virtual entities in the virtual worlds to perform realistic simulations. Simulation results show that our proposed architecture ensures the stability and capacity of the servers},
  doi       = {10.1109/ICACT.2006.206095},
  keywords  = {client-server systems;resource allocation;distributed applications;load testing architecture;networked virtual environment;server stability;virtual client;Analytical models;Databases;Discrete event simulation;Environmental management;Large-scale systems;Libraries;Network servers;Protocols;Testing;Virtual environment;Load test;beta test;game simulator;networked virtual environment;stress test;virtual client},
}

@Article{Avritzer2004,
  author   = {A. Avritzer and E. J. Weyuker},
  title    = {The role of modeling in the performance testing of e-commerce applications},
  journal  = {IEEE Transactions on Software Engineering},
  year     = {2004},
  volume   = {30},
  number   = {12},
  pages    = {1072-1083},
  month    = {Dec},
  issn     = {0098-5589},
  abstract = {An e-commerce scalability case study is presented in which both traditional performance testing and performance modeling were used to help tune the application for high performance. This involved the creation of a system simulation model as well as the development of an approach for test case generation and execution. We describe our experience using a simulation model to help diagnose production system problems, and discuss ways that the effectiveness of performance testing efforts was improved by its use.},
  doi      = {10.1109/TSE.2004.107},
  keywords = {Java;electronic commerce;program testing;resource allocation;software performance evaluation;e-commerce;production system diagnosis;software performance modeling;software performance testing;test case generation;workload characterization;Aerospace testing;Computer architecture;Databases;Helium;Java;Monitoring;Production systems;Scalability;Software testing;System testing},
}

@InProceedings{Maalej2013,
  author    = {A. J. Maâlej and M. Hamza and M. Krichen},
  title     = {WSCLT: A Tool for WS-BPEL Compositions Load Testing},
  booktitle = {2013 Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises},
  year      = {2013},
  pages     = {272-277},
  month     = {June},
  abstract  = {This paper addresses the load testing of WS-BPEL compositions. For that, we developed WSCLT tool, which takes as input a specification of the composition under test, expressed as a Timed Automaton, and considers various parameters such as the number of requests to handle simultaneously. Our WSCLT tool injects this load in the application and monitors the sequence of requests, invocations and responses between the components. This log is then analyzed by the tool to separate the actions corresponding to each instance and to check that they follow legitimate paths. A global report is then issued regarding all concurrent instances. We illustrate how to use our prototype tool by means of a case study.},
  doi       = {10.1109/WETICE.2013.71},
  issn      = {1524-4547},
  keywords  = {Web services;automata theory;program testing;WS-BPEL compositions;WSCLT;load testing;timed automaton;Atmospheric modeling;Automata;Delays;Load modeling;Queueing analysis;Testing;Web services;Timed Automaton;WS-BPEL compositions;load testing;log analysis},
}

@InProceedings{Williamette2012,
  author    = {C. Williamette and E. Hansen},
  title     = {Development of electrical performance testing standards for the acceptance of solar photovoltaic projects based on field experience and observation},
  booktitle = {2012 38th IEEE Photovoltaic Specialists Conference},
  year      = {2012},
  pages     = {000554-000559},
  month     = {June},
  abstract  = {As-built performance requirements are becoming more common in Interconnection Applications (IAs) and Power Purchase Agreements (PPAs). Often overlooked as, “just the last step in the commissioning process,” it is important to understand the scope of the testing requirements before committing to the agreement. The worst case scenario is when your project has design flaws that prevent it from meeting requirements. By the time the system is discovered to be failing, it can be too late and too costly to fix. Understanding standards for performance testing can help guide project design to ensure better success meeting those requirements later on.},
  doi       = {10.1109/PVSC.2012.6317675},
  issn      = {0160-8371},
  keywords  = {commissioning;interconnections;photovoltaic power systems;solar power stations;standards;PPA;commissioning process;electrical performance testing standards;field experience;interconnection applications;power purchase agreements;solar PV systems;solar photovoltaic projects;Indexes;Inverters;Irrigation;Monitoring;Soil;Wiring;Current-voltage characteristics;Performance Analysis;Soil measurements;Solar energy;System analysis and design;Thermal analysis},
}

@InProceedings{Kim2009b,
  author    = {G. h. Kim and H. c. Moon and G. P. Song and S. K. Shin},
  title     = {Software Performance Testing Scheme Using Virtualization Technology},
  booktitle = {Proceedings of the 4th International Conference on Ubiquitous Information Technologies Applications},
  year      = {2009},
  pages     = {1-5},
  month     = {Dec},
  abstract  = {In this paper, we propose software performance testing scheme using virtualization technology. Generally, people have used software performance testing tool such as load runner and silk performer. However, people should perform software performance testing manually in case of the situation that people cannot use testing tool. It needs a lot of resources such as human resource and computing resource. Therefore, we propose software performance testing scheme using virtualization technology to reduce resource consumption. Proposed scheme can reduce computer resource consumption because virtualization technology can make a number of virtual computers with a small number of physical computers. Also proposed scheme can reduce human resource consumption because, in proposed scheme, management computer can control keyboard and mouse of virtual computers automatically. Simulation result shows that proposed scheme has possibility to be used for software performance testing.},
  doi       = {10.1109/ICUT.2009.5405721},
  issn      = {1976-0035},
  keywords  = {software performance evaluation;virtual machines;computer management;computing resource;human resource;software performance testing;virtual computers;virtualization technology;Automatic control;Computational modeling;Human resource management;Keyboards;Mice;Performance evaluation;Physics computing;Resource virtualization;Software performance;Software testing},
}

@Article{Krishnamurthy2006,
  author   = {D. Krishnamurthy and J. A. Rolia and S. Majumdar},
  title    = {A Synthetic Workload Generation Technique for Stress Testing Session-Based Systems},
  journal  = {IEEE Transactions on Software Engineering},
  year     = {2006},
  volume   = {32},
  number   = {11},
  pages    = {868-882},
  month    = {Nov},
  issn     = {0098-5589},
  abstract = {Enterprise applications are often business critical but lack effective synthetic workload generation techniques to evaluate performance. These workloads are characterized by sessions of interdependent requests that often cause and exploit dynamically generated responses. Interrequest dependencies must be reflected in synthetic workloads for these systems to exercise application functions correctly. This poses significant challenges for automating the construction of representative synthetic workloads and manipulating workload characteristics for sensitivity analyses. This paper presents a technique to overcome these problems. Given request logs for a system under study, the technique automatically creates a synthetic workload that has specified characteristics and maintains the correct interrequest dependencies. The technique is demonstrated through a case study involving a TPC-W e-commerce system. Results show that incorrect performance results can be obtained by neglecting interrequest dependencies, thereby highlighting the value of our technique. The study also exploits our technique to investigate the impact of several workload characteristics on system performance. Results establish that high variability in the distributions of session length, session idle times, and request service times can cause increased contention among sessions, leading to poor system responsiveness. To the best of our knowledge, these are the first results of this kind for a session-based system. We believe our technique is of value for studies where fine control over workload is essential},
  doi      = {10.1109/TSE.2006.106},
  keywords = {electronic commerce;performance evaluation;program testing;TPC-W e-commerce system;e-commerce system;enterprise application;performance evaluation;sensitivity analyses;stress testing session-based system;synthetic workload generation technique;Application software;Character generation;Computer Society;Delay;Occupational stress;Sensitivity analysis;Stress control;System performance;System testing;Web server;Internet applications;Performance of systems;Web servers.;electronic commerce;measurement techniques;modeling techniques;software engineering;testing tools},
}

@InProceedings{Habash2011,
  author    = {R. W. Y. Habash and V. Groza and Y. Yang and C. Blouin and P. Guillemette},
  title     = {Performance Testing and Control of a Small Wind Energy Converter},
  booktitle = {2011 Sixth IEEE International Symposium on Electronic Design, Test and Application},
  year      = {2011},
  pages     = {263-268},
  month     = {Jan},
  abstract  = {Responding to more demand in coming years, the task of the small wind energy industry requires progress on several fronts-from public policy initiatives, to technology development, to market growth. Enhanced technologies such as contra-rotating blades, transmission systems, lubrication, airfoils, generators, and power electronics will lower cost and increase energy production. This paper mainly considers two key technological points of a small wind energy converter (SWEC) namely, the performance of the rotor system and induction generator. Small-scale prototypes have been built to experimentally verify the performance of the SWEC. Wind tunnel tests of the power output, power coefficient, and turbine speed were carried out to ascertain the aerodynamic power conversion and the operation capability at lower wind speeds. The results demonstrated a significant increase in performance compared to a single-rotor system of the same type. Another aspect of development and test is to present a comparative performance evaluation between a standard induction generator and an efficient but with modified design (TRIAS Generator) as a realistic solution of clean power for grid-connected SWECs. The paper also discusses issues related to control and monitoring of SWEC.},
  doi       = {10.1109/DELTA.2011.55},
  keywords  = {aerodynamics;asynchronous generators;power convertors;power generation control;power grids;power markets;rotors;wind power plants;wind tunnels;wind turbines;aerodynamic power conversion;grid connected SWEC;induction generator;market growth;performance testing;public policy;rotor system;small scale prototype;small wind energy converter control;technology development;wind energy industry;wind tunnel;Blades;Generators;Induction motors;Rotors;Wind energy;Wind speed;Wind turbines;Small wind generator;contra-rotating system;induction generator},
}

@InProceedings{Duttagupta2011a,
  author    = {S. Duttagupta and M. Nambiar},
  title     = {Performance Extrapolation for Load Testing Results of Mixture of Applications},
  booktitle = {2011 UKSim 5th European Symposium on Computer Modeling and Simulation},
  year      = {2011},
  pages     = {424-429},
  month     = {Nov},
  abstract  = {Load testing of IT applications faces the challenge of providing high quality test results that would represent the performance in production like scenarios, without incurring high cost of commercial load testing tools. It would help IT projects to be able to test with a small number of users and extrapolate to scenarios with much larger number of users. Such an extrapolation strategy when applied to mixture of application workloads running on a shared server environment must take into consideration application characteristics (CPU/IO intensive, memory bound) as well the server capabilities. The goal is to predict the performance of mixture workload, the maximum throughput offered by the application mix and the maximum number of users supported by the system before the throughput starts degrading. In this paper, we propose an extrapolation strategy that analyses a system workload mix based on its service demand on various resources and extrapolates its performance using simple empirical modeling techniques. Moreover, its ability to extrapolate throughput of an application mixture even if there is a change in the mixture, can help in capacity planning of the system.},
  doi       = {10.1109/EMS.2011.56},
  keywords  = {extrapolation;program testing;IT application;application mixture;empirical modeling technique;extrapolation strategy;information technology;load testing;Extrapolation;Load modeling;Production;Servers;Telecommunications;Testing;Throughput;Extrapolation;S-curve;load Testing;mixture of applications;multi-classes of job},
}

@InProceedings{Singh2012,
  author    = {M. Singh and R. Singh},
  title     = {Load Testing of web frameworks},
  booktitle = {2012 2nd IEEE International Conference on Parallel, Distributed and Grid Computing},
  year      = {2012},
  pages     = {592-596},
  month     = {Dec},
  abstract  = {This document deals with a comparative analysis on the web frame works namely Spring3.0 MVC, Struts 2.0, JSF 1.2x and Wickets. A detailed study is given on the behavior of the frameworks when they are utilized in the front end and at the backend JPA is used to make communication with the database. The Database utilized is Oracle 10g. Load Testing of all the applications is done using J-meter.},
  doi       = {10.1109/PDGC.2012.6449887},
  keywords  = {Internet;database management systems;online front-ends;program testing;J-meter;JSF 1.2x;Oracle 10g;Spring3.0 MVC;Struts 2.0;Web frameworks;Wickets;backend JPA;database;front end;load testing;Bandwidth;Color;Information filters;Process control;Springs;Throughput;JSF 1.2x;Spring3.0 MVC;Struts 2.0;Wickets and JPA},
}

@InProceedings{Subraya2000,
  author    = {B. M. Subraya and S. V. Subrahmanya},
  title     = {Object driven performance testing of Web applications},
  booktitle = {Proceedings First Asia-Pacific Conference on Quality Software},
  year      = {2000},
  pages     = {17-26},
  abstract  = {Performance of many Web sites depends on the load on the site at peak time under varying conditions. Performance testing is normally conducted in reasonably simulated environment with the help of performance testing tools. However, performance of a Web site depends on various parameters and each parameter must be tested under varying stress levels. It is not possible to draw a common denominator for performance parameters to test the Web site due to complexity of Web sites. Different parts of the Web site must be tested with different parameters under varying condition and stress level. In such circumstances, it is necessary to decompose the Web site into many components, which represents the behavior of various business components. These business components are mapped to various objects that truly represent the behavior and structure of the part of the web site. These objects are subjected to performance testing with different parameters and stress levels. This paper addresses the new testing process, which uses the concept of decomposing the behavior of the Web site into testable components, which are mapped onto testable objects. These testable objects are subjected to performance testing under varied performance parameters and stress levels},
  doi       = {10.1109/APAQ.2000.883774},
  keywords  = {computational complexity;information resources;program testing;programming environments;software performance evaluation;Web applications;Web sites;complexity;object driven performance testing;performance parameters;simulated environment;Acoustic testing;Application software;Cities and towns;Consumer electronics;Electronic commerce;Life testing;Software testing;Stress;System testing;Time to market},
}

@InProceedings{Haarmann2018,
  author    = {B. Haarmann and C. Martens and H. Petzka and G. Napolitano},
  title     = {A Mighty Dataset for Stress-Testing Question Answering Systems},
  booktitle = {2018 IEEE 12th International Conference on Semantic Computing (ICSC)},
  year      = {2018},
  pages     = {278-281},
  month     = {Jan},
  abstract  = {The general goal of semantic question answering systems is to provide correct answers to natural language queries, given a number of structured datasets. The increasing broad deployment of question answering (QA) systems in everyday life requires a comparable and reliable rating of how well QA systems perform and how scalable they are. In order to achieve this, we developed a massive dataset of more than 2 million natural language questions and their SPARQL queries for the DBpedia dataset. We combined natural language processing and linked open data to automatically generate this large amount of valid question-query pairs. Our aim is to assist the benchmarking or scoring of QA systems in terms of answering questions in a range of languages, retrieving answers from heterogeneous sources or answering massive amounts of questions within a limited time. This dataset represents an ideal choice for stress-testing systems' scalability, speed and correctness. As such it has already been included into the Large-scale QA task of the Question Answering Over Linked Data (QALD) Challenge and the HOBBIT project Question Answering Benchmark.},
  doi       = {10.1109/ICSC.2018.00054},
  keywords  = {Linked Data;natural language processing;query processing;question answering (information retrieval);DBpedia dataset;HOBBIT project Question Answering Benchmark;QA systems;SPARQL queries;combined natural language processing;natural language questions;semantic question answering systems;stress-testing Question Answering systems;stress-testing systems;valid question-query pairs;Benchmark testing;Knowledge discovery;Linked data;Natural languages;Resource description framework;Standards;Task analysis;Benchmark;DBpedia;Question-Answering;Semantics},
}

@InProceedings{Yang2012,
  author    = {X. Yang and Z. Chen},
  title     = {An improved wavelet denoising method used in electrical throttle performance testing},
  booktitle = {2012 International Conference on Image Analysis and Signal Processing},
  year      = {2012},
  pages     = {1-4},
  month     = {Nov},
  abstract  = {In this paper, an electrical throttle performance test system is designed mainly focusing on its potentiometer and function tests. An improved denoising algorithm based upon the wavelet transform is proposed in non-stationary testing environment. In the experiment, the virtual instrument is used to call the denoising module and processes the acquiring signals. It is proved that its effect is obviously more excellent than conventional algorithms. This test system is then used in actual assembly line. Good parts can be sorted out efficiently and the quality of assembly line is improved.},
  doi       = {10.1109/IASP.2012.6425016},
  issn      = {2156-0110},
  keywords  = {assembling;automotive engineering;fuel systems;mechanical testing;signal denoising;wavelet transforms;assembly line;electrical throttle performance testing;nonstationary testing environment;virtual instrument;wavelet denoising;wavelet transform;Algorithm design and analysis;Educational institutions;Noise;Noise reduction;Testing;Wavelet transforms;electrical throttle;performance test;wavelet denoising},
}

@InProceedings{Shen2016,
  author    = {A. Shen and M. Kuzlu and M. Pipattanasomporn and S. Rahman and L. Chen},
  title     = {A performance testing method for embedded software platforms},
  booktitle = {2016 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)},
  year      = {2016},
  pages     = {135-140},
  month     = {June},
  abstract  = {Performance testing is an important process in the embedded software development. It can detect bugs, help improve software quality and test the system reliability. The objective of this paper is to propose a performance testing method for embedded software platforms. A case study to evaluate the applicability of the proposed method is discussed. Performance tests are performed on three different platforms and test results are compared.},
  doi       = {10.1109/CYBER.2016.7574810},
  keywords  = {embedded systems;program debugging;program testing;software performance evaluation;software quality;software reliability;bug detection;embedded software development;embedded software platforms;performance testing;software quality;system reliability;Embedded software;Hardware;Monitoring;Software performance;Testing;Thermostats;Performance testing;embedded software;multi-agent;open source},
}

@InProceedings{Miljkovic2012a,
  author    = {Đ. Miljković and S. Bojić and M. Đukić and M. Jovanović},
  title     = {Automation testing of Graphical User Interface},
  booktitle = {2012 20th Telecommunications Forum (TELFOR)},
  year      = {2012},
  pages     = {1609-1612},
  month     = {Nov},
  abstract  = {In this paper is explained one solution for automation of testing Graphical User Interface. The paper gives a description of the problem, the concept of a solution and a description of the implementation of such a solution in order to confirm the above concept. Validation of the implementation was carried out on graphical tool for the development of software for audio target platform.},
  doi       = {10.1109/TELFOR.2012.6419531},
  keywords  = {graphical user interfaces;program testing;software engineering;audio target platform;automation testing;graphical tool;graphical user interface;software development;Automation;Browsers;Electronic mail;Graphical user interfaces;Manuals;Testing;XML;GUI;GUIPlayer;Lua;XML;ispitivanje},
}

@InProceedings{Meyer2017,
  author    = {G. Meyer},
  title     = {Enhanced Power Electronics System for High-Performance Testing of Motor Control Units in a Power HIL Environment},
  booktitle = {PCIM Asia 2017; International Exhibition and Conference for Power Electronics, Intelligent Motion, Renewable Energy and Energy Management},
  year      = {2017},
  pages     = {1-8},
  month     = {June},
  abstract  = {Hardware-in-the-loop (HIL) simulation is an established test method for analyzing motor control units (MCUs). For highly integrated drive controllers, the controller and the power electronics must be tested at the electric power level (emulation). Using this method requires specific power electronics for emulation. This paper introduces a special hardware solution that is based on an interleaved switching, three-level neutral-point-clamped (NPC) inverter and a sophisticated model-predictive control algorithm to establish a high-bandwidth electronic load for testing electronic power systems.},
}

@InProceedings{Shang2017,
  author    = {D. Shang and X. Zhang and J. Han and X. Xu},
  title     = {MultiModal-database-XJTU: An available database for biometrics recognition with its performance testing},
  booktitle = {2017 IEEE 3rd Information Technology and Mechatronics Engineering Conference (ITOEC)},
  year      = {2017},
  pages     = {521-526},
  month     = {Oct},
  abstract  = {The current need for large multimodal databases to evaluate automatic biometrics recognition systems has motivated the development of the XJTU multimodal database. The main purpose has been to consider a large scale population, with statistical significance, in a real multimodal procedure, and including several sources of variability that can be found in real environments. The acquisition process, contents and availability of the single-session baseline corpus are fully described. Some experiments showing consistency of data through the different acquisition sites and assessing data quality are also presented. MultiModal-Database-XJTU, a new multimodal database, is presented. The database consists of fingerprint images acquired with sensor, frontal face images from a camera, iris images from a Cannon scanner, and voice utterances acquired with a microphone. The MultiModal-Database-XJTU includes real multimodal data from 102 individuals. In this contribution, the acquisition setup and protocol are outlined, and the contents of the database are described. The database will be publicly available for research purposes.},
  doi       = {10.1109/ITOEC.2017.8122351},
  keywords  = {biometrics (access control);feature extraction;fingerprint identification;MultiModal-database-XJTU;XJTU multimodal database;automatic biometrics recognition systems;data quality;multimodal data;multimodal procedure;Authentication;Databases;Face;Feature extraction;Fingerprint recognition;Fingers;Multi-focus image fusion;Perfect reconstruction;Quantum particle swarm optimization;Superior speed},
}

@InProceedings{Amelot2011,
  author    = {J. Amelot and Y. S. Li-Baboud and C. Vasseur and J. Fletcher and D. Anand and J. Moyne},
  title     = {An IEEE 1588 Performance Testing Dashboard for Power Industry requirements},
  booktitle = {2011 IEEE International Symposium on Precision Clock Synchronization for Measurement, Control and Communication},
  year      = {2011},
  pages     = {132-137},
  month     = {Sept},
  abstract  = {The numerous time synchronization performance requirements in the Smart Grid necessitates a set of common metrics and test methods. The test methods help to verify the ability of the network system and its components to meet the power industry's accuracy, reliability and interoperability criteria for next-generation substations. In order to develop viable metrics and test methods, an IEEE 1588 Testbed for the power industry has been established. To ease the challenges of testing, monitoring and analysis of the results, a software-based testing dashboard was designed and implemented. The dashboard streamlines the performance testing process by converging multiple tests for accuracy, reliability and interoperability into a centralized interface. The dashboard enables real-time visualization and analysis of the results. The paper details the design and implementation of the IEEE 1588 Power Industry Performance Testing Dashboard as well as an update of the preliminary findings from the testbed.},
  doi       = {10.1109/ISPCS.2011.6070157},
  issn      = {1949-0305},
  keywords  = {open systems;power engineering computing;power generation reliability;smart power grids;substations;synchronisation;IEEE 1588;dashboard streamlines;interoperability;next-generation substations;power industry performance testing dashboard;reliability;smart grid;software-based testing dashboard;time synchronization;Frequency synchronization;Power industry;Robustness;Switches;Synchronization;Time frequency analysis;IEEE 1588;PMU;conformance testing;test methods;time synchronization},
}

@InProceedings{Niederstrasser1999,
  author    = {C. G. Niederstrasser and C. A. Kitts and M. A. Swartwout},
  title     = {Design and performance testing of a satellite health beacon receiving station},
  booktitle = {1999 IEEE Aerospace Conference. Proceedings (Cat. No.99TH8403)},
  year      = {1999},
  volume    = {5},
  pages     = {241-251 vol.5},
  abstract  = {As part of its space operations research program, Stanford University's Space Systems Development Laboratory (SSDL) is implementing an automated state of health assessment and notification system for spacecraft. Onboard the spacecraft, this system consists of software that filters telemetry to derive a health assessment and a periodic beacon that broadcasts this assessment to the ground. Throughout the world, a network of low-cost receiving stations receives the beacon signal and relays it to a central mission control center via the Internet. This paper addresses the design and development of a beacon receiving station. Each station is designed to be approximately an order of magnitude lower in price than a conventional two-way ground station. Emphasis is placed on making sure the station is highly autonomous, requiring little or no assistance from the host site. The stations are made up of only three separate components-an antenna, a receiver, and a personal computer},
  doi       = {10.1109/AERO.1999.790205},
  keywords  = {aerospace test facilities;automatic test equipment;automatic testing;computerised monitoring;ground support systems;receiving antennas;satellite ground stations;signal processing;telecommunication computing;Stanford University;antenna;beacon signal;central mission control center;cost;health assessment;performance testing;periodic beacon;personal computer;satellite health beacon receiving station;telemetry;two-way ground station;Information filtering;Information filters;Laboratories;Operations research;Relays;Satellite broadcasting;Software systems;Space vehicles;Telemetry;Testing},
}

@Article{Angrisani2003,
  author   = {L. Angrisani and A. Baccigalupi and G. D'Angiolo},
  title    = {A frame-level measurement apparatus for performance testing of ATM equipment},
  journal  = {IEEE Transactions on Instrumentation and Measurement},
  year     = {2003},
  volume   = {52},
  number   = {1},
  pages    = {20-26},
  month    = {Feb},
  issn     = {0018-9456},
  abstract = {Performance testing of asynchronous transfer mode (ATM) equipment is dealt with here. The attention is principally paid to frame-level metrics, recently proposed by the ATM Forum because of their suitability to reflect user-perceived performance better than traditional cell-level metrics. Following the suggestions of the ATM Forum, more and more network engineers and production managers are interested today in these metrics, thus increasing the need of instruments and measurement solutions appropriate to their estimation. Trying to satisfy this exigency, a new VME extension for instrumentation (VXI) based measurement apparatus is proposed in the paper. The apparatus features a suitable software, developed by the authors, which allows the evaluation of the aforementioned metrics by simply making use of common ATM analyzers; only two VXI line interfaces, capable of managing the physical and ATM layers, are, in fact, adopted. Some details concerning ATM technology and its hierarchical structure, as well as the main differences between frames, specific to the ATM adaptation layer, and cells, characterizing the underlying ATM layer, are first given. Both the hardware and software solutions of the measurement apparatus are then described in detail, paying particular attention to the measurement procedures implemented. In the end, the performance of a new ATM device is assessed through the proposed apparatus.},
  doi      = {10.1109/TIM.2003.809063},
  keywords = {asynchronous transfer mode;automatic test equipment;telecommunication computing;telecommunication equipment testing;ATM equipment;VME extension;VXI instrumentation;frame-level metric;measurement apparatus;performance testing;Asynchronous transfer mode;B-ISDN;Delay;Instruments;Laboratories;Manufacturing;Particle measurements;Quality of service;Software measurement;Testing},
}

@InProceedings{Jin2010,
  author    = {Ni Jin and Wang Mingming and Wang Jiangqing},
  title     = {Realization on intelligent GUI automation testing based-on .NET},
  booktitle = {2010 3rd International Conference on Computer Science and Information Technology},
  year      = {2010},
  volume    = {1},
  pages     = {14-17},
  month     = {July},
  abstract  = {Points out the obvious deficiencies in capture/playback mechanism at present, aiming at difficulties of maintenance and extension in constantly altered GUI elements, presents a new GUI automation testing solution - Building AUILibrary. It can search, identify all the controls, trigger all kinds of mouse and keyboard events, execute data driving verification roundly and accurately, trace and record execution process and save the locale when exception occurs, implement flexible and effective GUI automation testing indeed.},
  doi       = {10.1109/ICCSIT.2010.5563862},
  keywords  = {graphical user interfaces;program testing;software tools;user interface management systems;.NET framework;AUILibrary;capture mechanism;data driving verification;intelligent GUI automation testing;playback mechanism;Automation;Computers;Graphical user interfaces;Indexes;Software;GUI;Software testing;automation},
}

@InProceedings{Li2010a,
  author    = {G. Li and N. Tan},
  title     = {Design and Implementation of Remote Monitoring and Control System for Freight Train Load Testing},
  booktitle = {2010 Third International Conference on Information and Computing},
  year      = {2010},
  volume    = {1},
  pages     = {117-120},
  month     = {June},
  abstract  = {The key technology of the fatigue reliability design and test evaluation of freight train is to establish freight train load spectrum based on operating conditions. Design a set of remote monitoring and control system for the establishment of loading spectrum's actual needs. The system uses GPS technology for vehicle location, speed and other information, through the GPRS technology to build car-side with the ground control center of the interaction channel. Using the ARM7 microprocessors, transplant embedded μC/OS-II operating system, realized the hardware management and task scheduling. The system can achieve vehicle-side with the ground control center data exchange. Through the ground control center monitoring software running real-time get the vehicles and the test equipment status, timely adjustment of test equipment. At the same time enables automatic vehicle equipment. The system basically meet the needs of the overloaded train load test research requirements can be a steady, accurate and complete remote monitoring and control functions.},
  doi       = {10.1109/ICIC.2010.36},
  issn      = {2160-7443},
  keywords  = {Global Positioning System;automatic test equipment;computerised monitoring;microprocessor chips;operating systems (computers);packet radio networks;rail traffic;scheduling;traffic engineering computing;ARM7 microprocessors;GPRS technology;GPS technology;automatic vehicle equipment;data exchange;embedded μC/OS-II operating system;fatigue reliability design;freight train load spectrum;freight train load testing;ground control center;hardware management;remote monitoring;task scheduling;train car-side;Automatic control;Control systems;Fatigue;Global Positioning System;Land vehicles;Loading;Remote monitoring;Road vehicles;System testing;Test equipment;#NAME?},
}

@Article{Hempel2015,
  author   = {M. Hempel and J. W. Tomm and D. Venables and V. Rossin and E. Zucker and T. Elsaesser},
  title    = {Long-Term Aging and Quick Stress Testing of 980-nm Single-Spatial Mode Lasers},
  journal  = {Journal of Lightwave Technology},
  year     = {2015},
  volume   = {33},
  number   = {21},
  pages    = {4450-4456},
  month    = {Nov},
  issn     = {0733-8724},
  abstract = {Single-spatial mode lasers emitting at 980 nm are studied during continuous-wave long-term operation and ultra-high power short-term operation (stress-test) up to 13.5 W. We find that both tests eventually activate the same degradation mechanism, namely internal catastrophic optical damage. In the case of ultra-high power operation, we show that the mechanism that initializes this effect is a lateral widening of the optical mode, resulting in increased absorption outside the waveguide. Defects formed during long-term aging may eventually lead to the same effect. Stress testing allows for activation of several degradation mechanisms in a device one after the other and for distinguishing between mechanisms induced by aging and independent ones. Stress tests could pave the way toward more time-efficient testing, e.g., for comparison of different technology variants in development.},
  doi      = {10.1109/JLT.2015.2475605},
  keywords = {Aging;Cameras;Cavity resonators;Degradation;Monitoring;Optical pulses;Temperature measurement;Semiconductor device measurements;reliability;semiconductor diodes;semiconductor lasers},
}

@InProceedings{Brcic2015,
  author    = {P. Brčić},
  title     = {Performance testing of EMC xtremio all-flash storage system},
  booktitle = {2015 23rd Telecommunications Forum Telfor (TELFOR)},
  year      = {2015},
  pages     = {1020-1023},
  month     = {Nov},
  abstract  = {EMC XtremIO is one of the most advanced all-Flash data storage systems which is becoming an integral part of medim and enterprise data centers. The paper represents implementation of EMC XtremIO storage system for VDI, and adopted, implemented and validated methodology for testing performance of storage systems. There were generated and released three groups of different intense load tests, during which the data was collected, created tables and graphs. Finally was generated detailed analysis of the results.},
  doi       = {10.1109/TELFOR.2015.7377639},
  keywords  = {flash memories;program testing;EMC XtremIO all-flash storage system;load tests;storage system testing performance;Electromagnetic compatibility;Monitoring;Optical fiber testing;Servers;Synthetic aperture sonar;Virtual machining;All-Flash;XtremIO;data centri;performanse;sistem za skladi¿¿tenje podataka},
}

@InProceedings{Tang2010,
  author    = {J. l. Tang and Y. j. Liu and F. s. Wu},
  title     = {Virtual experiment system for metal creep performance testing based on VRML},
  booktitle = {2010 2nd International Conference on Advanced Computer Control},
  year      = {2010},
  volume    = {4},
  pages     = {140-143},
  month     = {March},
  abstract  = {A virtual experiment system for metal creep performance testing is built by virtual reality modeling language (VRML). The structure, function and design principles of the system are described and its implementation procedure is also discussed. The key development process, including object modeling, 3D scene building, VRML connecting to the real-time database, design of interactive virtual 3D scene and complex virtual interaction, is illustrated in this paper. In addition, the following key problems have been solved during the system realization: virtual models building and geometrical transforming, database designing and optimizing, 3D virtual experimental scenes combining dynamically, the realization of database accessing and the communication of virtual entities.},
  doi       = {10.1109/ICACC.2010.5486954},
  keywords  = {computer testing;database management systems;human computer interaction;virtual reality languages;3D scene building;complex virtual interaction;geometrical transforming;interactive virtual 3D scene;metal creep performance testing;object modeling;real time database;virtual entities;virtual experiment system;virtual reality modeling language;Buildings;Communication system control;Computer simulation;Creep;Instruments;Layout;Spatial databases;System testing;Virtual environment;Virtual reality;VRML;creep performance test;metal;virtual experiment},
}

@Article{Helmy2005,
  author   = {A. Helmy and S. Gupta},
  title    = {FOTG: fault-oriented stress testing of IP multicast},
  journal  = {IEEE Communications Letters},
  year     = {2005},
  volume   = {9},
  number   = {4},
  pages    = {375-377},
  month    = {April},
  issn     = {1089-7798},
  abstract = {Network simulators provide a useful tool, for protocol evaluation. However, the results depend heavily on the simulated scenarios, especially for complex protocols such as multicast. There has been little work on scenario generation. In this work we present a fault-oriented test generation (FOTG) algorithm for automated stress testing of multicast protocols. FOTG processes an extended FSM model and uses a mix of forward and backward search techniques. Unlike traditional verification approaches, instead of starting from initial states, FOTG starts from a fault and uses cause-effect relations for automatic topology synthesis then uses backward implication to generate tests. Using FOTG we test various mechanisms commonly employed by multicast routing and validate our results through simulation.},
  doi      = {10.1109/LCOMM.2005.1413639},
  keywords = {IP networks;multicast protocols;routing protocols;search problems;telecommunication network topology;FOTG algorithm;FSM model;IP multicast routing;automated stress testing;backward search technique;fault-oriented test generation;forward search technique;network simulator;protocol evaluation;topology synthesis;traditional verification approach;Automatic testing;Engines;Multicast algorithms;Multicast protocols;Robustness;Routing protocols;Stress;System testing;Topology;Very large scale integration},
}

@InProceedings{Dinh2016,
  author    = {A. Dinh and F. M. Bui and T. Nguyen},
  title     = {An accelerometer based system to measure myocardial performance index during stress testing},
  booktitle = {2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
  year      = {2016},
  pages     = {4877-4880},
  month     = {Aug},
  abstract  = {Stress testing is used to measure the performance of the heart in an elevated stress state, in order to monitor or diagnose certain heart problems. Many measurements can be used to determine the performance of the heart, with the Tei index being the measurement of interest in this work. The Tei index has been used as a reliable method to evaluate systolic and diastolic performance, as it overcomes some limitations of the classical echocardiographic indices. It is calculated based on the time intervals derived from echocardiography. This paper presents an exploratory study, which uses an accelerometer to record mechanical events occurring in each cardiac cycle, also known as the seismocardiogram (SCG). From timing measurements corresponding to various events in the heart, a metric for myocardial performance is calculated based on the Tei index. The use of SCG in addition to ECG has the potential to provide further insights about the heart during stress testing, since the SCG quantifies mechanical actions of the heart.},
  doi       = {10.1109/EMBC.2016.7591820},
  issn      = {1557-170X},
  keywords  = {accelerometers;biomedical equipment;electrocardiography;ECG;Tei index;accelerometer based system;cardiac cycle;diastolic performance;heart problem diagnosis;mechanical events;myocardial performance index measurements;seismocardiogram;stress state;stress testing;systolic performance;timing measurements;Accelerometers;Electrocardiography;Heart;Indexes;Sensors;Stress;Valves;Accelerometry;Diastole;Echocardiography;Exercise Test;Female;Heart;Heart Function Tests;Humans;Male;Systole;Wireless Technology},
}

@InProceedings{Chan1994a,
  author    = {H. A. Chan},
  title     = {A formulation to optimize stress testing},
  booktitle = {1994 Proceedings. 44th Electronic Components and Technology Conference},
  year      = {1994},
  pages     = {1020-1027},
  month     = {May},
  abstract  = {Although hard-defects may be detectable in factory tests, weak products may exhibit failures or degrade only under certain stress conditions. Without stress testing, these weak products may often be shipped to customers causing early failures in the field. A candidate product for stress testing needs to get more business benefits to more than pay off the cost of stress testing. A business measure of the success of the stress testing program is the net benefit, which is the total benefit minus the total cost of the program. The optimum stress testing program maximizes this net benefit. A given unit of a product has a probability of encountering a maximum stress X during its product life. It also has a probability of possessing a product yield strength Y, which is the maximum stress the unit can survive without failure. While the strength distribution depends on the design and manufacture processes, the distribution of the maximum stress is determined by the customers' environment. A convenient picture is to construct the contour map of the joint probability distribution of X and Y. In this contour map, a unit falling in the Y<X region will fail during its product life, whereas one falling in the Y>X region will not result in field failure. The effects of stress testing at a given maximum stress level, XST, are shown by a dividing line on the product strength into stress test failure and stress test pass. The units in the contour map are then divided into four regions by the Y=X line and the XST line. The cost and benefits may now be evaluated for each region. Now the value of XST is a free parameter that determines the relative size of each region. The second free parameter is the fraction of units going through stress testing. These two parameters may be adjusted to maximize the net benefit of the stress testing program},
  doi       = {10.1109/ECTC.1994.367502},
  keywords  = {circuit optimisation;environmental stress screening;environmental testing;failure analysis;integrated circuit yield;life testing;probability;production testing;contour map;early failures;factory tests;joint probability distribution;maximum stress;net benefit;product life;product yield strength;stress conditions;stress test failure;stress test pass;stress testing;Circuit testing;Costs;Degradation;Electronic equipment testing;Manufacturing processes;Probability distribution;Process design;Production facilities;Stress measurement;System testing},
}

@InProceedings{Angrisani2001,
  author    = {L. Angrisani and A. Baccigalupi and G. D'Angiolo},
  title     = {A frame-level measurement apparatus for performance testing of ATM equipment},
  booktitle = {IMTC 2001. Proceedings of the 18th IEEE Instrumentation and Measurement Technology Conference. Rediscovering Measurement in the Age of Informatics (Cat. No.01CH 37188)},
  year      = {2001},
  volume    = {3},
  pages     = {1630-1635 vol.3},
  abstract  = {Performance testing of ATM equipment is here dealt with. In particular, the attention is paid to frame-level metrics, recently proposed by the ATM forum because of their suitability to reflect user-perceived performance better than traditional cell-level metrics. Following the suggestions of the ATM forum, more and more network engineers and production managers are nowadays interested in these metrics, thus increasing the need of instruments and measurement solutions appropriate to their estimation. Trying to satisfy this exigency, a new VXI-based measurement apparatus is proposed in the paper. The apparatus features a suitable software, developed by the authors, which allows the evaluation of the aforementioned metrics by making simply use of common ATM analyzers; only two VXI line interfaces, capable of managing both the physical and ATM layer, are, in fact, adopted. At first, some details about the hierarchical structure of the ATM technology as used as the main differences between frames, peculiar to the ATM adaptation layer, and cells characterizing the lower ATM layer are given. Then, both the hardware and software solutions of the measurement apparatus are described in detail with a particular attention to the measurement procedures implemented. At the end the performance of a new ATM device, developed by Ericsson, is assessed in terms of frame-level metrics by means of the proposed apparatus},
  doi       = {10.1109/IMTC.2001.929479},
  issn      = {1091-5281},
  keywords  = {asynchronous transfer mode;automatic test equipment;performance evaluation;peripheral interfaces;telecommunication equipment testing;ATM adaptation layer;ATM equipment;Ericsson;VXI line interfaces;VXI-based measurement apparatus;common ATM analyzers;frame-level measurement;frame-level metrics;hardware;hierarchical structure;performance testing;software;user-perceived performance;3G mobile communication;Asynchronous transfer mode;B-ISDN;Communication switching;GSM;Particle measurements;Quality of service;Software measurement;Telecommunication switching;Testing},
}

@InProceedings{Bertolino2008,
  author    = {A. Bertolino and G. De Angelis and A. Sabetta},
  title     = {VCR: Virtual Capture and Replay for Performance Testing},
  booktitle = {2008 23rd IEEE/ACM International Conference on Automated Software Engineering},
  year      = {2008},
  pages     = {399-402},
  month     = {Sept},
  abstract  = {This paper proposes a novel approach to performance testing, called virtual capture and replay (VCR), that couples capture and replay techniques with the checkpointing capabilities provided by the latest virtualization technologies. VCR enables software performance testers to automatically take a snapshot of a running system when certain critical conditions are verified, and to later replay the scenario that led to those conditions. Several in-depth analyses can be separately carried out in the laboratory just by rewinding the captured scenario and replaying it using different probes and analysis tools.},
  doi       = {10.1109/ASE.2008.58},
  issn      = {1938-4300},
  keywords  = {program testing;virtual reality;VCR;checkpointing capabilities;software performance testing;virtual capture;virtual replay;virtualization technologies;Automatic testing;Checkpointing;Monitoring;Paper technology;Performance analysis;Software performance;Software testing;Space technology;System testing;Video recording},
}

@InProceedings{Xinfeng2011,
  author    = {Zhang Xinfeng and Shen Yong and SongGe},
  title     = {Stress testing on car remote monitoring system},
  booktitle = {2011 International Conference on Electric Information and Control Engineering},
  year      = {2011},
  pages     = {1715-1718},
  month     = {April},
  abstract  = {A virtual on-board concurrent user based remote monitoring system stress testing method is proposed. First, the scenario of maximum concurrent users is obtained through system analysis and the method is proposed. Second, the virtual on-board concurrent users are realized by computer data generation and coding according to package protocol. Finally, a case study of stress testing is done. It is turned out that the remote monitoring system's performance can be effectively evaluated by such test method, and the maximum number of concurrent users also can be predicted.},
  doi       = {10.1109/ICEICE.2011.5777983},
  keywords  = {automobile industry;automotive engineering;computerised monitoring;mechanical engineering computing;stress analysis;car remote monitoring system;computer data coding;computer data generation;package protocol;stress testing method;system analysis;virtual on-board concurrent user;Real time systems;Remote monitoring;Servers;Software;Stress;Testing;New energy Car;Remote monitoring system;Stress Test;virtual on-board terminal},
}

@InProceedings{Schurig1997,
  author    = {H. H. Schurig and M. A. Kruer and M. N. Levesque and E. M. Gaddy and W. J. Andiario},
  title     = {Performance testing of the 5 kW EOS AM-1 flexible solar array blanket},
  booktitle = {IECEC-97 Proceedings of the Thirty-Second Intersociety Energy Conversion Engineering Conference (Cat. No.97CH6203)},
  year      = {1997},
  volume    = {1},
  pages     = {550-555 vol.1},
  month     = {Jul},
  abstract  = {A GaAs/Ge flexible solar array blanket has been developed for use on the NASA/GSFC remote sensing EOS AM-1 spacecraft. This single wing array has been designed to provide 5 kW of power after five years in a low Earth polar orbit. The blanket configuration includes design features such as thin GaAs/Ge cell stacks mounted on a large flexible, hinged substrate, parallel connected solar cell strings providing high voltage output, a printed circuit harness, and a multi-layer jumper bus providing electrical continuity between the cell strings and the printed circuit harness. This work was contracted to TRW Space and Electronics Group in 1993 by Lockheed Martin Missiles & Space (LMMS). This paper presents the essential design of the EOS AM-1 solar array blanket, and summarizes the results of a qualification test program designed to demonstrate adequate design margins and to assess the performance of the mechanical and electrical components after exposure to a simulated mission space environment. It also reviews the complexities of performing electrical output testing on a 8.9 m×5.0 m deployed solar array blanket under AM0 conditions},
  doi       = {10.1109/IECEC.1997.659249},
  keywords  = {III-V semiconductors;aerospace testing;artificial satellites;elemental semiconductors;gallium arsenide;germanium;photovoltaic power systems;semiconductor device testing;solar cell arrays;space vehicle power plants;5 kW;5 m;8.9 m;AM0 conditions;EOS AM-1 spacecraft;GaAs-Ge;design features;flexible solar array blanket;low Earth polar orbit;mission space environment;performance testing;qualification test program;single wing array;Earth Observing System;Flexible printed circuits;Gallium arsenide;Missiles;NASA;Photovoltaic cells;Remote sensing;Space vehicles;Testing;Voltage},
}

@InProceedings{Yan2011,
  author    = {X. Yan and F. Wen and C. Fan and X. Wang},
  title     = {Performance Testing of Open Laboratory Management System Based on LoadRunner},
  booktitle = {2011 First International Conference on Instrumentation, Measurement, Computer, Communication and Control},
  year      = {2011},
  pages     = {164-167},
  month     = {Oct},
  abstract  = {Open Laboratory Management System provides an open virtual experiment environment for students, so that its system performance immediately impacts the quality of students learning. According to analyze the performance requirements of Open Laboratory Management System, the author discovers performance testing points, implements automated performance testing for performance testing points of the system based on Load Runner. In this paper, taking the students login for example, it elaborates testing process and provides the reference for system optimization.},
  doi       = {10.1109/IMCCC.2011.50},
  keywords  = {computer aided instruction;laboratories;program testing;virtual reality;LoadRunner;open laboratory management system;student learning;student login;testing process;virtual experiment environment;Educational institutions;Laboratories;Monitoring;Protocols;Time factors;LoadRunner;Open Laboratory Management System;performance testing},
}

@InProceedings{Rangaraj2013,
  author    = {S. Rangaraj and D. Kwon and M. Pei and J. Hicks and G. Leatherman and A. Lucero and T. Wilson and S. Streit and J. He},
  title     = {Accelerated stress testing methodology to risk assess silicon-package thermomechanical failure modes resulting from moisture exposure under use condition},
  booktitle = {2013 IEEE International Reliability Physics Symposium (IRPS)},
  year      = {2013},
  pages     = {5C.3.1-5C.3.5},
  month     = {April},
  abstract  = {IC components are exposed to moisture and thermal cycles during chip-package-board assembly and in their end use conditions. Moisture exposure influences the mechanical integrity of silicon backend dielectrics, assembly/packaging materials and packages. Reliability performance under accelerated stresses that simulate use conditions are often a critical factor in choice of materials, processing options and design rules. A complete assessment of the cumulative environmental exposure from chip-package assembly, shipment/storage, board system assembly, through end-customer use is required to guarantee product performance and reliability. This paper will detail these end user environments and use failure mode/mechanism specific acceleration models to develop accurate accelerated life testing plans and requirements. These requirements will then be compared to JEDEC standards based requirements and a need for re-calibration of these standards to more appropriate temperatures and stress durations will be highlighted.},
  doi       = {10.1109/IRPS.2013.6532032},
  issn      = {1541-7026},
  keywords  = {assembling;failure analysis;integrated circuit packaging;integrated circuit reliability;integrated circuit testing;life testing;risk management;stress analysis;IC components;JEDEC standards;accelerated life testing plans;accelerated stress testing methodology;assembly-packaging materials;board system assembly;chip-package-board assembly;cumulative environmental exposure;design rules;end user environments;failure mode-mechanism specific acceleration models;mechanical integrity;moisture cycle;moisture exposure;processing options;product performance;reliability performance;risk assessment;silicon backend dielectrics;silicon-package thermomechanical failure modes;standard re-calibration;stress durations;thermal cycle;through end-customer use;Acceleration;Materials;Mathematical model;Moisture;Reliability;Standards;Stress;HAST;JEDEC standard;acceleration model;moisture;thermal cyclin;use conditions},
}

@InProceedings{Capelli2017,
  author    = {L. Capelli and S. Sironi},
  title     = {Monitoring odour emisssions from an oil gas plant: Electronic nose performance testing in the field},
  booktitle = {2017 ISOCS/IEEE International Symposium on Olfaction and Electronic Nose (ISOEN)},
  year      = {2017},
  pages     = {1-3},
  month     = {May},
  abstract  = {This paper focuses on performance testing of electronic noses for environmental odour monitoring in terms of their capability of correctly classifying odours at low odour concentrations. The studied case concerns the realization of an electronic nose network for the continuous monitoring of odour emissions from a crude oil extraction and separation plant. The novelty of the work consists in the fact that performance testing, which is typically carried out in laboratory before installation in the field for environmental odour monitoring outside the plant boundaries, in this case was carried out after installation with the aim of testing the instruments performances in the effective working conditions. This involved the necessity to develop a specific and repeatable procedure to obtain samples at known quality and concentration in the field. Electronic nose performance was evaluated in terms of classification accuracy, which produced satisfactory results towards the considered olfactory classes.},
  doi       = {10.1109/ISOEN.2017.7968862},
  keywords  = {chemical variables measurement;crude oil;electronic noses;gas industry;crude oil extraction;electronic nose network;environmental odour emisssion monitoring;gas plant;oil plant;olfactory class;performance testing;separation plant;Earth Observing System;Electronic noses;Instruments;Liquids;Monitoring;Oils;Testing;continuous odour monitoring;electronic nose;odour concentration;performance testing;sample preparation},
}

@InProceedings{Bisgrove1997,
  author    = {J. Bisgrove and R. Dayao and B. Houser and T. Jones and J. C. Mayes and M. McGinnis and M. Schmidt and G. Skyles and B. K. Tan},
  title     = {Integrated test facility (ITF)-automation testing to support Intel's manufacturing output},
  booktitle = {1997 IEEE International Symposium on Semiconductor Manufacturing Conference Proceedings (Cat. No.97CH36023)},
  year      = {1997},
  pages     = {D17-D21},
  month     = {Oct},
  abstract  = {To meet the challenges of increasing automation and the potential for downtime, the current Virtual Factory Joint Automation Managers (JAM) worked with Components Automation Systems (CAS), the central engineering group responsible for the automation system, to create an Integrated Test Facility (ITF). ITF's mission is to conduct volume integrated testing of the automation suite prior to production release and to ensure that the automation suite does not hinge factory ramp. The ITF is a complete factory automation system running simulated production wafers. Established in January 1996, the ITF tests new automation product changes integrated into a complete factory manufacturing automation system and certifies that they can run in high volume. Integrated with CAS automation processes, the ITF is a key part of a process that delivers quality software},
  doi       = {10.1109/ISSM.1997.664526},
  keywords  = {factory automation;production engineering computing;production testing;test facilities;automation testing;factory manufacturing automation system;factory ramp;integrated test facility;manufacturing output;production release;quality software;simulated production wafers;volume integrated testing;Automatic testing;Content addressable storage;Engineering management;Fasteners;Manufacturing automation;Production facilities;Production systems;System testing;Test facilities;Virtual manufacturing},
}

@InProceedings{Lo2017,
  author    = {C. Y. Lo and Y. W. Hua and W. C. Yu and Y. M. Chuang},
  title     = {Functional verification and performance testing for OpenAirinterface (OAI) eNodeB},
  booktitle = {2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)},
  year      = {2017},
  pages     = {1456-1459},
  month     = {Dec},
  abstract  = {In this paper we develop and build an open air interface(OAI) eNodeB test platform for system developers to implement the network function verification and system performance evaluation for LTE network. In this test platform it also includes commercially available instruments such as EXFO EPC Simulator, Cobham TM UE Emulator and Cobham Data Generator to make this test platform performing the basic LTE network functions. The performances of this developed OAIeNodeB platform have been compared with the commercial LTE small cell eNodeB system, which is considered as the bench mark system based on Gemteck eNodeB, for proposed system parameters and various test cases .},
  doi       = {10.1109/APSIPA.2017.8282262},
  keywords  = {Long Term Evolution;performance evaluation;Cobham Data Generator;Cobham TM UE Emulator;EXFO EPC Simulator;Gemteck eNodeB;LTE network functions;developed OAIeNodeB platform;network function verification;open air interface eNodeB test platform;system performance evaluation;5G;B4G;EPC Emulator;OAI (Openairinterface);Open Source;UE Emulator;Verification Platform;eNodeB Emulator},
}

@Article{Johnson2007a,
  author   = {M. J. Johnson and C. W. Ho and E. M. Maximilien and L. Williams},
  title    = {Incorporating Performance Testing in Test-Driven Development},
  journal  = {IEEE Software},
  year     = {2007},
  volume   = {24},
  number   = {3},
  pages    = {67-73},
  month    = {May},
  issn     = {0740-7459},
  abstract = {Our performance-testing approach required manually inspecting the performance logs. During the project's development, JUnit-based performance testing tools, such as JUnitPerf, weren't available. Such tools provide better visibility of performance problems than manual inspection of performance logs. Although we believe manual inspection of performance trends is necessary, specifying the bottom-line performance in assert-based test cases can complement the use of performance log files, making the TFP testing results more visible to the developers. We're investigating the design of assert-based performance testing to improve the TFP process. Another direction of future work is automatic performance test generation. In this project, we relied on the performance architect's experience to identify the execution paths and measurement points for performance testing. We can derive this crucial information for performance testing from the performance requirements and system design. We plan to find guidelines for specifications of performance requirements and system design to make the automation possible},
  doi      = {10.1109/MS.2007.77},
  keywords = {formal specification;formal verification;program testing;software performance evaluation;systems analysis;JUnit-based performance testing tool;assert-based test case;automatic performance test generation;performance requirement specification;system design;test-driven development;Delay;Java;Printers;Process design;Software performance;Software testing;Switches;System software;System testing;Throughput;performance measures;test execution;testing strategies},
}

@InProceedings{Helmy1998,
  author    = {A. Helmy and D. Estrin},
  title     = {Simulation-based `STRESS' testing case study: a multicast routing protocol},
  booktitle = {Proceedings. Sixth International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems (Cat. No.98TB100247)},
  year      = {1998},
  pages     = {36-43},
  month     = {Jul},
  abstract  = {We propose a method for using simulation to analyze the robustness of multiparty (multicast-based) protocols in a systematic fashion. We call our method Systematic Testing of Robustness by Examination of Selected Scenarios (STRESS). STRESS aims to cut the time and effort needed to explore pathological cases of a protocol during its design. This paper has two goals: (1) to describe the method, and (2) to serve as a case study of robustness analysis of multicast routing protocols. We aim to offer design tools similar to those used in CAD and VLSI design, and demonstrate how effective systematic simulation can be in studying protocol robustness},
  doi       = {10.1109/MASCOT.1998.693672},
  keywords  = {digital simulation;local area networks;multicast communication;performance evaluation;telecommunication computing;telecommunication network routing;transport protocols;CAD;LAN;VLSI design;design tools;multicast routing protocols;multiparty protocols;pathological cases;robustness analysis;scenario generation;simulation-based STRESS testing;systematic robustness testing;systematic simulation;Analytical models;Computational modeling;Computer aided software engineering;Computer science;Multicast protocols;Network topology;Routing protocols;Stress;System testing;Unicast},
}

@InProceedings{Baiquan2014,
  author    = {X. Baiquan},
  title     = {Design of Platform for Performance Testing Based on JADE},
  booktitle = {2014 Sixth International Conference on Measuring Technology and Mechatronics Automation},
  year      = {2014},
  pages     = {251-254},
  month     = {Jan},
  abstract  = {For solving the problems presently such as coordination of the virtual users' act and the real-time acquisition of information, based on agent and JADE, this paper brings forward an architecture model of the platform for performance testing. JADE is multi-agent development environment which supports the management and communications control for agents. The principle of JADE is described and the basic method to design a platform for performance testing based on JADE is introduced, and offers a technology approach to realize the platform for performance testing.},
  doi       = {10.1109/ICMTMA.2014.63},
  issn      = {2157-1473},
  keywords  = {Java;multi-agent systems;program testing;software performance evaluation;JADE;Java Agent Development Framework;multiagent development environment;open source software;performance testing platform design;real-time information acquisition;virtual users act coordination;Automation;Mechatronics;Agent;JADE;Platform for performance testing},
}

@InProceedings{Krickovic2015,
  author    = {J. Kričković and Đ. Miljković and M. Đukić},
  title     = {Automation testing of Bootloader for target DSP platform},
  booktitle = {2015 23rd Telecommunications Forum Telfor (TELFOR)},
  year      = {2015},
  pages     = {1016-1019},
  month     = {Nov},
  abstract  = {In this paper is given the implementation of solutions for automated testing of Bootloader on the target DSP platform. Existing tools for manual testing do not meet the challenges of developing modern products, and its necessity for higher percentages of automation. The aim is to save time testing, reducing the occurrence of errors during testing due to human factors, and the ability that testing may execute a person who has no previous knowledge of a given field.},
  doi       = {10.1109/TELFOR.2015.7377638},
  keywords  = {digital signal processing chips;human factors;program testing;Bootloader;automation testing;human factor;software testing;target DSP platform;Automation;Digital signal processing;Electronic mail;Field programmable gate arrays;Hardware design languages;Linux;Testing;Bootloader;Python;TeraTerm;ispitivanje},
}

@InProceedings{Fang-ying2011,
  author    = {Y. Fang-ying},
  title     = {The credit risk macro stress testing of the Chinese banking system},
  booktitle = {2011 Chinese Control and Decision Conference (CCDC)},
  year      = {2011},
  pages     = {1198-1203},
  month     = {May},
  abstract  = {In order to test the overall credit risk of loans of China's banking system, a macroeconomic credit risk model is designed, including a multiple linear regression model describing default probability, and a set of regression models describing macroeconomic environment. Studies show that bank loan default rates and key macroeconomic factors are related. Then stress tests are implemented one by one according to different shocks. The results showed that most banks continue to profit even at 90% confidence level when estimated risk of loss, reflecting a moderate credit risk in the banking system. However, if confidence level rises to 99% when estimated risk of loss, the banking system will face significant losses. The results show that it is necessary to prevent the credit risk of real estate loans and government debt.},
  doi       = {10.1109/CCDC.2011.5968369},
  issn      = {1948-9439},
  keywords  = {banking;credit transactions;macroeconomics;probability;profitability;regression analysis;risk management;Chinese banking system;bank loan;confidence level;credit risk macrostress testing;default probability;default rate;government debt;linear regression model;macroeconomic credit risk model;macroeconomic environment;profit;real estate loan;Banking;Economic indicators;Electric shock;Equations;Macroeconomics;Mathematical model;Stress},
}

@InProceedings{Xing2007,
  author    = {C. Xing and G. Zhang and M. Chen},
  title     = {Research on universal network performance testing model},
  booktitle = {2007 International Symposium on Communications and Information Technologies},
  year      = {2007},
  pages     = {780-784},
  month     = {Oct},
  abstract  = {Network performance testing is one of the key components in optimizing network resource configuration and improving network performance. Existing performance testing tools usually focus on single performance parameters, and lack of the ability to satisfy integrated testing demands of network administrators. In this paper, a universal network performance testing model based on policy scheduling is proposed, which integrates many kinds of performance testing tools into a single system, and provides a uniform testing interface to network administrators. Universal Probe (UP) is the key component of such a model, thus a detailed study is given on UP, which includes UP architecture, policy-based UP cooperation, mobility, and UP deployment under resource constraints. At last, a practical Network Monitor and Measurement System that designed based on the discussed concepts is presented.},
  doi       = {10.1109/ISCIT.2007.4392122},
  keywords  = {computer network management;computer network reliability;monitoring;optimisation;scheduling;network monitor-measurement system;network resource configuration optimization;policy scheduling;uniform testing interface;universal network performance testing model;universal probe;Information technology;Testing},
}

@Article{Suryanarayana1997,
  author   = {T. Suryanarayana and J. L. Bhattacharya and K. S. N. Raju and K. A. Durga Prasad},
  title    = {Development and performance testing of a 200 kVA damperless superconducting generator},
  journal  = {IEEE Transactions on Energy Conversion},
  year     = {1997},
  volume   = {12},
  number   = {4},
  pages    = {330-336},
  month    = {Dec},
  issn     = {0885-8969},
  abstract = {A 200 kVA, 3000 RPM superconducting generator has been developed and tested. The rotor has been wound with superconducting wire of Nb-Ti alloy. A closed-circuit liquid helium system has been designed and installed for cooling the superconducting windings. The stator carries the air-gap type armature windings and a laminated-iron flux-shield. A new concept in the design of superconducting generators with high short-circuit ratio (more than 5) has been introduced. This eliminates the requirement of an electromagnetic damper and quick response excitation system. The generator has been comprehensively tested in the superconducting state. Open-circuit and sustained short-circuit tests, three-phase sudden short-circuit tests, synchronization with the grid and parallel operation with power systems have been conducted. The synchronous machine was operated up to its rated kVA in the four quadrants-as a generator and as a condenser with leading and lagging power factors. A few special tests on superconducting generators, which were not reported earlier, such as direct-online starting of a 20 hp squirrel-cage induction motor and negative phase sequence tests have also been performed successfully. Test results and conclusions are given},
  doi      = {10.1109/60.638869},
  keywords = {electric generators;machine testing;rotors;stators;superconducting machines;superconducting magnets;20 hp;200 kVA;NbTi;air-gap type armature windings;closed-circuit liquid helium system;damperless superconducting generator;laminated-iron flux-shield;open-circuit tests;performance testing;short-circuit ratio;short-circuit tests;stator;superconducting windings cooling;superconducting wire rotor;Air gaps;Cooling;Helium;Induction generators;Rotors;Stators;Superconducting filaments and wires;Superconducting transmission lines;System testing;Wounds},
}

@InProceedings{Gao2013,
  author    = {Q. Gao and W. Wang and G. Wu and X. Li and J. Wei and H. Zhong},
  title     = {Migrating Load Testing to the Cloud: A Case Study},
  booktitle = {2013 IEEE Seventh International Symposium on Service-Oriented System Engineering},
  year      = {2013},
  pages     = {429-434},
  month     = {March},
  abstract  = {Cloud computing has emerged as a new paradigm for the delivery of computing resources. It brings great opportunities to software testing, especially to load testing. In this paper, we focus on migrating conventional load testing tools to the cloud, for which the two significant issues are about multi-tenancy and load simulating resource management. We propose a four layer model for cloud-based load testing, along with the approach of test request admission control and scheduling to solve these issues. We carried out a concrete case study on our proposed approach and made the efficiency of cloud-based load testing shown successfully by two contrast experiments.},
  doi       = {10.1109/SOSE.2013.59},
  keywords  = {cloud computing;program testing;resource allocation;scheduling;cloud computing;cloud-based load testing;computing resource delivery;four layer model;load simulating resource management;load testing migration;multitenancy;scheduling;software testing;test request admission control;Admission control;Databases;Load modeling;Monitoring;Resource management;Software;Testing;cloud computing;load testing;migrating},
}

@InProceedings{Zhou2016,
  author    = {C. Zhou and D. Du and Z. Cao and Y. Wang and X. Yang},
  title     = {Assets overlapping networks and stress testing on stability of financial systems},
  booktitle = {2016 35th Chinese Control Conference (CCC)},
  year      = {2016},
  pages     = {10385-10389},
  month     = {July},
  abstract  = {Financial networks, creating potential propagation channels for shocks in crises, are widely viewed as a key factor to systemic stability. In this paper, we develop a dynamic model of deleveraging in an overlapping network of assets. We study the deleveraging spirals driven by the interaction between fire sales and confidence effects, and show how distress is amplified and propagated throughout the network. Using the regulatory data from the Peoples Bank of China (PBC), we construct the assets overlapping network and then apply the model to the system. The result suggests that: (1) the mutually reinforcing effects of fire sales and confidence can contribute to contagion significantly; (2) The vulnerability of the system are largely dependant on the distribution of large illiquid assets. Our model provides a ready-to-use yet powerful stress testing tool for macro-prudential regulation.},
  doi       = {10.1109/ChiCC.2016.7555000},
  keywords  = {asset management;finance;PBC;Peoples Bank of China;assets overlapping networks;confidence effects;deleveraging dynamic model;deleveraging spirals;financial systems stability;fire sales;illiquid assets;macroprudential regulation;stress testing;Electric shock;Heuristic algorithms;Investment;Portfolios;Stability analysis;Stress;Testing;Confidence Effects;Deleveraging;Financial Networks;Stress Testing;Systemic Risk},
}

@InProceedings{Iversen2009,
  author    = {P. O. Iversen and K. Rutkowski and S. Issartel and L. Foged and A. Scannavini},
  title     = {Radiated performance testing of diversity and MIMO enabled terminals},
  booktitle = {2009 3rd European Conference on Antennas and Propagation},
  year      = {2009},
  pages     = {1069-1071},
  month     = {March},
  abstract  = {This paper discuss general methods available for test and design engineers for testing radiated performances of multi-antenna enabled terminals in a controlled environment such as anechoic chambers. Methods for testing SIMO (Single-input Multi-Output), and MIMO (Multi-Input Multi-Output) performances in both passive and active way are highlighted. Information such as user defined propagation channel characteristic can be taking into account in passive measurements and is currently being investigated for the active testing.},
  issn      = {2164-3342},
  keywords  = {MIMO communication;antenna arrays;antenna radiation patterns;diversity reception;wireless channels;MIMO enabled terminals;diversity testing;multiantenna enabled terminals;passive measurements;propagation channel characteristics;radiated performance testing;Anechoic chambers;Antenna arrays;Antenna radiation patterns;Antennas and propagation;Current measurement;Design engineering;MIMO;Performance evaluation;Polarization;System testing},
}

@InProceedings{Liu2006,
  author    = {L. Liu and J. Lin and Z. Li and J. Li},
  title     = {State Machine Based CDMA Stress Testing Service System},
  booktitle = {2006 IEEE Asia-Pacific Conference on Services Computing (APSCC'06)},
  year      = {2006},
  pages     = {625-628},
  month     = {Dec},
  abstract  = {This paper introduces a system model of CDMA stress testing service platform based on state machine technology. This system provides an efficient service oriented solution on protocol and stress testing of CDMA system, with high performance and automatic capability. The concurrent multitask mechanism and the state machine framework enable the high performance and automatic capability of this system. And the scalable distributed architecture offers the maximum flexibility of deployment},
  doi       = {10.1109/APSCC.2006.93},
  keywords  = {code division multiple access;computer architecture;finite state machines;protocols;stress analysis;CDMA stress testing service system;concurrent multitask mechanism;protocol;scalable distributed architecture;state machine;Communication system control;Computer architecture;Electronic equipment testing;Hardware;Mobile communication;Multiaccess communication;Protocols;Software testing;Stress;System testing;Service;State Machine;Stress Testing},
}

@InProceedings{Chan2004,
  author    = {H. A. Chan},
  title     = {Accelerated stress testing for both hardware and software},
  booktitle = {Annual Symposium Reliability and Maintainability, 2004 - RAMS},
  year      = {2004},
  pages     = {346-351},
  abstract  = {Accelerated stress testing (AST) has been used in electronic, electromechanical, and mechanical systems to achieve robustness with high reliability primarily for hardware. For software products, the reliability program is often conducted separate from any hardware accelerated stress testing. Yet, many systems are consist of concurrent software and hardware issues. In addition, the stress testing processes were primarily adopted by those responsible to develop and manufacture hardware. For example, the stresses usually include temperature extremes, thermal cycles, vibrations, etc. These stresses are effective in accelerating latent hardware defects from degradable, marginal, or intermittent failures to hard failures so that root cause analyses and corrective actions may be made. Although experiments had indicated that software faults and hardware defects are related, the available formulation of the fundamental principles was still based on hardware systems. AST for software and for operating systems have been discussed in [M. Werner, et al., "Improving Customer Satisfaction via Accelerated Stress Testing of General Purpose Computer Operating Systems"] and [M. Werner, et al., 2002], but a fundamental understanding of AST for software is lacking. In order to generalize the fundamentals of accelerated stress testing to address both software and hardware, we need to define accelerated stress testing for software and to address whether they are needed, i.e., whether there are effective methods to achieve high software reliability. The basic reliability concepts categorize systems into different categories according to the presence of defects and faults and whether these weaknesses are explicit enough. The concepts for both hardware and software reliability separate the notion of defects and faults from failures. It further conceptually separates the notion of stressing and the notion of detection. The fundamental concept is that all failures except the explicit ones must be manifested under certain stress conditions. There is then a threshold stress level beyond which a system fails. The cumulative effect of stresses is included by defining time as one type of stress. Both hardware and software systems have marginal weakness, and degradable weakness. The process o- f recovery and repair are also examined for both hardware and software events. The basic reliability principles in accelerated stress testing for both software and hardware systems are combined and explained in this paper. While [M. Werner, et al., "Improving Customer Satisfaction via Accelerated Stress Testing of General Purpose Computer Operating Systems"] and [M. Werner, et al., 2002] also address the needs and advantages of AST for software, an effective software AST program requires efficient tools yet to be developed. The benefits should justify the needed further research and development in this area.},
  doi       = {10.1109/RAMS.2004.1285473},
  keywords  = {conformance testing;life testing;software reliability;stress analysis;accelerated stress testing;corrective actions;hardware defects;hardware reliability;reliability program;root cause analysis;software faults;software reliability;Customer satisfaction;Hardware;Life estimation;Operating systems;Software reliability;Software systems;Software testing;Software tools;System testing;Thermal stresses},
}

@InProceedings{Singer1989,
  author    = {P. A. Singer},
  title     = {Trends in VLF/LF modem performance testing},
  booktitle = {Military Communications Conference, 1989. MILCOM '89. Conference Record. Bridging the Gap. Interoperability, Survivability, Security., 1989 IEEE},
  year      = {1989},
  pages     = {581-584 vol.2},
  month     = {Oct},
  abstract  = {The author reviews the historical development of digital VLF/LF modem testing. He discusses the introduction of test equipment in the following four major functional areas: (a) transmit simulation, (b) channel simulation, (c) noise and interference generation, and (d) reception characterization. He demonstrates two major trends: (1) the use of general-purpose hardware and off-line software replacing special-purpose hardware; (2) Gaussian noise, atmospheric laboratory test environments being replaced by tailored simulated electromagnetic interference and atmospheric noise},
  doi       = {10.1109/MILCOM.1989.103992},
  keywords  = {automatic test equipment;digital simulation;electronic equipment testing;modems;performance evaluation;Gaussian noise;LF;VLF;atmospheric laboratory test environments;atmospheric noise;channel simulation;digital modem;electromagnetic interference;general-purpose hardware;interference generation;modem performance testing;noise generation;off-line software;reception characterization;test equipment;transmit simulation;Atmospheric modeling;Electromagnetic interference;Gaussian noise;Hardware;Low-frequency noise;Modems;Noise generators;Test equipment;Testing;Working environment noise},
}

@InProceedings{Chapuis2017,
  author    = {B. Chapuis and B. Garbinato},
  title     = {Scaling and Load Testing Location-Based Publish and Subscribe},
  booktitle = {2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)},
  year      = {2017},
  pages     = {2543-2546},
  month     = {June},
  abstract  = {The rise of the Internet of things (IoT) poses massive scalability issues for location-based services. More particularly, location-aware publish and subscribe services are struggling to scale out the computation of matches between publications and subscriptions that continuously update their location. In this demonstration paper, we propose a novel distributed and horizontally scalable architecture for location-aware publish and subscribe. Our middleware architecture relies on a multi-step routing mechanism based on consistent hashing and range partitioning. To demonstrate its scalability, we present a traffic data generator, which, in contrast to existing generators, can be used to perform real-time load tests. Finally, we show that our architecture can be deployed on a small 10-node cluster and can process up to 80,000 location updates per second producing 25,000 matches per seconds.},
  doi       = {10.1109/ICDCS.2017.234},
  issn      = {1063-6927},
  keywords  = {Internet of Things;message passing;middleware;Internet of Things;location-aware publish and subscribe services;location-based services;middleware architecture;multi-step routing mechanism;traffic data generator;Computer architecture;Generators;Middleware;Real-time systems;Roads;Routing;Scalability},
}

@InProceedings{Wu2012,
  author    = {J. Wu},
  title     = {Stress testing software to determine fault tolerance for hardware failure and anomalies},
  booktitle = {2012 IEEE AUTOTESTCON Proceedings},
  year      = {2012},
  pages     = {294-298},
  month     = {Sept},
  abstract  = {Today's military systems rely for their performance on combinations of hardware and software. While testing of hardware performance during design, development and operation is well understood, the testing of software is less mature. In particular, the effect of hardware failures in the field on software performance, and therefore systems performance, is all-too-often overlooked or is tested in a far less rigorous manner that that applied to Hardware failures alone. Numerous examples exist of major system failures driven by software anomalies but triggered by Hardware failures, with consequences that range from degraded mission performance to weapons system destruction and operator fatalities. Measuring software development quality and fault tolerance is a challenging task. Many software test methods focus on source-code only approach (unit tests, modular test) and neglect the impacts caused by hardware anomalies or failures. Such missing test coverage can and will result in potential degraded software performance quality, thereby adding to project cost and delaying schedule. It can also result in far more disastrous consequences for the warfighters. This paper will discuss the general nature of the hardware-failure-software anomaly - system failure flow-down. It will then describe techniques that exist for system software testing and will highlight extensions of these techniques to focus on an effective and comprehensive software testing that includes performance prediction and hardware failure fault tolerance. The end result is a suite of test methods that, when properly applied, offer a systematic and comprehensive analysis of prime software behaviors under a range of hardware field failure conditions.},
  doi       = {10.1109/AUTEST.2012.6334582},
  issn      = {1088-7725},
  keywords  = {fault tolerant computing;military computing;missiles;program testing;software metrics;software performance evaluation;software quality;delaying schedule;fault tolerance measurement;hardware anomalies;hardware failure fault tolerance;hardware field failure conditions;hardware performance testing;missing test coverage;mission performance degradation;operator fatalities;performance prediction;project cost;software anomalies;software behavior comprehensive analysis;software development quality measurement;software performance;software testing;source code;stress testing software;system failure flow-down;warfighters;weapon system destruction;Embedded systems;Fault detection;Hardware;Monitoring;Real-time systems;Voltage control},
}

@InProceedings{Zhizhong2011,
  author    = {L. Zhizhong and W. Sen and X. Jun and N. Bo and J. Hongliang and X. Hua},
  title     = {Performance testing and comprehensive evaluation on large grounding connection},
  booktitle = {2011 7th Asia-Pacific International Conference on Lightning},
  year      = {2011},
  pages     = {983-989},
  month     = {Nov},
  abstract  = {To comprehensively evaluate the safety of large grounding connection, testing and action principle of the main factors that impact the safe operation of grounding connection, were analyzed and studied, and the following conclusions were drew by theoretical analysis and simulation research. While evaluating step voltage and touch voltage, it's inadvisable to consider seasonal factors during the selection of soil resistivity; the testing direction of step voltage and touch voltage should be selected based on simulation computation for getting reliable data; eligibility criterion on electric integrity of grounding connection should not be 200mΩ but appropriately lowered; corrosion evaluation of grounding connection can be get rudely by analogized ways, which need the adding appropriate monitoring point in the corner of the grounding grid. Finally, the grading criterion and reference methods of weight value for the testing results of safe operation factors of grounding connection is proposed for establishing a quantified evaluation system of grading grounding connection, detailing the state evaluation system of large grounding connection.},
  doi       = {10.1109/APL.2011.6111055},
  keywords  = {earthing;power grids;grounding connection;grounding grid;soil resistivity;step voltage;touch voltage;Corrosion;Electric potential;Grounding;Immune system;Resistance;Testing;Thermal stability;Grounding connection;comprehensive evaluation;grading criterion;grounding grid;integrity of grounding connection;quantified evaluation},
}

@Article{Kyle1965,
  author   = {H. C. Kyle},
  title    = {Compatibility and Performance Testing of Communications Systems},
  journal  = {IEEE Transactions on Aerospace},
  year     = {1965},
  volume   = {AS-3},
  number   = {2},
  pages    = {139-143},
  month    = {June},
  issn     = {0536-1516},
  abstract = {During the normal progress of design, fabrication, and integration of communications subsystems for spacecraft and for ground installations, every effort is made to assure that the equipment meets certain specifications relating to performance, environment, reliability, and interface capability. These specifications are based on the best available definition of requirements and interface characteristics of complementing subsystems. Frequently, in the field of manned spaceflight, the spacecraft subsystems, the launch vehicle subsystems, and the ground systems must be designed and constructed concurrently. This means that the operating and interface characteristics of one subsystem are not available for use by the engineers in the design of the other subsystems. Close technical liaison among the various engineering groups is essential in the accomplishment of overall systems' integrity. Component and subsystem testing has been developed to a high degree, but the results of these are necessarily limited. They cannot validate the overall systems' performance and compatibility. It is considered mandatory that the interfacing subsystems be mated to form a complete system in a controlled test environment as early as practicable in any program, especially in one involving communications systems as new and as complex as those for Apollo. This must be accomplished at such a phase in the program that corrective engineering details can be fed back to the cognizant design, fabrication, or integration groups involved in time for necessary modifications prior to the beginning of the flight phase.},
  doi      = {10.1109/TA.1965.4319794},
  keywords = {Aerospace engineering;Automotive engineering;Communication system control;Control systems;Design engineering;Fabrication;Land vehicles;Road vehicles;Space vehicles;System testing},
}

@InProceedings{Wunderle2016,
  author    = {B. Wunderle and T. Onken and J. Heilmann and D. Silbernagl and J. Arnold and T. Bieniek and R. Pufall},
  title     = {Reliability of sputtered thin aluminium films under accelerated stress testing by vibration loading and modeling},
  booktitle = {2016 6th Electronic System-Integration Technology Conference (ESTC)},
  year      = {2016},
  pages     = {1-14},
  month     = {Sept},
  abstract  = {Aluminium is still one of the most important contact metallisations for power electronic chips like MOSFETs or IGBTs. With a large difference in thermal expansion coefficients (CTEs) between aluminium and silicon and the temperatures generated in hot-spots during high power transients, these layers are prone to failure due to thermo-mechanical fatigue. Usually lifetime assessment is done by subjecting dedicated test specimens to standardised stress tests as e.g. active or passive thermal cycling. This paper proposes a novel method for accelerated stress testing and lifetime modelling of thin aluminium films in the high-cycle fatigue regime by isothermal mechanical loading. The proposed novel test method is suggested to complement or replace resource-demanding thermal cycling tests and allow simple in-situ monitoring of failure.},
  doi       = {10.1109/ESTC.2016.7764458},
  keywords  = {semiconductor device reliability;thermal expansion;vibrations;CTE;IGBT;MOSFET;accelerated stress testing;active thermal cycling;high power transients;high-cycle fatigue regime;hot-spots;isothermal mechanical loading;lifetime modelling;passive thermal cycling;power electronic chips;sputtered thin aluminium films reliability;thermal expansion coefficients;thermomechanical fatigue;thin aluminium films;vibration loading;vibration modeling;Aluminum;Fatigue;Life estimation;Silicon;Stress;Testing},
}

@InProceedings{Mingqiu2011,
  author    = {Ren Mingqiu and Cai Jinyan and Zhu Yuanqing and Han Zhuangzhi},
  title     = {Design of radar ECCM performance testing system and its semi-physical simulation experiment},
  booktitle = {Proceedings of 2011 IEEE CIE International Conference on Radar},
  year      = {2011},
  volume    = {2},
  pages     = {1058-1062},
  month     = {Oct},
  abstract  = {This paper describes the theory, design, implementation, simulation and testing of a radar ECCM performance testing system capable of generating target echo, clutter and jamming signal for radar ECM/ECCM experiment. With the help of the proposed testing system, the jamming styles and parameters can be smartly intercalated with a variety of simulation scenarios. The rubs are resolved such as radar states data acquisition, echo real time simulation and display & control terminals setup of signal environment. Then a radar ECM semi-physical simulation experiment is applied to measure six typical ECCM performance indexes in the signal environment generated by the testing system. Experiment and data processing results show the testing platform is valid and practical. The testing system can be used to solve problems such as radar ECCM performance evaluation, radar advanced design and ECCM strategies when the equipment is relatively small in tracking and guidance phase.},
  doi       = {10.1109/CIE-Radar.2011.6159734},
  issn      = {1097-5764},
  keywords  = {electronic countermeasures;jamming;radar clutter;radar tracking;target tracking;testing;data processing;echo real time simulation;guidance phase;jamming signal;radar ECCM performance testing system;radar clutter;radar states data acquisition;semiphysical simulation experiment;target echo;tracking phase;Electronic countermeasures;Jamming;Radar antennas;Radar tracking;Target tracking;Testing;Radar ECCM;active jamming;evaluation index;semi-physical simulation experiment;testing system},
}

@InProceedings{Samoylenko2017,
  author    = {A. P. Samoylenko and A. I. Panychev and S. A. Panychev},
  title     = {Evaluation of telecommunication system reliability via stress testing},
  booktitle = {2017 International Siberian Conference on Control and Communications (SIBCON)},
  year      = {2017},
  pages     = {1-5},
  month     = {June},
  abstract  = {The problem of evaluating reliability of telecommunication systems in general, and their components is considered. The method of forecasting the reliability of a telecommunications system designed according to the results of stress testing is proposed. The essence of the proposed method is to use the emissions of a random process as a diagnostic parameter that displays the trajectory of a monitored quantity values. As a quantitative measure of reliability used system average uptime. The simulation for normal distribution law of a random parameters with different correlation functions is carried out. The estimation of the average uptime for various sizes of tolerance range of parameters is calculated. It is shown that the theory of random processes emissions is an adequate mathematical apparatus for the formalization of the results of stress testing.},
  doi       = {10.1109/SIBCON.2017.7998430},
  keywords  = {mathematical analysis;telecommunication network reliability;diagnostic parameter;different correlation functions;mathematical apparatus;monitored quantity values;normal distribution law;random parameters;random process emissions;stress testing;system average uptime;telecommunication system reliability;Monitoring;Random processes;Reliability;Stress;Telecommunications;Testing;Trajectory;average uptime;emissions of a random process;forced testing;reliability;stress test;survivability;telecommunication system;the trajectory of a random parameter;tolerance domain},
}

@InProceedings{Tangadpalliwar2011,
  author    = {S. Tangadpalliwar and K. Sandrasegaran and M. Raymond and A. Moitra and F. Madani},
  title     = {Benchmarking Embedded Devices for Broadband Performance Testing},
  booktitle = {2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing},
  year      = {2011},
  pages     = {321-327},
  month     = {Dec},
  abstract  = {Real time monitoring of broadband performance parameters is critical for estimating the user experience of new broadband services like VoIP, IPTV, Gaming and Video. This information is of interest to service providers themselves for efficient network design and maintenance and government regulatory bodies for analyzing ISPs, regions and national benchmarking. A web-based system TRUEE (Tool for Real-time User Experience Estimation) is a distributed system that incorporates independent modules such as standalone measurement devices installed at customer premises, data centers, test servers and web-clients for remote monitoring and management of the system. The focus of this paper is to discuss the process of benchmarking three commercial embedded devices with PC as reference device representing an end user system for accessing broadband services. This work is part of the ongoing development process of TRUEE. This benchmarking process is of significant importance for making an informed decision on the suitability of an embedded device capable of providing desired accuracy and consistency in estimation of the broadband performance parameters. Based on literature review, online forum reviews and cost analysis three devices based on ARM viz. SheevaPlug, Texas Instrument's BeagleBoard-xM and Gumstix Overo are selected for benchmarking. Results show that Marvell's SheevaPlug outperforms the other two devices in accurately measuring the broadband parameters on its network interface.},
  doi       = {10.1109/DASC.2011.71},
  keywords  = {Internet;benchmark testing;broadband networks;embedded systems;performance evaluation;ARM based device;Gumstix Overo;ISP analysis;Marvell SheevaPlug;TRUEE;Texas Instrument's BeagleBoard-xM;Web-based system;Web-clients;benchmarking embedded device;broadband performance parameter;broadband performance testing;broadband service;customer premises;data center;distributed system;end user system;government regulatory body;national benchmarking;network interface;real time monitoring;region benchmarking;remote monitoring;service provider;test servers;tool for real-time user experience estimation;Bandwidth;Benchmark testing;Broadband communication;Jitter;Linux;Performance evaluation;Throughput;Benchmarking;Broadband;Embedded device;Network Monitoring;Performance Testing},
}

@InProceedings{Liang2009,
  author    = {Z. Liang and L. Jianhua and W. Ruofei and G. Xiaobin},
  title     = {Design of Performance Testing System for Train Air Conditioning},
  booktitle = {2009 International Conference on Energy and Environment Technology},
  year      = {2009},
  volume    = {1},
  pages     = {85-89},
  month     = {Oct},
  abstract  = {The design of performance testing system for train air conditioning was done according to the NATIONAL STANDARD TB/T 1804-2003. The cooling capacity was measured by means of air enthalpy difference method. The hardware part of the test system consists of data collection unit and test instrument, while the software is programmed with Visual Basic 6.0, accompanied with the Microsoft Access database. The PLC unit and the touch screen are employed for local control of the system to achieve precise adjustment to the temperature and humidity of environmental chamber, the speed and flow of air. In view of the system characteristics of complex nonlinearity and being difficult to control exactly, test system adopts a fuzzy PID control based on plc to control experimental parameters such as temperature and humidity.},
  doi       = {10.1109/ICEET.2009.27},
  keywords  = {Visual BASIC;air conditioning;computerised instrumentation;fuzzy control;programmable controllers;test equipment;three-term control;touch sensitive screens;visual programming;Microsoft Access database;National Standard TB/T 1804-2003;PLC unit;Visual Basic 6.0;air enthalpy difference method;cooling capacity;data collection unit;environmental chamber humidity;fuzzy PID control;performance testing system;programmable logic controller;test instrument;touch screen;train air conditioning;Air conditioning;Control systems;Cooling;Hardware;Humidity control;Nonlinear control systems;Programmable control;Software testing;System testing;Temperature control;data acquisition;fuzzy control;performance test system;train air conditioning},
}

@Article{Baxter1979,
  author   = {P. D. Baxter and V. Lang and A. Anouchi},
  title    = {A Microprocessor-Based Positive Displacement Measurement System for Diesel Pump and Injector Performance Testing},
  journal  = {IEEE Transactions on Instrumentation and Measurement},
  year     = {1979},
  volume   = {28},
  number   = {4},
  pages    = {317-320},
  month    = {Dec},
  issn     = {0018-9456},
  abstract = {New stringent emissions and economy requirements for the burgeoning diesel engine market have resulted in development of a new entirely digital microprocessor-based fuel delivery measurement system. The system uses a unique inherently digital transducer and a microprocessor for measurement and control.},
  doi      = {10.1109/TIM.1979.4314840},
  keywords = {Diesel engines;Displacement measurement;Engine cylinders;Fluid flow measurement;Fuels;Maintenance;Pressure measurement;System testing;Transducers;Velocity measurement},
}

@InProceedings{Wienke2018,
  author    = {J. Wienke and D. Wigand and N. Koster and S. Wrede},
  title     = {Model-Based Performance Testing for Robotics Software Components},
  booktitle = {2018 Second IEEE International Conference on Robotic Computing (IRC)},
  year      = {2018},
  pages     = {25-32},
  month     = {Jan},
  abstract  = {In complex technical systems like robotics platforms, a manifold of issues can impair their dependability. While common testing and simulation methods largely focus on functional aspects, the utilization of resources like CPU, network bandwidth, or memory is only rarely tested systematically. With this contribution we propose a novel Domain-Specific Language (DSL) for modeling performance tests for individual robotics components with the aim to establish a systematic testing process for detecting regressions regarding the resource utilization. This DSL builds upon a testing framework from previous research and aims to significantly reduce the effort and complexity for creating performance tests. The DSL is built using the MPS language workbench and provides a feature-rich editor with modern editing aids. An evaluation indicates that developing performance tests requires only one third of the work in comparison to the original Java-based API.},
  doi       = {10.1109/IRC.2018.00013},
  keywords  = {C language;control engineering computing;embedded systems;formal specification;object-oriented programming;product development;program diagnostics;public domain software;robots;specification languages;DSL;Domain-Specific Language;MPS language workbench;complex technical systems;editing aids;feature-rich editor;model-based performance tests;performance testing;resource utilization;robotics platforms;robotics software components;simulation methods;systematic testing process;DSL;Resource management;Robots;Software;Testing;Tools;Unified modeling language;CBSE;DSL;MPS;performance;performance testing;resource awareness;testing},
}

@InProceedings{Le1994,
  author    = {D. Le and I. Karolik and R. Smith and A. J. Mcgovern and C. Curette and J. Ulbin and M. Zarubaiko and C. Henry and L. Stevens},
  title     = {Environmental Stress Testing with Boundary-Scan},
  booktitle = {Proceedings., International Test Conference},
  year      = {1994},
  pages     = {307-313},
  month     = {Oct},
  abstract  = {Environmental Stress Testing (EST) enhances product quality and reliability by detecting latent or marginal defects in a product. For EST to be effective, testing of a product must achieve a high fault coverage so that as many EST-induced defects can be detected. By utilizing Boundary-Scan (IEEE Std 1149.1-1990), EST can achieve a high fault coverage and at the same time, minimize test cost. The paper describes a complete infrastructure, both software and hardware, for using Boundary-Scan (B-S) in EST. In addition, the paper shows a simplified control mechanism to select individual circuit packs for Boundary-Scan testing. This control mechanism minimizes the number of wires required to drive the control interface and thus, the number of wires in the cable that connects a tester to the backplane of a system under test and across which Boundary-Scan tests are executed. Finally, the paper presents and discusses some study results for evaluating the effectiveness of monitored EST},
  doi       = {10.1109/TEST.1994.527964},
  issn      = {1089-3539},
  keywords  = {IEEE standards;automatic testing;boundary scan testing;environmental stress screening;production testing;IEEE Std 1149.1;boundary scan testing;control;control interface;effectiveness;environmental stress testing;fault coverage;latent defects;marginal defects;product quality;reliability;test cost;Circuit faults;Circuit testing;Control systems;Costs;Electrical fault detection;Fault detection;Hardware;Stress;System testing;Wires},
}

@InProceedings{Jodice1994,
  author    = {J. A. Jodice and S. Harpham},
  title     = {`End-to-end transient simulation for protection system performance testing'},
  booktitle = {Developments in the Use of Global Positioning Systems},
  year      = {1994},
  pages     = {6/1-6/5},
  month     = {Feb},
  abstract  = {Formatted according to the new IEEE Standard C37.111, 1992 (COMTRADE), digital information describing power system disturbances controls a test system which produces transient simulation signals for analyzing protective relay performance. Global positioning system (GPS) satellite timing signals are used to synchronize two remotely located test systems for performing transient end-to-end simulation tests. DFR records of actual events and Electromagnetic Transient Program (EMTP) simulations of multiple fault events, played back through satellite-synchronized end-to-end test systems have proven comprehensive analytical tools-virtually eliminating the need for costly and dangerous staged fault tests generally performed at a limited number of locations},
  keywords  = {digital simulation;electrical faults;power system analysis computing;power system protection;radionavigation;relay protection;satellite relay systems;software packages;synchronisation;Electromagnetic Transient Program;GPS;Global Positioning System;IEEE Standard C37.111;digital fault recorders;digital simulation;end-to-end simulation;multiple fault events;performance testing;power system disturbances;protective relay performance;satellite timing signals;synchronisation;transient simulation signals},
}

@InProceedings{Xu2011,
  author    = {W. Xu and C. Lv},
  title     = {Research of virtual reality in industrial design manufacture and performance testing},
  booktitle = {2011 2nd International Conference on Intelligent Control and Information Processing},
  year      = {2011},
  volume    = {1},
  pages     = {403-405},
  month     = {July},
  abstract  = {Virtual reality (VR) is a new method of visual operating and interacting of complex data can be realized by computers, in which one would have an immersed sense to observe and operate objects in three dimensions timely and unboundedly. VR is a new developing technique and a complex simulation tool for industry, it builds a simulated environment in which researchers can do many things such as driving, operating, designing and performance test in a unaffected way. Performance test plays an important role in vehicle design. Most of interactive processing in virtual vehicle manufacturing is perfect, but many deep interactive functions are under emphasis such as performance test after manufacturing, variation and recording of performance parameters. Research of VRML combining with JavaScript is presented in this paper, and vehicle designing and manufacturing, testing system are built based on it, in which we can real-time and dynamic control the car through keyboard and mouse, and get the real-time performance parameters.},
  doi       = {10.1109/ICICIP.2011.6008274},
  keywords  = {Java;automatic test software;automobile manufacture;performance evaluation;production engineering computing;virtual manufacturing;virtual reality languages;JavaScript;VRML;industrial design manufacture;interactive processing;performance testing;simulation tool;vehicle design;virtual reality;virtual vehicle manufacturing;visual interaction;Computational modeling;Shape},
}

@InProceedings{Guo2010a,
  author    = {Xiao-yang Guo and Ying-hui Chen and Xue-song Qiu and Fan Tang},
  title     = {Design and implementation of performance testing model for Web Services},
  booktitle = {2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics (CAR 2010)},
  year      = {2010},
  volume    = {1},
  pages     = {353-356},
  month     = {March},
  abstract  = {The performance testing model for Web Services is proposed. Aiming to enhance testing efficiency and automation, the model provides a multi-machine joint testing model and strategy model. The former is used to share the heavy load to multiple units, which could also be called load balance model, and the latter is used to simulate a realistic Web Services running environment. The model has been applied to an original web services testing software, and proved to be a feasible way for performance testing for web services.},
  doi       = {10.1109/CAR.2010.5456825},
  issn      = {1948-3414},
  keywords  = {Web services;program testing;resource allocation;software performance evaluation;heavy load share;load balance model;multi-machine joint testing model;realistic Web services running environment;software performance testing model;Asia;Automatic control;Automatic testing;Informatics;Laboratories;Load modeling;Robotics and automation;Service oriented architecture;Software testing;Web services;load balance;multi-machine testing;performance testing;strategy model;web services},
}

@Article{Ghosh1999,
  author   = {P. K. Ghosh and L. G. Durante},
  title    = {Measurement performance testing for nonsinusoidal environments},
  journal  = {IEEE Transactions on Power Systems},
  year     = {1999},
  volume   = {14},
  number   = {4},
  pages    = {1526-1532},
  month    = {Nov},
  issn     = {0885-8950},
  abstract = {A comparative study of the measurement accuracy capabilities of solid state watthour meters and other commercially available measurement instruments was performed. This study proposes a set of mathematically designed "waveforms" that could be used as a standard for the uniform, meaningful and reproducible evaluation testing of solid state watthour meters designed for use in nonsinusoidal environments. The test waveforms were theoretically developed based on an extensive database of field captured distorted waveforms that, in most cases, were monitored and recorded during power quality investigations over the last five years. Experimentation was performed using both the theoretically developed waveforms and the field captured waveforms.},
  doi      = {10.1109/59.801951},
  keywords = {calibration;harmonic distortion;power measurement;power supply quality;power system harmonics;watthour meters;measurement accuracy;measurement instruments;measurement performance testing;nonsinusoidal supply environments;power quality;solid state watthour meters;Electric variables measurement;Guidelines;Harmonic distortion;Laboratories;Power system harmonics;Power systems;Semiconductor materials;Solid state circuits;Testing;Watthour meters},
}

@Article{Lee1983,
  author   = {R. E. Lee and M. T. Bishop},
  title    = {Performance Testing of the Ratio Ground Relay on a Four-Wire Distribution Feeder},
  journal  = {IEEE Transactions on Power Apparatus and Systems},
  year     = {1983},
  volume   = {PAS-102},
  number   = {9},
  pages    = {2943-2949},
  month    = {Sept},
  issn     = {0018-9510},
  abstract = {Digital fault investigations on six Pennsylvania Power and Light 12 kV distribution feeders led to the development of a prototype Ratio Ground Relay to theoretically provide better detection of broken conductor faults. Further assessment of the relay's performance was provided through analog computer tests followed by staged fault testing on an operating distribution feeder. Performance tests are described and documented. These positive test results provided the incentive to monitor the performance of the Ratio Ground Relay on several PP&L distribution feeders.},
  doi      = {10.1109/TPAS.1983.318145},
  keywords = {Analog computers;Circuit faults;Circuit testing;Conductors;Digital relays;Fault detection;Impedance;Performance evaluation;Power system relaying;Prototypes},
}

@InProceedings{Li2014,
  author    = {J. Li and Q. Li and T. Bi and H. Liu and K. Xu and F. Sun},
  title     = {PMUs performance testing and evaluation in China},
  booktitle = {2014 IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC)},
  year      = {2014},
  pages     = {1-6},
  month     = {Dec},
  abstract  = {Phasor measurement units (PMU) are taking an increasingly important role in power system dynamic security monitoring and control. However, traditional Discrete Fourier Transforms (DFT) used by PMUs cannot obtain accurate phasor measurements during frequency excursion and transient events, being limited by its static phasor model. Therefore, the performance of PMUs under both static and dynamic conditions is fundamental. In this paper, the averaging effect of DFT is explored, which results in the measurement errors of PMUs under dynamic conditions. Then, a PMU testing system is introduced. With that, a centralized test aiming to improve the performance of M-class PMUs in China is accomplished by evaluating the PMUs from seven manufactures in China under static and dynamic conditions. The testing results show that the PMUs under test can satisfy most requirements in the standard by improving their algorithms. The testing data is analyzed to demonstrate the correctness of the theoretical derivation of the averaging effect of DFT.},
  doi       = {10.1109/APPEEC.2014.7066184},
  issn      = {2157-4839},
  keywords  = {discrete Fourier transforms;phasor measurement;power system control;power system security;China;DFT;M-class PMU measurement error;PMU performance evaluation;discrete Fourier transform;frequency excursion;phasor measurement unit performance testing;power system dynamic control;power system dynamic security monitoring;static phasor model;Discrete Fourier transforms;Frequency measurement;Phasor measurement units;Power system dynamics;Standards;Testing;Time measurement;Discrete Fourier transforms (DFT);dynamic phasor algorithm;phasor measurement units (PMU);power system measurements;power system transients},
}

@InProceedings{Bot2014,
  author    = {P. Bot and C. Vatamanu and D. Gavrilut and R. M. Benchea},
  title     = {Performance testing framework: Evaluating the impact on the system speed},
  booktitle = {2014 Second Workshop on Anti-malware Testing Research (WATeR)},
  year      = {2014},
  pages     = {1-6},
  month     = {Oct},
  abstract  = {The world we live in now is defined by the word “speed” and any device, technology, or system that doesn't keep up is rejected or replaced immediately. Because of this, one of the biggest concerns today is “optimization”. Its purpose is to reduce the impact on the user's device. The Anti-Virus industry is also confronting with this challenge. Although the first concern is to keep the user safe, providing a flawless protection, it is crucial to reduce the impact brought on the user's system, preventing him to disable or uninstall the AV solution and thus remaining unprotected. The increased number of malware types/families as well as their complexity generated the need for complicated detection methods, which means a constant evaluation is needed. Because of these reasons, our antimalware laboratory has developed a generic framework for measuring the impact that the AV solutions have on the system they are installed on. This system was designed to be easily configurable, managing the big number of changes that occur every day and fast so that every update released to the users can be tested. Also, this framework is used to test and develop new technologies that improve the performance of our AV product.},
  doi       = {10.1109/WATeR.2014.7015753},
  keywords  = {DP industry;data protection;invasive software;program testing;software performance evaluation;AV solution;antivirus industry;flawless protection;malware type;performance testing framework;system speed impact;Computers;Databases;Gold;Laboratories;Operating systems;Servers;generic framework;impact;performance;user interaction},
}

@Article{Pendurkar2001,
  author   = {R. Pendurkar and A. Chatterjee and Y. Zorian},
  title    = {Switching activity generation with automated BIST synthesis for performance testing of interconnects},
  journal  = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  year     = {2001},
  volume   = {20},
  number   = {9},
  pages    = {1143-1158},
  month    = {Sep},
  issn     = {0278-0070},
  abstract = {A novel scheme of synthesizing nonlinear feedback shift register structures that can be superimposed on the boundary of the component of a system under test to generate interconnect switching activities that resemble real life interconnect switching profiles is proposed. The goal is to perform at-speed interconnect test while simultaneously capturing the dynamic switching effects such as crosstalk and ground bounce, as accurately as possible during interconnect built-in self-test. A library of nonlinear feedback shift register structures called precharacterized test pattern generators (P-TPGs) is constructed. Components of P-TPGs can be modeled using Markov chain and can be interconnected together in specific ways to recreate the switching activity profile of the interconnections being tested. The unique advantage of this scheme is that there is no simulation overhead since P-TPG components are precharacterized by solving Markov equations analytically. An integrated genetic algorithm-based search and optimization technique for finding the best P-TPG component among various possible implementations and matching its activity profiles with those of the interconnections under test has been designed and implemented synthesis for testability allows generation of the worst case interconnect switching activities. Experimental results confirm the validity of our approach},
  doi      = {10.1109/43.945309},
  keywords = {Markov processes;automatic testing;built-in self test;crosstalk;design for testability;genetic algorithms;integrated circuit interconnections;integrated circuit testing;shift registers;Markov chain;automated BIST synthesis;crosstalk;design for testability;genetic algorithm;ground bounce;interconnect performance testing;nonlinear feedback shift register;precharacterized test pattern generator;search optimization;switching activity;Automatic testing;Built-in self-test;Crosstalk;Feedback;Libraries;Life testing;Nonlinear dynamical systems;Performance evaluation;Shift registers;System testing},
}

@Article{Gojare2015a,
  author   = {Satish Gojare and Rahul Joshi and Dhanashree Gaigaware},
  title    = {Analysis and Design of Selenium WebDriver Automation Testing Framework},
  journal  = {Procedia Computer Science},
  year     = {2015},
  volume   = {50},
  pages    = {341 - 346},
  issn     = {1877-0509},
  note     = {Big Data, Cloud and Computing Challenges},
  abstract = {Abstract Nowadays, number of software system has been implemented as web-based applications. These web applications are very complex. It is very difficult to test such complex web applications. Automation testing uses automation tools to reduce human intervention and repeatable tasks. In this paper we have designed and implemented automation testing framework for testing web applications. This new automation testing framework has been implemented using selenium WebDriver tool. Using this framework tester can easily write their test cases efficiently and in less time. Tester need not to study the selenium webdriver tool in detail. This framework is helpful to developer to analyze their code due to screen shot property of framework. This framework produces the customized test report to tester. It is very easy to maintain and repair the test suite for new release of the application using this framework. },
  doi      = {https://doi.org/10.1016/j.procs.2015.04.038},
  keywords = {Web applications, Automation testing, selenium webdriver, Automation testing framework.},
  url      = {https://www.sciencedirect.com/science/article/pii/S1877050915005396},
}

@Article{Sioutas2015,
  author   = {S. Sioutas and E. Sakkopoulos and A. Panaretos and D. Tsoumakos and P. Gerolymatos and G. Tzimas and Y. Manolopoulos},
  title    = {D-P2P-Sim+: A novel distributed framework for \{P2P\} protocols performance testing},
  journal  = {Journal of Systems and Software},
  year     = {2015},
  volume   = {100},
  pages    = {211 - 233},
  issn     = {0164-1212},
  abstract = {Abstract In recent technologies like IoT (Internet of Things) and Web 2.0, a critical problem arises with respect to storing and processing the large amount of collected data. In this paper we develop and evaluate distributed infrastructures for storing and processing large amount of such data. We present a distributed framework that supports customized deployment of a variety of indexing engines over million-node overlays. The proposed framework provides the appropriate integrated set of tools that allows applications processing large amount of data, to evaluate and test the performance of various application protocols for very large scale deployments (multi million nodes–billions of keys). The key aim is to provide the appropriate environment that contributes in taking decisions regarding the choice of the protocol in storage \{P2P\} systems for a variety of big data applications. Using lightweight and efficient collection mechanisms, our system enables real-time registration of multiple measures, integrating support for real-life parameters such as node failure models and recovery strategies. Experiments have been performed at the PlanetLab network and at a typical research laboratory in order to verify scalability and show maximum re-usability of our setup. D-P2P-Sim+ framework is publicly available at http://code.google.com/p/d-p2p-sim/downloads/list. },
  doi      = {https://doi.org/10.1016/j.jss.2014.11.001},
  keywords = {Distributed storage systems, IoT and Web 2.0 applications, P2P data management},
  url      = {https://www.sciencedirect.com/science/article/pii/S0164121214002416},
}

@Article{He2016a,
  author   = {Xiao He and Tian Zhang and Chang-Jun Hu and Zhiyi Ma and Weizhong Shao},
  title    = {An \{MDE\} performance testing framework based on random model generation},
  journal  = {Journal of Systems and Software},
  year     = {2016},
  volume   = {121},
  pages    = {247 - 264},
  issn     = {0164-1212},
  abstract = {Abstract The scalability of model-related operations (e.g., model transformations), when they are to be applied in industrial model-driven engineering, becomes an important issue. However, there is a lack of an automated performance testing framework for those operations, since the existing ones for ordinary programs are ill-suited. Such a framework is required to provide the function of creating and organizing test cases, and the ability of generating test input of large size automatically, because large scale models are not widely available, making it hard to test the performance and coverage of those operations without any bias. This paper proposes a performance testing framework, integrated with a random model generation algorithm, for model-related operations. The framework, based on a test model, can be used to specify and arrange test cases into test suites. And the model generation algorithm can generate a random model correctly and efficiently, according to the metamodel and user-defined constraints. Finally, we present two case studies, one experiment in randomness, and two experiments in generation efficiency to evaluate the framework and algorithm. Results show that the framework is competent to support performance testing of model-related operations, and the algorithm is random and efficient enough to generate test data for performance testing. },
  doi      = {https://doi.org/10.1016/j.jss.2016.04.044},
  keywords = {Model-related operation, Performance testing, Model generation, Model-driven engineering},
  url      = {https://www.sciencedirect.com/science/article/pii/S0164121216300292},
}

@Article{Pan2009,
  author   = {Lei Pan and Lynn M. Batten},
  title    = {Robust performance testing for digital forensic tools},
  journal  = {Digital Investigation},
  year     = {2009},
  volume   = {6},
  number   = {1–2},
  pages    = {71 - 81},
  issn     = {1742-2876},
  abstract = {In previous work, the authors presented a theoretical lower bound on the required number of testing runs for performance testing of digital forensic tools. However, experimental errors are inevitable in laboratory settings, occurring as measurement errors or as random errors and can result in practical situations where the number of testing runs is far from the theoretical bound. This paper adapts our former work to tolerate such errors in the testing results. The contribution of our new methodology enables the tester to achieve performance testing results of high quality from a manageable number of observations and in a dynamic but controllable way. This is of particular interest to forensic testers who do not have access to sophisticated equipment and who can allocate only a small amount of time to testing. },
  doi      = {https://doi.org/10.1016/j.diin.2009.02.003},
  keywords = {Digital forensic tool testing, Experimental errors, Performance testing, CFReDS project, EESAG},
  url      = {https://www.sciencedirect.com/science/article/pii/S1742287609000279},
}

@Article{Breeden2016,
  author   = {Joseph L. Breeden},
  title    = {Incorporating lifecycle and environment in loan-level forecasts and stress tests},
  journal  = {European Journal of Operational Research},
  year     = {2016},
  volume   = {255},
  number   = {2},
  pages    = {649 - 658},
  issn     = {0377-2217},
  abstract = {Abstract The new \{FASB\} current expected credit loss (CECL) proposal, IASB’s \{IFRS\} 9, and regulatory stress testing all require that the industry move toward forecasting probabilities of future events, rather than simply rank-ordering loans. Even more importantly, effective loan pricing requires this same forward-looking, loan-level forecasting. We created a loan-level version of Age-Period-Cohort (APC) models suitable for forecasting individual loan performance at a point-in-time or for the loan’s lifetime. The \{APC\} literature explains that any model of loan performance must make either an explicit or implicit assumption around the embedded model specification error between age of the loan, vintage origination date, and performance date. We have made this assumption explicit and implemented a technique using augmented macroeconomic history to stabilize the analysis. The preceding steps provide robust estimates of lifecycle and environmental impacts. We then use a Generalized Linear Model (GLM) with a population odds offset for each age/time combination derived from the lifecycle and environment functions in order to estimate origination and behavior scores. Analyzing a small \{US\} auto loan portfolio, we demonstrate that this model is robust out-of-sample and out-of-time for predicting both rank-ordering and probabilities by inserting the odds offset appropriate for the environment being modeled. In addition to producing loan-level forecasts and stress tests, the scores produced have higher rank-order performance out-of-sample and out-of-time than standard scores. The scores prove to be robust years into the future with no measurable degradation in performance because of the stabilizing effect of the offset factor during model construction. },
  doi      = {https://doi.org/10.1016/j.ejor.2016.06.008},
  keywords = {Forecasting, Risk, Banking, Time series, Age-Period-Cohort models},
  url      = {https://www.sciencedirect.com/science/article/pii/S0377221716304283},
}

@Article{Ahmad2018,
  author   = {Tanwir Ahmad and Dragos Truscan and Ivan Porres},
  title    = {Identifying worst-case user scenarios for performance testing of web applications using Markov-chain workload models},
  journal  = {Future Generation Computer Systems},
  year     = {2018},
  pages    = {-},
  issn     = {0167-739X},
  abstract = {Abstract The poor performance of web-based systems can negatively impact the profitability and reputation of the companies that rely on them. Finding those user scenarios which can significantly degrade the performance of a web application is very important in order to take necessary countermeasures, for instance, allocating additional resources. Furthermore, one would like to understand how the system under test performs under increased workload triggered by the worst-case user scenarios. In our previous work, we have formalized the expected behavior of the users of web applications by using probabilistic workload models and we have shown how to use such models to generate load against the system under test. As an extension, in this article, we suggest a performance space exploration approach for inferring the worst-case user scenario in a given workload model which has the potential to create the highest resource utilization on the system under test with respect to a given resource. We propose two alternative methods: one which identifies the exact worst-case user scenario of the given workload model, but it does not scale up for models with a large number of loops, and one which provides an approximate solution which, in turn, is more suitable for models with a large number of loops. We conduct several experiments to show that the identified user scenarios do provide in practice an increased resource utilization on the system under test when compared to the original models. },
  doi      = {https://doi.org/10.1016/j.future.2018.01.042},
  keywords = {Performance testing, Markov chain, Genetic algorithms, Graph-search algorithms},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167739X18301341},
}

@Article{Cappelletti1997,
  author   = {P. Cappelletti and R. Bez and D. Cantarelli and D. Nahmad and L. Ravazzi},
  title    = {Cast: An electrical stress test to monitor single bit failures in flash-EEPROM structures},
  journal  = {Microelectronics Reliability},
  year     = {1997},
  volume   = {37},
  number   = {3},
  pages    = {473 - 481},
  issn     = {0026-2714},
  abstract = {To increase yield and reliability of flash-EEPROM devices, great effort has been devoted to improve the way of monitoring the tunnel oxide quality, both as regards the electrical measurements and the related test structures. The most popular test is an electrical stress to evaluate the charge or the electric field at breakdown on large area or edge intensive capacitors. Although the capacitor test is a fundamental means to evaluate the oxide quality, it can not detect the subtle defects which are responsible for the most likely flash-EEPROM failure mechanisms such as the single bit over-erasure or failure after an electrical stress. To overcome this difficulty the cell array stress test (CAST, patent pending) has been conceived: by means of a suitable test structure it is possible to detect defective cells in a flash-EEPROM array. Correlation with actual flash-EEPROM yield is demonstrated. This test can be used either as a short-loop monitor for process control and improvement or as an end-of-process wafer level screening. },
  doi      = {https://doi.org/10.1016/0026-2714(95)00214-6},
  url      = {https://www.sciencedirect.com/science/article/pii/0026271495002146},
}

@Article{Garousi2008a,
  author   = {Vahid Garousi and Lionel C. Briand and Yvan Labiche},
  title    = {Traffic-aware stress testing of distributed real-time systems based on \{UML\} models using genetic algorithms},
  journal  = {Journal of Systems and Software},
  year     = {2008},
  volume   = {81},
  number   = {2},
  pages    = {161 - 185},
  issn     = {0164-1212},
  note     = {Model-Based Software Testing},
  abstract = {This paper presents a model-driven, stress test methodology aimed at increasing chances of discovering faults related to network traffic in distributed real-time systems (DRTS). The technique uses the \{UML\} 2.0 model of the distributed system under test, augmented with timing information, and is based on an analysis of the control flow in sequence diagrams. It yields stress test requirements that are made of specific control flow paths along with time values indicating when to trigger them. The technique considers different types of arrival patterns (e.g., periodic) for real-time events (common to DRTSs), and generates test requirements which comply with such timing constraints. Though different variants of our stress testing technique already exist (that stress different aspects of a distributed system), they share a large amount of common concepts and we therefore focus here on one variant that is designed to stress test the system at a time instant when data traffic on a network is maximal. Our technique uses genetic algorithms to find test requirements which lead to maximum possible traffic-aware stress in a system under test. Using a real-world \{DRTS\} specification, we design and implement a prototype \{DRTS\} and describe, for that particular system, how the stress test cases are derived and executed using our methodology. The stress test results indicate that the technique is significantly more effective at detecting network traffic-related faults when compared to test cases based on an operational profile. },
  doi      = {https://doi.org/10.1016/j.jss.2007.05.037},
  keywords = {Stress testing, Performance testing, Model-based testing, Distributed systems, Real-time systems, UML, Network traffic, Genetic algorithms},
  url      = {https://www.sciencedirect.com/science/article/pii/S0164121207001239},
}

@Article{Easterly2010,
  author   = {Dwight R. Easterly and Viacheslav I. Adamchuk and Michael F. Kocher and Roger M. Hoy},
  title    = {Using a vision sensor system for performance testing of satellite-based tractor auto-guidance},
  journal  = {Computers and Electronics in Agriculture},
  year     = {2010},
  volume   = {72},
  number   = {2},
  pages    = {107 - 118},
  issn     = {0168-1699},
  abstract = {A vision sensing system for the measurement of auto-guidance pass-to-pass and long-term errors was implemented to test the steering performance of tractors equipped with auto-guidance systems. The developed test system consisted of an optical machine vision sensor rigidly mounted on the rear of the tested tractor. The center of the drawbar hitch pin point was used as the reference from which to measure the deviation of the tractor's actual travel path from its desired path. The system was built and calibrated to a measurement accuracy of better than 2 mm. To evaluate the sensor, two auto-guidance systems equipped with RTK-level \{GNSS\} receivers were tested and the results for different travel speeds compared. Pass-to-pass and long-term errors were calculated using the relative positions of a reference at a collocated point when the tractor was operated in opposite directions within 15 min and more than 1 h apart, respectively. In addition to variations in speed, two different auto-guidance steering stabilization distances allowed for comparison of two different definitions of steady-state operation of the system. For the analysis, non-parametric cumulative distributions were generated to determine error values that corresponded to 95% of the cumulative distribution. Both auto-guidance systems provided 95% cumulative error estimates comparable to 51 mm (2 in.) claims and even smaller during Test A. Higher travel speeds (especially 5.0 m/s) significantly increased measured auto-guidance error, but no significant difference was observed between pass-to-pass and long-term error estimates. The vision sensor testing system could be used as a means to implement the auto-guidance test standard under development by the International Standard Organization (ISO). Third-party evaluation of auto-guidance performance will increase consumer awareness of the potential performance of products provided by a variety of vendors. },
  doi      = {https://doi.org/10.1016/j.compag.2010.03.004},
  keywords = {Auto-guidance, Auto-steering, GNSS, GPS, Receiver, Tractor testing, Standard},
  url      = {https://www.sciencedirect.com/science/article/pii/S0168169910000724},
}

@Article{Choi2004,
  author   = {Eunmi Choi},
  title    = {Performance test and analysis for an adaptive load balancing mechanism on distributed server cluster systems},
  journal  = {Future Generation Computer Systems},
  year     = {2004},
  volume   = {20},
  number   = {2},
  pages    = {237 - 247},
  issn     = {0167-739X},
  note     = {Modeling and simulation in supercomputing and telecommunications},
  abstract = {As the next generation of Internet services requires more highly scalable and available server systems, the cost-effective cluster of a large number of distributed computers becomes a popular solution. In this paper, we investigate to design and develop a server load balancing mechanism on cluster architecture, called the \{ALBM\} cluster. In order to construct the more scalable and reliable Internet service system, the \{ALBM\} cluster system consists of independent but co-operable components. The \{ALBM\} cluster system supports adaptive load balancing among servers via its adaptive load balancer (ALB) component in Layer 4 level and Layer 7 level. The Management Station (M-Station) and the Administrator Console are in charge of cluster management, system configuration management, and performance counter management. The Node Service is a system-level agent that is deployed into a server node. The node management and cluster management are the major tasks of the agent. Beside, the \{ALBM\} cluster is a flexible open system whose features of functionality can change or be easily expanded without affecting the rest of the system. In this paper, we also present a set of our experimental results to compare the performance of the \{ALBM\} cluster with that of \{LVS\} scheduling cluster system. We compare performance results of the \{ALBM\} with RR, LC, and \{WLC\} scheduling algorithms of a \{LVS\} cluster in both of homogeneous and heterogeneous system environments. },
  doi      = {https://doi.org/10.1016/S0167-739X(03)00138-9},
  keywords = {Cluster computing, Load balancing, LVS (Linux Virtual Server), Performance counter, Scalability, Availability},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167739X03001389},
}

@Article{Frankiewicz1991,
  author   = {Zygmunt Frankiewicz and Jacek Leski},
  title    = {Adaptive fiducial point detector for \{ECG\} stress testing systems},
  journal  = {International Journal of Bio-Medical Computing},
  year     = {1991},
  volume   = {28},
  number   = {1–2},
  pages    = {127 - 135},
  issn     = {0020-7101},
  abstract = {The paper deals with the problem of fiducial point detection in noisy exercise \{ECG\} signals. Performance of the averaging process depends on the detector's repeatability. The paper proposes an adaptive algorithm for optimization of the detector. The structure of the detector is well known and often used. Characteristics of the last filter are matched to the current signal and bandpass filter impulse response. The new method was tested using real \{ECG\} signals. Results indicated that the \{FP\} jittering was reduced to almost one half. },
  doi      = {https://doi.org/10.1016/0020-7101(91)90032-A},
  keywords = {Fiducial point detection, ECG signals},
  url      = {https://www.sciencedirect.com/science/article/pii/002071019190032A},
}

@Article{Huang2016,
  author   = {Jinsong Huang and Richard Kelly and Dianqinq Li and Chuangbing Zhou and Scott Sloan},
  title    = {Updating reliability of single piles and pile groups by load tests},
  journal  = {Computers and Geotechnics},
  year     = {2016},
  volume   = {73},
  pages    = {221 - 230},
  issn     = {0266-352X},
  abstract = {Abstract Pile load tests are used to refine designs and for quality assurance. They can also be used to verify the reliability of piles and pile groups. Stochastic methods have previously been developed to verify the reliability of single piles. A general stochastic method to verify the reliability of pile groups is developed in this paper. The method can be used to assess the reliability of groups where pile tests have been conducted to the ultimate capacity, to below the ultimate capacity but exceeding specified capacity, and where pile tests fail to achieve the specified capacity. In the latter case, the method allows decisions to be made as to whether the reliability of the entire pile group is satisfactory or whether additional piles need to be installed. },
  doi      = {https://doi.org/10.1016/j.compgeo.2015.12.003},
  keywords = {System reliability, Pile group, Load test, Bayesian updating},
  url      = {https://www.sciencedirect.com/science/article/pii/S0266352X1500258X},
}

@Article{Capdehourat2018,
  author   = {Germán Capdehourat and Germán Álvarez and Martín Álvarez and Pedro Porteiro and Fernando Bagalciague},
  title    = {High density emulation platform for Wi-Fi performance testing},
  journal  = {Ad Hoc Networks},
  year     = {2018},
  volume   = {70},
  pages    = {1 - 13},
  issn     = {1570-8705},
  abstract = {Abstract The \{IEEE\} 802.11 standard has become the basis of one of the most successful wireless communication technologies of all time. Originally created to provide wireless connectivity for a few devices, a couple of decades later it may support thousands of users in a single wireless LAN. This fact has made 802.11 a relevant research topic, and as it happens with other wireless technologies, many of the work carried out is based on simulations. In particular, studies for scenarios with high user density are usually performed this way, in many cases leading to conclusions which do not apply to real world situations. This mismatch can be due to multiple factors, such as the specific protocol implementations or the hardware and drivers used. In this article we present a novel 802.11-based testing platform, which aims to bridge the gap between simulations and the real world, in order to carry out research work for typical high density scenarios. The platform is compatible with standard 802.11-based wireless cards on the market and it was tested with two different radios, The validation metrics considered were the \{TCP\} throughput, the airtime utilization and the effective data rate, with relative errors ranging from 0 up to 15%. The potential of the tool is illustrated with real world measurements from two example use cases in education facilities: a school classroom and a conference room. The results indicate this might be the first step towards an open platform to enable active Wi-Fi performance testing for large scale scenarios. Further emulation capabilities are shown with different application tests already integrated to the platform, such as QoE tests for YouTube video playback or e-learning platforms. },
  doi      = {https://doi.org/10.1016/j.adhoc.2017.11.007},
  keywords = {\{IEEE\} 802.11, Client emulation, Performance testing},
  url      = {https://www.sciencedirect.com/science/article/pii/S1570870517302056},
}

@Article{Dobai2013,
  author   = {Roland Dobai and Marcel Balaz},
  title    = {SAT-based generation of compressed skewed-load tests for transition delay faults},
  journal  = {Microprocessors and Microsystems},
  year     = {2013},
  volume   = {37},
  number   = {2},
  pages    = {196 - 205},
  issn     = {0141-9331},
  note     = {Digital System Safety and Security},
  abstract = {Skewed-load tests ensure application of delay tests to logic cores of system-on-chip with only one storage element per cell in the wrapper boundary register and in the internal scan chain. This resolves the test area problem but the fault coverage and the test application time still require optimization efforts. The satisfiability-based test pattern generator of compressed skewed-load tests for transition delay fault is proposed. It represents a new efficient approach for generating compressed skewed-load tests because the test is gradually generated without the need of a pre-generated set of initialization and excitation vectors. Two optimization methods are also proposed. The first method, the wrapper cell ordering method, increases the fault coverage by reducing the shift dependence of skewed-load tests. The second method, the fault ordering method, ensures shorter tests by determining the order in which the faults will be targeted during the test generation and consequently, the new test vectors can overlap the test sequence in the greatest degree. The proposed methods were evaluated over benchmark circuits and the experimental results show higher fault coverages and shorter test lengths. },
  doi      = {https://doi.org/10.1016/j.micpro.2012.09.002},
  keywords = {Test generation, Test compression, Transition delay fault, Skewed-load, Fault coverage, Test length},
  url      = {https://www.sciencedirect.com/science/article/pii/S0141933112001640},
}

@InCollection{Chapman2016,
  author    = {Chris Chapman},
  title     = {Chapter 10 - Traffic performance testing in the network},
  booktitle = {Network Performance and Security},
  publisher = {Syngress},
  year      = {2016},
  editor    = {Chapman, Chris},
  pages     = {295 - 317},
  address   = {Boston},
  isbn      = {978-0-12-803584-9},
  abstract  = {Abstract We show how you may use open source tools to measure network performance. We cover key performance topics like streams and flows, as well as how to set them up and measure them. Last, we discuss how to interpret results. },
  doi       = {https://doi.org/10.1016/B978-0-12-803584-9.00010-X},
  keywords  = {network performance streams, flows, traffic analysis},
  url       = {https://www.sciencedirect.com/science/article/pii/B978012803584900010X},
}

@Article{Gao2018,
  author   = {Gelin Gao and Bud Mishra and Daniele Ramazzotti},
  title    = {Causal data science for financial stress testing},
  journal  = {Journal of Computational Science},
  year     = {2018},
  volume   = {26},
  pages    = {294 - 304},
  issn     = {1877-7503},
  abstract = {Abstract The most recent financial upheavals have cast doubt on the adequacy of some of the conventional quantitative risk management strategies, such as VaR (Value at Risk), in many common situations. Consequently, there has been an increasing need for verisimilar financial stress testings, namely simulating and analyzing financial portfolios in extreme, albeit rare scenarios. Unlike conventional risk management which exploits statistical correlations among financial instruments, here we focus our analysis on the notion of probabilistic causation, which is embodied by Suppes-Bayes Causal Networks (SBCNs); \{SBCNs\} are probabilistic graphical models that have many attractive features in terms of more accurate causal analysis for generating financial stress scenarios. In this paper, we present a novel approach for conducting stress testing of financial portfolios based on \{SBCNs\} in combination with classical machine learning classification tools. The resulting method is shown to be capable of correctly discovering the causal relationships among financial factors that affect the portfolios and thus, simulating stress testing scenarios with a higher accuracy and lower computational complexity than conventional Monte Carlo simulations. },
  doi      = {https://doi.org/10.1016/j.jocs.2018.04.003},
  keywords = {Stress testing, Graphical models, Causality, Suppes-Bayes Causal Networks, Classification, Decision trees},
  url      = {https://www.sciencedirect.com/science/article/pii/S1877750317311377},
}

@Article{Post2008,
  author   = {Julian W. Post and A. Bhattacharyya},
  title    = {Saline soak tests to determine the short-term reliability of an in situ thin film resistance temperature detector},
  journal  = {Microelectronics Reliability},
  year     = {2008},
  volume   = {48},
  number   = {10},
  pages    = {1673 - 1682},
  issn     = {0026-2714},
  abstract = {With an objective to assess the short-term reliability of thin film, encapsulated resistance temperature detectors (RTDs) in corrosive environments, these were placed in aqueous soak solutions of double de-ionized water (DDI) and phosphate buffered solution (PBS) or saline for eight weeks. They were removed weekly in order to characterize the effects of the solutions on their electrical properties, as well as their thermal response. The solutions were analyzed weekly as well with an FT-IR spectrometer in order to determine if chemical reactions took place during the soak tests and optical micrographic studies were carried out too. The \{RTDs\} appeared not to suffer degradation during the period of study. Nonetheless, it turned out that the soak tests offer a user-friendly and safe approach to remove the Benzocyclobutene (BCB) layer; this is an issue that is likely to be of some interest in the electronics fabrication community. },
  doi      = {https://doi.org/10.1016/j.microrel.2008.05.002},
  url      = {https://www.sciencedirect.com/science/article/pii/S0026271408001261},
}

@Article{Unsever2015,
  author   = {Y.S. Unsever and T. Matsumoto and M.Y. Özkan},
  title    = {Numerical analyses of load tests on model foundations in dry sand},
  journal  = {Computers and Geotechnics},
  year     = {2015},
  volume   = {63},
  pages    = {255 - 266},
  issn     = {0266-352X},
  abstract = {Abstract In this study, a series of vertical and cyclic horizontal load tests on 3-pile piled raft model were carried out in dry sand to investigate the piled raft behaviour under combined loads. Also, numerical modelling of experiments were carried out by using \{FEM\} software, \{PLAXIS\} 3D. Hardening soil model was employed to model the sand, and elastic model was used for the pile and the raft. Soil parameters were estimated from consolidated drained triaxial tests carried on the sand samples and pile parameters were estimated from simple bending tests. It is seen that the behaviour of piled raft is considerably influenced by the interaction of the raft and the piles, and that it is not possible to estimate piled raft behaviour by examining its components individually. },
  doi      = {https://doi.org/10.1016/j.compgeo.2014.10.005},
  keywords = {Piled raft, Vertical load test, Horizontal load test, Numerical modelling, Hardening soil model},
  url      = {https://www.sciencedirect.com/science/article/pii/S0266352X14001888},
}

@InCollection{Reeser2001,
  author    = {P. Reeser},
  title     = {Using stress test results to drive performance modeling: A case study in “Gray-Box” vendor analysis},
  booktitle = {Teletraffic Engineering in the Internet EraProceedings of the International Teletraffic Congress - ITC-I7},
  publisher = {Elsevier},
  year      = {2001},
  editor    = {Jorge Moreira de Souza, Nelson L.S. da Fonseca and Edmundo A. de Souza e Silva},
  volume    = {4},
  series    = {Teletraffic Science and Engineering},
  pages     = {1051 - 1061},
  abstract  = {In this case study, we present the results of analysis of a Java-based vendor product that performs dynamic Web page construction in a distributed environment. Since the vendor's scripts are proprietary, we must rely on “gray-box” stress test results to identify performance bottlenecks and determine system capacity. We present a methodology for reverse-engineering stress test results to build performance models of the system internals, and use those models to “see” inside the box. This approach provided significant insights into the performance of the vendor's proprietary code, and afforded us better leverage in the vendor management process. In particular, the approach identified significant bottlenecks in the Java code that prevented the system from fully utilizing the hardware resources. The approach also exposed the system's behavior under overload, and revealed the need for overload controls. Based on our success, we recommend that stress testing be incorporated into the software development process, especially when development consists largely of integrating external vendor components. Furthermore, in the case of vendor-provided software, this approach offers perhaps the only way to “see” inside the code, and in the case of new programming languages such as Java, exposes anomalies that could not be predicted from past experience. },
  doi       = {https://doi.org/10.1016/S1388-3437(01)80191-8},
  issn      = {1388-3437},
  url       = {https://www.sciencedirect.com/science/article/pii/S1388343701801918},
}

@Article{Bruce2018,
  author   = {Louise C. Bruce and Marieke A. Frassl and George B. Arhonditsis and Gideon Gal and David P. Hamilton and Paul C. Hanson and Amy L. Hetherington and John M. Melack and Jordan S. Read and Karsten Rinke and Anna Rigosi and Dennis Trolle and Luke Winslow and Rita Adrian and Ana I. Ayala and Serghei A. Bocaniov and Bertram Boehrer and Casper Boon and Justin D. Brookes and Thomas Bueche and Brendan D. Busch and Diego Copetti and Alicia Cortés and Elvira de Eyto and J. Alex Elliott and Nicole Gallina and Yael Gilboa and Nicolas Guyennon and Lei Huang and Onur Kerimoglu and John D. Lenters and Sally MacIntyre and Vardit Makler-Pick and Chris G. McBride and Santiago Moreira and Deniz Özkundakci and Marco Pilotti and Francisco J. Rueda and James A. Rusak and Nihar R. Samal and Martin Schmid and Tom Shatwell and Craig Snorthheim and Frédéric Soulignac and Giulia Valerio and Leon van der Linden and Mark Vetter and Brigitte Vinçon-Leite and Junbo Wang and Michael Weber and Chaturangi Wickramaratne and R. Iestyn Woolway and Huaxia Yao and Matthew R. Hipsey},
  title    = {A multi-lake comparative analysis of the General Lake Model (GLM): Stress-testing across a global observatory network},
  journal  = {Environmental Modelling \& Software},
  year     = {2018},
  volume   = {102},
  pages    = {274 - 291},
  issn     = {1364-8152},
  abstract = {Abstract The modelling community has identified challenges for the integration and assessment of lake models due to the diversity of modelling approaches and lakes. In this study, we develop and assess a one-dimensional lake model and apply it to 32 lakes from a global observatory network. The data set included lakes over broad ranges in latitude, climatic zones, size, residence time, mixing regime and trophic level. Model performance was evaluated using several error assessment metrics, and a sensitivity analysis was conducted for nine parameters that governed the surface heat exchange and mixing efficiency. There was low correlation between input data uncertainty and model performance and predictions of temperature were less sensitive to model parameters than prediction of thermocline depth and Schmidt stability. The study provides guidance to where the general model approach and associated assumptions work, and cases where adjustments to model parameterisations and/or structure are required. },
  doi      = {https://doi.org/10.1016/j.envsoft.2017.11.016},
  keywords = {Lake model, Stratification, GLM, Model assessment, Global observatory data, Network science},
  url      = {https://www.sciencedirect.com/science/article/pii/S1364815216311562},
}

@Article{Gaone2018,
  author   = {F.M. Gaone and S. Gourvenec and J.P. Doherty},
  title    = {Large-scale shallow foundation load tests on soft clay – At the National Field Testing Facility (NFTF), Ballina, NSW, Australia},
  journal  = {Computers and Geotechnics},
  year     = {2018},
  volume   = {93},
  pages    = {253 - 268},
  issn     = {0266-352X},
  note     = {Ballina Embankment Prediction Symposium},
  abstract = {Abstract This paper presents field test data from four instrumented rigid square pad foundations on soft clay that were brought to failure under concentric vertical loading. The test programme comprised two unconsolidated undrained (UU) foundation tests as well as two consolidated undrained (CU) tests. In the latter case the two foundations were preloaded to a proportion of the \{UU\} capacity and the soil was allowed to consolidate before being brought to undrained failure. In this paper, the site works and testing procedures are presented along with the load- and time-settlement responses of all four foundations. Horizontal stress and pore pressure data are presented for the two \{CU\} tests. The undrained and consolidated undrained load-settlement responses are shown to agree well with theoretical and numerical predictions. Results from the \{UU\} tests were the subject of a prediction exercise, summarised in a companion paper presented in this special issue. },
  doi      = {https://doi.org/10.1016/j.compgeo.2017.05.008},
  keywords = {Shallow foundations, Field testing, Soft clay},
  url      = {https://www.sciencedirect.com/science/article/pii/S0266352X17301180},
}

@Article{Kar2013,
  author   = {Yap Boon Kar and Tan Cai Hui and Ramasamy Agileswari and Calvin Lo},
  title    = {Comparison study on reliability performance for polymer core solder balls under multiple reflow and \{HTS\} stress tests},
  journal  = {Microelectronics Reliability},
  year     = {2013},
  volume   = {53},
  number   = {1},
  pages    = {164 - 173},
  issn     = {0026-2714},
  note     = {Reliability of Micro-Interconnects in 3D \{IC\} Packages},
  abstract = {Drop ball reliability for Ball Grid Array (BGA) package on lead-free product is a major reliability concern. Integrating a polymer core in the solder ball could be a good strategy to dissipate stress better compared to the purely metallic solder ball. However, the diffusion rate of the copper is much faster than the diffusion rate of the solder. Hence, Kirkendall voids starts forming and causing crack between the interface of copper and solder. This could affect the solder joint as well as the solder ball drop reliability especially when subjected to high temperature stress. The new polymer core solder ball with 1 μm thickness of nickel (Ni) coated on the copper (polymer core/copper/nickel/solder) could offer better solder ball joint and drop reliability performance. This work studies the effects of \{IMC\} growth, solder ball shear strength and drop test reliability. Subsequently, the failure modes were observed after multiple reflow (up to 5 times) and \{HTS\} stress tests. The \{IMC\} formation was observed under the high power scope with magnification 50× via the mechanical cross-section and was measured using an analytical software tool. Solder ball shear test was carried out to measure the solder joint performance after multiple reflow and \{HTS\} stress tests via the Dage 4000 series bond tester. Drop reliability test was carried out via the packing drop test. From this study, we could conclude that the polymer core solder ball with an additional Ni layer coating demonstrates better performance than the polymer core solder ball without Ni layer. The same observation applies to the solder ball shear strength, drop reliability performance in multiple reflow and \{HTS\} stress tests. The \{IMC\} thickness for polymer core solder ball without additional Ni layer is much thicker than the polymer core solder ball with an additional Ni layer, most probably because Ni could limit the Cu diffusion into the solder, thus resulting in better reliability performance. },
  doi      = {https://doi.org/10.1016/j.microrel.2012.07.032},
  url      = {https://www.sciencedirect.com/science/article/pii/S0026271412003836},
}

@Article{Gao2017a,
  author   = {Gelin Gao and Bud Mishra and Daniele Ramazzotti},
  title    = {Efficient Simulation of Financial Stress Testing Scenarios with Suppes-Bayes Causal Networks},
  journal  = {Procedia Computer Science},
  year     = {2017},
  volume   = {108},
  pages    = {272 - 284},
  issn     = {1877-0509},
  note     = {International Conference on Computational Science, \{ICCS\} 2017, 12-14 June 2017, Zurich, Switzerland},
  abstract = {Abstract The most recent financial upheavals have cast doubt on the adequacy of some of the conventional quantitative risk management strategies, such as VaR (Value at Risk), in many common situations. Consequently, there has been an increasing need for verisimilar financial stress testings, namely simulating and analyzing financial portfolios in extreme, albeit rare scenarios. Unlike conventional risk management which exploits statistical correlations among financial instruments, here we focus our analysis on the notion of probabilistic causation, which is embodied by Suppes-Bayes Causal Networks (SBCNs), \{SBCNs\} are probabilistic graphical models that have many attractive features in terms of more accurate causal analysis for generating financial stress scenarios. In this paper, we present a novel approach for conducting stress testing of financial portfolios based on \{SBCNs\} in combination with classical machine learning classification tools. The resulting method is shown to be capable of correctly discovering the causal relationships among financial factors that affect the portfolios and thus, simulating stress testing scenarios with a higher accuracy and lower computational complexity than conventional Monte Carlo Simulations. },
  doi      = {https://doi.org/10.1016/j.procs.2017.05.167},
  keywords = {stress Testing, Graphical Models, Causality, Suppes-Bayes Causal Networks, Classification, Decision Trees},
  url      = {https://www.sciencedirect.com/science/article/pii/S1877050917307500},
}

@Article{Lin2012,
  author   = {Shiu-Shin Lin and Maria Cecilia M. Marcos and Hsin-Wen Chang and Yit-Jin Chen},
  title    = {Design and implementation of a drilled shaft load test database},
  journal  = {Computers and Geotechnics},
  year     = {2012},
  volume   = {41},
  pages    = {106 - 113},
  issn     = {0266-352X},
  abstract = {This paper details the development and potential of the drilled shaft load test (DSLT) database in which 351 case histories of static load tests from various countries can be freely retrieved and utilized worldwide. Employing the Entity-Relationship (ER) model to the structure design of the database provides considerable flexibility and extensibility while the open source MySQL server systematically compiles the historic data. \{DSLT\} enables quick browsing, inexpensive query, and utility of data as pile design tools or as relevant data for advanced research. Moreover, it can serve as a data platform for a centralized storage of information among interested pile data holders worldwide. },
  doi      = {https://doi.org/10.1016/j.compgeo.2011.12.001},
  keywords = {Database, MySQL program, Drilled shafts, Load tests},
  url      = {https://www.sciencedirect.com/science/article/pii/S0266352X11001959},
}

@Article{Mitra2013,
  author   = {Arnab Mitra and Anirban Kundu},
  title    = {Cost Optimized Set of Primes Generation with Cellular Automata for Stress Testing in Distributed Computing},
  journal  = {Procedia Technology},
  year     = {2013},
  volume   = {10},
  pages    = {365 - 372},
  issn     = {2212-0173},
  note     = {First International Conference on Computational Intelligence: Modeling Techniques and Applications (CIMTA) 2013},
  abstract = {Abstract A sophisticated approach towards generation procedure of set of prime numbers using Cellular Automata (CA) has been reported here. Unique property of “Primality” found in prime numbers, has initiated a vast application and requirements for primes in many engineering and scientific applications. In this research, we have put an emphasis on cost efficient generation procedure for set of primes using \{CA\} for stress testing in distributed computing. An n-cell null boundary CA, have been considered to generate set of primes in cost effective method. Primality in generated pattern by \{CA\} has been verified with Fermat Primality Test. Proposed design for generation of primes to perform stress testing, is a cost effective solution. Physical implementation of system is cheap, since \{CA\} provides better flexibility and physical solution in designing the necessary hardware circuits at nominal cost. },
  doi      = {https://doi.org/10.1016/j.protcy.2013.12.372},
  keywords = {Distributed Computing, Stress Testing, Torture Testing, Primes, Fermat Primality, Cellular Automata (CA), Equal Length Cellular Automata (ELCA)},
  url      = {https://www.sciencedirect.com/science/article/pii/S2212017313005343},
}

@Article{Ataei2005,
  author   = {Sh. Ataei and A.A. Aghakouchak and M.S. Marefat and S. Mohammadzadeh},
  title    = {Sensor fusion of a railway bridge load test using neural networks},
  journal  = {Expert Systems with Applications},
  year     = {2005},
  volume   = {29},
  number   = {3},
  pages    = {678 - 683},
  issn     = {0957-4174},
  abstract = {Field testing of bridge vibrations induced by passage of vehicle is an economic and practical form of bridge load testing. Data processing of this type of tests are usually carried out in a system identification framework using output measurements techniques which are categorized as parametric or nonparametric methods. These methods are based on the theory of probability. Learning theory which stems its origin from two separate disciplines of statistical learning theory and neural networks, presents an efficient and robust framework for data processing of such tests. In this article, the linear two layer feed forward neural network (NN) with back propagation learning rule has been adapted for strain and displacement sensors fusion of a railway bridge load test. The trained \{NN\} has been used for structural analysis and finite element (FE) model updating. },
  doi      = {https://doi.org/10.1016/j.eswa.2005.04.038},
  keywords = {Learning theory, Neural networks, Sensor fusion, Railway bridge, Lad test, Model updating},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417405000849},
}

@Article{Ju2015,
  author   = {Yonghan Ju and Song Yi Jeon and So Young Sohn},
  title    = {Behavioral technology credit scoring model with time-dependent covariates for stress test},
  journal  = {European Journal of Operational Research},
  year     = {2015},
  volume   = {242},
  number   = {3},
  pages    = {910 - 919},
  issn     = {0377-2217},
  abstract = {Abstract Technology based loan default is related not only to technology-oriented attributes (management, technology, profitability and marketability), and firm-specific characteristics but also to the economic situation after the loan. However, the default phenomenon for technology based loan has not reflected the change of economic situation. We propose a framework of utilizing a time varying Cox hazard proportional model in the context of technology based credit scoring. The proposed model is used for stress test with various scenarios of lending portfolio and economic situations. The results indicate that the firms with higher management score than average have the lower loan default rates than the firms with higher profitability or marketability score than average due to the effect of manager's knowledge and experience and fund supply ability when they are exposed under the same economic condition. In scenario test, we found the highest default rate under stable exchange rate with high consumer price index. Moreover, firms with a high level of marketability factors turn out to be significantly affected by economic conditions in terms of technology credit risk. We expect the result of this study can provide valuable feedback for the management of technology credit fund for SMEs. },
  doi      = {https://doi.org/10.1016/j.ejor.2014.10.054},
  keywords = {Technology credit scoring, Stress test, Time-varying covariate, Survival analysis},
  url      = {https://www.sciencedirect.com/science/article/pii/S0377221714008765},
}

@Article{Antonelo2018,
  author   = {Eric Aislan Antonelo and Carlos Alberto Flesch and Filipe Schmitz},
  title    = {Reservoir computing for detection of steady state in performance tests of compressors},
  journal  = {Neurocomputing},
  year     = {2018},
  volume   = {275},
  pages    = {598 - 607},
  issn     = {0925-2312},
  abstract = {Abstract Fabrication of devices in industrial plants often includes undergoing quality assurance tests or tests that seek to determine some attributes or capacities of the device. For instance, in testing refrigeration compressors, we want to find the true refrigeration capacity of the compressor being tested. Such test (also called an episode) may take up to four hours, being an actual hindrance to applying it to the total number of compressors produced. This work seeks to reduce the time spent on such industrial trials by employing Recurrent Neural Networks (RNNs) as dynamical models for detecting when a test is entering the so-called steady-state region. Specifically, we use Reservoir Computing (RC) networks which simplify the learning of \{RNNs\} by speeding up training time and showing convergence to a global optimum. Also, this work proposes a self-organized subspace projection method for \{RC\} networks which uses information from the beginning of the episode to define a cluster to which the episode belongs to. This assigned cluster defines a particular binary input that shifts the operating point of the reservoir to a subspace of trajectories for the duration of the episode. This new method is shown to turn the \{RC\} model robust in performance with respect to varying combination of reservoir parameters, such as spectral radius and leak rate, when compared to a standard \{RC\} network. },
  doi      = {https://doi.org/10.1016/j.neucom.2017.09.005},
  keywords = {Reservoir computing, Echo state networks, Subspace projection, Unsupervised learning, Detection of steady state, Refrigeration compressors},
  url      = {https://www.sciencedirect.com/science/article/pii/S0925231217314765},
}

@Article{Jones2018,
  author   = {Taylor Jones and Arian Iraqi and Kurt Beschorner},
  title    = {Performance testing of work shoes labeled as slip resistant},
  journal  = {Applied Ergonomics},
  year     = {2018},
  volume   = {68},
  pages    = {304 - 312},
  issn     = {0003-6870},
  abstract = {Abstract The variability in friction and slip propensity across slip resistant (SR) shoes is poorly understood. This study aimed to quantify the impact of shoe design features on the available coefficient of friction (ACOF) across shoes labeled as SR. Differences in \{ACOF\} and the slipping rate across \{SR\} shoes were also quantified. Twelve shoes were tested across five types of flooring and three contaminant conditions using a whole shoe mechanical slip tester. Geometric and hardness parameters were measured to determine the effect of heel outsole design on ACOF. The rate of slipping was evaluated for three of the shoes on vinyl tile with canola oil using human subjects. Differences in \{ACOF\} were significant across shoe outsole designs (p &lt; .001). \{ACOF\} was correlated with geometrical and hardness parameters. Rate of slipping was lower for the highest \{ACOF\} shoe (p &lt; .001). This information can be used to guide \{SR\} shoe selection and design. },
  doi      = {https://doi.org/10.1016/j.apergo.2017.12.008},
  keywords = {Coefficient of friction, Shoe outsole, Slip and fall accidents},
  url      = {https://www.sciencedirect.com/science/article/pii/S0003687017302739},
}

@Article{Che2014,
  author   = {Xiaoping Che and Stephane Maag},
  title    = {Passive performance testing of network protocols},
  journal  = {Computer Communications},
  year     = {2014},
  volume   = {51},
  pages    = {36 - 47},
  issn     = {0140-3664},
  abstract = {Abstract Complementary to performance evaluation, performance testing of communicating protocols is a qualitative and quantitative test of a system, aiming at checking whether performance requirements of protocols have been satisfied under certain conditions. It raises an interesting issue of accurately formalizing specified performance requirements by taking consideration of data values of the protocol messages. In this paper, we present a novel logic-based testing approach to check protocol performance requirements through real execution traces and formally specified properties. In order to evaluate and assess our methodology, we develop a prototype and present experiments through a set of Session Initiation Protocol (SIP) properties. Finally, a performance benchmark method is proposed and relevant verdicts and discussions are provided. },
  doi      = {https://doi.org/10.1016/j.comcom.2014.06.001},
  keywords = {Passive testing, Performance testing, Session Initiation Protocol},
  url      = {https://www.sciencedirect.com/science/article/pii/S0140366414002096},
}

@Article{Cai2016,
  author   = {Miao Cai and Daoguo Yang and Jianna Zheng and Jianlin Huang and Dongjing Liu and Jing Xiao and Ping Zhang and Guoqi Zhang and Xianping Chen},
  title    = {Effects of stress-loading test methods on the degradation of light-emitting diode modules},
  journal  = {Microelectronics Reliability},
  year     = {2016},
  volume   = {64},
  pages    = {635 - 639},
  issn     = {0026-2714},
  note     = {Proceedings of the 27th European Symposium on Reliability of Electron Devices, Failure Physics and AnalysisProceedings of the 27th European Symposium on Reliability of Electron Devices, Failure Physics and Analysis},
  abstract = {Abstract This study investigates the degradation of light-emitting diode (LED) lamp modules by various stress–load test approaches, namely, step-up stress accelerated degradation testing, step-down stress accelerated degradation testing (SDSADT), and constant stress accelerated degradation testing. Two types of commercial \{LED\} lamps with different capabilities of heat dissipation (CHDs) are utilized in the experiment. LM-80 testing on two types of \{LED\} packages is further implemented to reproduce the degradation reaction of Lamp B. Result shows that \{SDSADT\} can effectively alleviate the initial increase in optical parameters. Lamp B with a strong \{CHD\} exhibits a similar lumen decay rate at each stress of step stress testing; this similarity implies that the decay rate of Lamp B is only related to the current loaded stress. The lumen decay rate of the initial decay paths for Lamp B as the thermal stress increases exhibits a parabolic law. This parabolic pattern is also detected in the LM-80 testing for the \{LED\} packages and is explained by the strong \{CHD\} of Lamp B. The thermally induced mechanisms, which influence the optical emission of LEDs, should be responsible for the parabolic decay law. Moreover, the color shift of the \{LED\} modules with increasing loaded stresses is more sensitive than lumen degradation. },
  doi      = {https://doi.org/10.1016/j.microrel.2016.07.009},
  keywords = {\{LED\} lamp module, Step-down stress accelerated degradation testing, Step-up stress accelerated degradation testing, Constant stress accelerated degradation testing, Degradation, Capability of heat dissipation},
  url      = {https://www.sciencedirect.com/science/article/pii/S0026271416301561},
}

@Article{Hu2014,
  author   = {Daning Hu and Jiaqi Yan and J. Leon Zhao and Zhimin Hua},
  title    = {Ontology-based scenario modeling and analysis for bank stress testing},
  journal  = {Decision Support Systems},
  year     = {2014},
  volume   = {63},
  pages    = {81 - 94},
  issn     = {0167-9236},
  note     = {1. Business Applications of Web of Things 2. Social Media Use in Decision Making},
  abstract = {Abstract The 2008 banking crisis demonstrated that there is a lack of effective methods for modeling and analyzing “exceptional but plausible” risk scenarios in bank stress testing. Existing stress testing practices mainly focus on modeling probability-based risk factors and events in banking systems using historical data. Rare (low probability) risk events that can cause financial crises in banking systems, such as the bankruptcy of Lehman Brothers, are largely ignored due to the lack of appropriate modeling and analysis methods. To address this problem, we propose an approach called Banking Event-driven Scenario-oriented Stress Testing (or simply, BESST) which has two main components: 1) an ontology-based event-driven scenario model (OESM), and 2) two analysis methods based on \{OESM\} for scenario recommendation and plausibility checking. The proposed \{BESST\} approach provides bank stress testing stakeholders an effective method for modeling and analyzing financial crisis scenarios that are rare but often have significant consequences. },
  doi      = {https://doi.org/10.1016/j.dss.2013.08.009},
  keywords = {Bank stress testing, Ontology, Scenario modeling, Plausibility check},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167923613002224},
}

@Article{Bahi2007,
  author   = {M.A. Bahi and P. Lecuyer and H. Fremont and J-P. Landesman},
  title    = {Sequential environmental stresses tests qualification for automotive components},
  journal  = {Microelectronics Reliability},
  year     = {2007},
  volume   = {47},
  number   = {9–11},
  pages    = {1680 - 1684},
  issn     = {0026-2714},
  note     = {18th European Symposium on Reliability of Electron Devices, Failure Physics and Analysis},
  abstract = {The purpose is to create a new qualification methodology for plastic encapsulated electronic components used in an automotive environment at high temperature. It is based on the acceleration of failure mechanisms like ball bond lift (due to intermetallic Au–Al thickness growth), by combination of environmental stresses. The delamination measurement was used as an indicator of potential assembly weaknesses. An optimized package sequential qualification test flow is proposed. },
  doi      = {https://doi.org/10.1016/j.microrel.2007.07.004},
  url      = {https://www.sciencedirect.com/science/article/pii/S0026271407002569},
}

@Article{Gonzalez2009,
  author   = {José Ramón González and Manuel Vázquez and Neftalí Núñez and Carlos Algora and Ignacio Rey-Stolle and Beatriz Galiana},
  title    = {Reliability analysis of temperature step-stress tests on III–V high concentrator solar cells},
  journal  = {Microelectronics Reliability},
  year     = {2009},
  volume   = {49},
  number   = {7},
  pages    = {673 - 680},
  issn     = {0026-2714},
  abstract = {III–V high concentrator solar cells are promising candidates for reducing the cost of photovoltaic electricity in terrestrial applications. However, the knowledge on the reliability of these devices is still scarce. Solar panels based on III–V high concentrator solar cells are about to be commercially available, and must compete with conventional systems based on silicon which have guarantees of approximately 25 years. This paper presents results of step-stress accelerated ageing tests carried out on these solar cells. Data have been analyzed according to Weibull reliability function. This analysis yields a lower value of the \{MTTF\} of 2.02 × 105 h (i.e. about 69.2 years assuming 8 h of average operation per day in a year) for a confidence interval of 90%. },
  doi      = {https://doi.org/10.1016/j.microrel.2009.04.001},
  url      = {https://www.sciencedirect.com/science/article/pii/S0026271409001115},
}

@Article{Winter2007,
  author   = {Victor L. Winter},
  title    = {Model-driven Transformation-based Generation of Java Stress Tests},
  journal  = {Electronic Notes in Theoretical Computer Science},
  year     = {2007},
  volume   = {174},
  number   = {1},
  pages    = {99 - 114},
  issn     = {1571-0661},
  note     = {Proceedings of the 7th International Workshop on Rule Based Programming (RULE 2006)},
  abstract = {This paper describes a practical application of transformation-based analysis and code generation. An overview is given of an approach for automatically constructing Java stress tests whose execution exercises all “interesting” class initialization sequence possibilities for a given class hierarchy. },
  doi      = {https://doi.org/10.1016/j.entcs.2006.10.022},
  keywords = {program transformation, strategic programming, Java class initialization, &lt;clinit&gt; method, JVM, TL, HATS},
  url      = {https://www.sciencedirect.com/science/article/pii/S1571066107001569},
}

@Article{Nowogrodzki2015,
  author  = {Anna Nowogrodzki},
  title   = {Stress tests for medics keep tabs on their health},
  journal = {New Scientist},
  year    = {2015},
  volume  = {228},
  number  = {3045},
  pages   = {22 -},
  issn    = {0262-4079},
  doi     = {https://doi.org/10.1016/S0262-4079(15)31507-4},
  url     = {https://www.sciencedirect.com/science/article/pii/S0262407915315074},
}

@Article{Tsai2011,
  author   = {Pei-hsun Tsai and Zheng-yi Feng and Shang-yuh Lin},
  title    = {A wavelet based method for estimating the damping ratio in statnamic pile load tests},
  journal  = {Computers and Geotechnics},
  year     = {2011},
  volume   = {38},
  number   = {2},
  pages    = {205 - 216},
  issn     = {0266-352X},
  abstract = {A wavelet based method is proposed to evaluate the time-dependent damping ratio in statnamic load tests by the continuous wavelet transform and half-power bandwidth method. The displacement along the pile during a statnamic test is described by a linear shape function, although the pile is assumed to be a single degree of freedom system (SDOF). The damping ratio is calculated by the half-power bandwidth method from the time–frequency spectra of continuous wavelet transform for the statnamic pile load test. A numerical simulation and two field statnamic tests were analyzed to verify the applicability of the proposed method, and the outcomes were compared with the results obtained using the unloading point method (UPM) and a method in literature. The damping ratio obtained with the proposed method is satisfactory and provides an additional interpretation measure for statnamic load tests. },
  doi      = {https://doi.org/10.1016/j.compgeo.2010.11.007},
  keywords = {Statnamic load test, Damping coefficient, Continuous wavelet transform},
  url      = {https://www.sciencedirect.com/science/article/pii/S0266352X10001618},
}

@Article{Bucur2015,
  author   = {Doina Bucur and Giovanni Iacca and Pieter-Tjerk de Boer},
  title    = {Characterizing topological bottlenecks for data delivery in \{CTP\} using simulation-based stress testing with natural selection},
  journal  = {Ad Hoc Networks},
  year     = {2015},
  volume   = {30},
  pages    = {22 - 45},
  issn     = {1570-8705},
  abstract = {Abstract Routing protocols for ad-hoc networks, e.g., the Collection Tree Protocol (CTP), are designed with simple node-local behaviour, but are deployed on testbeds with uncontrollable physical topology; exhaustively verifying the protocol on all possible topologies at design time is not tractable. We obtain topological insights on \{CTP\} performance, to answer the question: Which topological patterns cause \{CTP\} data routing to fail? We stress-test \{CTP\} with a quantitative testing method which searches for topologies using evolutionary algorithms combined with protocol simulation. The method iteratively generates new test topologies, such that the execution of the protocol over these topologies shows increasingly worse data-delivery ratios (DDR). We obtain a large set of example topologies of different network sizes up to 50 nodes, network densities, data rates, table sizes, and radio-frequency noise models, which, although connected, trigger a data delivery of nearly zero. We summarize these topologies into three types of topological problems, the root cause of which is the presence of certain asymmetric links and cycles, combined with a certain size of the routing table. We verify causality, i.e., show that randomly generated topologies having these particular features do cause low \{DDR\} in CTP. This testing methodology, while computationally intensive, is sound, fully automated and has better coverage over the corner cases of protocol behaviour than testing a protocol over manually crafted or random topologies. },
  doi      = {https://doi.org/10.1016/j.adhoc.2015.02.005},
  keywords = {Routing, Collection Tree Protocol, Performance evaluation, Data delivery ratio},
  url      = {https://www.sciencedirect.com/science/article/pii/S1570870515000426},
}

@InCollection{Chapman2016a,
  author    = {Chris Chapman},
  title     = {Chapter 1 - Introduction to practical security and performance testing},
  booktitle = {Network Performance and Security},
  publisher = {Syngress},
  year      = {2016},
  editor    = {Chapman, Chris},
  pages     = {1 - 14},
  address   = {Boston},
  isbn      = {978-0-12-803584-9},
  abstract  = {Abstract I will introduce the reader to some basic security concepts including types of attacks, best practices including description. Then network security devices and their subfunctions will be introduced. Finally, the user will understand what perception user experience is, how it is measured, the difference between soft and hard errors, and how users formulate quality of experience. },
  doi       = {https://doi.org/10.1016/B978-0-12-803584-9.00001-9},
  keywords  = {attack, DDoS, malware, penetration testing, volumetric attack, quality of experience (QoE), perceptual user experience, firewall, IPS/IDS, proxy server, botnet, cross site scripting attack (XSS), worm, virus, trojan horse attack, zero-day attack, SQL injection attack, hard QoE errors, soft QoE errors},
  url       = {https://www.sciencedirect.com/science/article/pii/B9780128035849000019},
}

@Article{Beriro2012,
  author  = {Darren J. Beriro and Robert J. Abrahart and C. Paul Nathanail},
  title   = {Comments on “Empirical modelling of plate load test moduli of soil via gene expression programming” by Ali Mollahasani, Amir Hossein Alavi and Amir Hossein Gandomi [Computers and Geotechnics 38 (2011) 281–286]},
  journal = {Computers and Geotechnics},
  year    = {2012},
  volume  = {39},
  pages   = {75 - 78},
  issn    = {0266-352X},
  doi     = {https://doi.org/10.1016/j.compgeo.2011.08.012},
  url     = {https://www.sciencedirect.com/science/article/pii/S0266352X11001431},
}

@Article{Mollahasani2012,
  author  = {Ali Mollahasani and Amir Hossein Alavi and Amir Hossein Gandomi},
  title   = {Reply to Comments on “Empirical modelling of plate load test moduli of soil via gene expression programming” by Ali Mollahasani, Amir Hossein Alavi, Amir Hossein Gandomi [Computers and Geotechnics 38 (2011) 281–286]},
  journal = {Computers and Geotechnics},
  year    = {2012},
  volume  = {39},
  pages   = {73 - 74},
  issn    = {0266-352X},
  doi     = {https://doi.org/10.1016/j.compgeo.2011.08.009},
  url     = {https://www.sciencedirect.com/science/article/pii/S0266352X11001406},
}

@Article{Bortolan2015,
  author   = {G. Bortolan and I. Christov and I. Simova and I. Dotsinsky},
  title    = {Noise processing in exercise \{ECG\} stress test for the analysis and the clinical characterization of \{QRS\} and T wave alternans},
  journal  = {Biomedical Signal Processing and Control},
  year     = {2015},
  volume   = {18},
  pages    = {378 - 385},
  issn     = {1746-8094},
  abstract = {Abstract The aim of this study is to analyze different sources of noise in \{ECG\} recordings from stress tests in order to obtain reliable parameters and measurements for the analysis of T-wave and QRS-complex alternans (TWA &amp; QRSA). Simple methods for eliminating common sources of noise like power-line interference, baseline drift and electromyographic noise were used. The pre-processing phase considered the detection of steep slope/spike, low amplitude signal, and flat line or missing lead artefacts. The detection of \{TWA\} and \{QRSA\} was based on Principal Component Analysis indices and wave amplitudes considering all the leads. A particular database of 106 \{ECG\} records during stress testing was considered. The signal quality analysis performed in this study has permitted to obtain reliable and noise-tolerant measurements of \{TWA\} and \{QRSA\} indices. The different diagnostic groups were used for the evaluation of the clinical significance of the alternans. Men have significantly higher values of \{QRSA\} than women. Smokers have significantly higher \{TWA\} values as compared with non-smokers. Significant negative correlation was obtained between age and both \{TWA\} and QRSA. Correlations between \{TWA\} and \{QRSA\} and the double product of arterial hypertension and the maximal heart rate during the stress test were statistically significant, positive and relatively strong. },
  doi      = {https://doi.org/10.1016/j.bspc.2015.02.003},
  keywords = {Signal filtering, Noise suppression, Principal Component Analysis, ECG stress test, Alternans},
  url      = {https://www.sciencedirect.com/science/article/pii/S1746809415000154},
}

@Article{Glavanovics2007,
  author   = {Michael Glavanovics and Helmut Köck and Vladimir Košel and Tobias Smorodin},
  title    = {Flexible active cycle stress testing of smart power switches},
  journal  = {Microelectronics Reliability},
  year     = {2007},
  volume   = {47},
  number   = {9–11},
  pages    = {1790 - 1794},
  issn     = {0026-2714},
  note     = {18th European Symposium on Reliability of Electron Devices, Failure Physics and Analysis},
  abstract = {Active cycle stress testing of smart power switches is conventionally performed either with current pulses of constant amplitude or with waveforms derived by switching inductive loads. A flexible test system is introduced that is capable of generating arbitrary current pulse shapes, which is verified experimentally on a typical smart power switch. It is demonstrated by a test run that pulses with different shape and amplitude but equal thermal stress derived from thermal simulation lead to comparable cycle life time. },
  doi      = {https://doi.org/10.1016/j.microrel.2007.07.065},
  url      = {https://www.sciencedirect.com/science/article/pii/S0026271407003216},
}

@Article{Chen2012,
  author   = {C.H. Chen and M.Y. Tsai},
  title    = {Strength determination of high-power \{LED\} die using point-load and line-load tests},
  journal  = {Microelectronics Reliability},
  year     = {2012},
  volume   = {52},
  number   = {5},
  pages    = {822 - 829},
  issn     = {0026-2714},
  note     = {Reliability of High-Power \{LED\} Packaging and Assembly},
  abstract = {The strength of high-power light emitting diode (LED) dies, cut from wafers with a laser, has to be determined for the need of design and quality control in order to assure the good reliability of packages in manufacturing and service. The objective of this study is to determine the strength of high-power \{LED\} die with a size of 1 × 1 × 0.1 mm3 by point-load test (PLT) and line-load test (LLT) associated with a plate-on-elastic-foundation configuration. \{ANSYS\} (one of commercial finite element codes) analysis is used to calculate the stress distributions of the die under both \{PLT\} and LLT. The \{ANSYS\} models of the \{PLT\} and \{LLT\} are validated by comparing with experimental force–displacement curves, and the results are further used to convert the die failure force from the tests into the die strength. The mechanism of tensile-stress dominated die strength has been discussed and validated in detail via these test results and analyses. The results of the \{PLT\} and \{LLT\} also indicate that for the die failure on chip surface, the average die strengths are about 1.44 \{GPa\} and 1.52 \{GPa\} from the \{PLTs\} with two different-radius pins, and about 1.2 \{GPa\} from the LLT. On the other hand, for failures on sapphire surface, the average die strengths are reasonably about 1.49 \{GPa\} and 1.26 \{GPa\} from the two PLTs, but the average one from the \{LLT\} is about 0.64 \{GPa\} (with less than 50% of the values from the PLT). The inconsistent data between two \{PLT\} and \{LLT\} for failure on sapphire surfaces were found to result from the edge chipping of the die specimen observed by scanning electron microscopy. It was also observed that the thin-layer GaN material has to be taken into account in the \{ANSYS\} analyses with a bi-material model of the \{LED\} die for precisely determining the die strength for failure on the chip surface. Otherwise, these strength data would be overestimated by a few tens of percent with a uni-material model of the \{LED\} die. All in all, this study has successfully demonstrated that the \{LED\} die strength can be determined by these feasible, easy-to-use and reliable test methods. },
  doi      = {https://doi.org/10.1016/j.microrel.2011.06.028},
  url      = {https://www.sciencedirect.com/science/article/pii/S0026271411002277},
}

@InCollection{Olexa2005,
  author    = {Ron Olexa},
  title     = {Chapter 8 - Network Performance Testing and Troubleshooting},
  booktitle = {Implementing 802.11, 802.16, and 802.20 Wireless Networks},
  publisher = {Newnes},
  year      = {2005},
  editor    = {Olexa, Ron},
  pages     = {213 - 222},
  address   = {Burlington},
  isbn      = {978-0-7506-7808-7},
  abstract  = {Publisher Summary Radio frequency related network problems manifest themselves in numerous ways. The connection to the network may be unstable, the connection speed may be slow, the user may notice slow response to network queries, or there may be noticeable “holes” in the desired coverage area. The most common cause of such problems is low signal-to-noise ratio (SNR). This can be caused by too much path attenuation, higher than expected interference levels, or the result of impaired antenna systems or failing hardware. Another cause is client “bouncing,” which is the tendency for a client at the edge of coverage of two or more base stations to bounce from base station to base station in search of better signal strength. This is the result of low \{SNR\} coupled with the search threshold levels set in the client. This problem is quite common in 802.11 systems but may not be a problem in more complex solutions. },
  doi       = {https://doi.org/10.1016/B978-075067808-7/50010-9},
  url       = {https://www.sciencedirect.com/science/article/pii/B9780750678087500109},
}

@Article{Hernandez2007,
  author   = {Wilmar Hernandez},
  title    = {Optimal estimation of the relevant information coming from a variable reluctance proximity sensor placed in a car undergoing performance tests},
  journal  = {Mechanical Systems and Signal Processing},
  year     = {2007},
  volume   = {21},
  number   = {7},
  pages    = {2732 - 2739},
  issn     = {0888-3270},
  abstract = {Today's automotive industry has a soaring interest in efficient, reliable and robust sensors able to make intelligent driving decisions that can save millions of lives every year. To that end, the sensors used in today's cars are being provided with microprocessors and application-specific integrated circuit technologies that incorporate a certain amount of intelligence into the sensors themselves. In this paper, an inverse square-root adaptive filtering algorithm for recursive least-squares estimation (QR-RLS) is used to improve the response of a wheel speed sensor placed in a car undergoing performance tests. Such an algorithm is used to carry out an optimal estimation of the relevant signal coming from the sensor, which is buried in a broad-band noise background where we have little knowledge of the noise characteristics. The results of the experiment are satisfactory, a significant improvement of 32.5 dB in the signal-to-noise ratio at the QR-RLS adaptive filter output was achieved. Also, in order to compare classical filtering techniques with optimal adaptive filtering techniques, the signal coming from the wheel speed sensor was also filtered by using a second-order lowpass digital Butterworth filter. The results of comparing the aforementioned filters show that the optimal adaptive filter is superior to the classical filter. },
  doi      = {https://doi.org/10.1016/j.ymssp.2007.02.005},
  keywords = {Wheel speed sensor, Adaptive noise canceller, Inverse QR-RLS adaptive filter},
  url      = {https://www.sciencedirect.com/science/article/pii/S0888327007000362},
}

@Article{Helou2002,
  author   = {Charles Hélou and Rachida Dssouli and Teodor-Gabriel Crainic},
  title    = {Performance testing of a negotiation platform},
  journal  = {Information and Software Technology},
  year     = {2002},
  volume   = {44},
  number   = {5},
  pages    = {313 - 330},
  issn     = {0950-5849},
  abstract = {Accessible from all over the world, the \{EC\} became an indispensable element to our society. It allows the use of electronic systems to exchange products, services and information between the different existent users. During these exchanges, it is very important to assure a good quality of service. However, the enormous expansion of the Internet users push its resources to the maximum of its limits, which provoke, in many cases, an important degradation in its performance. Consequently, it is primordial to analyze the capacity of servers in order to handle heavy workloads that are growing considerably as a function of the number of users. It is, therefore, necessary to conduct performance tests before servers' deployment in order to detect any imperfection and predict their behavior under stress. In this context, this paper present a simplified performance evaluation of the “alpha” version of a negotiation platform called Generic Negotiation Platform (GNP) dated on September 2000. This platform is still under development. Many performance factors could be examined in this evaluation. However, we considered only the response time factor because of its important impact on auctions and negotiations applications. We mostly oriented this study to give us an idea about the variation of the average response time of the server as a function of the number of users and the type of different transactions. We also tried to evaluate the effect of the auctions' rules on the server average response time. We limited our study to the close and open auctions at the second price. This study followed the traditional way of doing performance tests. Therefore, we fixed our test objectives and criterion and then create our own scripts. Once the nature of the workload of the server was specified, we created an adequate benchmark to generate requests to the server. Afterwards, the average response time of each considered transaction was collected. In order to interpret these results properly, we calculated the standard deviation and the coefficient of variation of each set of values. },
  doi      = {https://doi.org/10.1016/S0950-5849(01)00215-4},
  url      = {https://www.sciencedirect.com/science/article/pii/S0950584901002154},
}

@Article{Mollahasani2011,
  author   = {Ali Mollahasani and Amir Hossein Alavi and Amir Hossein Gandomi},
  title    = {Empirical modeling of plate load test moduli of soil via gene expression programming},
  journal  = {Computers and Geotechnics},
  year     = {2011},
  volume   = {38},
  number   = {2},
  pages    = {281 - 286},
  issn     = {0266-352X},
  abstract = {New empirical models were developed to predict the soil deformation moduli using gene expression programming (GEP). The principal soil deformation parameters formulated were secant (Es) and reloading (Er) moduli. The proposed models relate Es and Er obtained from plate load-settlement curves to the basic soil physical properties. The best \{GEP\} models were selected after developing and controlling several models with different combinations of the influencing parameters. The experimental database used for developing the models was established upon a series of plate load tests conducted on different soil types at depths of 1–24 m. To verify the applicability of the derived models, they were employed to estimate the soil moduli of a part of test results that were not included in the analysis. The external validation of the models was further verified using several statistical criteria recommended by researchers. A sensitivity analysis was carried out to determine the contributions of the parameters affecting Es and Er. The proposed models give precise estimates of the soil deformation moduli. The Es prediction model provides considerably better results in comparison with the model developed for Er. The simplified formulation for Es significantly outperforms the empirical equations found in the literature. The derived models can reliably be employed for pre-design purposes. },
  doi      = {https://doi.org/10.1016/j.compgeo.2010.11.008},
  keywords = {Soil deformation moduli, Soil physical properties, Gene expression programming, Nonlinear modeling},
  url      = {https://www.sciencedirect.com/science/article/pii/S0266352X1000162X},
}

@InCollection{Gerteisen1995,
  author    = {Edgar A. Gerteisen and Antony Jameson},
  title     = {Massive parallel implementation of the aircraft euler method and performance tests on different computational platforms},
  booktitle = {Parallel Computational Fluid Dynamics 1993},
  publisher = {North-Holland},
  year      = {1995},
  editor    = {Ecer, A. and Hauser, J. and Leca, P. and Periaux, J.},
  pages     = {277 - 285},
  address   = {Amsterdam},
  isbn      = {978-0-444-81999-4},
  abstract  = {Publisher Summary The aircraft Euler method, so-called airplane code, is a finite element based technique for solving the Euler equations combined with a method for constructing tetrahedral meshes. The attractiveness of an unstructured approach along with the demand of shortened turnaround times motivates a massively parallel implementation. The numerical method of airplane code and the guidelines for the parallelization strategy are outlined in this chapter. Performance results of the method have been carried out considering different massively parallel computational platforms, which demonstrate the portability of the current implementation. The results indicate that an efficient communication network is most crucial for parallel computing, especially with respect to scalability. The communication speed as well as the interconnection topology will be more important for modern parallel systems, which are based on latest processor technologies. This statement, however, refers to more or less communication intense algorithms well-known in computational fluid dynamics and may be totally different for other kind of scientific applications. },
  doi       = {https://doi.org/10.1016/B978-044481999-4/50159-6},
  url       = {https://www.sciencedirect.com/science/article/pii/B9780444819994501596},
}

@Article{Rao1994,
  author   = {S.U.M. Rao},
  title    = {Reliability physics of electronic devices through material characterization and environmental stress testing techniques},
  journal  = {Microelectronics Reliability},
  year     = {1994},
  volume   = {34},
  number   = {2},
  pages    = {229 - 245},
  issn     = {0026-2714},
  abstract = {This paper describes the approach of reliability physics to develop and produce electronic devices with an acceptable yield and reliability. The importance of material characterization techniques for process monitoring and product failure analysis is discussed. The potential and significance of environmental stress testing which has established as a distinct technique is explained. The technique is used to understand wear-out (Defect) failure mechanism and for reliability prediction. As can be seen that reliability physics acts as a ‘Midwife’ for the development of better or new device and/or technology with desired reliability level. },
  doi      = {https://doi.org/10.1016/0026-2714(94)90105-8},
  url      = {https://www.sciencedirect.com/science/article/pii/0026271494901058},
}

@Article{Cividini2011,
  author   = {Annamaria Cividini and Livio Locatelli and Alessio Contini and Giancarlo Gioda},
  title    = {A numerical interpretation of load tests on vibro-piles},
  journal  = {Computers and Geotechnics},
  year     = {2011},
  volume   = {38},
  number   = {2},
  pages    = {287 - 297},
  issn     = {0266-352X},
  abstract = {The finite element interpretation is discussed of two load tests carried out on instrumented vibro-piles in a granular deposit. A first back analysis, aimed at assessing the improvement of the mechanical characteristics of soil induced by the vibratory construction process, highlights an apparent contradiction between the experimental variation of the axial load along the pile and the numerical results. This suggests introducing as a free variable, in addition to the elastic and shear strength parameters of the granular soil, also the increase of the nominal diameter of pile caused by vibrations. The second back analysis provides some insight into the variation of the diameter with depth and leads to an acceptable interpretation, from the engineering standpoint, of the load tests. On these bases a quantitative comparison is presented between the calculated load–settlement diagram of the vibro-pile and that of a “standard” pile constructed without vibrations in the same granular deposit. },
  doi      = {https://doi.org/10.1016/j.compgeo.2010.11.009},
  keywords = {Load–settlement data, Piles, Granular soil, Finite element analyses},
  url      = {https://www.sciencedirect.com/science/article/pii/S0266352X10001631},
}

@Article{Everett2011,
  author   = {Cath Everett},
  title    = {Stress-testing Europe's critical infrastructure},
  journal  = {Computer Fraud \& Security},
  year     = {2011},
  volume   = {2011},
  number   = {7},
  pages    = {5 - 7},
  issn     = {1361-3723},
  abstract = {Opinion is currently divided over whether the first pan-European test centering on the protection of critical national infrastructure is likely to lead to the introduction of new legislation in the area. Europe's first test of whether it could cope with a massive cyber-attack generated some useful lessons. The aim was to understand how well participating member states could collaborate to counter 320 simulated attempts by hackers to paralyse the Internet. However, the exercise also raised questions over whether more legislation might be required to ensure that organisations in both the public and private sector are able to co-operate more effectively. And it highlighted the need for the private sector – not involved in the exercise – to get involved directly in national cyber-security, as Cath Everett discovers. },
  doi      = {https://doi.org/10.1016/S1361-3723(11)70071-9},
  url      = {https://www.sciencedirect.com/science/article/pii/S1361372311700719},
}

@Article{Cramer2006,
  author   = {Michael Cramer},
  title    = {The \{ADS40\} Vaihingen/Enz geometric performance test},
  journal  = {\{ISPRS\} Journal of Photogrammetry and Remote Sensing},
  year     = {2006},
  volume   = {60},
  number   = {6},
  pages    = {363 - 374},
  issn     = {0924-2716},
  note     = {Digital Aerial Cameras},
  abstract = {This paper presents the main results of a comprehensive \{ADS40\} performance analysis conducted at the Vaihingen/Enz test field. As such it represents one example of an independent in-flight performance study for one of the new and commercially operational digital airborne camera systems. Based on a large number of well coordinated and defined object points, which served as independent check points, the absolute geometric accuracy of the \{ADS40\} from true operational data has been verified. Empirical analysis of data from flying heights ranging from 1500 m to 4000 m proved the \{ADS40\} geometric accuracy to be in the range of 1–2 μm at image scale for horizontal coordinates and 0.03–0.05‰ of the flying height for vertical components. This is fully within specification for airborne imaging. },
  doi      = {https://doi.org/10.1016/j.isprsjprs.2006.05.004},
  keywords = {ADS40, push-broom, georeferencing, performance, GPS/inertial},
  url      = {https://www.sciencedirect.com/science/article/pii/S0924271606000578},
}

@Article{McGenn2012,
  author   = {William McGenn and Michael J. Uren and Johannes Benedikt and Paul J. Tasker},
  title    = {Development of an \{RF\} \{IV\} waveform based stress test procedure for use on GaN \{HFETs\}},
  journal  = {Microelectronics Reliability},
  year     = {2012},
  volume   = {52},
  number   = {12},
  pages    = {2880 - 2883},
  issn     = {0026-2714},
  note     = {27th \{JEDEC\} Reliability Of Compound Semiconductors Workshop (ROCS 2012)},
  abstract = {This paper reports on the development of an \{RF\} \{IV\} waveform based stress test procedure. \{DC\} and low-voltage \{RF\} characterisation was carried out before and after high power \{RF\} stress. \{RF\} waveform measurements showed that the exact change in the \{RF\} load line induced during \{RF\} degradation cannot be directly inferred from the \{DC\} or low power \{RF\} measurement. The \{RF\} degradation takes the form of a knee-walkout, a small pinch-off shift consistent with charge trapping and defect generation, and in addition gate leakage occurs once the \{RF\} voltage exceeds a critical voltage. },
  doi      = {https://doi.org/10.1016/j.microrel.2012.09.007},
  url      = {https://www.sciencedirect.com/science/article/pii/S0026271412004490},
}

@Article{Basu2011,
  author   = {Sanjay Basu},
  title    = {Comparing simulation models for market risk stress testing},
  journal  = {European Journal of Operational Research},
  year     = {2011},
  volume   = {213},
  number   = {1},
  pages    = {329 - 339},
  issn     = {0377-2217},
  abstract = {The subprime crisis has reminded us that effective stress tests should not only combine subjective scenarios with historical data, but also be probabilistic. In this paper, we combine three hypothetical shocks, of varying degrees, with more than six years of daily data on USD-INR and Euro-INR. Our objective is to compare six simulation-based stress models for foreign exchange positions. We find that while volatility-weighted historical simulation is the best model for volatility persistence, jump diffusion based Monte Carlo simulation is better at capturing correlation breakdown. Loss estimates from very fat-tailed distributions are not sensitive to the severity of stress scenarios. },
  doi      = {https://doi.org/10.1016/j.ejor.2011.02.023},
  keywords = {Risk management, Volatility updation, Tail diversification, Simulation models, Fat-tailed distributions},
  url      = {https://www.sciencedirect.com/science/article/pii/S0377221711001780},
}

@Article{Bailon2010,
  author   = {Raquel Bailón and Luca Mainardi and Michele Orini and Leif Sörnmo and Pablo Laguna},
  title    = {Analysis of heart rate variability during exercise stress testing using respiratory information},
  journal  = {Biomedical Signal Processing and Control},
  year     = {2010},
  volume   = {5},
  number   = {4},
  pages    = {299 - 310},
  issn     = {1746-8094},
  abstract = {This paper presents a novel method for the analysis of heart rate variability (HRV) during exercise stress testing enhanced with respiratory information. The instantaneous frequency and power of the low frequency (LF) and high frequency (HF) bands of the \{HRV\} are estimated by parametric decomposition of the instantaneous autocorrelation function (ACF) as a sum of damped sinusoids. The instantaneous \{ACF\} is first windowed and filtered to reduce the cross terms. The inclusion of respiratory information is proposed at different stages of the analysis, namely, the design of the filter applied to the instantaneous ACF, the parametric decomposition, and the definition of a dynamic \{HF\} band. The performance of the method is evaluated on simulated data as well as on a stress testing database. The simulation results show that the inclusion of respiratory information reduces the estimation error of the amplitude of the \{HF\} component from 3.5% to 2.4% in mean and related \{SD\} from 3.0% to 1.7% when a tuned time smoothing window is used at an \{SNR\} of 15 dB. Results from the stress testing database show that information on respiratory frequency produces \{HF\} power estimates which closely resemble those from the simulations which exhibited lower SD. The mean \{SD\} of these estimates with respect to their mean trends is reduced by 84% (from 0.74 × 1 0 − 3 s−2 to 0.12 × 1 0 − 3 s−2). The analysis of \{HRV\} in the stress testing database reveals a significant decrease in the power of both the \{LF\} and \{HF\} components around peak stress. },
  doi      = {https://doi.org/10.1016/j.bspc.2010.05.005},
  keywords = {Heart rate variability, Exercise stress testing, Respiratory frequency, Time–frequency analysis, Parametric decomposition},
  url      = {https://www.sciencedirect.com/science/article/pii/S1746809410000418},
}

@InCollection{Jacob2008,
  author    = {Bruce Jacob and Spencer W. Ng and David T. Wang},
  title     = {\{CHAPTER\} 23 - Performance Testing},
  booktitle = {Memory Systems},
  publisher = {Morgan Kaufmann},
  year      = {2008},
  editor    = {Jacob, Bruce and Ng, Spencer W. and Wang, David T.},
  pages     = {747 - 761},
  address   = {San Francisco},
  isbn      = {978-0-12-379751-3},
  doi       = {https://doi.org/10.1016/B978-012379751-3.50025-4},
  url       = {https://www.sciencedirect.com/science/article/pii/B9780123797513500254},
}

@Article{Rodrigues2013,
  author   = {Eugénio Rodrigues and Adélio Rodrigues Gaspar and Álvaro Gomes},
  title    = {An evolutionary strategy enhanced with a local search technique for the space allocation problem in architecture, Part 2: Validation and performance tests},
  journal  = {Computer-Aided Design},
  year     = {2013},
  volume   = {45},
  number   = {5},
  pages    = {898 - 910},
  issn     = {0010-4485},
  abstract = {The first part of this paper proposed a hybrid evolutionary technique which helps architects to generate sets of floor plans in the early design stage. The algorithm is an enhanced Evolutionary Strategy (ES) with a Stochastic Hill Climbing (SHC) technique. In this second part, the validity and performance of the technique is examined. Four tests are conducted. Three validation tests are used to determine the ability of the algorithm to replicate a floor plan made by an architect; the ability to produce a set of different floor plan designs by comparing the results with a well-known enumerated floor plan solution; its capability to work with less constrained problems, and to control the variation in the floor plan form with different compactness evaluators’ weights. The last test determines the evolving behavior, the breakdown of the evaluators’ performance for the objective function, and the robustness of the algorithm. The methodologies used in the tests and the problem specifications are presented. Results and observations on the evaluators’ weights and their importance and the limitations of the technique are analyzed and discussed. Finally, the conclusion to this part of the paper is made. },
  doi      = {https://doi.org/10.1016/j.cad.2013.01.003},
  keywords = {Evolutionary strategy, Stochastic hill climbing, Space allocation problem, Space planning},
  url      = {https://www.sciencedirect.com/science/article/pii/S0010448513000055},
}

@Article{Shen2001,
  author   = {Yin-Lin Shen and Sung-Ho Moon},
  title    = {Investigation of point-to-point performance test of touch trigger probes on coordinate-measuring machines},
  journal  = {Robotics and Computer-Integrated Manufacturing},
  year     = {2001},
  volume   = {17},
  number   = {3},
  pages    = {247 - 254},
  issn     = {0736-5845},
  abstract = {A major factor contributing to the total measuring error of coordinate measuring machines (CMMs) is the performance of the probing sub-system. Probing test methods are typically used to detect errors due to the probing sub-system. The probe performance evaluation method specified in the \{ANSI\} \{B89\} standard is investigated in this paper. The sampling plan associated in the probe performance evaluation was tested by using experimental probing data from a CMM. Research findings indicate that the performance of touch trigger probes is overestimated due to a systematic bias in the vertical direction of the best-fit reference ball center in the probe performance test. A two-latitude sampling plan synthesis method based on a pretravel model for touch trigger probes is proposed in this paper. The proposed method can be used to accurately identify the reference ball center in the performance test of touch trigger probes. },
  doi      = {https://doi.org/10.1016/S0736-5845(00)00056-9},
  keywords = {Probe performance test, Sampling plan, Pretravel error},
  url      = {https://www.sciencedirect.com/science/article/pii/S0736584500000569},
}

@Article{Babaoglu2009,
  author   = {Ismail Babaoglu and Omer Kaan Baykan and Nazif Aygul and Kurtulus Ozdemir and Mehmet Bayrak},
  title    = {Assessment of exercise stress testing with artificial neural network in determining coronary artery disease and predicting lesion localization},
  journal  = {Expert Systems with Applications},
  year     = {2009},
  volume   = {36},
  number   = {2, Part 1},
  pages    = {2562 - 2566},
  issn     = {0957-4174},
  abstract = {The aim of this study is to show the artificial neural network (ANN) on determination of coronary artery disease existence and localization of lesion based upon exercise stress testing (EST) data. \{EST\} and coronary angiography were performed on 330 patients. The data studied acquiring 27 verifying features was normalized employing z-score method. To select training and test data, 10-fold cross-validation methods were involved and multi-layered perceptron neural network was employed for the classification. The interpretation of \{EST\} using \{ANN\} proved 91%, 73% and 65% diagnostic accuracy for the left main coronary (LMCA), left anterior descending and left circumflex coronary arteries, respectively. Besides, 69% for the right coronary artery is also predicted. For the LMCA, a 94% negative predictive value (NPV) was obtained. This high percentage of \{NPV\} encourages the elimination of \{LMCA\} lesions. Some knowledge can also be obtained about lesion localization, besides diagnosing of coronary artery disease by the assessment of \{EST\} via ANN. },
  doi      = {https://doi.org/10.1016/j.eswa.2007.11.013},
  keywords = {Artificial neural networks, Exercise stress testing, Coronary artery disease},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417407005611},
}

@Article{Comodromos2003,
  author   = {Emilios M. Comodromos and Christos T. Anagnostopoulos and Michael K. Georgiadis},
  title    = {Numerical assessment of axial pile group response based on load test},
  journal  = {Computers and Geotechnics},
  year     = {2003},
  volume   = {30},
  number   = {6},
  pages    = {505 - 515},
  issn     = {0266-352X},
  abstract = {Axial pile load tests are considered within the design procedure of most major construction projects that include pile foundations, aiming to determine both the ultimate bearing capacity and the pile stiffness at working load level. Commonly used pile spacings of 3–4 pile diameters between the test pile and the reaction piles cause significant interaction with drastic effect on to the load-settlement relationship. The objective of this paper is to evaluate the influence of this interaction on both bearing capacity and stiffness of single piles and pile groups. For this purpose, a back analysis of a pile load test was initially performed which facilitated the determination of the single pile response and the verification of the soil properties. Subsequently, a numerical analysis was carried out to establish load-displacement relationships for several different layouts of pile groups. Based on these non-linear analyses the effect of the interaction was quantified for both the pile load test and pile group layouts examined. },
  doi      = {https://doi.org/10.1016/S0266-352X(03)00017-X},
  keywords = {Pile groups, Pile tests numerical analysis, Non-linear soil–pile interaction},
  url      = {https://www.sciencedirect.com/science/article/pii/S0266352X0300017X},
}

@Article{Robertson1993,
  author  = {Bernard Robertson and David Pullen},
  title   = {It security testing, a practical guide — part 5: Security stress/loading testing},
  journal = {Computer Audit Update},
  year    = {1993},
  volume  = {1993},
  number  = {3},
  pages   = {7 - 10},
  issn    = {0960-2593},
  doi     = {https://doi.org/10.1016/0960-2593(93)90041-X},
  url     = {https://www.sciencedirect.com/science/article/pii/096025939390041X},
}

@Article{Bosc2000,
  author   = {J.M Bosc and P Dupuy and J Gil and J.M Dorkel and G Sarrabayrouse},
  title    = {Thermal characterization of \{LDMOS\} transistors for accelerating stress testing},
  journal  = {Microelectronics Journal},
  year     = {2000},
  volume   = {31},
  number   = {9–10},
  pages    = {747 - 752},
  issn     = {0026-2692},
  abstract = {The time to market is a major concern in the high-technology industry and when designing new products, the development cycle time becomes critical. Indeed, when a delay occurs in the development schedule, the potential market share of the designed product can be drastically decreased. In this context, developing accelerated stress testing (AST) in order to assess quickly the long-term behavior of a semiconductor becomes extremely useful. In this paper we show an example of how thermal characterization including simulation can be used to define a consistent \{AST\} for power ICs. },
  doi      = {https://doi.org/10.1016/S0026-2692(00)00054-9},
  keywords = {Semiconductor industry, Multi-pulse testing, Energy pulse characterization},
  url      = {https://www.sciencedirect.com/science/article/pii/S0026269200000549},
}

@Article{1996,
  title   = {Environmental stress testing experiment using the Taguchi method : \{DENNIS\} E. PACHUCKI. \{IEEE\} Transactions on Components, Packaging, and Manufacturing Technology, Part A, 18(1), 3 (March 1995)},
  journal = {Microelectronics Reliability},
  year    = {1996},
  volume  = {36},
  number  = {4},
  pages   = {537 -},
  issn    = {0026-2714},
  doi     = {https://doi.org/10.1016/0026-2714(96)84390-3},
  key     = {tagkey1996537},
  url     = {https://www.sciencedirect.com/science/article/pii/0026271496843903},
}

@Article{1984,
  title   = {Probablistic models for proof load testing: Grigoriu, M and Hall, W B J. Struct. Division ASCE, Vol 110 No 2 (February 1984) pp 260–274},
  journal = {Computer-Aided Design},
  year    = {1984},
  volume  = {16},
  number  = {3},
  pages   = {177 -},
  issn    = {0010-4485},
  doi     = {https://doi.org/10.1016/0010-4485(84)90046-0},
  key     = {tagkey1984177},
  url     = {https://www.sciencedirect.com/science/article/pii/0010448584900460},
}

@Article{1996a,
  title   = {The benefits of stress testing : H. \{ANTHONY\} CHAN. \{IEEE\} Transactions on Components, Packaging and Manufacturing Technology, Part A, 18(1), 23 (March 1995)},
  journal = {Microelectronics Reliability},
  year    = {1996},
  volume  = {36},
  number  = {4},
  pages   = {543 -},
  issn    = {0026-2714},
  doi     = {https://doi.org/10.1016/0026-2714(96)84419-2},
  key     = {tagkey1996543},
  url     = {https://www.sciencedirect.com/science/article/pii/0026271496844192},
}

@Article{1994,
  title   = {Performance testing of cellular modems : Mike Mukund and Fred Mohajer. Test and Measurement World, 63 (January 1993)},
  journal = {Microelectronics Reliability},
  year    = {1994},
  volume  = {34},
  number  = {8},
  pages   = {1426 -},
  issn    = {0026-2714},
  doi     = {https://doi.org/10.1016/0026-2714(94)90255-0},
  key     = {tagkey19941426},
  url     = {https://www.sciencedirect.com/science/article/pii/0026271494902550},
}

@Article{1994a,
  title   = {A study of failures identified during board level environmental stress testing : T. Paul Parker and Cathy W. Webb. \{IEEE\} Transactions on Components, Hybrids, and Manufacturing Technology, 15(6), 1086 (1992)},
  journal = {Microelectronics Reliability},
  year    = {1994},
  volume  = {34},
  number  = {8},
  pages   = {1422 -},
  issn    = {0026-2714},
  doi     = {https://doi.org/10.1016/0026-2714(94)90238-0},
  key     = {tagkey19941422},
  url     = {https://www.sciencedirect.com/science/article/pii/0026271494902380},
}

@Article{Pryor1974,
  author  = {T.Allan Pryor and J.Douglas Ridges},
  title   = {A computer program for stress test data processing},
  journal = {Computers and Biomedical Research},
  year    = {1974},
  volume  = {7},
  number  = {4},
  pages   = {360 - 368},
  issn    = {0010-4809},
  doi     = {https://doi.org/10.1016/0010-4809(74)90012-3},
  url     = {https://www.sciencedirect.com/science/article/pii/0010480974900123},
}

@Article{McCallum1986,
  author   = {John C McCallum},
  title    = {Benchmark results for microcomputers and large computers: Performance tests on \{IBM\} and \{DEC\} Vax},
  journal  = {Data Processing},
  year     = {1986},
  volume   = {28},
  number   = {8},
  pages    = {426 - 433},
  issn     = {0011-684X},
  abstract = {Three commonly used benchmark programs: the Whetsone, the Dhrystone, and the Sieve, were run on an \{IBM\} PC, an \{IBM\} PC/AT, a Vax 11/785 and a Vax 8600 computer. The results show very large differences in performances predicted by the different benchmarks. },
  doi      = {https://doi.org/10.1016/0011-684X(86)90426-0},
  keywords = {data processing, benchmarks, microcomputers, computer performance},
  url      = {https://www.sciencedirect.com/science/article/pii/0011684X86904260},
}

@Article{1991,
  title   = {Job related physical performance tests : Purswell, J.L., Ratliff, R., and Hughes, A. In: B. Das (Ed), Advances in industrial ergonomics and safety — II, Taylor \&amp; Francis, London, 1990, pp 453–459, 14 refs},
  journal = {Applied Ergonomics},
  year    = {1991},
  volume  = {22},
  number  = {4},
  pages   = {278 -},
  issn    = {0003-6870},
  doi     = {https://doi.org/10.1016/0003-6870(91)90275-M},
  key     = {tagkey1991278},
  url     = {https://www.sciencedirect.com/science/article/pii/000368709190275M},
}

@Article{1982,
  title   = {Highly accelerated temperature and humidity stress test technique (HAST)},
  journal = {Microelectronics Reliability},
  year    = {1982},
  volume  = {22},
  number  = {6},
  pages   = {1186 -},
  issn    = {0026-2714},
  doi     = {https://doi.org/10.1016/S0026-2714(82)80601-X},
  key     = {tagkey19821186},
  url     = {https://www.sciencedirect.com/science/article/pii/S002627148280601X},
}

@Article{Dillon1981,
  author   = {Jane Dillon},
  title    = {The role of ergonomics in the development of performance tests for furniture},
  journal  = {Applied Ergonomics},
  year     = {1981},
  volume   = {12},
  number   = {3},
  pages    = {169 - 175},
  issn     = {0003-6870},
  abstract = {The development of realistic performance tests for furniture has been the subject of a continuing research programme. Such tests are necessary to ensure that furniture is both durable and safe to use: This paper discusses the general philosophy that tests should be based on the actual use to which furniture is likely to be subjected. The forces which act on a piece of furniture may be conveniently divided into two categories — functional and non-functional. The former occurs when the activity is one for which the furniture was designed, while non-functional use covers misuse for which the furniture was not specifically intended but which inevitably occurs and which must be considered in its design. The success of performance tests depends largely on the reproduction of service loads and ergonomics has played an important role in the recording and measuring of human behaviour in relation to different types of furniture. This has led to the development of test rigs to reproduce loads occuring in practice. A number of examples are discussed. The comparison of results obtained from these tests with the performance of furniture in everyday use has shown that the tests do adequately reproduce the type of failure which is likely to occur in practice. },
  doi      = {https://doi.org/10.1016/0003-6870(81)90006-5},
  url      = {https://www.sciencedirect.com/science/article/pii/0003687081900065},
}

@Article{Groocock1963,
  author   = {J.M. Groocock},
  title    = {Accelerated life testing and over-stress testing of transistors},
  journal  = {Microelectronics Reliability},
  year     = {1963},
  volume   = {2},
  number   = {3},
  pages    = {191 - 204},
  issn     = {0026-2714},
  abstract = {The advantages and disadvantages of accelerated life tests compared with conventional life tests are discussed and the methods by which accelerated life tests are used are examined. The physical basis of accelerated life tests in reaction kinetics is described and the methods by which the Arrhenius equation and the Eyring equation can be used to relate time to failure and temperature are discussed. On the basis of the Arrhenius equation and using the log normal failure distribution the results of temperature storage accelerated life tests on germanium alloy transistors are used to make predictions about life behaviour at lower temperatures. These predictions are compared with the results of long-term life tests on several hundred transistors extending to 20,000 hr. The results are then used to compare constant stress and step stress accelerated life tests. Electrical over-stress tests are described in which germanium alloy transistors are subjected to very high power pulses of short duration and silicon planar transistors have high currents passed through their emitter junctions in the reverse direction. Mechanical over-stress tests are exemplified by centrifuge tests on germanium alloy transistors. It is shown for one transistor type that the failure distribution, although in all cases normal, is markedly dependent upon the direction of stress. },
  doi      = {https://doi.org/10.1016/0026-2714(63)90004-0},
  url      = {https://www.sciencedirect.com/science/article/pii/0026271463900040},
}

@Article{1992,
  title   = {Advances in industrial ergonomics and safety \{III\} : Purswell, J L, McCauley, P Merrick C ‘Job related physical performance tests for firefighters’ in Karwowski, W and Yates, J W (eds) Taylor \&amp; Francis, London (1991) pp 499–504 (10 refs)},
  journal = {Applied Ergonomics},
  year    = {1992},
  volume  = {23},
  number  = {5},
  pages   = {357 -},
  issn    = {0003-6870},
  doi     = {https://doi.org/10.1016/0003-6870(92)90345-V},
  key     = {tagkey1992357},
  url     = {https://www.sciencedirect.com/science/article/pii/000368709290345V},
}

@Article{1984a,
  title   = {All change for the pound. Human performance tests with different versions of the proposed \{UK\} One Pound coin : Bruce, V., et alErgonomics, 1983, 26.3, 215–227},
  journal = {Applied Ergonomics},
  year    = {1984},
  volume  = {15},
  number  = {3},
  pages   = {231 -},
  issn    = {0003-6870},
  doi     = {https://doi.org/10.1016/0003-6870(84)90089-9},
  key     = {tagkey1984231},
  url     = {https://www.sciencedirect.com/science/article/pii/0003687084900899},
}

@Article{1984b,
  title   = {Mo-gate \{MOS\} devices stability under long-term positive bias-temperature stressing test : Tadatoshi Nozaki, Hidekazu Okabayashi and Kohei Higuchi. \{IEEE\} 21st Ann. Proc. Reliab. Phys. 178 (1983)},
  journal = {Microelectronics Reliability},
  year    = {1984},
  volume  = {24},
  number  = {3},
  pages   = {585 -},
  issn    = {0026-2714},
  doi     = {https://doi.org/10.1016/0026-2714(84)90505-5},
  key     = {tagkey1984585},
  url     = {https://www.sciencedirect.com/science/article/pii/0026271484905055},
}

@Article{1983,
  title   = {Accelerated stress testing of terrestrial solar cells : J. W. Lathrop, D. C. Hawkins, J. L. Prince and H. A. Walker. \{IEEE\} Trans. Reliab.R-31 (3), 258 (1982)},
  journal = {Microelectronics Reliability},
  year    = {1983},
  volume  = {23},
  number  = {3},
  pages   = {588 -},
  issn    = {0026-2714},
  doi     = {https://doi.org/10.1016/0026-2714(83)91196-4},
  key     = {tagkey1983588},
  url     = {https://www.sciencedirect.com/science/article/pii/0026271483911964},
}

@Article{1965,
  title   = {A review of step-stress testing : D. S. Peck, Bell Laboratories Record42, 327 (1964)},
  journal = {Microelectronics Reliability},
  year    = {1965},
  volume  = {4},
  number  = {3},
  pages   = {302 -},
  issn    = {0026-2714},
  doi     = {https://doi.org/10.1016/0026-2714(65)90101-0},
  key     = {tagkey1965302},
  url     = {https://www.sciencedirect.com/science/article/pii/0026271465901010},
}

@Article{1969,
  title   = {Physical analysis of stress testing for failure of electronic components : C. F. Kooi, \{IEEE\} Trans. Reliab.R17, June (1968), p. 80},
  journal = {Microelectronics Reliability},
  year    = {1969},
  volume  = {8},
  number  = {3},
  pages   = {250 -},
  issn    = {0026-2714},
  doi     = {https://doi.org/10.1016/0026-2714(69)90039-0},
  key     = {tagkey1969250},
  url     = {https://www.sciencedirect.com/science/article/pii/0026271469900390},
}

@Article{1971,
  title   = {Differential pressure test: A quantitative stress test method for bonded beam-leaded devices : E. J. Boore and D. M. Sutter. Proc. 21st Electronic Components Conf. Washing D.C., U.S.A., 10–12 May (1971), p. 2},
  journal = {Microelectronics Reliability},
  year    = {1971},
  volume  = {10},
  number  = {6},
  pages   = {412 -},
  issn    = {0026-2714},
  doi     = {https://doi.org/10.1016/0026-2714(71)90014-X},
  key     = {tagkey1971412},
  url     = {https://www.sciencedirect.com/science/article/pii/002627147190014X},
}

@Article{Balieu1980,
  author  = {E. Balieu and L. Spindler},
  title   = {Performance testing for improving the level of respiratory protection in a fire brigade : Annals of Occupational Hygiene 1978, 21.4, 351–361.},
  journal = {Applied Ergonomics},
  year    = {1980},
  volume  = {11},
  number  = {2},
  pages   = {111 -},
  issn    = {0003-6870},
  doi     = {https://doi.org/10.1016/0003-6870(80)90222-7},
  url     = {https://www.sciencedirect.com/science/article/pii/0003687080902227},
}

@Article{Cleveland1934,
  author  = {T.K. Cleveland},
  title   = {Loud speakers, theory, performance, testing and design: by N. W. McLachlan, D.Sc. (Engineering), London. 399 pages, illustrations, tables, 16 × 23.5 cms. Oxford, Clarendon Press, 1934},
  journal = {Journal of the Franklin Institute},
  year    = {1934},
  volume  = {218},
  number  = {5},
  pages   = {636 - 637},
  issn    = {0016-0032},
  doi     = {https://doi.org/10.1016/S0016-0032(34)90743-2},
  url     = {https://www.sciencedirect.com/science/article/pii/S0016003234907432},
}

@Conference{Pal2018,
  author          = {Pal, D. and Triyason, T. and Vanijja, V.},
  title           = {Asterisk server performance under stress test},
  year            = {2018},
  volume          = {2017-October},
  pages           = {1967-1971},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {VoIP has gained tremendous popularity in the recent times. However, security and Quality of Service (QoS) are two factors that severely affect its performance. The Session Initiation Protocol (SIP) servers must have enough hardware configurations as well as they should be properly configured to get a good voice quality. In this paper we investigate the effects of hardware configuration of the Asterisk (SIP) server that it might have on the QoS of VoIP. In particular, we load the server gradually with bulk calls and check the performance of CPU and RAM. We also scan the network packets and continuously monitor the call quality. In essence, we try to investigate a threshold value for the number of bulk calls that can be generated by our hardware configuration that will guarantee a good QoS. Therefore, one can conclude about the hardware configuration requirements of the Asterisk SIP server by analyzing the QoS of the generated calls. We also take into account the network loading conditions and try to combine the effects of both to come to a realistic value on the number of calls that can be generated. © 2017 IEEE.},
  author_keywords = {Asterisk; CPU utilization; QoS; SIP; Stress test},
  document_type   = {Conference Paper},
  doi             = {10.1109/ICCT.2017.8359973},
  isbn            = {9781509039432},
  journal         = {International Conference on Communication Technology Proceedings, ICCT},
  keywords        = {Computer hardware; Hardware; Internet protocols; Internet telephony; System-in-package; Voice/data communication systems, Asterisk; CPU utilization; Hardware configurations; Network packets; Server performance; Session initiation protocol; Stress test; Threshold-value, Quality of service},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047741086&doi=10.1109%2fICCT.2017.8359973&partnerID=40&md5=6a7f636d0856fc900d07ceab1ec5e9de},
}

@Article{Voegele2018,
  author          = {Vögele, C. and van Hoorn, A. and Schulz, E. and Hasselbring, W. and Krcmar, H.},
  title           = {WESSBAS: extraction of probabilistic workload specifications for load testing and performance prediction—a model-driven approach for session-based application systems},
  journal         = {Software and Systems Modeling},
  year            = {2018},
  volume          = {17},
  number          = {2},
  pages           = {443-477},
  issn            = {16191366},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The specification of workloads is required in order to evaluate performance characteristics of application systems using load testing and model-based performance prediction. Defining workload specifications that represent the real workload as accurately as possible is one of the biggest challenges in both areas. To overcome this challenge, this paper presents an approach that aims to automate the extraction and transformation of workload specifications for load testing and model-based performance prediction of session-based application systems. The approach (WESSBAS) comprises three main components. First, a system- and tool-agnostic domain-specific language (DSL) allows the layered modeling of workload specifications of session-based systems. Second, instances of this DSL are automatically extracted from recorded session logs of production systems. Third, these instances are transformed into executable workload specifications of load generation tools and model-based performance evaluation tools. We present transformations to the common load testing tool Apache JMeter and to the Palladio Component Model. Our approach is evaluated using the industry-standard benchmark SPECjEnterprise2010 and the World Cup 1998 access logs. Workload-specific characteristics (e.g., session lengths and arrival rates) and performance characteristics (e.g., response times and CPU utilizations) show that the extracted workloads match the measured workloads with high accuracy. © 2016, The Author(s).},
  author_keywords = {Load testing; Performance models; Performance prediction; Workload specifications},
  document_type   = {Article},
  doi             = {10.1007/s10270-016-0566-5},
  keywords        = {Computer programming languages; Extraction; Forecasting; Modeling languages; Problem oriented languages; Specifications, Domain specific languages; Industry-standard benchmarks; Model driven approach; Performance characteristics; Performance evaluation tools; Performance Model; Performance prediction; Testing and modeling, Load testing},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991818131&doi=10.1007%2fs10270-016-0566-5&partnerID=40&md5=574f259ea1ac394509d1f20d80296830},
}

@Article{Bouwman2018,
  author          = {Bouwman, H. and Heikkilä, J. and Heikkilä, M. and Leopold, C. and Haaker, T.},
  title           = {Achieving agility using business model stress testing},
  journal         = {Electronic Markets},
  year            = {2018},
  volume          = {28},
  number          = {2},
  pages           = {149-162},
  issn            = {10196781},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Business Model (BM) Innovations aim at making systemic changes in the business logic of companies when they are bringing innovative products and services to the market. Companies should be sensitive to changes in their business environment and able to modify their BMs in an agile way. To assess the agility of BMI during specific market entry situations, this paper uses a method that stress tests the value proposition and the components of a BM against contingent uncertainties. We present three qualitative case studies of companies that differ in their market entry approach. Starting from their strategic orientation, these case companies’ stress test their Business models and BM components, using a scenario-based identification of uncertainties. The BM Stress Test method contributes to a quick understanding of the components their BM needs to monitor, reconsider, or improve. Such stress testing helps enhance business agility. The research contributes to market strategy and business modelling research by introducing BM Stress Testing as a new method that can achieve and maintain agility regarding BM uncertainties. © 2017, The Author(s).},
  author_keywords = {Agility; Business model; Business model innovation; Business modelling; Market entry; Stress testing},
  document_type   = {Article},
  doi             = {10.1007/s12525-016-0243-0},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013135252&doi=10.1007%2fs12525-016-0243-0&partnerID=40&md5=f074771bba9e99a0c472abc4c5050332},
}

@Article{Hernando2018,
  author          = {Hernando, D. and Hernando, A. and Casajús, J.A. and Laguna, P. and Garatachea, N. and Bailón, R.},
  title           = {Methodological framework for heart rate variability analysis during exercise: application to running and cycling stress testing},
  journal         = {Medical and Biological Engineering and Computing},
  year            = {2018},
  volume          = {56},
  number          = {5},
  pages           = {781-794},
  issn            = {01400118},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Standard methodologies of heart rate variability analysis and physiological interpretation as a marker of autonomic nervous system condition have been largely published at rest, but not so much during exercise. A methodological framework for heart rate variability (HRV) analysis during exercise is proposed, which deals with the non-stationary nature of HRV during exercise, includes respiratory information, and identifies and corrects spectral components related to cardiolocomotor coupling (CC). This is applied to 23 male subjects who underwent different tests: maximal and submaximal, running and cycling; where the ECG, respiratory frequency and oxygen consumption were simultaneously recorded. High-frequency (HF) power results largely modified from estimations with the standard fixed band to those obtained with the proposed methodology. For medium and high levels of exercise and recovery, HF power results in a 20 to 40% increase. When cycling, HF power increases around 40% with respect to running, while CC power is around 20% stronger in running. © 2017, International Federation for Medical and Biological Engineering.},
  author_keywords = {Cardiolocomotor coupling; Non-stationary analysis; Pedalling cadence; Stride cadence},
  coden           = {MBECD},
  document_type   = {Article},
  doi             = {10.1007/s11517-017-1724-9},
  keywords        = {Frequency estimation, Autonomic nervous system; Heart rate variability; Heart rate variability analysis; Methodological frameworks; Non-stationary analysis; Pedalling cadence; Respiratory frequency; Stride cadence, Heart, adult; Article; breathing rate; cycling; electrocardiogram; exercise; exercise test; heart rate variability; human; human experiment; male; mathematical computing; methodology; oxygen consumption; physiological process; priority journal; running},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029797644&doi=10.1007%2fs11517-017-1724-9&partnerID=40&md5=59da15c33654ecbe9e4a532ed968f036},
}

@Conference{Maalej2018,
  author          = {Maâlej, A.J. and Lahami, M. and Krichen, M. and Jmäiel, M.},
  title           = {Distributed and resource-aware load testing of WS-BPEL compositions},
  year            = {2018},
  editor          = {Filipe J., Camp O., Smialek M., Filipe J., Hammoudi S.},
  volume          = {2},
  pages           = {29-38},
  publisher       = {SciTePress},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {One important type of testingWeb services compositions is load testing, as such applications solicit concurrent access by multiple users simultaneously. In this context, load testing of these applications seems an important task in order to detect problems under elevated loads. For this purpose, we propose a distributed and resource aware test architecture aiming to study the behavior of WS-BPEL compositions considering load conditions. The major contribution of this paper consists of (i) looking for the best node hosting the execution of each tester instance, then (ii) running a load test during which the composition under test is monitored and performance data are recorded and finally (iii) analyzing in a distributed manner the resulting test logs in order to identify problems under load. We also illustrate our approach by means of a case study in the healthcare domain considering the context of resource aware load testing. © 2018 by SCITEPRESS - Science and Technology Publications, Lda.},
  author_keywords = {Distributed execution environment; Distributed load testing; Distributed log analysis; Performance monitoring; Resource awareness; Tester instance placement; Web services composition},
  document_type   = {Conference Paper},
  isbn            = {9789897582981},
  journal         = {ICEIS 2018 - Proceedings of the 20th International Conference on Enterprise Information Systems},
  keywords        = {Information systems; Information use; Web services, Distributed loads; Execution environments; Log analysis; Performance monitoring; Resource awareness; Tester instance placement; Web services composition, Load testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047727084&partnerID=40&md5=582b26d08babf4cb1786b6d4eaa4392b},
}

@Article{Jailia2018,
  author          = {Jailia, M. and Agarwal, M. and Kumar, A.},
  title           = {Comparative study of N-tier and cloud-based web application using automated load testing tool},
  journal         = {Advances in Intelligent Systems and Computing},
  year            = {2018},
  volume          = {625},
  pages           = {239-250},
  issn            = {21945357},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {These days people cannot think a single day without online world. In online world, Web applications play very important role in all sectors, let it be for searching, shopping, and education too. Too many Web sites are launched daily. But what matters a lot for a user is all about performance. In this paper, we have discussed the comparison between N-tier-based Web application and cloud-based Web application, so that while designing of Web site one can efficiently select Web architecture. At last with the help of loadcomplete tool, performance is to be evaluated on various metrics. © Springer Nature Singapore Pte Ltd. 2018.},
  author_keywords = {Architecture; Cloud; Loadcomplete; N-tier; Web},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-981-10-5508-9_23},
  editor          = {Joshi A., Mishra D.K., Azar A.T.},
  isbn            = {9789811055072},
  keywords        = {Architecture; Clouds; Load testing; Websites, Cloud-based; Comparative studies; Loadcomplete; WEB application; Web architecture, Computer architecture},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031731921&doi=10.1007%2f978-981-10-5508-9_23&partnerID=40&md5=746f9dcbb9b18526a92ab64e78570685},
}

@Article{Agnihotri2018,
  author          = {Agnihotri, J. and Phalnikar, R.},
  title           = {Development of performance testing suite using apache JMeter},
  journal         = {Advances in Intelligent Systems and Computing},
  year            = {2018},
  volume          = {673},
  pages           = {317-326},
  issn            = {21945357},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Testing a product has become one of the most important tasks for any organization (Be it small scale or large scale). Without testing the product, it is not delivered to the customer. Testing is an ongoing activity from the beginning of a product’s development. A performance testing suite shall be developed using Apache JMeter for the purpose of testing a product. To perform performance testing on client- and server-type softwares, a 100% pure Java application named Apache JMeter is used. Apache JMeter is not a browser, it works at protocol level. Static and dynamic resources performance testing can be done using JMeter. A high level performance testing suite will be developed in capturing aspects of performance at UI and System level. Developing the testing suite helps in saving the time and cost of the organization. The discussion follows and describes benefits of performance testing and the performance testing suite. © 2018, Springer Nature Singapore Pte Ltd.},
  author_keywords = {JMeter, etc; Performance testing; Silk performer},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-981-10-7245-1_32},
  editor          = {Satapathy S.C., Chandavale A.A., Hiwale A.S., Bhateja V., Bhalla S.},
  isbn            = {9789811072444},
  keywords        = {Computer programming; Computer science, Dynamic resources; Java applications; JMeter, etc; Performance testing; Protocol level; Small scale; System levels, Intelligent computing},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045234512&doi=10.1007%2f978-981-10-7245-1_32&partnerID=40&md5=57fd08b6e3b6f389f15cfe42d537c31c},
}

@Conference{Liu2017a,
  author          = {Liu, R.-S. and Chang, Y.-S. and Hung, C.-W.},
  title           = {VST: A virtual stress testing framework for discovering bugs in SSD flash-translation layers},
  year            = {2017},
  volume          = {2017-November},
  pages           = {283-290},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Flash translation layers (FTLs) are the core embedded software (also known as firmware) of NAND flash-based solid-state drives (SSDs). The relentless pursuit of high-performance SSDs renders FTLs increasingly complex and intricate. Therefore, testing and validating FTLs are crucial and challenging tasks. Directly testing and validating FTLs on SSD hardware are common practices though, they are time-consuming and cumbersome because 1) the testing speed is limited by the hardware speed of SSDs and 2) just reproducing bugs can be challenging, let alone locating and root causing the bugs. This work presents virtual stress testing (VST), a simulation framework to enable executing SSD FTLs on PCs or servers against virtual SRAM, DRAM, and flash emulated by host-side main memory. FTL function calls, such as moving data from flash to DRAM, are served by the VST framework. Therefore, VST can test FTLs without SSD hardware requirements nor SSD speed limitations, and root causing bugs becomes manageable tasks. We apply VST to representative SSD design, OpenSSD, which is actively utilized and maintained by SSD and FTL communities. Experimental results show that VST can test FTLs at a speed up to 375 GB/s, which is several hundred times faster than directly testing FTLs on SSD hardware. Moreover, we successfully discover seven new FTL bugs in the OpenSSD design using VST, which is a solid evidence of VST's bug-discovering effectiveness. © 2017 IEEE.},
  author_keywords = {Data storage systems; Disk drives; Embedded software; Flash memories; Software debugging; Software testing; Systems simulation},
  coden           = {DICDF},
  document_type   = {Conference Paper},
  doi             = {10.1109/ICCAD.2017.8203790},
  isbn            = {9781538630938},
  issn            = {10923152},
  journal         = {IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD},
  keywords        = {Computer aided design; Computer hardware; Computer software; Data storage equipment; Digital storage; Dynamic random access storage; Embedded software; Embedded systems; Firmware; Flash memory; Hardware; Integrated circuit design; Program debugging; Software testing; Static random access storage, Common practices; Data storage systems; Disk drive; Flash translation layer; Function calls; Simulation framework; Software debugging; Systems simulation, Flash-based SSDs},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043538353&doi=10.1109%2fICCAD.2017.8203790&partnerID=40&md5=ea2d0e5719f02095cfece878a06026a5},
}

@Article{Portillo-Dominguez2017,
  author          = {Portillo-Dominguez, A.O. and Perry, P. and Magoni, D. and Murphy, J.},
  title           = {PHOEBE: an automation framework for the effective usage of diagnosis tools in the performance testing of clustered systems},
  journal         = {Software - Practice and Experience},
  year            = {2017},
  volume          = {47},
  number          = {11},
  pages           = {1837-1874},
  issn            = {00380644},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The identification of performance issues and the diagnosis of their root causes are time-consuming and complex tasks, especially in clustered environments. To simplify these tasks, researchers have been developing tools with built-in expertise for practitioners. However, various limitations exist in these tools that prevent their efficient usage in the performance testing of clusters (e.g. the need of manually analysing huge volumes of distributed results). In a previous work, we introduced a policy-based adaptive framework (PHOEBE) that automates the usage of diagnosis tools in the performance testing of clustered systems, in order to improve a tester's productivity, by decreasing the effort and expertise needed to effectively use such tools. This paper extends that work by broadening the set of policies available in PHOEBE, as well as by performing a comprehensive assessment of PHOEBE in terms of its benefits, costs and generality (with respect to the used diagnosis tool). The performed evaluation involved a set of experiments in assessing the different trade-offs commonly experienced by a tester when using a performance diagnosis tool, as well as the time savings that PHOEBE can bring to the performance testing and analysis processes. Our results have shown that PHOEBE can drastically reduce the effort required by a tester to do performance testing and analysis in a cluster. PHOEBE also exhibited consistent behaviour (i.e. similar time-savings and resource utilisations), when applied to a set of commonly used diagnosis tools, demonstrating its generality. Finally, PHOEBE proved to be capable of simplifying the configuration of a diagnosis tool. This was achieved by addressing the identified trade-offs without the need for manual intervention from the tester. Copyright © 2017 John Wiley & Sons, Ltd. Copyright © 2017 John Wiley & Sons, Ltd.},
  author_keywords = {cluster computing; performance analysis; performance testing; system performance},
  coden           = {SPEXB},
  document_type   = {Conference Paper},
  doi             = {10.1002/spe.2500},
  keywords        = {Commerce; Economic and social effects, Adaptive framework; Comprehensive assessment; Manual intervention; Performance analysis; Performance diagnosis; Performance issues; Performance testing; System performance, Cluster computing},
  language        = {English},
  publisher       = {John Wiley and Sons Ltd},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017621084&doi=10.1002%2fspe.2500&partnerID=40&md5=32bcbabace84fd7106fa9798fdb1169c},
}

@Conference{Deka2017a,
  author          = {Deka, B. and Huang, Z. and Franzen, C. and Nichols, J. and Li, Y. and Kumar, R.},
  title           = {ZIPT: Zero-integration performance testing of mobile app designs},
  year            = {2017},
  pages           = {727-736},
  publisher       = {Association for Computing Machinery, Inc},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {To evaluate the performance of mobile app designs, designers Andresearchers employ techniques such as A/B, usability, and analytics-driven testing. While these are all useful strategies for evaluating known designs, comparing many divergent solutions to identify the most performant remains a costly and difficult problem. This paper introduces a design performance testing approach that leverages existing app implementations and crowd workers to enable comparative testing at scale. This approach is manifest in ZIPT, a zero-integration performance testing platform that allows designers to collect detailed design and interaction data over any android app -including apps they do not own and did not build. Designers can deploy scripted tests via ZIPT to collect aggregate user performance metrics (e.g., completion rate, time on task) and qualitative feedback over third-party apps. Through case studies, we demonstrate that designers can use ZIPT's aggregate data and visualizations to understand the relative performance of interaction patterns found in the wild, and identify usability issues in existing android apps. © 2017 Copyright held by the owner/author(s).},
  author_keywords = {App design; Design support tools; Zero-integration performance testing},
  document_type   = {Conference Paper},
  doi             = {10.1145/3126594:3126647},
  isbn            = {9781450349819},
  journal         = {UIST 2017 - Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology},
  keywords        = {Aggregates; Android (operating system); Design; Integration; User interfaces, Comparative testing; Design performance; Design support tools; Divergent solution; Interaction pattern; Performance testing; Qualitative feedback; Relative performance, Integration testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041520399&doi=10.1145%2f3126594%3a3126647&partnerID=40&md5=94feddecc1f241bf1410ae7abf0dae85},
}

@Conference{Xie2017a,
  author          = {Xie, X. and Yang, Z. and Yu, J. and Zhang, W.},
  title           = {Design and implementation of bank financial business automation testing framework based on QTP},
  year            = {2017},
  pages           = {143-147},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The current software testing in the aspects of industrial benefits gradually causes the attention of the domestic financial bank. The innovation of software technology, the increase of software scale and the shortened developing period make the traditional manual testing meeting enormous challenges, while the development of automated testing technology has promoted the progress of the software testing industry. Because of the particularity of financial and banking services, the bank is under an obligation to ensure the quality and reliability of software. Therefore it's vital to test the software. In specific practice, although the powerful third-party testing tools can be used as a solution, it is hard to rely on certain tool to implement automated testing, hence a framework of automated test is required to be introduced for testing, which intends to handle high efficiency and high-quality testing for software automation. This paper proposes a kind of software automation testing framework based on QTP, mainly targeting on the core of the bank, credit, online banking to test the function of the three major operations. The framework is a secondary development based on QTP and mainly for regression testing of software, which integrates techniques including object recognition, data-driven, and keyword-driven technology, checkpoint technology, to proceed business-level testing. The paper expatiated on four issues, which were the test system design, the test standardization, the testing framework design and the testing of the implementation. The practical application shows that the framework can improve the operational efficiency, reduce the test cost, and guarantee the smooth progress of the software automation testing. © 2016 IEEE.},
  art_number      = {8070136},
  author_keywords = {QTP automated testing tool; software testing; test automation framework},
  document_type   = {Conference Paper},
  doi             = {10.1109/ICCSNT.2016.8070136},
  isbn            = {9781509021284},
  journal         = {Proceedings of 2016 5th International Conference on Computer Science and Network Technology, ICCSNT 2016},
  keywords        = {Application programs; Automation; Computer networks; Computer software; Efficiency; Finance; Object recognition; Software engineering; Software reliability; Testing, Automated testing tools; Business automation; Design and implementations; Operational efficiencies; Secondary development; Software automation; Software technology; Test automation frameworks, Software testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039901359&doi=10.1109%2fICCSNT.2016.8070136&partnerID=40&md5=2207e9b08eb4d845c9225d2bd4bebc2a},
}

@Conference{Abbas2017a,
  author          = {Abbas, R. and Sultan, Z. and Bhatti, S.N.},
  title           = {Comparative analysis of automated load testing tools: Apache JMeter, Microsoft Visual Studio (TFS), LoadRunner, Siege},
  year            = {2017},
  pages           = {39-44},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Software testing is the process of testing, verifying and validating the user's requirements. During whole software development, testing is an ongoing process. Black Box, White Box testing and grey box testing are the three main types of software testing. In Black box testing, user doesn't know intrinsic logics and design of system. In white box testing, Tester knows the intrinsic logic of code. In Grey box testing, Tester has little bit knowledge about the internal structure, code and working of the system. It is commonly used in case of Integration testing. Load testing is the type of testing which helps us to analyze the performance of the system under heavy load or under Zero load. With the help of a automated load Testing Tools, we can do it in better way. The intention for writing this research is to carry out a comparison of four automated load testing tools i.e. Apache JMeter, HP LoadRunner, Microsoft Visual Studio (TFS), Siege based on certain criteria i.e. test scripts generation, plug-in support, result reports, application support and cost. The main focus is to study and analyze these load testing tools and identify which tool is best and more efficient [10]. We assume this comparative analysis can help in selecting the most appropriate tool and motivates the use of open source load testing tools. © 2017 IEEE.},
  art_number      = {8065747},
  author_keywords = {automated testing; load testing; manual testing; stress test; Testing; testing tools},
  document_type   = {Conference Paper},
  doi             = {10.1109/COMTECH.2017.8065747},
  isbn            = {9781509059843},
  journal         = {International Conference on Communication Technologies, ComTech 2017},
  keywords        = {Automation; Integration testing; Load testing; Open source software; Software design; Software engineering; Software testing; Studios; Testing, Automated testing; Comparative analysis; Grey-box testing; Internal structure; Manual testing; Stress test; Testing tools; White-box testing, Black-box testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034760233&doi=10.1109%2fCOMTECH.2017.8065747&partnerID=40&md5=bbfa33bc6a24a4570030195aac6078c7},
}

@Conference{Gois2017a,
  author          = {Gois, N. and Porfirio, P. and Coelho, A.},
  title           = {A Multi-objective Metaheuristic Approach to Search-Based Stress Testing},
  year            = {2017},
  pages           = {55-62},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Nowadays applications need to deal with a large number of concurrent requests. These systems must be stress tested to ensure that they can function correctly under a load. In this context, a research field called Search-based Software Testing has become increasingly important. Most of the search-based test methods are based on single objective optimization. In the case of multi-objective optimization of tests, usually researchers assign different weight values to different objectives and combine them as a single objective. This research paper verifies the use of a multi-objective algorithm in search-based stress testing. The NSGA-II algorithm was implemented in the IAdapter tool using the jMetal framework. IAdapter is a JMeter plugin used for performing search-based stress tests. jMetal is an object-oriented Java-based framework for multi-objective optimization with metaheuristics. One experiment was conducted to validate the proposed approach. © 2017 IEEE.},
  art_number      = {8031452},
  author_keywords = {Multi-Objective Metaheuristic; Pareto Frontier; Search-Based Stress Test},
  document_type   = {Conference Paper},
  doi             = {10.1109/CIT.2017.19},
  isbn            = {9781538609583},
  journal         = {IEEE CIT 2017 - 17th IEEE International Conference on Computer and Information Technology},
  keywords        = {Heuristic methods; Object oriented programming; Optimization; Software testing; Testing, Concurrent requests; Multi objective algorithm; Multi-objective metaheuristics; NSGA-II algorithm; Pareto frontiers; Search-based software testing; Single objective optimization; Stress test, Multiobjective optimization},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032376817&doi=10.1109%2fCIT.2017.19&partnerID=40&md5=279d0b8aeaaa06392916a2beddc93869},
}

@Conference{Kim2017b,
  author          = {Kim, E.E. and Ziegler, S.},
  title           = {Towards an open framework of online interoperability and performance tests for the Internet of Things},
  year            = {2017},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {This article presents an initial set of results from the F-Interop European research project researching online platform for interoperability and performance tests for the Internet of Things. IoT interoperability testing is an important step for IoT solutions but current face-to-face testing is cost-inefficient and labor-intensive. F-Interop aims to provide online interoperability, conformance, and performance testing tools enabling remote tests. This article presents the challenges faced by the IoT in online testing, and how F-Interop is addressing them, in order to provide an extensive experimental platform for online tests. It gives an overview of its overall architecture and the developing online testing tools by F-Interop. © 2017 IEEE.},
  art_number      = {8016248},
  author_keywords = {conformance test; Internet of Things; interoperability test; performance test; privacy; scalability test; testbed as a service},
  document_type   = {Conference Paper},
  doi             = {10.1109/GIOTS.2017.8016248},
  isbn            = {9781509058730},
  journal         = {GIoTS 2017 - Global Internet of Things Summit, Proceedings},
  keywords        = {Acceptance tests; Data privacy; Internet of things; Testing, European research project; Experimental platform; Interoperability testing; Online testing tool; Performance testing; Performance tests; Scalability test; Testbed as a services, Interoperability},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029306540&doi=10.1109%2fGIOTS.2017.8016248&partnerID=40&md5=cfe524292c8b940e4e8be40056ebd05e},
}

@Article{Liu2017b,
  author          = {Liu, J. and Zhang, Z. and Chen, Y. and Zhang, X.},
  title           = {Host Injection Test Technology for Fault Handling Performance Test of Power Distribution Network with DG},
  journal         = {Dianli Xitong Zidonghua/Automation of Electric Power Systems},
  year            = {2017},
  volume          = {41},
  number          = {13},
  pages           = {119-124 and 132},
  issn            = {10001026},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The composition and principle of the improved host injection test platform for fault handling performance text of power distribution network with distributed generators (DGs) is described. The power flow calculation method and short circuit current calculation for the power distribution network with DGs are discussed. A natural fault scenario set-up approach is put forward. The action of relay protections, automatic devices, feeder terminal units (FTUs) and circuit breakers are simulated according to the comparison of short circuit calculation and the setting values. In addition, the action of switches and DGs separate from the grid during the restoration procedure can also be simulated. Thus, the correctness of the scheme and steps of service restoration can be tested more effectively. Examples are given to illustrate the feasibility and effectiveness of the test technology proposed. © 2017 Automation of Electric Power Systems Press.},
  author_keywords = {Distributed generator; Distribution automation; Fault location; Power distribution network; Power restoration; Relay protection; Test},
  coden           = {DXZIE},
  document_type   = {Article},
  doi             = {10.7500/AEPS20161111002},
  keywords        = {Distributed power generation; Electric circuit breakers; Electric equipment protection; Electric fault location; Electric load flow; Electric network analysis; Power quality; Relay protection; Restoration, Distributed generator (DGs); Distributed generators; Distribution automation; Power distribution network; Power flow calculations; Power restoration; Restoration procedure; Short circuit calculations, Testing},
  language        = {Chinese},
  publisher       = {Automation of Electric Power Systems Press},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026779446&doi=10.7500%2fAEPS20161111002&partnerID=40&md5=b73ee23914389730ff2fe7be71e8606b},
}

@Article{Garcia-Dominguez2017,
  author          = {Garcia-Dominguez, A. and Barmpis, K. and Kolovos, D.S. and Wei, R. and Paige, R.F.},
  title           = {Stress-testing remote model querying APIs for relational and graph-based stores},
  journal         = {Software and Systems Modeling},
  year            = {2017},
  pages           = {1-29},
  issn            = {16191366},
  note            = {cited By 1; Article in Press},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Recent research in scalable model-driven engineering now allows very large models to be stored and queried. Due to their size, rather than transferring such models over the network in their entirety, it is typically more efficient to access them remotely using networked services (e.g. model repositories, model indexes). Little attention has been paid so far to the nature of these services, and whether they remain responsive with an increasing number of concurrent clients. This paper extends a previous empirical study on the impact of certain key decisions on the scalability of concurrent model queries on two domains, using an Eclipse Connected Data Objects model repository, four configurations of the Hawk model index and a Neo4j-based configuration of the NeoEMF model store. The study evaluates the impact of the network protocol, the API design, the caching layer, the query language and the type of database and analyses the reasons for their varying levels of performance. The design of the API was shown to make a bigger difference compared to the network protocol (HTTP/TCP) used. Where available, the query-specific indexed and derived attributes in Hawk outperformed the comprehensive generic caching in CDO. Finally, the results illustrate the still ongoing evolution of graph databases: two tools using different versions of the same backend had very different performance, with one slower than CDO and the other faster than it. © 2017 The Author(s)},
  author_keywords = {API design; Collaborative modelling; Model persistence; NoSQL storage; Relational databases; Remote model querying; Stress testing},
  document_type   = {Article in Press},
  doi             = {10.1007/s10270-017-0606-9},
  keywords        = {Digital storage; Network protocols; Query languages; Query processing, Api design; Collaborative modelling; Relational Database; Remote model querying; Stress Testing, Internet protocols},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021753284&doi=10.1007%2fs10270-017-0606-9&partnerID=40&md5=8bdadb1523dba9197ea5ee4176f0e1d0},
}

@Conference{Xu2017,
  author          = {Xu, J. and Lei, Y. and Carver, R.},
  title           = {Using Delta Debugging to Minimize Stress Tests for Concurrent Data Structures},
  year            = {2017},
  pages           = {35-46},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Concurrent data structures are often tested under stress to detect bugs that can only be exposed by some rare interleavings of instructions. A typical stress test for a concurrent data structure creates a number of threads that repeatedly invoke methods of the target data structure. After a failure is detected by a stress test, developers need to localize the fault causing the failure. However, the execution trace of a failed stress test may be very long, making it time-consuming to replay the failure and localize the fault. In this paper, we present an approach to minimizing stress tests for concurrent data structures. Our approach is to create a smaller test that still produces the same failure by removing some of the threads and/or method invocations in the original stress test. We apply delta debugging to identify the threads and method invocations that are essential for causing the failure. Other threads and method invocations are removed to create a smaller stress test. To increase the chance of triggering the original failure during the execution of the new stress test, we force the new execution to replay the original failed execution trace when possible, and try to guide the execution back to the failed trace when the execution diverges. We describe a tool called TestMinimizer and report the results of an empirical study in which TestMinimizer was applied to 16 real-life concurrent data structures. The results of our evaluation showed that TestMinimizer can effectively and efficiently minimize the stress tests for these concurrent data structures. © 2017 IEEE.},
  art_number      = {7927961},
  author_keywords = {Concurrent data structures; Delta debugging; Execution replay; Minimization; Stress testing},
  document_type   = {Conference Paper},
  doi             = {10.1109/ICST.2017.11},
  isbn            = {9781509060313},
  journal         = {Proceedings - 10th IEEE International Conference on Software Testing, Verification and Validation, ICST 2017},
  keywords        = {Concurrency control; Data structures; Optimization; Testing; Verification, Concurrent data structures; Delta debugging; Empirical studies; Execution replay; Execution trace; Method invocation; Number of threads; Stress Testing, Software testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020718412&doi=10.1109%2fICST.2017.11&partnerID=40&md5=e17961e1aee71b5bd7737ce56890e2ab},
}

@Article{Cheng2017,
  author        = {Cheng, J. and Yu, K. and Libisch, F. and Dieterich, J.M. and Carter, E.A.},
  title         = {Potential Functional Embedding Theory at the Correlated Wave Function Level. 2. Error Sources and Performance Tests},
  journal       = {Journal of Chemical Theory and Computation},
  year          = {2017},
  volume        = {13},
  number        = {3},
  pages         = {1081-1093},
  issn          = {15499618},
  note          = {cited By 4},
  __markedentry = {[Jonnathan:]},
  abstract      = {Quantum mechanical embedding theories partition a complex system into multiple spatial regions that can use different electronic structure methods within each, to optimize trade-offs between accuracy and cost. The present work incorporates accurate but expensive correlated wave function (CW) methods for a subsystem containing the phenomenon or feature of greatest interest, while self-consistently capturing quantum effects of the surroundings using fast but less accurate density functional theory (DFT) approximations. We recently proposed two embedding methods [for a review, see: Acc. Chem. Res. 2014, 47, 2768 ]: density functional embedding theory (DFET) and potential functional embedding theory (PFET). DFET provides a fast but non-self-consistent density-based embedding scheme, whereas PFET offers a more rigorous theoretical framework to perform fully self-consistent, variational CW/DFT calculations [as defined in part 1, CW/DFT means subsystem 1(2) is treated with CW(DFT) methods]. When originally presented, PFET was only tested at the DFT/DFT level of theory as a proof of principle within a planewave (PW) basis. Part 1 of this two-part series demonstrated that PFET can be made to work well with mixed Gaussian type orbital (GTO)/PW bases, as long as optimized GTO bases and consistent electron-ion potentials are employed throughout. Here in part 2 we conduct the first PFET calculations at the CW/DFT level and compare them to DFET and full CW benchmarks. We test the performance of PFET at the CW/DFT level for a variety of types of interactions (hydrogen bonding, metallic, and ionic). By introducing an intermediate CW/DFT embedding scheme denoted DFET/PFET, we show how PFET remedies different types of errors in DFET, serving as a more robust type of embedding theory. © 2017 American Chemical Society.},
  coden         = {JCTCC},
  document_type = {Article},
  doi           = {10.1021/acs.jctc.6b01011},
  language      = {English},
  publisher     = {American Chemical Society},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015234212&doi=10.1021%2facs.jctc.6b01011&partnerID=40&md5=94f37314d4a24b6b16b232f23b0d5460},
}

@Article{Parichehreh2017,
  author        = {Parichehreh, A. and Spagnolini, U. and Marini, P. and Fontana, A.},
  title         = {Load-Stress Test of Massive Handovers for LTE Two-Hop Architecture in High-Speed Trains},
  journal       = {IEEE Communications Magazine},
  year          = {2017},
  volume        = {55},
  number        = {3},
  pages         = {170-177},
  issn          = {01636804},
  note          = {cited By 1},
  __markedentry = {[Jonnathan:]},
  abstract      = {Load-stress test is the experimental performance analysis in extreme traffic and density conditions, routinely required to validate any innovative radio access solution. This article focuses on load-stress test specifically designed for the two-hop architecture that enables the onboard connectivity in HSTs. The load-stress condition of train-to-infrastructure communication for a massive number of onboard UEs is very challenging, as it needs to account for extreme conditions and a complex testing environment. The load-stress method proposed in this article is for a ground network supporting onboard wireless connectivity in HSTs, and is validated for commercial eNBs from LTE cellular networks (Rel-11). The in-lab experimental setup is arranged by virtualizing multiple eNBs serving multiple cells, arranged sequentially along a line to simulate the HST track with a massive number of active onboard UEs. The focus of the experimental load-stress test is the analysis of the impact of Doppler shift and interruptions caused by the frequent HOs of multiple consecutive groups of UEs deployed in HST carriages at the speed of 300 km/h. The HO interruption time is characterized statistically based on the number of active UEe. The consequent impairments on the experienced QoS for high-throughput and low-latency services such as FTP and VoLTE are verified. This article validates experimentally the traffic and HO latency improvements (approximately threefold) in a multi-cell access scheme when the coverage of every single carriage is augmented by fixed directional antennas to offload UEs toward far-away eNBs along the train track. © 1979-2012 IEEE.},
  art_number    = {7876977},
  coden         = {ICOMD},
  document_type = {Article},
  doi           = {10.1109/MCOM.2017.1600773CM},
  keywords      = {Directive antennas; Load testing; Network architecture; Railroad cars; Railroad transportation; Railroads, Cellular network; Directional Antenna; Experimental performance analysis; Extreme conditions; Ground networks; High speed train (HST); High throughput; Wireless connectivities, Wireless telecommunication systems},
  language      = {English},
  publisher     = {Institute of Electrical and Electronics Engineers Inc.},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017588843&doi=10.1109%2fMCOM.2017.1600773CM&partnerID=40&md5=9ac2bd8d1656c20a1d5f0f5014363c37},
}

@Conference{Foegelle2017,
  author        = {Foegelle, M.D.},
  title         = {Advances in over-the-air performance testing methods for mmWave devices and 5G communications},
  year          = {2017},
  publisher     = {Institute of Electrical and Electronics Engineers Inc.},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {The boundary array technique introduced at AMTA 2006 has recently become the reference standard for over-the-air performance testing of wireless MIMO devices. While the concepts developed then are viable for testing of today's LTE handsets, the progression towards 5G technologies will pose new challenges that will require an alternate approach. Although the need to perform similar spatial environment based testing remains, the push towards mmWave communication links with beamforming arrays containing potentially hundreds of elements and extremely narrow beams will exceed the practical resolution limits of the boundary array approach. At the same time, these devices will incorporate chip scale antennas that are tightly integrated to the radio design, requiring a valid over-the-air test methodology to be able to evaluate the radio performance. © 2016 AMTA.},
  art_number    = {7806309},
  document_type = {Conference Paper},
  doi           = {10.1109/AMTAP.2016.7806309},
  isbn          = {9781509051793},
  journal       = {AMTA 2016 Proceedings},
  keywords      = {Millimeter wave devices; Millimeter waves; MIMO systems, Alternate approaches; Beamforming arrays; Mm-wave Communications; Over the airs; Reference standard; Resolution limits; Spatial environments; Test methodology, Beam forming networks},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011034446&doi=10.1109%2fAMTAP.2016.7806309&partnerID=40&md5=4c5a0d9b9ddf017c3b0379d9e54560d1},
}

@Conference{Khandelwal2017a,
  author          = {Khandelwal, H. and Mankodi, P. and Prajapati, R.},
  title           = {Enhancement of automation testing system using Yocto project},
  year            = {2017},
  volume          = {2017-January},
  pages           = {697-700},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Nowadays, in industries, Testing has become one of the important tasks. Testing is necessary for an effective performance of product and software applications. When companies having a mass production of hardware boards, it is necessary to do testing of each and every module of hardware like SPI, UART, GPIO, PWM, ADC, USB, Ethernet. If we do testing manually then it will significantly take more time, which we can be reduced by automation testing. But the solution is not an automation testing because automation testing also requires the same amount of system, for example for 300 boards 300 system is required. The only difference in manual and automation testing is that in automation testing it will require less human effort. Now we are focusing more on developing a solution in which many tests can be done on one single system i.e. for 300 boards only one system is required for testing hence this problem can be solved by Yocto Project. Yocto project have build the tool named Bitbake which is written in Python language, which works on multithreading and scheduling so that simultaneously you can test more boards on a single system. In this paper we did automation testing of GPIO pins using Yocto project. © 2017 IEEE.},
  author_keywords = {Automation; Bitbake; Open embedded; Yocto project},
  document_type   = {Conference Paper},
  doi             = {10.1109/ICECA.2017.8203630},
  journal         = {Proceedings of the International Conference on Electronics, Communication and Aerospace Technology, ICECA 2017},
  keywords        = {Application programs; Automation; Hardware, Automation testing; Bitbake; Effective performance; Mass production; Open embedded; PYTHON language; Software applications; Yocto project, Software testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047082888&doi=10.1109%2fICECA.2017.8203630&partnerID=40&md5=31ddf38efb6a06707eb7673300aaf8f2},
}

@Conference{Tikkala2017,
  author          = {Tikkala, V.-M. and Rantakaulio, A.},
  title           = {Test case selection procedure for simulation-assisted automation testing},
  year            = {2017},
  volume          = {3},
  pages           = {1635-1643},
  publisher       = {American Nuclear Society},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Simulation-assisted automation testing is an efficient tool for validating the automation systems for nuclear power plants. This paper presented a systematic procedure for selecting test cases for simulation-assisted automation testing. The procedure is relies on the plant's licensing framework and allows associating the test cases to the functional requirements in order to produce traceable test set for validation. The procedure is demonstrated with a case study concerning the automation tests of Loviisa NPP's automation renewal project. Copyright © (2017) by American Nuclear Society. All rights reserved.},
  author_keywords = {Apros; Automation testing; Simulation},
  document_type   = {Conference Paper},
  isbn            = {9781510851160},
  journal         = {10th International Topical Meeting on Nuclear Plant Instrumentation, Control, and Human-Machine Interface Technologies, NPIC and HMIT 2017},
  keywords        = {Man machine systems; Nuclear fuels; Nuclear power plants; Testing, Apros; Automation systems; Automation testing; Automation tests; Functional requirement; Renewal projects; Simulation; Test case selection, Automation},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047786397&partnerID=40&md5=b0a9130ff20727bfbde201a168e859a8},
}

@Article{GeethaDevasena2017a,
  author          = {Geetha Devasena, M.S. and Krishna Kumar, V. and Kingsy Grace, R.},
  title           = {LTTC: A load testing tool for cloud},
  journal         = {Advances in Intelligent Systems and Computing},
  year            = {2017},
  volume          = {508},
  pages           = {689-698},
  issn            = {21945357},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Software testing is the process of software engineering to free the software from bugs. Load testing is one of the techniques in software testing and is used to find the maximum load that software can handle without affecting its performance. Load testing is used to test the cloud services that are running in a cloud. All the resources in a cloud are used by the cloud users based on their demand. Using cloud, it is easy to gather the required load for a particular application by forming clusters. If the required load is coming from different clusters and it is not known quantitatively then the problem of load balancing is raised. The proposed load testing tool avoids the problem of getting unequal loads coming from different clusters by distributing the same amount of load to all the clusters. Also the proposed load testing tool for cloud is used to find the maximum number of simultaneous users for a particular cloud system is to handle. © Springer Nature Singapore Pte Ltd. 2017.},
  author_keywords = {Cloud testing; Load balancing; Load testing},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-981-10-2750-5_70},
  editor          = {Modi N., Verma P., Trivedi B.},
  isbn            = {9789811027499},
  keywords        = {Program debugging; Resource allocation; Software engineering; Software testing, Cloud services; Cloud systems; Cloud testing; Maximum load; Running-in, Load testing},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018676027&doi=10.1007%2f978-981-10-2750-5_70&partnerID=40&md5=5f9f9fdd334562034b79cbbfb6ec1caf},
}

@Conference{Brune2017,
  author          = {Brune, P.},
  title           = {Simulating user interactions: A model and tool for semi-realistic load testing of social app backend web services},
  year            = {2017},
  editor          = {Traverso P., Krempels K.-H., Monfort V., Majchrzak T.A.},
  pages           = {235-242},
  publisher       = {SciTePress},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Many mobile apps today support interactions between their users and/or the provider within the app. Therefore, these apps commonly call a web service backend system hosted by the app provider. For the implementation of such service backends, load tests are required to ensure their performance and scalability. However, existing tools like JMeter are not able to simulate "out of the box" a load distribution with the complex time evolution of heterogeneous, real and interacting users of a social app, which e.g. would be necessary to detect critical performance bottlenecks. Therefore, in this paper a probabilistic model for simulating interacting users of a social app is proposed and evaluated by implementing it in a prototype load testing tool and using it to test a backend of new real-world social app currently under development. Copyright © 2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
  author_keywords = {Load testing; Mobile app development; Mobile social network interaction; Model-based testing; User simulation; Web services},
  document_type   = {Conference Paper},
  isbn            = {9789897582462},
  journal         = {WEBIST 2017 - Proceedings of the 13th International Conference on Web Information Systems and Technologies},
  keywords        = {Complex networks; Information systems; Load testing; Websites, Mobile app; Mobile social networks; Model based testing; Performance and scalabilities; Performance bottlenecks; Probabilistic modeling; Support interaction; User simulation, Web services},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024479995&partnerID=40&md5=58033e1427ce3595493d6dd4dfae76d4},
}

@Conference{Eterovic2017,
  author        = {Eterovic, J.E. and Cipriano, M. and Jordi, B.},
  title         = {Proposal of an innovative methodology for the evaluation of the performance of cryptographic applications by load tests in a virtualized environment [Propuesta de una Metodología Innovadora para la Evaluación del Rendimiento de Aplicaciones Criptográficas mediante Pruebas de Carga en un Entorno Virtualizado]},
  year          = {2017},
  editor        = {Carrasquero J.V., Sanchez B., Callaos N.C., Tremante A., Plaza Vargas A.M.},
  pages         = {310-314},
  publisher     = {International Institute of Informatics and Systemics, IIIS},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  document_type = {Conference Paper},
  isbn          = {9781941763667},
  journal       = {CISCI 2017 - Decima Sexta Conferencia Iberoamericana en Sistemas, Cibernetica e Informatica, Decimo Cuarto Simposium Iberoamericano en Educacion, Cibernetica e Informatica, SIECI 2017 - Memorias},
  language      = {English; Spanish},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033225217&partnerID=40&md5=37030ae8e162052ff8d16c3f702e3734},
}

@Conference{Gao2017c,
  author          = {Gao, G. and Mishra, B. and Ramazzotti, D.},
  title           = {Efficient Simulation of Financial Stress Testing Scenarios with Suppes-Bayes Causal Networks},
  year            = {2017},
  editor          = {Lees M., Sloot P., Krzhizhanovskaya V., Dongarra J., Koumoutsakos P.},
  volume          = {108},
  pages           = {272-284},
  publisher       = {Elsevier B.V.},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The most recent financial upheavals have cast doubt on the adequacy of some of the conventional quantitative risk management strategies, such as VaR (Value at Risk), in many common situations. Consequently, there has been an increasing need for verisimilar financial stress testings, namely simulating and analyzing financial portfolios in extreme, albeit rare scenarios. Unlike conventional risk management which exploits statistical correlations among financial instruments, here we focus our analysis on the notion of probabilistic causation, which is embodied by Suppes-Bayes Causal Networks (SBCNs), SBCNs are probabilistic graphical models that have many attractive features in terms of more accurate causal analysis for generating financial stress scenarios. In this paper, we present a novel approach for conducting stress testing of financial portfolios based on SBCNs in combination with classical machine learning classification tools. The resulting method is shown to be capable of correctly discovering the causal relationships among financial factors that affect the portfolios and thus, simulating stress testing scenarios with a higher accuracy and lower computational complexity than conventional Monte Carlo Simulations. © 2017 The Authors. Published by Elsevier B.V.},
  author_keywords = {Causality; Classification; Decision Trees; Graphical Models; stress Testing; Suppes-Bayes Causal Networks},
  document_type   = {Conference Paper},
  doi             = {10.1016/j.procs.2017.05.167},
  issn            = {18770509},
  journal         = {Procedia Computer Science},
  keywords        = {Classification (of information); Decision trees; Graphic methods; Intelligent systems; Learning systems; Monte Carlo methods; Risk assessment; Risk management; Risk perception; Value engineering, Causal network; Causal relationships; Causality; GraphicaL model; Machine learning classification; Probabilistic graphical models; Statistical correlation; Stress Testing, Finance},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027328213&doi=10.1016%2fj.procs.2017.05.167&partnerID=40&md5=60df53b52d17a2c9ef1b62192892fcef},
}

@Article{Chattopadhyay2017a,
  author        = {Chattopadhyay, S.},
  title         = {Directed automated memory performance testing},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year          = {2017},
  volume        = {10206 LNCS},
  pages         = {38-55},
  issn          = {03029743},
  note          = {cited By 2},
  __markedentry = {[Jonnathan:]},
  abstract      = {Understanding software non-functional properties (e.g. time, energy and security) requires deep understanding of the execution platform. The design of caches plays a crucial role in impacting software performance (for low latency of caches) and software security (for cache being used as a side channel). We present CATAPULT, a novel test generation framework to systematically explore the cache behaviour of an arbitrary program. Our framework leverages dynamic symbolic execution and satisfiability modulo theory (SMT) solvers for generating test inputs. We show the application of CATAPULT in testing timing-related properties and testing cache side-channel vulnerabilities in several open-source programs, including applications from OpenSSL and Linux GDK libraries. © Springer-Verlag GmbH Germany 2017.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-662-54580-5_3},
  editor        = {Margaria T., Legay A.},
  isbn          = {9783662545799},
  keywords      = {Application programs; Computer operating systems; Open source software, Dynamic symbolic executions; Execution platforms; Memory performance; Non functional properties; Open source projects; Satisfiability modulo Theories; Software performance; Software security, Software testing},
  language      = {English},
  publisher     = {Springer Verlag},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017522007&doi=10.1007%2f978-3-662-54580-5_3&partnerID=40&md5=96df778dacf9b3c84ceb9f3d74ba6a7a},
}

@Conference{Esquiagola2017a,
  author          = {Esquiagola, J. and Costa, L. and Calcina, P. and Fedrecheski, G. and Zuffo, M.},
  title           = {Performance testing of an internet of things platform},
  year            = {2017},
  editor          = {Kantere V., Walters R., Ramachandran M., Munoz V.M., Chang V., Wills G.},
  pages           = {309-314},
  publisher       = {SciTePress},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The Internet of Things (IoT) is a network of physical objects, or things, with embedded electronics, software, sensors, and connectivity. The connection of all these things leverages value generation, by offering new services and strategic information. In order to make the Internet of Things possible, the integration of many technologies is necessary, such as machine-To-machine and cyber-physical systems. The process of testing IoT applications introduces new challenges because it does not only includes typical test strategies and methodologies. Testing an IoT system depends on its the specific configuration, and it also needs to consider the hardware platform and the network environment. Currently, industry and academy efforts are focusing on usability and connectivity tests, such as: simulating the environment where the device is to be used, and ensuring information is exchanged in a secure manner. In this paper, we use the current version of our IoT platform to perform stress testing of our IoT platform under different conditions. Our test methodology for IoT applications is also presented. Three different hardware platforms have been used for performing the stress testing of our platform. Copyright © 2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
  author_keywords = {Internet of things; Performance; Testing},
  document_type   = {Conference Paper},
  isbn            = {9789897582455},
  journal         = {IoTBDS 2017 - Proceedings of the 2nd International Conference on Internet of Things, Big Data and Security},
  keywords        = {Big data; Cyber Physical System; Embedded systems; Hardware; Testing, Embedded electronics; Hardware platform; Internet of thing (IOT); IOT applications; Machine to machines; Network environments; Performance; Performance testing, Internet of things},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024407175&partnerID=40&md5=c448d44c78f2f3c1cea0a737fc6bded7},
}

@Conference{Dasgupta2017,
  author        = {Dasgupta, D.},
  title         = {Performance testing approach to aws kinesis stream and loadrunner},
  year          = {2017},
  volume        = {2017-November},
  publisher     = {Computer Measurment Group Inc.},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {In the wake of an increasingly digital economy, businesses are racing to build operational knowledge around the vast sums of data they produce each day. And with data now at the center of almost every business function, developing practices for working with data is critical regardless of your company's size or industry. AWS Kinesis Stream provides a platform to consume these data from various sources and process them for analytical purposes. In the current age of Digital Marketing the important aspect which comes to play is the speed at which you can process the data. The AWS Cloud provides a broad set of infrastructure services, such as computing power, storage options, networking and databases that are delivered as a utility: on-demand, available in seconds, with pay-as-you-go pricing. Amazon Kinesis is a platform for streaming data on AWS, offering powerful services to make it easy to load and analyze streaming data, and also providing the ability for to build custom streaming data applications for specialized needs. To ensure the timely execution as well to determine the proper infrastructure to host the Kinesis Stream it is very important to execute a through performance test of the Kinesis Stream application. The Data Message flow to kinesis Stream gets authenticated using AES256 encryption which most of performance testing tools (e.g. Loadrunner) doesn't supports. This paper presents a succinct approach to implement the performance testing steps overcoming the authentication issue and execute Load Test on Kinesis Stream. The approach explains how to overcome the authentication issue with the help of Node.js and integrate it with Loadrunner and execute the performance test. The paper also provides details on the critical metrics to be monitored from CloudWatch for analyzing the Kinesis Stream performance. AWS provides its own monitoring through service called CloudWatch. This document also provides insight on the monitoring steps using CloudWatch during the performance testing. In Summary this paper provides an approach for testing Kinesis Stream with help of Node.js. The paper also provides benefits on the approach and how it can be utilized for other tools and testing approaches. © imPACt 2017 - Internet, Mobile, Performance and Capacity, Cloud and Technology. All rights reserved.},
  document_type = {Conference Paper},
  journal       = {imPACt 2017 - Internet, Mobile, Performance and Capacity, Cloud and Technology},
  keywords      = {Authentication; Cryptography; Distributed computer systems; Economics; Load testing, Business functions; Critical metrics; Digital marketing; Infrastructure services; Operational knowledge; Performance testing; Performance tests; Stream application, Digital storage},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047297680&partnerID=40&md5=0f74e0e0440fa0ac3473c9d3369cc4e9},
}

@Conference{Opachich2017,
  author          = {Opachich, Y.P. and Looker, Q. and Macneil, L. and Alarie, A. and Kimmel, M.W. and Long, J. and Max, D. and Stahoviak, J.W. and Tran, V. and Wolf, C. and Waltman, T. and Porter, J.L.},
  title           = {Solid state streak camera prototype electronic performance testing and characterization},
  year            = {2017},
  editor          = {Koch J.A., Grim G.P.},
  volume          = {10390},
  publisher       = {SPIE},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Streak Cameras are an essential diagnostic tool used in shock physics and high energy density physics experiments. Such experiments require well calibrated temporally resolved diagnostics for studying events that occur in the nanosecond to microsecond time scales. Although streak cameras are among the most common detectors used within the high energy density physics community, they require frequent calibration and typically lack reproducibility in the fine detail. A solid state device with similar temporal performance characteristics could provide several advantages to current streak camera systems by utilizing discrete spatial resolution set by the sensor diodes. National Security Technologies (NSTec) has built a multi-channel solid state streak camera (SSSC) prototype, in collaboration with Sandia National Laboratories, as part of an ongoing project to develop the technology to a level competitive with analog streak cameras. The device concept and results from electronic testing of our first prototypes will be discussed in this manuscript. These measurements will be used as a base for future SSSC development projects. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.},
  art_number      = {103900L},
  author_keywords = {Optical detector; Solid state detectors; Streak camera},
  coden           = {PSISD},
  document_type   = {Conference Paper},
  doi             = {10.1117/12.2276224},
  isbn            = {9781510612372},
  issn            = {0277786X},
  journal         = {Proceedings of SPIE - The International Society for Optical Engineering},
  keywords        = {Calibration; Inertial confinement fusion; National security; Semiconductor detectors; Solid state devices; Streak cameras, High energy density physics; Optical detectors; Prototype electronics; Sandia National Laboratories; Security technology; Solid state detectors; Temporal performance; Temporally resolved, High energy physics},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040740011&doi=10.1117%2f12.2276224&partnerID=40&md5=568e1ec042ba5456a0163ee167e45359},
}

@Conference{Firoozabadi2017,
  author        = {Firoozabadi, R. and Babaeizadeh, S.},
  title         = {A practical noise stress test to assess performance of automated photo-plethysmogram analysis},
  year          = {2017},
  volume        = {44},
  pages         = {1-4},
  publisher     = {IEEE Computer Society},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {Due to a significant spectral overlap between the motion artifact and underlying photoplethysmogram (PPG), reliable automated PPG analysis in real-life environment may be challenging. To evaluate the impact of motion artifact on the accuracy of automated PPG pulse detection, we designed a noise stress test (NST) in which artifact-bearing (noise-added) recordings are assembled from actual recordings by selecting intervals that contain predominantly motion artifact. To assemble the NST database, we analyzed 2000 synchronized electrocardiogram (ECG) and PPG recordings from MIMIC-II database. One-minute segments with the highest and lowest agreement between the ECG beats and the PPG pulses were selected using a semi-automated protocol. The resulting NST database included 52 artifact-free base recordings by visually selecting clean segments with normal pulse rate and rhythm, and 10 pure artifact recordings by selecting segments with negligible spectral content from the base signal. Cross combination of the base and artifact recordings, by calibrating the level of added artifact, generated 520 one-minute PPG signals for each desired signal-to-noise ratio (SNR). For each combined signal, the performance of automatic pulse detection and time-domain pulse rate variability analysis was evaluated by using the annotations from artifact-free base recordings as reference. © 2017 IEEE Computer Society. All rights reserved.},
  document_type = {Conference Paper},
  doi           = {10.22489/CinC.2017.140-293},
  issn          = {23258861},
  journal       = {Computing in Cardiology},
  keywords      = {Automation; Biomedical signal processing; Cardiology; Database systems; Electrocardiography; Nanostructured materials; Plates (structural components); Time domain analysis, Desired signal; Motion artifact; Noise stress test; Photoplethysmogram; Pulse detection; Pulse rate variability; Spectral content; Spectral overlap, Signal to noise ratio},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045102699&doi=10.22489%2fCinC.2017.140-293&partnerID=40&md5=55392dd15c0c8d98ed7fd91c05f068c8},
}

@Article{Hughes2017a,
  author          = {Hughes, N. and D’Agostino, A. and Reinerman-Jones, L.},
  title           = {The NRC human performance test facility: An approach to data collection using novices and a simplified environment},
  journal         = {Advances in Intelligent Systems and Computing},
  year            = {2017},
  volume          = {495},
  pages           = {183-192},
  issn            = {21945357},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In the spring of 2012, as part of a ‘hub and spoke’ model of research to address the human performance concerns related to current as well as new and advanced control room designs and operations, the U.S. Nuclear Regulatory Commission (NRC) sponsored a project to procure a low cost simulator to empirically measure and study human performance aspects of control room operations. Using this simulator, the Human Factors and Reliability Branch (HFRB) in the Office of Nuclear Regulatory Commission (NRC) began a program of research known as the NRC Human Performance Test Facility (HPTF) to collect empirical human performance data with the purpose of measuring and ultimately better understanding the various cognitive and physical elements that support safe control room operation. To accomplish this, HFRB first procured two 3-loop Westinghouse pressurized water reactor simulators with the capability to run a full range of power operation scenarios. HFRB staff work as co-investigators along with a team of researchers at the University of Central Florida (UCF) to design and carry-out a series of experiments aimed at measuring and understanding the human performance aspects of common control room tasks through the use of a variety of physiological and self-report metrics. The intent was to design experiments that balanced domain realism and laboratory control sufficiently to collect systematic, yet meaningful human performance data related to execution of common main control room (MCR) tasks. Investigators identified and defined three types of tasks that are examined in the present project: Checking, Detection, and Response Implementation. Task type presentation was partially counterbalanced to maintain ecologic validity with experimental control. A variety of subjective and physiological measures were used to understand performance of those tasks in terms ofworkload. The simulator used to collect these data was a digital representation of a generic analog NPP MCR interface. The data resulting from this experimentation enhances the current information gathering process, allowing for more robust technical bases to support regulatory guidance development and decision making. The present paper describes the approach behind this research effort. © Springer International Publishing Switzerland 2017.},
  author_keywords = {Decision-Making; Human performance; Main control room (MCR) tasks; Nuclear energy; Simulators},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-319-41950-3_16},
  editor          = {Cetiner S.M., Fechtelkotter P., Legatt M.},
  isbn            = {9783319419497},
  keywords        = {Decision making; Design; Electric industry; Human computer interaction; Human engineering; Nuclear energy; Physiology; Pressurized water reactors; Simulators; Software testing; Test facilities, Digital representations; Human performance; Information gathering; Main control room; Nuclear regulatory commission; Physiological measures; U.S. Nuclear Regulatory Commission; University of Central Florida, Data acquisition},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986325479&doi=10.1007%2f978-3-319-41950-3_16&partnerID=40&md5=9180947a138061bbe5a363f6e0e5d6d2},
}

@Conference{Vazquez2017,
  author        = {Vázquez, J. and Lacarra, E. and Sánchez, M.A. and Rioja, J. and Bruzual, J.},
  title         = {EDAS (EGNOS Data Access Service): Differential GPS corrections performance test with state-of-the-art precision agriculture system},
  year          = {2017},
  volume        = {3},
  pages         = {1988-1998},
  publisher     = {Institute of Navigation},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {EDAS (EGNOS Data Access Service) is the EGNOS internet broadcast service, which provides free of charge access to the data generated and collected by the EGNOS infrastructure. EDAS gathers all the raw data coming from the GPS, GLONASS and EGNOS GEO satellites collected by all the receivers located at the EGNOS reference stations, which are mainly distributed over Europe and North Africa. Once the data are received and processed, EDAS disseminates them over the Internet in real time and also through an FTP archive. The EDAS services portfolio is the result of various protocols and formats supported, along with several types of information made available to users by each service. This paper investigates the potential use of EDAS Differential GNSS corrections to support precision agriculture applications, by analysing the achieved performance during a dedicated in-field test campaign that has been conducted by ESSP and Topcon Agriculture. EDAS service provision is performed by ESSP, as EGNOS Service Provider, under contract with the European GNSS Agency (GSA), the EGNOS program manager. The European Commission (EC) is the owner of EGNOS system (including EDAS) and has delegated the exploitation of EGNOS to the GSA. ESSP also manages the EGNOS Helpdesk, which provides technical support to users by answering to any potential question or by providing clarifications about EGNOS services, thus including EDAS. In 2016, ESSP presented at the ION GNSS+ conference [21] the EDAS DGPS corrections performance achieved by applying EDAS DGPS corrections to the GNSS measurements from public reference GNSS stations (EUREF) at selected European locations in real-time during a 5-week period [21]. That study showed that horizontal accuracies below 1 meter (95th percentile) can be achieved using EDAS DGPS corrections up to a distance of 250 km from the designated EGNOS station and that, within that range, pass-to-pass accuracies (15 minutes, 95%) were expected to remain below 20 cm. However, those pass-to-pass results were considered preliminary since they were based on post-processed static data (according to ISO 12188-1) and needed to be confirmed by in-field tests, i.e. considering the environmental and dynamic conditions of farming operations. This year, ESSP complements the study presented last year by conducting in-field tests aiming at measuring the pass-to-pass accuracy that can be supported by EDAS DGPS corrections in a dynamic and real-life environment. In order to assess and validate the in-field tests, Topcon Agriculture joined ESSP for the activity. Topcon receivers, vehicles and guidance systems were used in order to confirm the suitability of the EDAS DGPS corrections for precision agriculture. Firstly, this paper introduces the EDAS system and its architecture, presenting the main types of data disseminated through its services and the online information available to the users. As part of this introduction, special attention is put on the description of the EDAS Ntrip service. This service has been the main enabler for the performance tests presented in the scope of this paper, since it provides differential corrections to the GPS and GLONASS satellites in RTCM format, taking the EGNOS stations as reference stations. Then, the paper describes the test scenarios and setups at the selected farm in Europe. Two different Topcon guidance systems on board tractors were running simultaneously to assess the EDAS DGPS positioning performance with respect to a reference, which was provided by an RTK-based Topcon solution. In each test, multiple runs with the rover tractor were performed over the reference patterns previously defined in the Topcon guidance systems. This paper presents a detailed analysis of the data recorded during the tests, especially in terms of the key performance indicators of the EDAS DGPS solution with respect to the RTK one. The in-field tests results show that the DGNSS corrections broadcast by EDAS could be a suitable solution for cereal farms (in particular for spraying/spreading of any crop type and tilling and harvesting of cereal), when located within a reasonable distance (below 250 km approximately) to the target EGNOS reference station. It is to be noted that cereal farms represent around 80% of the farms in Southern Europe. © 2017 Institute of Navigation. All rights reserved.},
  document_type = {Conference Paper},
  isbn          = {9781510853317},
  journal       = {30th International Technical Meeting of the Satellite Division of the Institute of Navigation, ION GNSS 2017},
  keywords      = {Automobile testing; Benchmarking; Geostationary satellites; Internet service providers; Ions; Orbits; Precision agriculture; Remote control; Tractors (truck), Agriculture applications; Differential correction; European Commission; Key performance indicators; On-line information; Positioning performance; Service provisions; Suitable solutions, Global positioning system},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047854102&partnerID=40&md5=5d084bdf401ccddebf32e10bf9c5028d},
}

@Book{Iyawe2016,
  title         = {User performance testing indicator: User performance indicator tool (UPIT)},
  publisher     = {IGI Global},
  year          = {2016},
  author        = {Iyawe, B.I.},
  isbn          = {9781522519454; 1522519440; 9781522519447},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {A growing area of research in Human Computer Interaction (HCI) and Human Robotic Interaction (HRI) is the development of haptic-based user performance testing. User performance testing Usability forms a vital part of these test objectives. As a result, diverse usability methods/strategies and test features are being employed. Apparently, with the robustness of haptic-based user performance testing features, user performance still has challenges. With this regard, it is vital to identify the direction and effectiveness of these methods/strategies and test features, and improvements required in the test objectives and evaluation. This chapter seeks to investigate the challenges of user performance and the user performance indicators in some HCI and HRI researches involving haptic-based test, as well as presents a User Performance Indicator Tool (UPIT) as a test validation tool to aid designers/testers in enhancing their user performance test and test evaluation outcomes. © 2017 by IGI Global. All rights reserved.},
  document_type = {Book Chapter},
  doi           = {10.4018/978-1-5225-1944-7.ch012},
  journal       = {Design Solutions for User-Centric Information Systems},
  keywords      = {Benchmarking; Waste disposal, Human computer interaction (HCI); Human-Robotic interaction; Test evaluation; Test validation; Usability methods; User performance, Human computer interaction},
  language      = {English},
  pages         = {205-229},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016030910&doi=10.4018%2f978-1-5225-1944-7.ch012&partnerID=40&md5=65317c99a77fda5cf26c6a75dec7bd1a},
}

@Conference{Amirante2016a,
  author        = {Amirante, A. and Castaldi, T. and Miniero, L. and Romanoy, S.P.},
  title         = {Jattack: A WebRTC load testing tool},
  year          = {2016},
  publisher     = {Institute of Electrical and Electronics Engineers Inc.},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {We present Jattack, an automated stressing tool for the analysis of the performance of WebRTC-enabled server-side components. Jattack has been initially conceived with the primary objective of performing a thorough scalability analysis of the well-known Janus WebRTC gateway. As such, it re-uses most of the Janus core stack components in order to reliably emulate the behavior of a dynamically adjustable number of WebRTC clients. The specific testing scenario can indeed be programmatically reproduced by writing a small controller component, which takes on the responsibility of properly orchestrating the scenario itself. The general-purpose nature of the tool, together with its flexibility deriving from the controller-based programmable approach, makes Jattack also suitable for stress-testing other WebRTC-enabled servers. © 2016 IEEE.},
  art_number    = {7780247},
  document_type = {Conference Paper},
  isbn          = {9781509042487},
  journal       = {2016 Principles, Systems and Applications of IP Telecommunications, IPTComm 2016},
  keywords      = {nocv2; Primary objective; Scalability analysis; Server sides; Stack components; Stress Testing, Load testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010826015&partnerID=40&md5=dad0d3fe13e598a4c5036c777646e9a2},
}

@Conference{Badarinath2016a,
  author          = {Badarinath, R. and Abhilash, M.T.},
  title           = {GP-GPU based high-performance test equipment for debugging radar digital units},
  year            = {2016},
  editor          = {R R.},
  pages           = {387-391},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Modern active phased array radars are made to optimize the size, weight and power without compromising its capability to combat with advanced electronic warfare. To accomplish this task, the signal is digitized at element level or at sub-array level and processed with the help of advanced digital signal processor. Proving the capabilities of this firmware at bench level helps to reduce the overall development time. Hence, it is necessary to have a built-in test unit or test vector generator to verify the optimal performance of digital modules. The best way to accomplish this goal is to use a high speed baseband I & Q radar data generator which helps in testing, identifying and segregating the problems at various stages. In this paper we have explored the capability of latest general purpose graphical processing unit (GP-GPU) as software defined built in test vector generator with high throughput for active array radar applications. © 2016 IEEE.},
  art_number      = {7684173},
  author_keywords = {Built-in test; CPU; Digital beamforming; GP-GPU; Radar signal processing},
  document_type   = {Conference Paper},
  doi             = {10.1109/SAPIENCE.2016.7684173},
  isbn            = {9781467385947},
  journal         = {Proceedings of 2016 International Conference on Data Mining and Advanced Computing, SAPIENCE 2016},
  keywords        = {Application programs; Data mining; Electronic warfare; Equipment testing; Firmware; Program processors; Radar; Radar signal processing; Signal processing; Software testing, Active phased array radar; Built in tests; Development time; Digital beam forming; Graphical processing unit (GPUs); High throughput; Optimal performance; Performance tests, Digital signal processors},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010288078&doi=10.1109%2fSAPIENCE.2016.7684173&partnerID=40&md5=ec77fc8c7b84de21a7b99497a096b23d},
}

@Conference{Zhang2016e,
  author          = {Zhang, H. and Nie, J.},
  title           = {Program performance test based on different computing environment},
  year            = {2016},
  editor          = {Chen G., Peng J.},
  pages           = {174-177},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {To test the efficiency of different programming languages and find out the suitable one for solving the calculation problem of spherical distance between two points, we have developed serial and parallel calculate algorithms according C, Python programming languages, and tested the execution speed of all algorithms. As for the inefficiency of Python, we improved the performance by replacing some functions and variables of Python procedure with Cython. The experimental results show that Python programs can get the same execution efficiency as C language does with the same Large-scale computing environment. © 2016 IEEE.},
  art_number      = {7563073},
  author_keywords = {C; Cython; Efficiency; Python},
  document_type   = {Conference Paper},
  doi             = {10.1109/ICOACS.2016.7563073},
  isbn            = {9781467377546},
  journal         = {Proceedings of 2016 IEEE International Conference of Online Analysis and Computing Science, ICOACS 2016},
  keywords        = {Cesium; Computer software; Efficiency; High level languages; Software testing, C language; Computing environments; Cython; Execution speed; Large-scale computing; Program performance; Python; Python programming language, C (programming language)},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989201306&doi=10.1109%2fICOACS.2016.7563073&partnerID=40&md5=955663ceab67b07421492c1009b711ac},
}

@Conference{Gao2016a,
  author        = {Gao, R. and Jiang, Z.M. and Barna, C. and Litoiu, M.},
  title         = {A Framework to Evaluate the Effectiveness of Different Load Testing Analysis Techniques},
  year          = {2016},
  pages         = {22-32},
  publisher     = {Institute of Electrical and Electronics Engineers Inc.},
  note          = {cited By 2},
  __markedentry = {[Jonnathan:]},
  abstract      = {Large-scale software systems like Amazon and eBay must be load tested to ensure they can handle hundreds and millions of current requests in the field. Load testing usually lasts for a few hours or even days and generates large volumes of system behavior data (execution logs and counters). This data must be properly analyzed to check whether there are any performance problems in a load test. However, the sheer size of the data prevents effective manual analysis. In addition, unlike functional tests, there is usually no test oracle associated with a load test. To cope with these challenges, there have been many analysis techniques proposed to automatically detect problems in a load test by comparing the behavior of the current test against previous test(s). Unfortunately, none of these techniques compare their performance against each other. In this paper, we have proposed a framework, which evaluates and compares the effectiveness of different test analysis techniques. We have evaluated a total of 23 test analysis techniques using load testing data from three open source systems. Based on our experiments, we have found that all the test analysis techniques can effectively build performance models using data from both buggy or non-buggy tests and flag the performance deviations between them. It is more cost-effective to compare the current test against two recent previous test(s), while using testing data collected under longer sampling intervals (≤ 180 seconds). Among all the test analysis techniques, Control Chart, Descriptive Statistics and Regression Tree yield the best performance. Our evaluation framework and findings can be very useful for load testing practitioners and researchers. To encourage further research on this topic, we have made our testing data publicity available to download. © 2016 IEEE.},
  art_number    = {7515456},
  document_type = {Conference Paper},
  doi           = {10.1109/ICST.2016.9},
  isbn          = {9781509018260},
  journal       = {Proceedings - 2016 IEEE International Conference on Software Testing, Verification and Validation, ICST 2016},
  keywords      = {Cost effectiveness; Internet; Load testing; Open source software; Open systems; Testing; Verification, Analysis techniques; Descriptive statistics; Evaluation framework; Large-scale software systems; Open source system; Performance Model; Performance problems; Sampling interval, Software testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983371864&doi=10.1109%2fICST.2016.9&partnerID=40&md5=1d9771caa8bdbddfadf6f49f1344fac2},
}

@Article{Doumpos2016,
  author          = {Doumpos, M. and Zopounidis, C. and Fragiadakis, P.},
  title           = {Assessing the financial performance of European banks under stress testing scenarios: a multicriteria approach},
  journal         = {Operational Research},
  year            = {2016},
  volume          = {16},
  number          = {2},
  pages           = {197-209},
  issn            = {11092858},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The European banking system has been under considerable pressure since the beginning of the financial crisis in 2007–2008. Except for the global credit crunch, the European sovereign debt crisis has created additional difficulties. In response to the need for increasing the transparency and stability in the European financial/banking system and identifying weaknesses in banks’ capital structures, EU-wide stress tests have been performed by the European Banking Authority (EBA) on a regular basis since 2010. In this context, the aim of this study is to examine the financial performance of the European banks that have participated in the stress tests of EBA. The analysis takes into account the actual financial data of the banks, on the basis of the Capital, Assets, Management, Earnings, Liquidity framework, as well the results of the stress tests. The evaluation of the banks’ financial strength is performed through a robust multicriteria decision aid classification methodology. The latter is used to distinguish between the banks, which failed to meet the minimum capital requirement conditions imposed by EBA, and the well-capitalized ones. © 2015, Springer-Verlag Berlin Heidelberg.},
  author_keywords = {Banking; Financial risk management; Multicriteria decision aid; Robustness; Stress tests},
  document_type   = {Article},
  doi             = {10.1007/s12351-015-0192-y},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938633534&doi=10.1007%2fs12351-015-0192-y&partnerID=40&md5=df37ca7e951d98caa6526fadbafb7b56},
}

@Conference{Loescher2016,
  author          = {Loescher, D. and Tasker, P. and Cripps, S.},
  title           = {Using waveform engineering to understand the impact of harmonic terminations during 5:1 VSWR stress tests},
  year            = {2016},
  pages           = {49-52},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {There are many applications where the operational environment of the antenna is challenging, which means its impedance can be highly variable, so the RF PA needs to be able to operate over a wide variety of loads without stress or failure. Assessing this is a key requirement of reliability testing, with VSWR sweeps being a typical way to test this durability. It is important to make sure the amount of information gained from these sweeps is maximized, so adding RF I-V waveform information can help give a more accurate view of what is occurring at the current generator plane. Also if the fundamental and second harmonic loads are systematically swept significant voltage stress, possibly not seen during the current conventional VSWR tests, is observed, which has implications in both the output matching network design and the current method of testing. © 2016 IEEE.},
  art_number      = {7440161},
  author_keywords = {Failure Testing; HBT; Reliability Tests; VSWR; Waveform Engineering},
  document_type   = {Conference Paper},
  doi             = {10.1109/PAWR.2016.7440161},
  isbn            = {9781509016846},
  journal         = {PAWR 2016 - Proceedings of the 2016 IEEE Topical Conference on Power Amplifiers for Wireless and Radio Applications},
  keywords        = {Heterojunction bipolar transistors; Outages; Power amplifiers; Radio frequency amplifiers, Amount of information; Failure testing; Harmonic termination; Operational environments; Output matching network; Reliability test; VSWR; Waveform engineerings, Durability},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966649865&doi=10.1109%2fPAWR.2016.7440161&partnerID=40&md5=6e28b1da72fd82a034cbc897b4a86388},
}

@Conference{Ali2016,
  author          = {Ali, A. and Badr, N.},
  title           = {Performance testing as a service for web applications},
  year            = {2016},
  pages           = {356-361},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  note            = {cited By 2},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Software testing is a vital activity that is undertaken during software engineering life cycle to ensure software quality and reliability. Performance testing is a type of software testing that is done to shows how web application behaves under a certain workload. Cloud computing as an emerging technology can be used in the field of software engineering to provide cloud testing in order to overcome all deficiencies of conventional testing by leveraging cloud computing resources. As a result, testing-as-a-service (TaaS) is introduced as a service model that performs all testing activities in fully automated manner, on demand with a pay-for use basis. Moreover, TaaS increases testing efficiency and reduces time and cost required for testing. In this paper, performance TaaS framework for web applications is introduced which provides all performance testing activities including automatic test case generation and test execution. In addition, the proposed framework addresses many issues as: maximize resource utilization and continuous monitoring to ensure system reliability. © 2015 IEEE.},
  art_number      = {7397245},
  author_keywords = {Cloud Computing; JMeter; Performance Testing; TaaS; web Application Testing},
  document_type   = {Conference Paper},
  doi             = {10.1109/IntelCIS.2015.7397245},
  isbn            = {9781509019496},
  journal         = {2015 IEEE 7th International Conference on Intelligent Computing and Information Systems, ICICIS 2015},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970028353&doi=10.1109%2fIntelCIS.2015.7397245&partnerID=40&md5=8580276deea4cb30386089a2e973c6c3},
}

@Conference{Lee2016a,
  author        = {Lee, S.-J. and Lin, Y.-C. and Lin, K.-H. and You, J.-L.},
  title         = {A framework for composing heterogeneous service tools involved in load testing lifecycle},
  year          = {2016},
  editor        = {Lam A.D.K.-T., Prior S.D., Meen T.-H.},
  pages         = {1075-1080},
  publisher     = {CRC Press/Balkema},
  note          = {cited By 1},
  __markedentry = {[Jonnathan:]},
  abstract      = {Load testing is the process of applying ordinary stress to a software system to determine the system performance under normal conditions. In a typical load testing lifecycle, three kinds of service tools are involved: test case recording service tools that make testers easier to generate test cases through a web browsing-like behavior; test case execution service tools that exercise test cases with simulations of a large number of concurrent users; system resource monitoring service tools that provide information of system footprints during the test case executions. However, using these three kinds of service tools one by one to complete a load testing may require extra effort on operating and configuring each service. In this paper, we proposed a framework for composing the three types of service tools as an integrated service for load testing. A raw test case recorded by Badboy tool is automatically converted into an expanded test case that can be executed by JMeter. JMeter and Cacti are then automatically invoked by the framework. The execution time period of JMeter is automatically identified as the input to Cacti for resource monitoring of the system under test. The test report together with system footprints is also automatically generated. In the experimental evaluation, the result shows that the framework significantly save time on operating and configuring the load testing service tools than the traditional approach under a t-test. © 2016 Taylor & Francis Group.},
  document_type = {Conference Paper},
  isbn          = {9781138028937},
  journal       = {Applied System Innovation - Proceedings of the International Conference on Applied System Innovation, ICASI 2015},
  keywords      = {Automatic test pattern generation; Life cycle; Load testing; Monitoring; Network function virtualization, Automatically generated; Experimental evaluation; Heterogeneous services; Integrated service; Resource monitoring; System footprints; System under test; Traditional approaches, Software testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016787389&partnerID=40&md5=2dbe54dbd4b63665e9e4ad3a1aac50ac},
}

@Conference{Brady2016,
  author        = {Brady, J.F. and Gunther, N.J.},
  title         = {How to emulate web traffic using standard load testing tools},
  year          = {2016},
  publisher     = {Computer Measurement Group Inc},
  note          = {cited By 1},
  __markedentry = {[Jonnathan:]},
  abstract      = {Conventional load-testing tools are based on a fifty-year old time-share computer paradigm where a finite number of users submit requests and respond in a synchronized fashion. Con- versely, modern web traffic is essentially asynchronous and driven by an unknown number of users. This difference presents a conundrum for testing the performance of modern web applications. Even when the difference is recognized, performance engineers often introduce modifications to their test scripts based on folklore or hearsay published in various Internet fora, much of which can lead to wrong results. We present a coherent methodology, based on two fundamental principles, for emulating web traffic using a standard load-test environment.},
  document_type = {Conference Paper},
  journal       = {imPACt 2016 - Internet, Mobile, Performance and Capacity, Cloud and Technology},
  keywords      = {Finite number; Fundamental principles; Standard loads; Test Environment; Test scripts; Testing tools; WEB application; Web traffic, Load testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014705823&partnerID=40&md5=579c4676d314db0214794c3eeb488543},
}

@Article{Eljuse2016a,
  author          = {Eljuse, B. and Walkinshaw, N.},
  title           = {A search based approach for stress-testing integrated circuits},
  journal         = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year            = {2016},
  volume          = {9962 LNCS},
  pages           = {80-95},
  issn            = {03029743},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In order to reduce software complexity and be power efficient, hardware platforms are increasingly incorporating functionality that was traditionally administered at a software-level (such as cache management). This functionality is often complex, incorporating multiple processors along with a multitude of design parameters. Such devices can only be reliably tested at a ‘system’ level, which presents various testing challenges; behaviour is often non-deterministic (from a software perspective), and finding suitable test sets to ‘stress’ the system adequately is often an inefficient, manual activity that yields fixed test sets that can rarely be reused. In this paper we investigate this problem with respect to ARM’s Cache Coherent Interconnect (CCI) Unit. We present an automated search-based testing approach that combines a parameterised testgeneration framework with the hill-climbing heuristic to find test sets that maximally ‘stress’ the CCI by producingmuch larger numbers of data stall cycles than the corresponding manual test sets. © Springer International Publishing AG 2016.},
  author_keywords = {Automated search based testing; Cache coherent interconnect; System level stress testing},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-319-47106-8_6},
  editor          = {Sarro F., Deb K.},
  isbn            = {9783319471051},
  keywords        = {Integrated circuit interconnects; Integrated circuits; Reconfigurable hardware; Software engineering, Automated searches; Cache coherent interconnect; Cache management; Design parameters; Hardware platform; Multiple processors; Software complexity; Stress Testing, Software testing},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989854375&doi=10.1007%2f978-3-319-47106-8_6&partnerID=40&md5=9aa6e339b3fbf686d39d076481f7f5a7},
}

@Article{Meira2016,
  author        = {Meira, J.A. and de Almeida, E.C. and Kim, D. and Filho, E.R.L. and Le Traon, Y.},
  title         = {“Overloaded! ” — A model-based approach to database stress testing},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year          = {2016},
  volume        = {9827 LNCS},
  pages         = {207-222},
  issn          = {03029743},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {As a new era of “Big Data” comes, contemporary database management systems (DBMS) introduced new functions to satisfy new requirements for big volume and velocity applications. Although the development agenda goes at full pace, the current testing agenda does not keep up, especially to validate non-functional requirements, such as: performance and scalability. The testing approaches strongly rely on the combination of unit testing tools and benchmarks. There is still a testing methodology missing, in which testers can model the runtime environment of the DBMS under test, defining the testing goals and the harness support for executing test cases. The major contribution of this paper is the MoDaST (Model-based Database Stress Testing) approach that leverages a state transition model to reproduce a runtime DBMS with dynamically shifting workload volumes and velocity. Each state in the model represents the possible running states of the DBMS. Therefore, testers can define state goals or specific state transitions that revealed bugs. Testers can also use MoDaST to pinpoint the conditions of performance loss and thrashing states. We put MoDaST to practical application testing two popular DBMS: PostgreSQL and VoltDB. The results show that MoDaST can reach portions of source code that are only possible with non-functional testing. Among the defects revealed by MoDaST, when increasing the code coverage, we highlight a defect confirmed by the developers of VoltDB as a major bug and promptly fixed. © Springer International Publishing Switzerland 2016.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-319-44403-1_13},
  editor        = {Hartmann S., Ma H.},
  isbn          = {9783319444024},
  keywords      = {Big data; Defects; Expert systems; Information management, Application testing; Model based approach; Non-functional requirements; Performance and scalabilities; Performance loss; Runtime environments; State transition models; Testing methodology, Database systems},
  language      = {English},
  publisher     = {Springer Verlag},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981273802&doi=10.1007%2f978-3-319-44403-1_13&partnerID=40&md5=5788b9fa12d0eb5a527227c8b72064a8},
}

@Conference{Tomm2016,
  author          = {Tomm, J.W. and Hempel, M. and Venables, D. and Rossin, V. and Zucker, E. and Elsaesser, T.},
  title           = {Rapid stress-testing vs. long-term aging: A case study of 980-nm emitting single-spatial mode lasers},
  year            = {2016},
  editor          = {Zediker M.S.},
  volume          = {9733},
  publisher       = {SPIE},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The degradation behaviors of 980-nm emitting nominally identical single-spatial mode lasers are studied during continuous wave long-term operation and during single-pulse stress tests. Both tests activate internal catastrophic optical damage as sudden degradation mechanism limiting the device lifetime. In case of high power stress-testing, the mechanism that initializes this effect is a spatial widening of the optical mode, resulting in increased absorption outside the waveguide. A similar disturbance to the optical mode is caused by defects that are generated during long-term operation. Thus two very different aging regimes eventually result in the same degradation scenario. We find that singlepulse stress-testing allows for activation of several degradation mechanisms in a device one after the other. Moreover, it becomes possible to distinguish between effects induced by gradual degradation and such that are independent on operation time. Thus stress-testing is considered a complementary tool, which might pave the way towards more economic device testing. © 2016 SPIE.},
  art_number      = {973303},
  author_keywords = {Device reliability; Diode laser; Long-term aging; Single-pulse test; Single-spatial mode laser},
  coden           = {PSISD},
  document_type   = {Conference Paper},
  doi             = {10.1117/12.2208256},
  isbn            = {9781628419689},
  issn            = {0277786X},
  journal         = {Proceedings of SPIE - The International Society for Optical Engineering},
  keywords        = {Continuous wave lasers; Degradation; Diodes; Laser applications; Laser beam welding; Power semiconductor diodes, Catastrophic optical damages; Complementary tools; Degradation behavior; Degradation mechanism; Device reliability; Long-term aging; Single pulse; Spatial modes, Semiconductor lasers},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978785818&doi=10.1117%2f12.2208256&partnerID=40&md5=ef4ecf94a013514b58f9a1a89b599644},
}

@Article{Agrawal2016,
  author        = {Agrawal, D. and Butt, A. and Doshi, K. and Larriba-Pey, J.-L. and Li, M. and Reiss, F.R. and Raab, F. and Schiefer, B. and Suzumura, T. and Xia, Y.},
  title         = {Sparkbench – A spark performance testing suite},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year          = {2016},
  volume        = {9508},
  pages         = {26-44},
  issn          = {03029743},
  note          = {cited By 5},
  __markedentry = {[Jonnathan:]},
  abstract      = {Spark has emerged as an easy to use, scalable, robust and fast system for analytics with a rapidly growing and vibrant community of users and contributors. It is multipurpose—with extensive and modular infrastructure for machine learning, graph processing, SQL, streaming, statistical processing, and more. Its rapid adoption therefore calls for a performance assessment suite that supports agile development, measurement, validation, optimization, configuration, and deployment decisions across a broad range of platform environments and test cases. Recognizing the need for such comprehensive and agile testing, this paper proposes going beyond existing performance tests for Spark and creating an expanded Spark performance testing suite. This proposal describes several desirable properties flowing from the larger scale, greater and evolving variety, and nuanced requirements of different applications of Spark. The paper identifies the major areas of performance characterization, and the key methodological aspects that should be factored into the design of the proposed suite. The objective is to capture insights from industry and academia on how to best characterize capabilities of Spark-based analytic platforms and provide cost-effective assessment of optimization opportunities in a timely manner. © Springer International Publishing Switzerland 2016.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-319-31409-9_3},
  editor        = {Nambiar R., Poess M.},
  isbn          = {9783319314082},
  keywords      = {Artificial intelligence; Big data; Cost effectiveness; Learning systems, Agile development; Graph processing; Methodological aspects; Performance assessment; Performance characterization; Performance testing; Performance tests; Statistical processing, Benchmarking},
  language      = {English},
  publisher     = {Springer Verlag},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961621850&doi=10.1007%2f978-3-319-31409-9_3&partnerID=40&md5=2e6483159c4148784466ccb01f282d91},
}

@Article{Meng2016,
  author          = {Meng, L.},
  title           = {Application of fiber bragg grating sensing technology in welding stress test},
  journal         = {International Journal of Simulation: Systems, Science and Technology},
  year            = {2016},
  volume          = {17},
  number          = {39},
  pages           = {46.1-46.4},
  issn            = {14738031},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Welding structures are widely used in various engineering fields. Effective monitoring of stress and temperature during welding process will help to take measures to control the welding deformation. In this paper, the monitoring method of welding stress and temperature based on fiber Bragg grating (FBG) sensor network is presented. First: i) the reliability and effectiveness of the FBG monitoring system in high temperature environment were studied, then ii) the distributed FBG sensing system was used to monitor the online welding stress of the aluminum alloy plates during the butt welding and groove welding processes. The welding stress was detected by the FBG networks in turn according to the welding sequence, and the closer the FBG was to welding seam, the greater the welding stress was. The welding stress caused by groove welding was smaller than that of the butt welding. © 2016, UK Simulation Society. All rights reserved.},
  author_keywords = {Fiber Bragg grating (FBG); High temperature strain; On line detection; Welding stress},
  document_type   = {Article},
  doi             = {10.5013/IJSSST.a.17.39.46},
  language        = {English},
  publisher       = {UK Simulation Society},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017097198&doi=10.5013%2fIJSSST.a.17.39.46&partnerID=40&md5=cc02e2361f3209999e75c498cfcd9a83},
}

@Conference{Podelko2016,
  author        = {Podelko, A.},
  title         = {Reinventing performance testing},
  year          = {2016},
  publisher     = {Computer Measurement Group Inc},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {Load testing is an important part of the performance engineering process. However the industry is changing and load testing should adjust to these changes - a stereotypical, last-moment performance check is not enough anymore. There are multiple aspects of load testing - such as environment, load generation, testing approach, life-cycle integration, feedback and analysis - and none remains static. This presentation discusses how performance testing is adapting to industry trends to remain relevant and bring value to the table.},
  document_type = {Conference Paper},
  journal       = {imPACt 2016 - Internet, Mobile, Performance and Capacity, Cloud and Technology},
  keywords      = {Life cycle; Load testing, Industry trends; Life cycle integration; Performance engineering; Performance testing, Integration testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014599093&partnerID=40&md5=787544e6e98388a8232ce53a9f8691d7},
}

@Conference{Wang2016,
  author          = {Wang, C. and Hu, S. and Gao, C. and Feng, C.},
  title           = {Performance test and image correction of CMOS image sensor in radiation environment},
  year            = {2016},
  editor          = {To S., Zhang Y., Xu M., Wu F.},
  volume          = {9684},
  publisher       = {SPIE},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {CMOS image sensors rival CCDs in domains that include strong radiation resistance as well as simple drive signals, so it is widely applied in the high-energy radiation environment, such as space optical imaging application and video monitoring of nuclear power equipment. However, the silicon material of CMOS image sensors has the ionizing dose effect in the high-energy rays, and then the indicators of image sensors, such as signal noise ratio (SNR), non-uniformity (NU) and bad point (BP) are degraded because of the radiation. The radiation environment of test experiments was generated by the 60Co γ-rays source. The camera module based on image sensor CMV2000 from CMOSIS Inc. was chosen as the research object. The ray dose used for the experiments was with a dose rate of 20krad/h. In the test experiences, the output signals of the pixels of image sensor were measured on the different total dose. The results of data analysis showed that with the accumulation of irradiation dose, SNR of image sensors decreased, NU of sensors was enhanced, and the number of BP increased. The indicators correction of image sensors was necessary, as it was the main factors to image quality. The image processing arithmetic was adopt to the data from the experiences in the work, which combined local threshold method with NU correction based on non-local means (NLM) method. The results from image processing showed that image correction can effectively inhibit the BP, improve the SNR, and reduce the NU. © 2016 SPIE.},
  art_number      = {96841H},
  author_keywords = {CMOS image sensor; Image processing; Performance test; Ray radiation},
  coden           = {PSISD},
  document_type   = {Conference Paper},
  doi             = {10.1117/12.2243427},
  isbn            = {9781628419191},
  issn            = {0277786X},
  journal         = {Proceedings of SPIE - The International Society for Optical Engineering},
  keywords        = {CMOS integrated circuits; Digital cameras; Digital storage; Equipment; Gamma rays; Image reconstruction; Image sensors; Ionizing radiation; Manufacture; Optical data processing; Optical testing; Pixels; Radiation; Signal to noise ratio, CMOS image sensor; High energy radiation; Non local means (NLM); Nuclear power equipments; Performance tests; Radiation environments; Radiation resistance; Ray radiation, Image processing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002057635&doi=10.1117%2f12.2243427&partnerID=40&md5=71170e9918b708c4c0bbf49fb073825a},
}

@Conference{Kanstren2015a,
  author          = {Kanstren, T. and Aho, P. and Lamsa, A. and Martin, H. and Liikka, J. and Seppanen, M.},
  title           = {Robot-assisted smartphone performance testing},
  year            = {2015},
  volume          = {2015-August},
  publisher       = {IEEE Computer Society},
  note            = {cited By 3},
  __markedentry   = {[Jonnathan:]},
  abstract        = {This paper describes experiences and lessons learned in applying an approach of using a physical robot for testing overall smartphone device performance based on user profiles. The process consists of capturing user actions, abstracting them to usage profiles, transforming these into test models, and generating test cases from the models. The goal is to support performance testing of touch screen devices and applications in a realistic test environment. To achieve this, the tests are based on real-world generated user profiles and executed using a real physical robot, simulating the actual user. Our performance testing targets different attributes of performance such as response times, power and resource usage, and software/hardware aging. Use of different hardware and software configurations in the test scenarios is considered. This work has been performed in close collaboration with industry partners in robotics provider and user industries. © 2015 IEEE.},
  art_number      = {7219669},
  author_keywords = {Electronic mail; Markov processes; Performance evaluation; Robot kinematics; Service robots; Testing},
  document_type   = {Conference Paper},
  doi             = {10.1109/TePRA.2015.7219669},
  isbn            = {9781479987573; 9781479987573},
  issn            = {23250526},
  journal         = {IEEE Conference on Technologies for Practical Robot Applications, TePRA},
  keywords        = {Electronic mail; Human computer interaction; Markov processes; Robot applications; Robots; Signal encoding; Smartphones; Testing; Touch screens, Collaboration with industries; Device performance; Hardware and software; Performance evaluation; Performance testing; Robot kinematics; Service robots; Software/hardware, Software testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949987453&doi=10.1109%2fTePRA.2015.7219669&partnerID=40&md5=5f8ef052ff3ebaaa9ff7abb803f38181},
}

@Article{Liu2015,
  author          = {Liu, C. and Nassar, R. and Guo, M.},
  title           = {A method of retail mortgage stress testing: Based on time-frame and magnitude analysis},
  journal         = {Journal of Forecasting},
  year            = {2015},
  volume          = {34},
  number          = {4},
  pages           = {261-274},
  issn            = {02776693},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In this study, a non-stationary Markov chain model and a vector autoregressive moving average with exogenous variables coupled with a logistic function (VARMAX-L) are used to analyze and predict the stability of a retail mortgage portfolio, based on the stress test framework. The method introduced in this paper can be used to forecast the transition probabilities in a retail mortgage over pre-specified states, given a shock with a certain magnitude. Hence this method provides a dynamic picture of the portfolio transition process through which one can assess its behavior over time. While the paper concentrates on retail mortgages, the methodology of this study can be adapted also to analyze other credit products in banks. Copyright © 2015 John Wiley & Sons, Ltd.},
  author_keywords = {asset distribution; non-stationary Markov chain; retail mortgages; VARMAX-L modeling},
  coden           = {JOFOD},
  document_type   = {Article},
  doi             = {10.1002/for.2326},
  keywords        = {Chains; Markov processes, Asset distribution; Magnitude analysis; Markov chain models; Nonstationary; Retail mortgages; Transition probabilities; Transition process; Vector autoregressive moving averages, Sales},
  language        = {English},
  publisher       = {John Wiley and Sons Ltd},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932194518&doi=10.1002%2ffor.2326&partnerID=40&md5=e507be50a628ae69faf03803daeeb677},
}

@Article{Ramasamy2015a,
  author          = {Ramasamy, G. and Ramalingam, S.},
  title           = {An effective automation testing framework for OATS tool},
  journal         = {Advances in Intelligent Systems and Computing},
  year            = {2015},
  volume          = {324},
  pages           = {543-550},
  issn            = {21945357},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Oracle application test suite (OATS) is a test tool of Oracle. It is a very good integrated testing tool for Web applications, Web services, Oracle applications, and Oracle databases. The Oracle application testing suite is part of the Oracle Enterprise Manager product family and comprises the following tightly integrated products. They are Oracle load testing for scalability, performance and load testing, Oracle functional testing for automated functional and regression testing, and Oracle Test Manager for test process management, including test requirements management, test management, test execution, and defect tracking. OATS uses OpenScript platform. This paper discusses model-based test automation methods and tools referred to collectively as the Test Automation Framework that reduces the time and resources necessary to develop high-quality and high-assurance systems using OATS functional testing tool. Framework is named as Easy to Automate (Ez2Auto) framework. This OATS tool is newly available in market, and there is no established framework available in literature or ready to use in market. © Springer India 2015.},
  author_keywords = {Automation test Framework; Ez2Auto; OATS; Open script; Oracle application test suite},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-81-322-2126-5_59},
  editor          = {Suresh L.P., Dash S.S., Panigrahi B.K.},
  isbn            = {9788132221258},
  keywords        = {Artificial intelligence; Automation; Commerce; Evolutionary algorithms; Managers; Social networking (online); Software testing; Web services, Automation tests; Ez2Auto; OATS; Open script; Oracle application test suite, Load testing},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84914706463&doi=10.1007%2f978-81-322-2126-5_59&partnerID=40&md5=c670c19b0aae240db51a1729308c3526},
}

@Conference{Gojare2015b,
  author          = {Gojare, S. and Joshi, R. and Gaigaware, D.},
  title           = {Analysis and design of selenium webdriver automation testing framework},
  year            = {2015},
  editor          = {Vijayakumar V., Neelanarayanan V.},
  volume          = {50},
  pages           = {341-346},
  publisher       = {Elsevier B.V.},
  note            = {cited By 2},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Nowadays, number of software system has been implemented as web-based applications. These web applications are very complex. It is very difficult to test such complex web applications. Automation testing uses automation tools to reduce human intervention and repeatable tasks. In this paper we have designed and implemented automation testing framework for testing web applications. This new automation testing framework has been implemented using selenium WebDriver tool. Using this framework tester can easily write their test cases efficiently and in less time. Tester need not to study the selenium webdriver tool in detail. This framework is helpful to developer to analyze their code due to screen shot property of framework. This framework produces the customized test report to tester. It is very easy to maintain and repair the test suite for new release of the application using this framework. © 2015 The Authors. Published by Elsevier B.V.},
  author_keywords = {Automation testing; Automation testing framework; Selenium webdriver; Web applications},
  document_type   = {Conference Paper},
  doi             = {10.1016/j.procs.2015.04.038},
  issn            = {18770509},
  journal         = {Procedia Computer Science},
  keywords        = {Application programs; Automation; Selenium; Social networking (online); World Wide Web, Automation testing; Automation tools; Human intervention; Software systems; Test case; Test reports; WEB application; Web-based applications, Big data},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937433268&doi=10.1016%2fj.procs.2015.04.038&partnerID=40&md5=0eeb3271cfcbfdc378cc96a479174f52},
}

@Conference{Podelko2015,
  author        = {Podelko, A.},
  title         = {Multiple dimensions of load testing},
  year          = {2015},
  publisher     = {Computer Measurement Group Inc},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {Load testing is an important part of the performance engineering process. It remains the main way to ensure appropriate performance and reliability in production. It is important to see a bigger picture beyond stereotypical, last-moment load testing. There are multiple dimensions of load testing: environment, load generation, testing approach, life-cycle integration, feedback and analysis. This paper discusses these dimensions and how load testing tools support them.},
  document_type = {Conference Paper},
  journal       = {41st International IT Capacity and Performance Conference},
  keywords      = {Life cycle; Load testing, Life cycle integration; Multiple dimensions; Performance and reliabilities; Performance engineering; Testing tools, Integration testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959387281&partnerID=40&md5=f952a63b9d0c58597d09b5c0fc4d4bae},
}

@Article{Yan2015,
  author          = {Yan, M. and Sun, H. and Liu, X. and Deng, T. and Wang, X.},
  title           = {Delivering Web service load testing as a service with a global cloud},
  journal         = {Concurrency Computation},
  year            = {2015},
  volume          = {27},
  number          = {3},
  pages           = {526-545},
  issn            = {15320626},
  note            = {cited By 2},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In this paper, we present WS-TaaS, a Web services load testing platform built on a global platform PlanetLab. WS-TaaS enables load testing process to be simple, transparent, and as close as possible to the real running scenarios of the target services. First, we briefly introduce the base of WS-TaaS, Service4All. Second, we provide detailed analysis of the requirements of Web service load testing and present its conceptual architecture as well as algorithm design for improving resource utilization. Third, we present the implementation details of WS-TaaS. Finally, we perform the evaluation of WS-TaaS with a set of experiments based on the testing of real Web services, and the results illustrate that WS-TaaS can efficiently facilitate the whole process of Web service load testing. Especially, comparing with existing testing tools, WS-TaaS can obtain more effective and accurate test results. © 2014 John Wiley & Sons, Ltd.},
  author_keywords = {cloud computing; load testing; PlanetLab; Service4All; testing as a service; Web services},
  coden           = {CCPEB},
  document_type   = {Article},
  doi             = {10.1002/cpe.3246},
  keywords        = {Cloud computing; Load testing; Social networking (online); Websites, Algorithm design; Conceptual architecture; PlanetLab; Resource utilizations; Service4All; Target services; Testing as a services; Testing platforms, Web services},
  language        = {English},
  publisher       = {John Wiley and Sons Ltd},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923531339&doi=10.1002%2fcpe.3246&partnerID=40&md5=fab50868c29f35578b97912d14daa5c6},
}

@Conference{Chajes2015,
  author        = {Chajes, M. and Shenton, H. and Al-Khateeb, H. and Wenczel, G. and Ramanna, N.},
  title         = {Structural health monitoring of the Indian River Inlet bridge: Results from controlled load tests conducted over the first two years of service},
  year          = {2015},
  editor        = {De Stefano A.},
  publisher     = {International Society for Structural Health Monitoring of Intelligent Infrastructure, ISHMII},
  note          = {cited By 1},
  __markedentry = {[Jonnathan:]},
  abstract      = {The Indian River Inlet Bridge (IRIB), a 533-meter long cable stayed bridge, was opened for traffic in 2012. From the very early stages of the design process, the Center for Innovative Bridge Engineering (CiBRe) at the University of Delaware (UD) worked with the Delaware Department of Transportation (DelDOT) and their design-build team of Skanska and AECOM to plan and install a comprehensive structural health monitoring (SHM) system. This is believed to be the first of its kind in the United States. The system continuously monitors the long-term performance of the bridge during normal operation and short-term performance during controlled load tests and extreme events. The SHM system is a fiber-optic based design with more than 120 sensors of varying type distributed throughout the bridge. Data from the system is being integrated into the bridge maintenance and inspection records for the bridge and will facilitate DelDOT's ability to maintain and operate the bridge throughout its life. This paper provides an overview of the SHM system while focusing on results from four controlled load tests that have been conducted over the first two years of service. The tests have enabled the developement of a robust FE model and are being used to establish and track the performance of the bridge from its initial "baseline" response. © 2015, International Society for Structural Health Monitoring of Intelligent Infrastructure, ISHMII. All rights reserved.},
  document_type = {Conference Paper},
  journal       = {SHMII 2015 - 7th International Conference on Structural Health Monitoring of Intelligent Infrastructure},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978696294&partnerID=40&md5=319cb82120839f783cb23001887955f3},
}

@Article{Mate2015,
  author          = {Maté, A. and Trujillo, J. and Mylopoulos, J.},
  title           = {Stress testing strategic goals with SWOT analysis},
  journal         = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year            = {2015},
  volume          = {9381},
  pages           = {65-78},
  issn            = {03029743},
  note            = {cited By 2},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Business strategies are intended to guide a company across the mine fields of competitive markets through the fulfilment of strategic objectives. The design of a business strategy generally considers a SWOT operating context consisting of inherent Strengths (S) and Weaknesses (W) of a company, as well as external Opportunities (O) and potential Threats (T) that the company may be facing. Given an ever-changing and uncertain environment, it is important to continuously maintain an updated view of the operating context, in order to determine whether the current strategy is adequate. However, traditional SWOT analysis only provides support for the initial design of business strategy, as opposed to on-going analysis as new, unexpected factors appear and disappear. This paper proposes a systematic analysis for business strategy founded on models of strategic goals and stress test scenarios. Our proposal allows us to improve decision making by (i) supporting continuous scenario analysis based on current and future context and, (ii) identifying and comparing strategic alternatives and courses of action that would lead to better results. © Springer International Publishing Switzerland 2015.},
  author_keywords = {Analysis; Business intelligence; KPIs; Strategic goals; SWOT},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-319-25264-3_5},
  editor          = {Lopez O.P., Lee M.L., Liddle S.W., Johannesson P., Opdahl A.L.},
  isbn            = {9783319252636},
  keywords        = {Competitive intelligence; Data mining; Decision making; Strategic planning, Analysis; Competitive markets; KPIs; Strategic goals; Strategic objectives; SWOT; Systematic analysis; Uncertain environments, Planning},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951772361&doi=10.1007%2f978-3-319-25264-3_5&partnerID=40&md5=f0b3ddc3a8705eda36b002caf1a01a9a},
}

@Article{Sioutas2015a,
  author          = {Sioutas, S. and Sakkopoulos, E. and Panaretos, A. and Tsoumakos, D. and Gerolymatos, P. and Tzimas, G. and Manolopoulos, Y.},
  title           = {D-P2P-Sim+: A novel distributed framework for P2P protocols performance testing},
  journal         = {Journal of Systems and Software},
  year            = {2015},
  volume          = {100},
  pages           = {211-232},
  issn            = {01641212},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In recent technologies like IoT (Internet of Things) and Web 2.0, a critical problem arises with respect to storing and processing the large amount of collected data. In this paper we develop and evaluate distributed infrastructures for storing and processing large amount of such data. We present a distributed framework that supports customized deployment of a variety of indexing engines over million-node overlays. The proposed framework provides the appropriate integrated set of tools that allows applications processing large amount of data, to evaluate and test the performance of various application protocols for very large scale deployments (multi million nodes-billions of keys). The key aim is to provide the appropriate environment that contributes in taking decisions regarding the choice of the protocol in storage P2P systems for a variety of big data applications. Using lightweight and efficient collection mechanisms, our system enables real-time registration of multiple measures, integrating support for real-life parameters such as node failure models and recovery strategies. Experiments have been performed at the PlanetLab network and at a typical research laboratory in order to verify scalability and show maximum re-usability of our setup. D-P2P-Sim+ framework is publicly available at http://code.google.com/p/d-p2p-sim/downloads/list. © 2014 Elsevier Inc.},
  author_keywords = {Distributed storage systems; IoT and Web 2.0 applications; P2P data management},
  coden           = {JSSOD},
  document_type   = {Conference Paper},
  doi             = {10.1016/j.jss.2014.11.001},
  keywords        = {Digital storage; Information management; Internet of things; Multiprocessing systems; Peer to peer networks; Research laboratories; Social networking (online); World Wide Web, Application protocols; Big data applications; Distributed infrastructure; Distributed storage system; Iot( internet of things); Large-scale deployment; Real-time registration; Web 2.0 applications, Big data},
  language        = {English},
  publisher       = {Elsevier Inc.},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919361065&doi=10.1016%2fj.jss.2014.11.001&partnerID=40&md5=db3b96f8b4c5679654ba1f4831309547},
}

@Conference{Zhang2015b,
  author          = {Zhang, J. and Huang, X. and Ma, L. and Xu, Y. and Li, H.},
  title           = {Performance testing program design and assessment methods of small arms},
  year            = {2015},
  publisher       = {Science and Engineering Institute},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In this paper, a comprehensive identification on the overall performance of light weapons is as a starting point, and it proposed simulated combat background, operational performance testing program of light weapons with a typical combat mission, and to build simulated battlefield environment and simulate human testing apparatus to establish methods are discussed, proposed the construction methods and technical approach. On the basis of analysis of the various performance evaluation methods, mathematical model of light weapons and tactical performance test evaluation is established.},
  author_keywords = {Environment simulation; Operational performance test; Small arms},
  document_type   = {Conference Paper},
  journal         = {2015 5th International Workshop on Computer Science and Engineering: Information Processing and Control Engineering, WCSE 2015-IPCE},
  keywords        = {Testing, Battlefield environments; Construction method; Environment simulation; Evaluation methods; Operational performance; Performance testing; Performance tests; Small arms, Software testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939501274&partnerID=40&md5=5b02dc074e9c25b84e455b4fcfc5c1cd},
}

@Article{Charmpis2015,
  author          = {Charmpis, D.C. and Dimitriou, L.},
  title           = {A stress-test of alternative formulations and algorithmic configurations for the binary combinatorial optimization of bridges rehabilitation selection},
  journal         = {Computational Methods in Applied Sciences},
  year            = {2015},
  volume          = {38},
  pages           = {489-507},
  issn            = {18713033},
  note            = {cited By 2},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Optimal surface transport asset management is a major concern with multiple economic and operational implications developed in various infrastructure areas. Although relevant 'mature' analytical frameworks have been proposed and developed, the problem setup and the algorithmic choices are still issues requiring thorough and detailed investigation. In this chapter, an optimal budget allocation framework is developed and stress-tested for the optimal scheduling of a bridges upgrading program. Asuitable test case is developed for performing in-depth analysis that takes into consideration the most important features involved in such scheduling problems, while alternative formulations are also presented and discussed. The proposed frameworks are applied on a real large-scale dataset from the highway system of US, able to provide an adequate test-bed for investigating the optimal upgrade problem. The paper aims in the investigation of the effects that alterations of the problem setup, but also the effects that algorithmic configurations are introducing, when addressing real-world applications. The binary/selection problem is handled with a suitably coded Branch-and-Bound (BaB) algorithm, which is regarded as a robust and fast heuristic for such optimization problems. BaB is tested in alternative standard and extreme configurations, offering insights on its performance. Interestingly enough, although the continuous relaxation introduced by the BaB enables fast convergence, the NP-hard problem's nature should be cautiously taken into consideration. The results are discussed in order to provide insights of applying the proposed framework in realistic infrastructure upgrading schemes. © 2015 Springer International Publishing Switzerland.},
  author_keywords = {Branch-and-bound; Optimal scheduling; Pareto front; Road bridges upgrade; Sequential combinatorial optimization},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-319-18320-6_25},
  editor          = {Papadrakakis M., Lagaros N.D.},
  isbn            = {9783319183190},
  language        = {English},
  publisher       = {Springer Netherland},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963622495&doi=10.1007%2f978-3-319-18320-6_25&partnerID=40&md5=d8ed478d3b92ebb2645144bbcfb0d29f},
}

@Article{Batalla2015,
  author        = {Batalla, J.M. and Gajewski, M. and Latoszek, W. and Krawiec, P.},
  title         = {Implementation and performance testing of ID layer nodes for hierarchized IoT network},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year          = {2015},
  volume        = {9012},
  pages         = {463-472},
  issn          = {03029743},
  note          = {cited By 1},
  __markedentry = {[Jonnathan:]},
  abstract      = {Recent advances in technologies for smart devices are having a significant impact in IoT (Internet of Things) scenarios as, e.g., intelligent buildings. Sensor/actuator networks use small and non-intrusive devices consuming reasonable amount of energy and offering improved performance. On the other hand, highly specialized devices providing high reliability are interconnected by dedicated network infrastructure because of safety reasons. This article discusses early stage of the implementation of an innovative hierarchical network infrastructure for connecting IoT objects and services where the location of the nodes is closely related to the structure of the environment as it occurs in intelligent buildings/enterprises. © Springer International Publishing Switzerland 2015.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-319-15705-4_45},
  editor        = {Nguyen N.T., Trawinski B., Nguyen N.T., Kosala R.},
  isbn          = {9783319157047},
  keywords      = {Database systems; Intelligent buildings, Dedicated networks; Hierarchical network; High reliability; Iot( internet of things); Non-intrusive; Performance testing; Sensor/actuator; Smart devices, Internet of things},
  language      = {English},
  publisher     = {Springer Verlag},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925251498&doi=10.1007%2f978-3-319-15705-4_45&partnerID=40&md5=b38a954ee27d1f474e1118a42a4b14ed},
}

@Conference{Zhao2015,
  author        = {Zhao, S. and Jiao, Y. and Mi, H. and Ma, T. and Lu, M.},
  title         = {An adaptive Kalman filter for a range measurement based indoor positioning system: Algorithm adaptation and performance testing},
  year          = {2015},
  volume        = {3},
  pages         = {2282-2290},
  publisher     = {Institute of Navigation},
  note          = {cited By 2},
  __markedentry = {[Jonnathan:]},
  abstract      = {To overcome the positioning inaccuracy and discontinuity due to the signal errors and user dynamics in a wireless indoor navigation system, an adaptive Kalman filter positioning algorithm is proposed. This adaptive method automatically tune the elements in the process and measurement variance-covariance matrices according to the innovation values to enable a varying dependence on process or measurement model. The theory of the method is presented based on which the parameter settings are discussed. Both static and dynamic experiments under real indoor environment are conducted to verify the proposed method. Iterative least square (ILS) and standard Kalman filter (KF) are introduced to compare with the proposed adaptive filter. Results show that the proposed method outperforms the ILS and KF in both positioning accuracy and continuity.},
  document_type = {Conference Paper},
  isbn          = {9781510817258},
  journal       = {28th International Technical Meeting of the Satellite Division of the Institute of Navigation, ION GNSS 2015},
  keywords      = {Algorithms; Bandpass filters; Covariance matrix; Global positioning system; Indoor positioning systems; Iterative methods; Kalman filters; Navigation systems, Adaptive kalman filter; Indoor navigation system; Iterative least squares; Performance testing; Positioning accuracy; Positioning algorithms; Standard Kalman filters; Variance-covariance matrices, Adaptive filters},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975757478&partnerID=40&md5=d28dcee02292f56121864ec46fbd034e},
}

@Article{Mrozek2015,
  author          = {Mrozek, D. and Paliga, A. and Małysiak-Mrozek, B. and Kozielski, S.},
  title           = {Database under pressure - scaling database performance tests in microsoft azure public cloud},
  journal         = {Communications in Computer and Information Science},
  year            = {2015},
  volume          = {521},
  pages           = {69-81},
  issn            = {18650929},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Making changes in production database or changes in database system configuration often requires these changes to be priorly tested in a test system. This also requires to replay the original workload in the test environment by simulating client’s activity on many workstations. In the paper, we show how this task can be realized with the use of many Workload Replay Agents working in Microsoft Azure public cloud. We present model and architecture of widely scalable, cloud-based stress testing environment, called CloudDBMonitor, which allows controlled execution of captured SQL scripts against a specified database in Microsoft SQL Server database management system. The stress testing environment provides the possibility to investigate how the tested database works under a large pressure generated by many simulated clients. © Springer International Publishing Switzerland 2015.},
  author_keywords = {Cloud computing; Databases; Efficiency; Microsoft Azure; Performance testing; Scalability; Stress testing; Workload replay},
  document_type   = {Article},
  doi             = {10.1007/978-3-319-18422-7_6},
  editor          = {Kozielski S., Mrozek D., Kasprowski P., Malysiak-Mrozek B., Kostrzewa D.},
  isbn            = {9783319184210},
  keywords        = {Cloud computing; Efficiency; Scalability; Windows operating system, Database performance; MicroSoft; Microsoft SQL Server database; Performance testing; Stress Testing; System configurations; Test Environment; Workload replay, Database systems},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929501178&doi=10.1007%2f978-3-319-18422-7_6&partnerID=40&md5=984b7b52f8fc52d84a1c3e8ec3960fb2},
}

@Conference{Yue2015,
  author          = {Yue, G.-D. and Wang, L.-D. and Liu, C. and Zhou, W. and Xu, Z.},
  title           = {Performance test and application of a wireless sensor network system for the distributed monitoring in railway track},
  year            = {2015},
  editor          = {De Stefano A.},
  publisher       = {International Society for Structural Health Monitoring of Intelligent Infrastructure, ISHMII},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {To monitor the safety status of track, a wireless sensor network (WSN) system for track safety monitoring is developed. It consists of a data acquisition layer, a data management & analysis layer, and a monitoring portal/visualization layer. To keep the data integrity and the connection rapid response, a concurrent processing model of network tasks is proposed; to manage and analyze the continuous generated data, a data management & discovery model is constructed based on a MapReduce computations and a rule calculation engine. Finally, the WSN system with 104 nodes is set up at China Academy of Railway Science over 30 days. During the service time, several experiments are carried out to check the loss rate, the throughout, and the data latency. Besides, when a passenger train with an 80 Kg standard weight in each seat is passing by at a constant speed of 140 Km/s, the acceleration data of the ballastless slab tangent track, the ballast tangent track and the ballast curve track resulting from the wheel-rail interaction are obtained and the vibration characteristics (energy magnitudes, durations and instantaneous frequencies) are analysed by the wavelet transform (WT). The result shows that the data loss rates of 104 sensors are less than 5%; it can easily deal with the data with maximum arrival rate 0.52 MB/s without missing data; data latency from the acquisition completion to being displayed on the GUI is less than 1 min. Moreover, when the train is passing by at the constant speed, the acceleration data are processed by WT. For different structures, the energy in the medium frequency region is bigger than the others in the low and high frequency region. At 140 Km/h, the effect range of high frequency region is about 8 m, hence we can also detect the whole of wheel tread. The instantaneous frequencies of different structures can be obtained after getting the wavelet ridges. The instantaneous frequencies in medium and high frequency regions for slab tangent track are similar to the ones for ballast tangent track and suffer from less fluctuations than the ones for curve track. © 2015, International Society for Structural Health Monitoring of Intelligent Infrastructure, ISHMII. All rights reserved.},
  author_keywords = {Correlation analytical method; Data management; Railway track monitoring; Wavelet transform; Wireless sensor network},
  document_type   = {Conference Paper},
  journal         = {SHMII 2015 - 7th International Conference on Structural Health Monitoring of Intelligent Infrastructure},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978775158&partnerID=40&md5=4b0e110aa0ec6d72b9486ae6c7e1a02a},
}

@Conference{Angmo2014a,
  author          = {Angmo, R. and Sharma, M.},
  title           = {Performance evaluation of web based automation testing tools},
  year            = {2014},
  pages           = {731-735},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  note            = {cited By 3},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In today's 21st century era countless software applications are written as a web based application which runs in a web browsers. With new technologies and commercialization of I.T. sector, the web based system has undergoes frequent and rapid changes. Today Softwares are coded as a web based application, which help to access data from any part of the globe. Even the economic relevance of web based enhances the control and quality of software. The quality assurance of any system depends on its test. But to do manually testing in most of the cases is time consuming, expensive and hectic. For the better business purpose and to save time and money automation testing is required. There are variety of tools are available in the market for this. One of the best known tool is selenium suite which is a combination of different automation testing tool. In this paper we will discuss about the selenium suite. It provides testers with different framework for different test cases. The main objective of this paper is to find the best tool in selenium suite and then compare it with some other tool for same task. For this purpose, performance evaluation is done on the basis of some criteria. © 2014 IEEE.},
  art_number      = {6949287},
  author_keywords = {Automation testing; Performance; Selenium; Test case; Watir-webdriver; Web applications},
  document_type   = {Conference Paper},
  doi             = {10.1109/CONFLUENCE.2014.6949287},
  isbn            = {9781479942367},
  journal         = {Proceedings of the 5th International Conference on Confluence 2014: The Next Generation Information Technology Summit},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84914141612&doi=10.1109%2fCONFLUENCE.2014.6949287&partnerID=40&md5=a5e9559eae1e4097423207a6e53cdaa9},
}

@Conference{Podelko2014,
  author        = {Podelko, A.},
  title         = {Load testing: Which tool to choose?},
  year          = {2014},
  publisher     = {Computer Measurment Group Inc.},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {The topic of load testing tool selection always triggers a lot of discussion. Unfortunately, it most often turns into religious wars than objective technical analysis. There are many aspects differentiating load testing tools and it is probably better to evaluate tools on each aspect separately. The paper discusses some aspects of load testing tools and lists some considerations impacting the selection process. The list is far from comprehensive and is provided rather to illustrate the existing issues and show how the selection process for specific needs may be approached.},
  document_type = {Conference Paper},
  journal       = {40th International Conference on Performance and Capacity 2014 by CMG},
  keywords      = {Technical analysis; Testing tools, Load testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925004873&partnerID=40&md5=ac49b3c19305d0998d6b6f7c2735c5da},
}

@Conference{VanHoorn2014,
  author          = {Van Hoorn, A. and Vögele, C. and Schulz, E. and Hasselbring, W. and Krcmar, H.},
  title           = {Automatic extraction of probabilistic workload specifications for load testing session-based application systems},
  year            = {2014},
  pages           = {139-146},
  publisher       = {ICST},
  note            = {cited By 7},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Workload generation is essential to systematically evaluate performance properties of application systems under controlled conditions, e.g., in load tests or benchmarks. The definition of workload specifications that represent the real workload as accurately as possible is one of the biggest challenges in this area. This paper presents our approach for the modeling and automatic extraction of probabilistic workload specifications for load testing session-based application systems. The approach, called Wessbas, comprises (i.) a domain-specific language (DSL) enabling layered modeling of workload specifications as well as support for (ii.) automatically extracting instances of the DSL from recorded sessions logs and (iii.) transforming instances of the DSL to workload specifications of existing load testing tools. During the extraction process, different groups of customers with similar navigational patterns are identified using clustering techniques. We developed corresponding tool support including a transformation to probabilistic test scripts for the Apache JMeter load testing tool. The evaluation of the proposed approach using the industry standard benchmark SPECjEnterprise2010 demonstrates its applicability and the representativeness of the extracted workloads. © Copyright 2015 ICST.},
  author_keywords = {Clustering; Load test extraction; Load testing; Session-based application systems; Workload specifications},
  document_type   = {Conference Paper},
  doi             = {10.4108/icst.valuetools.2014.258171},
  isbn            = {9781631900570},
  journal         = {Proceedings of the 8th International Conference on Performance Evaluation Methodologies and Tools, VALUETOOLS 2014},
  keywords        = {Benchmarking; Computer programming languages; Extraction; Modeling languages; Problem oriented languages; Specifications, Application systems; Clustering; Clustering techniques; Controlled conditions; Domain specific languages; Industry-standard benchmarks; Navigational patterns; Performance properties, Load testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962273190&doi=10.4108%2ficst.valuetools.2014.258171&partnerID=40&md5=c1219bf28d9426964d9231060cb11754},
}

@Conference{Logan2014,
  author        = {Logan, J.S.},
  title         = {Performance measurements and post data reduction: Using Radview WebLOAD and analytics to load test the Georgia tech research institute research portal web site in a linux environment},
  year          = {2014},
  publisher     = {Computer Measurment Group Inc.},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {The author will describe and evaluate Radview WebLOAD and Analytics, a suite of tools that simplified the collection of performance metrics for monitoring and analyzing the Georgia Institute of Technology (GT) Research Institute (GTRI) Research Portal Web Site. Radview WebLOAD and Analytics has a small footprint and gathers statistics from where VMSTAT gather its statistics. Furthermore, the author used Analytics to reduce the volumes of raw performance data to a few graphical tables that characterizes the performance of the GTRI Research Portal web site.},
  document_type = {Conference Paper},
  journal       = {40th International Conference on Performance and Capacity 2014 by CMG},
  keywords      = {Computer operating systems; Linux; Social networking (online); Websites, Georgia; Georgia Institute of Technology; Linux environment; Performance data; Performance measurements; Performance metrics; Research institutes; Small footprints, World Wide Web},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924940290&partnerID=40&md5=4e4a12b9d4a65dc6b5be887a0748ab2a},
}

@Conference{Apte2014,
  author          = {Apte, V. and Nadeesh, T.V.},
  title           = {PerfCenterLite: Extrapolating load test results for performance prediction of multi-tier applications},
  year            = {2014},
  pages           = {181-186},
  publisher       = {ICST},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Performance modeling is an important step in the lifecycle of a typical Web-based multi-tier application. However, while most practitioners are comfortable carrying out load tests on a Web application on a testbed, they find sophisticated performance modeling tools difficult to use because many inputs required by them are difficult to obtain. Chief among these is the service times of various types of requests at various resources in the multi-tier system (e.g. CPU execution time required at the Web server by a \Login" request). In this paper, we present PerfCenterLite, a tool focused on ease of use for practitioners of performance analysis. The tool (a) provides a spread-sheet template for describing the application architecture and (b) accepts standard performance metrics obtained from load testing of the application. PerfCenterLite then uses mathematical estimation techniques and transforms this input into a full-edged performance model as required by a sophisticated performance modeling tool. Validation experiments show that performance metrics predicted using PerfCenterLite match well with measured values. © Copyright 2015 ICST.},
  author_keywords = {Load test results; Performance modeling},
  document_type   = {Conference Paper},
  doi             = {10.4108/icst.valuetools.2014.258208},
  isbn            = {9781631900570},
  journal         = {Proceedings of the 8th International Conference on Performance Evaluation Methodologies and Tools, VALUETOOLS 2014},
  keywords        = {Mathematical transformations; World Wide Web, Application architecture; Mathematical estimation; Multi-tier applications; Performance analysis; Performance metrics; Performance Model; Performance prediction; Standard performance, Load testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962878568&doi=10.4108%2ficst.valuetools.2014.258208&partnerID=40&md5=7fbcbf02aa4f833e25525c23ef9cb4be},
}

@Article{Aluc2014,
  author          = {Aluç, G. and Hartig, O. and Tamer Özsu, M. and Daudjee, K.},
  title           = {Diversified stress testing of RDF data management systems},
  journal         = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year            = {2014},
  volume          = {8796},
  pages           = {197-212},
  issn            = {03029743},
  note            = {cited By 52},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The Resource Description Framework (RDF) is a standard for conceptually describing data on the Web, and SPARQL is the query language for RDF. As RDF data continue to be published across heterogeneous domains and integrated at Web-scale such as in the Linked Open Data (LOD) cloud, RDF data management systems are being exposed to queries that are far more diverse and workloads that are far more varied. The first contribution of our work is an indepth experimental analysis that shows existing SPARQL benchmarks are not suitable for testing systems for diverse queries and varied workloads. To address these shortcomings, our second contribution is the Waterloo SPARQL Diversity Test Suite (WatDiv) that provides stress testing tools for RDF data management systems. Using WatDiv, we have been able to reveal issues with existing systems that went unnoticed in evaluations using earlier benchmarks. Specifically, our experiments with five popular RDF data management systems show that they cannot deliver good performance uniformly across workloads. For some queries, there can be as much as five orders of magnitude difference between the query execution time of the fastest and the slowest system while the fastest system on one query may unexpectedly time out on another query. By performing a detailed analysis, we pinpoint these problems to specific types of queries and workloads. © Springer International Publishing Switzerland 2014.},
  author_keywords = {Benchmarking; RDF; SPARQL; Systems; Workload diversity},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-319-11964-9},
  editor          = {Tudorache T., Knoblock C., Groth P., Goble C., Welty C., Bernstein A., Mika P., Vrandecic D., Noy N., Janowicz K.},
  isbn            = {9783319119632},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908680825&doi=10.1007%2f978-3-319-11964-9&partnerID=40&md5=dde86714663bc7a42616146a8816d67f},
}

@Conference{Hwang2014a,
  author          = {Hwang, G.-H. and Wu-Lee, C. and Tung, Y.-H. and Chuang, C.-J. and Wu, S.-F.},
  title           = {Implementing TaaS-based stress testing by MapReduce computing model},
  year            = {2014},
  editor          = {Wenzheng L., Tsui E., Prasad Babu M.S.},
  pages           = {137-140},
  publisher       = {IEEE Computer Society},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In this paper we propose to employ the MapReduce computing model to implement a Testing as a Service (TaaS) for stress testing. We focus on stress testing for heavy-weight network transactions. The computation power of MapReduce computing system is used to simulate concurrent network transactions issued by a lot of users. The user first describes the testing scenario which he wants to be simulate in a testing script. The TaaS platform analyzes the testing script and then automatically distributes required testing data including details of transactions and files into a MapReduce computing system. We propose three different schemes to distribute testing data and measure their performances. We compare them with the popular stress testing tool JMeter and find out that our scheme can always have the tested system deliver higher error rate during the stress testing. © 2014 IEEE.},
  art_number      = {6933530},
  author_keywords = {Hadoop; MapReduce; Stress testing},
  document_type   = {Conference Paper},
  doi             = {10.1109/ICSESS.2014.6933530},
  isbn            = {9781479932788},
  issn            = {23270586},
  journal         = {Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS},
  keywords        = {Computing model; Hadoop; Map-reduce; Stress Testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910097561&doi=10.1109%2fICSESS.2014.6933530&partnerID=40&md5=b447c30dd456626115cf05b0158b8d6d},
}

@Conference{Liu2014c,
  author          = {Liu, Y. and Liu, S.},
  title           = {Research and implementation of a distributed performance testing execution system based on TTCN-3},
  year            = {2014},
  editor          = {Callaos N.C., Savoie M., Sanchez B., Lace N., Lesso W.},
  volume          = {1},
  pages           = {108-112},
  publisher       = {International Institute of Informatics and Systemics, IIIS},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {A distributed testing system is designed in this paper, which provides a mechanism of node communication, test script deployment, test scheduling, execution-driving and test result collection in distributed environment. A workload model is established, by which testers can describe the performance testing requirement. A performance testing framework is given, which simulates user behaviors in real environment based on virtual users so as to generate workload from the system under test (SUT). It can control the execution of virtual users by TTCN-3 standard interface. After executing the performance testing, test report is generated by extracting log. A method of generating performance test-case is studied by reusing functional test scripts. By executing performance testing on an online bookstore, this paper demonstrates the availability of the method of reusing TTCN-3 functional test scripts and the capability of distributed performance testing system established.},
  author_keywords = {Distributed testing system; Performance testing; System under test (SUT); Test suite reuse; TTCN-3},
  document_type   = {Conference Paper},
  isbn            = {9781941763049},
  journal         = {WMSCI 2014 - 18th World Multi-Conference on Systemics, Cybernetics and Informatics, Proceedings},
  keywords        = {Behavioral research; Cybernetics; Distributed computer systems; Information science; Scheduling, Distributed environments; Distributed performance; Distributed testing; Performance testing; Performance testing framework; Standard interface; System under test; TTCN-3, Testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923199193&partnerID=40&md5=65780fd55d61de21008530042b42f25c},
}

@Article{Senkerik2014,
  author          = {Senkerik, R. and Pluhacek, M. and Davendra, D. and Zelinka, I. and Oplatkova, Z.K.},
  title           = {Performance testing of multi-chaotic differential evolution concept on shifted benchmark functions},
  journal         = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year            = {2014},
  volume          = {8480 LNAI},
  pages           = {306-317},
  issn            = {03029743},
  note            = {cited By 4},
  __markedentry   = {[Jonnathan:]},
  abstract        = {This research deals with the hybridization of the two softcomputing fields, which are chaos theory and evolutionary computation. This paper aims on the investigations on the multi-chaos-driven evolutionary algorithm Differential Evolution (DE) concept. This paper is aimed at the embedding and alternating of set of two discrete dissipative chaotic systems in the form of chaos pseudo random number generators for the DE. In this paper the novel initial concept of DE/rand/1/bin strategy driven alternately by two chaotic maps (systems) is introduced. From the previous research, it follows that very promising results were obtained through the utilization of different chaotic maps, which have unique properties with connection to DE. The idea is then to connect these two different influences to the performance of DE into the one multi-chaotic concept. Repeated simulations were performed on the selected set of shifted benchmark functions in higher dimensions. Finally, the obtained results are compared with canonical DE. © 2014 Springer International Publishing.},
  author_keywords = {Deterministic chaos; Differential Evolution; Dissipative systems; Optimization},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-319-07617-1_28},
  isbn            = {9783319076164},
  keywords        = {Chaotic systems; Evolutionary algorithms; Lyapunov methods; Optimization, Benchmark functions; Chaotic map; Deterministic chaos; Differential Evolution; Dissipative systems; Higher dimensions; Performance testing; Pseudo random number generators, Benchmarking},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902456012&doi=10.1007%2f978-3-319-07617-1_28&partnerID=40&md5=5af4fbc7ff1611261abf8fae46c042b0},
}

@Conference{Gillies2014a,
  author          = {Gillies, K. and Bhate, Y.},
  title           = {Performance testing open source products for the TMT event service},
  year            = {2014},
  volume          = {9152},
  publisher       = {SPIE},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The software system for TMT is a distributed system with many components on many computers. Each component integrates with the overall system using a set of software services. The Event Service is a publish-subscribe message system that allows the distribution of demands and other events. The performance requirements for the Event Service are demanding with a goal of over 60 thousand events/second. This service is critical to the success of the TMT software architecture; therefore, a project was started to survey the open source and commercial market for viable software products. A trade study led to the selection of five products for thorough testing using a specially constructed computer/network configuration and test suite. The best performing product was chosen as the basis of a prototype Event Service implementation. This paper describes the process and performance tests conducted by Persistent Systems that led to the selection of the product for the prototype Event Service. © 2014 SPIE.},
  art_number      = {91521H},
  author_keywords = {middleware; performance testing; software design},
  coden           = {PSISD},
  document_type   = {Conference Paper},
  doi             = {10.1117/12.2057148},
  isbn            = {9780819496201},
  issn            = {0277786X},
  journal         = {Proceedings of SPIE - The International Society for Optical Engineering},
  keywords        = {Astronomy; Commerce; Middleware; Open source software; Software design, Commercial market; Distributed systems; Open source products; Performance requirements; Performance testing; Performance tests; Publish-subscribe; Software services, Open systems},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906894987&doi=10.1117%2f12.2057148&partnerID=40&md5=2419419ffdbe778d69ebed9bc0aff93f},
}

@Conference{Lee2014a,
  author          = {Lee, S. and Jo, J.-Y. and Kim, Y.},
  title           = {Performance testing of web-based data visualization},
  year            = {2014},
  volume          = {2014-January},
  number          = {January},
  pages           = {1648-1653},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  note            = {cited By 7},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Many scientific applications generate massive data that requires visualization. For example, the Nevada Solar Energy-Water-Environmental Nexus project has been generating a large amount of environmental monitoring data in textual format. As the data is available on the web, a web-based visualization tool is desirable for the project rather than a standalone tool. This research analyzes the processing mechanisms of four popular webbased data visualization tools, that is, Google Charts, Flex, OFC, D3, and compares their performances. A standalone visualization tool, JfreeChart, have been also used for comparison. The processing times have been divided into three segments, layout time, data transformation time, and rendering time, and separately measured. The actual temperature data from the Nevada Nexus project has been used for testing in different scales ranging from 100 to 100,000 data points. The result shows that each visualization tool has its own ideal environment. © 2014 IEEE.},
  art_number      = {6974152},
  author_keywords = {D3.js; Data Visualization; Flex; Google Charts; JFreeChart; Open Flash Chart; Sensor Data},
  coden           = {PICYE},
  document_type   = {Conference Paper},
  doi             = {10.1109/smc.2014.6974152},
  issn            = {1062922X},
  journal         = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
  keywords        = {Cybernetics; Metadata; Social networking (online); Solar energy; Visualization; Websites, D3.js; Flex; Google Charts; JFreeChart; Open Flash Chart; Sensor data, Data visualization},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938060452&doi=10.1109%2fsmc.2014.6974152&partnerID=40&md5=dd2e7770a9a070817ef3286a3a87e31b},
}

@Conference{Mao2014,
  author          = {Mao, B.},
  title           = {Calibrate workload model for accurate performance testing},
  year            = {2014},
  publisher       = {Computer Measurment Group Inc.},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Web performance testing, in short, is to simulate real user access workload and web system behaviour in test environment. Performance engineers often spent significant time to build and validate performance test workload model with their best effort and knowledge. The reality is that the workload models in performance testing often missed their real-world scenario targets due to missing "significant non critical" web usages or lack of accurate workload model validation. The accuracy of workload model is directly reflected back into the understanding of web app usage pattern in production. Without an accurate workload model, not only performance test results could be incorrect, but also many following tasks, performance bottleneck recreating, server performance tuning, capacity planning, and application framework validation could be at wrong targets. I will walk you through a practical way of building accurate workload model that will be matching to the targeted prod workload much closer comparing to the workload model created in current performance testing practice. The high accurate workload model and followed performance test results will bring high confidence on web app performance of new releases to project team.},
  author_keywords = {Model calibration; Performance testing; Web usage; Workload model},
  document_type   = {Conference Paper},
  journal         = {40th International Conference on Performance and Capacity 2014 by CMG},
  keywords        = {Accurate performance; Application frameworks; Current performance testing; Model calibration; Performance bottlenecks; Performance testing; Web usage; Work-load models, Social networking (online)},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924939869&partnerID=40&md5=803f1546ec042285fd1bd238ca779e06},
}

@Conference{Mukherjee2014a,
  author        = {Mukherjee, J. and Wang, M. and Krishnamurthy, D.},
  title         = {Performance testing web applications on the cloud},
  year          = {2014},
  pages         = {363-369},
  publisher     = {IEEE Computer Society},
  note          = {cited By 7},
  __markedentry = {[Jonnathan:]},
  abstract      = {Web applications are increasingly resorting to public cloud platforms such as the Amazon Web Services (AWS) Elastic Compute Cloud (EC2). However, previous studies have shown that the virtualized infrastructures used in a cloud environment can introduce performance issues. Hence, it is crucial to test the performance of the cloud to support Web applications. This is challenging because the performance effect of the cloud platform cannot be easily isolated from other extraneous factors. In this paper, we present a systematic experimental process to address this challenge. Following our proposed process, we test the performance of Web applications running on different types of AWS EC2 instances. Results suggest that Web server response times can fluctuate up to 1000% for the same workload under certain circumstances such as instance type, time-of-the-day, and day-of-the-week. © 2014 IEEE.},
  art_number    = {6825689},
  document_type = {Conference Paper},
  doi           = {10.1109/ICSTW.2014.57},
  isbn          = {9780769551944},
  journal       = {Proceedings - IEEE 7th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2014},
  keywords      = {Software testing; Web services, Amazon web services; Cloud environments; Cloud platforms; Elastic compute clouds; Performance effect; Performance issues; Performance testing; WEB application, Applications},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903575108&doi=10.1109%2fICSTW.2014.57&partnerID=40&md5=b09bfda0257828bfd74553e08fc8e998},
}

@Article{Yudenok2014,
  author          = {Yudenok, K.},
  title           = {Geo-coding and smart space platforms integration agent performance testing and analysis},
  journal         = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year            = {2014},
  volume          = {8638 LNCS},
  pages           = {62-69},
  issn            = {03029743},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Internet of Things, Smart Spaces and Geo-coding technologies are fastest growing directions in modern mobile market and urban environments [1, 2]. This is due to the advent of various services that using common technologies, as well as to develop common requirements and architectures for using geo-contextual services in semantic data processing. Location is a mandatory requirement for the Internet of Things and Smart Spaces directions products, because geo-context is a one of the factor to determine the location of subjects in various environments. As a result, it was decided to integrate geo-coding and smart spaces platforms, for the possibility of using geo-context in the semantic space. As an implementation used two open source software platforms - Geo2Tag and Smart-M3. The article discusses an integration agent performance testing and its analysis, provided recommendations for integration mechanisms optimization. © 2014 Springer International Publishing.},
  author_keywords = {Geo-coding; Geo2Tag; Internet of Things; LBS; Smart Spaces; Smart-M3},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-319-10353-2_6},
  isbn            = {9783319103525},
  keywords        = {Codes (symbols); Internet of things; Open source software; Semantics; Software engineering; Space platforms, Geo-coding; Geo2Tag; LBS; Smart space; Smart-M3, Integration testing},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905915536&doi=10.1007%2f978-3-319-10353-2_6&partnerID=40&md5=f1071b31365d1793d7637e62e67e5057},
}

@Conference{Reichelt2014,
  author        = {Reichelt, D.G. and Braubach, L.},
  title         = {Securing performance properties through continuous performance tests with the KoPeMe framework [Sicherstellung von Performanzeigenschaften durch kontinuierliche Performanztests mit dem KoPeMe Framework]},
  year          = {2014},
  editor        = {Hasselbring W., Ehmke N.C.},
  volume        = {P227},
  pages         = {267-278},
  publisher     = {Gesellschaft fur Informatik (GI)},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  document_type = {Conference Paper},
  isbn          = {9783885796213},
  issn          = {16175468},
  journal       = {Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)},
  language      = {English; German},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907958558&partnerID=40&md5=4e02f8e4f5a68101b1655e611b4e0225},
}

@Article{Jamro2014,
  author          = {Jamro, M.},
  title           = {Development and execution of POU-oriented performance tests for IEC 61131-3 control software},
  journal         = {Advances in Intelligent Systems and Computing},
  year            = {2014},
  volume          = {267},
  pages           = {91-101},
  issn            = {21945357},
  note            = {cited By 9},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Due to performing complex and crucial tasks in industry, the control software should be created in a way ensuring possibly the highest quality. It can be increased by modeling, standardized implementation, and precise testing. The latter should verify not only functional requirements, but also nonfunctional, such as performance. In the paper, a concept of agile POU-oriented performance testing is proposed, which is dedicated to the IEC 61131-3 standard. The approach allows to measure and analyze execution times of particular Program Organization Units. The concept supports multiple target platforms and allows to take performance into account during early development stages, as well as to perform regression testing. The proposed process consists of a few stages, namely modeling (using SysML diagrams), implementation (in a dedicated test definition language), and execution (by a dedicated testing framework). The approach has been introduced into the CPDev engineering environment for programming industrial controllers. © Springer International Publishing Switzerland 2014.},
  author_keywords = {Control software; IEC 61131-3; Performance; Testing},
  document_type   = {Article},
  doi             = {10.1007/978-3-319-05353-0_10},
  keywords        = {Quality control; Testing, Control software; Engineering environment; Functional requirement; IEC61131-3; Industrial controllers; Performance; Performance testing; Program organization units, Software testing},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911917398&doi=10.1007%2f978-3-319-05353-0_10&partnerID=40&md5=c23a04b3e0942f52a7155cd1f1fc8475},
}

@Conference{Zhao2014,
  author        = {Zhao, H. and Zhu, L. and Jiang, H. and Tang, T.},
  title         = {Design and performance tests in an integrated TD-LTE based train ground communication system},
  year          = {2014},
  pages         = {747-750},
  publisher     = {Institute of Electrical and Electronics Engineers Inc.},
  note          = {cited By 7},
  __markedentry = {[Jonnathan:]},
  abstract      = {In existing urban rail transit systems, the train ground communication system for different applications are deployed independently. Investing and constructing the communication infrastructures repeatedly not only wastes substantial social resources, it also brings difficulties to maintain all these infrastructures. In this paper, we first present the communication Quality of Service (QoS) requirement for different train ground applications. An integrated TD-LTE based train ground communication system for the urban rail transit system is designed next, which includes all the applications in urban rail transit system. In order to test the integrated TD-LTE based train ground communication system performance, an indoor testing environment is set up. The channel simulator and programmable attenuators are used to simulate the real urban rail transit environment. Extensive test results show that the designed integrated TD-LTE based train ground communication system performance satisfies urban rail transit communication requirement. © 2014 IEEE.},
  art_number    = {6957778},
  document_type = {Conference Paper},
  doi           = {10.1109/ITSC.2014.6957778},
  isbn          = {9781479960781},
  journal       = {2014 17th IEEE International Conference on Intelligent Transportation Systems, ITSC 2014},
  keywords      = {Environmental testing; Intelligent systems; Mass transportation; Quality of service; Transportation; Vehicle performance; Wireless telecommunication systems, Channel simulators; Communication infrastructure; Communication quality; Performance tests; Programmable attenuators; Train-ground communications; Urban rail transit; Urban rail transit systems, Light rail transit},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937136512&doi=10.1109%2fITSC.2014.6957778&partnerID=40&md5=2f7a4acd8d9388f629a8dee2162af2b7},
}

@Conference{Wang2014,
  author          = {Wang, C. and Cho, Y.K.},
  title           = {Performance test for rapid surface modeling of dynamic construction equipment from laser scanner data},
  year            = {2014},
  editor          = {Ha Q., Akbarnezhad A., Shen X.},
  pages           = {134-141},
  publisher       = {University of Technology Sydney},
  note            = {cited By 2},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In modern dynamic construction fields, more attention has been paid on safely operating heavy construction equipment such as cranes, excavators, and concrete pump. In order to improve the safety in complicated jobsites, it is highly required to provide heavy equipment operators with accurate measurement of on-site objects in near real time. In this paper, a rapid surface modeling method and its performance evaluation through on-site tests are introduced. The performance of the proposed method was tested with a heavy equipment at construction site. The interrelationships among data size, processing time, and the size of the resultant hull segments were examined from the data analyses. The field experimental results demonstrate that the proposed dynamic surface modeling method would significantly improve the equipment operation productivity and safety by distinguishing a dynamic surface model being controlled by the operator from the point cloud of existing static environment in 3D views.},
  author_keywords = {3D modeling; Construction equipment; Object recognition; Point cloud; Safety},
  document_type   = {Conference Paper},
  isbn            = {9780646597119},
  journal         = {31st International Symposium on Automation and Robotics in Construction and Mining, ISARC 2014 - Proceedings},
  keywords        = {Accident prevention; Concrete placing; Data handling; Equipment; Machinery; Object recognition; Robotics, 3-d modeling; Accurate measurement; Construction sites; Dynamic construction; Dynamic surface model; Laser scanner data; Point cloud; Static environment, Construction equipment},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912573117&partnerID=40&md5=bf8a06e9b5a04368d773d15e27ff2d75},
}

@Article{Quang2013,
  author          = {Quang, D.N. and See, O.H. and Nga, D.V. and Chee, L.L. and Xuen, C.Y. and Karuppiah, S.A.L.},
  title           = {Performance testing framework in a heterogeneous and hybrid smart grid communication network},
  journal         = {Research Journal of Applied Sciences, Engineering and Technology},
  year            = {2013},
  volume          = {6},
  number          = {23},
  pages           = {4506-4518},
  issn            = {20407459},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Heterogeneous and hybrid smart grid communication network is comprised of different communication mediums and technologies. Performance evaluation is one of the main concerns for smart grid communication system. In any smart grid communication implementation, to determine the performance factor of the network, a testing of an end-to-end process flow is required. An effective and coordinated testing procedure plays a crucial role in evaluating the performance of smart grid communications. Therefore, this study proposes a testing framework which specifies the types of communication mediums and technologies, the evaluation criteria and software tools to carry out the testing. The proposed testing scheme is used as a guideline to analyze and assess the performance of smart grid communication system. © Maxwell Scientific Organization, 2013.},
  author_keywords = {Communication technology; Evaluation criteria; Network testing; Performance metric; Smart grid; Testing framework},
  document_type   = {Article},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887541368&partnerID=40&md5=5dd85435d9d18536fc9ab6af618c8bc7},
}

@Conference{Sefer2013,
  author          = {Sefer, E. and Aykanat, S.},
  title           = {An evaluation of client-side dependencies of search engines by load testing},
  year            = {2013},
  pages           = {61-65},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Nowadays, web based large-scale systems, such as search engines, are widely used. The popularity of search engines created a new environment in which the applications need to be highly scalable due to the data tsunami generated by a huge load of requests. In this context, the main problem is to validate how far the web applications especially search engines can deal with the load generated by the clients. Load testing, in general, refers to the practice of accessing the system behavior under load. In this paper, we study on search engine performances' dependencies related to network bandwidth and Internet browsers in aspect of load testing. We observed that search engines' speed is dependent on Internet browsers and network bandwidth.},
  author_keywords = {Internet browser; Load testing; Network bandwidth; Search engine},
  document_type   = {Conference Paper},
  isbn            = {9781629933030},
  journal         = {5th International Conference on Advances in System Testing and Validation Lifecycle, VALID 2013, Held at SoftNet 2013},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894792333&partnerID=40&md5=4ac45683c80021abc31bf31d41f28578},
}

@Article{Shoukry2013,
  author          = {Shoukry, S.N. and Luo, Y. and Riad, M.Y. and William, G.W.},
  title           = {Bridge load testing and rating: A case study through wireless sensing technology},
  journal         = {Smart Structures and Systems},
  year            = {2013},
  volume          = {12},
  number          = {6},
  pages           = {661-678},
  issn            = {17381584},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In this paper, a wireless sensing system for structural field evaluation and rating of bridges is presented. The system uses a wireless platform integrated with traditional analogue sensors including strain gages and accelerometers along with the operating software. A wireless vehicle position indicator is developed using a tri-axial accelerometer node that is mounted on the test vehicle, and was used for identifying the moving truck position during load testing. The developed software is capable of calculating the theoretical bridge rating factors based on AASHTO Load and Resistance Factor Rating specifications, and automatically produces the field adjustment factor through load testing data. The sensing system along with its application in bridge deck rating was successfully demonstrated on the Evansville Bridge in West Virginia. A finite element model was conducted for the test bridge, and was used to calculate the load distribution factors of the bridge deck after verifying its results using field data. A confirmation field test was conducted on the same bridge and its results varied by only 3% from the first test. The proposed wireless sensing system proved to be a reliable tool that overcomes multiple drawbacks of conventional wired sensing platforms designed for structural load evaluation of bridges. Copyright © 2013 Techno-Press, Ltd.},
  author_keywords = {Bridge load rating; Finite element modeling; Remote sensing; Testing and inspecting procedures; Wireless data acquisition},
  document_type   = {Article},
  doi             = {10.12989/sss.2013.12.6.661},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889021876&doi=10.12989%2fsss.2013.12.6.661&partnerID=40&md5=64e30dff6fa4938365ec5d5a537eb6b7},
}

@Conference{Yildiran2013,
  author          = {Yildiran, H.O. and Gürel, C.},
  title           = {A mechatronic load testing equipment},
  year            = {2013},
  pages           = {17-25},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In a Project given to 2nd year students in Engineering Mechanics I (Statics) course the students are required to make calculations and prototype of a spring link- rigid body link weight carrying body with concurrent forces in 2D. Unfortunately the student had problems in visualization of the problem and also the solution. In this paper a prototype is shown (manufactured) which have an output of the results so as to use these results in checking calculation and visualization of the system in a lab environment study. Results are given to the students as: Theoretical, mechanical, through potentiometric device readings and by image processing. By this test apparatus, students change connection points and the weights and make the calculations to find forces in elements, displacement of spring and the angles that links make with horizontal. They see the results as; change in length of spring, the forces in each member visually on LCD (PC) and compare their results. The main object of this equipment, is to make Mechatronics Engineering students understand the problem better, check their results, meet with future mechatronic devices they will see in their following semesters and have an understanding of what mechatronic systems are.},
  author_keywords = {Coplanar Force Systems; Image Processing; Load Testing; Measurement; Mechatronics Measurement; Potentiometers; Statics},
  document_type   = {Conference Paper},
  isbn            = {9781629933139},
  journal         = {20th Annual International Conference on Mechatronics and Machine Vision in Practice, M2VIP 2013},
  keywords        = {Connection points; Engineering mechanics; Force systems; Mechatronic devices; Mechatronic systems; Statics; Test apparatus; Testing equipment, Computer vision; Image processing; Load testing; Measurements; Potentiometers (electric measuring instruments); Potentiometers (resistors); Visualization; Voltage dividers, Students},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893392582&partnerID=40&md5=8fc1ce73fb016ea99d08106ff5c01eda},
}

@Conference{Banerjee2013a,
  author          = {Banerjee, A. and Chattopadhyay, S. and Roychoudhury, A.},
  title           = {Static analysis driven cache performance testing},
  year            = {2013},
  pages           = {319-329},
  note            = {cited By 9},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Real-time, embedded software are constrained by several non-functional requirements, such as timing. With the ever increasing performance gap between the processor and the main memory, the performance of memory subsystems often pose a significant bottleneck in achieving the desired performance for a real-time, embedded software. Cache memory plays a key role in reducing the performance gap between a processor and main memory. Therefore, analyzing the cache behaviour of a program is critical for validating the performance of an embedded software. In this paper, we propose a novel approach to automatically generate test inputs that expose the cache performance issues to the developer. Each such test scenario points to the specific parts of a program that exhibit anomalous cache behaviour along with a set of test inputs that lead to such undesirable cache behaviour. We build a framework that leverages the concepts of both static cache analysis and dynamic test generation to systematically compute the cache-performance stressing test inputs. Our framework computes a test-suite which does not contain any false positives. This means that each element in the test-suite points to a real cache performance issue. Moreover, our test generation framework provides an assurance of the test coverage via a well-formed coverage metric. We have implemented our entire framework using Chronos worst case execution time (WCET) analyzer and LLVM compiler infrastructure. Several experiments suggest that our test generation framework quickly converges towards generating cache-performance stressing test cases. We also show the application of our generated test-suite in design space exploration and cache performance optimization. © 2013 IEEE.},
  art_number      = {6728886},
  author_keywords = {Cache performance; Performance testing; Test generation},
  coden           = {PRSYE},
  document_type   = {Conference Paper},
  doi             = {10.1109/RTSS.2013.39},
  isbn            = {9781479920075},
  issn            = {10528725},
  journal         = {Proceedings - Real-Time Systems Symposium},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894374407&doi=10.1109%2fRTSS.2013.39&partnerID=40&md5=d37855c5e7b89a1309b37bbf3d85e925},
}

@Conference{Deng2013,
  author          = {Deng, Z.Q. and Tian, Y. and Tang, D.W. and Jiang, S.Y. and Xiao, H. and Quan, Q.Q.},
  title           = {A new planetary exploration coring bit design and its performance tests research},
  year            = {2013},
  pages           = {252-257},
  note            = {cited By 3},
  __markedentry   = {[Jonnathan:]},
  abstract        = {According to the function requirements of coring bit for planetary exploration, and a new coring bit with barrier ring structure is developed to resolve the low coring ratio problem. The model of coring bit cutting tools and generalized planetary regolith interaction is established. The planetary soil lateral failure model which caused by cutting tools is analyzed and established. Take the Lunar soil as an example, the influence of structure parameters of cutting tools for cutting force and coring ratio is analyzed. Test have shown that with the barrier ring structure of the bit can improve the coring ratio effectively. However, the horizontal cutting force is significantly higher, the axial force is decline. The conclusion of research could provide the theoretical basis of lunar sampling drill design for Chang E project. © 2013 IEEE.},
  art_number      = {6720305},
  author_keywords = {barrier ring; coring bit; lateral failure model; planetary exploration},
  document_type   = {Conference Paper},
  doi             = {10.1109/ICInfA.2013.6720305},
  isbn            = {9781479913343},
  journal         = {2013 IEEE International Conference on Information and Automation, ICIA 2013},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894213355&doi=10.1109%2fICInfA.2013.6720305&partnerID=40&md5=b3f1ea84125a218f17c78dac9ff7f31e},
}

@Conference{Che2013a,
  author          = {Che, X. and Maag, S.},
  title           = {A formal passive performance testing approach for distributed communication systems},
  year            = {2013},
  pages           = {74-84},
  note            = {cited By 4},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Conformance testing of communicating protocols is a functional test which verifies whether the behaviors of the protocol satisfy defined requirements, while the performance testing of communicating protocols is a qualitative and quantitative test, aiming at checking whether the performance requirements of the protocol have been satisfied under certain conditions. It raises the interesting issue of converging these two kinds of tests by using the same formal approach. In this paper, we present a novel logic-based approach to test the protocol performance through real execution traces and formally specified properties. In order to evaluate and assess our methodology, we have developed a prototype and present experiments with a set of IMS/SIP properties. Finally, the relevant verdicts and discussions are provided. Copyright © 2013 SCITEPRESS.},
  author_keywords = {Distributed framework; Formal methods; Performance testing},
  document_type   = {Conference Paper},
  isbn            = {9789898565624},
  journal         = {ENASE 2013 - Proceedings of the 8th International Conference on Evaluation of Novel Approaches to Software Engineering},
  keywords        = {Communicating protocols; Conformance testing; Distributed communication systems; Distributed framework; Logic-based approach; Performance requirements; Performance testing; Protocol performance, Engineering; Formal methods; Industrial engineering, Software engineering},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887036820&partnerID=40&md5=3e03bc6a06577949db3b31860c107bee},
}

@Conference{Canfora2013a,
  author          = {Canfora, G. and Mercaldo, F. and Visaggio, C.A. and D'Angelo, M. and Furno, A. and Manganelli, C.},
  title           = {A case study of automating user experience-oriented performance testing on smartphones},
  year            = {2013},
  pages           = {66-69},
  note            = {cited By 11},
  __markedentry   = {[Jonnathan:]},
  abstract        = {We have developed a platform named Advanced Test Environment (ATE) for supporting the design and the automatic execution of UX tests for applications running on Android smart phones. The platform collects objective metrics used to estimate the UX. In this paper, we investigate the extent that the metrics captured by ATE are able to approximate the results that are obtained from UX testing with real human users. Our findings suggest that ATE produces UX estimations that are comparable to those reported by human users. We have also compared ATE with three widespread benchmark tools that are commonly used in the industry, and the results show that ATE outperforms these tools. © 2013 IEEE.},
  art_number      = {6569717},
  author_keywords = {android; mobile applications; smartphone; software testing; usability; user experience},
  document_type   = {Conference Paper},
  doi             = {10.1109/ICST.2013.16},
  journal         = {Proceedings - IEEE 6th International Conference on Software Testing, Verification and Validation, ICST 2013},
  keywords        = {Advanced tests; android; Android smart phones; Mobile applications; Objective metrics; Performance testing; usability; User experience, Design; Robots; Software testing; Tools, Smartphones},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883357280&doi=10.1109%2fICST.2013.16&partnerID=40&md5=abdc2ccc2a897f4a769adcc9c9b2669b},
}

@Article{Meier2013,
  author          = {Meier, F. and Bazo, A. and Burghardt, M. and Wolff, C.},
  title           = {Evaluating a web-based tool for crowdsourced navigation stress tests},
  journal         = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year            = {2013},
  volume          = {8015 LNCS},
  number          = {PART 4},
  pages           = {248-256},
  issn            = {03029743},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {We present a web-based tool for evaluating the information architecture of a website. The tool allows the use of crowdsourcing platforms like Amazon's MTurk as a means for recruiting test persons, and to conduct asynchronous remote navigation stress tests (cf. Instone 2000). We also report on an evaluation study which compares our tool-based crowdsourced approach to a more traditional laboratory test setting. Results of this comparison indicate that although there are interesting differences between the two testing approaches, both lead to similar test results. © 2013 Springer-Verlag Berlin Heidelberg.},
  author_keywords = {crowdsourcing; information architecture; MTurk; navigation stress test; remote usability testing},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-642-39253-5_27},
  isbn            = {9783642392528},
  keywords        = {Crowdsourcing; Information architectures; MTurk; Remote usability testing; Stress test, Human computer interaction; Information management; Information retrieval; Information science; Navigation; Product design; Tools; Web services, Testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880737476&doi=10.1007%2f978-3-642-39253-5_27&partnerID=40&md5=e88d570e71dfabbaf8615f363c5abb5d},
}

@Article{Stupiec2013a,
  author        = {Stupiec, E. and Walkowiak, T.},
  title         = {Automatic load testing of web application in SaaS model},
  journal       = {Advances in Intelligent Systems and Computing},
  year          = {2013},
  volume        = {224},
  pages         = {421-430},
  issn          = {21945357},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {Necessity of monitoring in combination with the actual complexity of the e-services creates a need for constructing systems for active monitoring of various types of web services. Usually those systems are high-availability services, that require on one hand ingenious software solutions and on the other hand reliable hardware architecture. The created systems need to be flexible enough to satisfy customers requirements. This paper introduces an example solution of a system, that implement functional monitor of services provided in SaaS model. The provided system allows to check certain functionalities or whole service by running functional/load tests scenarios that are automatically generated, based on specially prepared user model. © Springer International Publishing Switzerland 2013.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-319-00945-2_38},
  isbn          = {9783319009445},
  keywords      = {Automatic test pattern generation; Customer satisfaction; Web services, Active monitoring; Automatically generated; E-services; Hardware architecture; High availability; Software solution; User Modeling; WEB application, Software as a service (SaaS)},
  language      = {English},
  publisher     = {Springer Verlag},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883016896&doi=10.1007%2f978-3-319-00945-2_38&partnerID=40&md5=59f450ba33be94abe4401a8a1df7fb6d},
}

@Conference{Bennett2013,
  author        = {Bennett, P.J.},
  title         = {Vibration monitoring and live load tests of civil infrastructure with interferometric radar},
  year          = {2013},
  editor        = {Chang F.-K.},
  volume        = {1},
  pages         = {733-739},
  publisher     = {DEStech Publications},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {With advances in technology, interferometric radar is expanding the possibilities for monitoring vibrations and performing live load tests of bridges and other structures. This paper presents an instrument (IBIS-S) that utilizes interferometric radar to measure displacement as a function of time. Displacement of most structural elements in the line of sight can be measured to a precision of 0.01 mm at a sampling rate of 200 Hz in a noncontact manner. Traditional instruments used to monitor vibrations often require contact with the members, or noncontact measurements can only be done over a limited range. Further, traditional instruments can be time consuming to set up and costly to maintain. With interferometric radar technology, data typically are obtained in hours, and the monitoring is done from a remote point, precluding the need to access the structure or disrupt the use. It will be shown that the IBIS-S instrument can be deployed quickly, without interrupting the use of the structure, allowing the user to begin collecting vibration data under live loads within minutes. Included in this paper is a literature review of interferometric radar use on buildings, bridges, and wind turbines. Uses include fundamental frequency and mode shape determination of buildings, bridges, and other structures, as well as live load tests. Interferometric radar can be used successfully as part of a structural health monitoring program, wherein baseline vibration and displacement data are obtained and then the measurement process is repeated periodically. Depending on the structure type, changes in fundamental frequency or mode shape can reveal a loss of stiffness, which may be an indication of critical deterioration. Also discussed are the results of vibration monitoring for a cable-stayed pedestrian bridge. It will be shown that interferometric radar technology can be used to determine the global natural frequency of a cable-stayed bridge and the local natural frequency of individual elements (towers, cables, railing, etc.). Limitations of the technology are also discussed.},
  document_type = {Conference Paper},
  isbn          = {9781605951157},
  journal       = {Structural Health Monitoring 2013: A Roadmap to Intelligent Structures - Proceedings of the 9th International Workshop on Structural Health Monitoring, IWSHM 2013},
  keywords      = {Bridge cables; Cable stayed bridges; Cables; Footbridges; Intelligent structures; Interferometry; Monitoring; Natural frequencies; Radar; Radar measurement; Structural dynamics; Vibration measurement; Wind turbines, Civil infrastructures; Fundamental frequencies; Interferometric radars; Measurement process; Noncontact measurements; Structural elements; Structural health monitoring programs; Vibration monitoring, Structural health monitoring},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945174222&partnerID=40&md5=eb84235bfa1e8e1158d1ddcb23938c1d},
}

@Conference{Srinivasa2013a,
  author        = {Srinivasa, L.N. and Anbalagan, J. and Meenakshisundaram, S.},
  title         = {Performance testing approach for services and applications using MQ-Series®},
  year          = {2013},
  volume        = {2},
  pages         = {1151-1162},
  publisher     = {Computer Measurement Group Inc},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {Performance Testing of web-based applications in general is accomplished with the help of standard load testing tools and their methodology is well established and adopted by the Software Industry. With the advent of distributed Service Oriented Architecture (SOA) applications, load testing of services poses its own challenge to performance Testers and Engineers. In particular, this paper presents an approach and a tool by which the challenges for performance testing a messaging service (services using SOAP over MQ) can be overcome. Further, the paper illustrates how the existing tools can be adapted or new tools can be used to test them. In addition, it also specifies the testing, monitoring and tuning aspects of Messaging services.},
  document_type = {Conference Paper},
  journal       = {Annual International Conference of the Computer Measurement Group, CMG 2013},
  keywords      = {Information services; Service oriented architecture (SOA); Software engineering, Messaging services; Performance testing; Services and applications; Software industry; Standard loads; Testing tools; Web-based applications, Tools},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899807020&partnerID=40&md5=fd9b990a6c83fa5eb32ae90c8d03ae9f},
}

@Conference{Verma2013,
  author        = {Verma, M.},
  title         = {Performance testing: A guide to successful real world performance testing november 2013},
  year          = {2013},
  volume        = {2},
  pages         = {1090-1131},
  publisher     = {Computer Measurement Group Inc},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {In this paper, we present benefits of performance testing, forms of performance testing, key success factors and provider a framework to build a business case for Performance Testing and Application Performance Monitoring. It will be beneficial for beginner Performance Engineers and help close gaps for existing engineers by illustrating some best practices and guidelines for Successful Performance testing, and building a Performance Testing Center of Excellence.},
  document_type = {Conference Paper},
  journal       = {Annual International Conference of the Computer Measurement Group, CMG 2013},
  keywords      = {Computer science; Computers, Application performance; Best practices; Business case; Key success factors; Performance testing; Real-world performance, Measurements},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899883580&partnerID=40&md5=73860e1102ffaa7a506a6c188d10bb76},
}

@Article{Bachche2013,
  author          = {Bachche, S. and Oka, K.},
  title           = {Design, modeling and performance testing of end-effector for sweet pepper harvesting robot hand},
  journal         = {Journal of Robotics and Mechatronics},
  year            = {2013},
  volume          = {25},
  number          = {4},
  pages           = {705-717},
  issn            = {09153942},
  note            = {cited By 5},
  __markedentry   = {[Jonnathan:]},
  abstract        = {This paper presents a new design and modeling fundamentals of gripper and cutting system for 5 degree of freedom robotic arm, designed to harvest sweet peppers in horticultural green house. The design consists of two parallel jaws mounted on gears and operated with the help of servo motor. The same servo motor was used to operate the cutting system which was composed of scissors. The complete system was designed to operate by using one servo motor only. The system model was developed in SolidWorks and tested for different kinematic and dynamic performances. The performance of the gripper and cutting tool system has been evaluated through simulation to determine the design parameters of practical prototype. Based on the design concept, practical prototype of the gripper and cutting system was developed by considering the results obtained by model developed in SolidWorks. The developed prototype was tested to verify the feasibility and reliability of the model developed in Solid- Works. The performance and practical application of the developed prototype was verified and validated by conducting experiments in the lab and greenhouse and comparing the results with simulation results.},
  author_keywords = {Cutting tool; Gripper; Gripper model; Gripper simulation; Sweet pepper harvesting robot},
  document_type   = {Article},
  doi             = {10.20965/jrm.2013.p0705},
  keywords        = {Cutting tools; Degrees of freedom (mechanics); End effectors; Grippers; Harvesting; Machine design; Range finding; Robotic arms, Complete system; Degree of freedom; Design and modeling; Design parameters; Dynamic performance; Harvesting robot; Performance testing; System modeling, Software prototyping},
  language        = {English},
  publisher       = {Fuji Technology Press},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881571221&doi=10.20965%2fjrm.2013.p0705&partnerID=40&md5=92dd8277f61bc3518c519792cf2cd996},
}

@Conference{Batterywala2013,
  author        = {Batterywala, M.},
  title         = {Performance testing of NoSQL applications},
  year          = {2013},
  volume        = {2},
  pages         = {1080-1089},
  publisher     = {Computer Measurement Group Inc},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {This paper discusses the approach and solutions to performance test NoSQL databases. It also includes the available tools and how they can be used for this purpose taking Cassandra as an example. The paper also highlights the areas that should be looked at to get optimum performance from the Cassandra clusters in the application.},
  document_type = {Conference Paper},
  journal       = {Annual International Conference of the Computer Measurement Group, CMG 2013},
  keywords      = {Computer science; Computers, Cassandras; Nosql database; Optimum performance; Performance testing; Performance tests, Measurements},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899878335&partnerID=40&md5=4aee4b24a44620daa466e936160719b7},
}

@Conference{Comes2013,
  author          = {Comes, T. and Bertsch, V. and French, S.},
  title           = {Designing dynamic stress tests for improved critical infrastructure resilience},
  year            = {2013},
  pages           = {307-311},
  publisher       = {Karlsruher Institut fur Technologie (KIT)},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {This paper outlines an approach to support decision-makers in designing resilient critical infrastructure (CI) networks. As CIs have become increasingly interdependent disruptions can have far-reaching impacts. We focus on the vulnerability of CIs and the socio-economic systems, in which they are embedded, independent from any initial risk event. To determine which disruptions are the most severe and must be avoided, quantitative and qualitative assessments of a disruption's consequences and the perspectives of multiple stakeholders need to be integrated. To this end, we combine the results of consequence models and expert assessments into stress test scenarios, which are evaluated using multi-criteria decision analysis techniques. This approach enables dynamic adaption of the stress tests in the face of a fast changing environment and to take account of better information about interdependencies or changing preferences. This approach helps make trade-offs between costs for resilient CIs and potential losses of disruptions clearly apparent.},
  author_keywords = {Critical infrastructure disruption; MCDA; Participatory approaches; Resilience; Robustness; Stress test; Vulnerability},
  document_type   = {Conference Paper},
  isbn            = {9783923704804},
  journal         = {ISCRAM 2013 Conference Proceedings - 10th International Conference on Information Systems for Crisis Response and Management},
  keywords        = {Critical infrastructures; Decision making; Economic and social effects; Embedded systems; Information systems; Robustness (control systems), MCDA; Participatory approach; Resilience; Stress test; Vulnerability, Public works},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905641534&partnerID=40&md5=2196c1d3c9562c817ad29f3ca12fe6b6},
}

@Article{Jamro2013,
  author          = {Jamro, M. and Rzońca, D. and Trybus, B.},
  title           = {Communication Performance Tests in Distributed Control Systems},
  journal         = {Communications in Computer and Information Science},
  year            = {2013},
  volume          = {370 CCIS},
  pages           = {200-209},
  issn            = {18650929},
  note            = {cited By 10},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The paper presents a concept and implementation of Communication Performance Tests (CPT) for small distributed control systems. Requirements for the communication performance are specified using SysML notation. Test cases included in the specification are translated into a dedicated test definition language CPTest+. System implementation is then verified by executing the tests generated from the specification and analyzing results of test runs. The procedure is supported by specialized tools integrated with IEC 61131-3 development environment, including SysML model editor and CPTest testing environment. © Springer-Verlag Berlin Heidelberg 2013.},
  author_keywords = {communication; control systems; performance; testing},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-642-38865-1_21},
  isbn            = {9783642388644},
  keywords        = {Communication; Control systems; Distributed parameter networks; Specifications, Communication performance; Development environment; IEC61131-3; performance; Specialized tools; System implementation; Test case; Testing environment, Testing},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904647542&doi=10.1007%2f978-3-642-38865-1_21&partnerID=40&md5=3fc652ade2b5d092a8f6863ff42eacd0},
}

@Article{ToledoRodriguez2013a,
  author          = {Toledo Rodríguez, F. and Reina, M. and Baptista, F. and Polo Usaola, M. and Pérez Lamancha, B.},
  title           = {Automated Generation of Performance Test Cases from Functional Tests for Web Applications},
  journal         = {Communications in Computer and Information Science},
  year            = {2013},
  volume          = {417 CCIS},
  pages           = {164-173},
  issn            = {18650929},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {When modernizing systems there are big risks concerning functional and non-functional properties. It is expected that the functionality, the performance and the dependability are the same (or better) in the new version. Therefore, the preventive workload simulation (to verify non-functional properties) is crucial to guarantee the success of the modernization project. Since tools for load simulation work at protocol level, the automation of tasks for workload simulation demand much more effort than functional testing, whose test cases are designed using record and playback techniques on the GUI: these tools are more intuitive and they have to handle less variables and technical issues. In this article we present a tool to automatically generate workload simulation scripts from automated functional tests. The tool has been used in several projects in the industry, achieving important cost savings and improving flexibility when verifying non-functional properties of a migrated system. © Springer-Verlag Berlin Heidelberg 2013.},
  author_keywords = {Information System Testing; Non-functional Testing; Software Testing; Testing Automation},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-642-54092-9_12},
  isbn            = {9783642540912},
  keywords        = {Automation; Software testing, Automated generation; Functional testing; Modernization projects; Non functional properties; Non-functional; Performance tests; Record and playback; Testing automation, Software engineering},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904719234&doi=10.1007%2f978-3-642-54092-9_12&partnerID=40&md5=bdc2371ed3bfeac47df0bc1790141c47},
}

@Article{Dawar2013,
  author          = {Dawar, S. and van der Meer, S. and Keeney, J. and Fallon, E. and Bennet, T.},
  title           = {Cloudifying mobile network management: Performance tests of event distribution and rule processing},
  journal         = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
  year            = {2013},
  volume          = {125 LNICST},
  pages           = {94-107},
  issn            = {18678211},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {With the ever increasing number of devices, nodes and the events they create, scalability and performance become important aspects for Operation Support Systems (OSS). One solution is to distribute the work load, i.e. ‘cloudify’ the formerly centralized monitoring and decision functions. This requires remodeling Complex Event Processing (monitoring) and Policies (decision making) towards a distributed yet coordinated system. This paper describes an extended architecture, implementation and performance tests for a policy-based event processing system. The main advantage of our approach is that we use policies for event pattern matching (an advanced form of Complex Event Processing) and for the selection of corrective actions (called Distributed Governance). Policies are (a) distributed (over multiple components) and (b) coordinated (using centralized authoring). The resulting system can deal with large numbers of incoming events, as is required in a telecommunication environment. Peak load will be well above 1 million events per second, combining different data sources of a mobile network. This paper presents the motivation for such a system, along with a comprehensive presentation of its design, implementation and evaluation. © Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2013.},
  author_keywords = {Complex event processing; Distributed processing; Performance; Rule system},
  document_type   = {Conference Paper},
  editor          = {Pesch D., Wenning B.-L., Calvo R.A., Timm-Giel A., Pentikousis K.},
  isbn            = {9783319042763},
  keywords        = {Coordination reactions; Decision making; Mobile telecommunication systems; Network management; Pattern matching; Wireless networks, Complex event processing; Decision functions; Distributed processing; Multiple components; Operation support system; Performance; Rule systems; Scalability and performance, Complex networks},
  language        = {English},
  publisher       = {Springer Verlag},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009469025&partnerID=40&md5=7718ec0798f7dd6effe070ea89f46c41},
}

@Conference{Isenberg2012,
  author          = {Isenberg, S. and Goebl, M. and Baumgarten, U.},
  title           = {Is the Web ready for in-car infotainment? A framework for browser performance tests suited for embedded vehicle hardware},
  year            = {2012},
  pages           = {35-43},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {After Web applications have successfully found their way to PCs, smartphones and tablets, they are on the verge to be used on in-vehicle infotainment (IVI) systems. One of the often claimed drawbacks of Web applications is their low performance in conjunction with limited resources. We have created a benchmark framework to evaluate the performance of JavaScript in comparison to native code. The framework is designed to take the resource constraints of IVI systems into account. We conclude that general calculation tasks in JavaScript are on the average two to four times slower than native compiled counterparts on embedded vehicle hardware. The factor is independent from the allowed resource limits for each calculation. Using new features for Web applications (e.g. local storage functionality) or making frequent use of recursions there is a significant performance drop in JavaScript. In these cases native code runs up to 10 times faster than their counterparts in JavaScript. © 2012 IEEE.},
  art_number      = {6320530},
  author_keywords = {embedded systems; in-car infotainment systems; JavaScript benchmark; performance evaluation; Web applications},
  document_type   = {Conference Paper},
  doi             = {10.1109/WSE.2012.6320530},
  isbn            = {9781467330558},
  issn            = {21606153},
  journal         = {Proceedings of IEEE International Symposium on Web Systems Evolution, WSE},
  keywords        = {In-vehicle; Infotainment; Infotainment systems; Javascript; Native code; Performance evaluation; Performance tests; Recursions; Resource Constraint; WEB application, Embedded systems; Hardware; High level languages; Java programming language; System theory; Websites, Benchmarking},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870799639&doi=10.1109%2fWSE.2012.6320530&partnerID=40&md5=fa6491c0a44d368babc7132cc33068ad},
}

@Conference{Yao2012a,
  author          = {Yao, Y. and Wang, X.},
  title           = {A distributed, cross-platform automation testing framework for GUI-driven applications},
  year            = {2012},
  pages           = {723-726},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {With the rapid development of computer technology, nowadays GUIs have been widely used in desktop applications and web applications. GUI-driven application testing is an emergent approach to software testing and plays a key role to assure software quality. This paper first discusses the various methods for testing GUI-driven applications, and then defines a GUI model and formally defines the test case and the test suite. Finally, it proposes a novel automated, distributed and cross-platform testing framework for GUI. Experiments conducted showed that the proposed testing architecture managed to use parallel cross-platform clusters to test heterogeneous applications whose technologies were incompatible with the testing framework. © 2012 IEEE.},
  art_number      = {6526035},
  author_keywords = {automation testing; cross-platform testing; distributed testing framework; GUI-driven applications},
  document_type   = {Conference Paper},
  doi             = {10.1109/ICCSNT.2012.6526035},
  isbn            = {9781467329644},
  journal         = {Proceedings of 2nd International Conference on Computer Science and Network Technology, ICCSNT 2012},
  keywords        = {Application testing; Automation testing; Computer technology; Cross-platform; Desktop applications; Distributed testing; Software Quality; Testing framework, Automation; Computer science; Computer software selection and evaluation; Software testing, Graphical user interfaces},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880202574&doi=10.1109%2fICCSNT.2012.6526035&partnerID=40&md5=96564504db0d5f0f751fb695e16db1f7},
}

@Conference{Zhang2012a,
  author          = {Zhang, H.-L. and Zhang, S. and Li, X.-J. and Zhang, P. and Liu, S.-B.},
  title           = {Research of load testing and result application based on loadrunner},
  year            = {2012},
  pages           = {1069-1072},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In this paper, we made the plan of a load testing, and got results by means of the LoadRunner which is an automatic testing tool. We fully considered the characteristics of the electronic commerce application, designed the reasonable test cases, and simulated the practical scenario. In the process of running LoadRunner, we arranged the appropriate transactions and rendezvous, and designed the truthful test network environment. The plan was applied to the load testing phase of the telecommunication equipment sales system of special products. We analyzed the load testing results, proposed the improving measures, and realized the optimization of the telecommunication equipment sales system. © 2012. The authors - Published by Atlantis Press.},
  author_keywords = {Automatic testing tool; Load testing; Telecommunication equipment; Test script; Transaction},
  document_type   = {Conference Paper},
  isbn            = {9789491216381},
  journal         = {Proceedings of the 2012 National Conference on Information Technology and Computer Science, CITCS 2012},
  keywords        = {Electronic commerce applications; Loadrunner; Test case; Test network; Test scripts; Testing phase; Transaction, Automatic testing; Computer science; Load testing; Telecommunication equipment, Information technology},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878122217&partnerID=40&md5=93538ff766af8ebf7024944d50bd2826},
}

@Conference{Brady2012,
  author        = {Brady, J.F.},
  title         = {When load testing large user population web applications the devil is in the (virtual) user details},
  year          = {2012},
  note          = {cited By 3},
  __markedentry = {[Jonnathan:]},
  abstract      = {Many times load testing is dismissed as a waste of time and money because past results didn't conform to real world experience when the application went live. Sometimes it's because the test suite is too narrow but often it is due to the approach used to produce traffic and the way results are interpreted. This discussion focuses on the latter situation because a lack of testing scope is an obvious limitation but poor quality traffic and improper analysis techniques are subtle shortcomings that impact test credibility in ways that aren't always clear until the live application reveals them.},
  document_type = {Conference Paper},
  journal       = {CMG 2012 International Conference},
  keywords      = {Analysis techniques; Large users; Real-world experience; WEB application},
  language      = {English},
  page_count    = {12},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883096648&partnerID=40&md5=327be0652af0cb4996e2bf8dceb6b851},
}

@Article{Duttagupta2012,
  author          = {Duttagupta, S. and Nambiar, M.},
  title           = {Performance extrapolation using load testing results},
  journal         = {International Journal of Simulation: Systems, Science and Technology},
  year            = {2012},
  volume          = {13},
  number          = {2},
  pages           = {72-80},
  issn            = {14738031},
  note            = {cited By 2},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Load testing of IT applications is fraught with the challenges of time to market, quality of results, high cost of commercial tools, and accurately representing production like scenarios. It would help IT projects to be able to test with a small number of users and extrapolate to scenarios with much larger number of users. This in turn will cut down cycle times and costs and allow for a variety of extrapolations closer to production. In this paper, we present a simple extrapolation technique based on statistical empirical modelling that analyses application workload based on its service demand on various system resources. The proposed strategy is also applied to predict the performance of mixture workloads before the system encounters any hardware resource bottleneck. The strategy is found to be more than 90% accurate for a range of applications running across a number of hardware servers. The technique has currently been validated for scenarios where the hardware is the bottleneck and is extensible to a wider range of scenarios as well.},
  author_keywords = {Extrapolation; Load testing; Performance; Regression;multi-class jobs},
  document_type   = {Article},
  keywords        = {Empirical modelling; Extrapolation techniques; Hardware resources; Performance; Performance extrapolation; Quality of results; Regression multi-class jobs; System resources, Computer hardware; Hardware; Load testing, Extrapolation},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879265806&partnerID=40&md5=c7ed2832817664c69d449a938f48342c},
}

@Conference{Bag2012,
  author        = {Bag, A. and Rodi, S. and Pillai, K.},
  title         = {Performance testing of super fast application},
  year          = {2012},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {Performance Testing (both unit and system) is useful to understand application and sub-component(s) performance characteristics. System/Application performance testing gives insight into the overall performance of the application and is useful to debug performance issues before and during production phase. For High Performance Computing (HPC) applications, unit performance testing/proof-of-concept (POC) is very important to help choose from the different options (technology, design, data structures etc). For HPC applications, doing system performance testing becomes very complex as simulating very high input throughputs may necessitate construction of custom load injectors. Also, in HPC applications with complex workflows, simulating proper transaction mix and maintaining stable backend database size becomes complex. Monitoring different data points (latency, throughput) and debugging (log levels) is also tricky because of the overheads those incur. Unit performance testing of critical components involves complex workload and throughput modeling to determine achievable performance. This paper outlines two examples, one for POC through unit performance testing of a very high throughput application at architecture and design phase. The other is of system performance testing of a very high throughput application for SLA certification and tuning purpose.},
  document_type = {Conference Paper},
  journal       = {CMG 2012 International Conference},
  keywords      = {Achievable performance; Back-end database; Critical component; High performance computing (HPC); Performance characteristics; Performance issues; Performance testing; Throughput modeling, Throughput, Load testing},
  language      = {English},
  page_count    = {9},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883061195&partnerID=40&md5=f8a501c27003940313f2c0d709a76a38},
}

@Conference{Costa2012,
  author          = {Costa, B.A. and Lemos, J.M.},
  title           = {Predictive adaptive temperature control in a solar furnace for material stress tests},
  year            = {2012},
  pages           = {1340-1345},
  note            = {cited By 8},
  __markedentry   = {[Jonnathan:]},
  abstract        = {This paper explores the adaptive predictive Musmar algorithm to control the temperature of material samples in a solar furnace. Solar furnaces are devices that are powered by concentrated solar energy and are used in material stress applications. Solar furnaces are characterized by having a nonlinear dynamics, the nonlinear effect between the incident energy and the temperature of the sample, the nonlinear relation between the positioning of the shutter and the incident power applied on the sample, the interaction between the shutter dynamics and the temperature dynamics of the sample and the presence of fast perturbations on sunlight induced by clouds. This work is being developed in the framework of the SFERA project, to automate material stress experiments in solar furnaces of the Odeillo Processes Materials and Solar Energy Laboratory, located at the Oriental Pyrenees in the South of France. © 2012 IEEE.},
  art_number      = {6402719},
  author_keywords = {Adaptive Predictive Control; Solar Furnaces; Thermal Stress},
  document_type   = {Conference Paper},
  doi             = {10.1109/CCA.2012.6402719},
  isbn            = {9781467345033},
  journal         = {Proceedings of the IEEE International Conference on Control Applications},
  keywords        = {Adaptive predictive control; Concentrated solar energy; Incident energy; Incident power; Material stress; Nonlinear effect; Nonlinear relations; Pyrenees; Temperature dynamics, Machine tools; Solar equipment; Temperature control; Thermal stress, Solar furnaces},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873103857&doi=10.1109%2fCCA.2012.6402719&partnerID=40&md5=0d1c785075c83ba297823f6f00cc794c},
}

@Conference{Prasad2012,
  author          = {Prasad, N.S.},
  title           = {Performance testing of lidar components subjected to exposure in space via MISSE 7 mission},
  year            = {2012},
  volume          = {8519},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The objective of the Materials International Space Station Experiment (MISSE) is to study the performance of novel materials when subjected to the synergistic effects of the harsh space environment for several months. MISSE missions provide an opportunity for developing space qualifiable materials. Several laser and lidar components were sent by NASA Langley Research Center (LaRC) as a part of the MISSE 7 mission. The MISSE 7 module was transported to the international space station (ISS) via STS 129 mission that was launched on Nov 16, 2009. Later, the MISSE 7 module was brought back to the earth via the STS 134 that landed on June 1, 2011. The MISSE 7 module that was subjected to exposure in space environment for more than one and a half year included fiber laser, solid-state laser gain materials, detectors, and semiconductor laser diode. Performance testing of these components is now progressing. In this paper, the current progress on post-flight performance testing of a high-speed photodetector and a balanced receiver is discussed. Preliminary findings show that detector characteristics did not undergo any significant degradation. © 2012 SPIE.},
  art_number      = {85190O},
  author_keywords = {International Space Station (ISS); Lidar components; MISSE 7; Space qualification; STS-129; STS-134},
  coden           = {PSISD},
  document_type   = {Conference Paper},
  doi             = {10.1117/12.933275},
  isbn            = {9780819487742},
  issn            = {0277786X},
  journal         = {Proceedings of SPIE - The International Society for Optical Engineering},
  keywords        = {International Space stations; MISSE 7; Space qualification; STS-129; STS-134, Fiber lasers; Lasers; Nanophotonics; Optical radar; Semiconductor lasers, Space optics},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872816281&doi=10.1117%2f12.933275&partnerID=40&md5=35f2353c07afc5ad73df356fac60f433},
}

@Conference{Maeda2012,
  author          = {Maeda, Y. and Ichihara, K. and Shionome, Y. and Sato, T. and Hayashi, T. and Ishida, M. and Kan, H. and Namba, Y. and Takahashi, H. and Miyazawa, T. and Ishibashi, K. and Sakai, M. and Sugita, S. and Haba, Y. and Matsumoto, H. and Mori, H.},
  title           = {A thermal stress test of the depth-graded Pt/C Re ectors used in the ASTRO-H hard x-ray telescope (HXT)},
  year            = {2012},
  volume          = {8443},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The ASTRO-H Hard X-ray Telescope (HXT) to cover hard X-rays up to 80 keV is thin-foil, multi-nested conical optics with depth-graded Pt/C multilayer. The reflectors are made of heat-formed aluminum substrate of the thickness gauged of 200 m of the alloy 5052, followed by epoxy replication on Pt/C-sputtered smooth Pyrex cylindrical mandrels to acquire the X-ray reflective surface. The epoxy layer is 20 m depth. In this paper, we report a thermal stress test of the reflectors of the HXT. The reflectors can experience in various temperature environment either in ground or in space. The temperature range can be as wide as several tens degrees in space dependently on the thermal design of the telescope system. We kept the reflectors in the three different temperatures at 5, 50 and 60 degrees, respectively, for a week. It is found that the surface of the reflectors at 60 degrees or higher temperature were significantly changed. The change appears as wrinkles with a typical scale length of a few tens micron meters. It is noticed that the scale length is equivalent to the depth of the epoxy layer, suggesting the existence of the epoxy layer causes the change in the scale length. No changes on the surface were observed from the 5 and 50 degree samples. No change on X-ray reflectivity was also detected from them. © 2012 SPIE.},
  art_number      = {844359},
  author_keywords = {ASTRO-H; Hard X-ray Telescope; X-ray Optics},
  coden           = {PSISD},
  document_type   = {Conference Paper},
  doi             = {10.1117/12.925847},
  isbn            = {9780819491442},
  issn            = {0277786X},
  journal         = {Proceedings of SPIE - The International Society for Optical Engineering},
  keywords        = {Aluminum substrate; ASTRO-H; Cylindrical mandrel; Epoxy layers; Hard X ray; Hard X-ray telescope; Scale length; Telescope system; Temperature range; Thermal designs; Typical scale; X ray reflectivity; X-ray reflective, Aluminum; Gamma rays; Platinum alloys; Reflection; Space telescopes; Thermal stress, X rays},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871767664&doi=10.1117%2f12.925847&partnerID=40&md5=0c16a178486a3272038e1cc3cc088d57},
}

@Conference{Li2012a,
  author          = {Li, L. and Zhu, L.-L. and Zhai, H. and Liu, D. and Wang, H.-F.},
  title           = {Study on performance test of storage structure base on state scene performance},
  year            = {2012},
  pages           = {570-573},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {This paper is an introduction to software performance automated testing and theory. It introduces the features of Open Xml storage and SQL Server storage. Then this paper sets three state scenes and chooses different test automated tools respectively. Finally, it uses tools to monitor software performance index from these two data storage systems. Results are then analyzed, comparing the quality performance of different storage systems to the same state scene. © 2012 IEEE.},
  art_number      = {6394386},
  author_keywords = {Automated Testing; Open Xml; SQL Server},
  document_type   = {Conference Paper},
  doi             = {10.1109/CSSS.2012.148},
  isbn            = {9780769547190},
  journal         = {Proceedings - 2012 International Conference on Computer Science and Service System, CSSS 2012},
  keywords        = {Automated testing; Automated tools; Data storage systems; Monitor software; Performance tests; Quality performance; Software performance; SQL servers; Storage structures; Storage systems; XML storage, Data storage equipment, Computer science},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873802213&doi=10.1109%2fCSSS.2012.148&partnerID=40&md5=0d5f6e93716bfbd0e1a194a591763520},
}

@Conference{Chae2012a,
  author          = {Chae, E. and Lee, K. and Kim, K.-H. and Lee, J.},
  title           = {Performance test on radio communication device for train control system},
  year            = {2012},
  pages           = {462-465},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Train control system controls the headway and train route to prevent collisions and derailment of train on the basis of the train location. Radio communication based train control system can enhance the headway and safety of train in the manner of using radio communications instead of the wayside equipment such as the track circuit installed in the track. Radio communication based train control system uses the standard of IEEE 802.11 which uses an unlicensed frequency band because there is no dedicated frequency for railways. Since there is the risk where the frequency interference and other interference problems can be occurred because the unlicensed band might be used by various wireless devices, we analyzed wireless environments of Daebul Line which was selected as the test section, and in this paper, we measured the performance of radio communication device to be applied to the radio communication network and selected a optimized location which has no shaded area. © 2012 AICIT.},
  art_number      = {6530378},
  author_keywords = {radio communications; Train control system},
  document_type   = {Conference Paper},
  isbn            = {9788994364216},
  journal         = {Proceedings - 2012 7th International Conference on Computing and Convergence Technology (ICCIT, ICEI and ICACT), ICCCT 2012},
  keywords        = {Communication device; Communication-based train control systems; Frequency interference; Interference problems; Performance tests; Train control systems; Wireless devices; Wireless environment, Control systems; Frequency bands; Radio; Risk assessment; Standards, Radio communication},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881151947&partnerID=40&md5=51770473a91d99025133c72054698551},
}

@Article{Mayer2012a,
  author        = {Mayer, D.A. and Steele, O. and Wetzel, S. and Meyer, U.},
  title         = {CaPTIF: Comprehensive performance testing framework},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year          = {2012},
  volume        = {7641 LNCS},
  pages         = {55-70},
  issn          = {03029743},
  note          = {cited By 2},
  __markedentry = {[Jonnathan:]},
  abstract      = {In this paper we present the design and implementation of a framework for comprehensive performance evaluation of algorithms, modules, and libraries. Our framework allows for the definition of well-defined test inputs and the subsequent scheduling and execution of structured tests. In addition, the framework provides a web-based interface for user interaction and allows for the convenient browsing, plotting, and statistical analysis of test results. We furthermore report on our experience in using the new framework in the development of cryptographic protocols and algorithms-specifically in the context of secure multi-party computation. © 2012 IFIP International Federation for Information Processing.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-642-34691-0_6},
  isbn          = {9783642346903},
  keywords      = {Comprehensive performance; Comprehensive performance evaluation; Cryptographic protocols; Secure multi-party computation; Test inputs; User interaction; Web-based interface, Algorithms; Multimedia systems, Software testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870051454&doi=10.1007%2f978-3-642-34691-0_6&partnerID=40&md5=f2c44d4d5c03381a7780456ad616957f},
}

@Conference{Nagowah2012a,
  author          = {Nagowah, L. and Sowamber, G.},
  title           = {A novel approach of automation testing on mobile devices},
  year            = {2012},
  volume          = {2},
  pages           = {924-930},
  note            = {cited By 8},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Mobile phones and mobile applications have now become an integral part of our everyday life. Mobile application testing plays a pivotal role in making the mobile applications more reliable and defect free. Existing test automation tools have been tailored to perform mobile test automation through mobile emulators. Other tools require the mobile device where the application is installed, to be connected to a computer so that the tests can be run. Obviously, the results obtained from emulators often differ from those obtained on actual mobile devices. To our best knowledge only a few solutions for creating automated tests of mobile applications exist and their functionality is very limited. In this paper, we introduce the idea of implementing a mobile test automation framework MobTAF which performs mobile test automation on the mobile device where connection to a computer is not required. The framework moves the testing infrastructure to the phone, to support test situations that cannot easily be replicated with an emulator. A prototype application was then implemented to test the mobile automation framework, MobTAF. The results prove that MobTAF framework is an efficient way of performing mobile application tests directly on the mobile devices. © 2012 IEEE.},
  art_number      = {6297158},
  author_keywords = {mobile application testing; mobile device test automation; mobile test automation framework; mobile testing; software testing},
  document_type   = {Conference Paper},
  doi             = {10.1109/ICCISci.2012.6297158},
  isbn            = {9781467319386},
  journal         = {2012 International Conference on Computer and Information Science, ICCIS 2012 - A Conference of World Engineering, Science and Technology Congress, ESTCON 2012 - Conference Proceedings},
  keywords        = {Automated test; Automation testing; Defect-free; Integral part; Mobile applications; Mobile automations; Mobile tests; Test Automation; Test automation tool; Testing infrastructure, Automation; Information science; Mobile telecommunication systems; Software testing; Technology, Mobile devices},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867863998&doi=10.1109%2fICCISci.2012.6297158&partnerID=40&md5=33256d3338b521ad5b608c1fd3724ffd},
}

@Conference{Suffian2012,
  author          = {Suffian, M.D.M. and Fahrurazi, F.R.},
  title           = {Performance testing: Analyzing differences of response time between performance testing tools},
  year            = {2012},
  volume          = {2},
  pages           = {919-923},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {This research focuses on the study and evaluation of response time differences given by three tools used for performance testing. The motivation for this research work is to understand the behavior of various performance testing tools towards determining the accuracy of the response time result. It is conducted with the aim of demonstrating and proving that differences of response time do exist between different tools when conducting performance test for the same webpage as well as analyzing the reasons behind that situation. A static HTML webpage is put under load test for 1, 100, 200, 300, 400 and 500 concurrent users performed by the three tools. The findings clearly showed that different performance testing tool gave different response time when conducting load testing on same webpage. The findings are also supported with the justification for these differences, which involve architecture and simulation mechanism of the respective tool. The summary and future work is presented at the end of the research. © 2012 IEEE.},
  art_number      = {6297157},
  author_keywords = {concurrent users; load test; open source tool; performance testing; response time},
  document_type   = {Conference Paper},
  doi             = {10.1109/ICCISci.2012.6297157},
  isbn            = {9781467319386},
  journal         = {2012 International Conference on Computer and Information Science, ICCIS 2012 - A Conference of World Engineering, Science and Technology Congress, ESTCON 2012 - Conference Proceedings},
  keywords        = {concurrent users; Conducting performance; Load test; Open source tools; Performance testing; Simulation mechanisms; Time-differences; Web-page, Engineering research; Information science; Response time (computer systems); Technology; Websites, Load testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867858411&doi=10.1109%2fICCISci.2012.6297157&partnerID=40&md5=d0bbfa09833fdcc4b7c052a8854a659f},
}

@Conference{Ping2012a,
  author          = {Ping, C. and Huang, H. and Zhao, Y.},
  title           = {The performance test of U-shape antenna applied in tunnel detection},
  year            = {2012},
  pages           = {109-114},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Owing to the growth of population, thus increased land scarcity for normal surface road construct and improper city council planning it inflict more tunnel and underground structure constructed. As most of the constructed underground structures are subjected to severe adverse condition which need thorough inspection. To maintain the good inhabitable tunnel structure ground penetrating radar (GPR) always use as a measuring tools. GPR as an inspection tools in tunnel has been plague with series of setback. In this case a new type of antenna has been introduced in order to improve the performance in tunnel inspection. An emphasize part of the antenna design must be ensuring the directivity, bandwidth characteristic, radiation efficiency and the penetration depth. This research has been divided into three cases and those cases were performed in order to signify the characteristic of the antenna. Laboratory test and numerical simulation were carried out for the comparison and urged to the optimize solution. In this paper, Agilent E5060A ENA has been used for the laboratory test to examine the performance of the antenna. The FDTD method for numerical simulation is to prove the authenticity of the result of laboratory test. The test result illustrates that; the new designed antenna is suitable for tunnel inspection. The important improvement should be further carried out. Further studies must investigate the application of this type of antenna for the inspection of tunnel lining. ©2012 IEEE.},
  author_keywords = {Antenna; ENA; FDTD; Ground penetratingradar; Lining; Tunnel},
  document_type   = {Conference Paper},
  isbn            = {9781467326636},
  journal         = {2012 14th International Conference on Ground Penetrating Radar, GPR 2012},
  keywords        = {Agilent; Antenna design; Bandwidth characteristics; City council; Directivity; ENA; FDTD; Ground penetrating radar (GPR); Ground penetrating radars; Inspection tools; Laboratory test; Land scarcity; Measuring tools; Performance tests; Radiation efficiency; Surface roads; Tunnel detection; Tunnel inspection; Tunnel structures, Antenna grounds; Antennas; Computer simulation; Finite difference time domain method; Geological surveys; Ground penetrating radar systems; Inspection; Linings; Population statistics; Underground structures, Tunnels},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866787291&partnerID=40&md5=87e1565a962384de5c784e59f214ad9e},
}

@Conference{Jayasinghe2012a,
  author          = {Jayasinghe, D. and Swint, G. and Malkowski, S. and Li, J. and Wang, Q. and Park, J. and Pu, C.},
  title           = {Expertus: A generator approach to automate performance testing in IaaS clouds},
  year            = {2012},
  pages           = {115-122},
  note            = {cited By 26},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Cloud computing is an emerging technology paradigm that revolutionizes the computing landscape by providing on-demand delivery of software, platform, and infrastructure over the Internet. Yet, architecting, deploying, and configuring enterprise applications to run well on modern clouds remains a challenge due to associated complexities and non-trivial implications. The natural and presumably unbiased approach to these questions is thorough testing before moving applications to production settings. However, thorough testing of enterprise applications on modern clouds is cumbersome and error-prone due to a large number of relevant scenarios and difficulties in testing process. We address some of these challenges through Expertus - -a flexible code generation framework for automated performance testing of distributed applications in Infrastructure as a Service (IaaS) clouds. Expertus uses a multi-pass compiler approach and leverages template-driven code generation to modularly incorporate different software applications on IaaS clouds. Expertus automatically handles complex configuration dependencies of software applications and significantly reduces human errors associated with manual approaches for software configuration and testing. To date, Expertus has been used to study three distributed applications on five IaaS clouds with over 10,000 different hardware, software, and virtualization configurations. The flexibility and extensibility of Expertus and our own experience on using it shows that new clouds, applications, and software packages can easily be incorporated. © 2012 IEEE.},
  art_number      = {6253496},
  author_keywords = {Aspect; Automation; Clouds; Code Generation; Datacenter; EC2; Emulab; IaaS; Multi-Tier; Open Cirrus; Performance; Scalability; Template; Testing},
  document_type   = {Conference Paper},
  doi             = {10.1109/CLOUD.2012.98},
  isbn            = {9780769547558},
  journal         = {Proceedings - 2012 IEEE 5th International Conference on Cloud Computing, CLOUD 2012},
  keywords        = {Aspect; Code Generation; Datacenter; EC2; Emulab; IaaS; Multi-tier; Open Cirrus; Performance; Template, Automation; Cloud computing; Clouds; Industry; Network components; Program compilers; Scalability; Testing, Software testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866753912&doi=10.1109%2fCLOUD.2012.98&partnerID=40&md5=f1d73634e9c1299b2fc7932e89d0c2ba},
}

@Conference{Pinheiro2012,
  author          = {Pinheiro, P.V. and Boavida, F.},
  title           = {Some results on network mobility stress testing},
  year            = {2012},
  pages           = {92-99},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In the last few years, several IP network mobility proposals have come to light. Nevertheless, as none of these solutions has been deployed, the respective studies on functional characteristics, performance, scalability and signalling load are mostly limited to simple proof-of-concept studies, in reduced-size lab settings and/or simulated environments, with low or modest traffic loads. This paper presents a comparative study of three network mobility solutions - one of them proposed by the authors - with which it is intended to evaluate their behaviour under heavy load traffic. The study resorts to a network mobility emulator developed by the authors. After performing an extensive set of tests, based on the obtained results we are able to conclude that the proposed network mobility solution has clear performance advantages over other, more traditional solutions, regardless the number of mobile nodes, packet inter-arrival times, number of nesting levels, and percentage of route-optimised flows. © 2012 IEEE.},
  art_number      = {6217986},
  author_keywords = {network mobility; route optimisation; stress tests},
  document_type   = {Conference Paper},
  doi             = {10.1109/BCFIC.2012.6217986},
  isbn            = {9781467316712},
  journal         = {2012 2nd Baltic Congress on Future Internet Communications, BCFIC 2012},
  keywords        = {Comparative studies; Functional characteristics; Heavy loads; Inter-arrival time; IP networks; Mobile nodes; Network mobility; Optimisations; Proof of concept; Reduced size; Simulated environment; Stress test; Stress Testing; Traffic loads, Internet, Internet protocols},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863667215&doi=10.1109%2fBCFIC.2012.6217986&partnerID=40&md5=0e258178d536153ff52bd86a216086ad},
}

@Article{Braun2012,
  author          = {Braun, L.L. and Torrezam, A. and Szezupior Dos Santos, R.H.},
  title           = {Performance tests with LTSP},
  journal         = {IEEE Latin America Transactions},
  year            = {2012},
  volume          = {10},
  number          = {1},
  pages           = {1394-1397},
  issn            = {15480992},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {This article aims to demonstrate through performance tests, that it is possible to reuse outdated machines as effective and productive terminals, with the use of LTSP - Linux Terminal Service Project. Additionally, we will demonstrate that companies and institutions concerned with the environment may find this alternative a measure of computational saving and recycling. © 2005 IEEE.},
  art_number      = {6142490},
  author_keywords = {Linux; LTSP; performance test},
  document_type   = {Conference Paper},
  doi             = {10.1109/TLA.2012.6142490},
  keywords        = {Computational savings; Linux; LTSP; performance test; Performance tests; Terminal service, Computer operating systems},
  language        = {Portuguese},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856947090&doi=10.1109%2fTLA.2012.6142490&partnerID=40&md5=6604d7e0d537b15b3c2d7a2f5976883a},
}

@Conference{Netto2011a,
  author          = {Netto, M.A.S. and Menon, S. and Vieira, H.V. and Costa, L.T. and De Oliveira, F.M. and Saad, R. and Zorzo, A.},
  title           = {Evaluating load generation in virtualized environments for software performance testing},
  year            = {2011},
  pages           = {993-1000},
  note            = {cited By 4},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Before placing a software system into production, it is necessary to guarantee it provides users with a certain level of Quality-of-Service. Intensive performance testing is then necessary to achieve such a level and the tests require an isolated computing environment. Virtualization can therefore play an important role for saving energy costs by reducing the number of servers required to run performance tests and for allowing performance isolation when executing multiple tests in the same computing infrastructure. Load generation is an important component in performance testing as it simulates users interacting with the target application. This paper presents our experience in using a virtualized environment for load generation aimed at performance testing. We measured several performance metrics and varied system load, number of virtual machines per physical resource, and the CPU pinning schema for comparison of virtual and physical machines. The two main findings from our experiments are that physical machines produced steadier and faster response times under heavy load and that the pinning schema is an important aspect when setting up a virtualized environment for load generation. © 2011 IEEE.},
  art_number      = {6008948},
  author_keywords = {Load generation; LoadRunner; Multi-core architecture; Software performance testing; Virtualization},
  document_type   = {Conference Paper},
  doi             = {10.1109/IPDPS.2011.244},
  isbn            = {9780769543857},
  journal         = {IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum},
  keywords        = {Load generation; LoadRunner; Multicore architectures; Software performance testing; Virtualizations, Distributed parameter networks; Quality of service; Software testing; Virtual reality, Load testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-83455263586&doi=10.1109%2fIPDPS.2011.244&partnerID=40&md5=c594ce2e6ff42d9dbbe612b4a9c4ecde},
}

@Article{Wang2011b,
  author          = {Wang, C.},
  title           = {The research and design of NSL-oriented automation testing framework},
  journal         = {Advances in Intelligent and Soft Computing},
  year            = {2011},
  volume          = {128},
  pages           = {367-373},
  issn            = {18675662},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {By analyzing the Selenium and other open source testing tool, the lack of Selenium and the design of testing scripts are given to discuss and try to improve to resolve problems of NLS. These improvements include the using of page elements, enhancement of the response of the heavyweight component, optimization of testing scripts for multi-language versions. The parallel execution strategy for multilingual test cases has been provided, through which the users can execute test cases of multi-language in a great number of test servers at the same time, greatly improving the overall testing efficiency. The testing framework proposed has been applied to the actual web product globalization testing, and achieved very good results. © Springer-Verlag Berlin Heidelberg 2011.},
  author_keywords = {Automation testing; NLS; Selenium; Testing framework},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-642-25989-0_60},
  editor          = {Jin D., Lin S.},
  isbn            = {9783642259883},
  keywords        = {Automation testing; NLS; Open sources; Parallel executions; Test case; Testing efficiency; Testing framework; Testing tools, Open systems; Selenium; Software engineering, Software testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84555208318&doi=10.1007%2f978-3-642-25989-0_60&partnerID=40&md5=00b1f6f8fba663a270b60af1ba414d03},
}

@Conference{DeSousaSantos2011a,
  author          = {De Sousa Santos, I. and Santos, A.R. and Neto, P.D.A.D.S.},
  title           = {Reusing functional testing in order to decrease performance and stress testing costs},
  year            = {2011},
  pages           = {470-474},
  note            = {cited By 3},
  __markedentry   = {[Jonnathan:]},
  abstract        = {This work presents an experimental study of an idea related to the automatic generation of performance and stress testing by reusing functional testing. The idea was implemented in a tool named FERRARE GT. This tool is able to generate both test scripts as well as the data required for their execution. In this study we verified that the use of the method can generate benefits related to cost reduction, from the reduction of test effort and, at the same time, benefits related to test quality, from the improvement of the test relevance for the software development.},
  author_keywords = {Data generation; Experimental study; Non-functional requirements; Software testing},
  document_type   = {Conference Paper},
  isbn            = {1891706292; 9781891706295},
  journal         = {SEKE 2011 - Proceedings of the 23rd International Conference on Software Engineering and Knowledge Engineering},
  keywords        = {Automatic Generation; Data generation; Experimental studies; Functional testing; Non-functional requirements; Stress Testing; Test quality; Test scripts, Cost reduction; Knowledge engineering; Software design, Software testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855528652&partnerID=40&md5=7b757841e25e8a82b9b47d1676c97c14},
}

@Conference{DaSilveira2011a,
  author          = {Da Silveira, M.B. and Rodrigues, E.M. and Zorzo, A.F. and Costa, L.T. and Vieira, H.V. and De Oliveira, F.M.},
  title           = {Generation of scripts for performance testing based on UML models},
  year            = {2011},
  pages           = {258-263},
  note            = {cited By 10},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Software testing process has a high cost when compared to the other stages of software development. Automation of software testing through reuse of software artifacts (e.g. models) is a good alternative for mitigating these costs and making the process much more efficient and efficacious. Model-Based Testing (MBT) is a technique to automatic generation of testing artifacts based on software models. For software development, the most spread modeling language in either the industrial or academic environments is UML. In such environments, it is desirable to reuse UML models also for MBT. avoiding re-building a different model exclusively for testing automation. These are the main reasons that make these semi-formal models an alternative to implementing MBT. Even though there are a lot of testing tools available commercially, to the best of our knowledge, none of them fully uses MBT. Therefore, this paper describes a case study showing how to implement the MBT process to automate test scripts generation and execution in a real-world, context. Furthermore, our solution is generated automatically by a Software Product Line (SPL).},
  author_keywords = {Model-based testing; Performance testing; Software product line},
  document_type   = {Conference Paper},
  isbn            = {1891706292; 9781891706295},
  journal         = {SEKE 2011 - Proceedings of the 23rd International Conference on Software Engineering and Knowledge Engineering},
  keywords        = {Academic environment; Automatic Generation; High costs; Model based testing; Modeling languages; Performance testing; Software artifacts; Software model; Software product line; Software product lines; Test scripts; Testing automation; Testing tools; UML Model, Computer software reusability; Knowledge engineering; Models; Software design; Unified Modeling Language, Software testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855533817&partnerID=40&md5=6d99bc77c1dc9c5337054546ce1a1e97},
}

@Conference{Zhang2011e,
  author          = {Zhang, L. and Chen, Y. and Tang, F. and Ao, X.},
  title           = {Design and implementation of cloud-based performance testing system for web services},
  year            = {2011},
  pages           = {875-880},
  note            = {cited By 7},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Nowadays testing plays an important role in software development process. While software testing is expensive and time-consuming, sufficient testing is hard, especially for a distributed system using web services technique in the real circumstance. The development of cloud computing provides us new ideas to solve these testing problems. To address these issues, we propose a framework which integrates cloud computing and performance testing technologies. In this paper, first we present the architecture of the cloud-based performance testing system for web services (CPTS), which is a portable, extensible and easy-to-use framework for generating and submitting test workloads to computing clouds. Then, we show the process how to use CPTS to run a performance test and present the concept of dynamic migration in CPTS. Finally, we present our experiences with CPTS in Amazon EC2. We found that the CPTS allows a user to easily set up and test a web services system on the cloud and improve test effectively. © 2011 IEEE.},
  art_number      = {6158278},
  author_keywords = {cloud computing; dynamic migration; performance testing; virtual machine; web services},
  document_type   = {Conference Paper},
  doi             = {10.1109/ChinaCom.2011.6158278},
  isbn            = {9781457701016},
  journal         = {Proceedings of the 2011 6th International ICST Conference on Communications and Networking in China, CHINACOM 2011},
  keywords        = {Amazon ec2; Distributed systems; dynamic migration; performance testing; Performance tests; Software development process; Virtual machines, Cloud computing; Instruments; Software engineering; Software testing; Testing; Web services, Websites},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863236099&doi=10.1109%2fChinaCom.2011.6158278&partnerID=40&md5=20341a45f2af5b79332c6a52cb59fc6a},
}

@Conference{Shankar2011a,
  author          = {Shankar, S.S. and Shankar, J.S.},
  title           = {Synthesizable verification IP to stress test system-on-chip emulation and prototyping platforms},
  year            = {2011},
  pages           = {609-612},
  note            = {cited By 4},
  __markedentry   = {[Jonnathan:]},
  abstract        = {One of the biggest challenges today with Pre-silicon System-on-Chip verification is to stress out the SoC to uncover as many corner case design issues by injecting heavy real time data traffic into the system. The inherent efficiency and the performance of the Emulation and FPGA prototyping systems make them the ideal platforms to run these tests. A typical solution is to inject data traffic through protocol exercisers with proprietary hardware (vendor specific slow down solutions) which can bridge the emulated DUT with a real time device or use software API's with transaction based SCE-MI communication infrastructure. The need for a complex input output interface makes the former difficult to be used with all emulators / FPGA prototyping systems while SCE-MI communication infrastructure being protocol specific is a disadvantage. So, a synthesizable verification architecture compliant with SCE-MI 2.0 infrastructure through which the protocol specific traffic is injected through industry standard interfaces. i.e. PIPE (PCIe), UTMI (USB), MII (Ethernet) based on user configured stimuli has been designed and implemented. Being synthesizable, the verification environment can run in both emulation and prototyping platforms effectively stress testing the complete system. © 2011 IEEE.},
  art_number      = {6131936},
  author_keywords = {PIPE; SCE-MI; Stress Testing; UTMI},
  document_type   = {Conference Paper},
  doi             = {10.1109/ISICir.2011.6131936},
  isbn            = {9781612848648},
  journal         = {2011 International Symposium on Integrated Circuits, ISIC 2011},
  keywords        = {Communication infrastructure; Complete system; Complex inputs; Corner case; Data traffic; Design issues; FPGA prototyping; Industry standards; Prototyping platform; Real time; Real-time data; SCE-MI; Software API; Stress test; Stress Testing; System on chips; UTMI; Verification environment; Verification IP, Application specific integrated circuits; Communication; Integrated circuits; Internet protocols; Network architecture; Pipe; Programmable logic controllers, Field programmable gate arrays (FPGA)},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856697009&doi=10.1109%2fISICir.2011.6131936&partnerID=40&md5=fd57a5f6d16baf55e399308683652fde},
}

@Conference{Mudujutla2011,
  author        = {Mudujutla, G. and Hampaiah, U. and Jandhyala, S.},
  title         = {Performance testing challenges \& solutions for asynchronous systems},
  year          = {2011},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {This paper presents challenges faced in typical Asynchronous Systems Performance Testing (ASPT) and workaround solutions applied for them. An Enterprise Service Fulfillment (ESF) system consists of Business Gateways, Application Integrators Customer Relationship Management (CRM) Systems, Order Fulfillment Systems, Fault Resolution Systems and series of other back-end systems such as billing, revenue assurance, work order management, MIS etc. It uses web services, queue communications with high volumes of different business transactions. Stringent business Service Level Agreement (SLAs) (like individual component response times, throughputs, utilizations and End to End (E2E) response times), scaled down test environment and unavailability of back-end components in test environment poses some unique challenges during performance testing of asynchronous systems. This paper elaborates these challenges and presents suitable workaround solutions devised to handle asynchronous transactions for complete performance testing thus providing an assurance on the asynchronous SLAs before the business goes live.},
  document_type = {Conference Paper},
  journal       = {37th International Conference Computer Measurement Group},
  keywords      = {Asynchronous system; Backend system; Business service; Business transaction; Customer relationship management systems; End to end; Enterprise services; Individual components; Order fulfillment; Performance testing; Resolution systems; Revenue assurance; Test Environment; Work order management, Telecommunication systems; Web services, Response time (computer systems)},
  language      = {English},
  page_count    = {7},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872169652&partnerID=40&md5=c164e7574c0ffebb9da0392ccb99725e},
}

@Conference{Liu2011,
  author          = {Liu, C. and Fu, B. and Zhang, H. and Lian, L.},
  title           = {Construction and basic performance tests of underwater monitoring network},
  year            = {2011},
  pages           = {944-947},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {With the rapid development of economy, environmental pollution has become one of the major problems in coastal areas and cities along the river. Real-time observation of the water quality along the river has been considered as an efficient way to control wastewater emission and manage environment of water quality. Traditional ways to observe ocean environment, including satellite telemetry, radar, investigation ship, ocean observation station and etc, are not applicable for water quality observation along river because of their high cost, Poor real-time, low accuracy and so on. Based on Wireless Sensor Networks, the study discussed in this paper proposes a new observation system using under-water multisensory information. After processing multisensory data of each sensor the system transmits it to hub node through wireless sensor networks, and then transmits it to land data center through GPRS wireless network. In order to check the basic performance of this system, the authors have completed the node positioning experiment based on GPS module and the communication experiment based on ZigBee. This paper reports the hardware design and the experimental results. © 2011 ISAROB.},
  author_keywords = {Communication; Underwater; Wireless sensor networks(WSN); ZigBee},
  document_type   = {Conference Paper},
  isbn            = {9784990288051},
  journal         = {Proceedings of the 16th International Symposium on Artificial Life and Robotics, AROB 16th'11},
  keywords        = {Coastal area; Data centers; Environmental pollutions; Hardware design; High costs; Multisensory data; Multisensory information; Observation systems; Ocean environment; Ocean observations; Performance tests; Real-time observation; Underwater; Underwater monitoring; Wastewater emissions, Communication; Data handling; Experiments; Rivers; Robotics; Sensor nodes; Water quality; Wireless sensor networks, Zigbee},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866646527&partnerID=40&md5=9bdb726230cdbb85a3d22ae9d6d4677f},
}

@Article{Yu2011,
  author          = {Yu, Z. and Li, H. and Zhang, X. and Zhang, H. and Dai, Z.},
  title           = {Structure design of bionic gecko's toe and the adhesive locomotion performance test},
  journal         = {Jixie Gongcheng Xuebao/Journal of Mechanical Engineering},
  year            = {2011},
  volume          = {47},
  number          = {21},
  pages           = {7-13},
  issn            = {05776686},
  note            = {cited By 4},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Gecko has a superb locomotive capacity on variety surface, such as the ground, walls, ceilings and other complex environment in space. By analyzing the locomotion of gecko's toe adhesion structure and adhesion methods, bionic gecko's toe is designed which has several minimal adhering folds with flexible cantilever structure. By using multipurpose friction force experimental platform, the adhesion performance of bionic gecko's toe is analyzed, including the changing of the maximum tensile adhesion force of bionic gecko's toe with the adhesion numbers, the different stretching angles, different adhesion trajectories, and so on. The experiment shows that bionic gecko'toe has similar adhesion force performance with gecko's toe. When the bionic gecko's toe is designed for bionic gecko robot foot, the bionic gecko robot successfully achieves 90 degree wall-climbing movement. © 2011 Journal of Mechanical Engineering.},
  author_keywords = {Adhesive locomotion; Bionic gecko's toe; Performance test; Structure design},
  coden           = {CHHKA},
  document_type   = {Article},
  doi             = {10.3901/JME.2011.21.007},
  keywords        = {Adhesion forces; Adhesion method; Adhesion performance; Adhesion structures; Cantilever structures; Complex environments; Experimental platform; Friction force; Performance test; Performance tests; Stretching angle; Structure design; Wall-climbing, Bionics, Adhesion},
  language        = {Chinese},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-83255188048&doi=10.3901%2fJME.2011.21.007&partnerID=40&md5=10f070cf7a2f4471de5508f0b3df5137},
}

@Conference{Dobai2011,
  author          = {Dobai, R. and Baláž, M.},
  title           = {SAT-based generation of compressed skewed-load tests for transition delay faults},
  year            = {2011},
  pages           = {191-196},
  note            = {cited By 3},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The continuous trend to decrease the cost-per-function and to increase the quality of integrated circuits amplifies the test challenges. Overall low production cost can be achieved only by considering the test area overhead, the test application time and the test quality. The fulfillment of these requirements is possible by application of short tests, use of low-overhead design-for-testability methods/standards and targeting more realistic fault models. The satisfiability-based test pattern generator of compressed skewed-load tests for transition delay faults is proposed. The test application is possible to logic cores of system-on-chip even with only one storage element per cell in the wrapper boundary register and in the internal scan chain. Therefore, the test area is kept low while the testability of delay faults is ensured. The proposed method represents a new efficient approach for generating compressed skewed-load tests. The experimental results show significant test length reduction and increased fault coverage. © 2011 IEEE.},
  art_number      = {6037409},
  author_keywords = {Low-overhead; Satisfiability; System-on-chip; Test compression; Test generation; Transition delay fault},
  document_type   = {Conference Paper},
  doi             = {10.1109/DSD.2011.28},
  isbn            = {9780769544946},
  journal         = {Proceedings - 2011 14th Euromicro Conference on Digital System Design: Architectures, Methods and Tools, DSD 2011},
  keywords        = {Low-overhead; Satisfiability; System on chips; Test compression; Test generations; Transition delay faults, Application specific integrated circuits; Delay circuits; Design for testability; Digital circuits; Formal logic; Integrated circuit testing; Microprocessor chips; Programmable logic controllers; Systems analysis, Testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80055005391&doi=10.1109%2fDSD.2011.28&partnerID=40&md5=a811752d235becae9f1aa553f904e911},
}

@Conference{Meng2011a,
  author          = {Meng, X.},
  title           = {Designing approach analysis on small-scale software performance testing tools},
  year            = {2011},
  volume          = {8},
  pages           = {4254-4257},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Currently, most software performance testing tools in the market are large ones designated for enterprises. Aiming at the demand of small-sized and individual customers' conduction of software performance testing, the paper proposes an approach for designing and realizing a small tool for testing. Core design refers to simulating multi-user concurrent operation by simultaneous execution of multithreading and measuring performance of the system tested through whether each threading responses in a correct manner as well as testing data such as period of responding. Testing tool, which is realized by Java language, consists of three modules of case management, test implementation and test report. Multiple designing modes are utilized in a combined manner during designing, which makes the designing scheme a simple one with high efficiency and easy to expand. The market of performance testing is developing in a rapid manner and researching software performance test is gaining increasingly significance. © 2011 IEEE.},
  art_number      = {6023983},
  author_keywords = {designing approach; designing mode; small-scaled testing tool; software performance test},
  document_type   = {Conference Paper},
  doi             = {10.1109/EMEIT.2011.6023983},
  isbn            = {9781612840857},
  journal         = {Proceedings of 2011 International Conference on Electronic and Mechanical Engineering and Information Technology, EMEIT 2011},
  keywords        = {Case management; Concurrent operations; Core design; designing approach; designing mode; Designing scheme; Individual customers; Java language; Measuring performance; Multi-threading; Multi-user; Performance testing; small-scaled testing tool; Software performance; Software performance testing; Test reports; Testing data; Testing tools, Information technology; Java programming language; Mechanical engineering; Multitasking, Software testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053424607&doi=10.1109%2fEMEIT.2011.6023983&partnerID=40&md5=bccd4473f2976b4828a60cfc0de51509},
}

@Conference{Bennett2011a,
  author        = {Bennett, P.M. and Brown, L.L.},
  title         = {Recent successes and changes of the HPCMP sustained systems performance test},
  year          = {2011},
  pages         = {453-462},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {The sustained systems performance (SSP) test has been implemented on certain High Performance Computing Modernization Program (HPCMP) HPC systems in order to quantitatively evaluate updates to system software, hardware repairs, job queuing policy modifications, and revisions to the job scheduler as necessary. The test employs codes used in the system acquisition cycle with proven migration capability to HPCMP HPC systems and non-empirical tests for numerical accuracy. Metrics such as compilation time, queue wait time, benchmark execution time, and total test throughput time are gathered and compared against metric data from previous tests to monitor the systems under test while minimizing impact to the users. Jobs failing to execute properly or in anomalously short or long times are investigated, and the results are reported to system administrators and center directors at each center for appropriate actions. During the past year, the SSP test has been instrumental in surfacing configuration issues with the PBS scheduler and performance issues on several HPC systems. Additionally, the frequency of the SSP test on systems procured in Technology Insertion 2009 (TI-09) and thereafter has increased, with attendant changes in the test cases comprising the test. The SSP test continues to play an important role in monitoring the quality of service delivering HPC to HPCMP users at the system, DoD Supercomputing Resource Center, and vendor levels. © 2011 IEEE.},
  art_number    = {6018026},
  document_type = {Conference Paper},
  doi           = {10.1109/HPCMP-UGC.2010.46},
  isbn          = {9780769543925},
  journal       = {Proceedings - 2010 DoD High Performance Computing Modernization Program Users Group Conference, HPCMP UGC 2010},
  keywords      = {Execution time; High performance computing modernization programs; Job scheduler; Numerical accuracy; Performance issues; Resource center; Sustained systems; System acquisition; System administrators; System softwares; Systems under tests; Technology insertion; Test case; Throughput time, Computer software selection and evaluation; Modernization; Quality of service; Scheduling; Testing, Software testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053367357&doi=10.1109%2fHPCMP-UGC.2010.46&partnerID=40&md5=b0570b27c9cb94ea0d8c39f66e199839},
}

@Conference{Duttagupta2011b,
  author          = {Duttagupta, S. and Mansharamani, R.},
  title           = {Extrapolation tool for load testing results},
  year            = {2011},
  pages           = {69-76},
  note            = {cited By 14},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Load testing of IT applications is fraught with the challenges of time to market, quality of results, high cost of commercial tools, and accurately representing production like scenarios. It would help IT projects to be able to test with a small number of users and extrapolate to scenarios with much larger number of users. This in turn will cut down cycle times and costs and allow for a variety of extrapolations closer to production. We present a simple extrapolation technique based on statistical empirical modeling, which we have found to be more than 90% accurate across a range of applications running across a number of hardware servers. The technique has currently been validated for scenarios where the hardware is the bottleneck and is extensible to a wider range of scenarios as well. © 2011 Society for Modeling & Simu.},
  art_number      = {5984849},
  author_keywords = {Extrapolation; load testing; regression; S-Curves},
  document_type   = {Conference Paper},
  isbn            = {9781617823091},
  journal         = {Proceedings of the 2011 International Symposium on Performance Evaluation of Computer and Telecommunication Systems, SPECTS 2011},
  keywords        = {Commercial tools; Cycle time; Empirical modeling; Extrapolation techniques; Extrapolation tools; High costs; IT applications; IT project; Quality of results; regression; S-Curves; Testing results; Time to market, Computer hardware; Computer networks; Extrapolation; Information technology; Telecommunication systems, Load testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052609688&partnerID=40&md5=edf79fd99df53bf8edd6c2a35f45ea2f},
}

@Article{Fang-Ying2011,
  author          = {Fang-Ying, Y.},
  title           = {Macro stress testing with a macroeconomic credit risk model for China},
  journal         = {Communications in Computer and Information Science},
  year            = {2011},
  volume          = {227 CCIS},
  number          = {PART 4},
  pages           = {25-31},
  issn            = {18650929},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In order to test the overall credit risk of loans of China's banking system, a macroeconomic credit risk model is designed, including a multiple linear regression model describing default probability, and a set of regression models describing macroeconomic environment. Studies show that bank loan default rates and key macroeconomic factors are related. Then stress tests are implemented one by one according to different shocks. The results showed that most banks continue to profit even at 95% confidence level when estimated risk of loss, reflecting a moderate credit risk in the banking system. However, if confidence level rises to 99% when estimated risk of loss, the banking system will face significant losses. The results show that it is necessary to prevent the credit risk of real estate loans and government debt. © 2011 Springer-Verlag.},
  author_keywords = {credit risk; Macro stress-testing; Monte Carlo method; SUR},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-642-23226-8_4},
  isbn            = {9783642232251},
  keywords        = {Bank loans; Banking systems; Confidence levels; Credit risks; Default probabilities; Macroeconomic environments; MONTE CARLO; Multiple linear regression models; Real estate; Regression model; Stress test; Stress Testing; SUR, Information science; Linear regression; Monte Carlo methods; Online systems; Profitability; Risk assessment, Risk perception},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052347092&doi=10.1007%2f978-3-642-23226-8_4&partnerID=40&md5=ae5d7d24bcdebebd019cb918b1b40d24},
}

@Article{Krejcar2011a,
  author          = {Krejcar, O. and Motalova, L.},
  title           = {Home care web services evaluation by stress testing},
  journal         = {Communications in Computer and Information Science},
  year            = {2011},
  volume          = {171 CCIS},
  pages           = {238-248},
  issn            = {18650929},
  note            = {cited By 2},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Development of software applications result in complete application or solution. The last phase of developing process is the final testing of developed solution. The goal of our paper has focused on this problem in case of web services. The developed testing application can be used for any other software solutions with web service interface. The developed test environment, including application developed for the stress testing is based on Microsoft .NET Framework technology. Our stress testing application allows testing of selected problem areas to find any limitations before the tested developing solution will be set up at customer. By the help of our test application, the hardware solution for the server was selected on the base of selected home care agency needs. © 2011 Springer-Verlag.},
  author_keywords = {Mobile Device; Response Time; SQL Server; Stress testing},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-642-22729-5_20},
  isbn            = {9783642227288},
  keywords        = {Developing process; Developing solutions; Hardware solutions; Home care; Microsoft .NET; Problem areas; Software applications; Software solution; SQL servers; Stress testing; Test applications; Test Environment; Web service interface, Hardware; Mobile devices; Software design; Software testing; User interfaces, Web services},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051575858&doi=10.1007%2f978-3-642-22729-5_20&partnerID=40&md5=f7d27314cc26e42d4ce5f3e03efbd45d},
}

@Article{Lv2011,
  author          = {Lv, B. and Yuan, J. and Wang, Z. and Deng, Q.},
  title           = {Application of Particle Flow Simulation Method for performance test of semi-fixed abrasive tools},
  journal         = {Advanced Science Letters},
  year            = {2011},
  volume          = {4},
  number          = {6-7},
  pages           = {2457-2462},
  issn            = {19366612},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {To reach high surface integrity and high processing efficiency simultaneously in abrasive machining process, a novel abrasive machining method employing the semi-fixed abrasive tool (SFAT) is developed. To provide an effective supplementary mean for experiments and decrease the costs of experiments in the design of the SFAT, simulation works for the performance tests of the SFAT, based on Particle Flow Method, are discussed in this paper. Setup of particle flow code (PFC) model of the SFAT is introduced. A series of virtual performance tests for SFAT including compacting process, shear test, and indentation test are carried out. To verify the effectiveness of the virtual test, real experiments are also done under the same conditions in virtual experiments. In both virtual and real experiments, SFATs made of 1000# abrasive grits are taken as the samples. The results obtained in virtual experiments are compared with these obtained in real experiments. The experimental results show that although the virtual results are not in perfect agreement with the real experimental ones, the virtual results give out the same trend and regularity of the experimental ones and the inaccuracy is acceptable for performance test. It indicates that the simulation model based on particle flow method for performance test of SFAT is feasible to be used as supplementary mean and reduce the cost of real experiments in SFAT design with further studies. © 2011 American Scientific Publishers.},
  author_keywords = {Particle Flow Method; Performance Test; Semi-Fixed Abrasive Tool; Simulation},
  document_type   = {Article},
  doi             = {10.1166/asl.2011.1643},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051499177&doi=10.1166%2fasl.2011.1643&partnerID=40&md5=10f5af1b6002d82e525b0a76fc05bd67},
}

@Article{Liu2011a,
  author          = {Liu, C. and Fu, B. and Zhang, H. and Lian, L.},
  title           = {Construction and basic performance tests of an underwater monitoring network},
  journal         = {Artificial Life and Robotics},
  year            = {2011},
  volume          = {16},
  number          = {1},
  pages           = {98-101},
  issn            = {14335298},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {With the rapid development of the economy, environmental pollution has become one of the major problems in coastal areas and in cities along rivers. Real-time observations of the water quality along rivers have been considered to be an efficient way to control wastewater emission and manage environmental water quality. Traditional ways to observe the ocean environment, including satellite telemetry, radar, investigation ships, ocean observation stations, etc., are not applicable for water-quality observations along rivers because of their high cost, poor real-time information, low accuracy, and so on. Based on wireless sensor networks (WSN), the study reported here proposes a new observation system using underwater multisensory information. After processing the multisensory data from each sensor, the system transmits it to a hub node through WSN, and then transmits it to a land data center through a general packet radio service (GPRS) wireless network. In order to check the basic performance of this system, we completed a node positioning experiment based on a GPS module, and a communication experiment based on ZigBee. This article reports the design of the hardware and the experimental results. © ISAROB 2011.},
  author_keywords = {Observation underwater; Wireless communication; Wireless sensor networks; ZigBee},
  document_type   = {Article},
  doi             = {10.1007/s10015-011-0896-x},
  keywords        = {Coastal area; Data centers; Environmental pollutions; Environmental water; General packet radio services; High costs; Multisensory data; Multisensory information; Observation systems; Observation underwater; Ocean environment; Ocean observations; Performance tests; Rapid development; Real-time information; Real-time observation; Underwater monitoring; Wastewater emissions; Wireless communication; Wireless sensor; Zig-Bee, Coastal zones; Data handling; Emergency traffic control; Experiments; Radar stations; River control; River pollution; Sensors; Wastewater; Water quality; Wireless telecommunication systems, Wireless sensor networks},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959629879&doi=10.1007%2fs10015-011-0896-x&partnerID=40&md5=a5bb856456b1949253b416e8f2dd4c3f},
}

@Article{Zhang2011f,
  author          = {Zhang, H.},
  title           = {Multiple particle swarm optimizers with inertia weight with diversive curiosity and its performance test},
  journal         = {IAENG International Journal of Computer Science},
  year            = {2011},
  volume          = {38},
  number          = {2},
  pages           = {134-145},
  issn            = {1819656X},
  note            = {cited By 5},
  __markedentry   = {[Jonnathan:]},
  abstract        = {This paper presents a new method of curiosity-driven multi-swarm search, called multiple particle swarm optimizers with inertia weight with diversive curiosity (MPSOIWα/DC). Compared to a plain MPSOIW, it has the following outstanding features: (1) Decentralization in multi-swarm exploration with hybrid search, (2) Concentration in evaluation and behavior control with diversive curiosity, (3) Practical use of the results of evolutionary PSOIW, and (4) Their effective combination. This achievement expands the applied object of cooperative PSO with the multi-swarm's decision-making. To demonstrate the effectiveness of the proposal, computer experiments on a suite of multidimensional benchmark problems are carried out. We examine the intrinsic characteristics of the proposal, and compare the search performance with other methods. The obtained experimental results clearly indicate that the search performance of the MPSOIWα/DC is superior to that by the EPSOIW, PSOIW, OPSO, RGA/E, and MPSOα/DC for the given benchmark problems.},
  author_keywords = {Cooperative particle swarm optimization; Diversive and specific curiosity; Evolutionary particle swarm optimizer with inertia weight; Exploitation and exploration; Hybrid search; Localized random search; Stagnation; Swarm intelligence},
  document_type   = {Article},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960046489&partnerID=40&md5=c7ce5fa054574f21670a6785efae3054},
}

@Article{Alberti2011,
  author          = {Alberti, M. and Ciurana, J. and Rodríguez, C.A. and Özel, T.},
  title           = {Design of a decision support system for machine tool selection based on machine characteristics and performance tests},
  journal         = {Journal of Intelligent Manufacturing},
  year            = {2011},
  volume          = {22},
  number          = {2},
  pages           = {263-277},
  issn            = {09565515},
  note            = {cited By 19},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Economic globalization, together with heightened market competition and increasingly short product life cycles are motivating companies to use advanced manufacturing technologies. Use of high speed machining is increasingly widespread; however, as the technology is relatively new, it lacks a deep-rooted knowledge base which would facilitate implementation. One of the most frequent problems facing companies wishing to adopt this technology is selecting the most appropriate machine tool for the product in question and own enterprise characteristics. This paper presents a decision support system for high speed milling machine tool selection based on machine characteristics and performance tests. Profile machining tests are designed and conducted in participating machining centers. The decision support system is based on product dimension accuracy, process parameters such as feed rate and interpolation scheme used by CNC and machine characteristics such as machine accuracy and cost. Experimental data for process error and cycle operation time are obtained from profile machining tests with different geometrical feature zones that are often used in manufacturing of discrete parts or die/moulds. All those input parameters have direct impact on productivity and manufacturing cost. Artificial neural network models are utilized for decision support system with reasonable prediction capability. © Springer Science+Business Media LLC 2009.},
  author_keywords = {Decision support system; High speed machining; Machine tool selection},
  coden           = {JIMNE},
  document_type   = {Article},
  doi             = {10.1007/s10845-009-0286-6},
  keywords        = {Advanced manufacturing technologies; Artificial neural network models; Cycle operation; Dimension accuracy; Direct impact; Economic globalization; Experimental data; Feed-rates; Geometrical features; High speed machining; Input parameter; Interpolation schemes; Knowledge base; Machine accuracy; Machine tool selection; Machining test; Manufacturing cost; Market competition; On-machines; Performance tests; Prediction capability; Process errors; Process parameters; Short product, Competition; Decision making; Design; Knowledge based systems; Machine tools; Manufacture; Milling (machining); Neural networks, Decision support systems},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958783417&doi=10.1007%2fs10845-009-0286-6&partnerID=40&md5=544f913c592f9f9acf8da633ad5dfed5},
}

@Conference{Hua2011,
  author        = {Hua, Z. and Zhao, J.L.},
  title         = {A meta-model approach to scenario generation in bank stress testing},
  year          = {2011},
  pages         = {145-150},
  publisher     = {Jindal School of Management, JSOM},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {In the aftermath of the recent financial tsunami, the newly released Basel III Accord has demanded Scenario-based Stress Testing for banks. However, scenario generation is currently a bottleneck due to great heterogeneity in banking practices and organizational structures, leading to a research gap confronting IT professionals. To this end, we devise a way to treat financial scenario selection as a set-covering problem found in the field of approximation algorithms. Another ingenuity of our approach is to offering a high-level framework in order to accommodate individual bank variations, which we call as a meta-model approach. In addition, we propose a decision-support framework for scenario-based stress testing.},
  document_type = {Conference Paper},
  journal       = {Proceedings - 21st Workshop on Information Technologies and Systems, WITS 2011},
  keywords      = {Approximation algorithms; Decision support systems, Basel III; IT professional; Meta-model approach; Organizational structures; Scenario generation; Scenario-based; Set-covering problems; Stress Testing, Information technology},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901784777&partnerID=40&md5=0aac117b80d4d73ce9c40df847691b56},
}

@Article{Adamoli2011,
  author          = {Adamoli, A. and Zaparanuks, D. and Jovic, M. and Hauswirth, M.},
  title           = {Automated GUI performance testing},
  journal         = {Software Quality Journal},
  year            = {2011},
  volume          = {19},
  number          = {4},
  pages           = {801-839},
  issn            = {09639314},
  note            = {cited By 18},
  __markedentry   = {[Jonnathan:]},
  abstract        = {A significant body of prior work has devised approaches for automating the functional testing of interactive applications. However, little work exists for automatically testing their performance. Performance testing imposes additional requirements upon GUI test automation tools: the tools have to be able to replay complex interactive sessions, and they have to avoid perturbing the application's performance. We study the feasibility of using five Java GUI capture and replay tools for GUI performance test automation. Besides confirming the severity of the previously known GUI element identification problem, we also describe a related problem, the temporal synchronization problem, which is of increasing importance for GUI applications that use timer-driven activity. We find that most of the tools we study have severe limitations when used for recording and replaying realistic sessions of real-world Java applications and that all of them suffer from the temporal synchronization problem. However, we find that the most reliable tool, Pounder, causes only limited perturbation and thus can be used to automate performance testing. Based on an investigation of Pounder's approach, we further improve its robustness and reduce its perturbation. Finally, we demonstrate in a set of case studies that the conclusions about perceptible performance drawn from manual tests still hold when using automated tests driven by Pounder. Besides the significance of our findings to GUI performance testing, the results are also relevant to capture and replay-based functional GUI test automation approaches. © 2011 Springer Science+Business Media, LLC.},
  author_keywords = {Graphical user interfaces; Perfomance analysis; Performance testing; Test automation},
  document_type   = {Article},
  doi             = {10.1007/s11219-011-9135-x},
  language        = {English},
  publisher       = {Kluwer Academic Publishers},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052262857&doi=10.1007%2fs11219-011-9135-x&partnerID=40&md5=87947d27d88a1fa79549023ca406b493},
}

@Article{Pozin2011,
  author        = {Pozin, B.A. and Galakhov, I.V.},
  title         = {Models in performance testing},
  journal       = {Programming and Computer Software},
  year          = {2011},
  volume        = {37},
  number        = {1},
  pages         = {15-25},
  issn          = {03617688},
  note          = {cited By 5},
  __markedentry = {[Jonnathan:]},
  abstract      = {Metamodels ensuring the adequacy of the results of performance testing and its parts were developed; these parts are statement of the problem, initial data, and analysis of experimental results. Tools for the adaptation of metamodels to the characteristics of a specific automated load testing experiment and for the estimation of performance of a wide class of systems for automating business processes are described. © 2011 Pleiades Publishing, Ltd.},
  document_type = {Article},
  doi           = {10.1134/S036176881101004X},
  keywords      = {Business Process; Meta model; Performance testing, Load testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952675416&doi=10.1134%2fS036176881101004X&partnerID=40&md5=3b2cb85087700cdbf4a028a9cddd8171},
}

@Article{Zhu2010,
  author          = {Zhu, Z. and Xia, Y. and Luo, D. and Teng, T.},
  title           = {The design of shield tunnelling machine cutter header's cutting performance test bed},
  journal         = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year            = {2010},
  volume          = {6424 LNAI},
  number          = {PART 1},
  pages           = {356-362},
  issn            = {03029743},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In order to solve the problems of data access and low accuracy on the shield tunnelling machine construction site, a test bed that can simulate the shield tunnelling machine cutter head's cutting performance is designed. The test bed's box uses a fixed cutter head and a turning material bin. The whole configuration is designed to a welding framework. The cutter head is designed to a spoke form. The fixing angle and the distance between different cutters can be adjusted at random. The propelling and loading system of the test bed are controlled in an electro-hydraulic proportional control manner. It can be used to test the single factor and multiple factors that influence the cutter head's cutting performance. © 2010 Springer-Verlag.},
  author_keywords = {cutter head; hydraulic system; shield tunnelling machine; test bed},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-642-16584-9_34},
  isbn            = {3642165834; 9783642165832},
  keywords        = {cutter head; Cutting performance; Data access; Electro-hydraulic proportional control; hydraulic system; Loading system; Machine construction; Multiple factors; Shield tunnelling; Cutter heads; Cutting performance; Data access; Electro-hydraulic proportional control; Hydraulic system; Loading system; Multiple factors; Shield tunnelling machines, Cutting tools; Equipment testing; Hydraulic equipment; Hydraulic machinery; Hydraulics; Machine design; Robotics; Test facilities; Tunneling machines; Cutting tools; Equipment testing; Hydraulic equipment; Hydraulic machinery; Robotics; Testing; Tunneling machines, Cutting; Tunnels},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650441820&doi=10.1007%2f978-3-642-16584-9_34&partnerID=40&md5=d6a767bf768ff4ead4f1944b24eac3bc},
}

@Conference{Schriegel2010,
  author        = {Schriegel, S. and Kirschberger, D. and Trsek, H.},
  title         = {Reproducible IEEE 1588-performance tests with emulated environmental influences},
  year          = {2010},
  pages         = {146-150},
  note          = {cited By 6},
  __markedentry = {[Jonnathan:]},
  abstract      = {The IEEE 1588 standard is widely established and accepted for clock synchronization in Ethernet networks. High accuracy IEEE 1588 implementations require a well-coordinated hardware/software co-design. Processing of sophisticated control algorithms for the time speed of local clocks within synchronization slaves are particularly important. Hence, IEEE 1588 implementations should be tested with respect to certain performance indicators like control loop behavior and synchronization accuracy. Furthermore, interoperability with other devices and standard compliance also need to be considered. The achievable synchronization accuracy depends on environmental conditions, network load and network topology. A test system should be able to emulate these physical conditions. This requires a well-founded knowledge about influences on IEEE 1588 implementations caused by both, environmental conditions and network load. This could be a frequency drift of crystal caused by either temperature variations or mechanical stress. Unfortunately, the standard does not specify an expected behavior in such an environment. Due to lack of standardization and test methods, a system-wide guarantee for synchronization accuracy can only be given for proprietary closed systems. In this paper a reproducible test environment with the ability to emulate environmental conditions is presented, followed by an evaluation of two exemplary implementations. The possibility to guarantee synchronization accuracy with the help of appropriate certification tests in such a specific test environment will be demonstrated. © 2010 IEEE.},
  art_number    = {5609783},
  document_type = {Conference Paper},
  doi           = {10.1109/ISPCS.2010.5609783},
  isbn          = {9781424459797},
  journal       = {ISPCS 2010 - 2010 International IEEE Symposium on Precision Clock Synchronization for Measurement, Control and Communication, Proceedings},
  keywords      = {Certification tests; Clock Synchronization; Closed systems; Control algorithms; Control loop; Environmental conditions; Environmental influences; Ethernet networks; Frequency drifts; Hardware/software co-design; IEEE 1588; Mechanical stress; Network load; Network topology; Performance indicators; Performance tests; Physical conditions; Reproducible tests; Temperature variation; Test Environment; Test method; Test systems, Algorithms; Behavioral research; Benchmarking; Electric network topology; Mechanical clocks; Regulatory compliance; Standards; Stresses; Testing, Synchronization},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650132595&doi=10.1109%2fISPCS.2010.5609783&partnerID=40&md5=5a0982e50ab44ac497eb1e6ff8213bed},
}

@Conference{Xu2010b,
  author          = {Xu, W. and Xu, H. and Xie, Q. and Yang, Y. and Dai, M.},
  title           = {Design of automatic performance test system for CPS},
  year            = {2010},
  volume          = {4},
  pages           = {206-209},
  note            = {cited By 5},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In order to satisfy the needs of comprehensive and accurate performance test for CPS (Control and Protective Switching), an automatic performance test system was studied in this paper. The hardware structure and software was introduced in detail; the hardware system was made up of the industrial control computer, the three-phase current generator, adjustable single-phase power, pneumatic fixture, and so on. The test system software developed by LabVIEW was mainly used to achieve the functions of data acquisition, data processing and data display. The designed system is able to automatically test all functions of different types of CPS, including measurement function, communication function, multiple protection function, and so on. Practical application shows that the test system has following properties: high precision, low cost, strong anti-interference and convenient maintenance. © 2010 IEEE.},
  art_number      = {5610188},
  author_keywords = {Automatic test system; CPS; LabVIEW; Performance test},
  document_type   = {Conference Paper},
  doi             = {10.1109/CMCE.2010.5610188},
  isbn            = {9781424479566},
  journal         = {2010 International Conference on Computer, Mechatronics, Control and Electronic Engineering, CMCE 2010},
  keywords        = {Accurate performance; Anti-interference; Automatic test system; Automatically test; Communication functions; CPS; Data display; Hardware structures; Hardware system; High precision; Industrial control computer; LabViEW; Low costs; Measurement function; Performance tests; Protection function; Single-phase power; Test systems; Three-phase currents, Automatic testing; Computer hardware; Computer programming languages; Computer software maintenance; Data acquisition; Data handling; Electric equipment protection; Mechatronics, Computer control systems},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650034983&doi=10.1109%2fCMCE.2010.5610188&partnerID=40&md5=b4e2e20f1075e2c6bd20853e09de8417},
}

@Conference{Cho2010a,
  author          = {Cho, C.-S. and Lee, D.-C. and Sohn, K.-M. and Park, C.-J. and Kang, J.-H.},
  title           = {Scenario-based approach for blackbox load testing of online game servers},
  year            = {2010},
  pages           = {259-265},
  note            = {cited By 4},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Simply having a large beta test cannot consistently provide stability and performance to game servers, which are major issues in online game development. Therefore, test automations have been used in order to reduce the testing time of online games by simulating highly repetitive tasks and emulating server loads. However, in previous approaches, blackbox testing and scenario-based testing are not supported because they use prerecorded packets of real players as templates, or reuse a subset of the main game client for the test client. In this paper, we propose blackbox testing and scenario-based testing of online games as well as simple load testing. Instead of rewriting the virtual client dummy code, only the game description language and virtual game map are redefined when a new game is to be tested. In addition, an actual testing environment can be mimicked more closely, because complex and various scenarios such as attack, party play, and waypoint movement can be tested through combining actions. We have applied our tools on several online games to verify the effectiveness of our method. © 2010 IEEE.},
  art_number      = {5617141},
  author_keywords = {Blackbox testing; Game description language; Load test; Massive virtual users; Online game testing; Scenario-based testing; Virtual game map},
  document_type   = {Conference Paper},
  doi             = {10.1109/CyberC.2010.54},
  isbn            = {9780769542355},
  journal         = {Proceedings - 2010 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery, CyberC 2010},
  keywords        = {Black-box testing; Description languages; Load test; Massive virtual users; On-line games; Scenario-based testing; Virtual games, Computer aided software engineering; Internet; Servers; Software design; Testing, Load testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649955113&doi=10.1109%2fCyberC.2010.54&partnerID=40&md5=a6bd63e100ca26c643f44badc29feb5e},
}

@Article{Shinbo2010a,
  author          = {Shinbo, H. and Tagami, A. and Ano, S. and Hasegawa, T. and Suzuki, K.},
  title           = {Practical end-to-end performance testing tool for high speed 3G-based networks},
  journal         = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year            = {2010},
  volume          = {6435 LNCS},
  pages           = {205-220},
  issn            = {03029743},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {High speed IP communication is a killer application for 3rd generation (3G) mobile systems. Thus 3G network operators should perform extensive tests to check whether expected end-to-end performances are provided to customers under various environments. An important objective of such tests is to check whether network nodes fulfill requirements to durations of processing packets because a long duration of such processing causes performance degradation. This requires testers (persons who do tests) to precisely know how long a packet is hold by various network nodes. Without any tool's help, this task is time-consuming and error prone. Thus we propose a multi-point packet header analysis tool which extracts and records packet headers with synchronized timestamps at multiple observation points. Such recorded packet headers enable testers to calculate such holding durations. The notable feature of this tool is that it is implemented on off-the shelf hardware platforms, i.e., lap-top personal computers. The key challenges of the implementation are precise clock synchronization without any special hardware and a sophisticated header extraction algorithm without any drop. © 2010 IFIP International Federation for Information Processing.},
  author_keywords = {Clock Synchronization Protocol; End-to-end Performance Tests; Packet Header Analysis},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-642-16573-3_15},
  isbn            = {3642165729; 9783642165726},
  keywords        = {3G Networks; 3rd generation; Analysis tools; Clock Synchronization; End-to-end performance; End-to-end Performance Tests; Error prones; Hardware platform; Header extraction; High speed; IP communications; Killer-application; Know-how; Long duration; Mobile systems; Network node; Observation point; Packet header; Performance degradation; Special hardware; Time stamps; Clock Synchronization; End-to-end performance; Header extraction; IP communications; Killer-application; Off-the-shelf hardwares; Packet header; Performance degradation, Cold heading; Computer hardware; Internet protocols; Mathematical operators; Mechanical clocks; Personal computers; Synchronization; Testing; Clocks; Computer hardware; Hardware; Mechanical clocks; Personal computers; Software testing; Synchronization; Technology transfer, Wireless networks; 3G mobile communication systems},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649831936&doi=10.1007%2f978-3-642-16573-3_15&partnerID=40&md5=0d03447687c70ff9b05c30b604c8819c},
}

@Article{Murth2010,
  author        = {Murth, M. and Winkler, D. and Biffl, S. and Kühn, E. and Moser, T.},
  title         = {Performance testing of semantic publish/subscribe systems},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year          = {2010},
  volume        = {6428 LNCS},
  pages         = {45-46},
  issn          = {03029743},
  note          = {cited By 2},
  __markedentry = {[Jonnathan:]},
  abstract      = {Publish/subscribe mechanisms support clients in observing knowledge represented in semantic repositories and responding to knowledge changes. Currently available implementations of semantic publish/subscribe systems differ significantly with respect to performance and functionality. In this paper we present an evaluation framework for systematically evaluating publish/subscribe systems and its application to identify performance bottlenecks and optimization approaches. © 2010 Springer-Verlag Berlin Heidelberg.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-642-16961-8_14},
  isbn          = {3642169600; 9783642169601},
  keywords      = {Evaluation framework; Knowledge change; Optimization approach; Performance bottlenecks; Performance testing; Publish/subscribe; Publish/Subscribe system; Semantic repository; Evaluation framework; ITS applications; Optimization approach; Performance bottlenecks; Performance testing; Publish/subscribe mechanisms; Publish/Subscribe system; Semantic repository, Internet; Message passing; Publishing; Semantics, Peer to peer networks; Peer to peer networks},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649507306&doi=10.1007%2f978-3-642-16961-8_14&partnerID=40&md5=551e215fb5b0ea77be51ee082fa9e0f4},
}

@Conference{Khanapurkar2010,
  author        = {Khanapurkar, A. and Malan, S. and Nambiar, M.},
  title         = {A framework for automated system performance testing},
  year          = {2010},
  note          = {cited By 5},
  __markedentry = {[Jonnathan:]},
  abstract      = {Single application performance testing methodologies are pretty mature in the industry today. However enterprises need to repeatedly deal with issues like accounting for differences between Test and Production environments, capturing knowledge and wisdom of load testing projects, performing extrapolation and validating results of load testing termed as Enterprise Performance Testing challenges. The paper presents a framework we developed to overcome them. The paper also highlights that even though the science behind load testing has advanced, tools are slow in incorporating these techniques. Copyright © 2010, Unisys Corporation. All rights reserved.},
  document_type = {Conference Paper},
  journal       = {36th International Conference Computer Measurement Group},
  keywords      = {Application performance; Automated systems; Enterprise performance; Performance testing; Production environments, Industry, Automation},
  language      = {English},
  page_count    = {12},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872157819&partnerID=40&md5=01eedcf02b091c5bd5271aaa04469ddb},
}

@Conference{Jo2010a,
  author          = {Jo, H.-J. and Hwang, J.-G. and Lee, K.-M.},
  title           = {Proposal of automated performance testing tool for vital software in train control system},
  year            = {2010},
  pages           = {1151-1155},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In accordance with the development of recent computer technology, the dependency of train control system on the computer software is being increased further, and accordingly, the testing for the safety and reliability of train control system software became more important. Hence, the safety assurance of the vital software running on the train control system is very critical task and yet, not many works have been done. While much efforts have been reported to improve electronic hardware's safety, not so much systematic approaches to evaluate software's safety. In this paper, we suggested an automated tool for performance testing in train control system, and presented its result of implementation. The testing items in the implemented tool had referred to the international standards in relation to the software for train control system, such as IEC 61508 and IEC 62279. In these international standards, 'performance testing' for train control system S/W has to be recommended highly. ©ICROS.},
  art_number      = {5669732},
  author_keywords = {Performance testing; Software safety; Train control system},
  document_type   = {Conference Paper},
  isbn            = {9781424474530},
  journal         = {ICCAS 2010 - International Conference on Control, Automation and Systems},
  keywords        = {Automated tools; Computer technology; Critical tasks; Electronic hardwares; IEC 61508; International standards; Performance testing; Safety assurance; Software safety; Train control systems, Automation; Computer control; Computer software selection and evaluation; Computer testing; Control theory; Remote control; Safety testing; Software reliability; Standards, Computer control systems},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78751498420&partnerID=40&md5=8732332e84f196e695ba5c74e7b1a98a},
}

@Article{Ruiz2010,
  author          = {Ruiz, A.S. and Peralta-Ramirez, M.I. and Garcia-Rios, M.C. and Muñoz, M.A. and Navarrete-Navarrete, N. and Blazquez-Ortiz, A.},
  title           = {Adaptation of the trier social stress test to virtual reality: Psycho-phsyiological and neuroendocrine modulation},
  journal         = {Journal of Cyber Therapy and Rehabilitation},
  year            = {2010},
  volume          = {3},
  number          = {4},
  pages           = {405-415},
  issn            = {17849934},
  note            = {cited By 7},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The Trier Social Stress Test (TSST; Kirschbaum et al., 1993) is currently the most commonly used psychosocial stressor to generate a response of the axes involved in stress. The TSST has proven effective in the activation of the hypothalamic-pituitary-adrenal axis. In addition, new technologies, such as virtual reality (VR), are being integrated into stress research protocols (Kelly et al., 2007). To determine whether TSST as applied to VR leads to the sympathetic and neuroendocrine activation in a group of healthy individuals. Also, this study aims to connect this response with different psychological variables regarding stress vulnerability, psychopathology, and personality. Twenty-one university students (6 male and 15 female) were exposed to a modified version of the TSST adapted to a virtual environment (VE), in which they have to deliver a speech. Electrodermal activity and salivary cortisol secretion were simultaneously registered at different instances. After the task, sympathetic activation was observed in all participants, as well as increase in the cortisol secretion in 14 of the students. This increase was statistically significant in the moment prior to the speech and the moment after in the responder group. In the same fashion, statistically significant differences were found in the responder group only regarding obsession and compulsion scales and extroversion, which were higher in the responder group. Our findings support the use of the TSST paradigm in VR as an experimental situation appropriate to research designs in laboratory aiming to study the modulation of the axes implied in response to stress. © Virtual Reality Medical Institute.},
  author_keywords = {Hypothalamic-pituitary-adrenal axis; Psychophysiological activation; Salivary cortisol; TSST; Virtual reality},
  document_type   = {Article},
  keywords        = {hydrocortisone, adrenergic stimulation; adult; article; compulsion; controlled study; extraversion; female; human; human experiment; hydrocortisone release; hypophysis adrenal system; male; mental disease; mental task; neuroendocrine system; obsession; personality; psychologic test; psychophysiology; speech; task performance; Trier Social Stress Test; university student; virtual reality},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960377329&partnerID=40&md5=664f6a024a2ba96b9445ab9dd65db964},
}

@Conference{Quan2010a,
  author          = {Quan, X. and Lu, L.},
  title           = {Session-based performance test case generation for web applications},
  year            = {2010},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {There are many techniques and tools for Web application testing, but few of these address the procedure for gathering user session data accessed in a production environment to assist in testing Web application performance. In this paper, we present a session-based approach to automatically generate performance test cases by exploiting user session information taken from server logs. Such test cases are used for generating synthetic workload to evaluate performance. This paper illustrates the prototype implementation of our session-based performance test case generation approach.},
  art_number      = {5681735},
  author_keywords = {Decision tree; Performance test; User session; Web applications},
  document_type   = {Conference Paper},
  isbn            = {9789623676960},
  journal         = {SCMIS 2010 - Proceedings of 2010 8th International Conference on Supply Chain Management and Information Systems: Logistics Systems and Engineering},
  keywords        = {Performance test; Performance tests; Production environments; Prototype implementations; Server logs; Synthetic workloads; Test case; User session; User sessions; WEB application; Web application testing, Decision trees; Information systems; Logistics; Supply chain management; Supply chains; Testing; World Wide Web, Information management},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551531716&partnerID=40&md5=6eebcffd13fda7913e0bc130dea10f84},
}

@Conference{Yun2010a,
  author          = {Yun, S. and Lee, B.-J. and Lee, Y.J. and Sung, S.},
  title           = {Real-time performance test of an vision-based inertial SLAM},
  year            = {2010},
  pages           = {2423-2426},
  note            = {cited By 5},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Despite its precise positioning performance, a GPS based navigation system may require the reference or augmentation station in close boundaries and is liable to be affected by satellite observation environments. Thus, this paper presents a vision-based inertial SLAM navigation system which can operate in a real-time manner and uses purely unknown feature points in order to cope with the limited GPS/INS integration environment. And real-time performance of the presented system is verified via indoor test. ©ICROS.},
  art_number      = {5670282},
  author_keywords = {Heterogeneous sensor integration; IMU; Real-Time; Relative positioning; Vision sensor},
  document_type   = {Conference Paper},
  isbn            = {9781424474530},
  journal         = {ICCAS 2010 - International Conference on Control, Automation and Systems},
  keywords        = {Heterogeneous sensors; IMU; Real-Time; Relative positioning; Vision sensor, Navigation; Navigation systems, Sensors},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78751513600&partnerID=40&md5=9f0fe8c00ed61ed243cbb5b68f437ed5},
}

@Conference{Bian2010,
  author          = {Bian, W. and Yan, Z. and He, J. and Ma, C. and Zhang, C. and Chan, M.},
  title           = {Correlation between gated-diode R-G current and performance degradation of SOI n-MOSFETs after F-N stress test},
  year            = {2010},
  volume          = {2},
  pages           = {725-728},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {A correlation between the gated-diode R-G current and the performance degradation of SOI n-channel MOS transistor after F-N stress test has been demonstrated in this paper. Due to increase of interface traps after F-N stress test, the generation-recombination (R-G) current of the gated-diode in the SOI-MOSFET architecture increases while the performance characteristics of MOSFET transistor such as the saturation drain current and sub-threshold slope generate degradation. From a series of experimental measurements of the gated-diode and the SOI-MOSFET DC characteristics, a linear decrease of the drain saturation current and increase of the threshold voltage as well as the like-line rise of the sub-threshold swing and the corresponding degradation of the trans-conductance are also observed. These results provide theoretical and experimental evidences for us to use the gated-diode tool to monitor SOI-MOSFET degradation.},
  author_keywords = {F-N stress; Gated-diode method; Interface traps; MOSFET degradation; SOI technology},
  document_type   = {Conference Paper},
  isbn            = {9781439834022},
  journal         = {Nanotechnology 2010: Electronics, Devices, Fabrication, MEMS, Fluidics and Computational - Technical Proceedings of the 2010 NSTI Nanotechnology Conference and Expo, NSTI-Nanotech 2010},
  keywords        = {F-N stress; Gated-diode method; Interface traps; MOSFET degradation; SOI technology, Current voltage characteristics; Degradation; Diodes; Drain current; Fluidics; Nanotechnology; Silicon on insulator technology; Transistor transistor logic circuits, MOSFET devices},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78049418124&partnerID=40&md5=fd28b970df3b1e6a02401c6c5d870c66},
}

@Conference{Hao2010a,
  author          = {Hao, D. and Chen, Y. and Tang, F. and Qi, F.},
  title           = {Distributed agent-based performance testing framework on Web Services},
  year            = {2010},
  pages           = {90-94},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Web Services are applied widely in the field of information technology, and performance testing for Web Services applications has become an important problem. This paper introduces the method of performance testing, and proposes a framework of agent-based performance testing on Web Services, which includes TestFlow Generator, Scenario Creator, Test Manager, Load Generation Agent and Test Analyzer. And the implementation of kernel modules in the framework is introduced especially. To realize the load allocation to distributed Load Generation Agents from Test Manager, a queue-based allocation strategy is given. © 2010 IEEE.},
  art_number      = {5552290},
  author_keywords = {Allocation strategy; Load generation; Performance testing; Web Services},
  document_type   = {Conference Paper},
  doi             = {10.1109/ICSESS.2010.5552290},
  isbn            = {9781424460526},
  journal         = {Proceedings 2010 IEEE International Conference on Software Engineering and Service Sciences, ICSESS 2010},
  keywords        = {Agent based; Allocation strategy; Distributed agents; Distributed loads; Kernel modules; Load allocation; Load generation; Performance testing; Performance testing framework, Management; Managers; Software engineering; Web services, Load testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77957856652&doi=10.1109%2fICSESS.2010.5552290&partnerID=40&md5=007ca5232f08e83128a98036dac42dbc},
}

@Conference{Krizanic2010a,
  author          = {Križanić, J. and Grgurić, A. and Mošmondor, M. and Lazarevski, P.},
  title           = {Load testing and performance monitoring tools in use with AJAX based web applications},
  year            = {2010},
  pages           = {428-434},
  note            = {cited By 16},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In order to deliver quality assured software and avoid potential costs caused by unstable software, software testing is essential in software lifecycle. Load testing is one of the testing types with high importance. It is usually accompanied by performance monitoring of the hosting environment. In the case of web applications which are today widely used, one fact is obvious: most of web applications are public and used by vast number of users, which are making a considerable traffic load on hosting environments and web applications. Load testing and performance monitoring become facilitated with existing tools aimed for load testing and performance monitoring. In the paper we analyze and compare several existing tools which facilitate load testing and performance monitoring, in order to find the most appropriate tools by criteria such as ease of use, supported features, and license. Selected tools were put in action in the real environment, through several web applications. For the case study one of the web applications is used in order to introduce different capabilities of tools, including distributed testing, assembling of test scenario from previously recorded usage scenarios, security support, results analysis, monitoring of key parameters, and reporting and alerting about changes of these parameters.},
  art_number      = {5533420},
  author_keywords = {AJAX; Load testing; Performance monitoring; Web applications},
  document_type   = {Conference Paper},
  isbn            = {9789532330502},
  journal         = {MIPRO 2010 - 33rd International Convention on Information and Communication Technology, Electronics and Microelectronics, Proceedings},
  keywords        = {AJAX; Deliver quality; Distributed testing; Ease of use; Key parameters; Performance monitoring; Real environments; Results analysis; Security support; Software life cycles; Test scenario; Traffic loads; Usage scenarios; WEB application, Computer software selection and evaluation; Information technology; Microelectronics; Monitoring; Software testing; World Wide Web, Load testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956356687&partnerID=40&md5=c5a4507e719cbf1e392bc2283e45600d},
}

@Article{Lu2010,
  author          = {Lu, L. and Quan, X.},
  title           = {Session-based user behavior meta-model of web applications for user-level QoS load testing},
  journal         = {International Journal of Digital Content Technology and its Applications},
  year            = {2010},
  volume          = {4},
  number          = {4},
  pages           = {28-42},
  issn            = {19759339},
  note            = {cited By 4},
  __markedentry   = {[Jonnathan:]},
  abstract        = {With the rapid development of Service-Oriented Architecture (SOA) and Service-Oriented Computing (SOC), the Quality of Service (QoS) is more and more essential than before. There are a number of tools and techniques for Web application testing, but few of these have addressed the procedure to gather user session data accessed in the production environment to assist testing SOA and SOC Web application performance, so as to apply appropriate user-level quality of service policy (user-level QoS) according to the test result. In this paper, we present a session-based user behavior meta-model (SUBM) to automatically generate test cases for user-level QoS load testing. SUBM represents realistic user behavior by exploiting user session information taken from server logs. The major contribution of this paper is the fundamental role of user behavioral authenticity in load testing. This paper also illustrates the prototype implementation of our session-based user behavior meta-model.},
  author_keywords = {Decision tree; Load testing; User session; Web applications},
  document_type   = {Article},
  doi             = {10.4156/jdcta.vol4.issue4.3},
  keywords        = {Meta model; Production environments; Prototype implementations; Rapid development; Server logs; Service-oriented computing; Test case; Test results; Tools and techniques; User behaviors; User sessions; User-level QoS; WEB application; Web application testing; Web applications, Behavioral research; Decision trees; Information services; Quality control; Quality of service; Software prototyping; World Wide Web, Load testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651559753&doi=10.4156%2fjdcta.vol4.issue4.3&partnerID=40&md5=b7e517c7a2c4d7cfd45bb3f6210966cf},
}

@Conference{Nieminen2009a,
  author          = {Nieminen, M. and Räty, T. and Palokangas, J.},
  title           = {Stress testing the Logical Decision Making Server of a surveillance system},
  year            = {2009},
  pages           = {98-103},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The current generation of distributed and automated physical location surveillance systems faces high demands for robustness and reliability. We present and evaluate the design of the Logical Decision Making Server (LDMS), a rule-based automated decision making component used in the Single Location Surveillance Point (SLSP) system. To validate the robustness of the LDMS design for operation in the SLSP environment, we design and conduct a stress test experiment in which large load of TCP/IP input messages is sent instantaneously to the LDMS prototype implementation using the Nethawk EAST software. The stress test results are compared to measurements obtained during a real-life scenario. The LDMS is observed to withstand a significant amount of load without crashing, and its performance is can be considered sufficient for the SLSP system needs. A detailed analysis of results however shows an increase in the latency resulting from an extreme temporal load. We identify potential areas in the design to be improved if demands for higher response rates arise. The research is based on the construction of the related publications and technologies, and the results are established from the testing and validation of the implemented LDMS within the SLSP system. © 2009 IEEE.},
  art_number      = {5279915},
  author_keywords = {Component; Decision making; Stress testing; Surveillance},
  document_type   = {Conference Paper},
  doi             = {10.1109/VALID.2009.16},
  isbn            = {9780769537740},
  journal         = {1st International Conference on Advances in System Testing and Validation Lifecycle, VALID 2009},
  keywords        = {Automated decision making; Current generation; High demand; Logical decisions; Physical locations; Prototype implementations; Response rate; Rule based; Single location; Stress test; Stress Testing; Surveillance systems; Temporal loads, Design; Large scale systems; Monitoring; Security systems; Software prototyping; System theory, Decision making},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-72349089991&doi=10.1109%2fVALID.2009.16&partnerID=40&md5=14320bf7ef2552c1a168f8445994fbf5},
}

@Conference{Volkov2009,
  author        = {Volkov, O.},
  title         = {Custom protocol load testing - The case of visual studio test edition},
  year          = {2009},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {While there is a large variety of load testing tools aimed at the general web/web services based application today, there is a surprising dearth of options for load testing complex, composite custom-built systems that use non-standard messaging protocols. The paper will focus on a real case of implementing a Visual Studio 2008-based performance testing solution for an in-house built bulk document processing application, the challenges and lessons learned, and the unique aspects of using a performance testing tool that is really a part of a well integrated development and testing framework.},
  document_type = {Conference Paper},
  journal       = {35th International Conference Computer Measurement Group},
  keywords      = {Document processing applications; Integrated development; Messaging protocols; Performance testing; Testing framework; Testing tools; Visual studios, Measurements},
  language      = {English},
  page_count    = {10},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872126911&partnerID=40&md5=845b268dcfc0e8a73c2e981c03e6fa14},
}

@Conference{Tremblay2009,
  author        = {Tremblay, J. and El-Gamal, S. and Wattanasanticharoen, E. and Benmokrane, B.},
  title         = {Reinforced concrete pile load testing with fiber optic sensor},
  year          = {2009},
  note          = {cited By 2},
  __markedentry = {[Jonnathan:]},
  abstract      = {Pile load testing provides key information about pile design for a specific geological ground structure. These tests are required to guarantee that the piles will meet long term stability requirements for the foundation of the building. There are many types of sensor that can be used to monitor strain along the pile during pile load testing. The most commonly used sensor is the Vibrating Wire Strain Gauge (VWSG). Each VWSG has its own electrical cable which will have to withstand the concrete or grout pouring stage as well as the curing cycle. By the time the pile is ready for testing, a certain percentage of VWSG signals have often been lost. This paper presents a novel approach using Concrete Embeddable Fiber Optic Strain Gauges. One of the fiber optic based sensor advantage is to be able to daisy-chain the sensors. That is, reducing the number of cables along the pile. The optical cable can also be designed to withstand very harsh environments without adding too much to the cost of the sensors. This paper will also present comparative results as well as future possibilities to reduce cost and time for pile load testing.},
  document_type = {Conference Paper},
  isbn          = {9783905594522},
  journal       = {Structural Health Monitoring of Intelligent Infrastructure - Proceedings of the 4th International Conference on Structural Health Monitoring of Intelligent Infrastructure, SHMII 2009},
  keywords      = {Curing cycle; Electrical cables; Ground structure; Harsh environment; Long term stability; Pile load testing; Reduce costs; Vibrating wire, Cables; Concretes; Reinforced concrete; Sensors; Strain gages; Structural health monitoring, Piles},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896805126&partnerID=40&md5=2080c1adcd3548e69f0757b9fd893811},
}

@Conference{Johnson2009,
  author        = {Johnson, P.},
  title         = {Load testing on a budget, Part II},
  year          = {2009},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {An earlier paper provided a introductory tutorial on using the open-source tool JMeter to load test a web application. But that paper just scratched the surface of what JMeter is capable of. This paper continues where that paper left off, describing how you can make use of some of the other capabilities of JMeter to load test applications. This paper is provided as a tutorial giving specific steps to accomplish various tasks. Copyright © 2009, Unisys Corporation. All rights reserved.},
  document_type = {Conference Paper},
  journal       = {35th International Conference Computer Measurement Group},
  keywords      = {Load test; Open source tools; WEB application, Measurements},
  language      = {English},
  page_count    = {12},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872142129&partnerID=40&md5=da0540f9539f7cf71869584c230eced8},
}

@Article{Bainbridge2009,
  author        = {Bainbridge, D. and Witten, I.H. and Boddie, S. and Thompson, J.},
  title         = {Stress-testing general purpose digital library software},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year          = {2009},
  volume        = {5714 LNCS},
  pages         = {203-214},
  issn          = {03029743},
  note          = {cited By 4},
  __markedentry = {[Jonnathan:]},
  abstract      = {DSpace, Fedora, and Greenstone are three widely used open source digital library systems. In this paper we report on scalability tests performed on these tools by ourselves and others. These range from repositories populated with synthetically produced data to real world deployment with content measured in millions of items. A case study is presented that details how one of the systems performed when used to produce fully-searchable newspaper collections containing in excess of 20 GB of raw text (2 billion words, with 60 million unique terms), 50 GB of metadata, and 570 GB of images. © 2009 Springer.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-642-04346-8_21},
  isbn          = {3642043453; 9783642043451},
  keywords      = {D-space; General purpose; Open-source digital library systems; Real world deployment; Scalability test, Metadata; Research, Digital libraries},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952020187&doi=10.1007%2f978-3-642-04346-8_21&partnerID=40&md5=77f140911691a45466a48ccdc0f15fb9},
}

@Conference{Kim2009d,
  author        = {Kim, H. and Choi, B. and Wong, W.E.},
  title         = {Performance testing of mobile applications at the unit test level},
  year          = {2009},
  pages         = {171-180},
  note          = {cited By 13},
  __markedentry = {[Jonnathan:]},
  abstract      = {With the rapid growth of the wireless market and the development of various mobile devices, innovative methods and technologies to produce high-quality mobile applications and reduce time to market have been emerging. Mobile applications are often characterized by an array of limitations such as the short development lifecycle to gain a competitive advantage and difficulties to update once released. Hence, rigorous testing on the applications is required before distribution to the market, including structural white-box, functional black-box, integration and system testing. Although recently performance testing at the system test level has become crucial given its direct connection with the product quality improvement, most such tests are confined to the areas of load, usability, and stress testing. Moreover, the implementation itself is insufficient due to the limitations of the development environment. This paper proposes a method to support performance testing utilizing a database established through benchmark testing in emulator-based test environment at the unit test level. It also presents the tool that supports the proposed method of performance testing and verifies the reliability of performance test results through experiments. © 2009 IEEE.},
  art_number    = {5325380},
  document_type = {Conference Paper},
  doi           = {10.1109/SSIRI.2009.28},
  isbn          = {9780769537580},
  journal       = {SSIRI 2009 - 3rd IEEE International Conference on Secure Software Integration Reliability Improvement},
  keywords      = {Benchmark testing; Black boxes; Competitive advantage; Development environment; High quality; Innovative method; Mobile applications; Performance testing; Performance tests; Product quality; Rapid growth; Stress Testing; System test; System testing; Test Environment; Time to market; Unit tests; Wireless market, Commerce; Competition; Concurrent engineering; Mobile devices; Quality assurance; Software reliability; Testing, Load testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-72849129516&doi=10.1109%2fSSIRI.2009.28&partnerID=40&md5=c04e2c803a1d0214534175967a28fcee},
}

@Conference{Nivas2009,
  author        = {Nivas, T.},
  title         = {Guidelines for better performance testing},
  year          = {2009},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {Performance testing forms a fundamental part of any organization's software development lifecycle. Understanding large and complex application systems and then running end to end performance tests is of utmost importance, in order to avoid issues in production. Software systems are almost never perfect, but trying to avoid most of the basic issues/bugs before the application is deployed in production is a good practice. Running a test after choosing any one of the multitudes of free test tools available on the Internet or licensed tools is only a small part of the process. Even before you begin writing test scripts it is essential to understand the workload mix, the data flow, the components that make up the end to end system and the infrastructure available for testing. It is also necessary to assess the risks involved and come up with a mitigation plan. Once tests have been run and data collected it is also extremely vital to properly analyze data and present it, so that all stakeholders involved get a clear picture of the results. This paper will list out steps and guidelines that could be followed to successfully run performance tests. It will explain the criteria for creating good test plans, executing tests, analyzing the raw data and then presenting them in a manner that would be beneficial in understanding what and where if any, bottlenecks lie in the application. The paper will also present ways and tools that cold be employed to capture data during tests and how raw data could be analyzed and visually depicted to make it clear to the stakeholders viewing the test results.},
  document_type = {Conference Paper},
  journal       = {35th International Conference Computer Measurement Group},
  keywords      = {Complex applications; Data flow; End-to-end performance; End-to-end systems; Good practices; Mitigation plans; Performance testing; Performance tests; Software development life cycle; Software systems; Test plan; Test scripts; Test tools, Data visualization; Software engineering, Testing},
  language      = {English},
  page_count    = {12},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872139667&partnerID=40&md5=04a395fd7e98ea007dfd49ac18cab49e},
}

@Article{Bozdag2009,
  author          = {Bozdag, E. and Meshah, A. and van Deursen, A.},
  title           = {Performance testing of data delivery techniques for Ajax applications},
  journal         = {Journal of Web Engineering},
  year            = {2009},
  volume          = {8},
  number          = {4},
  pages           = {287-315},
  issn            = {15409589},
  note            = {cited By 9},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Ajax applications are designed to have high user interactivity and low user-perceived latency. Realtime dynamic web data such as news headlines, stock tickers, and auction updates need to be propagated to the users as soon as possible. However, Ajax still suffers from the limitations of the Web's request/response architecture which prevents servers from pushing real-time dynamic web data. Such applications usually use a pull style to obtain the latest updates, where the client actively requests the changes based on a predefined interval. It is possible to overcome this limitation by adopting a push style of interaction where the server broadcasts data when a change occurs on the server side. Both these options have their own trade-offs. This paper first introduces the characteristics of both pull and push approaches. It then presents the design and implementation of our distributed test framework, called Chiron, where different Ajax applications based on each approach can be automatically tested on. Finally, we present and discuss the results of our empirical study comparing different web-based data delivery approaches.© Rinton Press.},
  author_keywords = {Ajax; Comet; Empirical study; Performance testing; Push/pull; Web data delivery},
  document_type   = {Article},
  keywords        = {Ajax; Comet; Empirical study; Performance testing; Push/pull; Web data, Servers},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951512018&partnerID=40&md5=ea6ad6989cc77c5783f2be2ea0103a22},
}

@Conference{Shan2009a,
  author          = {Shan, M. and Wang, X. and Zhao, L. and Guo, L.},
  title           = {Using TTCN-3 in performance test for service application},
  year            = {2009},
  pages           = {253-258},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Service applications are applicable to provide services for requests of users from network. Due to the fact that they have to endure a big number of concurrent requests, the performance of service applications running under specific arrival rate of requests should be assessed. To measure the performance of a service application, Multi-party testing context is needed to simulate a number of concurrent requests and collect the responses. TTCN-3 is a test description language; it provides basic language elements for multi-party testing context that can be used in performance tests. This paper proposes a general approach of using TTCN-3 in multiparty performance testing service application. To this aim, a model of service application is presented, and performance testing framework for service applications is discussed. This testing framework is realized for a typical application by developing a reusable TTCN-3 abstract test suite. © 2009 IEEE.},
  art_number      = {5381754},
  author_keywords = {Peformance test; Service application; TTCN-3},
  document_type   = {Conference Paper},
  doi             = {10.1109/SERA.2009.18},
  isbn            = {9780769539034},
  journal         = {Proceedings - 7th ACIS International Conference on Software Engineering Research, Management and Applications, SERA09},
  keywords        = {Arrival rates; Description languages; General approach; Language elements; Performance testing; Performance testing framework; Performance tests; Service applications; Testing framework; Typical application, Engineering research; Linguistics; Software engineering; Testing, Computer software reusability},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949807359&doi=10.1109%2fSERA.2009.18&partnerID=40&md5=d6664fbea04a5f2a9528b307c38949f7},
}

@Conference{Jain2009,
  author        = {Jain, S. and Rahate, A. and Ranjekar, A.},
  title         = {Capacity prediction based on scaling and growth factor using performance test data},
  year          = {2009},
  note          = {cited By 1},
  __markedentry = {[Jonnathan:]},
  abstract      = {Paper evaluates capacity forecast based on resource utilization in the test environment; extrapolates it to production environment based on load profiles. Statistical analysis of the performance test outcome computes growth factor based on the rise of resource utilization subject to growth in load, while the scaling factor is based on historical data of production resource utilization, with similar load on test. The production capacity is predicted based on the growth and the scaling factors together. Business transactions and volumes inline with market forecast is pumped in test environment.},
  document_type = {Conference Paper},
  journal       = {35th International Conference Computer Measurement Group},
  keywords      = {Business transaction; Capacity forecast; Capacity prediction; Growth factor; Historical data; Load profiles; Market forecast; Performance tests; Production capacity; Production environments; Production resources; Resource utilizations; Scaling factors; Test Environment, Intelligent control, Forecasting},
  language      = {English},
  page_count    = {6},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872151704&partnerID=40&md5=865a76f1727967d0083f87cf8f87cc3c},
}

@Conference{Yun2009a,
  author          = {Yun, S. and Sung, S. and Lee, Y.J.},
  title           = {Design and performance test of relative navigation of a low cost inertial SLAM},
  year            = {2009},
  pages           = {4217-4221},
  note            = {cited By 2},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Despite its precise positioning performance, a GPS based navigation system may require the reference or augmentation station in close boundaries and is liable to be affected by satellite observation environments. Thus, this paper presents an INS/vision sensor integrated system, which in principle uses purely unknown feature points in previous epochs in order to cope with the limited GPS/INS integration environment. For the implementation of three-dimensional navigation using feature points, the presented system takes advantage of a robust image extraction and tracking algorithm, data association, and inertial SLAM filter algorithm. Finally, experimental results verified the performance of integrated navigation system, through which the performance enhancement in estimating relative position of the vehicle is demonstrated effectively. © 2009 SICE.},
  art_number      = {5332781},
  author_keywords = {GPS/INS; Integrated navigation; Positioning; SLAM; Vision sensor},
  document_type   = {Conference Paper},
  isbn            = {9784907764333},
  journal         = {ICCAS-SICE 2009 - ICROS-SICE International Joint Conference 2009, Proceedings},
  keywords        = {Data association; Feature point; Filter algorithm; GPS-based navigation systems; GPS/INS; GPS/INS integration; Image extraction; Integrated navigation; Integrated navigation systems; Integrated systems; Low costs; Performance enhancements; Performance tests; Precise positioning; Relative navigation; Relative positions; Satellite observations; Tracking algorithm; Vision sensors, Feature extraction; Integrated optics; Navigation; Sensors; Three dimensional, Navigation systems},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951140589&partnerID=40&md5=e4d1e4325b3b980c30bb0a06c69a15eb},
}

@Conference{Bondi2009a,
  author        = {Bondi, A.B. and Ros, J.P.},
  title         = {Experience with training a remotely located performance test team in a quasi-agile global environment},
  year          = {2009},
  pages         = {254-261},
  note          = {cited By 10},
  __markedentry = {[Jonnathan:]},
  abstract      = {We describe our experience of training a remotely located team of developers and testers to prepare and execute performance tests. The team is located in India. The lead performance engineer and the test project manager are based in New Jersey. The team members had little or no prior experience of performance testing. We describe how we overcame cultural differences and a large time difference to develop a performance testing team that is now functioning well with far less supervision than was required at its inception. Cultural differences included contrasting views on adherence to strict laboratory procedures and assumptions about the prior knowledge, experience, and expectations of working habits of the India-based and New Jersey-based teams. We show how these differences and organizational challenges were overcome with intensive on-site training, the use of twice-daily scrum meetings, the careful designation of team leaders and role players at the remote testing site, and, eventually, the development intensive use of automated tools to execute performance tests and track the results. © 2009 IEEE.},
  art_number    = {5196940},
  document_type = {Conference Paper},
  doi           = {10.1109/ICGSE.2009.34},
  isbn          = {9780769537108},
  journal       = {Proceedings - 2009 4th IEEE International Conference on Global Software Engineering, ICGSE 2009},
  keywords      = {Automated tools; Cultural difference; Global environment; Laboratory procedures; New Jersey; On-site training; Performance testing; Performance tests; Prior experience; Prior knowledge; Remote testing; Team leaders; Team members; Test projects; Time-differences, Project management, Computer software},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-71049195856&doi=10.1109%2fICGSE.2009.34&partnerID=40&md5=8dee03236a7a73e00a6544c399c4db37},
}

@Conference{Mazzetta2009a,
  author          = {Mazzetta, J.A. and Scopatz, S.D.},
  title           = {Ultraviolet through infrared imager performance testing},
  year            = {2009},
  volume          = {7481},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The objective of any imaging system is to optimize the amount of pertinent information collected from a scene. Whether it is used for artistic reproduction, scientific research, or camouflage detection, a camera has the same ultimate requirement. In the era of broadband, multi-spectral, hyperspectral, and fused sensor systems, both spectral and spatial data continue to play battling roles in determining which is dominant in how well an imaging system meets its definitive objective. Typically sensor testing requires hardware and software exclusively designed for the spectral region of interest. Thus an imaging system with ultraviolet through infrared imaging capabilities could require three or more separate test benches for sensor characterization. Obviously this not only increases the complexity, and subsequently the cost of testing, but also more importantly tends to produce discontinuous results. This paper will outline the hardware and software developed by the authors that employ identical test methods and shared optics to complete infrared, visible, and ultraviolet sensor performance analysis. Challenges encompassing multiple emitting source switching, splitting, and combining will be addressed along with new single fused type source designs. Decisions related to specifying optics and targets of sufficient quality and construction to provide coverage of the full spectral region will be discussed along with sample performance specifications and data. Test methodology controlled by a single automated software suite will be summarized including modulation transfer function, signal to noise ratio, uniformity, focus, distortion, intrascene dynamic range, and sensitivity. Selected examples of results obtained by this test set will be presented. © 2009 SPIE.},
  art_number      = {74810A},
  author_keywords = {Blackbody; Infrared; Integrating sphere; MTF; Multi-spectral; Optics; SNR; Test; Ultraviolet; Visible},
  coden           = {PSISD},
  document_type   = {Conference Paper},
  doi             = {10.1117/12.830536},
  isbn            = {9780819477873},
  issn            = {0277786X},
  journal         = {Proceedings of SPIE - The International Society for Optical Engineering},
  keywords        = {Blackbody; Infrared; Integrating sphere; MTF; Multi-spectral; SNR; Test; Ultraviolet; Visible, Acoustic intensity; Computer software; Imaging systems; Infrared devices; Optical transfer function; Optoelectronic devices; Sensors; Signal to noise ratio; Thermography (imaging), Testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350512627&doi=10.1117%2f12.830536&partnerID=40&md5=aa13647df9fcae905ce6eb99bf60e518},
}

@Conference{Ding2009,
  author          = {Ding, Y. and Yao, X.},
  title           = {Design of ferromagnetic pole based on ANSIS and performance tests under the magnetic finishing},
  year            = {2009},
  pages           = {1517-1520},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Magnetic finishing is a new surface finishing technique. When the ferromagneto pole is used in the magnetic finishing, a new method for finishing the surfaces automatically under the numerical control is conveniently developed. In the paper, design of the magnetic loop for magneto pole has been discussed and slotting parameter on the bottom of the pole which affect the distribution of the magnetic field has been analyzed by FEA (Finite Element Analyses). The performance tests for the slotted pole have been done on the numerical control machine tool ZJK7532A. The surface roughness of the finished work-piece have been improved very obviously comparing with the surface roughness of the finished work piece processed by the un-slotted pole. © 2009 IEEE.},
  art_number      = {5138448},
  author_keywords = {Fea; Ferromagnetic pole; Intensity of the magnetic field; Slotting},
  document_type   = {Conference Paper},
  doi             = {10.1109/ICIEA.2009.5138448},
  isbn            = {9781424428007},
  journal         = {2009 4th IEEE Conference on Industrial Electronics and Applications, ICIEA 2009},
  keywords        = {Fea; Ferromagnetic pole; Finite element analysis; Intensity of the magnetic field; Magnetic finishing; Magnetic loops; Numerical control; Numerical control machine tool; Performance tests; Surface finishing; Work pieces, Ferromagnetic materials; Ferromagnetism; Industrial electronics; Machinery; Magnetic fields; Numerical control systems; Slotting; Surface properties; Surface roughness, Poles},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349314418&doi=10.1109%2fICIEA.2009.5138448&partnerID=40&md5=2d149546089fc6c28d97ff3b7bf0a631},
}

@Conference{Oezkan2009,
  author          = {Özkan, B. and Akmeşe, A.},
  title           = {General characteristics of motion simulators used in the performance tests of infrared camera systems},
  year            = {2009},
  volume          = {7301},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The tests which are conducted to observe the behavior of a system in realistic operational conditions have great importance in order to determine its performance prior to the relevant field studies. These studies provide the designers with deciding on the necessary design updates and they also lead to reduce the total development cost in a significant level. In order to execute the mentioned tests, the motion simulators being able to simulate the motion characteristics of the system in a realistic environment are needed. Looking at the available simulators in the world, it is seen that different system configurations have been used in accomplishing the desired test objectives. In these systems, not only the mechanical designs differ from each other, but also the control systems are employed in various structures. In this study, the properties of widely-used motion simulators designed for infrared camera systems are evaluated with regard of the certain design issues. Also, their advantages and disadvantages are emphasized. © 2009 SPIE.},
  art_number      = {730104},
  author_keywords = {Infrared camera; Motion simulator; Performance test},
  coden           = {PSISD},
  document_type   = {Conference Paper},
  doi             = {10.1117/12.820976},
  isbn            = {9780819475671},
  issn            = {0277786X},
  journal         = {Proceedings of SPIE - The International Society for Optical Engineering},
  keywords        = {Design issues; Development costs; Field studies; Infra-red cameras; Infrared camera; Mechanical design; Motion characteristics; Motion simulator; Performance test; Performance tests; Realistic environments; Realistic operational conditions; System configurations, Cameras; Design; Synthetic apertures; Temperature indicating cameras; Testing, Simulators},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-69949114519&doi=10.1117%2f12.820976&partnerID=40&md5=f1eaee6e953aa28cec5e7cbf5fce43ad},
}

@Article{Liu2009a,
  author          = {Liu, H.-B. and Liu, L. and Zhou, Z. and Wu, W.},
  title           = {Automation test mechanism of cross-examination oriented to HLA},
  journal         = {Xitong Fangzhen Xuebao / Journal of System Simulation},
  year            = {2009},
  volume          = {21},
  number          = {17},
  pages           = {5440-5444+5466},
  issn            = {1004731X},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {HLA standard has hundreds of interfaces, so its compliance testing endures much effort. It's important to develop automated test methods. Aiming at the generation problem of many test cases, a cross-examination automatic test method was proposed. Test cases were filled into a cross-examination form on function manually. Then, according to the relationship of the interfaces, a test-case-tree could be exported and finally the test cases were generated automatically. Consequently, a universal test framework was established and Rational Robot was used as automation test tool. A synchronization component was designed for the RTI automation test on multi-computers. Experiment proves that cross-examination works well and the automatic test can reduce the workload considerably.},
  author_keywords = {Automatic-testing; Cross-examination; HLA; RTI},
  coden           = {XFXUF},
  document_type   = {Article},
  language        = {Chinese},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349401912&partnerID=40&md5=63cce5a51fe913f9ad79b60e4953925f},
}

@Article{Hu2009,
  author          = {Hu, J.-J. and Wu, G.-Q. and Qin, D.-T. and Zhang, Q.},
  title           = {Development and application of a performance test system for heavy duty commercial vehicles},
  journal         = {Chongqing Daxue Xuebao/Journal of Chongqing University},
  year            = {2009},
  volume          = {32},
  number          = {6},
  pages           = {614-619},
  issn            = {1000582X},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {To address limitations of vehicle performance testing systems such as huge size, single functions, low degrees of accuracy, and low stability a performance test system for heavy duty vehicle is developed using the dSPACE development environment based on Matlab/Simulink. Test system layout and development steps are designed. Vehicle performance testing data are acquired, displayed and saved. Based on this testing system, a heavy duty commercial vehicle performance road test is conducted, and operating data regarding experienced drivers and dynamic indices are obtained. The research results provide a theoretical basis for AMT development.},
  author_keywords = {Data acquisition; Dynamic performance; Heavy duty commercial vehicle},
  document_type   = {Article},
  keywords        = {Commercial vehicles; D-space; Development environment; Dynamic performance; Heavy duty; Heavy duty commercial vehicle; Heavy duty vehicles; Low degree; MATLAB /simulink; Operating data; Performance tests; Research results; Road tests; Test systems; Testing systems; Theoretical basis; Vehicle performance, Instruments; Taxicabs; Testing; Trucks, Vehicles},
  language        = {Chinese},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-68049115567&partnerID=40&md5=e12ad33dfaa7a7de25c70af8609ed71c},
}

@Conference{Jiang2008a,
  author        = {Jiang, Z.M. and Hassan, A.E. and Hamann, G. and Flora, P.},
  title         = {Automatic identification of load testing problems},
  year          = {2008},
  pages         = {307-316},
  note          = {cited By 56},
  __markedentry = {[Jonnathan:]},
  abstract      = {Many software applications must provide services to hundreds or thousands of users concurrently. These applications must be load tested to ensure that they can function correctly under high load. Problems in load testing are due to problems in the load environment, the load generators, and the application under test. It is important to identify and address these problems to ensure that load testing results are correct and these problems are resolved. It is difficult to detect problems in a load test due to the large amount of data which must be examined. Current industrial practice mainly involves time-consuming manual checks which, for example, grep the logs of the application for error messages. In this paper, we present an approach which mines the execution logs of an application to uncover the dominant behavior (i.e., execution sequences) for the application and flags anomalies (i.e., deviations) from the dominant behavior. Using a case study of two open source and two large enterprise software applications, we show that our approach can automatically identify problems in a load test. Our approach flags < 0.01% of the log lines for closer analysis by domain experts. The flagged lines indicate load testing problems with a relatively small number of false alarms. Our approach scales well for large applications and is currently used daily in practice. © 2008 IEEE.},
  art_number    = {4658079},
  document_type = {Conference Paper},
  doi           = {10.1109/ICSM.2008.4658079},
  isbn          = {9781424426140},
  journal       = {IEEE International Conference on Software Maintenance, ICSM},
  keywords      = {Alarm systems; Applications; Automation; Computer software maintenance; Electronic data interchange; Errors; Maintenance; Software testing, Application under tests; Automatic identifications; Case studies; Domain experts; Enterprise softwares; Error messages; Execution sequences; False alarms; High loads; Industrial practices; Manual checks; Open sources; Software applications; Testing results, Load testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-57849152538&doi=10.1109%2fICSM.2008.4658079&partnerID=40&md5=3d3e7a78dc863e72f521ab00475467df},
}

@Conference{Eros2008b,
  author        = {Eros, L. and Csondes, T.},
  title         = {Test component assignment in a performance testing environment},
  year          = {2008},
  pages         = {399-403},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {In this paper we are going to introduce the problem of assigning test components to hosts of a performance (or load) testing environment, and its two novel solutions. When testing the performance of a device (System Under Test - SUT), the test environment simulates the latter real-life environment of the SUT. The number of hosts in the test environment is however way less than the number of hosts the SUT will have to serve in its real-life environment. Thus, real-life hosts are simulated by software entities, the so-called test components that have to be optimally assigned and then executed on the hosts of the test environment (testing hosts). Our goal is to emulate all the test components by as few testing hosts as possible, that is, to maximize the load on the testing hosts. The problem to be solved is a special case of the task assignment problem for which many solutions have been developed. Our solutions presented in this paper are, however, optimized for distributing load testing traffic. Thus the possibilities and restrictions we had to take into account are very different from those of the classical task assignment case. One of the solutions we present extends existing bin packing heuristics, while the other one solves a series of integer linear programs to make the assignments. Our simulations have shown that by applying our solutions, the average load level on testing hosts can be significantly increased.},
  art_number    = {4669518},
  document_type = {Conference Paper},
  doi           = {10.1109/SOFTCOM.2008.4669518},
  isbn          = {9789532900071},
  journal       = {SoftCom 2008: 16th International Conference on Software, Telecommuncations and Computer Networks},
  keywords      = {Bin packings; Distributing loads; Integer Linear programs; Load levels; Novel solutions; Software entities; Task assignments; Test components; Test environments; Testing environments, Computer networks; Computer software; Computers; Integer programming; Internet; Software testing; Testing, Load testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-57649165511&doi=10.1109%2fSOFTCOM.2008.4669518&partnerID=40&md5=72edc35f1a34f895409160050087440c},
}

@Conference{Bozoki2008a,
  author        = {Bozóki, F. and Csondes, T.},
  title         = {Scheduling in performance test environment},
  year          = {2008},
  pages         = {404-408},
  note          = {cited By 2},
  __markedentry = {[Jonnathan:]},
  abstract      = {Nowadays automatic testing is getting more and more important in the telecommunication world. The sooner a fault is discovered the cheaper it is to correct it. If a fault is discovered during the development process the cost of the correction is significantly smaller. There are different test strategies, with different approaches like, Conformance Test, System Test and Performance Test. The System Test takes place after a successful Conformance Test. Performance Test is analyzing the load characteristics of the System Under Test (SUT). In this article we describe the main attributes of performance testing, where the main challenge is to generate the expected load without having as complex hardware as the SUT is itself. Most of the papers, presented in this subject are focusing on the characteristics of the generated load, but not the way how to achieve it. These papers usually have the assumption that the load can be generated by deploying more hardware resources. Other papers propose new extensions for test description languages such SDL or TTCN-3 [4]. In this article we intend to describe a Finite State Machine (FSM) based model and an algorithm which improves the efficiency of Scheduling in this Performance Test environment. We present an architecture based on the so called Virtual Threads, an algorithm to optimize the scheduling between these threads, and an example to demonstrate the algorithm.},
  art_number    = {4669519},
  document_type = {Conference Paper},
  doi           = {10.1109/SOFTCOM.2008.4669519},
  isbn          = {9789532900071},
  journal       = {SoftCom 2008: 16th International Conference on Software, Telecommuncations and Computer Networks},
  keywords      = {Automatic testing; Computer networks; Computers; Internet; Load testing; Mathematical models; Paper; Scheduling, Complex hardwares; Description languages; Development processes; Expected loads; Finite State machines; Hardware resources; Load characteristics; Performance tests; Test environments; Test strategies, Testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-57649219408&doi=10.1109%2fSOFTCOM.2008.4669519&partnerID=40&md5=21f2e171fad47f10672034adcbee42e9},
}

@Conference{Legassie2008,
  author          = {Legassie, M. and Bennett, L. and Comeau, S. and Dodd, S.},
  title           = {Advanced load-testing techniques for a science archive},
  year            = {2008},
  volume          = {7016},
  note            = {cited By 2},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Performance goals for data archive systems need to be established early in the design process to ensure stability and acceptable response throughput. Load testing is one technique used to measure the progress towards these performance goals. Providing resources for load-test planning is critical, and this planning must include feasibility studies, tool analyses, and generation of an overall load-test strategy. This strategy is much different for science data archives than other systems, including commercial websites and high-volume data centers. This paper will provide an overview of the load testing performed on the Spitzer Space Telescope's science archive, which is part of Science Operations System at the Spitzer Science Center (SSC). Methods used for planning and conducting SSC load tests will be presented, and advanced load-testing techniques will be provided to address runtime issues and enhance verification results. This work was performed at the California Institute of Technology under contract to the National Aeronautics and Space Administration. © 2008 Copyright SPIE - The International Society for Optical Engineering.},
  art_number      = {70161C},
  author_keywords = {Load testing; Performance testing; Science archive; Spitzer space telescope},
  coden           = {PSISD},
  document_type   = {Conference Paper},
  doi             = {10.1117/12.788045},
  isbn            = {9780819472267},
  issn            = {0277786X},
  journal         = {Proceedings of SPIE - The International Society for Optical Engineering},
  keywords        = {California Institute of Technology; Commercial websites; Data archives; Design process; Feasibility studies; Load test; National aeronautics and space administrations; Runtimes; Science archive; Science centers; Science operations; Science-data; Spitzer; Spitzer Space Telescope; Test planning; Test strategies; Verification results; Volume data, Buildings; NASA; Observatories; Optical telescopes; Space telescopes; Testing; Websites, Load testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-73449129043&doi=10.1117%2f12.788045&partnerID=40&md5=6a1bff09f05507040676ce280d73840c},
}

@Article{Joyce2008,
  author          = {Joyce, T. and Honari, B. and Wilson, S. and Donovan, J. and Gaffney, O.},
  title           = {Models for optimization of production environmental stress testing on electronic circuit packs},
  journal         = {International Journal of Reliability, Quality and Safety Engineering},
  year            = {2008},
  volume          = {15},
  number          = {6},
  pages           = {555-579},
  issn            = {02185393},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The problem of optimizing accelerated production testing is a pressing one in most electronic manufacturing facilities. Yet, practical models are scarce in the literature, especially for testing high volumes of electronic circuit packs in failure-accelerating environments. In this paper, we develop both a log-linear and linear model, based initially on the Weibull distribution. The models developed are suitable for modeling accelerated production testing data from a temperature-cycled environment. The model is "piecewise" in that the failures in each discrete "piece" of the temperature cycle are modeled as if the testing was in parallel rather than sequential mode. An extra covariate is introduced to indicate age at the start of each piece. The failures in a piece then depend on the stress in the piece itself and the time elapsed to the start of the piece. This last dependence captures the influence of reliability growth and has the result of providing an alternative linear model to the log-linear one. The paper demonstrates a simpler use of Poisson regression. An application, using actual production data, is described. Uses of the Loglogistic, Logistic, Lognormal and Normal distributions are also illustrated. © 2008 World Scientific Publishing Company.},
  author_keywords = {Accelerated stress testing; Generalized linear model; Poisson regression; Production environmental stress test; Weibull regression},
  coden           = {IJREF},
  document_type   = {Article},
  doi             = {10.1142/S0218539308003222},
  keywords        = {Accelerated stress testing; Covariate; Electronic circuits; Electronic manufacturing; Generalized linear model; Linear models; Log logistics; Lognormal and normal distributions; Piece wise; Poisson regression; Practical models; Production datum; Production testing; Reliability growths; Sequential modes; Temperature cycles; Weibull regression, Electron tubes; Mathematical models; Maximum likelihood; Normal distribution; Poisson distribution; Poisson equation; Regression analysis, Weibull distribution},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-64249132975&doi=10.1142%2fS0218539308003222&partnerID=40&md5=269c0c9769a7a0fe61b4634dc1ac806b},
}

@Conference{Gawande2008,
  author        = {Gawande, A. and Khemka, S.K. and Gupta, V.},
  title         = {Leveraging open source technologies for effective performance testing},
  year          = {2008},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {Business organizations face a daunting task of maintaining the peak performance of their applications; otherwise they have to incur heavy revenue loss in terms of increased IT investments and abated reputation. To alleviate this problem, performance engineers often turn to various performance testing solutions, which, themselves, introduce their own hefty expenditure in an organization's overall IT investment. This paper proposes a tool integration and enhancement approach that allows organizations to leverage open source technologies for economical and effective performance testing of applications.},
  document_type = {Conference Paper},
  journal       = {34th International Conference Computer Measurement Group},
  keywords      = {Business organizations; Effective performance; IT investments; Open-source technology; Peak performance; Performance testing; Tool integration, Investments, Information technology},
  language      = {English},
  page_count    = {7},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872112543&partnerID=40&md5=ae9ef28444f5d6908e668bc9427d298a},
}

@Conference{Yim2008,
  author        = {Yim, J. and Kim, G. and Nam, I. and Son, S. and Lim, J. and Lee, H. and Kang, S. and Kwak, B. and Lee, J. and Kang, S.},
  title         = {A prevenient voltage stress test method for high density memory},
  year          = {2008},
  pages         = {516-520},
  note          = {cited By 1},
  __markedentry = {[Jonnathan:]},
  abstract      = {The most effective acceleration factor of reliability is the high voltage stress. However high electric field generated on thin gate oxide transistors in nanometer technology becomes the uppermost limit. In this paper, an improved voltage stress method for DRAM with the 6F2 structure and the open bit line scheme is proposed to enhance the Early Life Failure Rates (ELFR) and the yield of package test. The proposed method reduces the degradation of transistors caused by a high voltage stress. Experimental results show that the proposed method improves the yield of package test and the characteristic of refresh, and avoids the degradation of transistors using voltage ramp stress (VRS). © 2008 IEEE.},
  art_number    = {4459605},
  document_type = {Conference Paper},
  doi           = {10.1109/DELTA.2008.93},
  isbn          = {0769531105; 9780769531106},
  journal       = {Proceedings - 4th IEEE International Symposium on Electronic Design, Test and Applications, DELTA 2008},
  keywords      = {Computer networks; DC generators; Degradation; Electric fields; Electronics engineering; Technical presentations, Electronic designs; High voltage stressing; International symposium; Voltage stressing, Testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-50649119049&doi=10.1109%2fDELTA.2008.93&partnerID=40&md5=504ed4203eb2a01fa8143a0ba585288f},
}

@Conference{Chen2008a,
  author        = {Chen, S. and Moreland, D. and Nepal, S. and Zic, J.},
  title         = {Yet another performance testing framework},
  year          = {2008},
  pages         = {170-179},
  note          = {cited By 8},
  __markedentry = {[Jonnathan:]},
  abstract      = {Performance testing is one of the vital activities spanning the whole life cycle of software engineering. While there are a consideruble number of performance testing products and open source tools available, they are either too expensive and complicated for small projects, or too specific and simple for diverse performance tests. This paper presents a general-purpose testing framework for both simple and small, and complicated and large-scale performance testing. Our framework proposes an abstraction to facilitate performance testing by separating the application logic from the common performance testing functionalities. This leads to a set of general-purpose data models and components, which form the core of the framework. The framework has been prototyped on both.NET and Java platforms and was used for a number of performance-related projects. © 2008 IEEE.},
  art_number    = {4483205},
  document_type = {Conference Paper},
  doi           = {10.1109/ASWEC.2008.4483205},
  isbn          = {0769531008; 9780769531007},
  journal       = {Proceedings of the Australian Software Engineering Conference, ASWEC},
  keywords      = {Computer programming; Computer software; Life cycle; Software engineering; Technology, Application logic; Australian Software Engineering Conference; Data modelling; Java platforms; Open-source tools; Performance testing; Performance testing framework; Testing framework, Software testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-50249114000&doi=10.1109%2fASWEC.2008.4483205&partnerID=40&md5=733487df1ca62e9667818b224ca14671},
}

@Article{Nagatani2008,
  author          = {Nagatani, K. and Yoshida, K. and Kiyokawa, K. and Yagi, Y. and Adachi, T. and Saitoh, H. and Suzuki, T. and Takizawa, O.},
  title           = {Development of a networked robotic system for disaster mitigation -system description of multi-robot system and performance tests of the robots},
  journal         = {Springer Tracts in Advanced Robotics},
  year            = {2008},
  volume          = {42},
  pages           = {453-462},
  issn            = {16107438},
  note            = {cited By 4},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In this paper, the research project named "networked robotic system for disaster mitigation" is introduced. The project aims to develop key technologies for multiple robots to be teleoperated through a wireless communication network, which includes a satellite communication link, for surveillance tasks at a disaster site. The robotic system consists of a large-scale outdoor robot and a group of smaller indoor robots. The large-scale robot will serve as a carrier for the smaller robots which are deployed inside a partly-collapsed building. A three-dimensional range sensor and an omnidirectional camera are used as tools to ease the teleoperation for the human operator. This paper presents the mission scenario and the development status of the proposed networked multi-robotic system. The results of the performance tests are also reported. © 2008 Springer-Verlag Berlin Heidelberg.},
  author_keywords = {Ad-hoc network; Augmented reality; Disaster mitigation; Laser range sensor; Omnidirectional camera; Surveillance robots; Teleoperation},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-540-75404-6_43},
  editor          = {Laugier C.L., Siegwart R.S.},
  isbn            = {9783540754039},
  keywords        = {Ad-hoc network; Augmented reality; Disaster mitigation; Laser range sensor; Omnidirectional camera; Surveillance robots; Teleoperation, Accidents; Industrial robots; Multipurpose robots; Network protocols; Project management; Robot learning; Robotics; Satellite communication systems; Sensor networks; Three dimensional; Wireless networks, Robots},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-49249115333&doi=10.1007%2f978-3-540-75404-6_43&partnerID=40&md5=2ed4f20063225a8055db8a6827eb9af8},
}

@Article{Harris2008,
  author          = {Harris, R. and Impelluso, T.},
  title           = {Virtual stress testing machine and the cyber-infrastructure},
  journal         = {Engineering with Computers},
  year            = {2008},
  volume          = {24},
  number          = {2},
  pages           = {107-117},
  issn            = {01770667},
  note            = {cited By 2},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The virtual stress testing machine (VSTM) project demonstrates the use of the cyber-infrastructure to integrate the algorithms of computational mechanics and supplement virtual environments with physics. The VSTM is not a tool, nor is it intended to be; rather it is a pedagogical presentation of new research paradigms that should be comprehensible to mechanical engineers. VSTM encompasses a real stress testing machine, a virtual stress-testing machine, and a server that initiates and regulates all component physics and visualization processes the server also controls the real Instron. A series of benchmark tests were conducted for analysis of reliability and to demonstrate how such tests can and should be conducted so as to foster communication between mechanical engineers and their colleagues across disciplines. These tests have demonstrated the concept of creating a physics-based virtual environment by revealing both the accuracy and real-time functionality of the simulation. The tests also exposed some system vulnerabilities in network communication and remote memory access processes. VSTM provides a description for mechanical engineers, of the necessary core network technologies needed to solve mechanics problems in new ways and join the community of computer scientists already at work in this arena. © Springer-Verlag London Limited 2007.},
  author_keywords = {Client/Server; Cyber infrastructure; Physics-based virtual reality},
  coden           = {ENGCE},
  document_type   = {Article},
  doi             = {10.1007/s00366-007-0077-7},
  keywords        = {Client server computer systems; Computational mechanics; Computer simulation; Visualization, Cyber infrastructure; Virtual stress testing machine, Virtual reality},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-42649135875&doi=10.1007%2fs00366-007-0077-7&partnerID=40&md5=ae0275717e3d2b9a88d6ece6f4b083f9},
}

@Article{Yang2008a,
  author          = {Yang, X. and Li, X. and Ji, Y. and Sha, M.},
  title           = {CROWNBench: A grid performance testing system using customizable synthetic workload},
  journal         = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year            = {2008},
  volume          = {4976 LNCS},
  pages           = {190-201},
  issn            = {03029743},
  note            = {cited By 1},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The Grid middleware must be developed iteratively and incrementally, so Grid performance testing is critical for middleware developers of Grid system. Considering the special characters of Grid system, in order to gain meaningful and comprehensive results of performance testing, it is necessary to implement testing on real Grid environment with various types of workload. CROWNBench, as described in this paper, is a system for helping Grid middleware developers to evaluate middleware design and implement using customizable synthetic workload. Middleware developers can customize testing workload basing on the model of Grid workload derived from real workload traces, including its structure and parameters, and then workload is synthesized automatically and contained jobs will be submitted by CROWNBench in a distributed manner. CROWNBench defines several metrics for measuring Grid performance as automatic testing results. The experiment, which used CROWNBench to test the performance of Grid system with CROWN Grid middleware, shows that the system already finished have accomplished its prospective goal. It can implement Grid performance testing in an efficient, flexible, controllable, replayable and automatic way to help middleware developers evaluate and improve their products effectively. © 2008 Springer-Verlag Berlin Heidelberg.},
  author_keywords = {Grid computing; Performance testing; Synthetic workload},
  document_type   = {Conference Paper},
  doi             = {10.1007/978-3-540-78849-2_21},
  isbn            = {3540788484; 9783540788485},
  keywords        = {Grid computing; Middleware; Parameter estimation; Problem solving; Software design, CROWNBench; Grid performance; Performance testing; Synthetic workloads, Software testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-43749114956&doi=10.1007%2f978-3-540-78849-2_21&partnerID=40&md5=4236b12b2815a894eebe71715b07c0e9},
}

@Article{Haines2008,
  author        = {Haines, S.},
  title         = {Continuous integration and performance testing},
  journal       = {Dr. Dobb's Journal},
  year          = {2008},
  volume        = {33},
  number        = {3},
  pages         = {36-38},
  issn          = {1044789X},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {Continuous integration systems is used to perform integration, performance, and load testing. Continuous integration is a software engineering process where an application under development is completely rebuilt and tested frequently and automatically. A continuous integration process is dependent on several factors including a single code repository, automated build process with self-testing, and continuous integration server. Continuous performance management implements performance and scalability testing within a continuous integration environment, which can perform integration and load testing. Extending continuous integration to different types of performance testing makes the investment in continuous integration even more worthwhile.},
  coden         = {DDJTE},
  document_type = {Article},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-40449106016&partnerID=40&md5=3cf42d3306f9d3b41cd1e253c140e5f9},
}

@Conference{Gottifredi2008a,
  author        = {Gottifredi, F. and Martinino, F. and Morante, Q. and Eleuteri, M. and Varriale, E. and Valle, V. and Pesci, G.},
  title         = {Galileo test range: Performance test results},
  year          = {2008},
  publisher     = {CNES},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {The Galileo Test Range (GTR) project is an initiative of Regione Lazio in the frame of its support to the Italian technical research and innovation in satellite navigation. It is born as the Italian National permanent Laboratory for the experimentation and analysis of the Galileo Signal, for testing and certification of user terminals and support services for the development of application services. The development of the GTR is foreseen in two phases: - Phase A = Definition and Start up: implementation of the initial system, based on the generation on ground of navigation signals (GPS-like), using pseudolite technology (4 PSL), and to receive real signals coming from GPS, EGNOS and the new GIOVE-A Experimental Satellite. - Phase B = Full deployment and initialization of the GTR: implementation of the GTR final configuration, not only able to generate Galileo-like signals (from 9 PSL), but also to receive and process real signals coming from Galileo IOV satellites. The Phase A architecture is composed by the following macro segments: - The Analysis & Control Centre composed by the Control Centre (CC) and all the specialized laboratories (i.e. Time, Orbitography, Synchronization, Integrity, R&D); - The Experimental Area (covered by Differential Reference Stations) including the Test Area (covered by the Pseudolites - PSL) The 4 PSL deployed for the Phase A (2 fixed and 2 transportable) are equipped with the following main elements: • an atomic reference clock composed by an OCXO locked to Rb oscillator in order to obtain good short and long term stability; • a dual frequency GPS/SBAS Receiver Assembly; • a GPS-like signal generator • a directional antenna to disseminate the GPS-Like signal in the Test Area The PSL Receiver observables are sent to the GTR-CC and then to the Orbitography Laboratory Facility in charge of the Time Synchronization function of the GTR based on the SynchroNet product of TAS-I. The reference for this Synchronization is given by the Time Laboratory Facility, equipped with an Active Hydrogen Maser and 4 Caesium Clocks. The clock corrections are sent back to the PSL, uploaded in the Navigation Message and broadcasted to the Users in the Test Area. Users equipped with a GPS Receiver can connect it to a PC with a dedicated software (developed by TAS-I) that makes a data fusion between GPS satellites observables and PSL ones so as to compute a better 3D position. If required, the SW can compute a 2D solution using only the Pseudolite observables, Users can compute a 2D position. The PSLs guarantee in a flexible way, thanks to the transportable PSLs, an increased availability of GNSS-like signals in the Test Area that users can use to improve theirs navigation performances. The tests carried out show that the achievable performance in the Test Area with the 4 PSL of Phase A are in the order of 5 m in 3D and 3 m in 2D. With the upgrade foreseen in Phase B in number and type of signal, the performance achievable will improve and potential applications can be satisfied with the use of the PSL technology. The aims of this paper are to present the advantages of the availability of signals generated by PSLs (fixed and transportable) in a controlled area and to present the reached performances for the phase A of the GTR using PSLs. Furthermore it will be presented an overview on the potential applications for this technology that can be a good solution for all those environments that require augmentations in performance and availability (i.e. urban canyons, harbors, container movement, etc⋯).},
  document_type = {Conference Paper},
  journal       = {ENC-GNSS 2008 - European Navigation Conference},
  keywords      = {Clocks; Data fusion; Directive antennas; Geostationary satellites; Hydrogen masers; Laboratories; Navigation; Orbits; Satellites; Signal receivers; Synchronization; Testing, Achievable performance; Application services; Laboratory facilities; Long term stability; Navigation messages; Navigation performance; Satellite navigation; Time synchronization, Global positioning system},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924143871&partnerID=40&md5=ffa4c335e1a82c97772f7072e27389cc},
}

@Conference{Haala2008,
  author          = {Haala, N. and Peter, M. and Kremer, J. and Hunter, G.},
  title           = {Mobile lidar mapping for 3D point cloud collection in Urban Areas - A performance test},
  year            = {2008},
  editor          = {Chen J., Maas H--G., Jiang J.},
  volume          = {37},
  pages           = {1119-1124},
  publisher       = {International Society for Photogrammetry and Remote Sensing},
  note            = {cited By 76},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The use of static terrestrial laser scanning for the 3D data capturing of smaller scenes as well as airborne laser scanning from helicopters and fixed wing aircraft for data collection of large areas are well established tools. However, in spite of their general acceptance and wide use both methods have their limitations for projects that include the rapid and cost effective capturing of 3D data from larger street sections. This is especially true if these sections include tunnels or if dense point coverage of the facades of the neighbouring architecture is required. To extend the applicability of laser scanning to these kinds of projects, terrestrial cinematic laser scanning based on mobile mapping systems can be used. Within the paper the components, the workflow and the performance of the vehicle based "StreetMapper" system are described, which simultaneously uses four 2D-laser scanners for 3D data collection, while georeferencing is realised by a high performance GNSS/inertial navigation system. Within our investigations the accuracy of the measured 3D point clouds is determined using reference values from an existing 3D city model. As it will be demonstrated, the achievable accuracy levels of better than 30mm in good GPS conditions make the system practical for many applications in urban mapping.},
  author_keywords = {Façade Interpretation; LIDAR; Point Cloud; Three-dimensional; Urban},
  document_type   = {Conference Paper},
  issn            = {16821750},
  journal         = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
  keywords        = {Cost effectiveness; Fixed wings; Laser applications; Mapping; Navigation systems; Optical radar; Remote sensing; Scanning; Surface analysis; Three dimensional computer graphics, 2D laser scanners; Airborne Laser scanning; Mobile mapping systems; Performance tests; Point cloud; Reference values; Terrestrial laser scanning; Urban, Data acquisition},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929159308&partnerID=40&md5=694449edb285771d0fdf206bb4591bb1},
}

@Conference{Feng2007a,
  author        = {Feng, L. and Zhuang, S.},
  title         = {Action-driven automation test framework for Graphical User Interface (GUI) software testing},
  year          = {2007},
  pages         = {22-27},
  note          = {cited By 5},
  __markedentry = {[Jonnathan:]},
  abstract      = {In this paper we describe the design and implementation of an action-driven automation test framework especially for GUI software testing. The idea of action-driven automation test framework comes from the core concept of "Quality Assurance (QA)". Better quality can be ensured by increasing the coverage of test cases on the software but the process of creating large number of test cases has to be optimized. With this goal the framework was designed to primarily increase the efficiency and flexibility in composing test cases and simplify the process of learning the test cases. This paper describes the background, features, and implementation details of the framework.},
  art_number    = {4374197},
  document_type = {Conference Paper},
  doi           = {10.1109/AUTEST.2007.4374197},
  isbn          = {1424412390; 9781424412396},
  journal       = {AUTOTESTCON (Proceedings)},
  keywords      = {GUI software; Integrated diagnostics; Quality assurance (QA); Test cases; Test framework; User interfaces, Automation; Computer software maintenance; Computer software selection and evaluation; Computer systems; Graphical user interfaces; Industrial engineering; Quality assurance; Software design; Software testing; Total quality management, Testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-48049101576&doi=10.1109%2fAUTEST.2007.4374197&partnerID=40&md5=edea08e4d06b6e59df9bc1d5a8b27ddf},
}

@Conference{Bondi2007,
  author        = {Bondi, A.B.},
  title         = {Automating the analysis of load test results to assess the scalability and stability of a component-based or SOA-based system},
  year          = {2007},
  note          = {cited By 4},
  __markedentry = {[Jonnathan:]},
  abstract      = {Thorough load testing of systems involves test runs of use cases and usage scenarios at multiple load levels. When there are dozens or even hundreds of use cases to subject to load tests, timely manual data analysis is simply not possible. We present a computationally inexpensive method of automatically eliminating the warm-up and cool-down transients from measurements of stable systems. In addition, the method enables the automated detection of possible system instability. It facilitates the rapid analysis of performance tests of systems with large numbers of use cases at multiple load levels. It can be used to analyse performance data obtained using commonly available system measurement tools.},
  document_type = {Conference Paper},
  journal       = {33rd International Conference Computer Measurement Group},
  keywords      = {Automated detection; Component based; Load test; Multiple loads; Performance data; Performance tests; Rapid analysis; SOA-based systems; Stable systems; System measurement; Test runs; Usage scenarios, System stability, Measurements},
  language      = {English},
  page_count    = {13},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872121596&partnerID=40&md5=b7a2ce5e196abea491e14acd01531501},
}

@Conference{Yakovyna2007b,
  author          = {Yakovyna, V. and Fedasyuk, D. and Seniv, M.},
  title           = {Software realization and performance testing of des cryptographic algorithm on the .NET platform},
  year            = {2007},
  pages           = {386-388},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The software realization of DES symmetric encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested and it was shown, that the encryption rate is 11.1 Mb/sec on the Intel Celeron D 351 3.2GHz processor, while the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.},
  art_number      = {4297591},
  author_keywords = {.NET; CryptoAPI; DES algorithm; Software realization; Symmetric cryptography},
  document_type   = {Conference Paper},
  doi             = {10.1109/CADSM.2007.4297591},
  isbn            = {9789665535874},
  journal         = {The Experience of Designing and Application of CAD Systems in Microelectronics - Proceedings of the 9th International Conference, CADSM 2007},
  keywords        = {Boolean functions; Electronics industry; Microelectronics; Software testing, Computer aided design (CAD) systems; Cryptographic software; Development environments; Encryption rate; Flexible architectures; International conferences; Performance testing; Processing performance; Software implementations; Software realization; Symmetric encryption, Cryptography},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-48349132084&doi=10.1109%2fCADSM.2007.4297591&partnerID=40&md5=f7069d04818e2c41ca164e1f55fa1418},
}

@Conference{Yakovyna2007c,
  author          = {Yakovyna, V. and Fedasyuk, D. and Seniv, M. and Bilas, O.},
  title           = {The Performance testing of RSA algorithm software realization},
  year            = {2007},
  pages           = {390-392},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The software realization of RSA public key encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested. The present paper shows, that the encryption rate is 306.4±0.6 kbytes/sec, while the coefficient of encryption time increasing with file size increasing is 3.299. It is concluded that the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.},
  art_number      = {4297593},
  author_keywords = {.NET; Operation performance; Public-key cryptography; RSA algorithm; Software realization},
  document_type   = {Conference Paper},
  doi             = {10.1109/CADSM.2007.4297593},
  isbn            = {9789665535874},
  journal         = {The Experience of Designing and Application of CAD Systems in Microelectronics - Proceedings of the 9th International Conference, CADSM 2007},
  keywords        = {Boolean functions; Electronics industry; Microelectronics; Software testing, Computer aided design (CAD) systems; Cryptographic software; Development environments; Encryption rate; File sizes; Flexible architectures; International conferences; Performance testing; Processing performance; Public-key encryptions; RSA algorithms; Software implementations; Software realization, Cryptography},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-48349119321&doi=10.1109%2fCADSM.2007.4297593&partnerID=40&md5=c9ff3b1e7ad9281fd43433e43027d53a},
}

@Article{Golding2007,
  author          = {Golding, P. and Tennant, V.},
  title           = {Performance testing: Evaluating an RFID library inventory reader},
  journal         = {International Journal of Internet Protocol Technology},
  year            = {2007},
  volume          = {2},
  number          = {3-4},
  pages           = {240-251},
  issn            = {17438209},
  note            = {cited By 2},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Numerous studies have been performed in supply chain environments to determine the performance requirement to achieve a near 100% read rate. However the literature on testing in the library environment is sparse. This study examines the operational efficiencies of a RFID library reader. The factors examined included angle directionality sensitivity, read distance and tag location. The findings suggested that the performance of the inventory system degrades significantly as the angle directionality moves from 0 to 60 degrees. The read distance varied from vendor specification. The findings provide empirical insight into the performance of an RFID reader in an operating environment. © 2007, Inderscience Publishers.},
  author_keywords = {Inventory reader; Library system; Performance; RFID},
  document_type   = {Article},
  doi             = {10.1504/IJIPT.2007.016224},
  keywords        = {Data warehouses; Inventory control; Radio frequency identification (RFID); Sensitivity analysis, Library inventory reader; Library system, Libraries},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-42149137894&doi=10.1504%2fIJIPT.2007.016224&partnerID=40&md5=d90ce40ce2422575c8871c5baf0428b2},
}

@Conference{Yao2007a,
  author        = {Yao, N. and Gao, F. and Cai, S. and Yao, W.},
  title         = {A new method of performance test for network storage},
  year          = {2007},
  pages         = {416-420},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {Network storages are used widely in many fields of our society. But their testing performances are not as expected. Most of the tools being used to test the performance of network storage comes from the tools used to test the traditional storage system because the storage devices connected to the net act as the local storage devices. So these tools inevitably miss the effects exerted by the networks which connect the hosts to the storage devices. For example, these tools can hardly generate requests which exceed the maximum loading of storage devices. In this paper, we propose one new method to test the performance of network storage which can easily generate requests that exceed the maximum loading of storage devices. In this method, the test program sends the requests by fixed frequency and the initiator will not be restrained by the targeter when the quantity of requests is close to the maximum load. The load simulated by the new method is more like the load in the real world, especially when the load is very high. © 2007 IEEE.},
  art_number    = {4392635},
  document_type = {Conference Paper},
  doi           = {10.1109/IMSCCS.2007.4392635},
  isbn          = {0769530397; 9780769530390},
  journal       = {Proceedings - 2nd International Multi-Symposiums on Computer and Computational Sciences, IMSCCS'07},
  keywords      = {Computational methods; Current voltage characteristics; Data storage equipment; Loading; Loads (forces); Testing; Tools, Computational sciences; Fixed frequencies; International (CO); Maximum loading; maximum loads; network storage; New methods; Performance testing; Real world; Storage devices; Storage systems; test programs, Storage (materials)},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-46449088778&doi=10.1109%2fIMSCCS.2007.4392635&partnerID=40&md5=b94eda26997f4dab8249d43270f5dfb9},
}

@Conference{Pan2007a,
  author          = {Pan, L. and Batten, L.M.},
  title           = {A lower bound on effective performance testing for digital forensic tools},
  year            = {2007},
  pages           = {117-130},
  note            = {cited By 4},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The increasing complexity and number of digital forensic tasks required in criminal investigations demand the development of an effective and efficient testing methodology, enabling tools of similar functionalities to be compared based on their performance. Assuming that the tool tester is familiar with the underlying testing platform and has the ability to use the tools correctly, we provide a numerical solution for the lower bound on the number of testing cases needed to determine comparative capabilities of any set of digital forensic tools. We also present a case study on the performance testing of password cracking tools, which allows us to confirm that the lower bound on the number of testing runs needed is closely related to the row size of certain orthogonal arrays. We show how to reduce the number of test runs by using knowledge of the underlying system. © 2007 IEEE.},
  art_number      = {4155356},
  author_keywords = {Abstraction layer model; Orthogonal arrays; Partition testing; SADFE; Software performance},
  document_type   = {Conference Paper},
  doi             = {10.1109/SADFE.2007.2},
  isbn            = {0769528082; 9780769528083},
  journal         = {Proceedings - SADFE 2007: Second International Workshop on Systematic Approaches to Digital Forensic Engineering},
  keywords        = {Computational complexity; Computer aided software engineering; Data reduction; Parallel processing systems, Abstraction layer model; Orthogonal arrays; Partition testing; SADFE; Software performance, Software testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548126958&doi=10.1109%2fSADFE.2007.2&partnerID=40&md5=7db53694ff93824d132237bdb44345ed},
}

@Article{Kimambo2007,
  author          = {Kimambo, C.Z.M.},
  title           = {Development and performance testing of solar cookers},
  journal         = {Journal of Energy in Southern Africa},
  year            = {2007},
  volume          = {18},
  number          = {3},
  pages           = {41-51},
  issn            = {1021447X},
  note            = {cited By 20},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The most common type of energy used is firewood. In some Sub Saharan countries, up to 90% of total energy use is from firewood. The consumption of wood fuel is in some countries as high as twice the sustainable yield, something that has led to environmental degradation due to deforestation and scarcity of firewood. The use of fossil fuels such as kerosene and LPG for cooking is expensive. Solar energy is a non-consumptive and non-polluting fuel. It can help alleviate the problem of insecurity of cooking energy, which is the major domestic energy requirement. Several attempts have been made to introduce solar cookers in different countries and have achieved variable successes. There are still critical issues yet to be resolved in order to make that technology acceptable for wider dissemination. They include getting the most appropriate types of solar cookers for specific locations, optimum size/capacity, types of materials to be used, optimal design and affordable cost. In an attempt to resolve these issues, a comprehensive study involving theoretical review, development work, experimental testing and evaluation of solar cookers was conducted for several years on six different types of solar cookers. The cookers are the 'SunStove' box cooker, wooden box cooker, panel cooker, reflector cooker with unpolished aluminium reflectors, reflector cooker with polished aluminium reflectors and reflector cooker with glass mirror reflectors. This paper presents the results of the study. Results obtained indicate that many of the cookers could be used to cook food for households in areas with medium and high insolation, with appropriate selection of the type and specification of the cookers. The specification should be based on the measured insolation data of the location indication of the direct and diffuse components. As a guiding tool, reflector cookers offer best comparative performance in areas with longest durations of clear sky (greatest direct beam), panel and collector cookers under moderate cloudy conditions and box cookers under very cloudy conditions.},
  author_keywords = {Cooker; Evaluation; Performance; Solar; Tanzania; Test},
  coden           = {JESAE},
  document_type   = {Article},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-36048972388&partnerID=40&md5=051d3602e62b826afe109db535dc40d5},
}

@Conference{Ma2007,
  author          = {Ma, C.-J. and Wu, X.-C. and Xie-zhong},
  title           = {Performance tests and application strategies of spatial indexes in the embedded-GIS data management},
  year            = {2007},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Spatial indexes arranged by some sequence, are related to the positions, shapes of geographic entities and relations among them, which describe the outline info of Object Identifier (OID), Minimum Bounding Rectangle (MBR) and pointers to storage location. Usually, the index situated between the spatial operating algorithms and the entities, enhances the efficiency of spatial operations by filtering and erasing irrelevant ones. Especially, for resource-constrained mobile terminals with Embedded-GIS, it's necessary to establish proper index strategies to solve the problem of limited memories conflicting with enormous data and the requirement of real-time processing. The paper not only stated the design and realization of the Seq-list, KD-tree, Quad-tree and R-tree indexes carried on Embedded-GIS, but also applied these to Compaq iPAQ H3800 conducting massive careful tests. Based on analyzing and contrasting test results of memories occupied, time spent and power consumed, the paper appraised the validity of above indexes and proposed corresponding strategies for different Embedded-GIS application environments. © 2006 IEEE.},
  art_number      = {4149578},
  author_keywords = {Embedded-GIS; KD-tree; Quad-tree; R-tree; Seq-list; Spatial index; Strategies},
  document_type   = {Conference Paper},
  doi             = {10.1109/WiCOM.2006.401},
  isbn            = {1424405173; 9781424405176},
  journal         = {2006 International Conference on Wireless Communications, Networking and Mobile Computing, WiCOM 2006},
  keywords        = {KD-tree; Quad-tree; R-tree; Seq-lists; Spatial index, Algorithms; Embedded systems; Geographic information systems; Information retrieval; Real time systems; Storage allocation (computer), Information management},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-37649027314&doi=10.1109%2fWiCOM.2006.401&partnerID=40&md5=689c5308a0ef10119161884a7eaa48fd},
}

@Conference{Deshmukh2006,
  author        = {Deshmukh, R. and Whiteman, L.},
  title         = {Salt Atmosphere, Temperature Humidity, Mechanical Shock Environmental Stress testing results, and FMA of the JG-PP / JCAA Lead Free Soldering Program},
  year          = {2006},
  volume        = {2},
  pages         = {657-666},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {The American Competitiveness Institute (ACI) performed a series of Environmental Stress Tests for the Joint Group of Pollution Prevention / Joint Council of Aging Aircraft (JG-PP / JCAA) Lead Free Soldering Program. The objective was to determine if Lead Free soldered hardware was equivalent to or better than its Tin Lead (SnPb) counterpart. The program's test vehicle was manufactured by BAE Systems in Irvine, Texas. The JG-PP / JCAA test vehicle was soldered with Tin Lead (SnPb) as a baseline, Tin Silver Copper (95.5Sn3.9Ag0.6Cu or SAC), Tin Silver Copper Bismuth ((92.3Sn3.4Ag1.0Cu3.3Bi or SACB), and stabilized Tin Copper (99.3Sn0.7Cu0.05Ni). The Salt Atmosphere test was performed in accordance to ASTM B117 Test Method for 48 hours. The Temperature Humidity test followed the procedure MIL-STD 810F; Test Method 507.4. In both tests, no failures were found that could be attributed to the solder joints. Therefore, the Tin Lead and Lead Free soldered hardware can be considered equivalent. Two types of Mechanical Shock tests were performed. The first Mechanical Shock test was performed using the test procedure MIL-STD 810F; Method 516.5; Procedure 1. The test was performed on all 3 axes. 2 components soldered with SACB failed the tests. The balance of the SnPb and Lead Free soldered components passed this mechanical shock test with no failures. The second Mechanical Shock test was performed to a modified version of MIL-STD 810F; Method 516.5; Procedure 1, where the test vehicle was tested in the Z-Direction, at increasing levels to failure. The mechanical shock levels reached in this test were above those in the first mechanical shock test. Across all test levels and component types, the SnPb soldered hardware performed comparable or better than the SAC and the SACB soldered hardware.},
  document_type = {Conference Paper},
  isbn          = {9781604236026},
  journal       = {IPC - Printed Circuits Expo, Apex, and the Designers Summit 2006: Perfectly Cutting Edge},
  keywords      = {Aging aircraft; BAE systems; Environmental stress; Lead-Free; Lead-free soldering; Mechanical shock; Pollution prevention; Solder joints; Temperature humidity; Test method; Test procedures; Test vehicle; Tin-copper; Tin-lead; Tin-silver-copper; Z-directions, Automobile manufacture; Bismuth; Competition; Cutting tools; Exhibitions; Failure (mechanical); Hardware; Printed circuits; Shock testing; Soldering; Tin, Software testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867020849&partnerID=40&md5=d19f1929218def290c798409c2de5752},
}

@Conference{Stankovic2006a,
  author          = {Stankovic, N.},
  title           = {Patterns and tools for performance testing},
  year            = {2006},
  pages           = {152-157},
  note            = {cited By 3},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The growth of software applications in size and complexity is being followed by a number of specific nonfunctional requirements such as portability, interoperability, and availability on various platforms. Most often, these have been addressed by middleware or programming environment. In addition, easy customizability, adaptability, and sharing of components facilitates the development cycle. These should be understood and applied in a broader sense, i.e. to byproducts created during the development process such as programs for functional and performance testing. Much time is spent on developing test programs but their quality and quality of thus obtained results varies largely if the process is not standardized and automated. In this paper we present our experience with performance testing of a large scale suite of gateways that are used for the seamless integration of heterogeneous communication networks. We analyze the commercial and public domain tools for load generation and motivate our decision to define an in-house framework and build a distributed tool for performance, testing that is also not restricted by licensing issues and is readily available to everyone involved. Our tool is built on Visper, the object-oriented distributed programming middleware. The suitability and adaptability of the Visper model for rapid application development and the quality of produced result have proven our decision correct.},
  art_number      = {4017687},
  author_keywords = {Software engineering; Software testing; Software tools},
  document_type   = {Conference Paper},
  doi             = {10.1109/EIT.2006.252109},
  isbn            = {078039593X; 9780780395930},
  journal         = {2006 IEEE International Conference on Electro Information Technology},
  keywords        = {Distributed tools; Heterogeneous communication networks; Object oriented distributed programming, Computer aided software engineering; Data transfer rates; Gateways (computer networks); Interoperability; Middleware; Object oriented programming; Process control, Software testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250880087&doi=10.1109%2fEIT.2006.252109&partnerID=40&md5=14bd41b4b59c59fbc251bbabdfb786cc},
}

@Conference{Saba2006a,
  author          = {Saba, H. and De Freitas Jorge, E.M. and Costa, V.F. and De Barros Pereira, H.B.},
  title           = {Webteste: A stress test tool},
  year            = {2006},
  volume          = {IT},
  number          = {WIA/-},
  pages           = {246-249},
  note            = {cited By 2},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The usage of web applications has became a very common activity in the organizations' scope. From the software engineering perspective, the incessant search for production of more robust softwares, with better quality, is a continuous requirement. The main purpose of this paper is to present the WebTeste, which is a test tool used to verify the robustness of a web application. After comparison of several simulation's results, the use of distributed and ordered computers suggests more reliable tests. In addition, the analysis of the obtained results can suggest a new (re)design of a web system. The WebTeste could be used to perform stress test in order to verify the robustness of a web application more precisely. © 2010.},
  author_keywords = {Stress test; Web server; WebTeste},
  document_type   = {Conference Paper},
  isbn            = {9789728865467},
  journal         = {WEBIST 2006 - 2nd International Conference on Web Information Systems and Technologies, Proceedings},
  keywords        = {Robust software; Stress test; Stress test tools; Test tools; WEB application; Web servers; Web system, Computer simulation; Information systems; Software engineering; Web services, Testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954095969&partnerID=40&md5=c9200aeb4220bff91ca3670fe74d6cb3},
}

@Book{Subraya2006,
  title         = {Integrated approach to web performance testing: A practitioner's guide},
  publisher     = {IGI Global},
  year          = {2006},
  author        = {Subraya, B.M.},
  isbn          = {9781591407850},
  note          = {cited By 5},
  __markedentry = {[Jonnathan:]},
  abstract      = {The performance testing of Web applications is not understood properly and no skill sets are available to address the challenges faced by practitioners. In addition, there is currently a lack of available research on the performance aspects of the application. Integrated Approach to Web Performance Testing: A Practitioner's Guide fills this void and provides an integrated approach and guidelines to performance testing of Web-based systems. Based upon a mix of theoretical and practical concepts, this book provides a detailed understanding of the various aspects of performance testing in relation to the different phases of the software development life cycle. Using a rich mixture of examples, checklists, and templates, this book illustrates the different facets of application performance. Integrated Approach to Web Performance Testing: A Practitioner's Guide applies a practical approach to making appropriate choices of tools, methodologies and project management for performance testing. © 2006 by Idea Group Inc. All rights reserved.},
  document_type = {Book},
  doi           = {10.4018/978-1-59140-785-0},
  journal       = {Integrated Approach to Web Performance Testing: A Practitioner's Guide},
  language      = {English},
  pages         = {1-368},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898105454&doi=10.4018%2f978-1-59140-785-0&partnerID=40&md5=b7b0211d71d59586df77c9ce6f6e52d2},
}

@Article{Kim2006,
  author          = {Kim, W. and Soh, W. and Sigfred, J.},
  title           = {Development of a packet simulator for performance test of information security system},
  journal         = {International Journal of Multimedia and Ubiquitous Engineering},
  year            = {2006},
  volume          = {1},
  number          = {1},
  pages           = {1-4},
  issn            = {19750080},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Development of information security system is brought by problem by the development of network environment, and the need of equipment for performance test, but performance test equipments are expensive and difficult to use. Therefore, we need an environment which can develop a performance test for an information security system. In this paper, the design and implementation of an APS (Attack Packet Simulator) extracts the attack information from Snort rule and creates an attack information in the Database using the extracted information. Stored information in the database creates and transmits the packets which are analyzed for comparing the results to other systems.},
  author_keywords = {Packet simulator; Security},
  document_type   = {Article},
  keywords        = {Attack packets; Network environments; Performance tests; Security, Information use; Security systems; Simulators, Security of data},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856587575&partnerID=40&md5=1c376e6b52cc2bf5a2812e41952c305d},
}

@Conference{Hou2006,
  author          = {Hou, T.-C. and Lynch, J.P.},
  title           = {Rapid-to-deploy wireless monitoring systems for static and dynamic load testing of bridges: Validation on the grove street bridge},
  year            = {2006},
  volume          = {6178},
  note            = {cited By 7},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Bridge management officials have expressed a keen interest in the use of low-cost and easy-to-install wireless sensors to record bridge responses during short-term load testing. To illustrate the suitability of wireless sensors for short-term monitoring of highway bridges, a wireless monitoring system is installed upon the Grove Street Bridge to monitor structural responses during static and dynamic load testing. Specifically, load testing of the Grove Street Bridge is conducted after its construction to validate the behavior of a novel jointless bridge deck constructed from a high-performance fiber reinforced cementations composite (HPFRCC) material. A heterogeneous array of sensing transducers are installed in the bridge including metal foil strain gages, accelerometers and linear variable differential transducers (LVDTs). First, the acceleration response of the bridge is monitored by the wireless system during routine traffic loading. Modal parameters (modal frequencies and mode shapes) are calculated by the wireless sensors so that an analytical model of the bridge constructed in a standard commercial finite element package can be updated off-line. Next, the bridge is closed to traffic and trucks of known weight are parked on the bridge to induce static deformations. The installation strategy of the wireless monitoring system during static load testing is optimized to monitor the strain and rotation response of the HPFRCC deck. The measured static response of the deck is compared to that predicted by the updated analytical model.},
  art_number      = {61780D},
  author_keywords = {Load testing; wireless sensors; Structural monitoring; System identification},
  coden           = {PSISD},
  document_type   = {Conference Paper},
  doi             = {10.1117/12.658902},
  isbn            = {0819462314; 9780819462312},
  issn            = {0277786X},
  journal         = {Proceedings of SPIE - The International Society for Optical Engineering},
  keywords        = {Rotation response; Static deformations; Structural monitoring; Wireless sensors, Condition monitoring; Deformation; Identification (control systems); Load testing; Mathematical models; Wireless telecommunication systems, Bridges},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749549640&doi=10.1117%2f12.658902&partnerID=40&md5=c71b9e1970e676b1e5cf57d7b0dddb53},
}

@Article{Herruzo2006,
  author        = {Herruzo, E. and Mesones, A.J. and Benavides, J.I. and Plata, O. and Zapata, E.L.},
  title         = {Distributed architecture system for computer performance testing},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year          = {2006},
  volume        = {3911 LNCS},
  pages         = {140-147},
  issn          = {03029743},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {This article presents a system which is based on a distributed network architecture, The system defines a "double" Client-Server structure which permits to incorporate new client systems in real-time using the Internet. We have used this distributed architecture system to develop a tool to measure the computer performance characteristics of several computer architecture systems. The computer performance is tested by a free library called PAPI (Performance API), which allows us to access to internal status registers of several CPU families in several Operating Systems. As this testing has to be done in real CPUs, we have to create a new system to provide this functionality. The structure proposed has only one entry point to the whole system, the Master Server, and several different Architecture Client Servers. We present the network system description and the usage of PAPI for performance testing. © Springer-Verlag Berlin Heidelberg 2006.},
  document_type = {Conference Paper},
  doi           = {10.1007/11752578_18},
  isbn          = {3540341412; 9783540341413},
  keywords      = {Client server computer systems; Computer systems programming; Distributed computer systems; Information retrieval systems; Internet; Real time systems, Computer performance; Distributed architecture system; Network systems, Computer architecture},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745795543&doi=10.1007%2f11752578_18&partnerID=40&md5=f3a1b6105d76b0a098a812bf402975ee},
}

@Article{Briand2006a,
  author          = {Briand, L.C. and Labiche, Y. and Shousha, M.},
  title           = {Using genetic algorithms for early schedulability analysis and stress testing in real-time systems},
  journal         = {Genetic Programming and Evolvable Machines},
  year            = {2006},
  volume          = {7},
  number          = {2},
  pages           = {145-170},
  issn            = {13892576},
  note            = {cited By 38},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Reactive real-time systems have to react to external events within time constraints: Triggered tasks must execute within deadlines. It is therefore important for the designers of such systems to analyze the schedulability of tasks during the design process, as well as to test the system's response time to events in an effective manner once it is implemented. This article explores the use of genetic algorithms to provide automated support for both tasks. Our main objective is then to automate, based on the system task architecture, the derivation of test cases that maximize the chances of critical deadline misses within the system; we refer to this testing activity as stress testing. A second objective is to enable an early but realistic analysis of tasks' schedulability at design time. We have developed a specific solution based on genetic algorithms and implemented it in a tool. Case studies were run and results show that the tool (1) is effective at identifying test cases that will likely stress the system to such an extent that some tasks may miss deadlines, (2) can identify situations that were deemed to be schedulable based on standard schedulability analysis but that, nevertheless, exhibit deadline misses.},
  author_keywords = {Genetic algorithms; Schedulability theory; Software verification and validation},
  document_type   = {Conference Paper},
  doi             = {10.1007/s10710-006-9003-9},
  keywords        = {Real time systems; Scheduling; Stress analysis; Systems analysis, Critical deadline; Schedulability theory; Software verification and validation; System task architecture, Genetic algorithms},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746266323&doi=10.1007%2fs10710-006-9003-9&partnerID=40&md5=e27b31b0db9c07074b30bcf3bd36b018},
}

@Conference{Smid2006,
  author        = {Smid, K.},
  title         = {Load test methodology for primary health care information system},
  year          = {2006},
  volume        = {2},
  publisher     = {Croatian Society for Information and Communication Technology},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {As the Primary Health Care Information System had attained projects transition phase, it was ready for the deployment of load testing. System architecture that was based on the J2EE blueprints is explained in order to introduce the important inducements of system load. Next, we will give overview of the load testing methodology that was used in design phase. Testing tools and infrastructure used for the generation of real system load are presented as the actual implementation of load testing design. At the end, load testing data and results that had been obtained are presented and evaluated in detail. © 2006 by MIPRO. Al1 rights reserved.},
  document_type = {Conference Paper},
  journal       = {MIPRO 2006 - 29th International Convention Proceedings: Telecommunications and Information},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84895858571&partnerID=40&md5=db47ecbd23c54634015f72bc87eac6a7},
}

@Conference{Cho2005,
  author          = {Cho, H. and Kim, S. and Lee, B.},
  title           = {A digital X-ray imaging system based on a CMOS photo-sensor array and its performance tests},
  year            = {2005},
  pages           = {100-106},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {We have developed a digital X-ray imaging module based on a CMOS photo-sensor array for portable high-resolution imaging applications and evaluated its image performance. The imaging module consists of a commercially-available CMOS photo-sensor array of 48 μm × 48 μm pixel size and 49.2 mm × 49.3 mm active area, a conventional Gd 2O 2S:Tb scintillator (Min-R, Kodak), a controlling readout IC board, a battery-operated X-ray generator (60 kV p, &lt; 1 mA), and a GUI software. In this paper, we described digital imaging components we integrated in detail, and also presented its performance evaluation in terms of the system response, the contrast-to-noise ratio (CNR), the modulation transfer function (MTF), the noise power spectrum (NPS), and the detective quantum efficiency (DQE).},
  author_keywords = {CMOS photo-sensor array; Digital radiography; Image performance; X-ray imaging},
  document_type   = {Conference Paper},
  isbn            = {9781932415834},
  journal         = {Proceedings of the 2005 International Conference on Mathematics and Engineering Techniques in Medicine and Biological Sciences, METMBS'05},
  keywords        = {Active areas; CMOS photo-sensor array; Contrast-to-noise ratios; Detective quantum efficiencies; Digital imaging; Digital radiography; Digital x-ray imaging; Digital x-ray imaging systems; GUI softwares; High-resolution imaging; Image performance; Modulation transfer functions; Module-based; Noise power spectrums; Performance evaluations; Performance tests; Pixel sizes; System response; X-ray generators; X-ray imaging, Computer graphics; Gadolinium; Image registration; Medical imaging; Optoelectronic devices; Power spectrum; Radiology; Sensor arrays; X ray analysis; X rays, X ray radiography},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-60749084473&partnerID=40&md5=e21f1d629c0a8b0e73792d4bba5da65d},
}

@Conference{Cucos2005,
  author        = {Cucos, L. and De Doncker, E.},
  title         = {"gRpas", a tool for performance testing and analysis},
  year          = {2005},
  editor        = {Sunderam V.S., Albada G.D., Sloot P.M.A., Dongarra J.J.},
  volume        = {3514},
  number        = {I},
  pages         = {322-329},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {This paper presents "gRpas", a tool written in Java and designed to help;analyzing test results from scientific computing applications. "gRpas" stands for "gather Results / plot, analyze, and store". As one of its main features, the tool is easy to interface with the user program. Furthermore it provides for one click data filtering and plot generation, effective graphical display of program output, and statistical report generation on algorithm results and performance. gRpas also has built-in functionality for comparison testing between two or more algorithms or algorithm versions. We will present examples of its use with parallel multivariate integration routines. However, its target applications cover a wide class of scientific computing programs. © Springer-Verlag Berlin Heidelberg 2005.},
  document_type = {Conference Paper},
  issn          = {03029743},
  journal       = {Lecture Notes in Computer Science},
  keywords      = {Comparison testing; Data filtering; Graphical display; Parallel multivariate integration; Comparison testing; Data filtering; Graphical displays; Parallel multivariate integration; Performance testing; Scientific computing applications; Statistical report; Target application, Algorithms; Computational complexity; Data reduction; Graphic methods; User interfaces; Artificial intelligence; Computer science; Computers, Java programming language; Application programs},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-25144435423&partnerID=40&md5=9cb38faba40b8edd64dc2cc0ceaaa63a},
}

@Article{Schieferdecker2005,
  author          = {Schieferdecker, I. and Din, G. and Apostolidis, D.},
  title           = {Distributed functional and load tests for Web services},
  journal         = {International Journal on Software Tools for Technology Transfer},
  year            = {2005},
  volume          = {7},
  number          = {4},
  pages           = {351-360},
  issn            = {14332779},
  note            = {cited By 11},
  __markedentry   = {[Jonnathan:]},
  abstract        = {System-level testing considers functionality and load aspects to check how a system performs for single service requests and scales as the number of service requests accessing/using it increases. This paper presents a flexible test framework including functional, service interaction and load tests. It is generic in terms of being largely independent of the system to be tested. The paper discusses the automation of the test framework with the Testing and Test Control Notation TTCN-3 and also presents an implementation of the test framework using a TTCN-3 toolset. The test framework is exemplified for Web service tests and demonstrates distributed functional and load tests for a specific Web service. © 2005 Springer-Verlag.},
  author_keywords = {Distributed tests; Test frameworks; Test specification; TTCN-3; Web services},
  document_type   = {Article},
  doi             = {10.1007/s10009-004-0165-6},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-23944511434&doi=10.1007%2fs10009-004-0165-6&partnerID=40&md5=8e9f0442a671da9fce1e67354dd09a43},
}

@Article{Chi2005,
  author          = {Chi, R. and Zhong, Y. and Zhang, S.},
  title           = {Automatic Web performance testing based on protocol analysis},
  journal         = {Jisuanji Gongcheng/Computer Engineering},
  year            = {2005},
  volume          = {31},
  number          = {7},
  pages           = {103-104+117},
  issn            = {10003428},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Applications based on Web are more and more widely used. Usually, there are many terminal users who use a Web system, so it is very important to test its performance. Automatic testing plays a crucial role in performance testing. With the aid of common network tools, the authors implemented automatic testing on complicated Web applications preliminarily through using current popular script language Python.},
  author_keywords = {Automatic testing; HTTP protocol analysis; Web testing},
  coden           = {JISGE},
  document_type   = {Article},
  language        = {Chinese},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-17944363282&partnerID=40&md5=a8bdd0d15dc1b10374c8c69e4baeefc4},
}

@Article{Liu2005,
  author          = {Liu, D. and Yan, H.-M. and Ding, Z.-H. and Lu, R. and Wang, X.-D. and Li, Z.-Y. and Yue, Z.-D.},
  title           = {Design of feeder automation testing in fat and sat stages},
  journal         = {Dianli Xitong Zidonghua/Automation of Electric Power Systems},
  year            = {2005},
  volume          = {29},
  number          = {3},
  pages           = {81-85},
  issn            = {10001026},
  note            = {cited By 13},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The factory acceptance test (FAT) and site acceptance test (SAT) of distribution automation system should be done before system putting into operation in order to ensure the product's quality. Especially, feeder automation (FA) testing is the key process. In this paper, the testing contents, method and its environment of FA in FAT and SAT stages are discussed. Furthermore, a FA testing case of Shanghai distribution networks including function test, performance test, reliability test and availability test are discussed.},
  author_keywords = {Distribution automation; Factory acceptance test (FAT); Feeder automation (FA); Site acceptance test (SAT)},
  coden           = {DXZIE},
  document_type   = {Article},
  keywords        = {Automation; Testing, Distribution automation; Factory acceptance test; Feeder automation; Products quality; Site acceptance test, Electric power distribution},
  language        = {Chinese},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-15044345493&partnerID=40&md5=eb283120256d433520f666f0c0792926},
}

@Article{Li2004,
  author        = {Li, Y. and Li, M. and Yu, J.},
  title         = {Web services testing, the methodology, and the implementation of the automation-testing tool},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year          = {2004},
  volume        = {3032},
  pages         = {940-947},
  issn          = {03029743},
  note          = {cited By 4},
  __markedentry = {[Jonnathan:]},
  abstract      = {Web Services testing is essential to achieve the goal of scalable, robust and successful Web Services especially in business environment where maybe exist hundreds of Web Services working together. In this paper, we give detailed explanation about the Web Services testing methodology and skill, which are very helpful to the testers. Compared with tradition programming testing, the Web Services testing has its own feature such as performance, authorization, and security. Based on the knowledge of the aspects of Web Services, we design and implement a testing tool to perform some tests automatically. © Springer-Verlag Berlin Heidelberg 2004.},
  document_type = {Article},
  keywords      = {Websites, Automation testing; Business environments; Design and implements; Testing methodology; Testing tools, Web services},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745897785&partnerID=40&md5=1c41940a838a29e9be2a108e49700f0d},
}

@Article{Dibuz2004,
  author        = {Dibuz, S. and Szabó, T. and Torpis, Z.},
  title         = {BCMP performance test with TTCN-3 mobile node emulator},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year          = {2004},
  volume        = {2978},
  pages         = {50-59},
  issn          = {03029743},
  note          = {cited By 5},
  __markedentry = {[Jonnathan:]},
  abstract      = {In this paper we show guidelines for performance testing through BRAIN Candidate Mobility Management Protocol (BCMP). At first, we investigate the main issues of our tests, then we describe briefly the applied TTCN-3 based distributed parallel test environment. We present the structure of the network to be tested and the Mobile Node Emulator, the main functional element of the performance test. We describe the actual test and the results. Finally, we summarize our experiences and proposals. © IFIP 2004.},
  document_type = {Article},
  keywords      = {Artificial intelligence; Computers, Functional elements; Mobile nodes; Mobility management protocol; Parallel test; Performance testing; Performance tests, Testing},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-35048815984&partnerID=40&md5=c9c5e4990f76d40eac3be7efaeed0f8b},
}

@Article{Sheng2004,
  author          = {Sheng, L. and Wu, J. and Zhang, M. and Xu, M.},
  title           = {Flow scheduling algorithm for traffic generation in high-speed network performance testing},
  journal         = {Qinghua Daxue Xuebao/Journal of Tsinghua University},
  year            = {2004},
  volume          = {44},
  number          = {7},
  pages           = {969-973},
  issn            = {10000054},
  note            = {cited By 3},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Traffic generation is a key component of high-speed network performance testing. A complex data traffic environment can be emulated for performance testing by generating simultaneously a number of flows with various data characteristics. The data rate and the degree of bursting of the packets in each flow are important parameters that are specified by the flow model in this paper. Since many flows should be sent from each network interface, a scheduling mechanism is needed to maintain the flow model of each flow. This paper describes a scheduling algorithm that groups the flows and polls them in round robin in both the flow-level and the group-level. The algorithm can achieve the scheduling objective with low time and space complexity. The algorithm implemented in a high-speed network performance tester, IP-TEST achieved a line-speed of 1 Gb/s and supported burst flow models.},
  author_keywords = {Computer networks; Flow scheduling; Network performance testing; Traffic generation},
  coden           = {QDXKE},
  document_type   = {Article},
  keywords        = {Computer networks; Performance; Testing, Flow scheduling; Grouping round robin; High speed network performance testing; Traffic generation, Telecommunication traffic},
  language        = {Chinese},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-5744254906&partnerID=40&md5=a6b4ba92d5d729178f3ae7b01bdea890},
}

@Conference{Chan2004a,
  author          = {Chan, H.A.},
  title           = {Accelerated stress testing for both hardware and software},
  year            = {2004},
  pages           = {346-351},
  note            = {cited By 8},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Accelerated Stress Testing (AST) has been used in electronic, electromechanical, and mechanical systems to achieve robustness with high reliability primarily for hardware. For software products, the reliability program is often conducted separate from any hardware accelerated stress testing. Yet, many systems consist of concurrent software and hardware issues. In addition, the stress testing processes were primarily adopted by those responsible to develop and manufacture hardware. For example, the stresses usually include temperature extremes, thermal cycles, vibrations, etc. These stresses are effective in accelerating latent hardware defects from degradable, marginal, or intermittent failures to hard failures so that root cause analyses and corrective actions may be made. Although experiments had indicated that software faults and hardware defects are related, the available formulation of the fundamental principles was still based on hardware systems. AST for software and for operating systems have been discussed in [3] and [4], but a fundamental understanding of AST for software is lacking. In order to generalize the fundamentals of accelerated stress testing to address both software and hardware, we need to define accelerated stress testing for software and to address whether they are needed, i.e., whether there are effective methods to achieve high software reliability. The basic reliability concepts categorize systems into different categories according to the presence of defects and faults and whether these weaknesses are explicit enough. The concepts for both hardware and software reliability separate the notion of defects and faults from failures. It further conceptually separates the notion of stressing and the notion of detection. The fundamental concept is that all failures except the explicit ones must be manifested under certain stress conditions. There is then a threshold stress level beyond which a system will fail. The cumulative effect of stresses is included by defining time as one type of stress. Both hardware and software systems have marginal weakness, and degradable weakness. The process of recovery and repair are also examined for both hardware and software events. The basic reliability principles in accelerated stress testing for both software and hardware systems are combined and explained in this paper. While [3] and [4] also address the needs and advantages of AST for software, an effective software AST program will require efficient tools yet to be developed. The benefits should justify the needed further research and development in this area.},
  author_keywords = {Reliability; Stress testing},
  coden           = {PRMSC},
  document_type   = {Conference Paper},
  issn            = {0149144X},
  journal         = {Proceedings of the Annual Reliability and Maintainability Symposium},
  keywords        = {Accelerated stress testing (AST); Product weakness detection; Time-to-market; Accelerated stress testing; Fundamental principles; Hardware and software; Reliability concepts; Reliability principles; Research and development; Software and hardwares; Stress Testing, Computer hardware; Concurrent engineering; Failure analysis; Reliability theory; Stress analysis; Testing; Thermal cycling; Vibrations (mechanical); Computer software; Defects; Hardware; Maintainability; Quality control; Reliability; Software testing; Stresses; Vibration analysis, Computer software; Software reliability},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-2342650761&partnerID=40&md5=70994249c409c42fd5a08c19f689ac25},
}

@Article{Rocha2003,
  author        = {Rocha, R.L.A. and Cardoso, L.F. and De Souza, J.M.},
  title         = {Performance tests in data warehousing ETLM process for detection of changes in data origin},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year          = {2003},
  volume        = {2737},
  pages         = {129-139},
  issn          = {03029743},
  note          = {cited By 1},
  __markedentry = {[Jonnathan:]},
  abstract      = {In a data warehouse (DW) environment, when the operational environment does not posses or does not want to inform the data about the changes that occurred, controls have to be implemented to enable detection of these changes and to reflect them in the DW environment. The main scenarios are: i) the impossibility to instrument the DBMS (triggers, transaction log, stored procedures, replication, materialized views, old and new versions of data, etc) due to security policies, data property or performance issues; ii) the lack of instrumentation resources on the DBMS; iii) the use of legacy technologies such file systems or semi-structured data; iv) application proprietary databases and ERP systems. In another article [1]; we presented the development and implementation of a technique that was derived for the comparison of database snapshots, where we use signatures to mark and detect changes. The technique is simple and can be applied to all four scenarios above. To prove the efficiency of our technique, in this article we do comparative performance tests between these approaches. We performed two benchmarks: the first one using synthetic data and the second one using the real data from a case study in the data warehouse project developed for Rio Sul Airlines, a regional aviation company belonging to the Brazil-based Varig group. We also describe the main approaches to solve the detection of changes in data origin. © Springer-Verlag Berlin Heidelberg 2003.},
  document_type = {Article},
  keywords      = {Legacy systems; Network security, Aviation companies; Comparative performance; Comparison of database; Detection of changes; Legacy technologies; Operational environments; Performance issues; Semi structured data, Data warehouses},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-26844479790&partnerID=40&md5=3b051b6b643c0b487a24ac94fa694eeb},
}

@Article{Cui2003,
  author          = {Cui, Y. and Xu, K. and Xu, M. and Wu, J.},
  title           = {Research on stress testing of OSPF protocol implementation},
  journal         = {High Technology Letters},
  year            = {2003},
  volume          = {9},
  number          = {3},
  pages           = {11-18},
  issn            = {10066748},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {The stability and robustness of routing protocol implementations (RPI) in a router are becoming more and more important with the growth of Internet scale. A novel approach named stress testing is proposed to test the properties of RPI. Compared with some traditional test techniques, stress testing is remarkably necessary to inspect and analyze RPI. The test environment is proposed and the test process of OSPF RPI is illustrated by a stochastic Petri Net model with large-scale route simulation and OSPF protocol emulation. Based on this model, the integrated performance tester (IP-TEST) is designed and developed, with which we test a CISCO2600 router. With mathematical methods, we find that the computational complexity of OSPF implementation in this router is O((lnN)4) to the number of its routing table entries. This experiment shows that this technique can inspect the stability, the computational complexity and the scalability of RPI. Furthermore, it can also be widely used with other routing protocols, such as RIP and BGP.},
  author_keywords = {Computational complexity; Petri net; Routing protocol implementation (RPI); Stability; Stress testing},
  coden           = {HTLEF},
  document_type   = {Article},
  keywords        = {Network protocols; Petri nets, Open shortest path first protocol; Routing protocol implementation; Stress testing techniques; Testing ability of routers, Routers},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-1242275195&partnerID=40&md5=80d0e6c5b4dd4dd675c1fe8c94edc6f2},
}

@Article{Jywe2003,
  author          = {Jywe, W.},
  title           = {The development and application of a planar encoder measuring system for performance tests of CNC machine tools},
  journal         = {International Journal of Advanced Manufacturing Technology},
  year            = {2003},
  volume          = {21},
  number          = {1},
  pages           = {20-28},
  issn            = {02683768},
  note            = {cited By 14},
  __markedentry   = {[Jonnathan:]},
  abstract        = {In this paper, a measuring device with a planar encoder is developed to test the performance of a CNC machine tool. With the assistance of a PC. this system can be employed for both 2D contouring tests and 3D positioning tests for a CNC machine tool. The structure and the principle of the system, the applications for the general 2D contouring test, the drift test, and the specified geometric pan path tests. An actual case study on improving the accuracy of machining a cam are described. Finally, a new 3D positioning method using the optic encoder is demonstrated.},
  author_keywords = {Ball bar system; CNC machine tool; Geometric part path; Planar encoder; Thermal drift test; Three-dimensional positioning; Two-dimensional contouring},
  coden           = {IJATE},
  document_type   = {Article},
  doi             = {10.1007/s001700300003},
  keywords        = {Computer control systems; Computer software; Coordinate measuring machines; Equipment testing; Error analysis; Geometry; Numerical control systems; Optical sensors; Semiconductor lasers; Thermal effects; Three dimensional; Two dimensional, Ball bar system; Computer numerical control machine tools; Geometric part path; Planar encoder measuring system; Thermal drift test; Three-dimensional positioning; Two-dimensional contouring, Machine tools},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037276139&doi=10.1007%2fs001700300003&partnerID=40&md5=047e97da0162c320d5ce0b8ccd741d58},
}

@Article{Zhang2002,
  author          = {Zhang, J. and Cheung, S.C.},
  title           = {Automated test case generation for the stress testing of multimedia systems},
  journal         = {Software - Practice and Experience},
  year            = {2002},
  volume          = {32},
  number          = {15},
  pages           = {1411-1435},
  issn            = {00380644},
  note            = {cited By 39},
  __markedentry   = {[Jonnathan:]},
  abstract        = {With the advancement in network bandwidth and computing power, multimedia systems have become a popular means for information delivery. However, general principles of system testing cannot be directly applied to testing of multimedia systems on account of their stringent temporal and synchronization requirements. In particular, few studies have been made on the stress testing of multimedia systems with respect to their temporal requirements under resource saturation. Stress testing is important because erroneous behavior is most likely to occur under resource saturation. This paper presents an automatable method of test case generation for the stress testing of multimedia systems. It adapts constraint solving techniques to generate test cases that lead to potential resource saturation in a multimedia system. Coverage of the test cases is defined upon the reachability graph of a multimedia system. The proposed stress testing technique is supported by tools and has been successfully applied to a real-life commercial multimedia system. Although our technique focuses on the stress testing of multimedia systems, the underlying issues and concepts are applicable to other types of real-time systems.},
  author_keywords = {Constraint solving; Multimedia systems; Resource consumption; Static analysis; Stress testing; Test case generation},
  coden           = {SPEXB},
  document_type   = {Article},
  doi             = {10.1002/spe.487},
  keywords        = {Automatic testing; Computer aided software engineering; Computer software selection and evaluation; Reliability; Resource allocation; Storage allocation (computer), Automated test case generation; Constraint solving; Resource consumption; Static analysis; Stress testing, Multimedia systems},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036907695&doi=10.1002%2fspe.487&partnerID=40&md5=d045edaf494a6fc351cca3154d6b4c74},
}

@Conference{Bailon2002,
  author        = {Bailón, R. and Olmos, S. and Serrano, P. and García, J. and Laguna, P.},
  title         = {Robust measure of ST/HR hysteresis in stress test ECG recordings},
  year          = {2002},
  editor        = {Murray A.},
  volume        = {29},
  pages         = {329-332},
  note          = {cited By 5},
  __markedentry = {[Jonnathan:]},
  abstract      = {In stress test ECG analysis, the so-called ST/HR hysteresis has recently been suggested to improve coronary artery disease (CAD) diagnosis. This parameter is estimated from the ST versus HR diagram including exercise and recovery phases. Unluckily, ST measurements are adversely affected by noise during the test. In this study we propose a method to automatically estimate the ST/HR hysteresis, incorporating multiple stage noise attenuation. The method is based on averaging and rejection of noisy beats. Evaluation is done on simulated exercise test recordings, constructed from real ECG averaged beats adding actual noise from stress test records. Results on a total of 216 different records, with RMS noise levels ranging from 114 to 979 μV, give a reduction in estimation error in the ST/HR diagram of 77.98% (from 168 to 37 μV) in mean and of 76.38% (from 271 to 63 μV) in standard deviation. This method may be considered as a suitable and robust tool for reliable ST/HR hysteresis estimation.},
  coden         = {COCAD},
  document_type = {Conference Paper},
  issn          = {02766574},
  journal       = {Computers in Cardiology},
  keywords      = {Computer simulation; Error analysis; Hysteresis; Robustness (control systems); Spurious signal noise; Stress analysis, Coronary artery disease (CAD), Electrocardiography},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036945430&partnerID=40&md5=f34430791de0e58874434669a02c25cb},
}

@Conference{Matthys2002a,
  author        = {Matthys, K. and Vanhercke, D. and Van Aken, S. and De Groote, K. and Coomans, I. and Verdonck, P.},
  title         = {Non-invasive assessment of hemodynamics in adolescents with arterial tonometry and doppler ultrasound during a conventional stress test},
  year          = {2002},
  editor        = {Murray A.},
  volume        = {29},
  pages         = {517-520},
  note          = {cited By 3},
  __markedentry = {[Jonnathan:]},
  abstract      = {Aiming to improve early diagnosis of people at cardiovascular risk, we are developing a custom set-up to allow an adequate hemodynamic analysis of heart function and arterial circulation properties, based on non-invasive acquisition of pressure (arterial tonometry) and flow (Doppler ultrasound techniques) waveforms. In an experimental setting 15 healthy volunteers were examined on a custom made supine bicycle. Able to record usable data throughout the bicycle test and automatically analyse derived hemodynamic parameters such as compliance, peripheral resistance, etc., we also applied the set-up in a real clinical environment. This research contributes to a more complete cardiovascular examination without significant additional discomfort for the patient or prolongation of the test protocol.},
  coden         = {COCAD},
  document_type = {Conference Paper},
  issn          = {02766574},
  journal       = {Computers in Cardiology},
  keywords      = {Biomedical engineering; Blood vessels; Computer aided diagnosis; Hemodynamics; Noninvasive medical procedures, Mental stresses; Tonometers, Cardiovascular system},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036954874&partnerID=40&md5=9c5222b04da2d90183a42e1dca76e854},
}

@Conference{Schwenker2002,
  author          = {Schwenker, J.P. and Brandi, B.R. and Burmester, W.L. and Hora, J.L. and Mainzer, A.K. and Quigley, P.C. and Van Cleve, J.E.},
  title           = {SIRTF-CTA optical performance test},
  year            = {2002},
  editor          = {Mather J.C.},
  volume          = {4850},
  number          = {1},
  pages           = {304-317},
  note            = {cited By 8},
  __markedentry   = {[Jonnathan:]},
  abstract        = {This paper describes the "End to End" optical test conducted on the Space InfraRed Telescope Facility (SIRTF) Cryogenic Telescope Assembly (CTA) in 2001. It was critical to verify SIRTF's optical functionality and quality under optical and thermal conditions that as much as possible simulated the flight environment. The Liquid Nitrogen cooled "Brutus" chamber at Ball Aerospace was the test facility. Flight-like self cooling, thermal blanketing, and auxiliary cooling loops allowed the assembly to reach temperatures close to orbital conditions. (25-5 K) Introducing optical sources at the SIRTF focal plane allowed the telescope to perform as the collimating source. A motorized and cryogenically characterized reflection flat was used to direct the refocused images of test sources to visible and IR focal planes in SIRTF's Multi-Instrument Chamber. A sequence of tests was performed to gather data on system focus position, image stability, telescope wavefront and instrument assembly confocality.},
  author_keywords = {Cryogenic; Focus; Infrared; Liquid helium; Telescope; Thermal vac; Wavefront},
  coden           = {PSISD},
  document_type   = {Conference Paper},
  doi             = {10.1117/12.461918},
  issn            = {0277786X},
  journal         = {Proceedings of SPIE - The International Society for Optical Engineering},
  keywords        = {Cryogenics; Infrared instruments; Space telescopes; Superfluid helium, Cryogenic telescope assembly (CTA), Optical testing},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037956974&doi=10.1117%2f12.461918&partnerID=40&md5=4b0bdb8c6fa06a9d5fff7fa009474fd6},
}

@Article{Shaw2002,
  author        = {Shaw, J.C.C. and Baisden, C.G. and Pryke, W.M.},
  title         = {Performance testing - A case study of a combined Web/telephony system},
  journal       = {BT Technology Journal},
  year          = {2002},
  volume        = {20},
  number        = {3},
  pages         = {76-86},
  issn          = {13583948},
  note          = {cited By 5},
  __markedentry = {[Jonnathan:]},
  abstract      = {This paper describes performance testing and how it interfaces with other disciplines within performance engineering. It describes choice of tools and some common pitfalls in setting up a valid performance test. Turning from the general to a case study, a description of performance testing on one product is given, covering both voice and Web application performance testing. Conclusions summarising what makes a successful performance test and its value are drawn.},
  coden         = {BTTJE},
  document_type = {Article},
  doi           = {10.1023/A:1020899610791},
  keywords      = {Computational complexity; Computer simulation; Conference calls; Congestion control (communication); Electronic mail; Internet telephony; Personal communication systems; Real time systems; Voice/data communication systems, Internet access authentication; Least cost routing; Performance testing; Personal numbering; User registration; Web telephony system, World Wide Web},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036629691&doi=10.1023%2fA%3a1020899610791&partnerID=40&md5=2ca7c7ae8972042f9d57c3ad73b296ee},
}

@Article{Wang2002,
  author        = {Wang, J. and Peng, Q.},
  title         = {An interactive method of assessing the characteristics of softcopy display using observer performance tests.},
  journal       = {Journal of digital imaging : the official journal of the Society for Computer Applications in Radiology},
  year          = {2002},
  volume        = {15 Suppl 1},
  pages         = {216-218},
  issn          = {08971889},
  note          = {cited By 4},
  __markedentry = {[Jonnathan:]},
  abstract      = {An interactive computer program has been developed to assess the quality of softcopy display by measuring the contrast sensitivity, spatial resolution, and spatial uniformity at various backgrounds and objects. This program runs on Microsoft Window or NT platform and is easy to use. It has been shown to be a sensitive and accurate tool to measure the characteristics of monitors of any kind. It can be used for routine QA as well as for the acceptance testing of picture archiving and communication systems. Data obtained using this program on monitors can be plotted chronologically so as to monitor any trend of deterioration. By introducing a randomization of the location of the test objects, this program eliminates the guessing error often associated with psychophysical measurements.},
  document_type = {Article},
  doi           = {10.1007/s10278-002-5003-3},
  keywords      = {article; computer program; computer terminal; hospital information system; information processing; quality control; standard, Computer Terminals; Data Display; Quality Control; Radiology Information Systems; Software},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036052108&doi=10.1007%2fs10278-002-5003-3&partnerID=40&md5=5a574a7f2bc1d313274ef12fc7559af2},
}

@Conference{Sakamoto2002a,
  author          = {Sakamoto, M. and Brisson, L. and Katsuno, A. and Inoue, A. and Kimura, Y.},
  title           = {Reverse Tracer: A software tool for generating realistic performance test programs},
  year            = {2002},
  volume          = {2002-January},
  pages           = {81-91},
  publisher       = {IEEE Computer Society},
  note            = {cited By 6},
  __markedentry   = {[Jonnathan:]},
  abstract        = {During the development of high-performance processors, software performance models are used to obtain performance estimates. These models are not cycle-accurate, so their results can have significant errors, leading to performance surprises after the hardware is built. Some performance tests can run directly on the logic simulators, to get more accurate results, but those simulators cannot run large interactive workloads with I/O and much operating system code. So the accurate performance estimates from logic simulators are only available for application code, and are not adequate for the evaluation of powerful server systems that are primarily intended to run large interactive workloads. We discuss a software tool system, the "Reverse Tracer", that generates executable performance tests from an instruction trace of the workload. The generated performance tests retain the essential performance characteristics of multi-user I/O-intensive workloads without doing any real I/O, so they can run in logic simulation to measure performance accurately before the hardware is built. © 2002 IEEE.},
  art_number      = {995700},
  author_keywords = {Computer architecture; Software testing; Software tools},
  document_type   = {Conference Paper},
  doi             = {10.1109/HPCA.2002.995700},
  isbn            = {0769515258},
  issn            = {15300897},
  journal         = {Proceedings - International Symposium on High-Performance Computer Architecture},
  keywords        = {Computer aided software engineering; Computer architecture; Computer hardware; Embedded systems; Hardware; Simulators; Software testing; Supercomputers, Accurate performance; Application codes; Cycle accurate; High performance processors; Logic simulations; Performance characteristics; Performance tests; Software performance models, Computer software},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0242519839&doi=10.1109%2fHPCA.2002.995700&partnerID=40&md5=4194f16a013caa0e022c2606d545b3a0},
}

@Conference{Wang2002a,
  author          = {Wang, J. and Peng, Q.},
  title           = {An interactive method of assessing the characteristics of softcopy display using observer performance tests},
  year            = {2002},
  editor          = {Chakraborty D.P., Krupinski E.A.},
  volume          = {4686},
  pages           = {189-197},
  note            = {cited By 3},
  __markedentry   = {[Jonnathan:]},
  abstract        = {An interactive, easy-to-use computer program has been developed to assess the quality of softcopy display by measuring the contrast sensitivity, spatial resolution and spatial uniformity at different backgrounds and object types. The program features random variation of the test object location, which minimizes the guessing error often associated with psychophysical measurements. It operates on a Microsoft Window/NT platform and is intended for routine quality assurance (QA) as well as for acceptance testing of PACS. The QA data obtained with this program can be plotted chronologically and centrally managed so as to detect trends in monitor deterioration. The principal motivation for developing this program was to provide an indirect yet sensitive and accurate measure of monitor characteristics with a minimum of specialized equipment.},
  author_keywords = {Contrast threshold; PACS QC; Quality assessment; Softcopy display},
  coden           = {PSISD},
  document_type   = {Conference Paper},
  doi             = {10.1117/12.462677},
  issn            = {0277786X},
  journal         = {Proceedings of SPIE - The International Society for Optical Engineering},
  keywords        = {Computer monitors; Computer program listings; Image analysis; Quality assurance, Softcopy display, Medical imaging},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036028717&doi=10.1117%2f12.462677&partnerID=40&md5=38aabc181e2dd3f68ed5e05145ccdeac},
}

@Article{Xu1999,
  author        = {Xu, Mingwei and Lin, Chuang and Wu, Jianping},
  title         = {Network protocol performance testing based on stochastic Petri nets},
  journal       = {Ruan Jian Xue Bao/Journal of Software},
  year          = {1999},
  volume        = {10},
  number        = {3},
  pages         = {248-252},
  issn          = {10009825},
  note          = {cited By 1},
  __markedentry = {[Jonnathan:]},
  abstract      = {The main issues to be solved in the protocol performance testing were analyzed. The quality of service (QoS) of the network protocol was described with the stochastic Petri nets (SPN) as formal tool. The transform rules from the SPN model to testing sets of the tree and tubular combined notation (TTCN) were proposed. The testing for the dynamic behavior description of the connect establishment delay, as an example, was given.},
  coden         = {RUXUE},
  document_type = {Article},
  keywords      = {Graph theory; Performance; Petri nets, Protocol performance testing; Stochastic Petri nets, Network protocols},
  language      = {Chinese},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033086689&partnerID=40&md5=669d97c24f77405d8b63edd9b3ad2f0f},
}

@Conference{Walrath1998,
  author        = {Walrath, James D.},
  title         = {Gold plated shovels with rope handles: cognitive issues in display design and a case for performance testing},
  year          = {1998},
  volume        = {2},
  pages         = {500-504},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {System performance is often described in terms MIPS, MFLOPS, IO bus speed, etc. However, these dimensions are not very useful in characterizing overall system performance when part of the system is not silicon based (e.g., when there is a human user). Thus in wishing to address overall system performance in man-machine systems we must toss the user into the fray. How should this be done? Often, we just ask users how they like the particular configuration. We have, after all, been inculcated with the dictum, 'Honor thy user,' and it isn't far from that pronouncement to, 'The user knows best.' Thus if the user is happy we can expect optimal system performance. Or can we? This paper focuses on the importance of acknowledging general quickly human behavior in the design and evaluation of computer displays.},
  coden         = {85QTA},
  document_type = {Conference Paper},
  journal       = {IEEE International Conference on Image Processing},
  keywords      = {Performance test, Man machine systems; Performance; Systems engineering, Computer monitors},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032298101&partnerID=40&md5=23168efdafdf4c6af31705b08241d66b},
}

@Article{Horio1998,
  author        = {Horio, H. and Murakami, M. and Chiba, Y. and Inada, H.},
  title         = {Fetal monitor for non-stress-test screening at home},
  journal       = {Biomedical Instrumentation and Technology},
  year          = {1998},
  volume        = {32},
  number        = {1},
  pages         = {39-47},
  issn          = {08998205},
  note          = {cited By 7},
  __markedentry = {[Jonnathan:]},
  abstract      = {A fetal monitoring device developed for non-stress-test (NST) screening at home works on battery power, and is so small and lightweight (152 X 120 X 64 mm, 600 g) that a pregnant woman can monitor fetal Doppler ultrasound and record fetal heart rate (FHR) and uterine contraction (UC) data on an attached memory IC card at any time and in any place away from a hospital. The physician can evaluate these data, transmitted via public telephone lines, using a built-in modem in the monitor. The combination of the memory IC card as a temporary storage device with the intermittent data transmission to the host provides endless data storage. The input-output relationship of the device was quantitatively evaluated using a Doppler ultrasound heart rate simulator. Forty pregnant women participated in an evaluation of this system. The total number of NST data transmissions was 648, and the total amount of data received was more than 6.7 Mbytes. Of the 648 transmissions, 475 were adequate for clinical interpretation. Of the 101 failed NST data transmissions, 85 resulted from patient handling errors. However, 82.4% of these errors resulted in reexamination and transfer of new data by the patients, who were aware of the insufficiency of the original data. The main cause of noise in the data was zero-count data; this noise rate accounted for 4.1% of the data abnormalities. A questionnaire survey found that 96% of the participants wanted to use the monitor again in their next pregnancies, and 83% would recommend its use to pregnant friends. The system was easily used and accepted by pregnant women, and the NST data obtained were sufficient for clinical interpretation.
A fetal monitoring device that works on battery power was developed for non-stress-test (NST) screening at home. It is small and lightweight that a pregnant woman can monitor fetal Doppler ultrasound and record fetal heart rate (FHR) and uterine contraction data on an attached memory integrated circuits at any time and in any place way from a hospital. The physician can evaluate these data, transmitted via public telephone line, using built-in modem in the monitor. Pregnant women participated in an evaluation of the fetal monitoring system. 648 NST data were transmitted and 6.7 Mbytes were the total amount of data received. The main cause of noise in the data was zero-count data; this noise rate accounted for 4.1% of the data abnormalities.},
  coden         = {BITYE},
  document_type = {Article},
  keywords      = {Data communication systems; Electronic medical equipment, Fetal Doppler ultrasound; Fetal heart rate; Non stress test (NST) screening, Fetal monitoring, article; clinical article; clinical trial; computer system; data analysis; doppler echography; female; fetus electrocardiography; fetus heart rate; fetus monitoring; human; pregnancy; questionnaire; screening test; uterus contraction, Computer Communication Networks; Costs and Cost Analysis; Diagnosis, Computer-Assisted; Equipment Design; Feasibility Studies; Female; Fetal Monitoring; Heart Rate, Fetal; Humans; Mass Screening; Models, Cardiovascular; Physician-Patient Relations; Pregnancy; Self Care; Ultrasonography, Prenatal; User-Computer Interface},
  language      = {English},
  publisher     = {Assoc for the Advancement of Medical Instrumentation, Arlington, VA, United States},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031884112&partnerID=40&md5=1e9a9f7635a2b53ecf901f63d8c22b07},
}

@Conference{Dodson1997,
  author        = {Dodson, George W.},
  title         = {And you think you have a stressful environment?! (Stress testing distributed systems)},
  year          = {1997},
  editor        = {Anon},
  volume        = {2},
  pages         = {733-740},
  publisher     = {CMG, Turnersville, NJ, United States},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {There are lots of challenges left for capacity and performance specialists. One of the largest is in determining the capacity and performance to be expected for new or enhanced applications for distributed computing, client/server environments, as well as in the explosive growing areas of intranet/Internet and message queuing environments. This paper discusses different challenges in multi-tiered distributed computing environments, together with some approaches that have worked in evaluating performance and capacity in these environments. A stress testing process is also described. Some examples of where stress testing was done, and where it wasn't done, are shared.},
  coden         = {CMPRE},
  document_type = {Conference Paper},
  journal       = {CMG Proceedings},
  keywords      = {Computer architecture; Local area networks; Online systems; Response time (computer systems); Wide area networks, Multi tired distributed computing environments, Distributed computer systems},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031346165&partnerID=40&md5=3393472b90b5eb996c87753a02d5805e},
}

@Conference{Merton1997a,
  author        = {Merton, Joseph K.},
  title         = {Performance testing in a client-server environment},
  year          = {1997},
  editor        = {Anon},
  volume        = {1},
  pages         = {594-601},
  publisher     = {CMG, Turnersville, NJ, United States},
  note          = {cited By 1},
  __markedentry = {[Jonnathan:]},
  abstract      = {As an enterprise grows and adapts to changing business conditions, performance of client-server systems is affected by workload changes caused by growth, functional application changes, and configuration changes in hardware, software, or network topology. This paper presents a case study of the implementation of performance testing in a client-server environment. It describes performance testing objectives, evaluation and selection of performance testing software, construction of a performance testing environment, construction and execution of test cases, and evaluation of results.},
  coden         = {CMPRE},
  document_type = {Conference Paper},
  journal       = {CMG Proceedings},
  keywords      = {Computer aided software engineering; Computer networks; Computer software selection and evaluation; Response time (computer systems); Systems analysis, Client/server environment, Online systems},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031370206&partnerID=40&md5=7c35689a11a891ecddaf5d3b707f27d1},
}

@Conference{Mungal1997,
  author        = {Mungal, Anthony G. and Daoust, Rene},
  title         = {Comparison of remote copy approaches: SRDF and PPRC performance testing},
  year          = {1997},
  editor        = {Anon},
  volume        = {1},
  pages         = {492-504},
  publisher     = {CMG, Turnersville, NJ, United States},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {As the proliferation of applications supporting critical business functions continue to increase, the need for continuous availability of data and associated subsystems continue to heighten. In fact, the whole `global' nature of many businesses today demand that lines of business function seamlessly across multiple time zones spanning difficult geographic areas. This places an increasing challenge on the personnel, resources and configurations required to support these business functions, hence, an understanding of the performance and availability characteristics of the I/O Subsystems capable of supporting such functions is essential. This paper details the results of an extensive suite of testing in a customer environment of EMC's Symmetrix Remote Data Facility (SRDF) and IBM's Peer to Peer Remote Copy (PPRC). An initial review of the various modes of Operations and the full assessment of the functionality of each of the two offerings is made. As expected, to the extent that variations exist within and amongst customer environments, the results of this testing will require specific interpretation. The true benefit of this type of testing is the rather comprehensive and quantitative amount of information which becomes immediately applicable to the many situations facing performance analysts, capacity planners, storage management and other technical management personnel.},
  coden         = {CMPRE},
  document_type = {Conference Paper},
  journal       = {CMG Proceedings},
  keywords      = {Data processing; Digital storage; Interfaces (computer); Online systems; Security of data, Peer to peer remote copy (PPRC); Symmetrix remote data facility (SRDF), Data communication systems},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031389539&partnerID=40&md5=231ad1439bfd8ce3682dac37180f017c},
}

@Conference{Roberts1997a,
  author        = {Roberts, David C. and Grossman, David A. and Frieder, Ophir and Bernstein, Robert and Bishop, Eric},
  title         = {Performance testing of communication protocols for three-tier computing: Results for ICA and X Window protocols},
  year          = {1997},
  pages         = {450-455},
  publisher     = {IEEE, Piscataway, NJ, United States},
  note          = {cited By 1},
  __markedentry = {[Jonnathan:]},
  abstract      = {We present the results of performance tests to compare two protocols for three-tier computing using the Windows NT operating system. Three-tier computing features a data server for stored databases (Tier 1), an application server that runs applications (Tier 2), and a simple client program that runs on desktop machines that presents the user interface (Tier 3). Three protocols are available to communicate between Tier 2 and 3: Intelligence Computer Architecture (ICA) with and without data compression, and X Window. We measured the performance of the three protocols in a multi-user environment in which we simulated the workload imposed by typical users. We found that, for Microsoft Office 97 and Lotus Notes applications, the X Window protocol uses approximately twice the network bandwidth of ICA, without compression. We also found that compressed ICA generates roughly one third less network traffic than uncompressed ICA at a cost of 20% of additional processor utilization.},
  coden         = {00247},
  document_type = {Conference Paper},
  journal       = {Proceedings of the International Conference on Computer Communications and Networks, ICCCN},
  keywords      = {Bandwidth; Computer architecture; Computer simulation; Data compression; Database systems; Telecommunication traffic; User interfaces; Wide area networks, Intelligence computer architecture (ICA); Three tier computing, Network protocols},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031331775&partnerID=40&md5=c05dfaf981a7895d04abb7ae590cc70b},
}

@Conference{Mahmoudi1997a,
  author        = {Mahmoudi, R. and Tauritz, J.L.},
  title         = {Performance testing of the North American CDMA system, using an envelope simulator},
  year          = {1997},
  pages         = {84-88},
  publisher     = {IEEE, Piscataway, NJ, United States},
  note          = {cited By 4},
  __markedentry = {[Jonnathan:]},
  abstract      = {The growing use of spread spectrum techniques for personal communications (PCS) in Japan and USA is proving to be an enormous stimulus for the study of system impact on component design. New and innovative techniques are required to translate system criteria into component specifications. In this paper we have studied the performance of the `North American Digital Cellular, IS-95' system proposed by QUALCOMM, under the influence of spurious signals using the new `Circuit Envelope Simulator' in HP-EESOF'S Microwave Design System, MDS. The implemented functional blocks facilitate the generation of proper (noisy) CDMA (Reverse and Forward) signals, which are then used to program an arbitrary wave generator in order to create actual test signals. Additionally, these functional blocks can be replaced with equivalent circuits, consisting of passive and active elements, etc. For illustrative purposes, we discuss the application of these signals to two real amplifiers, one linear and one non-linear. The measured results are critically compared with the simulation results.},
  coden         = {00267},
  document_type = {Conference Paper},
  journal       = {Annual Wireless Communications Conference, Proceedings},
  keywords      = {Active networks; Amplifiers (electronic); Bandwidth; Cellular radio systems; Communication channels (information theory); Computer simulation; Digital communication systems; Equivalent circuits; Passive networks; Personal communication systems; Radio links; Spurious signal noise, Circuit envelope simulator; Code division multiple access (CDMA), Spread spectrum communication},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030691255&partnerID=40&md5=1371b84a3b918980411f10c599a7e087},
}

@Conference{Mandracchia1996a,
  author          = {Mandracchia, E.A.},
  title           = {Ultrasonic diagnostic load testing of steel highway bridges},
  year            = {1996},
  volume          = {2946},
  pages           = {17-25},
  note            = {cited By 0},
  __markedentry   = {[Jonnathan:]},
  abstract        = {This paper presents a new product, the SonicForce™ Acoustic Strain Gauge (ASG), that utilizes a non-contact ultrasonic technology to measure applied strain requiring no paint removal and minimal surface preparation. After an overview of the ultrasonic technology is presented the results of a diagnostic test utilizing a prototype of the ASG will be discussed. The purpose of this test was to validate the Acoustic Strain Gauge as being functionally equivalent to the resistance strain gauge, and to demonstrate a cost effective enabling technology to the civil and structural engineering communities. The diagnostic tests program was supervised by Dr. Abba Lichtenstein in accordance with accepted guidelines contained in the manual for "Rating Bridges Through Testing" For the purpose of this study the bridge superstructure was modeled and structural loading profiles were determined using both resistive and acoustic strain measurement techniques. Measured strains as determined by the ASG (correlation between the ASG and the resistance strain gauge was 0.998) were compared to theoretical loads in order to determine if the Rodeo Gulch superstructure was operating in a safe and reliable manner. Additionally, under the direction of Phil Fish (Wisconsin DOT), two pre-production ASGs were used to monitor accumulated cyclic loading. These test data presented as a time series strip chart and rainflow histogram. ©2005 Copyright SPIE - The International Society for Optical Engineering.},
  author_keywords = {Applied strain; Bridge diagnostics; EMAT; Rainflow; Strain gauge; Ultrasonic},
  coden           = {PSISD},
  document_type   = {Conference Paper},
  doi             = {10.1117/12.259142},
  issn            = {0277786X},
  journal         = {Proceedings of SPIE - The International Society for Optical Engineering},
  keywords        = {Acoustics; Highway bridges; Highway systems; Load testing; Program diagnostics; Steel testing; Strain; Strain gages; Surface testing; Testing; Ultrasonics, Applied strain; EMAT; Rainflow; Strain gauge; Ultrasonic, Gages},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-58149379665&doi=10.1117%2f12.259142&partnerID=40&md5=1fc09f0927c455f015fc8c8cfeda11fe},
}

@Article{Mandeville1995,
  author        = {Mandeville, Robert},
  title         = {ATM stress test which switches survived?},
  journal       = {Data Communications},
  year          = {1995},
  volume        = {24},
  number        = {3},
  pages         = {10pp},
  issn          = {03636399},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {To find out if ATM is really delivering on its promises, DATA COMM and European Network Laboratories put together the industry's first full-blown stress test for ATM switches. The main goal was to find out how ATM switches work under real conditions. Testers evaluated seven enterprise-class switches using a custom suite of benchmarks that measure latency and jitter, and determine how well each box contends with data bursts and protects delay-sensitive traffic.},
  coden         = {DACOD},
  document_type = {Article},
  keywords      = {Bandwidth; Buffer storage; Communication channels (information theory); Congestion control (communication); Interfaces (computer); Performance; Queueing theory; Real time systems; Switches; Switching; Telecommunication traffic; Voice/data communication systems, ATM switches; Buffering; Cell loss priority; Jitters; Traffic management; Usage parameter control; Variable bit rate, Asynchronous transfer mode},
  language      = {English},
  publisher     = {McGraw-Hill Inc, New York, NY, United States},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-19244381037&partnerID=40&md5=01fdc9a7e7edef192936fa73b127a371},
}

@Conference{Subramanian1994,
  author        = {Subramanian, Rajesh and Bakeer, Reda M.},
  title         = {Program for the analysis of pile load tests},
  year          = {1994},
  editor        = {Khozeimeh Khalil},
  number        = {1},
  pages         = {644-651},
  publisher     = {Publ by ASCE, New York, NY, United States},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {The load capacity of piles are routinely determined from full scale pile load tests under actual field conditions. Several empirical methods were proposed for the analysis of field load/settlement data based on personal inspection and graphical construction. Each of these methods is suited for a particular condition of pile, soil, and load-testing combination. Personal interpretation of the data and human judgement required by these methods may result in inaccurate or inconsistent predictions. The computer program TUTSTPIL was developed to automate the analysis of pile load tests data. It offers a standard and time saving tool that increases accuracy and reduces calculation errors. TUTSTPIL determines the pile capacity using a group of well established methods and provides statistical assessment of the analysis. The C programming language was used to develop TUTSTPIL on a MS-DOS type personal computer. Field data can be read directly from a load/settlement file, entered interactively from the keyboard via menu-driven screens, or digitized from a paper copy of the load/settlement curve. The first two options are suitable for a design office environment, whereas the third option is ideal for performing parametric studies and when numerical data is not available.},
  coden         = {CCENE},
  document_type = {Conference Paper},
  isbn          = {0784400261},
  journal       = {Computing in Civil Engineering (New York)},
  keywords      = {Bearing capacity; C (programming language); Computer aided analysis; Computer software; Data reduction; Graphic methods; Inspection; Load limits; Load testing; Soil structure interactions; Statistical methods; Structural loads, Pile load testing; Software package TUTSTPIL, Pile foundations},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028592792&partnerID=40&md5=7bb68e20e5aaa0c39cdd0fe9a678155a},
}

@Conference{Grossman1994b,
  author        = {Grossman, D. and Staton, C.J. and Bailey, B. and McCabe, M.C. and Latts, A. and Frieder, O. and Bock, C. and Roberts, D.},
  title         = {Prototype-driven approach to application-level performance testing: A case study of a large finance application},
  year          = {1994},
  pages         = {125-135},
  publisher     = {IEEE, Los Alamitos, CA, United States},
  note          = {cited By 1},
  __markedentry = {[Jonnathan:]},
  abstract      = {We present an approach to application-level performance testing. This uses a popular test tool, TPNS (Teleprocessing Network Simulator) to simulate performance of an application. Our approach hinges upon a simple prototype to verify that the system performance falls within acceptable bounds. Once the initial prototype is developed, detailed tuning may take place. We present a case study in which we tested the performance of a large finance application. This approach led to critical performance tuning improvement. Due to this improvement, the average user response time in our simulations was reduced from 30 seconds to under 1.5 seconds. This simulation has been verified by actual system usage during the first two months of live operation in which the average response time has indeed been under 1.5 seconds.},
  coden         = {85PAA},
  document_type = {Conference Paper},
  journal       = {Proceedings of the Symposium on Assessment of Quality Software Development Tools},
  keywords      = {Computer aided analysis; Computer networks; Computer operating systems; Computer simulation; Computer software selection and evaluation; Data processing; Product design; Program diagnostics; Response time (computer systems); Standards; Systems analysis, Application level testing; Database management systems (DMBS); Initial production usage performance problems; Performance tuning; System level testing; Teleprocessing network simulator (TPNS), Database systems},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028603761&partnerID=40&md5=1ccc1c459c7630855c33c8ec9dd01fa1},
}

@Conference{Brey1992a,
  author        = {Brey, Jack},
  title         = {Stress testing a non-existent application tools, methods, and results},
  year          = {1992},
  pages         = {520-529},
  publisher     = {Publ by CMG, Chicago, IL, United States},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {How do you test an application that doesn't exist yet? How do you make an architectural decision when there are no similar applications in production anywhere? This case study covers the decision making process, the tools selected, the test plan, and the test results of an analysis used to choose between the use of a CASE tool and ACMS for a proposed application. The study involved use of both an analytic model and a benchmarking tool to establish the saturation point of a VAX 9000 under each alternative. The paper will discuss creation of the models, the results of the modeling activities, and the criteria that went into the actual decision.},
  coden         = {CMPRE},
  document_type = {Conference Paper},
  journal       = {CMG Proceedings},
  keywords      = {Decision theory; Testing, Software development, Computer software},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026997870&partnerID=40&md5=79923867b03124f2b2bbadc3b486efd6},
}

@Conference{Battersby1992a,
  author        = {Battersby, Glynis and De Rossett, Margaret},
  title         = {DB2 Version 2 Release 3 multi-user performance test results},
  year          = {1992},
  pages         = {542-549},
  publisher     = {Publ by CMG, Chicago, IL, United States},
  note          = {cited By 0},
  __markedentry = {[Jonnathan:]},
  abstract      = {A series of tests designed to determine the performance and resource consumption characteristics of DB2 Version 2 Release 3 as compared with DB2 Version 2 Release 2 was executed in a multi-user environment. The purpose of this paper is to describe the results of experiences using DB2 2.3 and DB2 2.2. The workload presented in the paper is synthetic and does not represent any known workload deployed at any site. No endorsement of IBM of its products is expressed, and none should be implied. No recommendation is made regarding the purchase DB2 or any other IBM products. A network of 300 terminals was simulated using IBM's Teleprocessing Network Simulator (TPNS), and test scripts were executed at various transaction rates to measure the system performance under both peak and non-peak conditions. The basic workload was then restructured to take advantage of DB2 2.3's new package feature and additional volume testing was conducted. The reader of this paper is assumed to have a basic knowledge of DB2 principles and MVS performance terminology and concepts. The reader may wish to read the provided glossary before proceeding, or may reference it as needed.},
  coden         = {CMPRE},
  document_type = {Conference Paper},
  journal       = {CMG Proceedings},
  keywords      = {Computer software selection and evaluation; Performance, DB2, Database systems},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026976162&partnerID=40&md5=1e61bfa01a07a22ed9062311e5cf452f},
}

@Conference{Fujimasa1990,
  author        = {Fujimasa, Iwao and Chinzei, Tsuneo},
  title         = {Dynamic thermographic analysis system at stress testing},
  year          = {1990},
  number        = {pt 4},
  pages         = {1582-1583},
  publisher     = {Publ by IEEE, Piscataway, NJ, United States},
  note          = {cited By 1},
  __markedentry = {[Jonnathan:]},
  abstract      = {A newly developed computed dynamic thermography system (dynamic CTS) is described which offers sequential image processing tools and mathematical methods for solving a heat convection model of the living body. Many graphic analysis tools are covered which can be applied to sequential thermograms taken under thermal, chemical and mechanical stress. An attempt is made to convert the system for commercially available medical thermographs, such as Thermovision 870 (AGEMA) and Infraeye 180 (Fujitsu).},
  coden         = {CEMBA},
  document_type = {Conference Paper},
  isbn          = {0879425598},
  issn          = {05891019},
  journal       = {Proceedings of the Annual Conference on Engineering in Medicine and Biology},
  keywords      = {Heat Transfer - Convection; Image Processing - Image Analysis; Infrared Imaging, Computed Dynamic Thermography System; Living Body Heat Convection Model; Medical Thermographs; Sequential Image Processing, Thermography},
  language      = {English},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025565730&partnerID=40&md5=5ab67ee11a46a3e276792d1a9b3a4ac5},
}

@Article{Roehrig1990,
  author          = {Roehrig, H. and Blume, H. and Ji, T.-L. and Browne, M.},
  title           = {Performance tests and quality control of cathode ray tube displays},
  journal         = {Journal of Digital Imaging},
  year            = {1990},
  volume          = {3},
  number          = {3},
  pages           = {134-145},
  issn            = {08971889},
  note            = {cited By 35},
  __markedentry   = {[Jonnathan:]},
  abstract        = {Spatial resolution, noise, characteristic curve, and absolute luminance are the essential parameters that describe physical image quality of a display. This paper presents simple procedures for assessing the performance of a cathode ray tube (CRT) in terms of these parameters as well as essy set up techniques. The procedures can be used in the environment where the CRT is used. The procedures are based on a digital representation of the Society of Motion Pictures and Television Engineers pattern plus a few simple other digital patterns. Additionally, measurement techniques are discussed for estimating brightness uniformity, veiling glare, and distortion. Apart from the absolute luminance, all performance features can be assessed with an uncalibrated photodetector and the eyes of a human observer. The measurement techniques especially enable the user to perform comparisons of different display systems. © 1990 Society for Imaging Informatics in Medicine.},
  author_keywords = {CRT performance; CRT set up; CRT testing; SMPTE patterns},
  coden           = {JDIME},
  document_type   = {Article},
  doi             = {10.1007/BF03167599},
  keywords        = {article; human; image quality; information processing; quality control; standard, Data Display; Human; Quality Control; Radiographic Image Enhancement; Support, Non-U.S. Gov't; Support, U.S. Gov't, P.H.S.},
  language        = {English},
  source          = {Scopus},
  url             = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025475109&doi=10.1007%2fBF03167599&partnerID=40&md5=aea9068fcf4e6b2f4bc0be36555a3e0d},
}

@Article{Mrozek2015a,
  author        = {Mrozek, Dariusz and Gosk, Paweł and Małysiak-Mrozek, Bożena},
  title         = {Scaling {Ab} {Initio} {Predictions} of 3D {Protein} {Structures} in {Microsoft} {Azure} {Cloud}},
  journal       = {Journal of Grid Computing},
  year          = {2015},
  volume        = {13},
  number        = {4},
  pages         = {561--585},
  month         = dec,
  issn          = {1570-7873, 1572-9184},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10723-015-9353-8},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10723-015-9353-8},
  urldate       = {2018-06-15},
}

@InCollection{Neat2004,
  author        = {Neat, Adam},
  title         = {{WebSphere} {Platform} {Performance}, {Tuning}, and {Optimization}},
  booktitle     = {Maximizing {Performance} and {Scalability} with {IBM} {WebSphere}},
  publisher     = {Apress},
  year          = {2004},
  pages         = {231--290},
  address       = {Berkeley, CA},
  isbn          = {978-1-59059-130-7 978-1-4302-0801-3},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Neat, Adam},
  doi           = {10.1007/978-1-4302-0801-3_6},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-0801-3_6},
  urldate       = {2018-06-15},
}

@Article{Yu2009,
  author        = {Yu, Jiang and Tappenden, Andrew and Miller, James and Smith, Michael},
  title         = {A {Scalable} {Testing} {Framework} for {Location}-{Based} {Services}},
  journal       = {Journal of Computer Science and Technology},
  year          = {2009},
  volume        = {24},
  number        = {2},
  pages         = {386--404},
  month         = mar,
  issn          = {1000-9000, 1860-4749},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11390-009-9232-5},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s11390-009-9232-5},
  urldate       = {2018-06-15},
}

@Article{Grundy2005,
  author        = {Grundy, John and Cai, Yuhong and Liu, Anna},
  title         = {{SoftArch}/{MTE}: {Generating} {Distributed} {System} {Test}-{Beds} from {High}-{Level} {Software} {Architecture} {Descriptions}},
  journal       = {Automated Software Engineering},
  year          = {2005},
  volume        = {12},
  number        = {1},
  pages         = {5--39},
  month         = jan,
  issn          = {0928-8910},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1023/B:AUSE.0000049207.62380.74},
  language      = {en},
  shorttitle    = {{SoftArch}/{MTE}},
  url           = {http://link.springer.com/10.1023/B:AUSE.0000049207.62380.74},
  urldate       = {2018-06-15},
}

@InCollection{McKay2004,
  author        = {McKay, Andy},
  title         = {Administering and {Scaling} {Plone}},
  booktitle     = {The {Definitive} {Guide} to {Plone}},
  publisher     = {Apress},
  year          = {2004},
  pages         = {427--463},
  address       = {Berkeley, CA},
  isbn          = {978-1-59059-329-5 978-1-4302-0734-4},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {McKay, Andy},
  doi           = {10.1007/978-1-4302-0734-4_14},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-0734-4_14},
  urldate       = {2018-06-15},
}

@Article{Li2012b,
  author        = {Li, Hongjian and Sun, Shixin and Tang, Hong and Dou, Yusheng and Lo, Glenn V.},
  title         = {Two-level parallelization of {Ehrenfest} force calculations in ab initio molecular dynamics simulation},
  journal       = {Cluster Computing},
  year          = {2012},
  volume        = {15},
  number        = {3},
  pages         = {255--263},
  month         = sep,
  issn          = {1386-7857, 1573-7543},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10586-012-0217-8},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10586-012-0217-8},
  urldate       = {2018-06-15},
}

@InCollection{Schieferdecker1997,
  author        = {Schieferdecker, I. and Stepien, B. and Rennoch, A.},
  title         = {{PerfTTCN}, a {TTCN} language extension for performance testing},
  booktitle     = {Testing of {Communicating} {Systems}},
  publisher     = {Springer US},
  year          = {1997},
  editor        = {Kim, Myungchul and Kang, Sungwon and Hong, Keesoo},
  pages         = {21--36},
  address       = {Boston, MA},
  isbn          = {978-1-4757-6701-8 978-0-387-35198-8},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-0-387-35198-8_2},
  url           = {http://link.springer.com/10.1007/978-0-387-35198-8_2},
  urldate       = {2018-06-15},
}

@InCollection{Haug2001,
  author        = {Haug, Michael and Olsen, Eric W. and Consolini, Luisa},
  title         = {Summaries of {PIE} {Reports}},
  booktitle     = {Software {Quality} {Approaches}: {Testing}, {Verification}, and {Validation}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2001},
  editor        = {Haug, Michael and Olsen, Eric W. and Consolini, Luisa},
  pages         = {215--293},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-41784-2 978-3-642-56612-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-642-56612-7_10},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-3-642-56612-7_10},
  urldate       = {2018-06-15},
}

@InCollection{Laghave2009,
  author        = {Laghave, Nikhil and Sosonkina, Masha and Maris, Pieter and Vary, James P.},
  title         = {Benefits of {Parallel} {I}/{O} in {Ab} {Initio} {Nuclear} {Physics} {Calculations}},
  booktitle     = {Computational {Science} – {ICCS} 2009},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2009},
  editor        = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Allen, Gabrielle and Nabrzyski, Jarosław and Seidel, Edward and van Albada, Geert Dick and Dongarra, Jack and Sloot, Peter M. A.},
  volume        = {5544},
  pages         = {84--93},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-642-01969-2 978-3-642-01970-8},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-642-01970-8_9},
  url           = {http://link.springer.com/10.1007/978-3-642-01970-8_9},
  urldate       = {2018-06-15},
}

@Article{Fu2013,
  author        = {Fu, Xiang and Powell, Michael C. and Bantegui, Michael and Li, Chung-Chih},
  title         = {Simple linear string constraints},
  journal       = {Formal Aspects of Computing},
  year          = {2013},
  volume        = {25},
  number        = {6},
  pages         = {847--891},
  month         = nov,
  issn          = {0934-5043, 1433-299X},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00165-011-0214-3},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s00165-011-0214-3},
  urldate       = {2018-06-15},
}

@Article{Alegroth2015,
  author        = {Alégroth, Emil and Feldt, Robert and Ryrholm, Lisa},
  title         = {Visual {GUI} testing in practice: challenges, problemsand limitations},
  journal       = {Empirical Software Engineering},
  year          = {2015},
  volume        = {20},
  number        = {3},
  pages         = {694--744},
  month         = jun,
  issn          = {1382-3256, 1573-7616},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10664-013-9293-5},
  language      = {en},
  shorttitle    = {Visual {GUI} testing in practice},
  url           = {http://link.springer.com/10.1007/s10664-013-9293-5},
  urldate       = {2018-06-15},
}

@Article{Karna2018,
  author        = {Karna, Anil Kumar and Chen, Yuting and Yu, Haibo and Zhong, Hao and Zhao, Jianjun},
  title         = {The role of model checking in software engineering},
  journal       = {Frontiers of Computer Science},
  year          = {2018},
  month         = apr,
  issn          = {2095-2228, 2095-2236},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11704-016-6192-0},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s11704-016-6192-0},
  urldate       = {2018-06-15},
}

@InCollection{Kontogiannis2002,
  author        = {Kontogiannis, Kostas and Mylopoulos, John and Wu, Suchun},
  title         = {Towards {Environment} {Retargetable} {Parser} {Generators}},
  booktitle     = {Advances in {Software} {Engineering}},
  publisher     = {Springer New York},
  year          = {2002},
  editor        = {Erdogmus, Hakan and Tanir, Oryal},
  pages         = {407--437},
  address       = {New York, NY},
  isbn          = {978-1-4419-2878-8 978-0-387-21599-0},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-0-387-21599-0_18},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-0-387-21599-0_18},
  urldate       = {2018-06-15},
}

@InCollection{Pagnoni1990,
  author        = {Pagnoni, Anastasia},
  title         = {Clock-{Independent} {Planning}: {Petri} {Nets}},
  booktitle     = {Project {Engineering}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1990},
  pages         = {119--161},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-642-75632-0 978-3-642-75630-6},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Pagnoni, Anastasia},
  doi           = {10.1007/978-3-642-75630-6_6},
  language      = {en},
  shorttitle    = {Clock-{Independent} {Planning}},
  url           = {http://www.springerlink.com/index/10.1007/978-3-642-75630-6_6},
  urldate       = {2018-06-15},
}

@InCollection{Hessel2008,
  author        = {Hessel, Anders and Larsen, Kim G. and Mikucionis, Marius and Nielsen, Brian and Pettersson, Paul and Skou, Arne},
  title         = {Testing {Real}-{Time} {Systems} {Using} {UPPAAL}},
  booktitle     = {Formal {Methods} and {Testing}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Hierons, Robert M. and Bowen, Jonathan P. and Harman, Mark},
  volume        = {4949},
  pages         = {77--117},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-78916-1 978-3-540-78917-8},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-78917-8_3},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-3-540-78917-8_3},
  urldate       = {2018-06-15},
}

@InCollection{Casale2009,
  author        = {Casale, Giuliano and Kalbasi, Amir and Krishnamurthy, Diwakar and Rolia, Jerry},
  title         = {Automatic {Stress} {Testing} of {Multi}-tier {Systems} by {Dynamic} {Bottleneck} {Switch} {Generation}},
  booktitle     = {Middleware 2009},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2009},
  editor        = {Bacon, Jean M. and Cooper, Brian F.},
  volume        = {5896},
  pages         = {393--413},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-642-10444-2 978-3-642-10445-9},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-642-10445-9_20},
  url           = {http://link.springer.com/10.1007/978-3-642-10445-9_20},
  urldate       = {2018-06-15},
}

@InCollection{Hansen2004,
  author        = {Hansen, John Erik and Thomsen, Carsten},
  title         = {Microsoft {Solutions} {Framework} 3.0},
  booktitle     = {Enterprise {Development} with {Visual} {Studio} .{NET}, {UML}, and {MSF}},
  publisher     = {Apress},
  year          = {2004},
  pages         = {833--900},
  address       = {Berkeley, CA},
  isbn          = {978-1-59059-042-3 978-1-4302-0696-5},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Hansen, John Erik and Thomsen, Carsten},
  doi           = {10.1007/978-1-4302-0696-5_20},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-0696-5_20},
  urldate       = {2018-06-15},
}

@Article{Fanfani2010,
  author        = {Fanfani, Alessandra and Afaq, Anzar and Sanches, Jose Afonso and Andreeva, Julia and Bagliesi, Giusepppe and Bauerdick, Lothar and Belforte, Stefano and Bittencourt Sampaio, Patricia and Bloom, Ken and Blumenfeld, Barry and Bonacorsi, Daniele and Brew, Chris and Calloni, Marco and Cesini, Daniele and Cinquilli, Mattia and Codispoti, Giuseppe and D’Hondt, Jorgen and Dong, Liang and Dongiovanni, Danilo and Donvito, Giacinto and Dykstra, David and Edelmann, Erik and Egeland, Ricky and Elmer, Peter and Eulisse, Giulio and Evans, Dave and Fanzago, Federica and Farina, Fabio and Feichtinger, Derek and Fisk, Ian and Flix, Josep and Grandi, Claudio and Guo, Yuyi and Happonen, Kalle and Hernàndez, José M. and Huang, Chih-Hao and Kang, Kejing and Karavakis, Edward and Kasemann, Matthias and Kavka, Carlos and Khan, Akram and Kim, Bockjoo and Klem, Jukka and Koivumäki, Jesper and Kress, Thomas and Kreuzer, Peter and Kurca, Tibor and Kuznetsov, Valentin and Lacaprara, Stefano and Lassila-Perini, Kati and Letts, James and Lindén, Tomas and Lueking, Lee and Maes, Joris and Magini, Nicolò and Maier, Gerhild and Mcbride, Patricia and Metson, Simon and Miccio, Vincenzo and Padhi, Sanjay and Pi, Haifeng and Riahi, Hassen and Riley, Daniel and Rossman, Paul and Saiz, Pablo and Sartirana, Andrea and Sciabà, Andrea and Sekhri, Vijay and Spiga, Daniele and Tuura, Lassi and Vaandering, Eric and Vanelderen, Lukas and Van Mulders, Petra and Vedaee, Aresh and Villella, Ilaria and Wicklund, Eric and Wildish, Tony and Wissing, Christoph and Würthwein, Frank},
  title         = {Distributed {Analysis} in {CMS}},
  journal       = {Journal of Grid Computing},
  year          = {2010},
  volume        = {8},
  number        = {2},
  pages         = {159--179},
  month         = jun,
  issn          = {1570-7873, 1572-9184},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10723-010-9152-1},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10723-010-9152-1},
  urldate       = {2018-06-15},
}

@InCollection{Wienholt2004,
  author        = {Wienholt, Nick},
  title         = {Solving {Performance} {Problems}},
  booktitle     = {Maximizing .{NET} {Performance}},
  publisher     = {Apress},
  year          = {2004},
  pages         = {235--248},
  address       = {Berkeley, CA},
  isbn          = {978-1-59059-141-3 978-1-4302-0784-9},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Wienholt, Nick},
  doi           = {10.1007/978-1-4302-0784-9_15},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-0784-9_15},
  urldate       = {2018-06-15},
}

@InCollection{Taentzer2008,
  author        = {Taentzer, Gabriele and Biermann, Enrico and Bisztray, Dénes and Bohnet, Bernd and Boneva, Iovka and Boronat, Artur and Geiger, Leif and Geiß, Rubino and Horvath, Ákos and Kniemeyer, Ole and Mens, Tom and Ness, Benjamin and Plump, Detlef and Vajk, Tamás},
  title         = {Generation of {Sierpinski} {Triangles}: {A} {Case} {Study} for {Graph} {Transformation} {Tools}},
  booktitle     = {Applications of {Graph} {Transformations} with {Industrial} {Relevance}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Schürr, Andy and Nagl, Manfred and Zündorf, Albert},
  volume        = {5088},
  pages         = {514--539},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-89019-5 978-3-540-89020-1},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-89020-1_35},
  shorttitle    = {Generation of {Sierpinski} {Triangles}},
  url           = {http://link.springer.com/10.1007/978-3-540-89020-1_35},
  urldate       = {2018-06-15},
}

@InCollection{Kersten1993,
  author        = {Kersten, M. L. and Kwakkel, F.},
  title         = {Design and implementation of a {DBMS} performance assessment tool},
  booktitle     = {Database and {Expert} {Systems} {Applications}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1993},
  editor        = {Goos, G. and Hartmanis, J. and Mařík, Vladimír and Lažanský, Jiří and Wagner, Roland R.},
  volume        = {720},
  pages         = {265--276},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-57234-3 978-3-540-47982-6},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-57234-1_24},
  url           = {http://link.springer.com/10.1007/3-540-57234-1_24},
  urldate       = {2018-06-15},
}

@Article{Lin2010a,
  author        = {Lin, Ching and Varadharajan, Vijay},
  title         = {{MobileTrust}: a trust enhanced security architecture for mobile agent systems},
  journal       = {International Journal of Information Security},
  year          = {2010},
  volume        = {9},
  number        = {3},
  pages         = {153--178},
  month         = jun,
  issn          = {1615-5262, 1615-5270},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10207-009-0098-x},
  language      = {en},
  shorttitle    = {{MobileTrust}},
  url           = {http://link.springer.com/10.1007/s10207-009-0098-x},
  urldate       = {2018-06-15},
}

@InCollection{Gough2015,
  author        = {Gough, Corey and Steiner, Ian and Saunders, Winston},
  title         = {Monitoring},
  booktitle     = {Energy {Efficient} {Servers}},
  publisher     = {Apress},
  year          = {2015},
  pages         = {209--268},
  address       = {Berkeley, CA},
  isbn          = {978-1-4302-6637-2 978-1-4302-6638-9},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Gough, Corey and Steiner, Ian and Saunders, Winston},
  doi           = {10.1007/978-1-4302-6638-9_7},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-6638-9_7},
  urldate       = {2018-06-15},
}

@Article{Zhao2009,
  author        = {Zhao, QinPing},
  title         = {A survey on virtual reality},
  journal       = {Science in China Series F: Information Sciences},
  year          = {2009},
  volume        = {52},
  number        = {3},
  pages         = {348--400},
  month         = mar,
  issn          = {1009-2757, 1862-2836},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11432-009-0066-0},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s11432-009-0066-0},
  urldate       = {2018-06-15},
}

@InCollection{Rendek2004,
  author        = {Rendek, Jan and Masini, Gérald and Dosch, Philippe and Tombre, Karl},
  title         = {The {Search} for {Genericity} in {Graphics} {Recognition} {Applications}: {Design} {Issues} of the {Qgar} {Software} {System}},
  booktitle     = {Document {Analysis} {Systems} {VI}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2004},
  editor        = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Marinai, Simone and Dengel, Andreas R.},
  volume        = {3163},
  pages         = {366--377},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-23060-1 978-3-540-28640-0},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-28640-0_35},
  shorttitle    = {The {Search} for {Genericity} in {Graphics} {Recognition} {Applications}},
  url           = {http://link.springer.com/10.1007/978-3-540-28640-0_35},
  urldate       = {2018-06-15},
}

@Article{Drummond2009,
  author        = {Drummond, L. Anthony and Galiano, Vicente and Migallón, Violeta and Penadés, Jose},
  title         = {{PyACTS}: {A} {Python} {Based} {Interface} to {ACTS} {Tools} and {Parallel} {Scientific} {Applications}},
  journal       = {International Journal of Parallel Programming},
  year          = {2009},
  volume        = {37},
  number        = {1},
  pages         = {58--77},
  month         = feb,
  issn          = {0885-7458, 1573-7640},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10766-008-0083-4},
  language      = {en},
  shorttitle    = {{PyACTS}},
  url           = {http://link.springer.com/10.1007/s10766-008-0083-4},
  urldate       = {2018-06-15},
}

@InCollection{Zimmerman2004,
  author        = {Zimmerman, W. Frederick},
  title         = {Installing {OneNote}},
  booktitle     = {Complete {Guide} to {OneNote}},
  publisher     = {Apress},
  year          = {2004},
  pages         = {35--73},
  address       = {Berkeley, CA},
  isbn          = {978-1-59059-216-8 978-1-4302-0823-5},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Zimmerman, W. Frederick},
  doi           = {10.1007/978-1-4302-0823-5_2},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-0823-5_2},
  urldate       = {2018-06-15},
}

@Article{Ward2015,
  author        = {Ward, Jonathan Stuart and Barker, Adam},
  title         = {Cloud cover: monitoring large-scale clouds with {Varanus}},
  journal       = {Journal of Cloud Computing},
  year          = {2015},
  volume        = {4},
  number        = {1},
  month         = dec,
  issn          = {2192-113X},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1186/s13677-015-0041-9},
  language      = {en},
  shorttitle    = {Cloud cover},
  url           = {http://www.journalofcloudcomputing.com/content/4/1/16},
  urldate       = {2018-06-15},
}

@Article{Garousi2009,
  author        = {Garousi, Vahid and Briand, Lionel C. and Labiche, Yvan},
  title         = {A {UML}-based quantitative framework for early prediction of resource usage and load in distributed real-time systems},
  journal       = {Software \& Systems Modeling},
  year          = {2009},
  volume        = {8},
  number        = {2},
  pages         = {275--302},
  month         = apr,
  issn          = {1619-1366, 1619-1374},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10270-008-0099-7},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10270-008-0099-7},
  urldate       = {2018-06-15},
}

@InCollection{Blunden2003,
  author        = {Blunden, Bill},
  title         = {Preventative {Medicine}},
  booktitle     = {Software {Exorcism}: {A} {Handbook} for {Debugging} and {Optimizing} {Legacy} {Code}},
  publisher     = {Apress},
  year          = {2003},
  pages         = {1--69},
  address       = {Berkeley, CA},
  isbn          = {978-1-4302-5423-2 978-1-4302-0788-7},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Blunden, Bill},
  doi           = {10.1007/978-1-4302-0788-7_1},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-0788-7_1},
  urldate       = {2018-06-15},
}

@Article{Ward2014,
  author        = {Ward, Jonathan Stuart and Barker, Adam},
  title         = {Observing the clouds: a survey and taxonomy of cloud monitoring},
  journal       = {Journal of Cloud Computing},
  year          = {2014},
  volume        = {3},
  number        = {1},
  month         = dec,
  issn          = {2192-113X},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1186/s13677-014-0024-2},
  language      = {en},
  shorttitle    = {Observing the clouds},
  url           = {http://www.journalofcloudcomputing.com/content/3/1/24},
  urldate       = {2018-06-15},
}

@Article{MarquesNeto2010,
  author        = {Marques Neto, Manoel C. and Santos, Celso A. S.},
  title         = {{StoryToCode}: a new model for specification of convergent interactive digital {TV} applications},
  journal       = {Journal of the Brazilian Computer Society},
  year          = {2010},
  volume        = {16},
  number        = {4},
  pages         = {215--227},
  month         = nov,
  issn          = {0104-6500, 1678-4804},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s13173-010-0021-3},
  language      = {en},
  shorttitle    = {{StoryToCode}},
  url           = {http://www.journal-bcs.com/content/16/4/},
  urldate       = {2018-06-15},
}

@InCollection{O'Regan2002,
  author        = {O'Regan, Gerard},
  title         = {Introduction to {Software} {Quality}},
  booktitle     = {A {Practical} {Approach} to {Software} {Quality}},
  publisher     = {Springer New York},
  year          = {2002},
  pages         = {1--48},
  address       = {New York, NY},
  isbn          = {978-1-4419-2951-8 978-0-387-22454-1},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {O'Regan, Gerard},
  doi           = {10.1007/978-0-387-22454-1_1},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-0-387-22454-1_1},
  urldate       = {2018-06-15},
}

@InCollection{Wienholt2004a,
  author        = {Wienholt, Nick},
  title         = {The {Common} {Language} {Runtime}},
  booktitle     = {Maximizing .{NET} {Performance}},
  publisher     = {Apress},
  year          = {2004},
  pages         = {213--234},
  address       = {Berkeley, CA},
  isbn          = {978-1-59059-141-3 978-1-4302-0784-9},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Wienholt, Nick},
  doi           = {10.1007/978-1-4302-0784-9_14},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-0784-9_14},
  urldate       = {2018-06-15},
}

@InCollection{Feijs1998,
  author        = {Feijs, L. M. G. and Meijs, F. A. C. and Moonen, J. R. and Wamel, J. J.},
  title         = {Conformance {Testing} of a {Multimedia} {System} {Using} {PHACT}},
  booktitle     = {Testing of {Communicating} {Systems}},
  publisher     = {Springer US},
  year          = {1998},
  editor        = {Petrenko, Alexandre and Yevtushenko, Nina},
  pages         = {193--210},
  address       = {Boston, MA},
  isbn          = {978-1-4757-6703-2 978-0-387-35381-4},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-0-387-35381-4_12},
  url           = {http://link.springer.com/10.1007/978-0-387-35381-4_12},
  urldate       = {2018-06-15},
}

@Article{Choi2017,
  author        = {Choi, Yunja and Byun, Taejoon},
  title         = {Constraint-based test generation for automotive operating systems},
  journal       = {Software \& Systems Modeling},
  year          = {2017},
  volume        = {16},
  number        = {1},
  pages         = {7--24},
  month         = feb,
  issn          = {1619-1366, 1619-1374},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10270-014-0449-6},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10270-014-0449-6},
  urldate       = {2018-06-15},
}

@Article{Kellerer2005,
  author        = {Kellerer, Bartholomäus and Reitenspiess, Manfred},
  title         = {Practical quality assurance for standards-based, high-availability middleware},
  journal       = {International Journal on Software Tools for Technology Transfer},
  year          = {2005},
  volume        = {7},
  number        = {4},
  pages         = {376--387},
  month         = aug,
  issn          = {1433-2779, 1433-2787},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10009-004-0162-9},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10009-004-0162-9},
  urldate       = {2018-06-15},
}

@Article{Shriraman2011,
  author        = {Shriraman, Arrvindh and Dwarkadas, Sandhya},
  title         = {Analyzing {Conflicts} in {Hardware}-{Supported} {Memory} {Transactions}},
  journal       = {International Journal of Parallel Programming},
  year          = {2011},
  volume        = {39},
  number        = {1},
  pages         = {33--61},
  month         = feb,
  issn          = {0885-7458, 1573-7640},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10766-010-0146-1},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10766-010-0146-1},
  urldate       = {2018-06-15},
}

@InCollection{Rackerby1993,
  author        = {Rackerby, Robert E. and Larson, Erik N. and Haagenson, Dean R. and Bezuk, Steve J. and Pendse, Rajendra D. and Wong, Chee C. and Puttlitz, Karl J.},
  title         = {Chip-{To}-{Substrate} ({First} {Level}) {Connection} {Technology} {Options}},
  booktitle     = {Multichip {Module} {Technologies} and {Alternatives}: {The} {Basics}},
  publisher     = {Springer US},
  year          = {1993},
  editor        = {Doane, Daryl Ann and Franzon, Paul D.},
  pages         = {349--486},
  address       = {Boston, MA},
  isbn          = {978-0-442-01236-6 978-1-4615-3100-5},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-1-4615-3100-5_9},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4615-3100-5_9},
  urldate       = {2018-06-15},
}

@Article{Park2012,
  author        = {Park, Ki-Hong and Ju, Won-Ki and Kim, Yoon-Ho},
  title         = {Implementation of {MAC}-based {RTL} module for {Inverse} {DCT} in {H}.264/{AVC}},
  journal       = {Multimedia Tools and Applications},
  year          = {2012},
  volume        = {61},
  number        = {1},
  pages         = {213--224},
  month         = nov,
  issn          = {1380-7501, 1573-7721},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11042-011-0747-8},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s11042-011-0747-8},
  urldate       = {2018-06-15},
}

@InCollection{Andersson2003,
  author        = {Andersson, Johan and Bache, Geoff and Sutton, Peter},
  title         = {{XP} with {Acceptance}-{Test} {Driven} {Development}: {A} {Rewrite} {Project} for a {Resource} {Optimization} {System}},
  booktitle     = {Extreme {Programming} and {Agile} {Processes} in {Software} {Engineering}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Marchesi, Michele and Succi, Giancarlo},
  volume        = {2675},
  pages         = {180--188},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-40215-2 978-3-540-44870-9},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-44870-5_23},
  shorttitle    = {{XP} with {Acceptance}-{Test} {Driven} {Development}},
  url           = {http://link.springer.com/10.1007/3-540-44870-5_23},
  urldate       = {2018-06-15},
}

@InCollection{Jeffery2004,
  author        = {Jeffery, Clinton and Auguston, Mikhail and Underwood, Scott},
  title         = {Towards {Fully} {Automatic} {Execution} {Monitoring}},
  booktitle     = {Radical {Innovations} of {Software} and {Systems} {Engineering} in the {Future}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2004},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Wirsing, Martin and Knapp, Alexander and Balsamo, Simonetta},
  volume        = {2941},
  pages         = {204--218},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-21179-2 978-3-540-24626-8},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-24626-8_14},
  url           = {http://link.springer.com/10.1007/978-3-540-24626-8_14},
  urldate       = {2018-06-15},
}

@InCollection{Richardson2003,
  author        = {Richardson, Chris},
  title         = {Windows {Forms}, {Web} {Forms}, and {No} {Forms}},
  booktitle     = {{COBOL} and {Visual} {Basic} on .{NET}},
  publisher     = {Apress},
  year          = {2003},
  pages         = {445--507},
  address       = {Berkeley, CA},
  isbn          = {978-1-59059-048-5 978-1-4302-0772-6},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Richardson, Chris},
  doi           = {10.1007/978-1-4302-0772-6_13},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-0772-6_13},
  urldate       = {2018-06-15},
}

@Article{Birkenheuer2011,
  author        = {Birkenheuer, Georg and Brinkmann, André and Högqvist, Mikael and Papaspyrou, Alexander and Schott, Bernhard and Sommerfeld, Dietmar and Ziegler, Wolfgang},
  title         = {Infrastructure {Federation} {Through} {Virtualized} {Delegation} of {Resources} and {Services}: {DGSI}: {Adding} {Interoperability} to {DCI} {Meta} {Schedulers}},
  journal       = {Journal of Grid Computing},
  year          = {2011},
  volume        = {9},
  number        = {3},
  pages         = {355--377},
  month         = sep,
  issn          = {1570-7873, 1572-9184},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10723-011-9192-1},
  language      = {en},
  shorttitle    = {Infrastructure {Federation} {Through} {Virtualized} {Delegation} of {Resources} and {Services}},
  url           = {http://link.springer.com/10.1007/s10723-011-9192-1},
  urldate       = {2018-06-15},
}

@InCollection{Rutherford2003,
  author        = {Rutherford, Matthew J. and Wolf, Alexander L.},
  title         = {A {Case} for {Test}-{Code} {Generation} in {Model}-{Driven} {Systems}},
  booktitle     = {Generative {Programming} and {Component} {Engineering}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Pfenning, Frank and Smaragdakis, Yannis},
  volume        = {2830},
  pages         = {377--396},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-20102-1 978-3-540-39815-8},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-39815-8_23},
  url           = {http://link.springer.com/10.1007/978-3-540-39815-8_23},
  urldate       = {2018-06-15},
}

@InCollection{Kuhn2008,
  author        = {Kuhn, Thomas and Gotzhein, Reinhard},
  title         = {Model-{Driven} {Platform}-{Specific} {Testing} through {Configurable} {Simulations}},
  booktitle     = {Model {Driven} {Architecture} – {Foundations} and {Applications}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Schieferdecker, Ina and Hartman, Alan},
  volume        = {5095},
  pages         = {278--293},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-69095-5 978-3-540-69100-6},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-69100-6_19},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-3-540-69100-6_19},
  urldate       = {2018-06-15},
}

@InCollection{Rackl2000,
  author        = {Rackl, Günther and Lindermeier, Markus and Rudorfer, Michael and Süss, Bernd},
  title         = {{MIMO} — {An} {Infrastructure} for {Monitoring} and {Managing} {Distributed} {Middleware} {Environments}},
  booktitle     = {Middleware 2000},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2000},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Sventek, Joseph and Coulson, Geoffrey},
  volume        = {1795},
  pages         = {71--87},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-67352-1 978-3-540-45559-2},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-45559-0_4},
  url           = {http://link.springer.com/10.1007/3-540-45559-0_4},
  urldate       = {2018-06-15},
}

@InCollection{Montana2008,
  author        = {Montana, David and Reynolds, Mark},
  title         = {Validation {Algorithms} for a {Secure} {Internet} {Routing} {PKI}},
  booktitle     = {Public {Key} {Infrastructure}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Mjølsnes, Stig F. and Mauw, Sjouke and Katsikas, Sokratis K.},
  volume        = {5057},
  pages         = {17--30},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-69484-7 978-3-540-69485-4},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-69485-4_2},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-3-540-69485-4_2},
  urldate       = {2018-06-15},
}

@InCollection{Boulet1989,
  author        = {Boulet, Marie-Michèle and Lavoie, L. and Labbé, P. and Slobodrian, S. and Barbeau, L.},
  title         = {Educational knowledge based system design using a diagnostic approach},
  booktitle     = {Computer {Assisted} {Learning}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1989},
  editor        = {Goos, G. and Hartmanis, J. and Barstow, D. and Brauer, W. and Brinch Hansen, P. and Gries, D. and Luckham, D. and Moler, C. and Pnueli, A. and Seegmüller, G. and Stoer, J. and Wirth, N. and Maurer, Hermann},
  volume        = {360},
  pages         = {1--13},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-51142-7 978-3-540-46163-0},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-51142-3_47},
  url           = {http://link.springer.com/10.1007/3-540-51142-3_47},
  urldate       = {2018-06-15},
}

@InCollection{Schaefer2008,
  author        = {Schaefer, Jan and Stynes, Jeanne and Kroeger, Reinhold},
  title         = {Model-{Based} {Performance} {Instrumentation} of {Distributed} {Applications}},
  booktitle     = {Distributed {Applications} and {Interoperable} {Systems}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Meier, René and Terzis, Sotirios},
  volume        = {5053},
  pages         = {210--223},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-68639-2 978-3-540-68642-2},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-68642-2_17},
  url           = {http://link.springer.com/10.1007/978-3-540-68642-2_17},
  urldate       = {2018-06-15},
}

@Article{Wu2010b,
  author        = {Wu, Tianyi and Chen, Yuguo and Han, Jiawei},
  title         = {Re-examination of interestingness measures in pattern mining: a unified framework},
  journal       = {Data Mining and Knowledge Discovery},
  year          = {2010},
  volume        = {21},
  number        = {3},
  pages         = {371--397},
  month         = nov,
  issn          = {1384-5810, 1573-756X},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10618-009-0161-2},
  language      = {en},
  shorttitle    = {Re-examination of interestingness measures in pattern mining},
  url           = {http://link.springer.com/10.1007/s10618-009-0161-2},
  urldate       = {2018-06-15},
}

@InCollection{Klaczewski2006,
  author        = {Kłaczewski, Paweł and Wytrębowicz, Jacek},
  title         = {j2eeprof — a tool for testing multitier applications},
  booktitle     = {Software {Engineering} {Techniques}: {Design} for {Quality}},
  publisher     = {Springer US},
  year          = {2006},
  editor        = {Sacha, Krzysztof},
  volume        = {227},
  pages         = {199--210},
  address       = {Boston, MA},
  isbn          = {978-0-387-39387-2},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-0-387-39388-9_20},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-0-387-39388-9_20},
  urldate       = {2018-06-15},
}

@InCollection{Lewin1992,
  author        = {Lewin, D. and Protheroe, D.},
  title         = {Digital circuit testing and design for testability},
  booktitle     = {Design of {Logic} {Systems}},
  publisher     = {Springer US},
  year          = {1992},
  pages         = {403--455},
  address       = {Boston, MA},
  isbn          = {978-0-412-42890-6 978-1-4899-6856-2},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Lewin, D. and Protheroe, D.},
  doi           = {10.1007/978-1-4899-6856-2_10},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4899-6856-2_10},
  urldate       = {2018-06-15},
}

@InCollection{Daniel2003,
  author        = {Daniel, Guido and Dienstuhl, Jan and Engell, Sebastian and Felske, Sven and Goser, Karl and Klinkenberg, Ralf and Morik, Katharina and Ritthoff, Oliver and Schmidt-Traub, Henner},
  title         = {Novel {Learning} {Tasks}, {Optimization}, and {Their} {Application}},
  booktitle     = {Advances in {Computational} {Intelligence}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Rozenberg, G. and Bäck, Th. and Eiben, A. E. and Kok, J. N. and Spaink, H. P. and Schwefel, Hans-Paul and Wegener, Ingo and Weinert, Klaus},
  pages         = {245--318},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-642-07758-6 978-3-662-05609-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-662-05609-7_8},
  url           = {http://link.springer.com/10.1007/978-3-662-05609-7_8},
  urldate       = {2018-06-15},
}

@InCollection{Assefa2012,
  author        = {Assefa, Beakal Gizachew and Ergenc, Belgin},
  title         = {{OrderBased} {Labeling} {Scheme} for {Dynamic} {XML} {Query} {Processing}},
  booktitle     = {Multidisciplinary {Research} and {Practice} for {Information} {Systems}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2012},
  editor        = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Quirchmayr, Gerald and Basl, Josef and You, Ilsun and Xu, Lida and Weippl, Edgar},
  volume        = {7465},
  pages         = {287--301},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-642-32497-0 978-3-642-32498-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-642-32498-7_22},
  url           = {http://link.springer.com/10.1007/978-3-642-32498-7_22},
  urldate       = {2018-06-15},
}

@Article{Hindle2015,
  author        = {Hindle, Abram},
  title         = {Green mining: a methodology of relating software change and configuration to power consumption},
  journal       = {Empirical Software Engineering},
  year          = {2015},
  volume        = {20},
  number        = {2},
  pages         = {374--409},
  month         = apr,
  issn          = {1382-3256, 1573-7616},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10664-013-9276-6},
  language      = {en},
  shorttitle    = {Green mining},
  url           = {http://link.springer.com/10.1007/s10664-013-9276-6},
  urldate       = {2018-06-15},
}

@InCollection{Schieferdecker2008,
  author        = {Schieferdecker, Ina and Grabowski, Jens and Vassiliou-Gioles, Theofanis and Din, George},
  title         = {The {Test} {Technology} {TTCN}-3},
  booktitle     = {Formal {Methods} and {Testing}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Hierons, Robert M. and Bowen, Jonathan P. and Harman, Mark},
  volume        = {4949},
  pages         = {292--319},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-78916-1 978-3-540-78917-8},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-78917-8_10},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-3-540-78917-8_10},
  urldate       = {2018-06-15},
}

@InCollection{2003,
  title         = {Strategies and {Methods} for {Test} {Case} {Design} {I}},
  booktitle     = {Practical {Software} {Testing}},
  publisher     = {Springer-Verlag},
  year          = {2003},
  pages         = {61--95},
  address       = {New York},
  isbn          = {978-0-387-95131-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/0-387-21658-8_4},
  language      = {en},
  url           = {http://link.springer.com/10.1007/0-387-21658-8_4},
  urldate       = {2018-06-15},
}

@Article{Tan2009,
  author        = {Tan, Jefferson and Abramson, David and Enticott, Colin},
  title         = {{REMUS}: {A} {Rerouting} and {Multiplexing} {System} for {Grid} {Connectivity} {Across} {Firewalls}},
  journal       = {Journal of Grid Computing},
  year          = {2009},
  volume        = {7},
  number        = {1},
  pages         = {25--50},
  month         = mar,
  issn          = {1570-7873, 1572-9184},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10723-008-9104-1},
  language      = {en},
  shorttitle    = {{REMUS}},
  url           = {http://link.springer.com/10.1007/s10723-008-9104-1},
  urldate       = {2018-06-15},
}

@InCollection{Rumpe2003,
  author        = {Rumpe, Bernhard},
  title         = {Model-{Based} {Testing} of {Object}-{Oriented} {Systems}},
  booktitle     = {Formal {Methods} for {Components} and {Objects}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and de Boer, Frank S. and Bonsangue, Marcello M. and Graf, Susanne and de Roever, Willem-Paul},
  volume        = {2852},
  pages         = {380--402},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-20303-2 978-3-540-39656-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-39656-7_16},
  url           = {http://link.springer.com/10.1007/978-3-540-39656-7_16},
  urldate       = {2018-06-15},
}

@InCollection{Joerelid2002,
  author        = {Jörelid, Lennart},
  title         = {Example 3: {Entity} {EJBs} for {Database} {Integration}},
  booktitle     = {J2EE {FrontEnd} {Technologies}: {A} {Programmer}’s {Guide} to {Servlets}, {JavaServer} {Pages}, and {Enterprise} {JavaBeans}},
  publisher     = {Apress},
  year          = {2002},
  pages         = {847--985},
  address       = {Berkeley, CA},
  isbn          = {978-1-893115-96-5 978-1-4302-1148-8},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Jörelid, Lennart},
  doi           = {10.1007/978-1-4302-1148-8_11},
  language      = {en},
  shorttitle    = {Example 3},
  url           = {http://link.springer.com/10.1007/978-1-4302-1148-8_11},
  urldate       = {2018-06-15},
}

@Article{Ilias2014,
  author        = {Iliaš, Miroslav and Dobrucký, Miroslav},
  title         = {Grid {Computing} with {Relativistic} {Quantum} {Chemistry} {Software}: {Case} {Study} of {Code} {Adaptation} and {Effective} {Deployment}},
  journal       = {Journal of Grid Computing},
  year          = {2014},
  volume        = {12},
  number        = {4},
  pages         = {681--690},
  month         = dec,
  issn          = {1570-7873, 1572-9184},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10723-014-9309-4},
  language      = {en},
  shorttitle    = {Grid {Computing} with {Relativistic} {Quantum} {Chemistry} {Software}},
  url           = {http://link.springer.com/10.1007/s10723-014-9309-4},
  urldate       = {2018-06-15},
}

@Article{Chen2015a,
  author        = {Chen, Luxi and Huang, Linpeng and Li, Chen and Zan, Tao},
  title         = {Integrating behavior analysis into architectural modeling},
  journal       = {Frontiers of Computer Science},
  year          = {2015},
  volume        = {9},
  number        = {1},
  pages         = {15--33},
  month         = feb,
  issn          = {2095-2228, 2095-2236},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11704-014-3505-z},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s11704-014-3505-z},
  urldate       = {2018-06-15},
}

@Article{Garousi2010a,
  author        = {Garousi, Vahid},
  title         = {Incorporating message weights in {UML}-based analysis of behavioral dependencies in distributed systems},
  journal       = {Software \& Systems Modeling},
  year          = {2010},
  volume        = {9},
  number        = {1},
  pages         = {113--137},
  month         = jan,
  issn          = {1619-1366, 1619-1374},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10270-008-0111-2},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10270-008-0111-2},
  urldate       = {2018-06-15},
}

@InCollection{Salomon2000,
  author        = {Salomon, David},
  title         = {Image {Compression}},
  booktitle     = {Data {Compression}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2000},
  pages         = {221--456},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-78086-1 978-3-642-86092-8},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Salomon, David},
  doi           = {10.1007/978-3-642-86092-8_5},
  language      = {en},
  url           = {http://www.springerlink.com/index/10.1007/978-3-642-86092-8_5},
  urldate       = {2018-06-15},
}

@InCollection{Schwarz2003,
  author        = {Schwarz, Peter},
  title         = {System {Simulation}},
  booktitle     = {The {Electronic} {Design} {Automation} {Handbook}},
  publisher     = {Springer US},
  year          = {2003},
  editor        = {Jansen, Dirk},
  pages         = {293--328},
  address       = {Boston, MA},
  isbn          = {978-1-4419-5369-8 978-0-387-73543-6},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-0-387-73543-6_13},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-0-387-73543-6_13},
  urldate       = {2018-06-15},
}

@InCollection{Groz2008,
  author        = {Groz, Roland and Li, Keqin and Petrenko, Alexandre and Shahbaz, Muzammil},
  title         = {Modular {System} {Verification} by {Inference}, {Testing} and {Reachability} {Analysis}},
  booktitle     = {Testing of {Software} and {Communicating} {Systems}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Suzuki, Kenji and Higashino, Teruo and Ulrich, Andreas and Hasegawa, Toru},
  volume        = {5047},
  pages         = {216--233},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-68514-2 978-3-540-68524-1},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-68524-1_16},
  url           = {http://link.springer.com/10.1007/978-3-540-68524-1_16},
  urldate       = {2018-06-15},
}

@Article{Ho2014,
  author        = {Ho, Zu-sheng and Uang, Chii-maw and Wang, Ping-chieh},
  title         = {Extracting {DC} bus current information for optimal phase correction and current ripple in sensorless brushless {DC} motor drive},
  journal       = {Journal of Zhejiang University SCIENCE C},
  year          = {2014},
  volume        = {15},
  number        = {4},
  pages         = {312--320},
  month         = apr,
  issn          = {1869-1951, 1869-196X},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1631/jzus.C1300247},
  language      = {en},
  url           = {http://link.springer.com/10.1631/jzus.C1300247},
  urldate       = {2018-06-15},
}

@InCollection{Probert1999,
  author        = {Probert, Robert L. and Williams, Alan W.},
  title         = {Fast {Functional} {Test} {Generation} {Using} an {SDL} {Model}},
  booktitle     = {Testing of {Communicating} {Systems}},
  publisher     = {Springer US},
  year          = {1999},
  editor        = {Csopaki, Gyula and Dibuz, Sarolta and Tarnay, Katalin},
  volume        = {21},
  pages         = {299--315},
  address       = {Boston, MA},
  isbn          = {978-1-4757-6699-8 978-0-387-35567-2},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-0-387-35567-2_19},
  url           = {http://link.springer.com/10.1007/978-0-387-35567-2_19},
  urldate       = {2018-06-15},
}

@Article{Bested2017,
  author        = {Bested, Morten and Weisberg, Andreas Harby and Durão, Frederico Araújo},
  title         = {A social interactive whiteboard system using finger-tracking for mobile devices},
  journal       = {Multimedia Tools and Applications},
  year          = {2017},
  volume        = {76},
  number        = {4},
  pages         = {5367--5397},
  month         = feb,
  issn          = {1380-7501, 1573-7721},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11042-016-3922-0},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s11042-016-3922-0},
  urldate       = {2018-06-15},
}

@InCollection{Almgren2001,
  author        = {Almgren, Magnus and Lindqvist, Ulf},
  title         = {Application-{Integrated} {Data} {Collection} for {Security} {Monitoring}},
  booktitle     = {Recent {Advances} in {Intrusion} {Detection}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2001},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Lee, Wenke and Mé, Ludovic and Wespi, Andreas},
  volume        = {2212},
  pages         = {22--36},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-42702-5 978-3-540-45474-8},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-45474-8_2},
  url           = {http://link.springer.com/10.1007/3-540-45474-8_2},
  urldate       = {2018-06-15},
}

@Article{Shi2015,
  author        = {Shi, Xiaoyu and Briere, Christopher A. and Djouadi, Seddik M. and Wang, Yefu and Feng, Yong},
  title         = {Power-aware performance management of virtualized enterprise servers via robust adaptive control},
  journal       = {Cluster Computing},
  year          = {2015},
  volume        = {18},
  number        = {1},
  pages         = {419--433},
  month         = mar,
  issn          = {1386-7857, 1573-7543},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10586-014-0407-7},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10586-014-0407-7},
  urldate       = {2018-06-15},
}

@InCollection{Xu2003,
  author        = {Xu, Jinmei and Xiong, Hui and Sung, Sam Yuan and Kumar, Vipin},
  title         = {A {New} {Clustering} {Algorithm} for {Transaction} {Data} via {Caucus}},
  booktitle     = {Advances in {Knowledge} {Discovery} and {Data} {Mining}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Goos, G. and Hartmanis, J. and van Leeuwen, J. and Whang, Kyu-Young and Jeon, Jongwoo and Shim, Kyuseok and Srivastava, Jaideep},
  volume        = {2637},
  pages         = {551--562},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-04760-5 978-3-540-36175-6},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-36175-8_55},
  url           = {http://link.springer.com/10.1007/3-540-36175-8_55},
  urldate       = {2018-06-15},
}

@Article{Wei2017,
  author        = {Wei, Xiong and Hu, Ming and Peng, Tao and Jiang, Minghua and Wang, Zhiying and Qin, Xiao},
  title         = {{PRODA}: improving parallel programs on {GPUs} through dependency analysis},
  journal       = {Cluster Computing},
  year          = {2017},
  month         = dec,
  issn          = {1386-7857, 1573-7543},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10586-017-1295-4},
  language      = {en},
  shorttitle    = {{PRODA}},
  url           = {http://link.springer.com/10.1007/s10586-017-1295-4},
  urldate       = {2018-06-15},
}

@Article{Gay2010,
  author        = {Gay, Gregory and Menzies, Tim and Jalali, Omid and Mundy, Gregory and Gilkerson, Beau and Feather, Martin and Kiper, James},
  title         = {Finding robust solutions in requirements models},
  journal       = {Automated Software Engineering},
  year          = {2010},
  volume        = {17},
  number        = {1},
  pages         = {87--116},
  month         = mar,
  issn          = {0928-8910, 1573-7535},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10515-009-0059-7},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10515-009-0059-7},
  urldate       = {2018-06-15},
}

@Article{Cazzola2014,
  author        = {Cazzola, Walter and Vacchi, Edoardo},
  title         = {On the incremental growth and shrinkage of {LR} goto-graphs},
  journal       = {Acta Informatica},
  year          = {2014},
  volume        = {51},
  number        = {7},
  pages         = {419--447},
  month         = oct,
  issn          = {0001-5903, 1432-0525},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00236-014-0201-2},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s00236-014-0201-2},
  urldate       = {2018-06-15},
}

@Article{Zhang2017a,
  author        = {Zhang, Xiaofei and Chen, Lei},
  title         = {Distance-{Aware} {Selective} {Online} {Query} {Processing} {Over} {Large} {Distributed} {Graphs}},
  journal       = {Data Science and Engineering},
  year          = {2017},
  volume        = {2},
  number        = {1},
  pages         = {2--21},
  month         = mar,
  issn          = {2364-1185, 2364-1541},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s41019-016-0023-z},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s41019-016-0023-z},
  urldate       = {2018-06-15},
}

@Article{Azevedo2007,
  author        = {Azevedo, Francisco},
  title         = {Maxx: {Test} {Pattern} {Optimisation} with {Local} {Search} {Over} an {Extended} {Logic}},
  journal       = {Constraints},
  year          = {2007},
  volume        = {12},
  number        = {4},
  pages         = {507--538},
  month         = oct,
  issn          = {1383-7133, 1572-9354},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10601-007-9025-9},
  language      = {en},
  shorttitle    = {Maxx},
  url           = {http://link.springer.com/10.1007/s10601-007-9025-9},
  urldate       = {2018-06-15},
}

@InCollection{Mitrovic2008,
  author        = {Mitrović, Nikola and Royo, Jose A. and Mena, Eduardo},
  title         = {Performance {Analysis} of an {Adaptive} {User} {Interface} {System} {Based} on {Mobile} {Agents}},
  booktitle     = {Engineering {Interactive} {Systems}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Gulliksen, Jan and Harning, Morton Borup and Palanque, Philippe and van der Veer, Gerrit C. and Wesson, Janet},
  volume        = {4940},
  pages         = {1--17},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-92697-9 978-3-540-92698-6},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-92698-6_1},
  url           = {http://link.springer.com/10.1007/978-3-540-92698-6_1},
  urldate       = {2018-06-15},
}

@Article{Huang2009,
  author        = {Huang, Yong-Qin and Li, Hong-Liang and Xie, Xiang-Hui and Qian, Lei and Hao, Zi-Yu and Guo, Feng and Zhang, Kun},
  title         = {{ArchSim}: {A} {System}-{Level} {Parallel} {Simulation} {Platform} for the {Architecture} {Design} of {High} {Performance} {Computer}},
  journal       = {Journal of Computer Science and Technology},
  year          = {2009},
  volume        = {24},
  number        = {5},
  pages         = {901--912},
  month         = sep,
  issn          = {1000-9000, 1860-4749},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11390-009-9281-9},
  language      = {en},
  shorttitle    = {{ArchSim}},
  url           = {http://link.springer.com/10.1007/s11390-009-9281-9},
  urldate       = {2018-06-15},
}

@InCollection{Caianiello2003,
  author        = {Caianiello, Pasquale and Costantini, Stefania and Omodeo, Eugenio G.},
  title         = {An {Environment} for {Specifying} {Properties} of {Dyadic} {Relations} and {Reasoning} about {Them} {I}: {Language} {Extension} {Mechanisms}},
  booktitle     = {Theory and {Applications} of {Relational} {Structures} as {Knowledge} {Instruments}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and de Swart, Harrie and Orłowska, Ewa and Schmidt, Gunther and Roubens, Marc},
  volume        = {2929},
  pages         = {87--106},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-20780-1 978-3-540-24615-2},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-24615-2_5},
  shorttitle    = {An {Environment} for {Specifying} {Properties} of {Dyadic} {Relations} and {Reasoning} about {Them} {I}},
  url           = {http://link.springer.com/10.1007/978-3-540-24615-2_5},
  urldate       = {2018-06-15},
}

@InCollection{Fisher2007,
  author        = {Fisher, Marc and Elbaum, Sebastian and Rothermel, Gregg},
  title         = {Dynamic {Characterization} of {Web} {Application} {Interfaces}},
  booktitle     = {Fundamental {Approaches} to {Software} {Engineering}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2007},
  editor        = {Dwyer, Matthew B. and Lopes, Antónia},
  volume        = {4422},
  pages         = {260--275},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-71288-6 978-3-540-71289-3},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-71289-3_21},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-3-540-71289-3_21},
  urldate       = {2018-06-15},
}

@Article{Gurrin2004,
  author        = {Gurrin, Cathal and Smeaton, Alan F.},
  title         = {Replicating {Web} {Structure} in {Small}-{Scale} {Test} {Collections}},
  journal       = {Information Retrieval},
  year          = {2004},
  volume        = {7},
  number        = {3/4},
  pages         = {239--263},
  month         = sep,
  issn          = {1386-4564},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1023/B:INRT.0000011206.23588.ab},
  language      = {en},
  url           = {http://link.springer.com/10.1023/B:INRT.0000011206.23588.ab},
  urldate       = {2018-06-15},
}

@Article{Wang2007,
  author        = {Wang, Frank Zhigang and Wu, Sining and Helian, Na and Xu, Zhiwei and Deng, Yuhui and Khare, Vineet and Liao, Chenhan and Thompson, Chris and Parker, Michael},
  title         = {Grid-based {Data} {Access} to {Nucleotide} {Sequence} {Database}},
  journal       = {New Generation Computing},
  year          = {2007},
  volume        = {25},
  number        = {4},
  pages         = {409--424},
  month         = aug,
  issn          = {0288-3635, 1882-7055},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00354-007-0026-4},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s00354-007-0026-4},
  urldate       = {2018-06-15},
}

@InCollection{Wienholt2004b,
  author        = {Wienholt, Nick},
  title         = {Introduction},
  booktitle     = {Maximizing .{NET} {Performance}},
  publisher     = {Apress},
  year          = {2004},
  pages         = {1--8},
  address       = {Berkeley, CA},
  isbn          = {978-1-59059-141-3 978-1-4302-0784-9},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Wienholt, Nick},
  doi           = {10.1007/978-1-4302-0784-9_1},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-0784-9_1},
  urldate       = {2018-06-15},
}

@InCollection{Bosch2000,
  author        = {Bosch, Jan and Szyperski, Clemens and Weck, Wolfgang},
  title         = {Component-{Oriented} {Programming}},
  booktitle     = {Object-{Oriented} {Technology}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2000},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Malenfant, Jacques and Moisan, Sabine and Moreira, Ana},
  volume        = {1964},
  pages         = {55--64},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-41513-8 978-3-540-44555-5},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-44555-2_5},
  url           = {http://link.springer.com/10.1007/3-540-44555-2_5},
  urldate       = {2018-06-15},
}

@InCollection{Qiu2000,
  author        = {Qiu, Shi Guang and Ling, Tok Wang},
  title         = {View {Selection} in {OLAP} {Environment}},
  booktitle     = {Database and {Expert} {Systems} {Applications}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2000},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Ibrahim, Mohamed and Küng, Josef and Revell, Norman},
  volume        = {1873},
  pages         = {447--456},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-67978-3 978-3-540-44469-5},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-44469-6_42},
  url           = {http://link.springer.com/10.1007/3-540-44469-6_42},
  urldate       = {2018-06-15},
}

@Article{Roedig2005,
  author        = {Roedig, Utz and Schmitt, Jens},
  title         = {Multimedia and firewalls: a performance perspective},
  journal       = {Multimedia Systems},
  year          = {2005},
  volume        = {11},
  number        = {1},
  pages         = {19--33},
  month         = nov,
  issn          = {0942-4962, 1432-1882},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00530-005-0187-2},
  language      = {en},
  shorttitle    = {Multimedia and firewalls},
  url           = {http://link.springer.com/10.1007/s00530-005-0187-2},
  urldate       = {2018-06-15},
}

@InCollection{Goos1999,
  title         = {The {Foundation} {Component}},
  booktitle     = {{PREMO}: {A} {Framework} for {Multimedia} {Middleware}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1999},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan},
  volume        = {1591},
  pages         = {59--124},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-66720-9 978-3-540-46821-9},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Duke, David J. and Herman, Ivan and Marshall, M. Scott},
  doi           = {10.1007/3-540-46821-8_5},
  url           = {http://link.springer.com/10.1007/3-540-46821-8_5},
  urldate       = {2018-06-15},
}

@Article{Silva2015,
  author        = {Silva, Francisco Airton and Maciel, Paulo and Matos, Rubens},
  title         = {{SmartRank}: a smart scheduling tool for mobile cloud computing},
  journal       = {The Journal of Supercomputing},
  year          = {2015},
  volume        = {71},
  number        = {8},
  pages         = {2985--3008},
  month         = aug,
  issn          = {0920-8542, 1573-0484},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11227-015-1423-y},
  language      = {en},
  shorttitle    = {{SmartRank}},
  url           = {http://link.springer.com/10.1007/s11227-015-1423-y},
  urldate       = {2018-06-15},
}

@InCollection{Kajan2002,
  author        = {Kajan, Ejub},
  title         = {D},
  booktitle     = {Information {Technology} {Encyclopedia} and {Acronyms}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2002},
  pages         = {127--168},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-41793-4 978-3-642-56262-4},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Kajan, Ejub},
  doi           = {10.1007/978-3-642-56262-4_5},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-3-642-56262-4_5},
  urldate       = {2018-06-15},
}

@InCollection{Grabowski1999,
  author        = {Grabowski, Jens and Hogrefe, Dieter},
  title         = {Towards the {Third} {Edition} of {TTCN}},
  booktitle     = {Testing of {Communicating} {Systems}},
  publisher     = {Springer US},
  year          = {1999},
  editor        = {Csopaki, Gyula and Dibuz, Sarolta and Tarnay, Katalin},
  volume        = {21},
  pages         = {19--29},
  address       = {Boston, MA},
  isbn          = {978-1-4757-6699-8 978-0-387-35567-2},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-0-387-35567-2_2},
  url           = {http://link.springer.com/10.1007/978-0-387-35567-2_2},
  urldate       = {2018-06-15},
}

@Article{Choi2014,
  author        = {Choi, SookKyong and Chung, KwangSik and Yu, Heonchang},
  title         = {Fault tolerance and {QoS} scheduling using {CAN} in mobile social cloud computing},
  journal       = {Cluster Computing},
  year          = {2014},
  volume        = {17},
  number        = {3},
  pages         = {911--926},
  month         = sep,
  issn          = {1386-7857, 1573-7543},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10586-013-0286-3},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10586-013-0286-3},
  urldate       = {2018-06-15},
}

@InCollection{Wang2006,
  author        = {Wang, Zhiliang and Wu, Jianping and Yin, Xia and Shi, Xingang and Tian, Beihang},
  title         = {Using {TimedTTCN}-3 in {Interoperability} {Testing} for {Real}-{Time} {Communication} {Systems}},
  booktitle     = {Testing of {Communicating} {Systems}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2006},
  editor        = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Uyar, M. Ümit and Duale, Ali Y. and Fecko, Mariusz A.},
  volume        = {3964},
  pages         = {324--340},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-34184-0 978-3-540-34185-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/11754008_21},
  url           = {http://link.springer.com/10.1007/11754008_21},
  urldate       = {2018-06-15},
}

@InCollection{Ruelling2003,
  author        = {Rülling, Wolfgang},
  title         = {Design for {Testability}},
  booktitle     = {The {Electronic} {Design} {Automation} {Handbook}},
  publisher     = {Springer US},
  year          = {2003},
  editor        = {Jansen, Dirk},
  pages         = {339--381},
  address       = {Boston, MA},
  isbn          = {978-1-4419-5369-8 978-0-387-73543-6},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-0-387-73543-6_15},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-0-387-73543-6_15},
  urldate       = {2018-06-15},
}

@InCollection{Fernandez2005,
  author        = {Fernandez, Jean-Claude and Mounier, Laurent and Pachon, Cyril},
  title         = {A {Model}-{Based} {Approach} for {Robustness} {Testing}},
  booktitle     = {Testing of {Communicating} {Systems}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2005},
  editor        = {Khendek, Ferhat and Dssouli, Rachida},
  volume        = {3502},
  pages         = {333--348},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-26054-7 978-3-540-32076-0},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/11430230_23},
  url           = {http://link.springer.com/10.1007/11430230_23},
  urldate       = {2018-06-15},
}

@Article{Liu2018,
  author        = {Liu, Yu-Tao and Du, Dong and Xia, Yu-Bin and Chen, Hai-Bo and Zang, Bin-Yu and Liang, Zhenkai},
  title         = {{SplitPass}: {A} {Mutually} {Distrusting} {Two}-{Party} {Password} {Manager}},
  journal       = {Journal of Computer Science and Technology},
  year          = {2018},
  volume        = {33},
  number        = {1},
  pages         = {98--115},
  month         = jan,
  issn          = {1000-9000, 1860-4749},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11390-018-1810-y},
  language      = {en},
  shorttitle    = {{SplitPass}},
  url           = {http://link.springer.com/10.1007/s11390-018-1810-y},
  urldate       = {2018-06-15},
}

@InCollection{Hermann2012,
  author        = {Hermann, Eckehard and Litschauer, Udo and Fuß, Jürgen},
  title         = {A {Formal} {Equivalence} {Classes} {Based} {Method} for {Security} {Policy} {Conformance} {Checking}},
  booktitle     = {Multidisciplinary {Research} and {Practice} for {Information} {Systems}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2012},
  editor        = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Quirchmayr, Gerald and Basl, Josef and You, Ilsun and Xu, Lida and Weippl, Edgar},
  volume        = {7465},
  pages         = {146--160},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-642-32497-0 978-3-642-32498-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-642-32498-7_12},
  url           = {http://link.springer.com/10.1007/978-3-642-32498-7_12},
  urldate       = {2018-06-15},
}

@Article{Meunier2005,
  author        = {Meunier, Philippe and Findler, Robert Bruce and Steckler, Paul and Wand, Mitchell},
  title         = {Selectors {Make} {Set}-{Based} {Analysis} {Too} {Hard}},
  journal       = {Higher-Order and Symbolic Computation},
  year          = {2005},
  volume        = {18},
  number        = {3-4},
  pages         = {245--269},
  month         = dec,
  issn          = {1388-3690, 1573-0557},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10990-005-4876-5},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10990-005-4876-5},
  urldate       = {2018-06-15},
}

@InCollection{2008,
  title         = {Introducing {MySQL}},
  booktitle     = {Beginning {PHP} and {MySQL}},
  publisher     = {Apress},
  year          = {2008},
  pages         = {621--633},
  address       = {Berkeley, CA},
  isbn          = {978-1-59059-862-7 978-1-4302-0299-8},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-1-4302-0299-8_25},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-0299-8_25},
  urldate       = {2018-06-15},
}

@InCollection{Paiva2003,
  author        = {Paiva, Ana C. R. and Faria, João C. P. and Vidal, Raul F. A. M.},
  title         = {Specification-{Based} {Testing} of {User} {Interfaces}},
  booktitle     = {Interactive {Systems}. {Design}, {Specification}, and {Verification}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Jorge, Joaquim A. and Jardim Nunes, Nuno and Falcão e Cunha, João},
  volume        = {2844},
  pages         = {139--153},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-20159-5 978-3-540-39929-2},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-39929-2_10},
  url           = {http://link.springer.com/10.1007/978-3-540-39929-2_10},
  urldate       = {2018-06-15},
}

@Article{Chowdhury2018,
  author        = {Chowdhury, Shaiful and Di Nardo, Silvia and Hindle, Abram and Jiang, Zhen Ming},
  title         = {An exploratory study on assessing the energy impact of logging on {Android} applications},
  journal       = {Empirical Software Engineering},
  year          = {2018},
  volume        = {23},
  number        = {3},
  pages         = {1422--1456},
  month         = jun,
  issn          = {1382-3256, 1573-7616},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10664-017-9545-x},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10664-017-9545-x},
  urldate       = {2018-06-15},
}

@InCollection{Li2004a,
  author        = {Li, Jun and Moore, Keith},
  title         = {Enabling {Rapid} {Feature} {Deployment} on {Embedded} {Platforms} with {JeCOM} {Bridge}},
  booktitle     = {On the {Move} to {Meaningful} {Internet} {Systems} 2004: {CoopIS}, {DOA}, and {ODBASE}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2004},
  editor        = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Meersman, Robert and Tari, Zahir},
  volume        = {3291},
  pages         = {1482--1501},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-23662-7 978-3-540-30469-2},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-30469-2_41},
  url           = {http://link.springer.com/10.1007/978-3-540-30469-2_41},
  urldate       = {2018-06-15},
}

@InCollection{Reis2007,
  author        = {Reis, Sacha and Metzger, Andreas and Pohl, Klaus},
  title         = {Integration {Testing} in {Software} {Product} {Line} {Engineering}: {A} {Model}-{Based} {Technique}},
  booktitle     = {Fundamental {Approaches} to {Software} {Engineering}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2007},
  editor        = {Dwyer, Matthew B. and Lopes, Antónia},
  volume        = {4422},
  pages         = {321--335},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-71288-6 978-3-540-71289-3},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-71289-3_25},
  language      = {en},
  shorttitle    = {Integration {Testing} in {Software} {Product} {Line} {Engineering}},
  url           = {http://link.springer.com/10.1007/978-3-540-71289-3_25},
  urldate       = {2018-06-15},
}

@InCollection{Fritzsche2008,
  author        = {Fritzsche, Mathias and Johannes, Jendrik},
  title         = {Putting {Performance} {Engineering} into {Model}-{Driven} {Engineering}: {Model}-{Driven} {Performance} {Engineering}},
  booktitle     = {Models in {Software} {Engineering}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Giese, Holger},
  volume        = {5002},
  pages         = {164--175},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-69069-6 978-3-540-69073-3},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-69073-3_18},
  language      = {en},
  shorttitle    = {Putting {Performance} {Engineering} into {Model}-{Driven} {Engineering}},
  url           = {http://link.springer.com/10.1007/978-3-540-69073-3_18},
  urldate       = {2018-06-15},
}

@InCollection{Tummala1997,
  author        = {Tummala, Rao and Li, Weiping and Tessier, Ted and Wassick, Tom},
  title         = {Thin-{Film} {Packaging}},
  booktitle     = {Microelectronics {Packaging} {Handbook}},
  publisher     = {Springer US},
  year          = {1997},
  editor        = {Tummala, Rao R. and Rymaszewski, Eugene J. and Klopfenstein, Alan G.},
  pages         = {624--813},
  address       = {Boston, MA},
  isbn          = {978-1-4613-7767-2 978-1-4615-6037-1},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-1-4615-6037-1_6},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4615-6037-1_6},
  urldate       = {2018-06-15},
}

@InCollection{Landrum2004,
  author        = {Landrum, Rodney and Voytek, Walter J.},
  title         = {Report {Management}},
  booktitle     = {Pro {SQL} {Server} {Reporting} {Services}},
  publisher     = {Apress},
  year          = {2004},
  pages         = {163--207},
  address       = {Berkeley, CA},
  isbn          = {978-1-59059-423-0 978-1-4302-0727-6},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Landrum, Rodney and Voytek, Walter J.},
  doi           = {10.1007/978-1-4302-0727-6_8},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-0727-6_8},
  urldate       = {2018-06-15},
}

@InCollection{Rackl1999,
  author        = {Rackl, Günther and de Stefani, Filippo and Héran, Francois and Pasquarelli, Antonello and Ludwig, Thomas},
  title         = {Airport simulation using {CORBA} and {DIS}},
  booktitle     = {High-{Performance} {Computing} and {Networking}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1999},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Sloot, Peter and Bubak, Marian and Hoekstra, Alfons and Hertzberger, Bob},
  volume        = {1593},
  pages         = {70--79},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-65821-4 978-3-540-48933-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/BFb0100567},
  url           = {http://link.springer.com/10.1007/BFb0100567},
  urldate       = {2018-06-15},
}

@Article{Karaboga2009,
  author        = {Karaboga, Dervis and Akay, Bahriye},
  title         = {A survey: algorithms simulating bee swarm intelligence},
  journal       = {Artificial Intelligence Review},
  year          = {2009},
  volume        = {31},
  number        = {1-4},
  pages         = {61--85},
  month         = jun,
  issn          = {0269-2821, 1573-7462},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10462-009-9127-4},
  language      = {en},
  shorttitle    = {A survey},
  url           = {http://link.springer.com/10.1007/s10462-009-9127-4},
  urldate       = {2018-06-15},
}

@Article{Jonsson2016,
  author        = {Jonsson, Leif and Borg, Markus and Broman, David and Sandahl, Kristian and Eldh, Sigrid and Runeson, Per},
  title         = {Automated bug assignment: {Ensemble}-based machine learning in large scale industrial contexts},
  journal       = {Empirical Software Engineering},
  year          = {2016},
  volume        = {21},
  number        = {4},
  pages         = {1533--1578},
  month         = aug,
  issn          = {1382-3256, 1573-7616},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10664-015-9401-9},
  language      = {en},
  shorttitle    = {Automated bug assignment},
  url           = {http://link.springer.com/10.1007/s10664-015-9401-9},
  urldate       = {2018-06-15},
}

@InCollection{Bohli2012,
  author        = {Bohli, Jens-Matthias and Li, Wenting and Seedorf, Jan},
  title         = {Assisting {Server} for {Secure} {Multi}-{Party} {Computation}},
  booktitle     = {Information {Security} {Theory} and {Practice}. {Security}, {Privacy} and {Trust} in {Computing} {Systems} and {Ambient} {Intelligent} {Ecosystems}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2012},
  editor        = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Askoxylakis, Ioannis and Pöhls, Henrich C. and Posegga, Joachim},
  volume        = {7322},
  pages         = {144--159},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-642-30954-0 978-3-642-30955-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-642-30955-7_13},
  url           = {http://link.springer.com/10.1007/978-3-642-30955-7_13},
  urldate       = {2018-06-15},
}

@Article{Liu2008,
  author        = {Liu, Hui and Zhang, Jun},
  title         = {High dynamic adaptive mobility network model and performance analysis},
  journal       = {Science in China Series F: Information Sciences},
  year          = {2008},
  volume        = {51},
  number        = {8},
  pages         = {1154--1166},
  month         = aug,
  issn          = {1009-2757, 1862-2836},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11432-008-0035-z},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s11432-008-0035-z},
  urldate       = {2018-06-15},
}

@Article{Agus2009,
  author        = {Agus, Marco and Bettio, Fabio and Giachetti, Andrea and Gobbetti, Enrico and Iglesias Guitián, José Antonio and Marton, Fabio and Nilsson, Jonas and Pintore, Giovanni},
  title         = {An interactive 3D medical visualization system based on a light field display},
  journal       = {The Visual Computer},
  year          = {2009},
  volume        = {25},
  number        = {9},
  pages         = {883--893},
  month         = sep,
  issn          = {0178-2789, 1432-2315},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00371-009-0311-y},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s00371-009-0311-y},
  urldate       = {2018-06-15},
}

@Article{Adoni2018,
  author        = {Adoni, Wilfried Yves Hamilton and Nahhal, Tarik and Aghezzaf, Brahim and Elbyed, Abdeltif},
  title         = {The {MapReduce}-based approach to improve the shortest path computation in large-scale road networks: the case of {A}* algorithm},
  journal       = {Journal of Big Data},
  year          = {2018},
  volume        = {5},
  number        = {1},
  month         = dec,
  issn          = {2196-1115},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1186/s40537-018-0125-8},
  language      = {en},
  shorttitle    = {The {MapReduce}-based approach to improve the shortest path computation in large-scale road networks},
  url           = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-018-0125-8},
  urldate       = {2018-06-15},
}

@Article{Koukis2010,
  author        = {Koukis, Evangelos and Nanos, Anastassios and Koziris, Nectarios},
  title         = {{GMBlock}: {Optimizing} data movement in a block-level storage sharing system over {Myrinet}},
  journal       = {Cluster Computing},
  year          = {2010},
  volume        = {13},
  number        = {4},
  pages         = {349--372},
  month         = dec,
  issn          = {1386-7857, 1573-7543},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10586-009-0106-y},
  language      = {en},
  shorttitle    = {{GMBlock}},
  url           = {http://link.springer.com/10.1007/s10586-009-0106-y},
  urldate       = {2018-06-15},
}

@InCollection{Yoo2001,
  author        = {Yoo, Jeong-Joon and Lee, Doheon and Suh, Young-Ho and Lee, Dong-Ik},
  title         = {Scalable {Workflow} {System} {Model} {Based} on {Mobile} {Agents}},
  booktitle     = {Intelligent {Agents}: {Specification}, {Modeling}, and {Applications}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2001},
  editor        = {Goos, G. and Hartmanis, J. and van Leeuwen, J. and Carbonell, Jaime G. and Siekmann, Jörg and Yuan, Soe -Tsyr and Yokoo, Makoto},
  volume        = {2132},
  pages         = {222--236},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-42434-5 978-3-540-44637-8},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-44637-0_16},
  url           = {http://link.springer.com/10.1007/3-540-44637-0_16},
  urldate       = {2018-06-15},
}

@InCollection{Douglas1997,
  author        = {Douglas, Sarah A. and Mithal, Anant Kartik},
  title         = {Challenges of the {Present} and {Future}},
  booktitle     = {The {Ergonomics} of {Computer} {Pointing} {Devices}},
  publisher     = {Springer London},
  year          = {1997},
  pages         = {189--217},
  address       = {London},
  isbn          = {978-3-540-19986-1 978-1-4471-0917-4},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Douglas, Sarah A. and Mithal, Anant Kartik},
  doi           = {10.1007/978-1-4471-0917-4_8},
  url           = {http://link.springer.com/10.1007/978-1-4471-0917-4_8},
  urldate       = {2018-06-15},
}

@Article{Chargueraud2012,
  author        = {Charguéraud, Arthur},
  title         = {The {Locally} {Nameless} {Representation}},
  journal       = {Journal of Automated Reasoning},
  year          = {2012},
  volume        = {49},
  number        = {3},
  pages         = {363--408},
  month         = oct,
  issn          = {0168-7433, 1573-0670},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10817-011-9225-2},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10817-011-9225-2},
  urldate       = {2018-06-15},
}

@InCollection{Cruzes2017,
  author        = {Cruzes, Daniela Soares and Felderer, Michael and Oyetoyan, Tosin Daniel and Gander, Matthias and Pekaric, Irdin},
  title         = {How is {Security} {Testing} {Done} in {Agile} {Teams}? {A} {Cross}-{Case} {Analysis} of {Four} {Software} {Teams}},
  booktitle     = {Agile {Processes} in {Software} {Engineering} and {Extreme} {Programming}},
  publisher     = {Springer International Publishing},
  year          = {2017},
  editor        = {Baumeister, Hubert and Lichter, Horst and Riebisch, Matthias},
  volume        = {283},
  pages         = {201--216},
  address       = {Cham},
  isbn          = {978-3-319-57632-9 978-3-319-57633-6},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-319-57633-6_13},
  shorttitle    = {How is {Security} {Testing} {Done} in {Agile} {Teams}?},
  url           = {http://link.springer.com/10.1007/978-3-319-57633-6_13},
  urldate       = {2018-06-15},
}

@InCollection{Minker1999,
  author        = {Minker, Wolfgang and Waibel, Alex and Mariani, Joseph},
  title         = {Portability of the {Stochastic} {Parser}},
  booktitle     = {Stochastically-{Based} {Semantic} {Analysis}},
  publisher     = {Springer US},
  year          = {1999},
  pages         = {121--167},
  address       = {Boston, MA},
  isbn          = {978-1-4613-7396-4 978-1-4615-5255-0},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Minker, Wolfgang and Waibel, Alex and Mariani, Joseph},
  doi           = {10.1007/978-1-4615-5255-0_6},
  url           = {http://link.springer.com/10.1007/978-1-4615-5255-0_6},
  urldate       = {2018-06-15},
}

@Article{Kominek1997,
  author        = {Kominek, John},
  title         = {Advances in fractal compression for multimedia applications},
  journal       = {Multimedia Systems},
  year          = {1997},
  volume        = {5},
  number        = {4},
  pages         = {255--270},
  month         = jun,
  issn          = {09424962},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s005300050059},
  url           = {http://link.springer.com/10.1007/s005300050059},
  urldate       = {2018-06-15},
}

@InCollection{Valtchev2008,
  author        = {Valtchev, Petko and Duquenne, Vincent},
  title         = {On the {Merge} of {Factor} {Canonical} {Bases}},
  booktitle     = {Formal {Concept} {Analysis}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Medina, Raoul and Obiedkov, Sergei},
  volume        = {4933},
  pages         = {182--198},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-78136-3 978-3-540-78137-0},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-78137-0_14},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-3-540-78137-0_14},
  urldate       = {2018-06-15},
}

@InCollection{Martin2001,
  author        = {Martin, Hugues and du Bousquet, Lydie},
  title         = {Automatic {Test} {Generation} for {Java} {Card} {Applets}},
  booktitle     = {Java on {Smart} {Cards}:{Programming} and {Security}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2001},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Attali, Isabelle and Jensen, Thomas},
  volume        = {2041},
  pages         = {121--136},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-42167-2 978-3-540-45165-5},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-45165-X_10},
  url           = {http://link.springer.com/10.1007/3-540-45165-X_10},
  urldate       = {2018-06-15},
}

@InCollection{Thomas2001,
  author        = {Thomas, John C.},
  title         = {Collaborative {Innovation} {Tools}},
  booktitle     = {New {Frontiers} in {Artificial} {Intelligence}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2001},
  editor        = {Goos, G. and Hartmanis, J. and van Leeuwen, J. and Terano, Takao and Ohsawa, Yukio and Nishida, Toyoaki and Namatame, Akira and Tsumoto, Syusaku and Washio, Takashi},
  volume        = {2253},
  pages         = {27--34},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-43070-4 978-3-540-45548-6},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-45548-5_4},
  url           = {http://link.springer.com/10.1007/3-540-45548-5_4},
  urldate       = {2018-06-15},
}

@InCollection{RagabHassen2008,
  author        = {Ragab Hassen, Ramy and Nourine, Lhouari and Toumani, Farouk},
  title         = {Protocol-{Based} {Web} {Service} {Composition}},
  booktitle     = {Service-{Oriented} {Computing} – {ICSOC} 2008},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Bouguettaya, Athman and Krueger, Ingolf and Margaria, Tiziana},
  volume        = {5364},
  pages         = {38--53},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-89647-0 978-3-540-89652-4},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-89652-4_7},
  url           = {http://link.springer.com/10.1007/978-3-540-89652-4_7},
  urldate       = {2018-06-15},
}

@InCollection{Thies2002,
  author        = {Thies, William and Karczmarek, Michal and Amarasinghe, Saman},
  title         = {{StreamIt}: {A} {Language} for {Streaming} {Applications}},
  booktitle     = {Compiler {Construction}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2002},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Horspool, R. Nigel},
  volume        = {2304},
  pages         = {179--196},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-43369-9 978-3-540-45937-8},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-45937-5_14},
  shorttitle    = {{StreamIt}},
  url           = {http://link.springer.com/10.1007/3-540-45937-5_14},
  urldate       = {2018-06-15},
}

@InCollection{Hellwagner1999,
  author        = {Hellwagner, Hermann and Weidendorfer, Josef},
  title         = {{SCI} {Sockets} {Library}},
  booktitle     = {{SCI}: {Scalable} {Coherent} {Interface}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1999},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Hellwagner, Hermann and Reinefeld, Alexander},
  volume        = {1734},
  pages         = {209--229},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-66696-7 978-3-540-47048-9},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/10704208_16},
  url           = {http://link.springer.com/10.1007/10704208_16},
  urldate       = {2018-06-15},
}

@InCollection{Bolle2004,
  author        = {Bolle, Ruud M. and Connell, Jonathan H. and Pankanti, Sharath and Ratha, Nalini K. and Senior, Andrew W.},
  title         = {{APIs}, {Standards}, and {Databases}},
  booktitle     = {Guide to {Biometrics}},
  publisher     = {Springer New York},
  year          = {2004},
  pages         = {229--242},
  address       = {New York, NY},
  isbn          = {978-1-4419-2305-9 978-1-4757-4036-3},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Bolle, Ruud M. and Connell, Jonathan H. and Pankanti, Sharath and Ratha, Nalini K. and Senior, Andrew W.},
  doi           = {10.1007/978-1-4757-4036-3_13},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4757-4036-3_13},
  urldate       = {2018-06-15},
}

@InCollection{Petrovic2004,
  author        = {Petrović, Vladimir and Xydeas, Costas},
  title         = {Evaluation of {Image} {Fusion} {Performance} with {Visible} {Differences}},
  booktitle     = {Computer {Vision} - {ECCV} 2004},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2004},
  editor        = {Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Pajdla, Tomáš and Matas, Jiří},
  volume        = {3023},
  pages         = {380--391},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-21982-8 978-3-540-24672-5},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-24672-5_30},
  url           = {http://link.springer.com/10.1007/978-3-540-24672-5_30},
  urldate       = {2018-06-15},
}

@InCollection{Marszalkowski2012,
  author        = {Marszałkowski, Jakub},
  title         = {Prototype of {High} {Performance} {Scalable} {Advertising} {Server} with {Local} {Memory} {Storage} and {Centralised} {Processing}},
  booktitle     = {Information and {Communication} {Technologies}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2012},
  editor        = {Szabó, Róbert and Vidács, Attila},
  volume        = {7479},
  pages         = {194--203},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-642-32807-7 978-3-642-32808-4},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-642-32808-4_18},
  url           = {http://link.springer.com/10.1007/978-3-642-32808-4_18},
  urldate       = {2018-06-15},
}

@Article{Guibas1993,
  author        = {Guibas, Leonidas and Salesin, David and Stolfi, Jorge},
  title         = {Constructing strongly convex approximate hulls with inaccurate primitives},
  journal       = {Algorithmica},
  year          = {1993},
  volume        = {9},
  number        = {6},
  pages         = {534--560},
  month         = jun,
  issn          = {0178-4617, 1432-0541},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/BF01190154},
  language      = {en},
  url           = {http://link.springer.com/10.1007/BF01190154},
  urldate       = {2018-06-15},
}

@InCollection{Pecht1997,
  author        = {Pecht, Michael G. and Nguyen, Luu T.},
  title         = {Plastic {Packaging}},
  booktitle     = {Microelectronics {Packaging} {Handbook}},
  publisher     = {Springer US},
  year          = {1997},
  editor        = {Tummala, Rao R. and Rymaszewski, Eugene J. and Klopfenstein, Alan G.},
  pages         = {394--508},
  address       = {Boston, MA},
  isbn          = {978-1-4613-7767-2 978-1-4615-6037-1},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-1-4615-6037-1_4},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4615-6037-1_4},
  urldate       = {2018-06-15},
}

@Article{Lau2011,
  author        = {Lau, Wilfred W. F. and Yuen, Allan H. K.},
  title         = {The impact of the medium of instruction: {The} case of teaching and learning of computer programming},
  journal       = {Education and Information Technologies},
  year          = {2011},
  volume        = {16},
  number        = {2},
  pages         = {183--201},
  month         = jun,
  issn          = {1360-2357, 1573-7608},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10639-009-9118-8},
  language      = {en},
  shorttitle    = {The impact of the medium of instruction},
  url           = {http://link.springer.com/10.1007/s10639-009-9118-8},
  urldate       = {2018-06-15},
}

@InCollection{Lundin2002,
  author        = {Lundin, Emilie and Kvarnström, Håkan and Jonsson, Erland},
  title         = {A {Synthetic} {Fraud} {Data} {Generation} {Methodology}},
  booktitle     = {Information and {Communications} {Security}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2002},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Deng, Robert and Bao, Feng and Zhou, Jianying and Qing, Sihan},
  volume        = {2513},
  pages         = {265--277},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-00164-5 978-3-540-36159-6},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-36159-6_23},
  url           = {http://link.springer.com/10.1007/3-540-36159-6_23},
  urldate       = {2018-06-15},
}

@Article{Verma2018,
  author        = {Verma, Pawan Kumar and Verma, Rajesh and Alrayes, Mohammad Meftah and Prakash, Arun and Tripathi, Rajeev and Naik, Kshirasagar},
  title         = {A novel energy efficient and scalable hybrid-mac protocol for massive {M}2M networks},
  journal       = {Cluster Computing},
  year          = {2018},
  month         = feb,
  issn          = {1386-7857, 1573-7543},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10586-018-1948-y},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10586-018-1948-y},
  urldate       = {2018-06-15},
}

@InCollection{Watson1997,
  author        = {Watson, Richard and Salzman, Eric},
  title         = {Tracing the evaluation of lazy functional languages: {A} model and its implementation},
  booktitle     = {Advances in {Computing} {Science} — {ASIAN}'97},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1997},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Shyamasundar, R. K. and Ueda, K.},
  volume        = {1345},
  pages         = {336--350},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-63875-9 978-3-540-69658-2},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-63875-X_63},
  shorttitle    = {Tracing the evaluation of lazy functional languages},
  url           = {http://link.springer.com/10.1007/3-540-63875-X_63},
  urldate       = {2018-06-15},
}

@InCollection{Vaughn2002,
  author        = {Vaughn, William R.},
  title         = {{ADO} {Command} {Strategies}},
  booktitle     = {{ADO}.{NET} and {ADO} {Examples} and {Best} {Practices} for {VB} {Programmers}},
  publisher     = {Apress},
  year          = {2002},
  pages         = {81--138},
  address       = {Berkeley, CA},
  isbn          = {978-1-893115-68-2 978-1-4302-0671-2},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Vaughn, William R.},
  doi           = {10.1007/978-1-4302-0671-2_5},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-0671-2_5},
  urldate       = {2018-06-15},
}

@Article{Drago2004,
  author        = {Drago, Frédéric and Chiba, Norishige},
  title         = {Painting canvas synthesis},
  journal       = {The Visual Computer},
  year          = {2004},
  volume        = {20},
  number        = {5},
  pages         = {314--328},
  month         = jul,
  issn          = {0178-2789, 1432-2315},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00371-004-0240-8},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s00371-004-0240-8},
  urldate       = {2018-06-15},
}

@Article{Pjesivac-Grbovic2007,
  author        = {Pješivac-Grbović, Jelena and Angskun, Thara and Bosilca, George and Fagg, Graham E. and Gabriel, Edgar and Dongarra, Jack J.},
  title         = {Performance analysis of {MPI} collective operations},
  journal       = {Cluster Computing},
  year          = {2007},
  volume        = {10},
  number        = {2},
  pages         = {127--143},
  month         = may,
  issn          = {1386-7857, 1573-7543},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10586-007-0012-0},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10586-007-0012-0},
  urldate       = {2018-06-15},
}

@InCollection{Rymaszewski1997,
  author        = {Rymaszewski, Eugene J. and Tummala, Rao R. and Watari, Toshihiko},
  title         = {Microelectronics {Packaging}—{An} {Overview}},
  booktitle     = {Microelectronics {Packaging} {Handbook}},
  publisher     = {Springer US},
  year          = {1997},
  editor        = {Tummala, Rao R. and Rymaszewski, Eugene J. and Klopfenstein, Alan G.},
  pages         = {3--128},
  address       = {Boston, MA},
  isbn          = {978-1-4613-7767-2 978-1-4615-6037-1},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-1-4615-6037-1_1},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4615-6037-1_1},
  urldate       = {2018-06-15},
}

@InCollection{Oliveira2013,
  author        = {Oliveira, Luís M. R. and Cardoso, A. J. Marques},
  title         = {Modeling and {Characterization} of {Leakage} {Inductances} for {Transformer} {Winding} {Fault} {Studies}},
  booktitle     = {Technological {Innovation} for the {Internet} of {Things}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2013},
  editor        = {Camarinha-Matos, Luis M. and Tomic, Slavisa and Graça, Paula},
  volume        = {394},
  pages         = {423--430},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-642-37290-2 978-3-642-37291-9},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-642-37291-9_45},
  url           = {http://link.springer.com/10.1007/978-3-642-37291-9_45},
  urldate       = {2018-06-15},
}

@InCollection{Kohonen1997,
  author        = {Kohonen, Teuvo},
  title         = {Mathematical {Preliminaries}},
  booktitle     = {Self-{Organizing} {Maps}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1997},
  editor        = {Huang, Thomas S. and Kohonen, Teuvo and Schroeder, Manfred R. and Lotsch, Helmut K. V.},
  volume        = {30},
  pages         = {1--58},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-62017-4 978-3-642-97966-8},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Kohonen, Teuvo},
  doi           = {10.1007/978-3-642-97966-8_1},
  url           = {http://www.springerlink.com/index/10.1007/978-3-642-97966-8_1},
  urldate       = {2018-06-15},
}

@Article{Ravichandran2014,
  author        = {Ravichandran, K. S. and Narayanamurthy, Badrinath and Ganapathy, Gopinath and Ravalli, Sri and Sindhura, Jaladhanki},
  title         = {An efficient approach to an automatic detection of erythemato-squamous diseases},
  journal       = {Neural Computing and Applications},
  year          = {2014},
  volume        = {25},
  number        = {1},
  pages         = {105--114},
  month         = jul,
  issn          = {0941-0643, 1433-3058},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00521-013-1452-5},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s00521-013-1452-5},
  urldate       = {2018-06-15},
}

@InCollection{Chronopoulos2001,
  author        = {Chronopoulos, Anthony T. and Kucherov, Andrey B.},
  title         = {A {Parallel} {Krylov}-{Type} {Method} for {Nonsymmetric} {Linear} {Systems}},
  booktitle     = {High {Performance} {Computing} — {HiPC} 2001},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2001},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Monien, Burkhard and Prasanna, Viktor K. and Vajapeyam, Sriram},
  volume        = {2228},
  pages         = {104--114},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-43009-4 978-3-540-45307-9},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-45307-5_10},
  url           = {http://link.springer.com/10.1007/3-540-45307-5_10},
  urldate       = {2018-06-15},
}

@InCollection{Bergman2008,
  author        = {Bergman, Christer},
  title         = {Match-on-{Card} for {Secure} and {Scalable} {Biometric} {Authentication}},
  booktitle     = {Advances in {Biometrics}},
  publisher     = {Springer London},
  year          = {2008},
  editor        = {Ratha, Nalini K. and Govindaraju, Venu},
  pages         = {407--421},
  address       = {London},
  isbn          = {978-1-84628-920-0 978-1-84628-921-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-1-84628-921-7_21},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-84628-921-7_21},
  urldate       = {2018-06-15},
}

@InCollection{Goos2003,
  author        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Hong, Sungjune and Kim, Keecheon and Han, Sunyoung},
  title         = {Intelligent {Fault}-{Tolerant} {Web} {Caching} {Service} on {Application} {Level} {Active} {Networks}},
  booktitle     = {Computational {Science} and {Its} {Applications} — {ICCSA} 2003},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Kumar, Vipin and Gavrilova, Marina L. and Tan, Chih Jeng Kenneth and L’Ecuyer, Pierre},
  volume        = {2667},
  pages         = {144--152},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-40155-1 978-3-540-44839-6},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-44839-X_16},
  url           = {http://link.springer.com/10.1007/3-540-44839-X_16},
  urldate       = {2018-06-15},
}

@InCollection{2004,
  title         = {Image {Compression}},
  booktitle     = {Data {Compression}},
  publisher     = {Springer-Verlag},
  year          = {2004},
  pages         = {251--512},
  address       = {New York},
  isbn          = {978-0-387-40697-8},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/0-387-21832-7_5},
  language      = {en},
  url           = {http://link.springer.com/10.1007/0-387-21832-7_5},
  urldate       = {2018-06-15},
}

@Article{Sopena2009,
  author        = {Sopena, Julien and Arantes, Luciana and Legond-Aubry, Fabrice and Sens, Pierre},
  title         = {Building effective mutual exclusion services for grids},
  journal       = {The Journal of Supercomputing},
  year          = {2009},
  volume        = {49},
  number        = {1},
  pages         = {84--107},
  month         = jul,
  issn          = {0920-8542, 1573-0484},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11227-008-0235-8},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s11227-008-0235-8},
  urldate       = {2018-06-15},
}

@InCollection{Alves2003,
  author        = {Alves, Albano and Pina, António and Exposto, José and Rufino, José},
  title         = {{ToCL}: {A} {Thread} {Oriented} {Communication} {Library} to {Interface} {VIA} and {GM} {Protocols}},
  booktitle     = {Computational {Science} — {ICCS} 2003},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Goos, G. and Hartmanis, J. and van Leeuwen, J. and Sloot, Peter M. A. and Abramson, David and Bogdanov, Alexander V. and Gorbachev, Yuriy E. and Dongarra, Jack J. and Zomaya, Albert Y.},
  volume        = {2658},
  pages         = {1022--1031},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-40195-7 978-3-540-44862-4},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-44862-4_110},
  shorttitle    = {{ToCL}},
  url           = {http://link.springer.com/10.1007/3-540-44862-4_110},
  urldate       = {2018-06-15},
}

@InCollection{Volino2000,
  author        = {Volino, Pascal and Magnenat-Thalmann, Nadia},
  title         = {Simulation {Models}},
  booktitle     = {Virtual {Clothing}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2000},
  pages         = {11--101},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-642-63189-4 978-3-642-57278-4},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Volino, Pascal and Magnenat-Thalmann, Nadia},
  doi           = {10.1007/978-3-642-57278-4_2},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-3-642-57278-4_2},
  urldate       = {2018-06-15},
}

@InCollection{2008a,
  title         = {Select},
  booktitle     = {{SQL} {Server} 2008 {Transact}-{SQL} {Recipes}},
  publisher     = {Apress},
  year          = {2008},
  pages         = {1--62},
  address       = {Berkeley, CA},
  isbn          = {978-1-59059-980-8 978-1-4302-0625-5},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-1-4302-0625-5_1},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-0625-5_1},
  urldate       = {2018-06-15},
}

@Article{Georgatos2010,
  author        = {Georgatos, Fotis and Gkamas, Vasileios and Ilias, Aristeidis and Kouretis, Giannis and Varvarigos, Emmanouel},
  title         = {A {Grid}-enabled {CPU} {Scavenging} {Architecture} and a {Case} {Study} of its {Use} in the {Greek} {School} {Network}},
  journal       = {Journal of Grid Computing},
  year          = {2010},
  volume        = {8},
  number        = {1},
  pages         = {61--75},
  month         = mar,
  issn          = {1570-7873, 1572-9184},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10723-009-9143-2},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10723-009-9143-2},
  urldate       = {2018-06-15},
}

@InCollection{Mokhtarian2003,
  author        = {Mokhtarian, Farzin and Bober, Miroslaw},
  title         = {{MPEG}-7 {Standardisation} of the {Curvature} {Scale} {Space} {Shape} {Descriptor}},
  booktitle     = {Curvature {Scale} {Space} {Representation}: {Theory}, {Applications}, and {MPEG}-7 {Standardization}},
  publisher     = {Springer Netherlands},
  year          = {2003},
  editor        = {Viergever, Max A.},
  volume        = {25},
  pages         = {173--213},
  address       = {Dordrecht},
  isbn          = {978-90-481-6270-3 978-94-017-0343-7},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Mokhtarian, Farzin and Bober, Miroslaw},
  doi           = {10.1007/978-94-017-0343-7_6},
  url           = {http://link.springer.com/10.1007/978-94-017-0343-7_6},
  urldate       = {2018-06-15},
}

@InCollection{Rodriguez2008,
  author        = {Rodríguez, A. L. and López-de-Teruel, P. E. and Ruiz, A. and García-Mateos, G. and Fernóndez, L.},
  title         = {A {Design} {Pattern} for {Component} {Oriented} {Development} of {Agent} {Based} {Multithreaded} {Applications}},
  booktitle     = {Euro-{Par} 2008 – {Parallel} {Processing}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Luque, Emilio and Margalef, Tomàs and Benítez, Domingo},
  volume        = {5168},
  pages         = {709--718},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-85450-0 978-3-540-85451-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-85451-7_76},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-3-540-85451-7_76},
  urldate       = {2018-06-15},
}

@InCollection{Wienholt2004c,
  author        = {Wienholt, Nick},
  title         = {Language {Specifics}},
  booktitle     = {Maximizing .{NET} {Performance}},
  publisher     = {Apress},
  year          = {2004},
  pages         = {85--100},
  address       = {Berkeley, CA},
  isbn          = {978-1-59059-141-3 978-1-4302-0784-9},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Wienholt, Nick},
  doi           = {10.1007/978-1-4302-0784-9_6},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-0784-9_6},
  urldate       = {2018-06-15},
}

@InCollection{Sathyanarayan2008,
  author        = {Sathyanarayan, V. Sai and Kohli, Pankaj and Bruhadeshwar, Bezawada},
  title         = {Signature {Generation} and {Detection} of {Malware} {Families}},
  booktitle     = {Information {Security} and {Privacy}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Mu, Yi and Susilo, Willy and Seberry, Jennifer},
  volume        = {5107},
  pages         = {336--349},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-69971-2 978-3-540-70500-0},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-70500-0_25},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-3-540-70500-0_25},
  urldate       = {2018-06-15},
}

@InCollection{Hakli1998,
  author        = {Hakli, Raul and Nykänen, Matti and Tamm, Hellis and Ukkonen, Esko},
  title         = {Implementing a {Declarative} {String} {Query} {Language} with {String} {Restructuring}},
  booktitle     = {Practical {Aspects} of {Declarative} {Languages}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1998},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Gupta, Gopal},
  volume        = {1551},
  pages         = {179--195},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-65527-5 978-3-540-49201-6},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-49201-1_13},
  url           = {http://link.springer.com/10.1007/3-540-49201-1_13},
  urldate       = {2018-06-15},
}

@Article{Sacramento2008,
  author        = {Sacramento, Vagner and Endler, Markus and de Souza, Clarisse},
  title         = {A privacy service for location-based collaboration among mobile users},
  journal       = {Journal of the Brazilian Computer Society},
  year          = {2008},
  volume        = {14},
  number        = {4},
  pages         = {41--57},
  month         = dec,
  issn          = {0104-6500, 1678-4804},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/BF03192571},
  language      = {en},
  url           = {http://www.journal-bcs.com/content/14/4/},
  urldate       = {2018-06-15},
}

@InCollection{Owolabi1988,
  author        = {Owolabi, O. and Ferguson, J. D.},
  title         = {Approximate string matching: {Investigations} with a hardware string comparator},
  booktitle     = {Pattern {Recognition}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1988},
  editor        = {Goos, G. and Hartmanis, J. and Barstow, D. and Brauer, W. and Brinch Hansen, P. and Gries, D. and Luckham, D. and Moler, C. and Pnueli, A. and Seegmüller, G. and Stoer, J. and Wirth, N. and Kittler, J.},
  volume        = {301},
  pages         = {536--545},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-19036-3 978-3-540-38947-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-19036-8_54},
  shorttitle    = {Approximate string matching},
  url           = {http://link.springer.com/10.1007/3-540-19036-8_54},
  urldate       = {2018-06-15},
}

@InCollection{Heuer1996,
  author        = {Heuer, Andreas and Kröger, Joachim},
  title         = {Query optimization in the {CROQUE} project},
  booktitle     = {Database and {Expert} {Systems} {Applications}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1996},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Wagner, Roland R. and Thoma, Helmut},
  volume        = {1134},
  pages         = {489--499},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-61656-6 978-3-540-70651-9},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/BFb0034704},
  url           = {http://link.springer.com/10.1007/BFb0034704},
  urldate       = {2018-06-15},
}

@InCollection{Mirkovic2001,
  author        = {Mirković, Dragan and Johnsson, S. Lennart},
  title         = {Automatic {Performance} {Tuning} in the {UHFFT} {Library}},
  booktitle     = {Computational {Science} — {ICCS} 2001},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2001},
  editor        = {Goos, G. and Hartmanis, J. and van Leeuwen, J. and Alexandrov, Vassil N. and Dongarra, Jack J. and Juliano, Benjoe A. and Renner, René S. and Tan, C. J. Kenneth},
  volume        = {2073},
  pages         = {71--80},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-42232-7 978-3-540-45545-5},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-45545-0_17},
  url           = {http://link.springer.com/10.1007/3-540-45545-0_17},
  urldate       = {2018-06-15},
}

@InCollection{Churchill2003,
  author        = {Churchill, Elizabeth and Nelson, Les and Denoue, Laurent and Murphy, Paul and Helfman, Jonathan},
  title         = {The {Plasma} {Poster} {Network}},
  booktitle     = {Public and {Situated} {Displays}},
  publisher     = {Springer Netherlands},
  year          = {2003},
  editor        = {O’Hara, Kenton and Perry, Mark and Churchill, Elizabeth and Russell, Daniel},
  pages         = {233--260},
  address       = {Dordrecht},
  isbn          = {978-90-481-6449-3 978-94-017-2813-3},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-94-017-2813-3_10},
  url           = {http://link.springer.com/10.1007/978-94-017-2813-3_10},
  urldate       = {2018-06-15},
}

@InCollection{Sweeney2001,
  author        = {Sweeney, Mary Romero},
  title         = {Creating {Test} {Utilities}},
  booktitle     = {Visual {Basic} for {Testers}},
  publisher     = {Apress},
  year          = {2001},
  pages         = {137--182},
  address       = {Berkeley, CA},
  isbn          = {978-1-893115-53-8 978-1-4302-1138-9},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Sweeney, Mary Romero},
  doi           = {10.1007/978-1-4302-1138-9_5},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-1138-9_5},
  urldate       = {2018-06-15},
}

@Article{Manning2008,
  author        = {Manning, Anna M. and Haglin, David J. and Keane, John A.},
  title         = {A recursive search algorithm for statistical disclosure assessment},
  journal       = {Data Mining and Knowledge Discovery},
  year          = {2008},
  volume        = {16},
  number        = {2},
  pages         = {165--196},
  month         = apr,
  issn          = {1384-5810, 1573-756X},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10618-007-0078-6},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10618-007-0078-6},
  urldate       = {2018-06-15},
}

@Article{Su2008,
  author        = {Su, Sen and Li, Fei and Yang, FangChun},
  title         = {Iterative selection algorithm for service composition in distributed environments},
  journal       = {Science in China Series F: Information Sciences},
  year          = {2008},
  volume        = {51},
  number        = {11},
  pages         = {1841--1856},
  month         = nov,
  issn          = {1009-2757, 1862-2836},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11432-008-0147-5},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s11432-008-0147-5},
  urldate       = {2018-06-15},
}

@Article{Banicescu2011,
  author        = {Banicescu, Ioana and Lim, Hyeona and Cariño, Ricolindo L. and Kim, Seongjai},
  title         = {A parameter study of a hybrid {Laplacian} mean-curvature flow denoising model},
  journal       = {The Journal of Supercomputing},
  year          = {2011},
  volume        = {57},
  number        = {3},
  pages         = {339--356},
  month         = sep,
  issn          = {0920-8542, 1573-0484},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11227-010-0417-z},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s11227-010-0417-z},
  urldate       = {2018-06-15},
}

@InCollection{Eliuk2008,
  author        = {Eliuk, S. and Boulanger, P. and Kabin, K.},
  title         = {{SUNVIZ}: {A} {Real}-{Time} {Visualization} {Environment} for {Space} {Physics} {Applications}},
  booktitle     = {Advances in {Visual} {Computing}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Bebis, George and Boyle, Richard and Parvin, Bahram and Koracin, Darko and Remagnino, Paolo and Porikli, Fatih and Peters, Jörg and Klosowski, James and Arns, Laura and Chun, Yu Ka and Rhyne, Theresa-Marie and Monroe, Laura},
  volume        = {5359},
  pages         = {1--11},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-89645-6 978-3-540-89646-3},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-89646-3_1},
  shorttitle    = {{SUNVIZ}},
  url           = {http://link.springer.com/10.1007/978-3-540-89646-3_1},
  urldate       = {2018-06-15},
}

@InCollection{Butler1992,
  author        = {Butler, Kenneth M. and Mercer, M. Ray},
  title         = {Analyzing {Test} {Performance} with the {ATPG} {Model}},
  booktitle     = {Assessing {Fault} {Model} and {Test} {Quality}},
  publisher     = {Springer US},
  year          = {1992},
  pages         = {87--100},
  address       = {Boston, MA},
  isbn          = {978-1-4613-6602-7 978-1-4615-3606-2},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Butler, Kenneth M. and Mercer, M. Ray},
  doi           = {10.1007/978-1-4615-3606-2_11},
  url           = {http://link.springer.com/10.1007/978-1-4615-3606-2_11},
  urldate       = {2018-06-15},
}

@Article{Kim2018,
  author        = {Kim, Jinoh and Sim, Alex and Tierney, Brian and Suh, Sang and Kim, Ikkyun},
  title         = {Multivariate network traffic analysis using clustered patterns},
  journal       = {Computing},
  year          = {2018},
  month         = apr,
  issn          = {0010-485X, 1436-5057},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00607-018-0619-4},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s00607-018-0619-4},
  urldate       = {2018-06-15},
}

@Article{Regan1995,
  author        = {Regan, Clare},
  title         = {An investigation into nausea and other side-effects of head-coupled immersive virtual reality},
  journal       = {Virtual Reality},
  year          = {1995},
  volume        = {1},
  number        = {1},
  pages         = {17--31},
  month         = jun,
  issn          = {1359-4338, 1434-9957},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/BF02009710},
  language      = {en},
  url           = {http://link.springer.com/10.1007/BF02009710},
  urldate       = {2018-06-15},
}

@InCollection{Chakravarty1999,
  author        = {Chakravarty, Manuel M. T.},
  title         = {Lazy {Lexing} is {Fast}},
  booktitle     = {Functional and {Logic} {Programming}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1999},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Middeldorp, Aart and Sato, Taisuke},
  volume        = {1722},
  pages         = {68--84},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-66677-6 978-3-540-47950-5},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/10705424_5},
  url           = {http://link.springer.com/10.1007/10705424_5},
  urldate       = {2018-06-15},
}

@InCollection{Gregori2004,
  author        = {Gregori, Stefano and Tasso, Sergio and Laganà, Antonio},
  title         = {Fine {Grain} {Parallelization} of a {Discrete} {Variable} {Wavepacket} {Calculation} {Using} {ASSIST}-{CL}},
  booktitle     = {Computational {Science} and {Its} {Applications} – {ICCSA} 2004},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2004},
  editor        = {Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Laganá, Antonio and Gavrilova, Marina L. and Kumar, Vipin and Mun, Youngsong and Tan, C. J. Kenneth and Gervasi, Osvaldo},
  volume        = {3044},
  pages         = {437--444},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-22056-5 978-3-540-24709-8},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-24709-8_47},
  url           = {http://link.springer.com/10.1007/978-3-540-24709-8_47},
  urldate       = {2018-06-15},
}

@InCollection{Andersson2002,
  author        = {Andersson, Ulf and Hedman, Fredrik},
  title         = {Performance of an {IBM} {Pwr}4 {Node} for the {GEMS} {TD} {Codes} and {Parallacs}},
  booktitle     = {Applied {Parallel} {Computing}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2002},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Fagerholm, Juha and Haataja, Juha and Järvinen, Jari and Lyly, Mikko and Råback, Peter and Savolainen, Ville},
  volume        = {2367},
  pages         = {467--475},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-43786-4 978-3-540-48051-8},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-48051-X_46},
  url           = {http://link.springer.com/10.1007/3-540-48051-X_46},
  urldate       = {2018-06-15},
}

@InCollection{Douglas1997a,
  author        = {Douglas, Sarah A. and Mithal, Anant Kartik},
  title         = {A {Survey} of {Ergonomic} {Studies}},
  booktitle     = {The {Ergonomics} of {Computer} {Pointing} {Devices}},
  publisher     = {Springer London},
  year          = {1997},
  pages         = {63--84},
  address       = {London},
  isbn          = {978-3-540-19986-1 978-1-4471-0917-4},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Douglas, Sarah A. and Mithal, Anant Kartik},
  doi           = {10.1007/978-1-4471-0917-4_4},
  url           = {http://link.springer.com/10.1007/978-1-4471-0917-4_4},
  urldate       = {2018-06-15},
}

@InCollection{Smith2003,
  author        = {Smith, Kenny},
  title         = {Learning {Biases} for the {Evolution} of {Linguistic} {Structure}: {An} {Associative} {Network} {Model}},
  booktitle     = {Advances in {Artificial} {Life}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Banzhaf, Wolfgang and Ziegler, Jens and Christaller, Thomas and Dittrich, Peter and Kim, Jan T.},
  volume        = {2801},
  pages         = {517--524},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-20057-4 978-3-540-39432-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-39432-7_55},
  shorttitle    = {Learning {Biases} for the {Evolution} of {Linguistic} {Structure}},
  url           = {http://link.springer.com/10.1007/978-3-540-39432-7_55},
  urldate       = {2018-06-15},
}

@Article{Domingo-Ferrer2018,
  author        = {Domingo-Ferrer, Josep and Blanco-Justicia, Alberto and Ràfols, Carla},
  title         = {Dynamic group size accreditation and group discounts preserving anonymity},
  journal       = {International Journal of Information Security},
  year          = {2018},
  volume        = {17},
  number        = {3},
  pages         = {243--260},
  month         = jun,
  issn          = {1615-5262, 1615-5270},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10207-017-0368-y},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10207-017-0368-y},
  urldate       = {2018-06-15},
}

@InCollection{Wienholt2004d,
  author        = {Wienholt, Nick},
  title         = {Strings, {Text}, and {Regular} {Expressions}},
  booktitle     = {Maximizing .{NET} {Performance}},
  publisher     = {Apress},
  year          = {2004},
  pages         = {47--62},
  address       = {Berkeley, CA},
  isbn          = {978-1-59059-141-3 978-1-4302-0784-9},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Wienholt, Nick},
  doi           = {10.1007/978-1-4302-0784-9_4},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-0784-9_4},
  urldate       = {2018-06-15},
}

@InCollection{Hughes2000,
  author        = {Hughes, Peter H. and Brataas, Gunnar},
  title         = {Scalability of a {Workstation} {Cluster} {Architecture} for {Video}-on-{Demand} {Applications}},
  booktitle     = {Computer {Performance} {Evaluation}.{Modelling} {Techniques} and {Tools}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2000},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Haverkort, Boudewijn R. and Bohnenkamp, Henrik C. and Smith, Connie U.},
  volume        = {1786},
  pages         = {277--293},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-67260-9 978-3-540-46429-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-46429-8_20},
  url           = {http://link.springer.com/10.1007/3-540-46429-8_20},
  urldate       = {2018-06-15},
}

@InCollection{Maekelae2006,
  author        = {Mäkelä, Eetu and Hyvönen, Eero and Saarela, Samppa},
  title         = {Ontogator — {A} {Semantic} {View}-{Based} {Search} {Engine} {Service} for {Web} {Applications}},
  booktitle     = {The {Semantic} {Web} - {ISWC} 2006},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2006},
  editor        = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Cruz, Isabel and Decker, Stefan and Allemang, Dean and Preist, Chris and Schwabe, Daniel and Mika, Peter and Uschold, Mike and Aroyo, Lora M.},
  volume        = {4273},
  pages         = {847--860},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-49029-6 978-3-540-49055-5},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/11926078_61},
  url           = {http://link.springer.com/10.1007/11926078_61},
  urldate       = {2018-06-15},
}

@InCollection{Hare2009,
  author        = {Hare, Joanna and Gill, Steve and Loudon, Gareth and Ramduny-Ellis, Devina and Dix, Alan},
  title         = {Physical {Fidelity}: {Exploring} the {Importance} of {Physicality} on {Physical}-{Digital} {Conceptual} {Prototyping}},
  booktitle     = {Human-{Computer} {Interaction} – {INTERACT} 2009},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2009},
  editor        = {Gross, Tom and Gulliksen, Jan and Kotzé, Paula and Oestreicher, Lars and Palanque, Philippe and Prates, Raquel Oliveira and Winckler, Marco},
  volume        = {5726},
  pages         = {217--230},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-642-03654-5 978-3-642-03655-2},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-642-03655-2_26},
  shorttitle    = {Physical {Fidelity}},
  url           = {http://link.springer.com/10.1007/978-3-642-03655-2_26},
  urldate       = {2018-06-15},
}

@InCollection{Mount2001,
  author        = {Mount, Claude and Liao, T. Warren},
  title         = {Prototype of an {Intelligent} {Failure} {Analysis} {System}},
  booktitle     = {Case-{Based} {Reasoning} {Research} and {Development}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2001},
  editor        = {Goos, G. and Hartmanis, J. and van Leeuwen, J. and Aha, David W. and Watson, Ian},
  volume        = {2080},
  pages         = {716--730},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-42358-4 978-3-540-44593-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-44593-5_51},
  url           = {http://link.springer.com/10.1007/3-540-44593-5_51},
  urldate       = {2018-06-15},
}

@InCollection{Klimov2004,
  author        = {Klimov, Alexander and Shamir, Adi},
  title         = {New {Cryptographic} {Primitives} {Based} on {Multiword} {T}-{Functions}},
  booktitle     = {Fast {Software} {Encryption}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2004},
  editor        = {Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Roy, Bimal and Meier, Willi},
  volume        = {3017},
  pages         = {1--15},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-22171-5 978-3-540-25937-4},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-25937-4_1},
  url           = {http://link.springer.com/10.1007/978-3-540-25937-4_1},
  urldate       = {2018-06-15},
}

@InCollection{Golbreich2007,
  author        = {Golbreich, Christine and Horridge, Matthew and Horrocks, Ian and Motik, Boris and Shearer, Rob},
  title         = {{OBO} and {OWL}: {Leveraging} {Semantic} {Web} {Technologies} for the {Life} {Sciences}},
  booktitle     = {The {Semantic} {Web}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2007},
  editor        = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Aberer, Karl and Choi, Key-Sun and Noy, Natasha and Allemang, Dean and Lee, Kyung-Il and Nixon, Lyndon and Golbeck, Jennifer and Mika, Peter and Maynard, Diana and Mizoguchi, Riichiro and Schreiber, Guus and Cudré-Mauroux, Philippe},
  volume        = {4825},
  pages         = {169--182},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-76297-3 978-3-540-76298-0},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-76298-0_13},
  shorttitle    = {{OBO} and {OWL}},
  url           = {http://link.springer.com/10.1007/978-3-540-76298-0_13},
  urldate       = {2018-06-15},
}

@Article{Goldstein2002,
  author        = {Goldstein, Mikael and Alsio¨, Gunilla and Werdenhoff, Jost},
  title         = {The {Media} {Equation} {Does} {Not} {Always} {Apply}: {People} are not {Polite} {Towards} {Small} {Computers}},
  journal       = {Personal and Ubiquitous Computing},
  year          = {2002},
  volume        = {6},
  number        = {2},
  pages         = {87--96},
  month         = apr,
  issn          = {1617-4909, 1617-4917},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s007790200008},
  shorttitle    = {The {Media} {Equation} {Does} {Not} {Always} {Apply}},
  url           = {http://link.springer.com/10.1007/s007790200008},
  urldate       = {2018-06-15},
}

@Article{Yang2018,
  author        = {Yang, Cheng-Yu and Huang, Cheng-Ta and Wang, Ya-Ping and Chen, Yen-Wen and Wang, Shiuh-Jeng},
  title         = {File changes with security proof stored in cloud service systems},
  journal       = {Personal and Ubiquitous Computing},
  year          = {2018},
  volume        = {22},
  number        = {1},
  pages         = {45--53},
  month         = feb,
  issn          = {1617-4909, 1617-4917},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00779-017-1090-5},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s00779-017-1090-5},
  urldate       = {2018-06-15},
}

@Article{Chang2011a,
  author        = {Chang, Jian and Yang, Xiaosong and Pan, Jun J. and Li, Wenxi and Zhang, Jian J.},
  title         = {A fast hybrid computation model for rectum deformation},
  journal       = {The Visual Computer},
  year          = {2011},
  volume        = {27},
  number        = {2},
  pages         = {97--107},
  month         = feb,
  issn          = {0178-2789, 1432-2315},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00371-010-0533-z},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s00371-010-0533-z},
  urldate       = {2018-06-15},
}

@Article{Shainer2011,
  author        = {Shainer, Gilad and Ayoub, Ali and Lui, Pak and Liu, Tong and Kagan, Michael and Trott, Christian R. and Scantlen, Greg and Crozier, Paul S.},
  title         = {The development of {Mellanox}/{NVIDIA} {GPUDirect} over {InfiniBand}—a new model for {GPU} to {GPU} communications},
  journal       = {Computer Science - Research and Development},
  year          = {2011},
  volume        = {26},
  number        = {3-4},
  pages         = {267--273},
  month         = jun,
  issn          = {1865-2034, 1865-2042},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00450-011-0157-1},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s00450-011-0157-1},
  urldate       = {2018-06-15},
}

@InCollection{Embury2000,
  author        = {Embury, Suzanne M. and Shao, Jianhua and Gray, W. Alex and Fishlock, Nigel},
  title         = {Advertising {Database} {Capabilities} for {Information} {Sharing}},
  booktitle     = {Advanced {Information} {Systems} {Engineering}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2000},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Wangler, Benkt and Bergman, Lars},
  volume        = {1789},
  pages         = {47--63},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-67630-0 978-3-540-45140-2},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-45140-4_5},
  url           = {http://link.springer.com/10.1007/3-540-45140-4_5},
  urldate       = {2018-06-15},
}

@InCollection{Fleischhammer1996,
  author        = {Fleischhammer, Werner},
  title         = {Reliability and environmental requirements},
  booktitle     = {Quality by {Design} for {Electronics}},
  publisher     = {Springer US},
  year          = {1996},
  pages         = {121--152},
  address       = {Boston, MA},
  isbn          = {978-1-4613-5857-2 978-1-4615-2065-8},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Fleischhammer, Werner},
  doi           = {10.1007/978-1-4615-2065-8_5},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4615-2065-8_5},
  urldate       = {2018-06-15},
}

@InCollection{Sabuncu2003,
  author        = {Sabuncu, Orkunt and Alpaslan, Ferda N. and Akman, Varol},
  title         = {Using {Criticalities} as a {Heuristic} for {Answer} {Set} {Programming}},
  booktitle     = {Logic {Programming} and {Nonmonotonic} {Reasoning}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Lifschitz, Vladimir and Niemelä, Ilkka},
  volume        = {2923},
  pages         = {234--246},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-20721-4 978-3-540-24609-1},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-24609-1_21},
  url           = {http://link.springer.com/10.1007/978-3-540-24609-1_21},
  urldate       = {2018-06-15},
}

@InCollection{Sung2004,
  author        = {Sung, Sam Y. and Li, Zhao and Ling, Tok W.},
  title         = {Clustering {Techniques} for {Large} {Database} {Cleansing}},
  booktitle     = {Clustering and {Information} {Retrieval}},
  publisher     = {Springer US},
  year          = {2004},
  editor        = {Du, Ding-Zhu and Raghavendra, Cauligi},
  volume        = {11},
  pages         = {227--259},
  address       = {Boston, MA},
  isbn          = {978-1-4613-7949-2 978-1-4613-0227-8},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Wu, Weili and Xiong, Hui and Shekhar, Shashi},
  doi           = {10.1007/978-1-4613-0227-8_8},
  url           = {http://link.springer.com/10.1007/978-1-4613-0227-8_8},
  urldate       = {2018-06-15},
}

@InCollection{Lee2009,
  author        = {Lee, Myung-Sub and Park, Chang-Hyeon},
  title         = {The {Three}-{Level} {Approaches} for {Differentiated} {Service} in {Clustering} {Web} {Server}},
  booktitle     = {Active and {Programmable} {Networks}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2009},
  editor        = {Hutchison, David and Denazis, Spyros and Lefevre, Laurent and Minden, Gary J.},
  volume        = {4388},
  pages         = {230--235},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-642-00971-6 978-3-642-00972-3},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-642-00972-3_23},
  url           = {http://link.springer.com/10.1007/978-3-642-00972-3_23},
  urldate       = {2018-06-15},
}

@InCollection{Gold1991,
  author        = {Gold, Gary},
  title         = {A word to phoneme translator},
  booktitle     = {Computing in the 90's},
  publisher     = {Springer New York},
  year          = {1991},
  editor        = {Goos, Gerhard and Hartmanis, Juris and Sherwani, Naveed A. and de Doncker, Elise and Kapenga, John A.},
  volume        = {507},
  pages         = {65--69},
  address       = {New York, NY},
  isbn          = {978-0-387-97628-0 978-0-387-34815-5},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/BFb0038474},
  url           = {http://link.springer.com/10.1007/BFb0038474},
  urldate       = {2018-06-15},
}

@Article{Rosales2006,
  author        = {Rosales, RÓMer and Sclaroff, Stan},
  title         = {Combining {Generative} and {Discriminative} {Models} in a {Framework} for {Articulated} {Pose} {Estimation}},
  journal       = {International Journal of Computer Vision},
  year          = {2006},
  volume        = {67},
  number        = {3},
  pages         = {251--276},
  month         = may,
  issn          = {0920-5691, 1573-1405},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11263-006-5165-4},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s11263-006-5165-4},
  urldate       = {2018-06-15},
}

@InCollection{Douglas1997b,
  author        = {Douglas, Sarah A. and Mithal, Anant Kartik},
  title         = {Factors in {Applying} {Psychomotor} {Studies} to {Pointing} {Devices}},
  booktitle     = {The {Ergonomics} of {Computer} {Pointing} {Devices}},
  publisher     = {Springer London},
  year          = {1997},
  pages         = {37--62},
  address       = {London},
  isbn          = {978-3-540-19986-1 978-1-4471-0917-4},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Douglas, Sarah A. and Mithal, Anant Kartik},
  doi           = {10.1007/978-1-4471-0917-4_3},
  url           = {http://link.springer.com/10.1007/978-1-4471-0917-4_3},
  urldate       = {2018-06-15},
}

@InCollection{Willinger2000,
  author        = {Willinger, Walter},
  title         = {The {Discovery} of {Self}-{Similar} {Traffic}},
  booktitle     = {Performance {Evaluation}: {Origins} and {Directions}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2000},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Haring, Günter and Lindemann, Christoph and Reiser, Martin},
  volume        = {1769},
  pages         = {513--527},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-67193-0 978-3-540-46506-5},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-46506-5_24},
  url           = {http://link.springer.com/10.1007/3-540-46506-5_24},
  urldate       = {2018-06-15},
}

@Article{Syllebranque2008,
  author        = {Syllebranque, Cédric and Boivin, Samuel},
  title         = {Estimation of mechanical parameters of deformable solids from videos},
  journal       = {The Visual Computer},
  year          = {2008},
  volume        = {24},
  number        = {11},
  pages         = {963--972},
  month         = nov,
  issn          = {0178-2789, 1432-2315},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00371-008-0273-5},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s00371-008-0273-5},
  urldate       = {2018-06-15},
}

@InCollection{Lee2000,
  author        = {Lee, K. and Lee, Y.},
  title         = {A {Framework} of {Two}-{Stage} {Combination} of {Multiple} {Recognizers} for {Handwritten} {Numerals}},
  booktitle     = {{PRICAI} 2000 {Topics} in {Artificial} {Intelligence}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2000},
  editor        = {Goos, G. and Hartmanis, J. and van Leeuwen, J. and Mizoguchi, Riichiro and Slaney, John},
  volume        = {1886},
  pages         = {617--626},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-67925-7 978-3-540-44533-3},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-44533-1_62},
  url           = {http://link.springer.com/10.1007/3-540-44533-1_62},
  urldate       = {2018-06-15},
}

@InCollection{Baker2007,
  author        = {Baker, Paul and Dai, Zhen Ru and Grabowski, Jens and Haugen, Øystein and Schieferdecker, Ina and Williams, Clay},
  title         = {User-{Interface} {Testing}},
  booktitle     = {Model-{Driven} {Testing}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2007},
  pages         = {117--124},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-72562-6},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-72563-3_9},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-3-540-72563-3_9},
  urldate       = {2018-06-15},
}

@InCollection{Hergula2002,
  author        = {Hergula, Klaudia and Härder, Theo},
  title         = {Coupling of {FDBS} and {WfMS} for {Integrating} {Database} and {Application} {Systems}: {Architecture}, {Complexity}, {Performance}},
  booktitle     = {Advances in {Database} {Technology} — {EDBT} 2002},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2002},
  editor        = {Goos, G. and Hartmanis, J. and van Leeuwen, J. and Jensen, Christian S. and Šaltenis, Simonas and Jeffery, Keith G. and Pokorny, Jaroslav and Bertino, Elisa and Böhn, Klemens and Jarke, Matthias},
  volume        = {2287},
  pages         = {372--389},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-43324-8 978-3-540-45876-0},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-45876-X_25},
  shorttitle    = {Coupling of {FDBS} and {WfMS} for {Integrating} {Database} and {Application} {Systems}},
  url           = {http://link.springer.com/10.1007/3-540-45876-X_25},
  urldate       = {2018-06-15},
}

@Article{AbbaspourAsadollah2017,
  author        = {Abbaspour Asadollah, Sara and Sundmark, Daniel and Eldh, Sigrid and Hansson, Hans},
  title         = {Concurrency bugs in open source software: a case study},
  journal       = {Journal of Internet Services and Applications},
  year          = {2017},
  volume        = {8},
  number        = {1},
  month         = dec,
  issn          = {1867-4828, 1869-0238},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1186/s13174-017-0055-2},
  language      = {en},
  shorttitle    = {Concurrency bugs in open source software},
  url           = {http://jisajournal.springeropen.com/articles/10.1186/s13174-017-0055-2},
  urldate       = {2018-06-15},
}

@Article{Hlavacs2012,
  author        = {Hlavacs, Helmut and Weidlich, Roman and Treutner, Thomas},
  title         = {Energy efficient peer-to-peer file sharing},
  journal       = {The Journal of Supercomputing},
  year          = {2012},
  volume        = {62},
  number        = {3},
  pages         = {1167--1188},
  month         = dec,
  issn          = {0920-8542, 1573-0484},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11227-011-0602-8},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s11227-011-0602-8},
  urldate       = {2018-06-15},
}

@Article{Liu2009b,
  author        = {Liu, Yonghuai},
  title         = {Replicator {Dynamics} in the {Iterative} {Process} for {Accurate} {Range} {Image} {Matching}},
  journal       = {International Journal of Computer Vision},
  year          = {2009},
  volume        = {83},
  number        = {1},
  pages         = {30--56},
  month         = jun,
  issn          = {0920-5691, 1573-1405},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11263-009-0210-8},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s11263-009-0210-8},
  urldate       = {2018-06-15},
}

@Article{Fan2009,
  author        = {Fan, Dong-Rui and Yuan, Nan and Zhang, Jun-Chao and Zhou, Yong-Bin and Lin, Wei and Song, Feng-Long and Ye, Xiao-Chun and Huang, He and Yu, Lei and Long, Guo-Ping and Zhang, Hao and Liu, Lei},
  title         = {Godson-{T}: {An} {Efficient} {Many}-{Core} {Architecture} for {Parallel} {Program} {Executions}},
  journal       = {Journal of Computer Science and Technology},
  year          = {2009},
  volume        = {24},
  number        = {6},
  pages         = {1061--1073},
  month         = nov,
  issn          = {1000-9000, 1860-4749},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11390-009-9295-3},
  language      = {en},
  shorttitle    = {Godson-{T}},
  url           = {http://link.springer.com/10.1007/s11390-009-9295-3},
  urldate       = {2018-06-15},
}

@Article{Xie1999,
  author        = {Xie, Yong and Liu, Changdong and Lee, Myung J. and Saadawi, Tarek N.},
  title         = {Adaptive multimedia synchronization in a teleconference system},
  journal       = {Multimedia Systems},
  year          = {1999},
  volume        = {7},
  number        = {4},
  pages         = {326--337},
  month         = jul,
  issn          = {0942-4962, 1432-1882},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s005300050134},
  url           = {http://link.springer.com/10.1007/s005300050134},
  urldate       = {2018-06-15},
}

@InCollection{Bugliesi1994,
  author        = {Bugliesi, Michele and Nardiello, Giuseppe},
  title         = {{SelfLog}: {Language} and {Implementation}},
  booktitle     = {Implementations of {Logic} {Programming} {Systems}},
  publisher     = {Springer US},
  year          = {1994},
  editor        = {Tick, Evan and Succi, Giancarlo},
  pages         = {1--15},
  address       = {Boston, MA},
  isbn          = {978-1-4613-6157-2 978-1-4615-2690-2},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-1-4615-2690-2_1},
  language      = {en},
  shorttitle    = {{SelfLog}},
  url           = {http://link.springer.com/10.1007/978-1-4615-2690-2_1},
  urldate       = {2018-06-15},
}

@InCollection{Maruster2002,
  author        = {Maruster, Laura and Weijters, A. J. M. M. Ton and van der Aalst, W. M. P. Wil and van den Bosch, Antal},
  title         = {Process {Mining}: {Discovering} {Direct} {Successors} in {Process} {Logs}},
  booktitle     = {Discovery {Science}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2002},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Lange, Steffen and Satoh, Ken and Smith, Carl H.},
  volume        = {2534},
  pages         = {364--373},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-00188-1 978-3-540-36182-4},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-36182-0_37},
  shorttitle    = {Process {Mining}},
  url           = {http://link.springer.com/10.1007/3-540-36182-0_37},
  urldate       = {2018-06-15},
}

@InCollection{Grenning2004,
  author        = {Grenning, James and Peeters, Johan and Behring, Carsten},
  title         = {Agile {Development} for {Embedded} {Software}},
  booktitle     = {Extreme {Programming} and {Agile} {Methods} - {XP}/{Agile} {Universe} 2004},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2004},
  editor        = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Zannier, Carmen and Erdogmus, Hakan and Lindstrom, Lowell},
  volume        = {3134},
  pages         = {194--195},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-22839-4 978-3-540-27777-4},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-27777-4_25},
  url           = {http://link.springer.com/10.1007/978-3-540-27777-4_25},
  urldate       = {2018-06-15},
}

@InCollection{Bos2004,
  author        = {Bos, Erik and Vriens, Christ},
  title         = {An {Agile} {CMM}},
  booktitle     = {Extreme {Programming} and {Agile} {Methods} - {XP}/{Agile} {Universe} 2004},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2004},
  editor        = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Zannier, Carmen and Erdogmus, Hakan and Lindstrom, Lowell},
  volume        = {3134},
  pages         = {129--138},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-22839-4 978-3-540-27777-4},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-27777-4_13},
  url           = {http://link.springer.com/10.1007/978-3-540-27777-4_13},
  urldate       = {2018-06-15},
}

@Article{Cao2017,
  author        = {Cao, Lele and Sun, Fuchun and Li, Hongbo and Huang, Wenbing},
  title         = {Advancing the incremental fusion of robotic sensory features using online multi-kernel extreme learning machine},
  journal       = {Frontiers of Computer Science},
  year          = {2017},
  volume        = {11},
  number        = {2},
  pages         = {276--289},
  month         = apr,
  issn          = {2095-2228, 2095-2236},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11704-016-5171-9},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s11704-016-5171-9},
  urldate       = {2018-06-15},
}

@Article{Ma2017,
  author        = {Ma, Xiaochuan and Zhang, Jianhua and Zhang, Yuxiang and Ma, Zhanyu},
  title         = {Data scheme-based wireless channel modeling method: motivation, principle and performance},
  journal       = {Journal of Communications and Information Networks},
  year          = {2017},
  volume        = {2},
  number        = {3},
  pages         = {41--51},
  month         = sep,
  issn          = {2096-1081, 2509-3312},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s41650-017-0009-7},
  language      = {en},
  shorttitle    = {Data scheme-based wireless channel modeling method},
  url           = {http://link.springer.com/10.1007/s41650-017-0009-7},
  urldate       = {2018-06-15},
}

@InCollection{Marik2000,
  author        = {Mařík, Radek},
  title         = {Quality in {Computer} {Vision}},
  booktitle     = {Performance {Characterization} in {Computer} {Vision}},
  publisher     = {Springer Netherlands},
  year          = {2000},
  editor        = {Viergever, Max A. and Klette, Reinhard and Stiehl, H. Siegfried and Viergever, Max A. and Vincken, Koen L.},
  volume        = {17},
  pages         = {41--51},
  address       = {Dordrecht},
  isbn          = {978-90-481-5487-6 978-94-015-9538-4},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-94-015-9538-4_4},
  url           = {http://link.springer.com/10.1007/978-94-015-9538-4_4},
  urldate       = {2018-06-15},
}

@Article{Bhattacharya2012,
  author        = {Bhattacharya, Abhishek and Wu, Wanmin and Yang, Zhenyu},
  title         = {Quality of experience evaluation of voice communication: an affect-based approach},
  journal       = {Human-centric Computing and Information Sciences},
  year          = {2012},
  volume        = {2},
  number        = {1},
  pages         = {7},
  issn          = {2192-1962},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1186/2192-1962-2-7},
  language      = {en},
  shorttitle    = {Quality of experience evaluation of voice communication},
  url           = {http://hcis-journal.springeropen.com/articles/10.1186/2192-1962-2-7},
  urldate       = {2018-06-15},
}

@Article{Seitz2008,
  author        = {Seitz, Ludwig and Selander, Göran and Rissanen, Erik and Ling, Cao and Sadighi, Babak},
  title         = {Decentralized {Access} {Control} {Management} for {Network} {Configuration}},
  journal       = {Journal of Network and Systems Management},
  year          = {2008},
  volume        = {16},
  number        = {3},
  pages         = {303--316},
  month         = sep,
  issn          = {1064-7570, 1573-7705},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s10922-008-9111-3},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s10922-008-9111-3},
  urldate       = {2018-06-15},
}

@InCollection{Lengal2012,
  author        = {Lengál, Ondřej and Šimáček, Jiří and Vojnar, Tomáš},
  title         = {{VATA}: {A} {Library} for {Efficient} {Manipulation} of {Non}-deterministic {Tree} {Automata}},
  booktitle     = {Tools and {Algorithms} for the {Construction} and {Analysis} of {Systems}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2012},
  editor        = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Flanagan, Cormac and König, Barbara},
  volume        = {7214},
  pages         = {79--94},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-642-28755-8 978-3-642-28756-5},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-642-28756-5_7},
  shorttitle    = {{VATA}},
  url           = {http://link.springer.com/10.1007/978-3-642-28756-5_7},
  urldate       = {2018-06-15},
}

@Article{Fan2013a,
  author        = {Fan, Shuang-shuang and Yang, Can-jun and Peng, Shi-lin and Li, Kai-hu and Xie, Yu and Zhang, Shao-yong},
  title         = {Underwater glider design based on dynamic model analysis and prototype development},
  journal       = {Journal of Zhejiang University SCIENCE C},
  year          = {2013},
  volume        = {14},
  number        = {8},
  pages         = {583--599},
  month         = aug,
  issn          = {1869-1951, 1869-196X},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1631/jzus.C1300001},
  language      = {en},
  url           = {http://link.springer.com/10.1631/jzus.C1300001},
  urldate       = {2018-06-15},
}

@InCollection{Weaver2004,
  author        = {Weaver, James L. and Mukhar, Kevin and Crume, Jim},
  title         = {Working with {Databases}},
  booktitle     = {Beginning {J}2EE 1.4: {From} {Novice} to {Professional}},
  publisher     = {Apress},
  year          = {2004},
  pages         = {221--257},
  address       = {Berkeley, CA},
  isbn          = {978-1-59059-341-7 978-1-4302-0716-0},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Weaver, James L. and Mukhar, Kevin and Crume, Jim},
  doi           = {10.1007/978-1-4302-0716-0_6},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4302-0716-0_6},
  urldate       = {2018-06-15},
}

@InCollection{Matthews1998,
  author        = {Matthews, Iain and Bangham, J. Andrew and Harvey, Richard and Cox, Stephen},
  title         = {A comparison of active shape model and scale decomposition based features for visual speech recognition},
  booktitle     = {Computer {Vision} — {ECCV}’98},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1998},
  editor        = {Goos, G. and Hartmanis, J. and van Leeuwen, J. and Burkhardt, Hans and Neumann, Bernd},
  volume        = {1407},
  pages         = {514--528},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-64613-6 978-3-540-69235-5},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/BFb0054762},
  url           = {http://link.springer.com/10.1007/BFb0054762},
  urldate       = {2018-06-15},
}

@InCollection{Bader2008,
  author        = {Bader, Michael},
  title         = {Exploiting the {Locality} {Properties} of {Peano} {Curves} for {Parallel} {Matrix} {Multiplication}},
  booktitle     = {Euro-{Par} 2008 – {Parallel} {Processing}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Luque, Emilio and Margalef, Tomàs and Benítez, Domingo},
  volume        = {5168},
  pages         = {801--810},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-85450-0 978-3-540-85451-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-85451-7_85},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-3-540-85451-7_85},
  urldate       = {2018-06-15},
}

@InCollection{KumarPratihar2008,
  author        = {Kumar Pratihar, Tushar and Kumar Pratihar, Dilip},
  title         = {Cluster-wise {Design} of {Takagi} and {Sugeno} {Approach} of {Fuzzy} {Logic} {Controller}},
  booktitle     = {Engineering {Evolutionary} {Intelligent} {Systems}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Kacprzyk, Janusz and Abraham, Ajith and Grosan, Crina and Pedrycz, Witold},
  volume        = {82},
  pages         = {211--250},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-75395-7 978-3-540-75396-4},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-75396-4_8},
  url           = {http://link.springer.com/10.1007/978-3-540-75396-4_8},
  urldate       = {2018-06-15},
}

@InCollection{Dacal-Nieto2011,
  author        = {Dacal-Nieto, Angel and Formella, Arno and Carrión, Pilar and Vazquez-Fernandez, Esteban and Fernández-Delgado, Manuel},
  title         = {Common {Scab} {Detection} on {Potatoes} {Using} an {Infrared} {Hyperspectral} {Imaging} {System}},
  booktitle     = {Image {Analysis} and {Processing} – {ICIAP} 2011},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2011},
  editor        = {Maino, Giuseppe and Foresti, Gian Luca},
  volume        = {6979},
  pages         = {303--312},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-642-24087-4 978-3-642-24088-1},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-642-24088-1_32},
  url           = {http://link.springer.com/10.1007/978-3-642-24088-1_32},
  urldate       = {2018-06-15},
}

@InCollection{Mansor2008,
  author        = {Mansor, Sarina and Hughes, Nicholas P. and Noble, J. Alison},
  title         = {Wall {Motion} {Classification} of {Stress} {Echocardiography} {Based} on {Combined} {Rest}-and-{Stress} {Data}},
  booktitle     = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2008},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Metaxas, Dimitris and Axel, Leon and Fichtinger, Gabor and Székely, Gábor},
  volume        = {5242},
  pages         = {139--146},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-85989-5 978-3-540-85990-1},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-85990-1_17},
  url           = {http://link.springer.com/10.1007/978-3-540-85990-1_17},
  urldate       = {2018-06-15},
}

@Article{Alavi2013,
  author        = {Alavi, Amir Hossein and Gandomi, Amir Hossein and Nejad, Hadi Chahkandi and Mollahasani, Ali and Rashed, Azadeh},
  title         = {Design equations for prediction of pressuremeter soil deformation moduli utilizing expression programming systems},
  journal       = {Neural Computing and Applications},
  year          = {2013},
  volume        = {23},
  number        = {6},
  pages         = {1771--1786},
  month         = nov,
  issn          = {0941-0643, 1433-3058},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00521-012-1144-6},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s00521-012-1144-6},
  urldate       = {2018-06-15},
}

@Article{Lachapelle2007,
  author        = {Lachapelle, Gérard},
  title         = {Pedestrian navigation with high sensitivity {GPS} receivers and {MEMS}},
  journal       = {Personal and Ubiquitous Computing},
  year          = {2007},
  volume        = {11},
  number        = {6},
  pages         = {481--488},
  month         = aug,
  issn          = {1617-4909, 1617-4917},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00779-006-0094-3},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s00779-006-0094-3},
  urldate       = {2018-06-15},
}

@InCollection{Ross2003,
  author        = {Ross, Peter and Hart, Emma and Lawson, Alistair and Webb, Andrew and Prem, Erich and Poelz, Patrick and Morgavi, Giovanna},
  title         = {Requirements for {Getting} a {Robot} to {Grow} up},
  booktitle     = {Advances in {Artificial} {Life}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Banzhaf, Wolfgang and Ziegler, Jens and Christaller, Thomas and Dittrich, Peter and Kim, Jan T.},
  volume        = {2801},
  pages         = {847--856},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-20057-4 978-3-540-39432-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-39432-7_91},
  url           = {http://link.springer.com/10.1007/978-3-540-39432-7_91},
  urldate       = {2018-06-15},
}

@Article{Lu2010a,
  author        = {Lu, Peter J. and Oki, Hidekazu and Frey, Catherine A. and Chamitoff, Gregory E. and Chiao, Leroy and Fincke, Edward M. and Foale, C. Michael and Magnus, Sandra H. and McArthur, William S. and Tani, Daniel M. and Whitson, Peggy A. and Williams, Jeffrey N. and Meyer, William V. and Sicker, Ronald J. and Au, Brion J. and Christiansen, Mark and Schofield, Andrew B. and Weitz, David A.},
  title         = {Orders-of-magnitude performance increases in {GPU}-accelerated correlation of images from the {International} {Space} {Station}},
  journal       = {Journal of Real-Time Image Processing},
  year          = {2010},
  volume        = {5},
  number        = {3},
  pages         = {179--193},
  month         = sep,
  issn          = {1861-8200, 1861-8219},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11554-009-0133-1},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s11554-009-0133-1},
  urldate       = {2018-06-15},
}

@InCollection{Vukobratovic1985,
  author        = {Vukobratović, Miomir and Potkonjak, Veljko},
  title         = {Dynamic {Analysis} of {Manipulator} {Motion}},
  booktitle     = {Applied {Dynamics} and {CAD} of {Manipulation} {Robots}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1985},
  pages         = {20--149},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-642-82206-3 978-3-642-82204-9},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Vukobratović, Miomir and Potkonjak, Veljko},
  doi           = {10.1007/978-3-642-82204-9_2},
  url           = {http://www.springerlink.com/index/10.1007/978-3-642-82204-9_2},
  urldate       = {2018-06-15},
}

@InCollection{Sullivan1996,
  author        = {Sullivan, J. C. W. and Pipe, A. G.},
  title         = {Efficient {Evolution} {Strategies} for {Exploration} in mobile robotics},
  booktitle     = {Evolutionary {Computing}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1996},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Fogarty, Terence C.},
  volume        = {1143},
  pages         = {147--161},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-61749-5 978-3-540-70671-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/BFb0032780},
  url           = {http://link.springer.com/10.1007/BFb0032780},
  urldate       = {2018-06-15},
}

@InCollection{Pioro2008,
  author        = {Pióro, Michał and Śliwiński, Tomasz and Zagożdżon, Michał and Dzida, Mateusz and Ogryczak, Włodzimierz},
  title         = {Path {Generation} {Issues} for {Survivable} {Network} {Design}},
  booktitle     = {Computational {Science} and {Its} {Applications} – {ICCSA} 2008},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Gervasi, Osvaldo and Murgante, Beniamino and Laganà, Antonio and Taniar, David and Mun, Youngsong and Gavrilova, Marina L.},
  volume        = {5073},
  pages         = {820--835},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-69840-1 978-3-540-69848-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-69848-7_65},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-3-540-69848-7_65},
  urldate       = {2018-06-15},
}

@Article{Nguyen2017,
  author        = {Nguyen, Thang Trung and Nguyen, Thuan Thanh and Vo, Dieu Ngoc},
  title         = {An effective cuckoo search algorithm for large-scale combined heat and power economic dispatch problem},
  journal       = {Neural Computing and Applications},
  year          = {2017},
  month         = mar,
  issn          = {0941-0643, 1433-3058},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00521-017-2941-8},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s00521-017-2941-8},
  urldate       = {2018-06-15},
}

@InCollection{Wyss2001,
  author        = {Wyss, Catharine and Giannella, Chris and Robertson, Edward},
  title         = {{FastFDs}: {A} {Heuristic}-{Driven}, {Depth}-{First} {Algorithm} for {Mining} {Functional} {Dependencies} from {Relation} {Instances} {Extended} {Abstract}},
  booktitle     = {Data {Warehousing} and {Knowledge} {Discovery}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2001},
  editor        = {Goos, Gerhard. and Hartmanis, Juris. and van Leeuwen, Jan. and Kambayashi, Yahiko and Winiwarter, Werner and Arikawa, Masatoshi},
  volume        = {2114},
  pages         = {101--110},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-42553-3 978-3-540-44801-3},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-44801-2_11},
  shorttitle    = {{FastFDs}},
  url           = {http://link.springer.com/10.1007/3-540-44801-2_11},
  urldate       = {2018-06-15},
}

@InCollection{Harkow1996,
  author        = {Harkow, Roy},
  title         = {The {AutoLISP} {World}},
  booktitle     = {Essential {AutoLISP}®},
  publisher     = {Springer New York},
  year          = {1996},
  pages         = {5--58},
  address       = {New York, NY},
  isbn          = {978-0-387-94571-2 978-1-4612-2350-4},
  __markedentry = {[Jonnathan:6]},
  collaborator  = {Harkow, Roy},
  doi           = {10.1007/978-1-4612-2350-4_1},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4612-2350-4_1},
  urldate       = {2018-06-15},
}

@InCollection{Rantzau2004,
  author        = {Rantzau, Ralf},
  title         = {Frequent {Itemset} {Discovery} with {SQL} {Using} {Universal} {Quantification}},
  booktitle     = {Database {Support} for {Data} {Mining} {Applications}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2004},
  editor        = {Meo, Rosa and Lanzi, Pier Luca and Klemettinen, Mika},
  volume        = {2682},
  pages         = {194--213},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-22479-2 978-3-540-44497-8},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-44497-8_10},
  url           = {http://link.springer.com/10.1007/978-3-540-44497-8_10},
  urldate       = {2018-06-15},
}

@InCollection{Flauzac2003,
  author        = {Flauzac, Olivier and Krajecki, Michaël and Fugère, Jean},
  title         = {{CONFIIT}: {A} {Middleware} for {Peer} to {Peer} {Computing}},
  booktitle     = {Computational {Science} and {Its} {Applications} — {ICCSA} 2003},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Kumar, Vipin and Gavrilova, Marina L. and Tan, Chih Jeng Kenneth and L’Ecuyer, Pierre},
  volume        = {2669},
  pages         = {69--78},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-40156-8 978-3-540-44842-6},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-44842-X_8},
  shorttitle    = {{CONFIIT}},
  url           = {http://link.springer.com/10.1007/3-540-44842-X_8},
  urldate       = {2018-06-15},
}

@InCollection{Wing1991,
  author        = {Wing, Hilda},
  title         = {Selecting for {Air} {Traffic} {Control}: {The} {State} of the {Art}},
  booktitle     = {Automation and {Systems} {Issues} in {Air} {Traffic} {Control}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1991},
  editor        = {Wise, John A. and Hopkin, V. David and Smith, Marvin L.},
  pages         = {409--427},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-642-76558-2 978-3-642-76556-8},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-642-76556-8_38},
  language      = {en},
  shorttitle    = {Selecting for {Air} {Traffic} {Control}},
  url           = {http://www.springerlink.com/index/10.1007/978-3-642-76556-8_38},
  urldate       = {2018-06-15},
}

@InCollection{Dzeroski1998,
  author        = {Džeroski, Sašo and De Raedt, Luc and Blockeel, Hendrik},
  title         = {Relational reinforcement learning},
  booktitle     = {Inductive {Logic} {Programming}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {1998},
  editor        = {Goos, G. and Hartmanis, J. and van Leeuwen, J. and Carbonell, Jaime G. and Siekmann, Jörg and Page, David},
  volume        = {1446},
  pages         = {11--22},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-64738-6 978-3-540-69059-7},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/BFb0027307},
  url           = {http://link.springer.com/10.1007/BFb0027307},
  urldate       = {2018-06-15},
}

@Article{Sakurai2002,
  author        = {Sakurai, Yasushi and Yoshikawa, Masatoshi and Uemura, Shunsuke and Kojima, Haruhiko},
  title         = {Spatial indexing of high-dimensional data based on relative approximation},
  journal       = {The VLDB Journal The International Journal on Very Large Data Bases},
  year          = {2002},
  volume        = {11},
  number        = {2},
  pages         = {93--108},
  month         = oct,
  issn          = {10668888},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00778-002-0066-9},
  url           = {http://link.springer.com/10.1007/s00778-002-0066-9},
  urldate       = {2018-06-15},
}

@Article{Bailey1990,
  author        = {Bailey, David H.},
  title         = {{FFTs} in external or hierarchical memory},
  journal       = {The Journal of Supercomputing},
  year          = {1990},
  volume        = {4},
  number        = {1},
  pages         = {23--35},
  month         = mar,
  issn          = {0920-8542, 1573-0484},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/BF00162341},
  language      = {en},
  url           = {http://link.springer.com/10.1007/BF00162341},
  urldate       = {2018-06-15},
}

@InCollection{Goos2003a,
  author        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Yang, Zhenglin and Liu, Guirong},
  title         = {3D {Protein} {Peptide} {Chain} {Search} {Using} an {Improved} {Genetic} {Algorithm}},
  booktitle     = {Computational {Science} and {Its} {Applications} — {ICCSA} 2003},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Kumar, Vipin and Gavrilova, Marina L. and Tan, Chih Jeng Kenneth and L’Ecuyer, Pierre},
  volume        = {2667},
  pages         = {322--329},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-40155-1 978-3-540-44839-6},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-44839-X_35},
  url           = {http://link.springer.com/10.1007/3-540-44839-X_35},
  urldate       = {2018-06-15},
}

@Article{Grohman2004,
  author        = {Grohman, Wojciech},
  title         = {Using {Convex} {Sets} for {Exploratory} {Data} {Analysis} and {Visualization}},
  journal       = {Data Mining and Knowledge Discovery},
  year          = {2004},
  volume        = {9},
  number        = {3},
  pages         = {275--295},
  month         = nov,
  issn          = {1384-5810},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1023/B:DAMI.0000040906.82842.b5},
  language      = {en},
  url           = {http://link.springer.com/10.1023/B:DAMI.0000040906.82842.b5},
  urldate       = {2018-06-15},
}

@InCollection{Cho2003,
  author        = {Cho, Jeung-Bo and Jung, Min-Soo and Jun, Sung-Ik},
  title         = {An {Efficient} {Small} {Sized} {On}-{Card} {Verifier} for {Java} {Card}},
  booktitle     = {Computational {Science} and {Its} {Applications} — {ICCSA} 2003},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Kumar, Vipin and Gavrilova, Marina L. and Tan, Chih Jeng Kenneth and L’Ecuyer, Pierre},
  volume        = {2668},
  pages         = {552--561},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-40161-2 978-3-540-44843-3},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-44843-8_60},
  url           = {http://link.springer.com/10.1007/3-540-44843-8_60},
  urldate       = {2018-06-15},
}

@Article{Shrivastava2015,
  author        = {Shrivastava, Sourabh and Singh, Satish Kumar and Hooda, Dhara Singh},
  title         = {Color sensing and image processing-based automatic soybean plant foliar disease severity detection and estimation},
  journal       = {Multimedia Tools and Applications},
  year          = {2015},
  volume        = {74},
  number        = {24},
  pages         = {11467--11484},
  month         = dec,
  issn          = {1380-7501, 1573-7721},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s11042-014-2239-0},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s11042-014-2239-0},
  urldate       = {2018-06-15},
}

@Article{Hasanipanah2016,
  author        = {Hasanipanah, Mahdi and Noorian-Bidgoli, Majid and Jahed Armaghani, Danial and Khamesi, Hossein},
  title         = {Feasibility of {PSO}-{ANN} model for predicting surface settlement caused by tunneling},
  journal       = {Engineering with Computers},
  year          = {2016},
  volume        = {32},
  number        = {4},
  pages         = {705--715},
  month         = oct,
  issn          = {0177-0667, 1435-5663},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/s00366-016-0447-0},
  language      = {en},
  url           = {http://link.springer.com/10.1007/s00366-016-0447-0},
  urldate       = {2018-06-15},
}

@InCollection{Silva2003,
  author        = {Silva, Frutuoso G. M. and Gomes, Abel J. P.},
  title         = {{AIF} - {A} {Data} {Structure} for {Polygonal} {Meshes}},
  booktitle     = {Computational {Science} and {Its} {Applications} — {ICCSA} 2003},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Kumar, Vipin and Gavrilova, Marina L. and Tan, Chih Jeng Kenneth and L’Ecuyer, Pierre},
  volume        = {2669},
  pages         = {478--487},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-40156-8 978-3-540-44842-6},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-44842-X_49},
  url           = {http://link.springer.com/10.1007/3-540-44842-X_49},
  urldate       = {2018-06-15},
}

@InCollection{Kedlaya2008,
  author        = {Kedlaya, Kiran S. and Sutherland, Andrew V.},
  title         = {Computing {L}-{Series} of {Hyperelliptic} {Curves}},
  booktitle     = {Algorithmic {Number} {Theory}},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2008},
  editor        = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and van der Poorten, Alfred J. and Stein, Andreas},
  volume        = {5011},
  pages         = {312--326},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-79455-4 978-3-540-79456-1},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/978-3-540-79456-1_21},
  url           = {http://link.springer.com/10.1007/978-3-540-79456-1_21},
  urldate       = {2018-06-15},
}

@InCollection{Morgado2003,
  author        = {Morgado, Francisco and Gomes, Abel},
  title         = {A {Non}-uniform {Binary} {Space} {Partition} {Algorithm} for 2D {Implicit} {Curves}},
  booktitle     = {Computational {Science} and {Its} {Applications} — {ICCSA} 2003},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2003},
  editor        = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Kumar, Vipin and Gavrilova, Marina L. and Tan, Chih Jeng Kenneth and L’Ecuyer, Pierre},
  volume        = {2669},
  pages         = {418--427},
  address       = {Berlin, Heidelberg},
  isbn          = {978-3-540-40156-8 978-3-540-44842-6},
  __markedentry = {[Jonnathan:6]},
  doi           = {10.1007/3-540-44842-X_43},
  url           = {http://link.springer.com/10.1007/3-540-44842-X_43},
  urldate       = {2018-06-15},
}

@Comment{jabref-meta: databaseType:bibtex;}
