@inproceedings{20085211804750,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Scheduling in performance test environment},
journal = {SoftCom 2008: 16th International Conference on Software, Telecommuncations and Computer Networks},
author = {Bozoki, Ferenc and Csondes, Tibor},
year = {2008},
pages = {404 - 408},
address = {Split-Dubrovnik, Croatia},
abstract = {Nowadays automatic testing is getting more and more important in the telecommunication world. The sooner a fault is discovered the cheaper it is to correct it. If a fault is discovered during the development process the cost of the correction is significantly smaller. There are different test strategies, with different approaches like, Conformance Test, System Test and Performance Test. The System Test takes place after a successful Conformance Test. Performance Test is analyzing the load characteristics of the System Under Test (SUT). In this article we describe the main attributes of performance testing, where the main challenge is to generate the expected load without having as complex hardware as the SUT is itself. Most of the papers, presented in this subject are focusing on the characteristics of the generated load, but not the way how to achieve it. These papers usually have the assumption that the load can be generated by deploying more hardware resources. Other papers propose new extensions for test description languages such SDL or TTCN-3 [4]. In this article we intend to describe a Finite State Machine (FSM) based model and an algorithm which improves the efficiency of Scheduling in this Performance Test environment. We present an architecture based on the so called Virtual Threads, an algorithm to optimize the scheduling between these threads, and an example to demonstrate the algorithm.<br/>},
key = {Load testing},
keywords = {Automatic testing;Computer hardware;Computer networks;Hardware;Scheduling;Software testing;},
note = {Architecture-based;Description languages;Development process;Hardware resources;Load characteristics;Performance testing;Performance tests;System under test;},
URL = {http://dx.doi.org/10.1109/SOFTCOM.2008.4669519},
} 


@article{1995242672792,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Environmental stress testing experiment using the Taguchi method},
journal = {IEEE transactions on components, packaging, and manufacturing technology. Part A},
author = {Pachucki, Dennis E.},
volume = {18},
number = {1},
year = {1995},
pages = {3 - 9},
issn = {10709886},
abstract = {An environmental stress screening (ESS), a method for improving manufacturing process by applying stress beyond product specification detect latent defects in the product, was performed to find out the relevant stress used in the production of printed wiring boards. Three types of stress - random vibration, temperature cycling and power cycling - were emphasized. Experimental results were statistically obtained using the Taguchi design method.},
key = {Printed circuit manufacture},
keywords = {Application specific integrated circuits;Computer software;Data acquisition;Data storage equipment;Environmental testing;Microprocessor chips;Random processes;Statistical methods;Stresses;Thermal cycling;Vibrations (mechanical);},
note = {Analysis of variance;Environmental stress testing;Functional diagnostic test suite;Power cycling;Power on self test;Printed wiring board;Programmable memory chip;Random vibration;Taguchi method;Temperature cycling;},
URL = {http://dx.doi.org/10.1109/95.370727},
} 


@inproceedings{20172103685017,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling expands value of performance testing for big data applications},
journal = {ICPE 2017 - Companion of the 2017 ACM/SPEC International Conference on Performance Engineering},
author = {Zibitsker, Boris and Lupersolsky, Alex},
year = {2017},
pages = {119 - 123},
address = {L'Aquila, Italy},
abstract = {Performance testing of Big Data applications is performed typically on small test environment with limited volume of data. The results of these types of tests do not take into consideration differences between test and production hardware and software environment and contention for resources with many applications in production environments. In this paper we will review application of the modeling for extending the results of performance testing, predicting how new application will perform in production environment. We will review how modeling results can be used to evaluate different options and justify decisions during design, development, implementation and performance management of the production environment. &copy; 2017 ACM.},
key = {Big data},
keywords = {Application programs;Benchmarking;Software testing;},
note = {Big data applications;Data infrastructure;Performance assurances;Performance engineering;Performance Model;Performance prediction;Performance testing;},
URL = {http://dx.doi.org/10.1145/3053600.3053624},
} 


@inproceedings{20083111416216,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A tool for automated performance testing of Java3D applications in agile environments},
journal = {2nd International Conference on Software Engineering Advances - ICSEA 2007},
author = {Xueling, Shu and Maurer, Frank},
year = {2007},
address = {Cap Esterel, France},
abstract = {Following the agile philosophy that all core features of a system need an automated test harness, performance requirements also need such a check when they are essential for the success of a project. The purpose of this paper is to describe a tool, J3DPerfUnit, which supports automated performance testing for Java3D applications in agile environments. We elicited tool requirements from domain experts through a survey and evaluated J3DPerfUnit using code from our partner's bioinformatics project and Java3D official tutorials. The evaluation pointed out that the tool is effective in detecting performance problems and in identifying where they come from when loading/unloading a 3D object. &copy; 2007 IEEE.<br/>},
key = {Software engineering},
keywords = {Automation;},
note = {Agile environment;Automated test;Core features;Domain experts;Performance problems;Performance requirements;Performance testing;Tool requirements;},
URL = {http://dx.doi.org/10.1109/ICSEA.2007.11},
} 


@article{1999284675977,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Network application performance testing for lotus notes},
journal = {CMG Transactions},
author = {Williams, Andrew},
number = {95},
year = {1999},
pages = {49 - 64},
abstract = {As customers move toward network applications, the problem of acceptable performance and user load stresses have not evaporated. Increasingly, customers need to simulate large network user loads to measure end-to-end response time and identify potential bottlenecks. This paper presents a methodology to achieve this and details results from real applications evaluations on an OS/2 and AIX Lotus Notes 4.1 environment. In all, thirty client machines were setup in a laboratory and linked to an additional set of seventy virtual users all exercising Lotus Notes application test cases to create a user load of 100 active concurrent users. During the process the clients and servers were monitored with various tools. The paper details the process used, a sample of the results, problems found in the process, the metrics required and future directions for network performance test solutions. It will focus mostly on the method of creating large, realistic loads for Lotus Notes applications - a topic largely ignored by the testing community up to this point in time. The subject will be of interest to any owner interested in implementing a network application or client/server application or a test specialist involved in testing these type of applications.},
key = {Computer applications},
keywords = {Client server computer systems;Computer software;Computer testing;Internet;Performance;Response time (computer systems);},
note = {Lotus notes;Network application performance testing;},
} 


@inproceedings{20162102421542,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Challenges with applying performance testing methods for systems deployed on shared environments with indeterminate competing workloads: Position paper},
journal = {ICPE 2016 Companion - Companion Publication for 7th ACM/SPEC International Conference on Performance Engineering},
author = {Bondi, Andre B.},
year = {2016},
pages = {41 - 44},
address = {Delft, Netherlands},
abstract = {There is a tendency to move production environments from corporate-owned data centers to cloud-based services. Users who do not maintain a private production environment might not wish to maintain a private performance test environment either. The application of performance engineering methods to the development and delivery of software systems is complicated when the form and or parameters of the target deployment environment cannot be controlled or determined. The difficulty of diagnosing the causes of performance issues during testing or production may be increased by the presence of highly variable workloads on the target platform that compete with the application of interest for resources in ways that might be hard to determine. In particular, performance tests might be conducted in virtualized environments that introduce factors influencing customer-affecting metrics (such as transaction response time) and observed resource usage. Observed resource usage metrics in virtualized environments can have different meanings from those in a native environment. Virtual machines may suffer delays in execution. We explore factors that exacerbate these complications. We argue that these complexities reinforce the case for rigorously using software performance engineering methods rather than diminishing it. We also explore possible performance testing methods for mitigating the risk associated with these complexities.},
key = {Software testing},
keywords = {Application programs;Testing;Virtual reality;},
note = {Cloud performance;Performance engineering;Performance issues;Performance measurements;Performance testing;Production environments;Software performance engineerings;Virtualized environment;},
URL = {http://dx.doi.org/10.1145/2859889.2859895},
} 


@article{20174004236999,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Empirical study on the discrepancy between performance testing results from virtual and physical environments},
journal = {Empirical Software Engineering},
author = {Arif, Muhammad Moiz and Shang, Weiyi and Shihab, Emad},
volume = {23},
number = {3},
year = {2018},
pages = {1490 - 1518},
issn = {13823256},
abstract = {Large software systems often undergo performance tests to ensure their capability to handle expected loads. These performance tests often consume large amounts of computing resources and time since heavy loads need to be generated. Making it worse, the ever evolving field requires frequent updates to the performance testing environment. In practice, virtual machines (VMs) are widely exploited to provide flexible and less costly environments for performance tests. However, the use of VMs may introduce confounding overhead (e.g., a higher than expected memory utilization with unstable I/O traffic) to the testing environment and lead to unrealistic performance testing results. Yet, little research has studied the impact on test results of using VMs in performance testing activities. To evaluate the discrepancy between the performance testing results from virtual and physical environments, we perform a case study on two open source systems &ndash; namely Dell DVD Store (DS2) and CloudStore. We conduct the same performance tests in both virtual and physical environments and compare the performance testing results based on the three aspects that are typically examined for performance testing results: 1) single performance metric (e.g. CPU Time from virtual environment vs. CPU Time from physical environment), 2) the relationship among performance metrics (e.g. correlation between CPU and I/O) and 3) performance models that are built to predict system performance. Our results show that 1) A single metric from virtual and physical environments do not follow the same distribution, hence practitioners cannot simply use a scaling factor to compare the performance between environments, 2) correlations among performance metrics in virtual environments are different from those in physical environments 3) statistical models built based on the performance metrics from virtual environments are different from the models built from physical environments suggesting that practitioners cannot use the performance testing results across virtual and physical environments. In order to assist the practitioners leverage performance testing results in both environments, we investigate ways to reduce the discrepancy. We find that such discrepancy can be reduced by normalizing performance metrics based on deviance. Overall, we suggest that practitioners should not use the performance testing results from virtual environment with the simple assumption of straightforward performance overhead. Instead, practitioners should consider leveraging normalization techniques to reduce the discrepancy before examining performance testing results from virtual and physical environments.<br/> &copy; 2017, Springer Science+Business Media, LLC.},
key = {Software testing},
keywords = {Open source software;Open systems;Virtual reality;},
note = {Large software systems;Performance metrices;Performance metrics;Performance testing;Physical environments;Software performance;Software performance engineerings;Testing environment;},
URL = {http://dx.doi.org/10.1007/s10664-017-9553-x},
} 


@inproceedings{20090111821844,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic identification of load testing problems},
journal = {IEEE International Conference on Software Maintenance, ICSM},
author = {Jiang, Zhen Ming and Hassan, Ahmed E. and Hamann, Gilbert and Flora, Parminder},
year = {2008},
pages = {307 - 316},
address = {Beijing, China},
abstract = {Many software applications must provide services to hundreds or thousands of users concurrently. These applications must be load tested to ensure that they can function correctly under high load. Problems in load testing are due to problems in the load environment, the load generators, and the application under test. It is important to identify and address these problems to ensure that load testing results are correct and these problems are resolved. It is difficult to detect problems in a load test due to the large amount of data which must be examined. Current industrial practice mainly involves time-consuming manual checks which, for example, grep the logs of the application for error messages. In this paper, we present an approach which mines the execution logs of an application to uncover the dominant behavior (i.e., execution sequences) for the application and flags anomalies (i.e., deviations) from the dominant behavior. Using a case study of two open source and two large enterprise software applications, we show that our approach can automatically identify problems in a load test. Our approach flags &lt; 0.01% of the log lines for closer analysis by domain experts. The flagged lines indicate load testing problems with a relatively small number of false alarms. Our approach scales well for large applications and is currently used daily in practice. &copy; 2008 IEEE.<br/>},
key = {Load testing},
keywords = {Automation;Computer software maintenance;Enterprise software;Open source software;Open systems;Software testing;},
note = {Application under tests;Automatic identification;Domain experts;Execution sequences;Industrial practices;Large enterprise;Number of false alarms;Software applications;},
URL = {http://dx.doi.org/10.1109/ICSM.2008.4658079},
} 


@inproceedings{20111013722289,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A research on the torque converter performance test-bed control system},
journal = {Proceedings - International Conference on Electrical and Control Engineering, ICECE 2010},
author = {Gao, Yuanlou and Fei, Xiaoxing},
year = {2010},
pages = {3224 - 3226},
abstract = {According to the characteristics of test bed, using a motor driven program based on inverter with a speed sensor, and an eddy current dynamometer constant torsional loading scheme, it implements the stability of constant speed drive and torsional load for the torque converter test-bed, providing a good test environment for the performance test. This method is economical and practical, energy saving and environmental protective. The constant voltage-frequency ratio of frequency control method is applied in motor speed control, and a way of changing the excitation voltage to change the output torque of the eddy current dynamometer is used. The results show that the system achieve good control results. &copy; 2010 IEEE.<br/>},
key = {Electric machine control},
keywords = {Dynamometers;Eddy currents;Energy conservation;Equipment testing;Hydraulic torque converters;Software testing;Structural loads;Torque;},
note = {Constant voltage;Converter performance;Eddy current dynamometer;Excitation voltage;Motor-speed control;Performance tests;Test Environment;Torsional loadings;},
URL = {http://dx.doi.org/10.1109/iCECE.2010.787},
} 


@inproceedings{20063010030632,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Using genetic algorithms for early schedulability analysis and stress testing in real-time systems},
journal = {Genetic Programming and Evolvable Machines},
author = {Briand, Lionel C. and Labiche, Yvan and Shousha, Marwa},
volume = {7},
number = {2},
year = {2006},
pages = {145 - 170},
issn = {13892576},
abstract = {Reactive real-time systems have to react to external events within time constraints: Triggered tasks must execute within deadlines. It is therefore important for the designers of such systems to analyze the schedulability of tasks during the design process, as well as to test the system's response time to events in an effective manner once it is implemented. This article explores the use of genetic algorithms to provide automated support for both tasks. Our main objective is then to automate, based on the system task architecture, the derivation of test cases that maximize the chances of critical deadline misses within the system; we refer to this testing activity as stress testing. A second objective is to enable an early but realistic analysis of tasks' schedulability at design time. We have developed a specific solution based on genetic algorithms and implemented it in a tool. Case studies were run and results show that the tool (1) is effective at identifying test cases that will likely stress the system to such an extent that some tasks may miss deadlines, (2) can identify situations that were deemed to be schedulable based on standard schedulability analysis but that, nevertheless, exhibit deadline misses.},
key = {Genetic algorithms},
keywords = {Real time systems;Scheduling;Stress analysis;Systems analysis;},
note = {Critical deadline;Schedulability theory;Software verification and validation;System task architecture;},
URL = {http://dx.doi.org/10.1007/s10710-006-9003-9},
} 


@inproceedings{2004528742400,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of a microturbine generator set with twin rotating disk regenerators},
journal = {Proceedings of the ASME Turbo Expo 2004},
author = {Chiang, Hsiao-Wei D. and Wang, Chun-Hao and Hsu, Chih-Neng},
volume = {6},
year = {2004},
pages = {37 - 44},
address = {Vienna, Austria},
abstract = {An investigation was conducted to study the performance of a 150 kW microturbine generator set with twin rotating disk regenerators, including testing and analyses. Originally designed as a vehicular microturbine engine, twin rotating ceramic disk regenerators were used to dramatically improve fuel consumption by transferring heat energy from the exhaust gas stream to compressor discharge. This microturbine engine consists of a gasifier assembly, a power turbine, a combustor, a regenerator system, a reduction and accessory drive gearbox, and a fuel management system. Because the microturbine engine did not come with the necessary start and control system (including electronic engine control unit), a start sequence was successfully developed and a manual control system installed. This paper reports on testing of the microturbine generator set at different load conditions using load banks. As a parallel effort, a software program was used to predict the performance of the microturbine generator set at different operating conditions in order to compare with the test results.},
key = {Turbines},
keywords = {Control systems;Disks (machine components);Gas generators;Mechanical testing;Performance;Regenerators;Rotors;Shafts (machine components);},
note = {Combined heat and power (CHP);Microturbine generators;Rotating disk regenerators;Vehicular microturbine engine;},
} 


@inproceedings{1993081001700,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stress testing a non-existent application tools, methods, and results},
journal = {CMG Proceedings},
author = {Brey, Jack},
year = {1992},
pages = {520 - 529},
address = {Reno, NV, USA},
abstract = {How do you test an application that doesn't exist yet? How do you make an architectural decision when there are no similar applications in production anywhere? This case study covers the decision making process, the tools selected, the test plan, and the test results of an analysis used to choose between the use of a CASE tool and ACMS for a proposed application. The study involved use of both an analytic model and a benchmarking tool to establish the saturation point of a VAX 9000 under each alternative. The paper will discuss creation of the models, the results of the modeling activities, and the criteria that went into the actual decision.},
key = {Computer software},
keywords = {Decision theory;Testing;},
note = {Software development;},
} 


@inproceedings{20142417826528,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A web automation testing framework over cloud},
journal = {Applied Mechanics and Materials},
author = {Chen, Min Gang and Zhong, Wen Bin and Chen, Wen Jie and Hu, Yun and Cai, Li Zhi},
volume = {556-562},
year = {2014},
pages = {6149 - 6153},
issn = {16609336},
address = {Shanghai, China},
abstract = {With the increasingly fast-paced software releasing or updating, research on the method of an efficient software automation testing framework based on cloud computing has become particularly important. In this paper, we propose an automation testing framework over cloud. We also describe some key technologies in the aspect of the design of hierarchical test case and automatic distribution of test cases in the cloud computing environment. Testing experiments show that our framework can take advantage of on-demand testing resources in the cloud to improve the efficiency of automation testing. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Software testing},
keywords = {Automation;Cloud computing;Computer systems;Information technology;},
note = {Automation testing;Cloud computing environments;Cloud testing;Key technologies;Software automation;TaaS;Testing resources;Web automation;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.556-562.6149},
} 


@inproceedings{20120114656330,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The research and design of NSL-oriented automation testing framework},
journal = {Advances in Intelligent and Soft Computing},
author = {Wang, Chongwen},
volume = {128},
year = {2011},
pages = {367 - 373},
issn = {18675662},
abstract = {By analyzing the Selenium and other open source testing tool, the lack of Selenium and the design of testing scripts are given to discuss and try to improve to resolve problems of NLS. These improvements include the using of page elements, enhancement of the response of the heavyweight component, optimization of testing scripts for multi-language versions. The parallel execution strategy for multilingual test cases has been provided, through which the users can execute test cases of multi-language in a great number of test servers at the same time, greatly improving the overall testing efficiency. The testing framework proposed has been applied to the actual web product globalization testing, and achieved very good results. &copy; Springer-Verlag Berlin Heidelberg 2011.<br/>},
key = {Open source software},
keywords = {Selenium;},
note = {Automation testing;Multi languages;Open sources;Parallel executions;Test case;Testing efficiency;Testing framework;Testing tools;},
URL = {http://dx.doi.org/10.1007/978-3-642-25989-0_60},
} 


@article{20173804193684,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Rational decision framework for designing pile-load test programs},
journal = {Geotechnical Testing Journal},
author = {Najjar, S. and Saad, G. and Abdallah, Y.},
volume = {40},
number = {2},
year = {2017},
pages = {302 - 316},
issn = {01496115},
abstract = {There is currently an inconsistency in the recommendations that are available in pile-design codes and practices regarding the required number of proof-load tests and the level of the proof loads for piles. In this paper, a pre-posterior decision-making framework is proposed to allow for selecting the optimal pile-load test program that would result in the maximum expected benefit to a project, while maintaining a target level of reliability in the pile design at the site. This proposed methodology is original, practical, and is based on site-specific information that is unique to any given project. The proposed methodology is based on a robust Bayesian approach that allows for updating the capacity distribution of piles at a site, given the results of the proof-load test program. The efficiency of the proposed decision framework is demonstrated by applying it on a practical design example that involves piles that are driven in a site consisting of medium-dense sand. Results indicate that: (1) the optimum proof-load level that results in the maximum benefit to the example project is 1.5 times the design load, (2) the optimum number of tests is a function of the number of piles (superstructure load) and the costs of the pile construction and testing, (3) as the number of piles in the site increases, the optimal required number of proof-load tests also increase, with the optimum number of pile-load tests being around 1 % to 2 % of the total number of piles at the site, and (4) the optimal number of pile-load tests increases as the cost of pile construction and installation increases and as the cost of implementing the pile test program decreases. Copyright &copy; 2017 by ASTM International.},
key = {Piles},
keywords = {Bayesian networks;Costs;Decision making;Decision theory;Load testing;Reliability;Reliability analysis;Software testing;Statistical tests;Test facilities;Testing;},
note = {Bayesian approaches;Capacity distribution;Decision framework;Decision-making frameworks;Deep foundations;Field testing;Pile test program;Site-specific information;},
URL = {http://dx.doi.org/10.1520/GTJ20160088},
} 


@inproceedings{20152701007652,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {PLeTsPerf - A Model-Based Performance Testing Tool},
journal = {2015 IEEE 8th International Conference on Software Testing, Verification and Validation, ICST 2015 - Proceedings},
author = {Rodrigues, Elder and Bernardino, Maicon and Costa, Leandro and Zorzo, Avelino and Oliveira, Flavio},
year = {2015},
pages = {Graz University of Technology (TU Graz); IEEE Computer Society - },
address = {Graz, Austria},
abstract = {Performance testing is a highly specialized task, since it requires that a performance engineer knows the application to be tested, its usage profile, and the infrastructure where it will execute. Moreover, it requires that testing teams expend a considerable effort and time on its automation. In this paper, we present the PLeTsPerf, a model-based performance testing tool to support the automatic generation of scenarios and scripts from application models. PLetsPerf is a mature tool, developed in collaboration with an IT company, which has been used in several works, experimental studies and pilot studies. We present an example of use to demonstrate the process of generating test scripts and scenarios from UML models to test a Web application. We also present the lessons learned and discuss our conclusions about the use of the tool.<br/> &copy; 2015 IEEE.},
key = {Software testing},
keywords = {Model checking;Unified Modeling Language;},
note = {Application models;Automatic Generation;Model based testing;Model-based OPC;Performance testing;Pilot studies;Testing tools;WEB application;},
URL = {http://dx.doi.org/10.1109/ICST.2015.7102628},
} 


@inproceedings{20082111274878,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {CROWNBench: A grid performance testing system using customizable synthetic workload},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Yang, Xing and Li, Xiang and Ji, Yipeng and Sha, Mo},
volume = {4976 LNCS},
year = {2008},
pages = {190 - 201},
issn = {03029743},
address = {Shenyang, China},
abstract = {The Grid middleware must be developed iteratively and incrementally, so Grid performance testing is critical for middleware developers of Grid system. Considering the special characters of Grid system, in order to gain meaningful and comprehensive results of performance testing, it is necessary to implement testing on real Grid environment with various types of workload. CROWNBench, as described in this paper, is a system for helping Grid middleware developers to evaluate middleware design and implement using customizable synthetic workload. Middleware developers can customize testing workload basing on the model of Grid workload derived from real workload traces, including its structure and parameters, and then workload is synthesized automatically and contained jobs will be submitted by CROWNBench in a distributed manner. CROWNBench defines several metrics for measuring Grid performance as automatic testing results. The experiment, which used CROWNBench to test the performance of Grid system with CROWN Grid middleware, shows that the system already finished have accomplished its prospective goal. It can implement Grid performance testing in an efficient, flexible, controllable, replayable and automatic way to help middleware developers evaluate and improve their products effectively. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Software testing},
keywords = {Grid computing;Middleware;Parameter estimation;Problem solving;Software design;},
note = {CROWNBench;Grid performance;Performance testing;Synthetic workloads;},
URL = {http://dx.doi.org/10.1007/978-3-540-78849-2_21},
} 


@article{20160101744936,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Combining genetic algorithms and constraint programming to support stress testing of task deadlines},
journal = {ACM Transactions on Software Engineering and Methodology},
author = {Di Alesio, Stefano and Briand, Lionel C. and Nejati, Shiva and Gotlieb, Arnaud},
volume = {25},
number = {1},
year = {2015},
issn = {1049331X},
abstract = {Tasks in real-time embedded systems (RTES) are often subject to hard deadlines that constrain how quickly the system must react to external inputs. These inputs and their timing vary in a large domain depending on the environment state and can never be fully predicted prior to system execution. Therefore, approaches for stress testing must be developed to uncover possible deadline misses of tasks for different input arrival times. In this article, we describe stress-test case generation as a search problem over the space of task arrival times. Specifically, we search for worst-case scenarios maximizing deadline misses, where each scenario characterizes a test case. In order to scale our search to large industrial-size problems, we combine two state-of-the-art search strategies, namely, genetic algorithms (GA) and constraint programming (CP). Our experimental results show that, in comparison with GA and CP in isolation, GA+CP achieves nearly the same effectiveness as CP and the same efficiency and solution diversity as GA, thus combining the advantages of the two strategies. In light of these results, we conclude that a combined GA+CP approach to stress testing is more likely to scale to large and complex systems. 2015 Copyright is held by the owner/author(s).<br/>},
key = {Genetic algorithms},
keywords = {Computer programming;Constraint theory;Embedded systems;Interactive computer systems;Real time systems;Software testing;},
note = {Constraint programming;Environment state;Real-time embedded systems;Search strategies;Search-based software testing;Stress Testing;Task deadline;Worst case scenario;},
URL = {http://dx.doi.org/10.1145/2818640},
} 


@inproceedings{20093912331518,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing based on test-driven development for mobile applications},
journal = {Proceedings of the 3rd International Conference on Ubiquitous Information Management and Communication, ICUIMC'09},
author = {Kim, Heejin and Choi, Byoungju and Yoon, Seokjin},
year = {2009},
pages = {612 - 617},
address = {Suwon, Korea, Republic of},
abstract = {Due to the tight schedule of product development for mobile applications and lack of performance testing methods, the product-oriented performance testing that is mostly done in the end of the development shows problems such as identifying a cause of detected faults, tracking down and modifying the faults when faults occur. The importance of testing is emphasized in TDD and the automated test framework is supported for efficient software development with unit tests. In this paper, we propose the methods of performance testing based on test-driven development with regard to non-functional factors as well as functionality of software during the software development process by advancing performance testing to the development stage and introduce a testing tool that assists performance testing on software development phase. It provides automation of test case generation and test execution at unit test level. It will eventually improve the development productivity as well as the reliability and quality of mobile applications by reducing the time and cost to execute tests in the process of the entire mobile applications development and helping to detect faults. Copyright 2009 ACM.<br/>},
key = {Software testing},
keywords = {Computer programming;Information management;Mobile computing;Software design;},
note = {Development productivity;Development stages;Mobile applications;Mobile applications development;Performance testing;Software development process;Test case generation;Test driven development;},
URL = {http://dx.doi.org/10.1145/1516241.1516349},
} 


@inproceedings{20152500949640,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Practical end-to-end performance testing tool for high speed 3G-based networks},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Shinbo, Hiroyuki and Tagami, Atsushi and Ano, Shigehiro and Hasegawa, Toru and Suzuki, Kenji},
volume = {6435},
year = {2010},
pages = {205 - 220},
issn = {03029743},
address = {Natal, Brazil},
abstract = {High speed IP communication is a killer application for 3rd generation (3G) mobile systems. Thus 3G network operators should perform extensive tests to check whether expected end-to-end performances are provided to customers under various environments. An important objective of such tests is to check whether network nodes fulfill requirements to durations of processing packets because a long duration of such processing causes performance degradation. This requires testers (persons who do tests) to precisely know how long a packet is hold by various network nodes. Without any tool&rsquo;s help, this task is time-consuming and error prone. Thus we propose a multi-point packet header analysis tool which extracts and records packet headers with synchronized timestamps at multiple observation points. Such recorded packet headers enable testers to calculate such holding durations. The notable feature of this tool is that it is implemented on off-the shelf hardware platforms, i.e., lap-top personal computers. The key challenges of the implementation are precise clock synchronization without any special hardware and a sophisticated header extraction algorithm without any drop<br/> &copy; IFIP International Federation for Information Processing 2010.},
key = {Software testing},
keywords = {3G mobile communication systems;Computer hardware;Hardware;Mechanical clocks;Personal computers;Synchronization;Technology transfer;},
note = {Clock Synchronization;End-to-end performance;Header extraction;IP communications;Killer-application;Off-the-shelf hardwares;Packet header;Performance degradation;},
} 


@inproceedings{20143518112883,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and implementation of automation testing framework based on keyword driven},
journal = {Applied Mechanics and Materials},
author = {He, Zhong Hai and Zhang, Xiang and Zhu, Xiang Yin},
volume = {602-605},
year = {2014},
pages = {2142 - 2146},
issn = {16609336},
address = {Chongqing, China},
abstract = {For the purpose of settling problems in the present automated testing frameworks, the paper presents an automated testing framework based on keyword driven technology. At first, it summarized and analyzed the recent automated testing frameworks; and then it proposed the framework's system architecture, and also presented the key technology details of the framework. At last, this paper compared this paper's framework with the recent frameworks by the IP phone, which proved that this framework had superiority in reducing the scale of test scripts, raising the overall efficiency of testing and so on. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Software testing},
keywords = {Materials;Mechanics;},
note = {Automated testing;Automation testing;Design and implementations;Key technologies;Keyword driven;Overall efficiency;System architectures;Test scripts;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.602-605.2142},
} 


@inbook{20172403758303,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Study on the Establishment of Dynamic Performance Test Environment for the Digital Protective Relay using RTDS},
journal = {Power Plants and Power Systems Control 2006},
author = {Jang, ByungTae and Choe, ChangYoul and Jung, GilJo},
year = {2007},
pages = {143 - 146},
abstract = {This chapter presents a study on the establishment of dynamic performance test environment for the digital protective relay using real time digital simulator (RTDS). A performance test of digital protective relay is divided into three parts, which include a static test, a dynamic test, and EMC test. Among these, a dynamic test the most important, but it is not easy to diffuse a technique for dynamic test because of the intricate approach to real time digital simulator. To solve these problems, Korea Electric Power Research Institute (KEPRI) has established environments for performance test, which consist of a system model and a performance test procedure for the dynamic test. Differing from the general test equipment, RTDS has a strong point to examine real time close-loop test. Since users should articulately use both software (PSCAD) and hardware (RTDS), it is difficult for the users to access a dynamic performance test. The system modeling was performed by using equivalent impedance data of transmission line, equivalent impedance data of bus, and no load loss data of transformer. When carrying out performance test of the digital protective relay by using RTDS in domestic and overseas organizations, engineers can utilize this procedure for examining reliability and propriety in terms of the result of performance verification test. &copy; 2007 Elsevier Ltd All rights reserved.},
key = {Software testing},
keywords = {Electric fault currents;Electromagnetic compatibility;Equipment testing;Equivalent circuits;Mechanisms;Relay protection;},
note = {Digital protective relay;Dynamic performance tests;Equivalent impedance;Korea electric power research institutes;Performance tests;Performance verification;Real time digital simulator;Test equipments;},
URL = {http://dx.doi.org/10.1016/B978-008046620-0/50024-4},
} 


@inproceedings{20094512426132,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Ultraviolet through infrared imager performance testing},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Mazzetta, Jason A. and Scopatz, Stephen D.},
volume = {7481},
year = {2009},
pages = {SPIE Europe - },
issn = {0277786X},
address = {Berlin, Germany},
abstract = {The objective of any imaging system is to optimize the amount of pertinent information collected from a scene. Whether it is used for artistic reproduction, scientific research, or camouflage detection, a camera has the same ultimate requirement. In the era of broadband, multi-spectral, hyperspectral, and fused sensor systems, both spectral and spatial data continue to play battling roles in determining which is dominant in how well an imaging system meets its definitive objective. Typically sensor testing requires hardware and software exclusively designed for the spectral region of interest. Thus an imaging system with ultraviolet through infrared imaging capabilities could require three or more separate test benches for sensor characterization. Obviously this not only increases the complexity, and subsequently the cost of testing, but also more importantly tends to produce discontinuous results. This paper will outline the hardware and software developed by the authors that employ identical test methods and shared optics to complete infrared, visible, and ultraviolet sensor performance analysis. Challenges encompassing multiple emitting source switching, splitting, and combining will be addressed along with new single fused type source designs. Decisions related to specifying optics and targets of sufficient quality and construction to provide coverage of the full spectral region will be discussed along with sample performance specifications and data. Test methodology controlled by a single automated software suite will be summarized including modulation transfer function, signal to noise ratio, uniformity, focus, distortion, intrascene dynamic range, and sensitivity. Selected examples of results obtained by this test set will be presented. &copy; 2009 SPIE.<br/>},
key = {Signal to noise ratio},
keywords = {Hardware;Hyperspectral imaging;Image segmentation;Imaging systems;Infrared devices;Infrared radiation;Optics;Software testing;Testing;Thermography (imaging);},
note = {Blackbody;Integrating spheres;Multi-spectral;Ultraviolet;Visible;},
URL = {http://dx.doi.org/10.1117/12.830536},
} 


@inproceedings{20165203175826,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Virtual instrumentation for no-load testing of induction motor},
journal = {Proceedings - 2016 IEEE International Power Electronics and Motion Control Conference, PEMC 2016},
author = {Subtirelu, Gheorghe-Eugen and Dobriceanu, Mircea and Linca, Mihaita},
year = {2016},
pages = {854 - 859},
address = {Varna, Bulgaria},
abstract = {The main objective of this paper is to solve a practical and current problem, by taking advantage of the virtual instrumentation in testing electrical machines. The abilities of virtual instrumentation are used to data acquisition, measurement and analyze the values of no-load testing's parameters for three-phase induction motor. The virtual measurement system bench is designed and consist from two principal components: the hardware components (six LEM transducers for measuring three voltages and three currents; elements for signal conditioning and power transducers; USB multifunction Input / Output module; a personal computer) and the software components (operating system for the computer; drivers for the acquisition and manipulation of data; virtual instrument for calculation and graphical presentation of results). The LabVIEW graphical programming environment is used for designing virtual instrument. This virtual measurement system bench is an easy to use device which can be used in engineering education laboratories from universities or in electrical machines testing workbenches; it is capable of data acquisition, storage or memorization on different media, visualization of different graphs or analysis on-line or off-line of the results obtained. The virtual measurement system described in the paper can work independently (in the Simulation mode or Real time Acquisition mode) or integrated as part of a future complex virtual system for measurement and analysis in the domain of electrical machines testing workbenches. &copy; 2016 IEEE.},
key = {Electric variables measurement},
keywords = {Automobile engines;Computer graphics;Computer hardware;Computer operating systems;Data acquisition;Data visualization;Digital instruments;Digital storage;Distance education;Electric machinery;Induction motors;Load testing;Motion control;Personal computers;Power control;Power electronics;Transducers;},
note = {Graphical presentations;Labview graphical programming;Measurement and analysis;Principal Components;Real time acquisition;Three phase induction motor;Virtual Instrumentation;Virtual measurement system;},
URL = {http://dx.doi.org/10.1109/EPEPEMC.2016.7752106},
} 


@article{20144700216949,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Axis geometrical errors analysis through a performance test to evaluate kinematic error in a five axis tilting-rotary table machine tool},
journal = {Precision Engineering},
author = {Alessandro, Velenosi and Gianni, Campatelli and Antonio, Scippa},
volume = {39},
year = {2015},
pages = {224 - 233},
issn = {01416359},
abstract = {Geometrical work piece errors in milling process are commonly generated by different error sources. Axis geometrical errors, such as the straightness error for linear axis and the offset location error of the origin of rotary axis, introduce kinematic error in the tool path. Direct measurement of kinematic error requires special devices such as laser interferometers, grid plate encoders or double ball bars, which impose production stop and specialized staff. These problems could be analyzed using indirect measurements obtained by means of a cutting performance test that is already a standard for three axis machine tools. Because of the different architectures of five-axis milling machines these tests are hardly standardizable, therefore this paper proposes a devised easy-to-use and time efficient cutting performance test to identify and quantify axis geometrical errors for a five axis tilting-rotary table machine tool. This test can be performed as a periodical checkup or, in case of production, as a re-start test. The main goal of this study is to develop a kinematic analytical model capable of correlating the work-piece geometrical errors to the axis geometrical errors of the machine tool. The model has been implemented on a multi-body software in order to simulate the axes motion sequence of the performance test and validated to decouple the kinematic error into the geometrical axis errors. The developed models have demonstrated to be capable of correcting a generic five axis tool path by predicting the tool-path error displacement. The overall validation of this approach has been carried out by comparing the simulated and experimentally measured profile of the NAS 979 standard five axis contouring cone frustum profile.<br/> &copy; 2014 Elsevier Inc.},
key = {Errors},
keywords = {Cutting tools;Geometry;Interferometers;Kinematics;Laser interferometry;Machine tools;Milling (machining);Milling machines;Software testing;Testing;},
note = {Accuracy;Cutting test;Different architectures;Five-axis machine tools;Indirect measurements;Kinematic error;Laser interferometer;Straightness errors;},
URL = {http://dx.doi.org/10.1016/j.precisioneng.2014.09.007},
} 


@inproceedings{20124415618550,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A novel approach of automation testing on mobile devices},
journal = {2012 International Conference on Computer and Information Science, ICCIS 2012 - A Conference of World Engineering, Science and Technology Congress, ESTCON 2012 - Conference Proceedings},
author = {Nagowah, Leckraj and Sowamber, Gayeree},
volume = {2},
year = {2012},
pages = {924 - 930},
address = {Kuala Lumpur, Malaysia},
abstract = {Mobile phones and mobile applications have now become an integral part of our everyday life. Mobile application testing plays a pivotal role in making the mobile applications more reliable and defect free. Existing test automation tools have been tailored to perform mobile test automation through mobile emulators. Other tools require the mobile device where the application is installed, to be connected to a computer so that the tests can be run. Obviously, the results obtained from emulators often differ from those obtained on actual mobile devices. To our best knowledge only a few solutions for creating automated tests of mobile applications exist and their functionality is very limited. In this paper, we introduce the idea of implementing a mobile test automation framework MobTAF which performs mobile test automation on the mobile device where connection to a computer is not required. The framework moves the testing infrastructure to the phone, to support test situations that cannot easily be replicated with an emulator. A prototype application was then implemented to test the mobile automation framework, MobTAF. The results prove that MobTAF framework is an efficient way of performing mobile application tests directly on the mobile devices. &copy; 2012 IEEE.<br/>},
key = {Software testing},
keywords = {Application programs;Automation;Mobile computing;Mobile devices;Telephone sets;},
note = {Automation testing;Mobile application testing;Mobile applications;Mobile device test automations;Mobile test automation frameworks;Mobile testing;Test automation tool;Testing infrastructure;},
URL = {http://dx.doi.org/10.1109/ICCISci.2012.6297158},
} 


@inproceedings{20132016337943,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The research of performance test method for Linux process scheduling},
journal = {Proceedings of the 2012 4th International Symposium on Information Science and Engineering, ISISE 2012},
author = {Lan, Yuqing and Xu, Hao and Liu, Xiaohui},
year = {2012},
pages = {216 - 219},
address = {Shanghai, China},
abstract = {Performance test plays a fundamental and irreplaceable role in the field of software test, especially in guaranteeing the quality and reliability of an operating system. The performance of the process scheduling subsystem directly affects the accuracy and stability of the whole operating system. Linux operating system vendors execute performance test almost in every period of the Linux operating system research and development to enhance their products' competitiveness. However, the lack of methods and tools for the Linux process scheduling performance test has caused great difficulties for Linux operating system vendors to evaluate and tune the Linux kernel performance. Therefore, in order to solve the issues mentioned above, this paper, based on the analysis of Linux process scheduling mechanism, proposes a Linux process scheduling performance test method, implements a Linux process scheduling performance test tool as well, and finally validates the tool experimentally. &copy; 2012 IEEE.},
key = {Computer operating systems},
keywords = {Benchmarking;Competition;Information science;Scheduling;Software reliability;Software testing;},
note = {Benchmark tests;linux;Performance analysis;Performance testing;Process scheduling;},
URL = {http://dx.doi.org/10.1109/ISISE.2012.54},
} 


@article{20080111005563,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {BES III offline software system and performance test},
journal = {Hedianzixue Yu Tance Jishu/Nuclear Electronics and Detection Technology},
author = {Sun, Yong-Zhao and Li, Wei-Dong and Mao, Ze-Pu and Ma, Qiu-Mei and Ma, Xiang and Wang, Liang-Liang and Wang, Ji-Ke and Deng, Zi-Yan and You, Zheng-Yun and Wen, Shuo-Pin and Bian, Jian-Ming and Sun, Sheng-Sen and Zhu, Yong-Sheng and Liu, Huai-Min and Liu, Chun-Xiu and Wu, Ling-Hui and Li, Hai-Bo and Li, Gang and Zhang, Chang-Chun and Zhang, Ling and Zhang, Yao and Zhang, Xue-Yao and Zhang, Jian-Yong and Zou, Jia-Heng and Qiu, Jin-Fa and He, Miao and He, Kang-Lin and Ji, Xiao-Bin and Yang, Ming and Yuan, Chang-Zheng and Mao, Ya-Jun and Yu, Guo-Wei and Mo, Xiao-Hu and Yuan, Ye and Cao, Guo-Fu and Huang, Bin and Xie, Yu-Guang and Zang, Shi-Lei},
volume = {27},
number = {5},
year = {2007},
pages = {842 - 846},
issn = {02580934},
abstract = {The offline software for the BESIII experiment and the control flow for data processing are described. With the software tool, Tuning and Analysis Utilities (TAU), its system performance has been measured. The BESIII computing requirements have been re-estimated and results are consistent with the previous calculation in the BESIII Technical Design Report.},
} 


@inproceedings{20114014398894,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Recent successes and changes of the HPCMP sustained systems performance test},
journal = {Proceedings - 2010 DoD High Performance Computing Modernization Program Users Group Conference, HPCMP UGC 2010},
author = {Bennett, Paul M. and Brown, Laura L.},
year = {2011},
pages = {453 - 462},
address = {Schaumburg, IL, United states},
abstract = {The sustained systems performance (SSP) test has been implemented on certain High Performance Computing Modernization Program (HPCMP) HPC systems in order to quantitatively evaluate updates to system software, hardware repairs, job queuing policy modifications, and revisions to the job scheduler as necessary. The test employs codes used in the system acquisition cycle with proven migration capability to HPCMP HPC systems and non-empirical tests for numerical accuracy. Metrics such as compilation time, queue wait time, benchmark execution time, and total test throughput time are gathered and compared against metric data from previous tests to monitor the systems under test while minimizing impact to the users. Jobs failing to execute properly or in anomalously short or long times are investigated, and the results are reported to system administrators and center directors at each center for appropriate actions. During the past year, the SSP test has been instrumental in surfacing configuration issues with the PBS scheduler and performance issues on several HPC systems. Additionally, the frequency of the SSP test on systems procured in Technology Insertion 2009 (TI-09) and thereafter has increased, with attendant changes in the test cases comprising the test. The SSP test continues to play an important role in monitoring the quality of service delivering HPC to HPCMP users at the system, DoD Supercomputing Resource Center, and vendor levels. &copy; 2011 IEEE.<br/>},
key = {Software testing},
keywords = {Modernization;Quality of service;Scheduling;},
note = {High performance computing modernization programs;Numerical accuracy;Performance issues;Sustained systems;System acquisition;System administrators;Systems under tests;Technology insertion;},
URL = {http://dx.doi.org/10.1109/HPCMP-UGC.2010.46},
} 


@article{20071210503114,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Study on APU performance test based on virtual instrument technology},
journal = {Beijing Ligong Daxue Xuebao/Transaction of Beijing Institute of Technology},
author = {Zhang, Bao-Gang and Cheng, Xi-Ming},
volume = {26},
number = {SUPPL. 2},
year = {2006},
pages = {26 - 30},
issn = {10010645},
abstract = {The dynamic performance test of the auxiliary power unit (APU) is built on virtual instrument (VI) to evaluate its controls applied on the series hybrid electric vehicle. And its test method is presented. This test system is developed on a PCI-DAQ board and an industrial PC as its hardware basis and the graphical programming environment LabVIEW as its software platform, on which signals of the engine ECU and multi-sensor are adopted, adjusted, filtered, stored and processed to analyze the control performance of the APU. This test data shoud that the VI method is proved exact for the APU control system in practice.},
key = {Electric vehicles},
keywords = {Analog to digital conversion;Data acquisition;Dynamics;Hardware;Sensors;Software design;},
note = {Auxiliary power unit (APU);Graphical programming environment Lab VIEW;Human machine interface;PCI-DAQ board;Test system;Virtual instrument (VI);},
} 


@article{20101912923286,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Dynamic GPS receiver carrier-wave Doppler analysis and loop tracking performance test},
journal = {Beijing Ligong Daxue Xuebao/Transaction of Beijing Institute of Technology},
author = {Li, Jie and Shen, Qiang and Tang, Wan-Ling and Zhao, Hong-Juan and Peng, Hong-Sheng},
volume = {30},
number = {2},
year = {2010},
pages = {136 - 139},
issn = {10010645},
abstract = {Against the problem that the ordinary GPS receiver can not work normally under the dynamic conditions of the cannon-launched guided ammunition, this paper adopts SPIRENT satellite signal simulator to analyze the carrier-wave Doppler frequency and its variation rate under several dynamic conditions, and generate the satellite signal under different dynamic status conditions of the carrier. A software receiver is utilized to perform the test to analyze on the performances of the tracking loop adopting the second-order and third-order phase-locked loops (PLL), the second-order PLL assisted by the first-order frequency-locked loop (FLL), and the third-order PLL assisted by the second-order FLL. It shows that when the acceleration is 40g, only PLL will lose lock, while the PLL assisted by the FLL tracks normally. However, in ballistic environment, the second-order PLL assisted by the first-order FLL tracks normally by one channel, the third-order PLL assisted by the second-order FLL tracks normally by two channels. This paper puts forward an improvement proposal for the carrier-wave tracking loop.<br/>},
key = {Global positioning system},
keywords = {Doppler effect;Locks (fasteners);Phase locked loops;Satellites;Signal receivers;Software testing;},
note = {Carrier waves;Doppler frequency shift;Dynamic condition;First-order frequency;GPS receivers;Satellite signals;Software receivers;Tracking performance;},
} 


@inproceedings{20134416937199,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research on DB2 performance testing automation},
journal = {Advanced Materials Research},
author = {Zhuang, Lei and Gao, Zhen and Wu, Hao and Yang, Chun Xin and Zheng, Miao},
volume = {756-759},
year = {2013},
pages = {2204 - 2208},
issn = {10226680},
address = {Nanjing, Jiangsu, China},
abstract = {Software testing play a significant role in modern software development and maintenance process, which is also an important means to ensure software reliability and improve software quality. With the continuous improvement of quality requirements of the software products and software engineering technology become more sophisticated, software testing has been participating into every phase of software lift cycle, become more and more important in software development and maintenance. DB2 Performance testing consists of four parts, which are environment setup, workload run, data measurement and environment clean up. Before all the operations are done manually and need about two hours' continuous attention. What's worse, even three times a day. This mechanical and complicated procedure is clearly unacceptable. This paper put forward a reusable automated testing framework based on IBM automated testing tools RFT to achieve the whole testing procedure automation. It reduces the count of human-computer interaction and greatly improves the efficiency of DB2 performance testing. &copy; (2013) Trans Tech Publications, Switzerland.},
key = {Information technology},
keywords = {Computer software selection and evaluation;Maintenance;Materials science;Software design;Software testing;},
note = {Automated testing;Automated testing tools;Continuous improvements;Performance testing;Quality requirements;RFT;Software development and maintenances;Testing framework;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMR.756-759.2204},
} 


@inproceedings{20102913088766,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A methodology to support load test analysis},
journal = {Proceedings - International Conference on Software Engineering},
author = {Malik, Haroon},
volume = {2},
year = {2010},
pages = {421 - 424},
issn = {02705257},
address = {Cape Town, South africa},
abstract = {Performance analysts rely heavily on load testing to measure the performance of their applications under a given load. During the load test, analyst strictly monitor and record thousands of performance counters to measure the run time system properties such as CPU utilization, Disk I/O, memory consumption, network traffic etc. The most frustrating problem faced by analysts is the time spent and complexity involved in analysing these huge counter logs and finding relevant information distributed across thousands of counters. We present our methodology to help analysts by automatically identifying important performance counters for load test and comparing them across tests to find performance gain/loss. Further, our methodology help analysts to understand the root cause of a load test failure by finding previously solved problems in test repositories. A case study on load test data of a large enterprise application shows that our methodology can effectively guide performance analysts to identify and compare top performance counters across tests in limited time thereby archiving 88% counter data reduction. &copy; 2010 ACM.<br/>},
key = {Principal component analysis},
keywords = {Automation;Load testing;Radiation counters;Software engineering;Testing;},
note = {CPU utilization;Large enterprise;Memory consumption;Network traffic;Performance counters;Performance Gain;Run time systems;Test analysis;},
URL = {http://dx.doi.org/10.1145/1810295.1810408},
} 


@article{20155101684562,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A comparative evaluation of state-of-the-art load and stress testing approaches},
journal = {International Journal of Computer Applications in Technology},
author = {Maalej, Afef Jmal and Krichen, Moez and Jmaiel, Mohamed},
volume = {51},
number = {4},
year = {2015},
pages = {283 - 293},
issn = {09528091},
abstract = {In order to deliver quality assured software and avoid potential costs caused by unstable software, testing is essential in software life cycle. Load testing is one of the testing types with high importance. It is usually accompanied by performance monitoring of the hosting environment. The purpose of this paper is to present related solutions to both load and stress testing issues in different fields and emerging paradigms, and to evaluate them in order to identify their advantages and their shortcomings. Looking at the areas focused by existing researchers, gaps and untouched zones of different systems relatively to load testing can be discovered. This investigation will especially allow promoting future research in the context of load testing of web service compositions, considered as an arising concept in service-oriented architecture (SOA).<br/> &copy; 2015 Inderscience Enterprises Ltd.},
key = {Load testing},
keywords = {Application programs;Computer applications;Information services;Life cycle;Service oriented architecture (SOA);Software architecture;Software testing;Web services;Websites;},
note = {Comparative evaluations;Emerging paradigms;Performance monitoring;State of the art;Stress Testing;Web service composition;},
URL = {http://dx.doi.org/10.1504/IJCAT.2015.070491},
} 


@article{20181905163736,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Standard Guide for Thermal Performance Testing of Cryogenic Insulation Systems},
journal = {Standard Guide for Thermal Performance Testing of Cryogenic Insulation Systems},
year = {2013},
abstract = {Scope: This guide provides information for the laboratory measurement of the steady-state thermal transmission properties and heat flux of thermal insulation systems under cryogenic conditions. Thermal insulation systems may be composed of one or more materials that may be homogeneous or non-homogeneous; flat, cylindrical, or spherical; at boundary conditions from near absolute zero or 4 K up to 400 K; and in environments from high vacuum to an ambient pressure of air or residual gas. The testing approaches presented as part of this guide are distinct from, and yet complementary to, other ASTM thermal test methods including C177, C518, and C335. A key aspect of this guide is the notion of an insulation system, not an insulation material. Under the practical use environment of most cryogenic applications even a single-material system can still be a complex insulation system (1-3).<sup>2</sup>To determine the inherent thermal properties of insulation materials, the standard test methods as cited in this guide should be consulted. The function of most cryogenic thermal insulation systems used in these applications is to maintain large temperature differences thereby providing high levels of thermal insulating performance. The combination of warm and cold boundary temperatures can be any two temperatures in the range of near 0 K to 400 K. Cold boundary temperatures typically range from 4 K to 100 K, but can be much higher such as 300 K. Warm boundary temperatures typically range from 250 K to 400 K, but can be much lower such as 40 K. Large temperature differences up to 300 K are typical. Testing for thermal performance at large temperature differences with one boundary at cryogenic temperature is typical and representative of most applications. Thermal performance as a function of temperature can also be evaluated or calculated in accordance with Practices C1058 or C1045 when sufficient information on the temperature profile and physical modeling are available. The range of residual gas pressures for this Guide is from 10<sup>-7</sup>torr to 10<sup>+3</sup>torr (1.33<sup>-5</sup>Pa to 133 kPa) with different purge gases as required. Corresponding to the applications in cryogenic systems, three sub-ranges of vacuum are also defined: High Vacuum (HV) from &lt;10<sup>-6</sup>torr to 10<sup>-3</sup>torr (1.333<sup>-4</sup>Pa to 0.133 Pa) [free molecular regime], Soft Vacuum (SV) from 10<sup>-2</sup>torr to 10 torr (from 1.33 Pa to 1,333 Pa) [transition regime], No Vacuum (NV) from 100 torr to 1000 torr (13.3 kPa to 133 kPa) [continuum regime]. Thermal performance can vary by four orders of magnitude over the entire vacuum pressure range. Effective thermal conductivities can range from 0.010 mW/m-K to 100 mW/m-K. The primary governing factor in thermal performance is the pressure of the test environment. High vacuum insulation systems are often in the range from 0.05 mW/m-K to 2 mW/m-K while non-vacuum systems are typically in the range from 10 mW/m-K to 30 mW/m-K. Soft vacuum systems are generally between these two extremes (4). Of particular demand is the very low thermal conductivity (very high thermal resistance) range in sub-ambient temperature environments. For example, careful delineation of test results in the range of 0.01 mW/m-K to 1 mW/m-K (from R-value 14,400 to R-value 144) is required as a matter of normal engineering applications for many cryogenic insulation systems (5-7). The application of effective thermal conductivity values to multilayer insulation (MLI) systems and other combinations of diverse materials, because they are highly anisotropic and specialized, must be done with due caution and full provision of supporting technical information (8). The use of heat flux (W/m<sup>2</sup>) is, in general, more suitable for reporting the thermal performance of MLI systems (9-11). This guide covers different approaches for thermal performance measurement in sub-ambient temperature environments. The test apparatuses (apparatus) are divided into two categories: boiloff calorimetry and electrical power. Both absolute and comparative apparatuses are included. This guide sets forth the general design requirements necessary to construct and operate a satisfactory test apparatus. A wide variety of apparatus constructions, test conditions, and operating conditions are covered. Detailed designs are not given but must be developed within the constraints of the general requirements. Examples of different cryogenic test apparatuses are found in the literature (12). These apparatuses include boiloff types (13-17) as well as electrical types (18-21). These testing approaches are applicable to the measurement of a wide variety of specimens, ranging from opaque solids to porous or transparent materials, and a wide range of environmental conditions including measurements conducted at extremes of temperature and with various gases and over a range of pressures. Of particular importance is the ability to test highly anisotropic materials and systems such as multilayer insulation (MLI) systems (22-25). Other test methods are limited in this regard and do not cover the testing of MLI and other layered systems under the extreme cryogenic and vacuum conditions that are typical for these systems. In order to ensure the level of precision and accuracy expected, users applying this standard must possess a working knowledge of the requirements of thermal measurements and testing practice and of the practical application of heat transfer theory relating to thermal insulation materials and systems. Detailed operating procedures, including design schematics and electrical drawings, should be available for each apparatus to ensure that tests are in accordance with this Guide. In addition, automated data collecting and handling systems connected to the apparatus must be verified as to their accuracy. Verification can be done by calibration and comparing data sets, which have known results associated with them, using computer models. It is impractical to establish all details of design and construction of thermal insulation test equipment and to provide procedures covering all contingencies associated with the measurement of heat flow, extremely delicate thermal balances, high vacuum, temperature measurements, and general testing practices. The user may also find it necessary, when repairing or modifying the apparatus, to become a designer or builder, or both, on whom the demands for fundamental understanding and careful experimental technique are even greater. The test methodologies given here are for practical use and adaptation as well as to enable future development of improved equipment or procedures. This guide does not specify all details necessary for the operation of the apparatus. Decisions on sampling, specimen selection, preconditioning, specimen mounting and positioning, the choice of test conditions, and the evaluation of test data shall follow applicable ASTM Test Methods, Guides, Practices or Product Specifications or governmental regulations. If no applicable standard exists, sound engineering judgment that reflects accepted heat transfer principles must be used and documented. This guide allows a wide range of apparatus design and design accuracy to be used in order to satisfy the requirements of specific measurement problems. Compliance with a further specified test method should include a report with a discussion of the significant error factors involved as well the uncertainty of each reported variable. The values stated in SI units are to be regarded as the standard. The values given in parentheses are for information only. Either SI or Imperial units may be used in the report, unless otherwise specified. Safety precautions including normal handling and usage practices for the cryogen of use. Prior to operation of the apparatus with any potentially hazardous cryogen or fluid, a complete review of the design, construction, and installation of all systems shall be conducted. Safety practices and procedures regarding handling of hazardous fluids have been extensively developed and proven through many years of use. For systems containing hydrogen, particular attention shall be given to ensure the following precautions are addressed: (1) adequate ventilation in the test area, (2) prevention of leaks, (3) elimination of ignition sources, (4) fail safe design, and (5) redundancy provisions for fluid fill and vent lines. This standard does not purport to address all of the safety concerns, if any, associated with its use. It is the responsibility of the user of this standard to establish appropriate safety and health practices and determine the applicability of regulatory limitations prior to use. Major sections within this standard are arranged as follows: (Table Presented)<br/> &copy;2013 ASTM International. All rights reserved.},
key = {Thermal insulation},
keywords = {Anisotropy;Construction equipment;Cryogenics;Data handling;Equipment testing;Hazards;Heat flux;Heating equipment;Materials testing;Multilayers;Permafrost;Software testing;Tapes;Temperature;Temperature measurement;Thermal conductivity;Thermal insulating materials;Vacuum applications;},
note = {Effective thermal conductivity;Environmental conditions;Governmental regulations;Low thermal conductivity;Temperature environments;Thermal insulation materials;Thermal insulation systems;Thermal performance testing;},
URL = {http://dx.doi.org/10.1520/C1774},
versions = {1},
standard designation = {C1774},
standardID = {C1774-13},
} 


@inproceedings{20094712463986,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Experience with training a remotely located performance test team in a quasi-agile global environment},
journal = {Proceedings - 2009 4th IEEE International Conference on Global Software Engineering, ICGSE 2009},
author = {Bondi, Andre B. and Ros, Johannes P.},
year = {2009},
pages = {254 - 261},
address = {Limerick, Ireland},
abstract = {We describe our experience of training a remotely located team of developers and testers to prepare and execute performance tests. The team is located in India. The lead performance engineer and the test project manager are based in New Jersey. The team members had little or no prior experience of performance testing. We describe how we overcame cultural differences and a large time difference to develop a performance testing team that is now functioning well with far less supervision than was required at its inception. Cultural differences included contrasting views on adherence to strict laboratory procedures and assumptions about the prior knowledge, experience, and expectations of working habits of the India-based and New Jersey-based teams. We show how these differences and organizational challenges were overcome with intensive on-site training, the use of twice-daily scrum meetings, the careful designation of team leaders and role players at the remote testing site, and, eventually, the development intensive use of automated tools to execute performance tests and track the results. &copy; 2009 IEEE.<br/>},
key = {Personnel training},
keywords = {Software engineering;},
note = {Cultural difference;Global environment;Laboratory procedures;On-site training;Performance testing;Performance tests;Prior experience;Time-differences;},
URL = {http://dx.doi.org/10.1109/ICGSE.2009.34},
} 


@inproceedings{20073510787985,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A lower bound on effective performance testing for digital forensic tools},
journal = {Proceedings - SADFE 2007: Second International Workshop on Systematic Approaches to Digital Forensic Engineering},
author = {Pan, Lei and Batten, Lynn M.},
year = {2007},
pages = {117 - 130},
address = {Bell Harbor, WA, United states},
abstract = {The increasing complexity and number of digital forensic tasks required in criminal investigations demand the development of an effective and efficient testing methodology, enabling tools of similar functionalities to be compared based on their performance. Assuming that the tool tester is familiar with the underlying testing platform and has the ability to use the tools correctly, we provide a numerical solution for the lower bound on the number of testing cases needed to determine comparative capabilities of any set of digital forensic tools. We also present a case study on the performance testing of password cracking tools, which allows us to confirm that the lower bound on the number of testing runs needed is closely related to the row size of certain orthogonal arrays. We show how to reduce the number of test runs by using knowledge of the underlying system. &copy; 2007 IEEE.},
key = {Software testing},
keywords = {Computational complexity;Computer aided software engineering;Data reduction;Parallel processing systems;},
note = {Abstraction layer model;Orthogonal arrays;Partition testing;SADFE;Software performance;},
URL = {http://dx.doi.org/10.1109/SADFE.2007.2},
} 


@inproceedings{20174004232566,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a structural load testing tool},
journal = {Proceedings of the 1996 ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 1996},
author = {Yang, Cheer-Sun D. and Pollock, Lori L.},
year = {1996},
pages = {201 - 208},
address = {San Diego, CA, United states},
abstract = {Load sensitive faults cause a program to fail when it is executed under a heavy load or over a long period of time, but may have no detrimental effect under small loads or short executions. In addition to testing the functionality of these programs, testing how well they perform under stress is very important. Current approaches to stress, or load, testing treat the system as a black box, generating test data based on parameters specified by the tester within an operational profile. In this paper, we advocate a structural approach to load testing. There exist many structural testing methods; however, their main goal is generating test data for executing all statements, branches, definition-use pairs, or paths of a program at least once, without consideration for executing any particular path extensively.Our initial work has focused on the identification of potentially load sensitive modules based on a static analysis of the module's code, and then limiting the stress testing to the regions of the modules that could be the potential causes of the load sensitivity. This analysis will be incorporated into a testing tool for structural load testing which takes a program as input, and automatically determines whether that program needs to be load tested, and if so, automatically generates test data for structural load testing of the program. &copy; 1996 ACM.},
key = {Software testing},
keywords = {Black-box testing;Load testing;Static analysis;Structural analysis;Structural loads;Test facilities;},
note = {Black boxes;Load sensitivities;Load-sensitive;Operational profile;Stress Testing;Structural approach;Structural testing;Testing tools;},
URL = {http://dx.doi.org/10.1145/229000.226318},
} 


@inproceedings{20125015795037,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Continuous performance testing in virtual time},
journal = {Proceedings - 2012 9th International Conference on Quantitative Evaluation of Systems, QEST 2012},
author = {Baltas, Nikos and Field, Tony},
year = {2012},
pages = {13 - 22},
address = {London, United kingdom},
abstract = {In this paper we show how program code and performance models can be made to cooperateseamlessly to support continuous software performance testing throughout thedevelopment lifecycle. We achieve this by extending our existing VEXtool for executing programs in virtual time so that events that occurduring normal execution and those that occur during the simulation of a performance model can bescheduled on a single global virtual time line. The execution time of anincomplete component of an application is thus estimated by a performance model, whilstthat of existing code is measured by instrumentation that is added dynamicallyat program load time. A key challenge is to be able to map some or all of the resourcesin a performance model to the real resources of the host platform on which theapplication is running. We outline a continuous performance engineering methodologythat exploits our unified framework and illustrate the principles involved byway of a simple Java application development case study. &copy; 2012 IEEE.},
key = {Software testing},
keywords = {Computer simulation;},
note = {Execution time;Global virtual time;Java applications;Performance engineering;Performance Model;Performance testing;Program code;Software performance;Software performance testing;Unified framework;Virtual execution;Virtual-time;},
URL = {http://dx.doi.org/10.1109/QEST.2012.26},
} 


@article{1984070110764,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {'ASAP': A microcomputer-based automated safety and performance testing system},
journal = {Journal of clinical engineering},
author = {Eschelbach, R.E.},
volume = {9},
number = {1},
year = {1984},
pages = {21 - 27},
issn = {03638855},
abstract = {An HP-85 microcomputer programmed in BASIC was interfaced to a PEI 2000 safety analyzer via an HP-6942A Multiprogrammer and appropriate interface cards. This configuration allows automated safety and performance testing as well as report generation. The system is operated by means of a menu displayed on a built-in CRT and the keyboard. Data are displayed and then stored on the built-in cassette unit. Additional testing features are easily added with minimal software development, since all programming is in BASIC and all interface drivers are part of the hardware.},
key = {BIOMEDICAL EQUIPMENT},
keywords = {COMPUTER PROGRAMMING LANGUAGES - BASIC;COMPUTERS, MICROPROCESSOR - Medical Applications;DATA STORAGE, MAGNETIC - Tape;DISPLAY DEVICES - Medical Applications;MAINTENANCE - Computer Applications;},
note = {AUTOMATED PERFORMANCE TESTING;AUTOMATED SAFETY TESTING;MICROCOMPUTERS;},
} 


@article{2005219112949,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A MSK performance testing/measuring tool sitwa},
journal = {Advances in Modelling and Analysis B},
author = {Izworski, Antoni and Skowronski, Slawomir and Lewoc, Jozef B.},
volume = {47},
number = {5-6},
year = {2004},
pages = {77 - 90},
issn = {12404543},
abstract = {It is rather difficult to find detailed and in-depth references concerning communication network performance testing/measuring tools. Therefore, the paper presents the solution developed earlier for the Interuniversity Computer Network in Poland. The structure and the functionality of the tool described are modified so that the description may be directly applied to TCP/IP networks. Some testing/measuring results are presented and benefits gained are discussed. The possible use of similar solution in present day communication networks is depicted.},
key = {Computer networks},
keywords = {Computer software;Data transfer;Measurement theory;Microcomputers;Network protocols;Telecommunication networks;Testing;},
note = {Internal tools;MSK performance testing;Network development;TCP/IP networks;},
} 


@inproceedings{20151000615046,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Galileo test range: Performance test results},
journal = {ENC-GNSS 2008 - European Navigation Conference},
author = {Gottifredi, F. and Martinino, F. and Morante, Q. and Eleuteri, M. and Varriale, E. and Valle, V. and Pesci, G.},
year = {2008},
address = {Toulouse, France},
abstract = {The Galileo Test Range (GTR) project is an initiative of Regione Lazio in the frame of its support to the Italian technical research and innovation in satellite navigation. It is born as the Italian National permanent Laboratory for the experimentation and analysis of the Galileo Signal, for testing and certification of user terminals and support services for the development of application services. The development of the GTR is foreseen in two phases: - Phase A = Definition and Start up: implementation of the initial system, based on the generation on ground of navigation signals (GPS-like), using pseudolite technology (4 PSL), and to receive real signals coming from GPS, EGNOS and the new GIOVE-A Experimental Satellite. - Phase B = Full deployment and initialization of the GTR: implementation of the GTR final configuration, not only able to generate Galileo-like signals (from 9 PSL), but also to receive and process real signals coming from Galileo IOV satellites. The Phase A architecture is composed by the following macro segments: - The Analysis &amp; Control Centre composed by the Control Centre (CC) and all the specialized laboratories (i.e. Time, Orbitography, Synchronization, Integrity, R&amp;D); - The Experimental Area (covered by Differential Reference Stations) including the Test Area (covered by the Pseudolites - PSL) The 4 PSL deployed for the Phase A (2 fixed and 2 transportable) are equipped with the following main elements: &bull; an atomic reference clock composed by an OCXO locked to Rb oscillator in order to obtain good short and long term stability; &bull; a dual frequency GPS/SBAS Receiver Assembly; &bull; a GPS-like signal generator &bull; a directional antenna to disseminate the GPS-Like signal in the Test Area The PSL Receiver observables are sent to the GTR-CC and then to the Orbitography Laboratory Facility in charge of the Time Synchronization function of the GTR based on the SynchroNet product of TAS-I. The reference for this Synchronization is given by the Time Laboratory Facility, equipped with an Active Hydrogen Maser and 4 Caesium Clocks. The clock corrections are sent back to the PSL, uploaded in the Navigation Message and broadcasted to the Users in the Test Area. Users equipped with a GPS Receiver can connect it to a PC with a dedicated software (developed by TAS-I) that makes a data fusion between GPS satellites observables and PSL ones so as to compute a better 3D position. If required, the SW can compute a 2D solution using only the Pseudolite observables, Users can compute a 2D position. The PSLs guarantee in a flexible way, thanks to the transportable PSLs, an increased availability of GNSS-like signals in the Test Area that users can use to improve theirs navigation performances. The tests carried out show that the achievable performance in the Test Area with the 4 PSL of Phase A are in the order of 5 m in 3D and 3 m in 2D. With the upgrade foreseen in Phase B in number and type of signal, the performance achievable will improve and potential applications can be satisfied with the use of the PSL technology. The aims of this paper are to present the advantages of the availability of signals generated by PSLs (fixed and transportable) in a controlled area and to present the reached performances for the phase A of the GTR using PSLs. Furthermore it will be presented an overview on the potential applications for this technology that can be a good solution for all those environments that require augmentations in performance and availability (i.e. urban canyons, harbors, container movement, etc&mellip;).<br/>},
key = {Global positioning system},
keywords = {Clocks;Data fusion;Directive antennas;Geostationary satellites;Hydrogen masers;Laboratories;Navigation;Orbits;Signal receivers;Synchronization;Testing;},
note = {Achievable performance;Application services;Directional Antenna;Laboratory facilities;Long term stability;Navigation performance;Satellite navigation;Time synchronization;},
} 


@inproceedings{20104313329116,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design of BDI agent for adaptive performance testing of Web services},
journal = {Proceedings - International Conference on Quality Software},
author = {Ma, Bo and Chen, Bin and Bai, Xiaoying and Huang, Junfei},
year = {2010},
pages = {435 - 440},
issn = {15506002},
abstract = {As services are dynamic discovered and bound in the open Internet environment, testing has to be exercised continuously and online to verify and validate the continuous changes and to ensure the quality of the integrated service-based system. During this process, testing strategies have to be adapted in accordance to the changes in the environment and target systems. Software agents are characterized by context awareness, autonomous decision making and social collaboration capabilities. The paper introduces the design of BDI (Believe-Decision-Intention) agents to facilitate adaptive performance testing of Web Services. The BDI model specifies the necessary test knowledge, test goal and action plan to carry out test and adaptive schedule. Performance testing is defined as a scheduling problem to select the workload and test cases in order to achieve the goal of performance abnormal detection. A two-level control architecture is built. At the TR (Test Runner) level, the BDI agents control the workload of concurrent requests. At the TC (Test Coordinator) level, the BDI agents control the complexity of test cases. Agents communicate and collaborate with each other to share knowledge and test plan. The paper introduces the design of the BDI model, the adaptation rules and the control architecture. Case study is exercised to illustrate the adaptive testing process based on the design of BDI agents. &copy; 2010 IEEE.},
key = {Web services},
keywords = {Autonomous agents;Concurrency control;Decision making;Intelligent agents;Software agents;Web crawler;Websites;},
note = {Adaptive testing;Autonomous decision;BDI Agent;Collaboration capabilities;Concurrent requests;Control architecture;Internet environment;Performance testing;},
URL = {http://dx.doi.org/10.1109/QSIC.2010.69},
} 


@article{20073710811107,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Development of client-oriented computer integrated test and control system for thermal performance test},
journal = {Yi Qi Yi Biao Xue Bao/Chinese Journal of Scientific Instrument},
author = {Li, Fang and Weng, Wenbing and Wang, Hengshan and Liu, Zhanjie},
volume = {28},
number = {8},
year = {2007},
pages = {1445 - 1450},
issn = {02543087},
abstract = {High precision air conditioner performance test equipment should have good test and control means and client-friendly test software. The factors that influence air conditioner test precision were analyzed and a test and control system was designed. The test and control system is based on client-oriented principle; high performance measurement sensors, automatic control elements and touch-screen monitor are adopted, and critical control and data-acquisition software is written, which makes the system have good control precision, convenient operation, friendly interface and reliable performance. The system has been applied successfully in several air conditioner test equipment.},
} 


@article{20175204586748,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Exploiting load testing and profiling for Performance Antipattern Detection},
journal = {Information and Software Technology},
author = {Trubiani, Catia and Bran, Alexander and van Hoorn, Andre and Avritzer, Alberto and Knoche, Holger},
volume = {95},
year = {2018},
pages = {329 - 345},
issn = {09505849},
abstract = {Context: The performance assessment of complex software systems is not a trivial task since it depends on the design, code, and execution environment. All these factors may affect the system quality and generate negative consequences, such as delays and system failures. The identification of bad practices leading to performance flaws is of key relevance to avoid expensive rework in redesign, reimplementation, and redeployment. Objective: The goal of this manuscript is to provide a systematic process, based on load testing and profiling data, to identify performance issues with runtime data. These performance issues represent an important source of knowledge as they are used to trigger the software refactoring process. Software characteristics and performance measurements are matched with well-known performance antipatterns to document common performance issues and their solutions. Method: We execute load testing based on the characteristics of collected operational profile, thus to produce representative workloads. Performance data from the system under test is collected using a profiler tool to create profiler snapshots and get performance hotspot reports. From such data, performance issues are identified and matched with the specification of antipatterns. Software refactorings are then applied to solve these performance antipatterns. Results: The approach has been applied to a real-world industrial case study and to a representative laboratory study. Experimental results demonstrate the effectiveness of our tool-supported approach that is able to automatically detect two performance antipatterns by exploiting the knowledge of domain experts. In addition, the software refactoring process achieves a significant performance gain at the operational stage in both case studies. Conclusion: Performance antipatterns can be used to effectively support the identification of performance issues from load testing and profiling data. The detection process triggers an antipattern-based software refactoring that in our two case studies results in a substantial performance improvement.<br/> &copy; 2017 Elsevier B.V.},
key = {Software testing},
keywords = {Load testing;Systems engineering;},
note = {Anti-patterns;Complex software systems;Empirical data;Execution environments;Performance assessment;Performance measurements;Software characteristic;Software performance engineerings;},
URL = {http://dx.doi.org/10.1016/j.infsof.2017.11.016},
} 


@inproceedings{20170503290813,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {GP-GPU based high-performance test equipment for debugging radar digital units},
journal = {Proceedings of 2016 International Conference on Data Mining and Advanced Computing, SAPIENCE 2016},
author = {Badarinath, R. and Abhilash, M.T.},
year = {2016},
pages = {387 - 391},
address = {Ernakulam, India},
abstract = {Modern active phased array radars are made to optimize the size, weight and power without compromising its capability to combat with advanced electronic warfare. To accomplish this task, the signal is digitized at element level or at sub-array level and processed with the help of advanced digital signal processor. Proving the capabilities of this firmware at bench level helps to reduce the overall development time. Hence, it is necessary to have a built-in test unit or test vector generator to verify the optimal performance of digital modules. The best way to accomplish this goal is to use a high speed baseband I &amp; Q radar data generator which helps in testing, identifying and segregating the problems at various stages. In this paper we have explored the capability of latest general purpose graphical processing unit (GP-GPU) as software defined built in test vector generator with high throughput for active array radar applications. &copy; 2016 IEEE.},
key = {Digital signal processors},
keywords = {Application programs;Data mining;Electronic warfare;Equipment testing;Firmware;Program processors;Radar;Radar signal processing;Signal processing;Software testing;},
note = {Active phased array radar;Built in tests;Development time;Digital beam forming;Graphical processing unit (GPUs);High throughput;Optimal performance;Performance tests;},
URL = {http://dx.doi.org/10.1109/SAPIENCE.2016.7684173},
} 


@inproceedings{20164002875524,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Program performance test based on different computing environment},
journal = {Proceedings of 2016 IEEE International Conference of Online Analysis and Computing Science, ICOACS 2016},
author = {Zhang, Hailong and Nie, Jun},
year = {2016},
pages = {174 - 177},
address = {Chongqing, China},
abstract = {To test the efficiency of different programming languages and find out the suitable one for solving the calculation problem of spherical distance between two points, we have developed serial and parallel calculate algorithms according C, Python programming languages, and tested the execution speed of all algorithms. As for the inefficiency of Python, we improved the performance by replacing some functions and variables of Python procedure with Cython. The experimental results show that Python programs can get the same execution efficiency as C language does with the same Large-scale computing environment. &copy; 2016 IEEE.},
key = {C (programming language)},
keywords = {Cesium;Computer software;Efficiency;High level languages;Software testing;},
note = {C language;Computing environments;Cython;Execution speed;Large-scale computing;Program performance;Python;Python programming language;},
URL = {http://dx.doi.org/10.1109/ICOACS.2016.7563073},
} 


@inproceedings{20161102081160,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance Test of Various Types of Antenna Arrays in Real Propagation Environment},
journal = {IOP Conference Series: Materials Science and Engineering},
author = {Budiyanto, Setiyo and Nugraha, Beny and Widiastuti, Dian},
volume = {105},
number = {1},
year = {2016},
issn = {17578981},
address = {Yogyakarta, Indonesia},
abstract = {The research was conducted on various types of antenna arrays namely Uniform Array, Binomial Array, Dolph-Chebyshev Array, and Taylor Array. This research is done in the real propagation environment in order to define precisely the number of antenna elements, the distance between the elements, the angle of the antenna arrays, the side lobe level and the n-bar array distribution. The testing process is done by using Matlab and the Non-Uniform Array Simulation Program. The results obtained for various types of antenna arrays are as follows: On Uniform Array produces Half Power Beam Width (HPBW) of 10.152&deg; and directivity of l0 dB, on Binomial Array generates Half Power Beam Width (HPBW) of 20.245&deg; and directivity of 7.47 dB, on Dolph-Chebyshev Arrayproduces Half Power Beam Width (HPBW) of 20.304&deg; and directivity of 4.0185 dB, and on Taylor Arrayproduces Half Power Beam Width (HPBW) of 12.78&deg; and directivity of 8.9 dB.},
key = {Antenna arrays},
keywords = {Antenna lobes;Bins;MATLAB;Planning;Software testing;Sustainable development;},
note = {Binomial arrays;Chebyshev arrays;Real propagation;Taylor Array;Uniform array;},
URL = {http://dx.doi.org/10.1088/1757-899X/105/1/012015},
} 


@inproceedings{2005048809225,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {VSTM: Virtual stress testing machine},
journal = {Proceedings of the International Conference on Parallel and Distributed Processing Techniques and Applications, PDPTA'04},
author = {Harris, R. and Ausin, A.M. and Angulo, J.S. and Valafar, F. and Impelluso, T.},
volume = {3},
year = {2004},
pages = {1345 - 1351},
address = {Las Vegas, NV, United states},
abstract = {Virtual stress testing machine is a client-server software environment with a distributed memory system. VSTM encompasses a stress testing machine, a server component that initiates and controls all processes, a computational finite element component, and a number of visualization components. The goal of this design is to provide a virtual stress analysis environment, in which a specimen undergoes a series of stress applications. The finite element component calculates the displacement (deformation) of the specimen under stress. The visualization clients read the results of the finite element analysis, and construct an image of the deformed specimen color-coded to indicate varying levels of stress. A multitude of applications have been envisioned for this system, including studies in medicine.},
key = {Computer software},
keywords = {Animation;Client server computer systems;Data processing;Distributed computer systems;Finite element method;Fluid mechanics;Virtual reality;Visualization;},
note = {Distributed Memory;Finite element codes;Stress Testing;Virtual stress testing machines (VSTM);},
} 


@article{20091712054109,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Parallel stream scheduling for high-speed performance test systems},
journal = {Qinghua Daxue Xuebao/Journal of Tsinghua University},
author = {Cao, Rui and Wu, Jianping and Xu, Mingwei},
volume = {49},
number = {4},
year = {2009},
pages = {608 - 611},
issn = {10000054},
abstract = {Existing hardware-based parallel stream scheduling algorithms are not applicable to high-speed test systems. This paper proves that a universal purely hardware-based parallel stream scheduling mechanism does not exist and then presents a software-based pre-computed parallel stream scheduling mechanism for high speed network device test systems. This scheduling mechanism computes a stream sequence in software and then the hardware schedules the stream according to this stream sequence. Experiments on a test system with a 10 Gb/s interface show that the mechanism provides good uniformity and equity, and can work in a full-load environment. The stream scheduling mechanism is independent of the number of streams and the test device interface speed, is suitable for any test system and has good extensibility.<br/>},
key = {Computer hardware description languages},
keywords = {Hardware;HIgh speed networks;Scheduling;Scheduling algorithms;Software testing;Test facilities;Testing;},
note = {High-speed network devices;High-speed performance;Network devices;Performance tests;Scheduling mechanism;Stream Scheduling;Stream sequence;Stream slice;},
} 


@inproceedings{20144200110472,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Evaluating capture and replay and model-based performance testing tools: An empirical comparison},
journal = {International Symposium on Empirical Software Engineering and Measurement},
author = {Rodrigues, Elder M. and Oliveira, Flavio M. and Bernardino, Maicon and Saad, Rodrigo S. and Costa, Leandro T. and Zorzo, Avelino F. and Guarienti, Priscila},
year = {2014},
pages = {IEEE Software; Microsoft Research; Politecnico di Torino; Telecom Italia JOL (Joint Open Lab); Telecom Italia Lab - },
issn = {19493770},
address = {Torino, Italy},
abstract = {[Context] A variety of testing tools have been developed to support and automate software performance testing activities. These tools may use different techniques, such as Model-Based Testing (MBT) or Capture and Replay (CR). [Goal] For software companies, it is important to evaluate such tools w.r.t. the effort required for creating test artifacts using them; despite its importance, there are few empirical studies comparing performance testing tools, specially tools developed with different approaches. [Method]We are conducting experimental studies to provide evidence about the required effort to use CR-based tools and MBT tools. In this paper, we present our first results, evaluating the effort (time spent) when using LoadRunner and Visual Studio CRbased tools, and the PLeTsPerf MBT tool to create performance test scripts and scenarios to test Web applications, in the context of a collaboration project between Software Engineering Research Center at PUCRS and a technological laboratory of a global IT company. [Results] Our results indicate that, for simple testing tasks, the effort of using a CR-based tool was lower than using an MBT tool, but as the testing complexity increases tasks, the advantage of using MBT grows significantly. [Conclusions] To conclude, we discuss the lessons we learned from the design, operation, and analysis of our empirical experiment. Copyright 2014 ACM.<br/>},
key = {Software testing},
keywords = {Application programs;Experiments;Model checking;},
note = {Collaboration projects;Empirical - comparisons;Empirical experiments;Model based testing;Performance testing;Software performance testing;Testing complexity;Testing tools;},
URL = {http://dx.doi.org/10.1145/2652524.2652587},
} 


@inproceedings{20120214674980,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Generation of scripts for performance testing based on UML models},
journal = {SEKE 2011 - Proceedings of the 23rd International Conference on Software Engineering and Knowledge Engineering},
author = {Da Silveira, Maicon B. and Rodrigues, Elder M. and Zorzo, Avelino F. and Costa, Leandro T. and Vieira, Hugo V. and De Oliveira, Flavio M.},
year = {2011},
pages = {258 - 263},
address = {Miami, FL, United states},
abstract = {Software testing process has a high cost when compared to the other stages of software development. Automation of software testing through reuse of software artifacts (e.g. models) is a good alternative for mitigating these costs and making the process much more efficient and efficacious. Model-Based Testing (MBT) is a technique to automatic generation of testing artifacts based on software models. For software development, the most spread modeling language in either the industrial or academic environments is UML. In such environments, it is desirable to reuse UML models also for MBT. avoiding re-building a different model exclusively for testing automation. These are the main reasons that make these semi-formal models an alternative to implementing MBT. Even though there are a lot of testing tools available commercially, to the best of our knowledge, none of them fully uses MBT. Therefore, this paper describes a case study showing how to implement the MBT process to automate test scripts generation and execution in a real-world, context. Furthermore, our solution is generated automatically by a Software Product Line (SPL).<br/>},
key = {Software testing},
keywords = {Computer software reusability;Formal methods;Knowledge engineering;Model checking;Software design;Unified Modeling Language;},
note = {Academic environment;Automatic Generation;Model based testing;Performance testing;Software artifacts;Software Product Line;Software product line (SPL);Testing automation;},
} 


@inproceedings{20142017708611,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing approach for services and applications using MQ-Series},
journal = {Annual International Conference of the Computer Measurement Group, CMG 2013},
author = {Srinivasa, Lakshmi N. and Anbalagan, Jagadeesh and Meenakshisundaram, Sriganesh},
volume = {2},
year = {2013},
pages = {1151 - 1162},
address = {London, United kingdom},
abstract = {Performance Testing of web-based applications in general is accomplished with the help of standard load testing tools and their methodology is well established and adopted by the Software Industry. With the advent of distributed Service Oriented Architecture (SOA) applications, load testing of services poses its own challenge to performance Testers and Engineers. In particular, this paper presents an approach and a tool by which the challenges for performance testing a messaging service (services using SOAP over MQ) can be overcome. Further, the paper illustrates how the existing tools can be adapted or new tools can be used to test them. In addition, it also specifies the testing, monitoring and tuning aspects of Messaging services.<br/>},
key = {Software testing},
keywords = {Application programs;Information services;Load testing;Service oriented architecture (SOA);},
note = {Distributed service;Messaging services;Performance testing;Services and applications;Software industry;Standard loads;Testing tools;Web-based applications;},
} 


@article{20070810438668,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Objective performance testing and quality assurance of medical ultrasound equipment},
journal = {Ultrasound in Medicine and Biology},
author = {Thijssen, Johan M. and Weijers, Gert and de Korte, Chris L.},
volume = {33},
number = {3},
year = {2007},
pages = {460 - 471},
issn = {03015629},
abstract = {There is an urgent need for a measurement protocol and software analysis for objective testing of the imaging performance of medical ultrasound equipment from a user's point of view. Methods for testing of imaging performance were developed. Simple test objects were used, which have a long life expectancy. First, the elevational focus (slice thickness) of the transducer was estimated and the in-plane transmit focus was positioned at the same depth. Next, the postprocessing look-up-table (LUT) was measured and linearized. The tests performed were echo level dynamic range (dB), contrast resolution (i.e., gamma of display, number of gray levels/dB) and sensitivity, overall system sensitivity, lateral sensitivity profile, dead zone, spatial resolution and geometric conformity of display. The concept of a computational observer was used to define the lesion signal-to-noise ratio, SNR<inf>L</inf> (or Mahalanobis distance), as a measure for contrast sensitivity. All the measurements were made using digitized images and quantified by objective means, i.e., by image analysis. The whole performance measurement protocol, as well as the quantitative measurements, have been implemented in software. An extensive data-base browser was implemented from which analysis of the images can be started and reports generated. These reports contain all the information about the measurements, such as graphs, images and numbers. The approach of calibrating the gamma by using a linearized LUT was validated by processing simultaneously acquired rf data. The contrast resolution and echo level of the rf data had to be compressed by a factor of two and amplified by a gain factor corresponding to 12 dB. This resulted in contrast curves that were practically identical to those obtained from DICOM image data. The effects of changing the transducer center frequency on the spatial resolution and contrast sensitivity were estimated to illustrate the practical usefulness of the developed approach of quality assurance by measuring objective performance characteristics. The developed methods might be considered as a minimum set of objective quality assurance measures. This set might be used to predict clinical performance of medical ultrasound equipment, taking into account the performance at a unique point in space i.e., the coinciding depths of the elevation and in-plane (azimuth) foci. Furthermore, it should be investigated whether the approach might be used to compare objectively various brands of equipment and to evaluate the performance specifications given by the manufacturer. Last but not least, the developed approach can be used to monitor, in a hospital environment, the medical ultrasound equipment during its life cycle. The software package may be viewed and downloaded at the website http://www.qa4us.eu. (E-mail: j.thijssen@cukz.umcn.nl). &copy; 2007 World Federation for Ultrasound in Medicine &amp; Biology.},
key = {Ultrasonic equipment},
keywords = {Computer software;Database systems;Image analysis;Medical imaging;Quality assurance;Signal to noise ratio;Ultrasonic transducers;},
note = {Computational observer;Contrast resolution;Objective assessment;Performance testing;Spatial resolution;},
URL = {http://dx.doi.org/10.1016/j.ultrasmedbio.2006.09.006},
} 


@inproceedings{20095312600275,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of mobile applications at the unit test level},
journal = {SSIRI 2009 - 3rd IEEE International Conference on Secure Software Integration Reliability Improvement},
author = {Kim, Heejin and Choi, Byoungju and Wong, W. Eric},
year = {2009},
pages = {171 - 180},
address = {Shanghai, China},
abstract = {With the rapid growth of the wireless market and the development of various mobile devices, innovative methods and technologies to produce high-quality mobile applications and reduce time to market have been emerging. Mobile applications are often characterized by an array of limitations such as the short development lifecycle to gain a competitive advantage and difficulties to update once released. Hence, rigorous testing on the applications is required before distribution to the market, including structural white-box, functional black-box, integration and system testing. Although recently performance testing at the system test level has become crucial given its direct connection with the product quality improvement, most such tests are confined to the areas of load, usability, and stress testing. Moreover, the implementation itself is insufficient due to the limitations of the development environment. This paper proposes a method to support performance testing utilizing a database established through benchmark testing in emulator-based test environment at the unit test level. It also presents the tool that supports the proposed method of performance testing and verifies the reliability of performance test results through experiments. &copy; 2009 IEEE.<br/>},
key = {Integration testing},
keywords = {Benchmarking;Black-box testing;Commerce;Competition;Integration;Load testing;Mobile computing;Software reliability;Testing;},
note = {Benchmark testing;Competitive advantage;Development environment;Innovative method;Mobile applications;Performance testing;Performance tests;Quality improvement;},
URL = {http://dx.doi.org/10.1109/SSIRI.2009.28},
} 


@inproceedings{20163702805346,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The NRC human performance test facility: An approach to data collection using novices and a simplified environment},
journal = {Advances in Intelligent Systems and Computing},
author = {Hughes, Niav and DAgostino, Amy and Reinerman-Jones, Lauren},
volume = {495},
year = {2017},
pages = {183 - 192},
issn = {21945357},
address = {Walt Disney World, FL, United states},
abstract = {In the spring of 2012, as part of a &lsquo;hub and spoke&rsquo; model of research to address the human performance concerns related to current as well as new and advanced control room designs and operations, the U.S. Nuclear Regulatory Commission (NRC) sponsored a project to procure a low cost simulator to empirically measure and study human performance aspects of control room operations. Using this simulator, the Human Factors and Reliability Branch (HFRB) in the Office of Nuclear Regulatory Commission (NRC) began a program of research known as the NRC Human Performance Test Facility (HPTF) to collect empirical human performance data with the purpose of measuring and ultimately better understanding the various cognitive and physical elements that support safe control room operation. To accomplish this, HFRB first procured two 3-loop Westinghouse pressurized water reactor simulators with the capability to run a full range of power operation scenarios. HFRB staff work as co-investigators along with a team of researchers at the University of Central Florida (UCF) to design and carry-out a series of experiments aimed at measuring and understanding the human performance aspects of common control room tasks through the use of a variety of physiological and self-report metrics. The intent was to design experiments that balanced domain realism and laboratory control sufficiently to collect systematic, yet meaningful human performance data related to execution of common main control room (MCR) tasks. Investigators identified and defined three types of tasks that are examined in the present project: Checking, Detection, and Response Implementation. Task type presentation was partially counterbalanced to maintain ecologic validity with experimental control. A variety of subjective and physiological measures were used to understand performance of those tasks in terms ofworkload. The simulator used to collect these data was a digital representation of a generic analog NPP MCR interface. The data resulting from this experimentation enhances the current information gathering process, allowing for more robust technical bases to support regulatory guidance development and decision making. The present paper describes the approach behind this research effort. &copy; Springer International Publishing Switzerland 2017.},
key = {Data acquisition},
keywords = {Decision making;Design;Electric industry;Human computer interaction;Human engineering;Nuclear energy;Physiology;Pressurized water reactors;Simulators;Software testing;Test facilities;},
note = {Digital representations;Human performance;Information gathering;Main control room;Nuclear regulatory commission;Physiological measures;U.S. Nuclear Regulatory Commission;University of Central Florida;},
URL = {http://dx.doi.org/10.1007/978-3-319-41950-3_16},
} 


@inproceedings{20171903654986,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {An exploratory study of the state of practice of performance testing in Java-based open source projects},
journal = {ICPE 2017 - Proceedings of the 2017 ACM/SPEC International Conference on Performance Engineering},
author = {Leitner, Philipp and Bezemer, Cor-Paul},
year = {2017},
pages = {373 - 384},
address = {L'Aquila, Italy},
abstract = {The usage of open source (OS) software is wide-spread across many industries. While the functional quality of OS projects is considered to be similar to closed-source software, much is unknown about the quality in terms of performance. One challenge for OS developers is that, unlike for functional testing, there is a lack of accepted best practices for performance testing. To reveal the state of practice of performance testing in OS projects, we conduct an exploratory study on 111 Java-based OS projects from GitHub. We study the performance tests of these projects from five perspectives: (1) developers, (2) size, (3) test organization, (4) types of performance tests and (5) used tooling. We show that writing performance tests is not a popular task in OS projects: performance tests form only a small portion of the test suite, are rarely updated, and are usually maintained by a small group of core project developers. Further, even though many projects are aware that they need performance tests, developers appear to struggle implementing them. We argue that future performance testing frameworks should provider better support for low-friction testing, for instance via non-parameterized methods or performance test generation, as well as focus on a tight integration with standard continuous integration tooling. &copy; 2017 Copyright held by the owner/author(s).},
key = {Software testing},
keywords = {Integration testing;Java programming language;Open source software;Open systems;Software engineering;},
note = {Empirical Software Engineering;Mining software repositories;Open sources;Performance engineering;Performance testing;},
URL = {http://dx.doi.org/10.1145/3030207.3030213},
} 


@inproceedings{20171903645382,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Drop weight dynamic load testing for construction monitoring and quality control of offshore drilled foundations},
journal = {Geotechnical Special Publication},
author = {Robertson, Seth O. and Paikowsky, Samuel G.},
number = {GSP 279},
year = {2017},
pages = {143 - 153},
issn = {08950563},
address = {Orlando, FL, United states},
abstract = {High strain drop weight dynamic load testing is an effective tool when evaluating the construction quality and axial capacity of offshore drilled deep foundations. This is a result of the complexity and cost of the alternative conventional static load tests. Drop weight systems can be designed for project specific needs, providing sufficient energy to mobilize the required resistance while permitting ease in transporting the device. Test shafts/piles can be instrumented and analyzed using the same dynamic testing techniques used for driven pile foundations. A case study is presented where drop weight dynamic load tests were utilized for offshore drilled shaft foundations. The project includes the design, construction, and quality control for a cement unloading pier at the Tema port in Ghana, Africa. The foundations are unique, consisting of 0.8m outer diameter steel pipes embedded in 1.0m rock-socketed drilled shafts. Three dynamic load tests to failure and six load verification tests were performed offshore. The load verification tests were carried out due to construction difficulties and/or complex subsurface conditions. The piles' integrity and mobilized resistances were assessed using the signal matching analysis software CAPWAP. The underlying assumptions in the one-dimensional wave equation formulation on which CAPWAP is based are violated in these complex cases. Finite element analyses were therefore performed using the PLAXIS 2D software in order to examine the validity of the one-dimensional wave equation application under such conditions. This paper briefly describes the project, the associated difficulties, the unique foundations, example load tests and their analyses, as well as some initial processing in examining the validity of the one-dimensional wave equation analyses under the tested conditions. &copy; ASCE.},
key = {Load testing},
keywords = {Application programs;Drops;Dynamic loads;Finite element method;Foundations;Pile foundations;Piles;Quality control;Shaft sinking;Unloading;Wave equations;},
note = {Construction monitoring;Construction quality;Drilled foundations;One-dimensional wave equations;Signal matching analysis;Subsurface conditions;Three dynamic loads;Verification tests;},
URL = {http://dx.doi.org/10.1061/9780784480465.015},
} 


@inproceedings{20100712710119,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Apply automation testing in enterprises},
journal = {Applied Mechanics and Materials},
author = {Ding, Yan and Qi, Feng},
volume = {20-23},
year = {2010},
pages = {337 - 341},
issn = {16609336},
address = {Macao, China},
abstract = {In order to keep pace of product development and delivery, it is essential to implement an effective and reusable automation test framework. The traditional capture/replay framework is not only out of date but hard to use. Much more robust automation framework must be found otherwise automation test will only end up with failure forever. Success comes when clear concept of automation test is in managers' mind and full preparation is made. The paper first make it clear what is test automation and how it should be used and then list some approaches and tools popular in automation test. Then, it describes details of a framework. A model is given after it. It has been proved that this flow is reliable and greatly improves test efficiency in a company. &copy; (2010) Trans Tech Publications.},
key = {Testing},
keywords = {Automation;Computer software;Information technology;Product development;},
note = {Automation testing;Capture/replay;Software test;Test Automation;Test automation frameworks;Test efficiency;Test framework;},
} 


@inproceedings{20130315904438,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Load testing on a budget},
journal = {34th International Conference Computer Measurement Group},
author = {Johnson, Peter},
year = {2008},
address = {Las Vegas, NV, United states},
abstract = {Load testing your application before placing it into production is always a good idea. Load testing during development is an even better idea. But commercial load testing software tends to be expensive and thus placing copies into the hands of every developer might not be feasible. This paper examines JMeter, a popular free, open source load testing tool. This paper is written as a tutorial showing how to use JMeter to load test an example application.},
key = {Measurements},
note = {Load test;Open sources;Testing software;},
} 


@inproceedings{20161502225478,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing and assessment of multi-vendor protection schemes using proprietary protocols and the IEC 61850 standard},
journal = {Proceedings of the Conference on the Industrial and Commercial Use of Energy, ICUE},
author = {Arnold, T. and Adewole, A.C. and Tzoneva, R.},
volume = {2015-September},
year = {2015},
pages = {284 - 290},
issn = {21660581},
address = {Cape Town, South africa},
abstract = {The International Electrotechnical Commission (IEC) developed a global standard for power system communication permitting Intelligent Electronic Devices (IEDs) to interoperate within the smart grid environment. However, in order for electric power utility companies to adopt IEC 61850 standard-based devices with confidence, it is necessary to carry out performance tests and evaluations to allay their fears. This paper presents an evaluation of the performance of IEC 61850 standard-based devices with respect to their speed, security, and dependability of operation. The study was implemented using multi-vendor IEDs configured for a Permissive Overreaching Transfer Trip (POTT) communication scheme with conventional proprietary protocols and the IEC 61850 Generic Object Oriented Substation Events (GOOSE) messages based on hardware-in-the-loop simulations with the Real-Time Digital Simulator (RTDS). RSCAD software was used in the modelling of a typical power system network protected by two multi-vendor distance protection IEDs using a lab-scale testbed designed and implemented for the investigations relating to this paper. Real-time simulations for various fault locations and fault resistances were carried out. The results obtained demonstrated the dependability and security of the operation of the IEC 61850-based POTT communication scheme with faster operating times compared with the conventional POTT communication scheme based on vendor-specific proprietary protocols. This paper could serve as a reference to electric power utility companies as they adopt IEC 61850 standard-based devices in their networks. &copy; 2015 CPUT.},
key = {Electric power system protection},
keywords = {Digital devices;Electric fault currents;Electric power systems;Electric power transmission networks;Electric substations;Electron devices;Electronic equipment;Object oriented programming;Smart power grids;Standards;Thermoelectric equipment;},
note = {Distance protection;GOOSE;IEC 61850;Intelligent electronic device;POTT;Real time digital simulation;},
URL = {http://dx.doi.org/10.1109/ICUE.2015.7280280},
} 


@article{20091912073123,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Model-based method for web service performance testing},
journal = {Beijing Youdian Daxue Xuebao/Journal of Beijing University of Posts and Telecommunications},
author = {Chen, Ying-Hui and Qiu, Xue-Song and Liu, Yi-Chang and Tang, Fan and Gao, Zhi-Peng},
volume = {32},
number = {SUPPL.},
year = {2009},
pages = {44 - 48},
issn = {10075321},
abstract = {Software performance testing is one of the important techniques used to assure the quality of web services. In order to improve the efficiency and automatization of web service performance testing, a model-based method for web service performance testing is proposed. Web service performance testing models built by distinct layers are presented. The layers of testing models includes test step model layer, test transaction model layer and test scenario model layer from the bottom up. The lower layer models were reusable for the higher layer model building. Furthermore, a web service performance testing tool is implemented, and an efficient solution is provided for model-based automatic performance testing.<br/>},
key = {Web services},
keywords = {Software testing;Websites;},
note = {Model-based method;Performance testing;Quality of web services;Service performance;Software performance testing;Testing modeling;Testing tools;Transaction model;},
} 


@inproceedings{2006169828455,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Bridge load rating using an integrated load testing and finite element analysis approach: A case study},
journal = {Proceedings, Annual Conference - Canadian Society for Civil Engineering},
author = {Halfawy, M.R. and Wipf, T. and Wood, D. and Abu-Hawash, A. and Phares, B.},
volume = {2002},
year = {2002},
pages = {1371 - 1379},
address = {Montreal, QB, Canada},
abstract = {Bridge load rating is the primary decision tool that is currently in use to evaluate and predict bridge performance under various loading conditions. Traditional bridge rating calculations involve calculating the load carrying capacity of the structural elements based on design plans, field inspection reports, and engineering judgment. Experience shows that bridge performance is always under-estimated using this simplified approach and in many cases results in placing unnecessary load restrictions on bridges. Bridge diagnostic load testing has been widely recognized as a more reliable and accurate method for bridge rating. However, the time and cost involved in conducting bridge load testing has been a major impediment to employing this valuable tool on a large scale. Bridge owners can typically only afford to perform load testing for major bridges and under critical circumstances. The need for more cost-effective and easy-to-implement methods to perform bridge load testing and rating analysis is well evident. In this paper, the use of an integrated system to conduct bridge load testing, finite element analysis, and rating is demonstrated. The system consists of load testing instrumentation and data acquisition hardware as well as four software components to perform structural analysis and rating calculations. A case study of a prestressed concrete bridge is presented to demonstrate the seamless integration of the load testing and analysis processes.},
key = {Load testing},
keywords = {Bridges;Data acquisition;Finite element method;Loading;Prestressed concrete;},
note = {Bridge load rating;Bridge performance;Decision tool;Instrumentation;},
} 


@inproceedings{20102312986747,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and implementation of performance testing model for web services},
journal = {CAR 2010 - 2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics},
author = {Guo, Xiao-Yang and Qiu, Xue-Song and Chen, Ying-Hui and Tang, Fan},
volume = {1},
year = {2010},
pages = {353 - 356},
address = {Wuhan, China},
abstract = {The performance testing model for Web Services is proposed. Aiming to enhance testing efficiency and automation, the model provides a multi-machine joint testing model and strategy model. The former is used to share the heavy load to multiple units, which could also be called load balance model, and the latter is used to simulate a realistic Web Services running environment. The model has been applied to an original web services testing software, and proved to be a feasible way for performance testing for web services. &copy;2010 IEEE.<br/>},
key = {Web services},
keywords = {Automation;Load testing;Robotics;Software testing;Websites;},
note = {Design and implementations;Load balance;Multi-machines;Performance testing;Strategy modeling;Testing efficiency;Testing modeling;Testing software;},
URL = {http://dx.doi.org/10.1109/CAR.2010.5456825},
} 


@inproceedings{20082811353983,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Realistic load testing of web applications},
journal = {Proceedings of the European Conference on Software Maintenance and Reengineering, CSMR},
author = {Draheim, Dirk and Grundy, John and Hosking, John and Lutteroth, Christof and Weber, Gerald},
year = {2006},
pages = {57 - 67},
issn = {15345351},
address = {Bari, Italy},
abstract = {We present a new approach for performing load testing of web applications by simulating realistic user behaviour with stochastic form-oriented analysis models. Realism in the simulation of user behaviour is necessary in order to achieve valid testing results. In contrast to many other user models, web site navigation and time delay are modelled stochastically. The models can be constructed from sample data and can take into account effects of session history on user behaviour and the existence of different categories of users. The approach is implemented in an existing architecture modelling and performance evaluation tool and is integrated with existing methods for forward and reverse engineering. &copy; 2006 IEEE.<br/>},
key = {Behavioral research},
keywords = {Computer software maintenance;Load testing;Reengineering;Reverse engineering;Stochastic models;Stochastic systems;Websites;},
note = {Existing architectures;Form-oriented analysis;New approaches;Performance evaluation tools;Sample data;User behaviour;WEB application;Web site navigation;},
URL = {http://dx.doi.org/10.1109/CSMR.2006.43},
} 


@inproceedings{20182005202831,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and performance test of NIRS-based spinal cord lesion detector},
journal = {Progress in Biomedical Optics and Imaging - Proceedings of SPIE},
author = {Li, Nanxi and Li, Ting},
volume = {10484},
year = {2018},
pages = {The Society of Photo-Optical Instrumentation Engineers (SPIE) - },
issn = {16057422},
address = {San Francisco, CA, United states},
abstract = {Spinal cord lesions can cause a series of severe complications, which can even lead to paralysis with high mortality. However, the traditional diagnosis of spinal cord lesion relies on complicated imaging modalities and other invasive and dangerous methods. Here, we have designed a small monitor based on NIRS technology for noninvasive monitoring for spinal cord lesions. The development of the instrument system includes the design of hardware circuits and the program of software. In terms of hardware, OPT101<sup>1</sup>is selected as the light detector, and the appropriate probe distribution structure is selected according to the simulation result of Monte Carlo Simulation. At the same time, the powerful controller is selected as our system's central processing chip for the circuit design, and the data is transmitted by serial port to the host computer for post processing. Finally, we verify the stability and feasibility of the instrument system. It is found that the spinal signal could be obviously detected in the system, which indicates that our monitor based on NIRS technology has the potential to monitor the spinal lesion.<br/> &copy; 2018 SPIE.},
key = {Monte Carlo methods},
keywords = {Computer hardware;Convergence of numerical methods;Detectors;Hardware;Integrated circuit manufacture;Intelligent systems;Printed circuit design;Remote control;Surgery;},
note = {Design of hardwares;feasibility;Imaging modality;Instrument systems;NIRS;Non-invasive monitoring;Performance tests;Spinal cords;},
URL = {http://dx.doi.org/10.1117/12.2287071},
} 


@article{1990080510160,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Computerised performance testing of data acquisition facilities},
journal = {Measurement Science and Technology},
author = {Abdel-Aal, R.E.},
volume = {1},
number = {3},
year = {1990},
pages = {216 - 219},
issn = {09570233},
abstract = {This paper describes a low-cost approach to performing automatic performance measurements on data acquisition modules and systems employed in physics research. A versatile programmable CAMAC pulse generator is described which produces accurately timed repetitive logic pulses whose width and repetition rate are set by software. The variable rate is useful in determining the performance of data acquisition systems over a wide range of data rates, while the variable width may be used in the automatic measurement of the characteristics of modules such as time-to-digital converters (TDCS). Using a time-to-amplitude converter (TAC), this width can be converted into a variable amplitude for testing analogue-to-digital converter (ADC) modules. Hardware and software aspects are described. Typical applications are discussed including automated performance measurements on a VAX 11/785 data acquisition system and on a TAC/ADC combination.},
key = {Data Processing},
keywords = {Data Conversion, Analog to Digital;Physics--Research;Pulse Generators;},
note = {CAMAC Pulse Generator;Performance Testing;Time-to-Digital Converters;},
URL = {http://dx.doi.org/10.1088/0957-0233/1/3/002},
} 


@inproceedings{20130615981548,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Study on performance test of storage structure base on state scene performance},
journal = {Proceedings - 2012 International Conference on Computer Science and Service System, CSSS 2012},
author = {Li, Li and Zhu, Lei-Lei and Zhai, Hongyu and Liu, Dan and Wang, Hai-Fang},
year = {2012},
pages = {570 - 573},
address = {Nanjing, China},
abstract = {This paper is an introduction to software performance automated testing and theory. It introduces the features of Open Xml storage and SQL Server storage. Then this paper sets three state scenes and chooses different test automated tools respectively. Finally, it uses tools to monitor software performance index from these two data storage systems. Results are then analyzed, comparing the quality performance of different storage systems to the same state scene. &copy; 2012 IEEE.},
key = {Computer science},
keywords = {Data storage equipment;},
note = {Automated testing;Automated tools;Data storage systems;Monitor software;Performance tests;Quality performance;Software performance;SQL servers;Storage structures;Storage systems;XML storage;},
URL = {http://dx.doi.org/10.1109/CSSS.2012.148},
} 


@inproceedings{20124815738641,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {CaPTIF: Comprehensive performance testing framework},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Mayer, Daniel A. and Steele, Orie and Wetzel, Susanne and Meyer, Ulrike},
volume = {7641 LNCS},
year = {2012},
pages = {55 - 70},
issn = {03029743},
address = {Aalborg, Denmark},
abstract = {In this paper we present the design and implementation of a framework for comprehensive performance evaluation of algorithms, modules, and libraries. Our framework allows for the definition of well-defined test inputs and the subsequent scheduling and execution of structured tests. In addition, the framework provides a web-based interface for user interaction and allows for the convenient browsing, plotting, and statistical analysis of test results. We furthermore report on our experience in using the new framework in the development of cryptographic protocols and algorithms-specifically in the context of secure multi-party computation. &copy; 2012 IFIP International Federation for Information Processing.},
key = {Software testing},
keywords = {Algorithms;Multimedia systems;},
note = {Comprehensive performance;Comprehensive performance evaluation;Cryptographic protocols;Secure multi-party computation;Test inputs;User interaction;Web-based interface;},
URL = {http://dx.doi.org/10.1007/978-3-642-34691-0_6},
} 


@inproceedings{20125015792900,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design of performance testing bed for hydraulic products of engineering machinery},
journal = {Advanced Materials Research},
author = {Liu, Zhihai and Zeng, Qingliang and Kang, Hongxi and Wang, Chenglong},
volume = {590},
year = {2012},
pages = {427 - 430},
issn = {10226680},
address = {Qingdao, China},
abstract = {Hydraulic test platform is a very important testing tool for hydraulic products of engineering machinery. In this paper, a new type of hydraulic test bed is developed which can be used for performance testing of hydraulic valves, hydraulic motor and hydraulic pump. The composition structure diagram of hydraulic system, power supply system, and the signal flow diagram of data acquisition system were designed. The communication between sensors and computer via RS232 were researched. At last, the hydraulic test software is developed by using Labwindows/CVI and Simense PLC. &copy; (2012) Trans Tech Publications, Switzerland.},
key = {Hydraulic machinery},
keywords = {Communication;Electric power systems;Equipment testing;Hydraulic equipment;Hydraulic motors;Machine design;Mechatronics;Product design;Systems analysis;},
note = {Composition structure;Data acquisition system;Engineering machinery;Hydraulic pump;Hydraulic system;Hydraulic tests;Hydraulic valves;Labwindows;LabWindows/CVI;Performance testing;Signal flow;Structure design;Testing tools;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMR.590.427},
} 


@inproceedings{20142717899524,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Preliminary performance test of mechanical pump for a STELLA-1},
journal = {ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE)},
author = {Han, Ji-Woong and Ko, Bock Seong and Park, Sang-Jun and Lee, Yoon Sang and Jeong, Ji-Young and Lee, Yong Bum},
volume = {15},
year = {2013},
pages = {ASME - },
address = {San Diego, CA, United states},
abstract = {In the process of sodium-cooled fast reactor (SFR) design, it is very important to verify thermo-hydraulic performance of each component in the sodium environment. In KAERI (Korea Atomic Energy Research Institute) STELLA (Sodium Integral Effect Test Loop for Safety Simulation and Assessment) project is under a Mid- and Long-term Nuclear R&amp;D Program. The STELLA project is composed of two stages. In the 1st stage the performance for heat exchangers such as DHX (Decay heat exchanger) and AHX (Air heat exchanger) and for PHTS (Primary heat transport system) mechanical pump will be evaluated. The detailed design of each component is based on that of a 600MWe demonstration reactor. Since full-scale components could not be installed in STELLA-1 [1], the model pump is designed to be scaled-down based on the scaling law. Various pump tests have been done in water environment by using model pump. In this study the design features of model pump were described and the scaling parameters were examined. The results of pump performance tests have been also introduced which is essential to perform safety analysis. Copyright &copy; 2013 by ASME.<br/>},
key = {Pumps},
keywords = {Heat exchangers;Safety engineering;Sodium-cooled fast reactors;Software testing;},
note = {Demonstration reactor;Korea Atomic Energy Research Institute;Performance tests;Primary heat transport systems;Scaling parameter;Sodium cooled fast reactors (SFR);Thermo-hydraulic performance;Water environments;},
URL = {http://dx.doi.org/10.1115/IMECE2013-65654},
} 


@inproceedings{20081711224509,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Real- time measurement of friction coefficient in the frictional performance test of brake disk},
journal = {Key Engineering Materials},
author = {Huo, Xiao-Jing and Zhang, Rui-Qing and Wang, Hui and Qian, Dong-Ping and Teng, Jia-Xu},
volume = {373-374},
year = {2008},
pages = {484 - 487},
issn = {10139826},
abstract = {Development and optimizing of friction material formula, oriented to improve the service life and security of brake disk, is largely based on advanced measurement method to accurately provide the friction coefficient. In this study, virtual instrumentation technique was used to design an automation measurement system of friction coefficient. With proper sensors, data of four measured variables such as temperature, rotation speed, pressure and friction torque are acquired by the computer combined with a plug-in data acquisition board. The system work principle, selection of sensors, multi-channel sampling, signal processing and anti-jamming measures have been presented in detail. Those functions of the software such as real-time data acquisition, dynamic wave displaying, high-speed report saving and inquiry, and so on, have been realized by LabWindows/CVI 7.1. The system works safely with high accuracy and friendly user interface in practical operation.},
key = {Friction materials},
keywords = {Disks (machine components);Measurement theory;Optimization;Real time systems;},
note = {Brake disks;Friction coefficient;Virtual instrumentation;},
} 


@inproceedings{20174904486358,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {No-load performance testing of an arduino-primed hybrid solar-electric crop dryer},
journal = {2017 ASABE Annual International Meeting},
author = {Nwakuba, Nnaemeka R. and Chukwuezie, Collins O. and Asoegwu, Sabbas N. and Nwaigwe, Kevin N.},
year = {2017},
pages = {ASABE - },
address = {Spokane, WA, United states},
abstract = {This work presents the performance testing of an arduino-controlled hybrid solar-electric cabinet dryer under no-load condition. The integral hybrid system mainly consists of solar and electric heat components which are connected to a programmable circuit board (micro-controller) with a piece of software (integrated development environment, IDE) known as arduino micro-processor which controls and automates the overall operation of the dryer system through its relay and receives signals from transducer sensors (a capacitive humidity and thermistor sensors) placed at different locations on the dryer. Through the use of a 4 X 4 matrix keypad, preset chamber temperature threshold and chamber air flow rates were inputted; relative humidities of the different locations, tray and chamber temperatures and energy consumption from both solar and electric energy sources were measured, recorded, displayed on the liquid crystal display (LCD) and transferred to a microcomputer via a universal serial board (USB) cord. With the arduino platform, the quantity of moisture loss per given time and energy required for drying as well as other basic drying parameters can be effectively measured with minimum human supervision, thus making the entire operation automated and efficient. No-load tests were conducted to evaluate the thermal profile of the dryer, which involved running the dryer at five different air velocities (0.1, 0.5, 1.0, 1.5, and 2.0 m/s) in order to determine the required time to reach the preset optimum drying temperatures of 50, 55, 60, 65, 70oC. Results obtained show that an average minimum drying chamber heat-up times of 9.8 and 6.2 minutes were required by the electrical and hybrid heat sources at a temperature and air velocity of 70oC and 2 m/s respectively. Ambient air temperature, relative humidity and air velocity were observed to have significant influence on the dryer heat-up time and tray temperatures. Drying time had significant effect on the energy consumption of the dryer mainly due to hourly solar heat. The hybrid and electric heat sources developed a maximum chamber temperature of about 92.5 and 84oC respectively after 210 minutes. Peak energy of 1946 and 1485kW-hr were developed by the hybrid and electric heat units respectively and 784kW/m<sup>2</sup>was developed by the solar collector. The solar component contributed a maximum drying chamber temperature of 30 to 31.7oC which is about 50 to 55% of the required drying chamber temperature. Energy regression equation models were developed in terms of time for each heat source as well as the hybrid with an average R<sup>2</sup>-value of 0.99. The general performance of the dryer was attributed to the heat contribution of the solar collector and that of the electric heater as well as its negligible thermal losses. Good prospects for future applications as well as recommendations were stated.<br/>},
key = {Dryers (equipment)},
keywords = {Air;Atmospheric humidity;Capacitive sensors;Drying;Electric heating;Electric losses;Energy utilization;Humidity control;Hybrid systems;Liquid crystal displays;Load testing;Solar collectors;},
note = {Ambient air temperature;Arduino processor;Heat profiles;Heat-up time;Hybrid dryers;Integrated development environment;Liquid crystal display(LCD);Programmable circuits;},
URL = {http://dx.doi.org/10.13031/aim.201700079},
} 


@inproceedings{1993081001702,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {DB2 Version 2 Release 3 multi-user performance test results},
journal = {CMG Proceedings},
author = {Battersby, Glynis and De Rossett, Margaret},
year = {1992},
pages = {542 - 549},
address = {Reno, NV, USA},
abstract = {A series of tests designed to determine the performance and resource consumption characteristics of DB2 Version 2 Release 3 as compared with DB2 Version 2 Release 2 was executed in a multi-user environment. The purpose of this paper is to describe the results of experiences using DB2 2.3 and DB2 2.2. The workload presented in the paper is synthetic and does not represent any known workload deployed at any site. No endorsement of IBM of its products is expressed, and none should be implied. No recommendation is made regarding the purchase DB2 or any other IBM products. A network of 300 terminals was simulated using IBM's Teleprocessing Network Simulator (TPNS), and test scripts were executed at various transaction rates to measure the system performance under both peak and non-peak conditions. The basic workload was then restructured to take advantage of DB2 2.3's new package feature and additional volume testing was conducted. The reader of this paper is assumed to have a basic knowledge of DB2 principles and MVS performance terminology and concepts. The reader may wish to read the provided glossary before proceeding, or may reference it as needed.},
key = {Database systems},
keywords = {Computer software selection and evaluation;Performance;},
note = {DB2;},
} 


@inproceedings{20122615166184,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Space constructible radiator (SCR) life test heat pipe performance testing and evaluation},
journal = {SAE Technical Papers},
author = {Mai, T.D. and Sifuentes, R.T. and Chen, A.L. and Cornwell, J.D.},
year = {1994},
issn = {01487191},
address = {Friedrichshafen, Germany},
abstract = {The Space Constructible Radiator (SCR) Life Test heat pipe performance testing is currently conducted at NASA/Johnson Space Center as part of the Advanced Technology Development Program. The SCR is a dual passage, monogroove heat pipe radiator designed and manufactured by Grumman Aerospace for NASA. The heat pipe has many aerospace applications since it can transport a large amount of heat with a compact lightweight design. As the micro-meteoroid/orbital debris environment worsens, it may be advantageous to add the heat pipe radiator to the Space Station's thermal control system. The SCR Life Test has been operating over the last 10 years and will continue until the year 2000. The overall heat transfer coefficient has decreased from 792 W/K (1500 Btu/Hr-&deg;F) to 475 W/K (900 Btu/Hr-&deg;F) but appears to have stabilized. This paper summarizes the SCR Life Test setup and the test results to date. &copy; Copyright 1994 Society of Automotive Engineers, Inc.<br/>},
key = {Heat pipes},
keywords = {Aerospace applications;Control systems;Environmental management;Heat transfer;NASA;Radiators;Slip forming;Software testing;Space debris;Space platforms;Space stations;Testing;},
note = {Advanced technology development;Large amounts;Life-tests;Lightweight design;Overall heat transfer coefficient;Pipe performance;Space centers;Thermal control systems;},
URL = {http://dx.doi.org/10.4271/941437},
} 


@inproceedings{20170403289953,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research and comparative analysis of performance test on SDN controller},
journal = {2016 1st IEEE International Conference on Computer Communication and the Internet, ICCCI 2016},
author = {Fan, Yamei and Qing, Liao and Qi, He},
year = {2016},
pages = {207 - 210},
address = {Wuhan, China},
abstract = {The emergence of Software Defined Network(SDN) gives the demand of big data and network management a chance. SDN separates the control and forwarding in traditional network through OpenFlow protocol. In the software-defined network, SDN controller is an important integral part that is the core of SDN. In this paper, firstly we summarize the common SDN controller, and choose two popular, wider using open-source controllers(OpenDaylight and ONOS), analyze the implementation architecture and model framework of the two controllers. Then build the controller platform, simulate the underlying topology using IXIA test instruments, Cbench and Mininet to get the performance parameters and furthermore analyze the data. &copy; 2016 IEEE.},
key = {Information management},
keywords = {Big data;Controllers;Open source software;Testing;},
note = {Comparative analysis;Implementation architecture;Model framework;ONOS;OpenDaylight;Performance parameters;Performance tests;Test instruments;},
URL = {http://dx.doi.org/10.1109/CCI.2016.7778909},
} 


@article{20154601556944,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Surface structure biomimetic design and performance testing of slippery trapping plate used for controlling agricultural insect},
journal = {Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering},
author = {Wang, Lixin and Huang, Fengshan and Zhou, Qiang},
volume = {31},
number = {20},
year = {2015},
pages = {34 - 40},
issn = {10026819},
abstract = {The technology of photoelectric inducing-trapping can kill agricultural insect (locust, ant, etc.) and protect the agricultural production from being destroyed effectively, and avoid the environment pollution caused by spraying pesticide. The key factor of this technology is to develop a kind of slippery trapping plate which can restrict insects' excellent attachment ability generated by rigid claw and adhesive pad. To obtain structural information for biomimetic developing the slippery trapping plate, surface morphology of bionic prototype (slippery zone of Nepenthes alata pitcher) was detailedly examined in August and September of 2013. Several sections (1 cm<sup>2</sup>) were cut from the slippery surface and rinsed in distilled water before being air-dried, then mounted on aluminum blocks and sputter coated, and observed with a scanning electron microscope (SEM). Fresh sample (2 cm<sup>2</sup>) was cut from slippery surface and glued to an aluminum block, and examined with a scanning white-light interferometer (SWLI). The structural parameters of slippery surface were statistically acquired via analyzing the saved images with the software belonging to the SEM and SWLI equipment. The results showed that the slippery surface is covered by a layer of dense and irregular wax crystals, along with numerous downward-directed lunate cells. Length and thickness of the platelet-shaped wax crystals was 1109.6&plusmn;68.5 nm and 89.11&plusmn;5.17 nm, respectively; the height and interval distance of the lunate cells was 20.41&plusmn;1.73 &mu;m and 71.53&plusmn;3.86 &mu;m, respectively; the angles of the lunate cell's slope and precipice was 23.1&plusmn;2.4&deg; and 76.1&plusmn;4.0&deg;, respectively. These obtained parameters suggested that the slippery zone bears micro-nano scaled surface architectures. Based on acquired structural parameters, biomimetic model of the slippery trapping plate was designed with CAXA software. The biomimetic model consisted of a substrate and an epicuticular layer, the substrate was covered by micro-scaled triangular prisms (simplified lunate cells) and numerous blind holes, and the epicuticular layer was composed of massive flaky graphite (simplified wax coverings) possessing the physical properties of lubrication and slippage. To prepare the slippery trapping plate, laser micro-fabrication technology was adopted to machine the micro-scaled architectures (triangular prisms and blind holes) of the substrate (alloy steel, 100 mm&times;50 mm&times;5 mm, length&times;width&times;thickness), and high voltage electrostatic incorporation technology was used to attach the flaky graphite (mesh number 1500-2000, dimension 6.5-10 &mu;m) to the machined substrate. The flaky graphite was put on an organic glass box (95 mm&times;45 mm&times;30 mm, length&times;width&times;height); and put the laser-machined substrate and an alloy plate on the top and bottom of the box, respectively. The positive and negative electrode of high voltage electrostatic source was respectively connected to the substrate and alloy plate, and applied high voltage electrostatic (16.0-18.0 KV) for 100-120 s. With the incorporation of the high voltage electrostatic, the flaky graphite was absorbed to the blind holes of substrate and attached tightly. To test the function of the biomimetic slippery trapping plate, attachment forces of adult locust (Locusta migratoria manilensis) were measured with an insect micro-force measurement system in July 2015. The system mainly consisted of a force transducer (1-PW4C3), a signal conditioning module (SCXI-1520), a data acquisition platform (PCI-6221), and data-processing &amp; displaying software. The locust was connected to the force transducer (along load direction) using a thin thread (12 cm long) fastened its neck position, and then put on the tested surface. The locust climbed on the tested surface along the load direction of the force transducer. When the thin thread started to pull, the locust crawled ahead frantically to attempt to break away from this restriction, so generated attachment forces and their maximal values were recorded. The results showed that values of attachment force provided by locust on bionic slippery trapping plate ranged from 328.7 mN to 458.3 mN, whereas on slippery surface ranged from 307.3 mN to 397.1 mN. Attachment force of locust on bionic slippery trapping plate (402.9&plusmn;26.1 mN) was barely 1.1 times than that on slippery surface (361.9&plusmn;25.5 mN), suggesting the biomimetic slippery trapping plate bore rather similar function as the slippery surface, thereby achieved the protected biomimetic results. The obtained conclusion provides theoretical and technical references to biomimetic development of slippery trapping plate used for controlling agricultural insect.<br/> &copy;, 2015, Chinese Society of Agricultural Engineering. All right reserved.},
key = {Plates (structural components)},
keywords = {Agricultural machinery;Agriculture;Alloy steel;Aluminum;Aluminum coatings;Binary alloys;Biomimetics;Bionics;Crystal structure;Crystals;Data acquisition;Data handling;Electrostatics;Force measurement;Graphite;Organic lasers;Pest control;Potassium alloys;Prisms;Scanning electron microscopy;Substrates;Transducers;Vanadium alloys;},
note = {Agricultural productions;Biomimetic design;Environment pollution;Laser micro-fabrication;Nepenthes pitcher;Scanning white light interferometers;Signal conditioning module;Structural information;},
URL = {http://dx.doi.org/10.11975/j.issn.1002-6819.2015.20.005},
} 


@inproceedings{20172903961802,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of an internet of things platform},
journal = {IoTBDS 2017 - Proceedings of the 2nd International Conference on Internet of Things, Big Data and Security},
author = {Esquiagola, John and Costa, Laisa and Calcina, Pablo and Fedrecheski, Geovane and Zuffo, Marcelo},
year = {2017},
pages = {309 - 314},
address = {Porto, Portugal},
abstract = {The Internet of Things (IoT) is a network of physical objects, or things, with embedded electronics, software, sensors, and connectivity. The connection of all these things leverages value generation, by offering new services and strategic information. In order to make the Internet of Things possible, the integration of many technologies is necessary, such as machine-To-machine and cyber-physical systems. The process of testing IoT applications introduces new challenges because it does not only includes typical test strategies and methodologies. Testing an IoT system depends on its the specific configuration, and it also needs to consider the hardware platform and the network environment. Currently, industry and academy efforts are focusing on usability and connectivity tests, such as: simulating the environment where the device is to be used, and ensuring information is exchanged in a secure manner. In this paper, we use the current version of our IoT platform to perform stress testing of our IoT platform under different conditions. Our test methodology for IoT applications is also presented. Three different hardware platforms have been used for performing the stress testing of our platform. Copyright &copy; 2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
key = {Internet of things},
keywords = {Big data;Cyber Physical System;Embedded systems;Hardware;Testing;},
note = {Embedded electronics;Hardware platform;Internet of thing (IOT);IOT applications;Machine to machines;Network environments;Performance;Performance testing;},
} 


@inproceedings{20100312647310,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Bridging the gap between manufacturing reality and design assumptions: Chaining manufacturing analyses and defects with performance testing},
journal = {Proceedings from the 12th International Conference on Modeling of Casting, Welding, and Advanced Solidification Processes},
author = {Sholapurwalla, Adi and Scott, Sam},
year = {2009},
pages = {101 - 109},
address = {Vancouver, BC, Canada},
abstract = {In today's competitive environment it has become commonplace for foundries to incorporate capabilities such as component design, part assembly and other non-traditional foundry operations. To predict the behavior of a casting component under service conditions, value-added functionality has also been integrated into engineering software by linking solutions together and adding multi-physics analyses into the design cycle. The structural simulation of safety components made of die cast alloys is frequently based on the assumption of a homogenous distribution of mechanical properties. In reality defects caused by the production process like porosity is one of the most degrading factors leading to non-homogenous mechanical properties. In order to predict the behavior of the part under service conditions, it is necessary to take into account the influence of the porosity distribution resulting from the casting process into the structural simulation. This production part is then used in a performance analysis, such as crash or impact, to observe how the as-cast part will perform in its actual usage. This paper describes a methodology to model the complete High Pressure Die Casting (HPDC) process, determine macro and micro porosity results and then map these porosity results onto a geometry which can be used for a crash/impact analysis. The porosity map leads to a more correct description of the mechanical strength of the component, which then leads to more accurate virtual component testing. These results will be compared to the experimentally measured porosity distribution in the actual part, as well as actual loading cases to observe the deflection and failure of the component. This type of advanced technology and predictive engineering is the next giant step in the software industry.<br/>},
key = {Porosity},
keywords = {Casting;Defects;Die casting;Foundries;Manufacture;Mechanical properties;Software engineering;Solidification;Welding;},
note = {Chaining casting and impact;Competitive environment;High pressure die casting;Impact;Porosity distributions;Predictive engineering;Strength;Structural simulations;},
} 


@inproceedings{20103013100705,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Automating performance testing of interactive Java applications},
journal = {Proceedings - International Conference on Software Engineering},
author = {Jovic, Milan and Adamoli, Andrea and Zaparanuks, Dmitrijs and Hauswirth, Matthias},
year = {2010},
pages = {8 - 15},
issn = {02705257},
address = {Cape Town, South africa},
abstract = {Interactive applications with graphical user interfaces are prevalent in today's environment: Everybody with access to any kind of computer constantly uses them. A significant body of prior work has devised approaches for automating the functional testing of such applications. However, no such work exists for automatically testing their performance. Performance testing imposes additional requirements upon GUI test automation tools: the tools have to be able to replay complex interactive sessions, and they have to avoid perturbing the application's performance. We study the feasibility of using five Java GUI capture &amp; replay tools for GUI performance test automation. Besides confirming the severity of the previously known GUI element identification problem, we also identify a related problem, the temporal synchronization problem, which is of increasing importance for GUI applications that use timer-driven activity. We find that most of the tools we study have severe limitations when used for recording and replaying realistic sessions of real-world Java applications, and that all of them suffer from the temporal synchronization problem. However, we find that the most reliable tool, Pounder, causes only limited perturbation, and thus can be used to automate performance testing. Besides the significance of our findings to GUI performance testing, the results are also relevant to capture &amp; replay-based functional GUI test automation approaches. Copyright 2010 ACM.<br/>},
key = {Software testing},
keywords = {Automation;Graphical user interfaces;Java programming language;Testing;},
note = {Functional testing;Identification problem;Interactive applications;Interactive Java applications;Interactive session;Performance testing;Temporal synchronization;Test automation tool;},
URL = {http://dx.doi.org/10.1145/1808266.1808268},
} 


@inproceedings{20170403283736,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Traction inverter performance testing using mathematical and real-time controller-in-the-loop Permanent Magnet Synchronous Motor emulator},
journal = {IECON Proceedings (Industrial Electronics Conference)},
author = {Kadam, Arvind H. and Menon, Rishi and Williamson, Sheldon S.},
year = {2016},
pages = {6651 - 6656},
address = {Florence, Italy},
abstract = {In the development stage of electric vehicle drive, simulation plays a vital role. It's a powerful tool which allows the developer to investigate various control strategies and test hardware systems in harmless work environment. The software simulations platform does have constraints. In that the complex mathematical operations take longer time to solve and eventually increases the overall simulation time and cannot perform the real-time operation. This simulation further needs to be converted to the target processor's language, either assembly or C-language, which will operate in the drive system. However, if a real-time simulation environment could be comprehended, then the real processor used in the system could be incorporated in the simulation. This eventually will eliminate the chance of introducing error during code translation as well as reduce simulation time. Also, the target controller could be tested within the simulation before introducing it the actual system. This paper discuss a concept of controller-in-loop simulation, which can be used to simulate the entire system in real-time. A simple dynamic model of Permanent Magnet Synchronous Motor is simulated with MATLAB/Simulink as well as on a TMS320F28069 digital signal processor from Texas Instruments Inc. Comparative study of simulation results of both the platforms, demonstrate that although MATLAB/Simulink provides excellent GUI and functionality, it fails to performs real-time simulation which can be accomplished with controller-in-simulation. &copy; 2016 IEEE.},
URL = {http://dx.doi.org/10.1109/IECON.2016.7793156},
} 


@article{1998434363424,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Results of the performance testing of purpose-built and PC-based electrocardiographs using a simple evaluation procedure},
journal = {Journal of Medical Engineering and Technology},
author = {Kahlmeyer, H. and Haucler, C. and Lyngsmo, K.O. and Berg, S. and Schipper, K.P.},
volume = {22},
number = {2},
year = {1998},
pages = {73 - 81},
issn = {03091902},
abstract = {This paper presents the results of the evaluation testing of six 12-lead electrocardiographs, three purpose-built instruments and three of the recently introduced personal computer-based type (PC-based). As for PC-based electrocardiographs, three examples of the MRT systems, two examples of the 300 Hz CardioScope model and one prototype of the 1200 Hz CardioScope were examined but only results for one representative example of each are given here. It was of particular interest to compare the performance advantages and limitations of the PC-based electrocardiographs with that of instruments currently in use. A test procedure was developed that can be used by a medical technical department to evaluate an electrocardiograph before making a purchase decision. The procedure includes tests of frequency response, sampling rate, 50 Hz filter attenuation, gain and common mode rejection ratio (CMRR) plus tests based upon simulated electrocardiograms (ECGs). The procedure takes account of the AHA and ECRI recommendations for electrocardiograph checks and can be completed in less than two hours. The only equipment required being an ECG simulator and a signal generator. The results of this work show that purpose-built electrocardiographs meet all normal performance requirements, whereas the PC-based types, whilst having the potential to at least equal these requirements, currently exhibit software and hardware related problems.},
key = {Electrocardiography},
keywords = {Cardiovascular system;Computer aided diagnosis;Electrophysiology;Equipment testing;Personal computers;},
note = {Electrocardiographs;},
URL = {http://dx.doi.org/10.3109/03091909809010002},
} 


@inproceedings{20151200665216,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Impact of proof load test programs on the reliability of foundations},
journal = {Geotechnical Special Publication},
author = {Abdallah, Youmna and Najjar, Shadi and Saad, George},
volume = {GSP 256},
year = {2015},
pages = {1850 - 1860},
issn = {08950563},
address = {San Antonio, TX, United states},
abstract = {Traditionally, proof-load tests have been utilized to validate design methods and construction procedures. There is currently an inconsistency in the recommendations that are available in pile design codes and practices regarding the required number of proof-load tests and the level of the proof loads. Recently, and in the framework of reliability-based design, researchers have shown that information from pile load tests may have a considerable impact on reducing the probability of failure of piles at a site, thus allowing for the use of lower factors of safety for the piles. This paper presents the results of a thorough investigation that is conducted to study the effect of choosing different proof-load test programs on the reliability of piles. This is achieved by utilizing a Bayesian approach to update the capacity distributions of piles at a site given the results of the proof-load test program. In the updating exercise, an effort is made to update both the mean and the lower-bound capacity to maximize the benefit of the collected proof load data. The significance of the results presented lies in the fact that these results constitute necessary input to any practical decision framework for choosing the number and the magnitude of the proof load test that would maximize the value of information of the test program.<br/> &copy; ASCE 2015.},
key = {Piles},
keywords = {Bayesian networks;Reliability;Software testing;Statistical tests;Test facilities;},
note = {Bayesian approaches;Capacity distribution;Construction procedures;Decision framework;Factors of safeties;Probability of failure;Reliability based design;Value of information;},
URL = {http://dx.doi.org/10.1061/9780784479087.169},
} 


@article{20152300919393,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Reliability-based design of proof load test programs for foundations},
journal = {Geotechnical Engineering},
author = {Abdallah, Y. and Najjar, S.S. and Saad, G.},
volume = {46},
number = {2},
year = {2015},
pages = {94 - 101},
issn = {00465828},
abstract = {There is currently an inconsistency in the recommendations that are available in pile design codes and practices regarding the required number of proof-load tests and the level of the proof loads. This paper presents the results of a comprehensive investigation that is conducted to study the effect of choosing different proof-load test programs on the reliability of piles. This is achieved by utilizing a Bayesian approach to update the capacity distribution of piles at a site given the results of the proof-load test program. In the updating exercise, an effort is made to update both the mean and the lower-bound capacity to maximize the benefit of the collected proof load data. The significance of the results presented lies in the fact that these results constitute necessary input to any practical decision framework for choosing the number and the magnitude of the proof load test that would maximize the value of information of the test program.<br/>},
key = {Statistical tests},
keywords = {Bayesian networks;Piles;Reliability;Software testing;Test facilities;},
note = {Bayesian approaches;Bayesian updating;Capacity distribution;Decision framework;Lower bounds;Reliability based design;Test program;Value of information;},
} 


@article{20144500152713,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {An empirical comparison of model-based and capture and replay approaches for performance testing},
journal = {Empirical Software Engineering},
author = {Macedo Rodrigues, Elder and Moreira de Oliveira, Flavio and Teodoro Costa, Leandro and Bernardino, Maicon and Zorzo, Avelino Francisco and do Rocio Senger Souza, Simone and Saad, Rodrigo},
volume = {20},
number = {6},
year = {2015},
pages = {1831 - 1860},
issn = {13823256},
abstract = {A variety of testing tools has been developed to support and automate the software testing activity. Some of them may use different techniques such as Model-based Testing (MBT) or Capture and Replay (CR). Model-based Testing is a technique for automatic generation of testing artifacts based on software models. One of the main benefits of using MBT is related to the easiness of maintaining models over code; hence, it is likely that using models as a source for automatic generation of scripts requires less effort and reduces the number of faults. Otherwise, CR-based tools basically record the user interaction with the System Under Test (SUT) and then playback the recorded test. This paper presents our effort on setting up and running an experimental study performed in order to evaluate the effort to use MBT and CR-based tools to generate performance scripts. Thus, we apply an MBT and a CR approaches for the purpose of evaluation with respect to the effort to generate scripts and scenarios from the perspective of the performance testers and the performance test engineers in the context of undergraduates, M.Sc. and Ph.D. students, performance testers and performance test engineers for the generation of performance test scripts and scenarios. Our results indicate that, for simple testing tasks, the effort of using a CR-based tool was lower than using an MBT tool, but as the complexity or size of the activities of the testing tasks increases, the advantage of using MBT increased significantly.<br/> &copy; 2014, Springer Science+Business Media New York.},
key = {Software testing},
keywords = {Automatic programming;Model checking;},
note = {Empirical studies;Experimental study;Model based testing;Performance testing;Script generation;Testing automation;},
URL = {http://dx.doi.org/10.1007/s10664-014-9337-5},
} 


@article{20142817930030,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research on GUI-based automation test technology driven by separated definition data},
journal = {International Journal of Control and Automation},
author = {Liu, Zhenyu and Chen, Qiang and Cai, Lizhi},
volume = {7},
number = {6},
year = {2014},
pages = {421 - 432},
issn = {20054297},
abstract = {GUI-based software is often developed a complicated test script with existing traditional automation software testing tools. The software automated test development technology consequently carried out some study of existing automated testing with current automated testing tools to simplify the script. The paper proposed a novel test automation technology with separated definition data, which replaced by script development or modification. The definition data are depicted for script driven, page description and test data separately. The test automation technology provided completed function and interface between this method and actual test tool. The test engineers is not need to write the any test script, but modify the definition files for test developing to some extent. The automation functional test technology has support the typical test tool and proved effective in the specific cases. &copy; 2014 SERSC.},
key = {Software testing},
keywords = {Automation;Graphical user interfaces;Testing;},
note = {Automated test;Automated testing;Automated testing tools;Automation software;Automation tests;Definition data;Functional test;Test Automation;},
URL = {http://dx.doi.org/10.14257/ijca.2014.7.6.39},
} 


@inproceedings{20144600195389,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Implementing TaaS-based stress testing by MapReduce computing model},
journal = {Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS},
author = {Hwang, Gwan-Hwan and Wu-Lee, Chi and Tung, Yuan-Hsin and Chuang, Chih-Ju and Wu, Syz-Feng},
year = {2014},
pages = {137 - 140},
issn = {23270586},
address = {Beijing, China},
abstract = {In this paper we propose to employ the MapReduce computing model to implement a Testing as a Service (TaaS) for stress testing. We focus on stress testing for heavy-weight network transactions. The computation power of MapReduce computing system is used to simulate concurrent network transactions issued by a lot of users. The user first describes the testing scenario which he wants to be simulate in a testing script. The TaaS platform analyzes the testing script and then automatically distributes required testing data including details of transactions and files into a MapReduce computing system. We propose three different schemes to distribute testing data and measure their performances. We compare them with the popular stress testing tool JMeter and find out that our scheme can always have the tested system deliver higher error rate during the stress testing.<br/> &copy; 2014 IEEE.},
key = {Software engineering},
keywords = {Electrical engineering;Engineering;Industrial engineering;},
note = {Computation power;Computing model;Computing system;Hadoop;Map-reduce;Network transactions;Stress Testing;Testing as a services;},
URL = {http://dx.doi.org/10.1109/ICSESS.2014.6933530},
} 


@inproceedings{20155101697731,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Robot-assisted smartphone performance testing},
journal = {IEEE Conference on Technologies for Practical Robot Applications, TePRA},
author = {Kanstren, Teemu and Aho, Pekka and Lamsa, Arttu and Martin, Henar and Liikka, Jussi and Seppanen, Miska},
volume = {2015-August},
year = {2015},
issn = {23250526},
address = {15 Middlesex Canal Park, Woburn, MA, United states},
abstract = {This paper describes experiences and lessons learned in applying an approach of using a physical robot for testing overall smartphone device performance based on user profiles. The process consists of capturing user actions, abstracting them to usage profiles, transforming these into test models, and generating test cases from the models. The goal is to support performance testing of touch screen devices and applications in a realistic test environment. To achieve this, the tests are based on real-world generated user profiles and executed using a real physical robot, simulating the actual user. Our performance testing targets different attributes of performance such as response times, power and resource usage, and software/hardware aging. Use of different hardware and software configurations in the test scenarios is considered. This work has been performed in close collaboration with industry partners in robotics provider and user industries.<br/> &copy; 2015 IEEE.},
key = {Software testing},
keywords = {Electronic mail;Human computer interaction;Markov processes;Robot applications;Robots;Smartphones;Testing;Touch screens;},
note = {Collaboration with industries;Device performance;Hardware and software;Performance evaluations;Performance testing;Robot kinematics;Service robots;Software/hardware;},
URL = {http://dx.doi.org/10.1109/TePRA.2015.7219669},
} 


@inproceedings{20120214675019,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Reusing functional testing in order to decrease performance and stress testing costs},
journal = {SEKE 2011 - Proceedings of the 23rd International Conference on Software Engineering and Knowledge Engineering},
author = {De Sousa Santos, Ismayle and Santos, Alcemir Rodrigues and Neto, Pedro De Alcantara Dos S.},
year = {2011},
pages = {470 - 474},
address = {Miami, FL, United states},
abstract = {This work presents an experimental study of an idea related to the automatic generation of performance and stress testing by reusing functional testing. The idea was implemented in a tool named FERRARE GT. This tool is able to generate both test scripts as well as the data required for their execution. In this study we verified that the use of the method can generate benefits related to cost reduction, from the reduction of test effort and, at the same time, benefits related to test quality, from the improvement of the test relevance for the software development.<br/>},
key = {Software testing},
keywords = {Cost reduction;Knowledge engineering;Software design;},
note = {Automatic Generation;Data generation;Experimental study;Functional testing;Non-functional requirements;Stress Testing;Test efforts;Test quality;},
} 


@article{20170703341550,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Measurable Augmented Reality for Prototyping Cyberphysical Systems: A Robotics Platform to Aid the Hardware Prototyping and Performance Testing of Algorithms},
journal = {IEEE Control Systems},
author = {Omidshafiei, Shayegan and Agha-Mohammadi, Ali-Akbar and Chen, Yu Fan and Ure, Nazim Kemal and Liu, Shih-Yuan and Lopez, Brett T. and Surati, Rajeev and How, Jonathan P. and Vian, John},
volume = {36},
number = {6},
year = {2016},
pages = {65 - 87},
issn = {1066033X},
abstract = {Planning, control, perception, and learning are current research challenges in multirobot systems. The transition dynamics of the robots may be unknown or stochastic, making it difficult to select the best action each robot must take at a given time. The observation model, a function of the robots' sensor systems, may be noisy or partial, meaning that deterministic knowledge of the team's state is often impossible to attain. Moreover, the actions each robot can take may have an associated success rate and/or a probabilistic completion time. Robots designed for real-world applications require careful consideration of such sources of uncertainty, regardless of the control scheme or planning or learning algorithms used for a specific problem. Understanding the underlying mechanisms of planning algorithms can be challenging due to the latent variables they often operate on. When performance testing such algorithms on hardware, the simultaneous use of the debugging and visualization tools available on a workstation can be difficult. This transition from experimentation to implementation becomes especially challenging when the experiments need to replicate some feature of the software tool set in hardware, such as simulation of visually complex environments. This article details a robotics prototyping platform, called measurable augmented reality for prototyping cyberphysical systems (MAR-CPS), that directly addresses this problem, allowing for the real-time visualization of latent state information to aid hardware prototyping and performance testing of algorithms. &copy; 2016 IEEE.},
key = {Robot programming},
keywords = {Augmented reality;Computer aided software engineering;Computer debugging;Computer software;Embedded systems;Hardware;Learning algorithms;Program debugging;Real time systems;Robotics;Robots;Stochastic systems;Visualization;},
note = {Complex environments;Cyber physical systems (CPSs);Hardware prototyping;Prototyping platform;Real time visualization;Research challenges;Sources of uncertainty;Visualization tools;},
URL = {http://dx.doi.org/10.1109/MCS.2016.2602090},
} 


@inproceedings{20142817910404,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing web applications on the cloud},
journal = {Proceedings - IEEE 7th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2014},
author = {Mukherjee, Joydeep and Wang, Mea and Krishnamurthy, Diwakar},
year = {2014},
pages = {363 - 369},
address = {Cleveland, OH, United states},
abstract = {Web applications are increasingly resorting to public cloud platforms such as the Amazon Web Services (AWS) Elastic Compute Cloud (EC2). However, previous studies have shown that the virtualized infrastructures used in a cloud environment can introduce performance issues. Hence, it is crucial to test the performance of the cloud to support Web applications. This is challenging because the performance effect of the cloud platform cannot be easily isolated from other extraneous factors. In this paper, we present a systematic experimental process to address this challenge. Following our proposed process, we test the performance of Web applications running on different types of AWS EC2 instances. Results suggest that Web server response times can fluctuate up to 1000% for the same workload under certain circumstances such as instance type, time-of-the-day, and day-of-the-week. &copy; 2014 IEEE.<br/>},
key = {Software testing},
keywords = {Verification;Web services;},
note = {Amazon web services;Cloud environments;Cloud platforms;Elastic compute clouds;Performance effect;Performance issues;Performance testing;WEB application;},
URL = {http://dx.doi.org/10.1109/ICSTW.2014.57},
} 


@article{20072010604779,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Incorporating performance testing in test-driven development},
journal = {IEEE Software},
author = {Johnson, Michael J. and Maximilien, E. Michael and Ho, Chih-Wei and Williams, Laurie},
volume = {24},
number = {3},
year = {2007},
pages = {67 - 73},
issn = {07407459},
abstract = {Performance design and performance testing are necessarily different from functional test case design. A rigorous test-driven design methodology isn't practical for all performance measurement. A test-first approach to performance provides some advantages in a TDD environment. Experience with applying early performance testing in a TDD framework for a device-driver development project provides insight into the test-first approach. The results show a trend of performance improvement throughout the development life cycle, and better performance compared to an earlier release. Lessons learned include the benefit of having a performance architect on the development team and of tracking performance measurements throughout the development life cycle.This article is part of a special issue on test-driven development. &copy; 2007 IEEE.},
key = {Software engineering},
keywords = {Software design;Software testing;},
note = {Test execution;Test-driven design;Test-driven development;},
URL = {http://dx.doi.org/10.1109/MS.2007.77},
} 


@article{2006109749019,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research on queuing-model-based framework for software performance testing},
journal = {Jisuanji Gongcheng/Computer Engineering},
author = {Ouyang, Rongbin and Guo, Zhi and Gu, Ming},
volume = {32},
number = {3},
year = {2006},
pages = {73 - 75},
issn = {10003428},
abstract = {This paper presents a new performance testing framework which uses simulation and modeling techniques based on queuing model. For the framework, it presents an algorithm to estimate the simulation model's parameters. With the framework, it can generate volumes of simulated test data according to a small quantity of real data. The framework is practiced on the performance testing of Beijing one-card-multiple-services system.},
} 


@article{20140517243353,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Comprehensive load test on prestressed concrete piles in alluvial clays and marl in Savannah, Georgia},
journal = {Journal of Performance of Constructed Facilities},
author = {Tan, Yong and Lin, Guoming},
volume = {28},
number = {1},
year = {2014},
pages = {178 - 190},
issn = {08873828},
abstract = {This paper introduces a comprehensive full-scale pile load test program on 457-mm (18-in.) square prestressed concrete (PSC) piles in Savannah, Georgia. The program consisted of pile driving analyzer testing during initial pile driving and restrikes, Statnamic tests, static axial compression load tests, and reciprocal lateral load tests. On the basis of the interpretation of the test data, some important findings were obtained: (1) the alluvial clays in Savannah can only provide very limited resistance; (2) the time-dependent pile capacity gain after pile driving (i.e., setup effect) was approximately proportional to the pile embedment length into the Marl formation; (3) the estimated equivalent static pile capacities from the Statnamic tests were comparable to those from the static axial load tests; (4) the Marl formation is a competent bearing stratum for piles; (5) the potential degradation of pile concrete stiffness caused by pile driving should be accounted for in pile capacity analysis; and (6) the piles exhibited stiffer response under the monotonic lateral loading condition than the cyclic lateral loading condition. Finally, predictions on both axial and lateral pile capacities, using the soil parameters derived from the instrumentation data and back-analysis of the pile load tests, were compared with the corresponding pile load test results. The comparisons demonstrate that in combination of the static-bearing capacity formulas and the LPILE program, the developed soil models can make reliable predictions on both the vertical and lateral behaviors of the PSC piles driven through the soft alluvial clays to end bearing in the Marl formation. &copy; 2014 American Society of Civil Engineers.<br/>},
key = {Piles},
keywords = {Axial loads;Concrete beams and girders;Fertilizers;Load testing;Pile driving;Prestressed concrete;Software testing;},
note = {Alluvial clay;Axial compression load;Bearing capacity formulas;Cyclic lateral loading;Lateral load tests;Lateral loading conditions;Marl formation;Pile driving analyzers;},
URL = {http://dx.doi.org/10.1061/(ASCE)CF.1943-5509.0000305},
} 


@inproceedings{20143118006642,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Automated Generation of Performance Test Cases from Functional Tests for Web Applications},
journal = {Communications in Computer and Information Science},
author = {Toledo Rodriguez, Federico and Reina, Matias and Baptista, Fabian and Polo Usaola, Macario and Perez Lamancha, Beatriz},
volume = {417 CCIS},
year = {2013},
pages = {164 - 173},
issn = {18650929},
address = {Angers, France},
abstract = {When modernizing systems there are big risks concerning functional and non-functional properties. It is expected that the functionality, the performance and the dependability are the same (or better) in the new version. Therefore, the preventive workload simulation (to verify non-functional properties) is crucial to guarantee the success of the modernization project. Since tools for load simulation work at protocol level, the automation of tasks for workload simulation demand much more effort than functional testing, whose test cases are designed using record and playback techniques on the GUI: these tools are more intuitive and they have to handle less variables and technical issues. In this article we present a tool to automatically generate workload simulation scripts from automated functional tests. The tool has been used in several projects in the industry, achieving important cost savings and improving flexibility when verifying non-functional properties of a migrated system. &copy; Springer-Verlag Berlin Heidelberg 2013.<br/>},
key = {Software testing},
keywords = {Automation;Load testing;},
note = {Automated generation;Functional testing;Modernization projects;Non functional properties;Non-functional;Performance tests;Record and playback;Testing automation;},
URL = {http://dx.doi.org/10.1007/978-3-642-54092-9_12},
} 


@article{20093612285539,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A preliminary study on the fracture behaviors of reinforced concrete slabs by monitoring the load test using acoustic emission method},
journal = {Journal of the Chinese Institute of Civil and Hydraulic Engineering},
author = {Pei, K.C. and Kan, Y.C. and Yen, T. and Lin, D.W.},
volume = {21},
number = {2},
year = {2009},
pages = {155 - 168},
issn = {10155856},
abstract = {This paper presents the use of Acoustic Emission Technique (AE) to evaluate the fracture behavior of different RC slabs under the load test. During the load test, AE inspection was applied using a self-developed instrument to record/monitor the emitted ultrasonic waves within the 2 &times; 2 m slab-type specimens. AE records for three RC slabs were demonstrated here for analyzing in hit-count, frequency and wave-form. These results revealed the "Kaiser effect" and the "intermittent" characteristic due to the concrete-rebar mechanism and other composite behaviors. The experimental program is based on monitoring the load tests of three RC slabs with 280 kg/cm<sup>2</sup>concrete strength. The Kaiser effect was validated and the characteristics of various reinforcement arrangements of slab were found while the load tests were being performed.<br/>},
key = {Acoustic emission testing},
keywords = {Acoustic emissions;Concrete slabs;Fracture;Fracture mechanics;Load testing;Reinforced concrete;Software testing;Ultrasonic applications;},
note = {Acoustic emission method;Acoustic emission techniques;Composite behavior;Concrete strength;Experimental program;Kaiser effect;RC slab;Reinforcement arrangements;},
} 


@article{20091912076008,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Investigation of shear resistance of steel bridge girders by load testing and monitoring of load response data under highway traffic conditions},
journal = {Canadian Journal of Civil Engineering},
author = {Au, Alexander and Lam, Clifford and Tharmabala, Bala},
volume = {36},
number = {3},
year = {2009},
pages = {449 - 462},
issn = {03151468},
abstract = {A recent strength evaluation of the Hogg's Hollow Bridge on Highway 401 in Ontario revealed a significant deficiency in the shear resistance of the existing girders at support locations. This was attributed to the absence of transverse stiffeners at the extreme ends of the girders. However, none of the bridge girders showed any signs of distress. The Ontario Ministry of Transportation recently conducted a field study to investigate this shear issue in greater detail. To that end, a test program was devised to (a) monitor the real stresses in the end panels of two selected girders in the Hogg's Hollow Bridge when subjected to (i) a test truck with known axle loads and (&laquo;) normal highway traffic loading, and (b) calibrate the observed stresses against theoretically expected responses in the girders and calculate the live load capacity factor using the shear data derived from the field measurements.<br/>},
key = {Highway bridges},
keywords = {Automobile testing;Load testing;Plate girder bridges;Software testing;Steel bridges;Steel testing;Traffic surveys;},
note = {Bridge testing;Field measurement;Live-load capacity;Shear resistances;Steel bridge girders;Strength evaluation;Traffic loads;Transverse stiffener;},
URL = {http://dx.doi.org/10.1139/L09-009},
} 


@inproceedings{20090311864290,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Ultrasonic diagnostic load testing of steel highway bridges},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Mandracchia, Efrain A.},
volume = {2946},
year = {1996},
pages = {17 - 25},
issn = {0277786X},
address = {Scottsdale, AZ, United states},
abstract = {This paper presents a new product, the SonicForce&trade; Acoustic Strain Gauge (ASG), that utilizes a non-contact ultrasonic technology to measure applied strain requiring no paint removal and minimal surface preparation. After an overview of the ultrasonic technology is presented the results of a diagnostic test utilizing a prototype of the ASG will be discussed. The purpose of this test was to validate the Acoustic Strain Gauge as being functionally equivalent to the resistance strain gauge, and to demonstrate a cost effective enabling technology to the civil and structural engineering communities. The diagnostic tests program was supervised by Dr. Abba Lichtenstein in accordance with accepted guidelines contained in the manual for "Rating Bridges Through Testing" For the purpose of this study the bridge superstructure was modeled and structural loading profiles were determined using both resistive and acoustic strain measurement techniques. Measured strains as determined by the ASG (correlation between the ASG and the resistance strain gauge was 0.998) were compared to theoretical loads in order to determine if the Rodeo Gulch superstructure was operating in a safe and reliable manner. Additionally, under the direction of Phil Fish (Wisconsin DOT), two pre-production ASGs were used to monitor accumulated cyclic loading. These test data presented as a time series strip chart and rainflow histogram. &copy;2005 Copyright SPIE - The International Society for Optical Engineering.<br/>},
key = {Ultrasonic testing},
keywords = {Cost effectiveness;Cost engineering;Highway bridges;Load testing;Nondestructive examination;Program diagnostics;Software testing;Steel testing;Strain;Strain gages;Ultrasonics;},
note = {Applied strain;Bridge diagnostics;Civil and structural engineerings;EMAT;Measurement techniques;Rainflow;Resistance strain gauges;Ultrasonic diagnostics;},
URL = {http://dx.doi.org/10.1117/12.259142},
} 


@inproceedings{20133716718139,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A case study of automating user experience-oriented performance testing on smartphones},
journal = {Proceedings - IEEE 6th International Conference on Software Testing, Verification and Validation, ICST 2013},
author = {Canfora, Gerardo and Mercaldo, Francesco and Visaggio, Corrado Aaron and D'Angelo, Mauro and Furno, Antonio and Manganelli, Carminantonio},
year = {2013},
pages = {66 - 69},
address = {Luxembourg, Luxembourg},
abstract = {We have developed a platform named Advanced Test Environment (ATE) for supporting the design and the automatic execution of UX tests for applications running on Android smart phones. The platform collects objective metrics used to estimate the UX. In this paper, we investigate the extent that the metrics captured by ATE are able to approximate the results that are obtained from UX testing with real human users. Our findings suggest that ATE produces UX estimations that are comparable to those reported by human users. We have also compared ATE with three widespread benchmark tools that are commonly used in the industry, and the results show that ATE outperforms these tools. &copy; 2013 IEEE.},
key = {Smartphones},
keywords = {Design;Robots;Software testing;Tools;},
note = {Advanced tests;android;Android smart phones;Mobile applications;Objective metrics;Performance testing;usability;User experience;},
URL = {http://dx.doi.org/10.1109/ICST.2013.16},
} 


@inproceedings{1995122539885,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Condenser and feedwater heater computerized performance testing and diagnostic programs},
journal = {American Society of Mechanical Engineers, Power Division (Publication) PWR},
author = {Diaz-Tous, I.A. and Mateos, M.A.},
volume = {25},
year = {1994},
pages = {165 - 172},
address = {Phoenix, AZ, USA},
abstract = {Accurate interpretation of performance-test results can lead to improved unit heat-rate and reduced equipment failure or damage when appropriate and timely corrective actions are taken. Aware of the difficulties inherent in performance testing as well as the need for a PC-based tool to support performance engineers in power plant problem diagnosis, NYSEG and ENCOR commenced developing (in 1990) the Computerized Performance Test Program (CPTP). CPTP is designed to ease performance testing, enhance the quality of performance-test results and provide correct diagnostics and recommendations for actions to the performance-test engineer and power-operations management. To accomplish these goals, CPTP utilizes expert algorithms based on the years of experience accumulated by the engineering staffs at NYSEG and ENCOR. Such experience is demonstrated by the extensive guidance provided by CPTP regarding the prioritization of equipment testing and the preparation and execution of the proper test procedures. Equally insightful are the interpretation of the test results and the corrective actions prescribed to solve diagnosed problems. For all these reasons, CPTP is an effective training tool for plant personnel to improve the performance of the condenser and feedwater heaters and plan the maintenance of any power plant. Currently, NYSEG and Portland General Electric (PGE) are using CPTP modules for performance testing, diagnostic and training purposes.},
key = {Feedwater heaters},
keywords = {Algorithms;Computer aided analysis;Computer software;Condensers (liquefiers);Performance;},
note = {Computerized performance test program (CTCP);Diagnostic programs;},
} 


@inproceedings{20155101691349,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Reverse Tracer: A software tool for generating realistic performance test programs},
journal = {Proceedings - International Symposium on High-Performance Computer Architecture},
author = {Sakamoto, M. and Brisson, L. and Katsuno, A. and Inoue, A. and Kimura, Y.},
volume = {2002-January},
year = {2002},
pages = {81 - 91},
issn = {15300897},
address = {Cambridge, MA, United states},
abstract = {During the development of high-performance processors, software performance models are used to obtain performance estimates. These models are not cycle-accurate, so their results can have significant errors, leading to performance surprises after the hardware is built. Some performance tests can run directly on the logic simulators, to get more accurate results, but those simulators cannot run large interactive workloads with I/O and much operating system code. So the accurate performance estimates from logic simulators are only available for application code, and are not adequate for the evaluation of powerful server systems that are primarily intended to run large interactive workloads. We discuss a software tool system, the "Reverse Tracer", that generates executable performance tests from an instruction trace of the workload. The generated performance tests retain the essential performance characteristics of multi-user I/O-intensive workloads without doing any real I/O, so they can run in logic simulation to measure performance accurately before the hardware is built.<br/> &copy; 2002 IEEE.},
key = {Software testing},
keywords = {Computer aided software engineering;Computer architecture;Computer circuits;Embedded systems;Hardware;Simulators;Supercomputers;},
note = {Accurate performance;Application codes;Cycle accurate;High performance processors;Logic simulations;Performance characteristics;Performance tests;Software performance models;},
URL = {http://dx.doi.org/10.1109/HPCA.2002.995700},
} 


@inproceedings{20110413611893,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Proposal of automated performance testing tool for vital software in train control system},
journal = {ICCAS 2010 - International Conference on Control, Automation and Systems},
author = {Jo, Hyun-Jeong and Hwang, Jong-Gyu and Lee, Kang-Mi},
year = {2010},
pages = {1151 - 1155},
abstract = {In accordance with the development of recent computer technology, the dependency of train control system on the computer software is being increased further, and accordingly, the testing for the safety and reliability of train control system software became more important. Hence, the safety assurance of the vital software running on the train control system is very critical task and yet, not many works have been done. While much efforts have been reported to improve electronic hardware's safety, not so much systematic approaches to evaluate software's safety. In this paper, we suggested an automated tool for performance testing in train control system, and presented its result of implementation. The testing items in the implemented tool had referred to the international standards in relation to the software for train control system, such as IEC 61508 and IEC 62279. In these international standards, 'performance testing' for train control system S/W has to be recommended highly. &copy;ICROS.<br/>},
key = {Computer control systems},
keywords = {Automation;Computer control;Computer software selection and evaluation;Safety testing;Software reliability;Software testing;Vehicle performance;},
note = {Automated tools;Computer technology;Electronic hardwares;International standards;Performance testing;Safety assurance;Software safety;Train control systems;},
} 


@inproceedings{20153001060092,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Analysis and design of selenium webdriver automation testing framework},
journal = {Procedia Computer Science},
author = {Gojare, Satish and Joshi, Rahul and Gaigaware, Dhanashree},
volume = {50},
year = {2015},
pages = {341 - 346},
issn = {18770509},
address = {Chennai, India},
abstract = {Nowadays, number of software system has been implemented as web-based applications. These web applications are very complex. It is very difficult to test such complex web applications. Automation testing uses automation tools to reduce human intervention and repeatable tasks. In this paper we have designed and implemented automation testing framework for testing web applications. This new automation testing framework has been implemented using selenium WebDriver tool. Using this framework tester can easily write their test cases efficiently and in less time. Tester need not to study the selenium webdriver tool in detail. This framework is helpful to developer to analyze their code due to screen shot property of framework. This framework produces the customized test report to tester. It is very easy to maintain and repair the test suite for new release of the application using this framework.<br/> &copy; 2015 The Authors. Published by Elsevier B.V.},
key = {Big data},
keywords = {Application programs;Automation;Selenium;},
note = {Automation testing;Automation tools;Human intervention;Software systems;Test reports;Test suites;WEB application;Web-based applications;},
URL = {http://dx.doi.org/10.1016/j.procs.2015.04.038},
} 


@inproceedings{20174104268960,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Based on the analysis of mobile terminal application software performance test},
journal = {Proceedings - 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing, SNPD 2017},
author = {Chunye, Du and Wei, Song and Jianhua, Wu},
year = {2017},
pages = {391 - 394},
address = {Kanazawa, Japan},
abstract = {With the rapid development of mobile terminal, mobile applications are gradually penetrated into all aspects of people's life and work. Mobile games, mobile streaming media, location services, mobile Internet news, instant messaging, mobile music and other rich and colorful information era are changing the social life. In view of this, we propose the application software performance test based on the mobile terminal, and analyze the performance test technology and method of the mobile application. Experimental results show that the performance test of the application system can predict the pressure in real environment, the system will be applied in the problems exposed, through the analysis of the data of the test, it will provide help for performance optimization of application system. &copy; 2017 IEEE.},
key = {Application programs},
keywords = {Artificial intelligence;Computer software;Computer terminals;Media streaming;Mobile computing;Mobile phones;Mobile telecommunication systems;Software engineering;Software testing;Testing;},
note = {Loadrunner;Mobile applications;Mobile terminal;Performance tests;Test method;Test technology;},
URL = {http://dx.doi.org/10.1109/SNPD.2017.8022751},
} 


@inproceedings{1994031191086,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Load testing software using deterministic state testing},
journal = {Proceedings of the 1993 International Symposium on Software Testing and Analysis (ISSTA)},
author = {Avritzer, Alberto and Larson, Brian},
year = {1993},
pages = {82 - 88},
address = {Cambridge, MA, USA},
abstract = {In this paper we introduce a new load testing technique called Deterministic Markov State Testing and report on its application. Our approach is called 'deterministic' because the sequence of test case execution is set at planning time, and 'state testing' because each test case certifies a unique software state. There are four main advantages of Deterministic Markov State Testing for system testers: provision of precise software state information for root cause analysis in load test, accommodation for limitations of the system test lab configuration, higher acceleration ratios in system test, and simple management of distributed execution of test cases. System testers using the proposed method have great flexibility in dealing with common system test problems: limited access to the system test environment, unstable software, or changing operational conditions. Because each test case verifies correct execution on a path from the idle state to the software state under test, our method does not require the continuous execution of all test cases. Deterministic Markov State Testing is operational-profile-based, and allows for measurement of software reliability robustness when the operational profile changes.},
key = {Computer software},
keywords = {Computer system recovery;Distributed computer systems;Failure analysis;Probability;Random processes;Reliability;Robustness (control systems);Software engineering;Statistical tests;Telecommunication systems;},
note = {Deterministic Markov State Testing;Load testing software;Operational profile;Planning time;Software reliability robustness;System testers;},
} 


@inproceedings{20131016093036,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Application stress testing: Achieving cyber security by testing cyber attacks},
journal = {2012 IEEE International Conference on Technologies for Homeland Security, HST 2012},
author = {Underbrink, Al and Potter, Andrew and Jaenisch, Holger and Reifer, Donald J.},
year = {2012},
pages = {556 - 561},
address = {Waltham, MA, United states},
abstract = {Application stress testing applies the concept of computer network penetration testing to software applications. Since software applications may be attacked - from inside or outside a protected network boundary - they are threatened by actions and conditions which cause delays, disruptions, or failures. Stress testing exposes software systems to simulated cyber attacks, revealing potential weaknesses and vulnerabilities in their implementation. By using such testing, these internal weaknesses and vulnerabilities can be discovered earlier in the software development life cycle, corrected prior to deployment, and lead to improved software quality. Application stress testing is a process and software prototype for verifying the quality of software applications under severe operating conditions. Since stress testing is rarely - if at all - performed today, the possibility of deploying critical software systems that have been stress tested provides a much stronger indication of their ability to withstand cyber attacks. Many possible attack vectors against critical software can be verified as true threats and mitigated prior to deployment. This improves software quality and serves as a tremendous risk reduction for critical software systems used in government and commercial enterprises. The software prototype models and verifies failure conditions of a system under test (SUT). The SUT is first executed in a virtual environment and its normal operational modes are observed. A normal behavior model is generated in order to predict failure conditions based on attack models and external SUT interfaces. Using off-the-shelf software tools, the predictions are verified in the virtual environment by stressing the executing SUT with attacks against the SUT. Results are presented to testers and system developers for dispensation or mitigation. &copy; 2012 IEEE.},
key = {Software testing},
keywords = {Ability testing;Application programs;Computer software selection and evaluation;Crime;National security;Security systems;Software design;Software prototyping;Virtual reality;},
note = {Application testing;attack;Attack model;Attack vector;Commercial enterprise;Critical software;Cyber security;Cyber-attacks;Failure conditions;Network penetration testing;Normal behavior;Operating condition;Operational modes;Penetration testing;Protected networks;Quality of softwares;Risk reductions;Software applications;Software assurance;Software development life cycle;Software prototypes;Software Quality;Software systems;Stress Testing;System developers;System under test;},
URL = {http://dx.doi.org/10.1109/THS.2012.6459909},
} 


@inproceedings{20180104610715,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and implementation of bank financial business automation testing framework based on QTP},
journal = {Proceedings of 2016 5th International Conference on Computer Science and Network Technology, ICCSNT 2016},
author = {Xie, Xianjie and Yang, Zhijun and Yu, Jiankun and Zhang, Weifeng},
year = {2016},
pages = {143 - 147},
address = {Changchun, China},
abstract = {The current software testing in the aspects of industrial benefits gradually causes the attention of the domestic financial bank. The innovation of software technology, the increase of software scale and the shortened developing period make the traditional manual testing meeting enormous challenges, while the development of automated testing technology has promoted the progress of the software testing industry. Because of the particularity of financial and banking services, the bank is under an obligation to ensure the quality and reliability of software. Therefore it's vital to test the software. In specific practice, although the powerful third-party testing tools can be used as a solution, it is hard to rely on certain tool to implement automated testing, hence a framework of automated test is required to be introduced for testing, which intends to handle high efficiency and high-quality testing for software automation. This paper proposes a kind of software automation testing framework based on QTP, mainly targeting on the core of the bank, credit, online banking to test the function of the three major operations. The framework is a secondary development based on QTP and mainly for regression testing of software, which integrates techniques including object recognition, data-driven, and keyword-driven technology, checkpoint technology, to proceed business-level testing. The paper expatiated on four issues, which were the test system design, the test standardization, the testing framework design and the testing of the implementation. The practical application shows that the framework can improve the operational efficiency, reduce the test cost, and guarantee the smooth progress of the software automation testing.<br/> &copy; 2016 IEEE.},
key = {Software testing},
keywords = {Application programs;Automation;Computer networks;Computer software;Efficiency;Finance;Object recognition;Software engineering;Software reliability;Testing;},
note = {Automated testing tools;Business automation;Design and implementations;Operational efficiencies;Secondary development;Software automation;Software technology;Test automation frameworks;},
URL = {http://dx.doi.org/10.1109/ICCSNT.2016.8070136},
} 


@inproceedings{1994011191086,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Load testing software using deterministic state testing},
author = {Avritzer, Alberto and Larson, Brian},
year = {1993},
pages = {82 - 88},
address = {Cambridge, MA, United states},
abstract = {In this paper we introduce a new load testing technique called Deterministic Markov State Testing and report on its application. Our approach is called 'deterministic' because the sequence of test case execution is set at planning time, and 'state testing' because each test case certifies a unique software state. There are four main advantages of Deterministic Markov State Testing for system testers: provision of precise software state information for root cause analysis in load test, accommodation for limitations of the system test lab configuration, higher acceleration ratios in system test, and simple management of distributed execution of test cases. System testers using the proposed method have great flexibility in dealing with common system test problems: limited access to the system test environment, unstable software, or changing operational conditions. Because each test case verifies correct execution on a path from the idle state to the software state under test, our method does not require the continuous execution of all test cases. Deterministic Markov State Testing is operational-profile-based, and allows for measurement of software reliability robustness when the operational profile changes.},
key = {Computer software},
keywords = {Statistical tests;Software engineering;Robustness (control systems);Reliability;Distributed computer systems;Telecommunication systems;Random processes;Probability;Failure analysis;Computer system recovery;},
note = {Load testing software;Deterministic Markov State Testing;System testers;Software reliability robustness;Operational profile;Planning time;},
URL = {http://dx.doi.org/10.1145/154183.154244},
} 


@inproceedings{20174604403370,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Automation testing framework for web applications with selenium WebDriver: Opportunities and threats},
journal = {ACM International Conference Proceeding Series},
author = {Vila, Elior and Novakova, Galia and Todorova, Diana},
volume = {Part F131200},
year = {2017},
pages = {144 - 150},
address = {Bangkok, Thailand},
abstract = {The present paper discusses the need of automation testing in the process of software development, in order to provide high quality, robust and reliable software product. It answers the question why automation testing plays such a significant role in software development lifecycle as well as why not to use already existing automation testing tools when testing web applications and why it is better to create automation testing framework. Some reliable approaches how to build a testing framework are investigated. Selenium WebDriver tool is pointed out as appropriate solution when creating such framework and its wide use is outlined. Moreover, the paper provides analysis and detailed list of opportunities and threats of using Selenium WebDriver tool. The paper concludes by providing arguments for the value of the creation of automation framework for Web applications with Selenium WebDriver.<br/> &copy; 2017 Association for Computing Machinery.},
key = {Software testing},
keywords = {Application programs;Automation;Image processing;Network function virtualization;Selenium;Software design;Software engineering;},
note = {Automation testing;High quality;Software development life cycle;Software products;Testing framework;WEB application;},
URL = {http://dx.doi.org/10.1145/3133264.3133300},
} 


@inproceedings{1991100274593,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Development of an economical, software-controlled battery load testing system},
journal = {INTELEC, International Telecommunications Energy Conference (Proceedings)},
author = {Hadfield, J.A.},
year = {1990},
pages = {553 - 555},
issn = {02750473},
address = {Orlando, FL, USA},
abstract = {Battery discharge capacity tests have traditionally been performed manually, although several mechanized systems are commercially available. A need was identified at the Manitoba Telephone System (MTS) to accurately and economically load test batteries in the field, to verify the capacity of new installations as well as to assist determining the true end-of-life of existing strings. The development of an economical, software-controlled system for testing -48-volt battery strings in the telephone environment is discussed.},
key = {Electric Batteries},
keywords = {Computer Software;Electric Discharges;Telephone Systems;},
note = {Battery Discharges;Battery Loads;Battery Strings;},
} 


@inproceedings{20102713049591,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Webteste: A stress test tool},
journal = {WEBIST 2006 - 2nd International Conference on Web Information Systems and Technologies, Proceedings},
author = {Saba, Hugo and De Freitas Jorge, Eduardo Manuel and Costa, Victor Franco and De Barros Pereira, Hernane Borges},
volume = {IT/WIA},
year = {2006},
pages = {246 - 249},
address = {Setubal, Portugal},
abstract = {The usage of web applications has became a very common activity in the organizations' scope. From the software engineering perspective, the incessant search for production of more robust softwares, with better quality, is a continuous requirement. The main purpose of this paper is to present the WebTeste, which is a test tool used to verify the robustness of a web application. After comparison of several simulation's results, the use of distributed and ordered computers suggests more reliable tests. In addition, the analysis of the obtained results can suggest a new (re)design of a web system. The WebTeste could be used to perform stress test in order to verify the robustness of a web application more precisely. &copy; 2010.},
key = {Web crawler},
keywords = {Information systems;Software engineering;Testing;},
note = {Engineering perspective;Robust software;Stress test;Stress test tools;WEB application;Web servers;Web system;WebTeste;},
} 


@inproceedings{20145000305850,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {An effective automation testing framework for OATS tool},
journal = {Advances in Intelligent Systems and Computing},
author = {Ramasamy, Gobi and Ramalingam, Sathishkumar},
volume = {324},
year = {2015},
pages = {543 - 550},
issn = {21945357},
address = {Kumaracoil, India},
abstract = {Oracle application test suite (OATS) is a test tool of Oracle. It is a very good integrated testing tool for Web applications, Web services, Oracle applications, and Oracle databases. The Oracle application testing suite is part of the Oracle Enterprise Manager product family and comprises the following tightly integrated products. They are Oracle load testing for scalability, performance and load testing, Oracle functional testing for automated functional and regression testing, and Oracle Test Manager for test process management, including test requirements management, test management, test execution, and defect tracking. OATS uses OpenScript platform. This paper discusses model-based test automation methods and tools referred to collectively as the Test Automation Framework that reduces the time and resources necessary to develop high-quality and high-assurance systems using OATS functional testing tool. Framework is named as Easy to Automate (Ez2Auto) framework. This OATS tool is newly available in market, and there is no established framework available in literature or ready to use in market.<br/> &copy; Springer India 2015.},
key = {Load testing},
keywords = {Artificial intelligence;Automation;Commerce;Evolutionary algorithms;Managers;Model checking;Software testing;Web services;},
note = {Automation tests;Ez2Auto;OATS;Open script;Test suites;},
URL = {http://dx.doi.org/10.1007/978-81-322-2126-5_59},
} 


@inproceedings{20115114614209,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Evaluating load generation in virtualized environments for software performance testing},
journal = {IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum},
author = {Netto, Marco A.S. and Menon, Suzane and Vieira, Hugo V. and Costa, Leandro T. and De Oliveira, Flavio M. and Saad, Rodrigo and Zorzo, Avelino},
year = {2011},
pages = {993 - 1000},
address = {Anchorage, AK, United states},
abstract = {Before placing a software system into production, it is necessary to guarantee it provides users with a certain level of Quality-of-Service. Intensive performance testing is then necessary to achieve such a level and the tests require an isolated computing environment. Virtualization can therefore play an important role for saving energy costs by reducing the number of servers required to run performance tests and for allowing performance isolation when executing multiple tests in the same computing infrastructure. Load generation is an important component in performance testing as it simulates users interacting with the target application. This paper presents our experience in using a virtualized environment for load generation aimed at performance testing. We measured several performance metrics and varied system load, number of virtual machines per physical resource, and the CPU pinning schema for comparison of virtual and physical machines. The two main findings from our experiments are that physical machines produced steadier and faster response times under heavy load and that the pinning schema is an important aspect when setting up a virtualized environment for load generation. &copy; 2011 IEEE.<br/>},
key = {Software testing},
keywords = {Computer architecture;Load testing;Quality of service;Virtual reality;Virtualization;},
note = {Computing environments;Computing infrastructures;Loadrunner;Multicore architectures;Performance isolations;Performance testing;Software performance testing;Virtualized environment;},
URL = {http://dx.doi.org/10.1109/IPDPS.2011.244},
} 


@article{1996463344529,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing a large finance application},
journal = {IEEE Software},
author = {Grossman, David and McCabe, M.Catherine and Staton, Christopher and Bailey, Bret and Frieder, Ophir and Roberts, David C.},
volume = {13},
number = {5},
year = {1996},
pages = {50 - 54},
issn = {07407459},
abstract = {American Management System's Federal Financial System, a financial accounting application, was applied in a Customer Information Control System DB2 environment running on a large IBM mainframe. A test tool, TPNS (Teleprocessing Network Simulator), was used to verify if the software's performance is within acceptable standards. Detailed tuning was made after the development of the initial prototype. The test produced a fair approximation of the actual performance during the first two years of operation.},
key = {Computer software selection and evaluation},
keywords = {Computer aided software engineering;Computer operating systems;Computer simulation;Database systems;Financial data processing;Response time (computer systems);},
note = {Software package Federal financial system;Software package Teleprocessing network simulator;},
URL = {http://dx.doi.org/10.1109/52.536458},
} 


@inproceedings{2005159032294,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Experiences integrating and scaling a performance test bed generator with an open source CASE tool},
journal = {Proceedings - 19th International Conference on Automated Software Engineering, ASE 2004},
author = {Cai, Yuhong and Grundy, John and Hosking, John},
year = {2004},
pages = {36 - 45},
address = {Linz, Austria},
abstract = {We report on our experiences developing a performance test-bed generator for industrial usage by extending an open-source UML CASE tool. This tool generates client and server code, database configuration and deployment scripts from a high-level software architecture description. It automates the code generation, compilation, deployment and performance metric result collection processes. We identify a range of problems that arose from our previous research on performance test-bed generation that needed to be addressed to scale this automated software engineering technique. We describe a range of approaches we used to solve these problems in our new tool. We then report on industrial deployment and evaluation of our new tool and discuss the effectiveness of these solutions. &copy; 2004 IEEE.},
key = {Computer aided software engineering},
keywords = {Codes (symbols);Computer architecture;Computer programming languages;Computer simulation;Computer software;Database systems;Industrial applications;Mathematical models;Problem solving;Program compilers;},
note = {Architectural analysis;Experience report;Software performance testing;Software tool extension;},
} 


@article{20100312640850,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Realization and application of transformer substation automation test simulation system based on PLC module},
journal = {Dianli Xitong Baohu yu Kongzhi/Power System Protection and Control},
author = {Deng, Jie-Qing and Yuan, Yu-Bo},
volume = {37},
number = {24},
year = {2009},
pages = {157 - 160},
issn = {16743415},
abstract = {The current transformer substation automation test is mainly for single measurement and control device, is not for automation system. So transformer substation automation test simulation system based on PLC module is proposed and the effective test for automation system is carried out. Firstly, this paper describes structure of automation system test and explains test simulation system's constitution. Then it carries on explanation to the simulation environment reality from two aspects of hardware and software. Secondly, it elaborates in detail how to use the test simulation system to simulate electrical network breakdown, to test performance of automation system. Lastly, this paper points out because the PLC system provides the user the development contact surface, it enables the test simulation system to have certain flexibility and the extendibility.<br/>},
key = {Electric transformer testing},
keywords = {Automation;Computer software;Electric transformers;Transformer substations;},
note = {Automation systems;Electrical networks;Hardware and software;Measurement and control;Simulation environment;Simulation systems;Substation automation;Substation Automation Systems;},
} 


@inproceedings{20130916056163,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Software performance test automation by using the virtualization},
journal = {Lecture Notes in Electrical Engineering},
author = {Kim, Gwang-Hun and Kim, Yeon-Gyun and Shin, Seok-Kyu},
volume = {215 LNEE},
year = {2013},
pages = {1191 - 1199},
issn = {18761100},
address = {Pyeong Chang, Korea, Republic of},
abstract = {In this paper, we propose a method on software performance test automation by using the virtualization. In general, most test engineers use the public performance testwares such as Load Runner and Silk Performer to validate the performance efficiency of their own systems. In case that they cannot use the performance testwares due to some technical limitations in the testwares, the testers should perform the testing in manually. As waste of computer and human resources is resulted from the situation, we need to propose the test automation scheme by using the virtualization technology to prevent the dissipation in the test environment which has limited resources. The system architecture considered efficient usage of computer resources and test automation to reduce human acts are addressed mainly in this paper. Finally, a number of experiments show that the proposed schemes allow offering the possibility for automated software performance testing by using the virtualization. &copy; 2013 Springer Science+Business Media. automation*Virtualization.},
key = {Software testing},
keywords = {Automation;Virtual reality;},
note = {Computer resources;Performance efficiency;Performance testing;Software performance;Software performance engineerings;Software performance testing;System architectures;Technical limitations;Test Automation;Test engineers;Test Environment;Virtualization technologies;Virtualizations;},
URL = {http://dx.doi.org/10.1007/978-94-007-5860-5_143},
} 


@article{20131116116954,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of LiDAR exploitation software},
journal = {Computers and Geosciences},
author = {Varela-Gonzalez, M. and Gonzalez-Jorge, H. and Riveiro, B. and Arias, P.},
volume = {54},
year = {2013},
pages = {122 - 129},
issn = {00983004},
abstract = {Mobile LiDAR systems are being used widely in recent years for many applications in the field of geoscience. One of most important limitations of this technology is the large computational requirements involved in data processing. Several software solutions for data processing are available in the market, but users are often unknown about the methodologies to verify their performance accurately. In this work a methodology for LiDAR software performance testing is presented and six different suites are studied: QT Modeler, AutoCAD Civil 3D, Mars 7, Fledermaus, Carlson and TopoDOT (all of them in x64). Results depict as QTModeler, TopoDOT and AutoCAD Civil 3D allow the loading of large datasets, while Fledermaus, Mars7 and Carlson do not achieve these powerful performance. AutoCAD Civil 3D needs large loading time in comparison with the most powerful softwares such as QTModeler and TopoDOT. Carlson suite depicts the poorest results among all the softwares under study, where point clouds larger than 5 million points cannot be loaded and loading time is very large in comparison with the other suites even for the smaller datasets. AutoCAD Civil 3D, Carlson and TopoDOT show more threads than other softwares like QTModeler, Mars7 and Fledermaus. &copy; 2012 Elsevier Ltd.},
key = {Loading},
keywords = {Computer aided design;Data processing;Optical radar;Software testing;Three dimensional computer graphics;},
note = {AutoCad;Carlson;Computational requirements;Geosciences;Large datasets;Loading time;Mobile lidar;Mobile lidar system;Performance testing;Point cloud;Software performance testing;Software solution;Stress test;},
URL = {http://dx.doi.org/10.1016/j.cageo.2012.12.001},
} 


@article{20104913468013,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A genetic algorithm-based stress test requirements generator tool and its empirical evaluation},
journal = {IEEE Transactions on Software Engineering},
author = {Garousi, Vahid},
volume = {36},
number = {6},
year = {2010},
pages = {778 - 797},
issn = {00985589},
abstract = {Genetic algorithms (GAs) have been applied previously to UML-driven stress test requirements generation with the aim of increasing chances of discovering faults relating to network traffic in distributed real-time systems. However, since evolutionary algorithms are heuristic, their performance can vary across multiple executions, which may affect robustness and scalability. To address this, we present the design and technical detail of a UML-driven, GA-based stress test requirements generation tool, together with its empirical analysis. The main goal is to analyze and improve the applicability, efficiency, and effectiveness and also to validate the design choices of the GA used in the tool. Findings of the empirical evaluation reveal that the tool is robust and reasonably scalable when it is executed on large-scale experimental design models. The study also reveals the main bottlenecks and limitations of the tools, e.g., there is a performance bottleneck when the system under test has a large number of sequence diagrams which could be triggered independently from each other. In addition, issues specific to stress testing, e.g., the impact of variations in task arrival pattern types, reveal that the tool generally generates effective test requirements, although the features of those test requirements might be different in different runs (e.g., different stress times from the test start time might be chosen). While the use of evolutionary algorithms to generate software test cases has been widely reported, the extent, depth, and detail of the empirical findings presented in this paper are novel and suggest that the proposed approach is effective and efficient in generating stress test requirements. It is hoped that the findings of this empirical study will help other SBSE researchers with the empirical evaluation of their own techniques and tools. &copy; 2010 IEEE.<br/>},
key = {Software testing},
keywords = {Genetic algorithms;Heuristic algorithms;Interactive computer systems;Real time systems;},
note = {Distributed real time system;Empirical analysis;Empirical evaluations;Genetic algorithm (GAs);Performance bottlenecks;Stress Testing;Test Automation;Test tools;},
URL = {http://dx.doi.org/10.1109/TSE.2010.5},
} 


@inproceedings{20111213849200,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design of comprehensive performance test system for residual current fire monitoring detector based on virtual instrument technology},
journal = {Proceedings - 3rd International Conference on Measuring Technology and Mechatronics Automation, ICMTMA 2011},
author = {Xie, Qi and Xu, Wei and Gu, Qimin and Xu, Huigang},
volume = {1},
year = {2011},
pages = {950 - 953},
abstract = {Aiming at the need of detecting the residual current fire monitoring detector, an intelligent test system based on virtual instrument technology was designed. This system was composed of industrial computer, data acquisition card, signal conditioning circuit, three-phase great current generator and pneumatic fixture, etc. Using LabVIEW virtual instrument technology platform, the related test and data processing program codes were developed, and its high speed data acquisition and data processing satisfied the needs of ex-factory comprehensive performance test for residual current fire monitoring detector. The hardware design was given and the working principles of this generator were introduced, the module design of system software was also introduced in detail. Practical application shows that the intelligent test system features with stable and reliable, easy to operate and maintain, high precision and can improve the design and performance of products, which can be widely used.<br/>},
key = {Software testing},
keywords = {Data acquisition;Data handling;Digital instruments;Fires;Product design;Signal conditioning circuits;Signal processing;},
note = {Comprehensive performance;Data acquisition cards;Fire Monitoring;High speed data acquisition;Intelligent test;Intelligent test system;LabVIEW virtual instrument;Virtual instrument technology;},
URL = {http://dx.doi.org/10.1109/ICMTMA.2011.238},
} 


@inproceedings{20180604700217,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Software-defined network solutions for science scenarios: Performance testing framework and measurements},
journal = {ACM International Conference Proceeding Series},
author = {Rao, Nageswara S.V. and Liu, Qiang and Sen, Satyabrata and Kettimuthu, Raj and Boley, Josh and Settlemyer, Bradley W. and Chen, Hsing B. and Katramatos, Dimitrios and Yu, Dantong},
year = {2018},
pages = {ACM Special Interest Group on Mobility of Systems, Users, Data and Computing (SIGMOBILE); ACM Special Interest Group on Operating Systems (SIGOPS) - },
address = {Varanasi, India},
abstract = {High-performance scientific workflows utilize supercomputers, scientific instruments, and large storage systems. Their executions require fast setup of a small number of dedicated network connections across the geographically distributed facility sites.We present Software-Defined Network (SDN) solutions consisting of site daemons that use dpctl, Floodlight, ONOS, or OpenDaylight controllers to set up these connections. The development of these SDN solutions could be quite disruptive to the infrastructure, while requiring a close coordination among multiple sites; in addition, the large number of possible controller and device combinations to investigate could make the infrastructure unavailable to regular users for extended periods of time. In response, we develop a Virtual Science Network Environment (VSNE) using virtual machines, Mininet, and custom scripts that support the development, testing, and evaluation of SDN solutions, without the constraints and expenses of multi-site physical infrastructures; furthermore, the chosen solutions can be directly transferred to production deployments. By complementing VSNE with a physical testbed, we conduct targeted performance tests of various SDN solutions to help choose the best candidates. In addition, we propose a switching response method to assess the setup times and throughput performances of different SDN solutions, and present experimental results that show their advantages and limitations.<br/> &copy; 2018 ACM. 978-1-4503-6372-3/18/01. . . $15.00.},
key = {Distributed computer systems},
keywords = {Controllers;Data storage equipment;Electric lighting;Software defined networking;Software testing;Solution mining;Supercomputers;},
note = {Dedicated networks;Performance testing framework;Physical testbeds;Science scenarios;Scientific instrument;Scientific workflows;Switching response;Throughput performance;},
URL = {http://dx.doi.org/10.1145/3154273.3154336},
} 


@inproceedings{20163502742304,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A Framework to Evaluate the Effectiveness of Different Load Testing Analysis Techniques},
journal = {Proceedings - 2016 IEEE International Conference on Software Testing, Verification and Validation, ICST 2016},
author = {Gao, Ruoyu and Jiang, Zhen Ming and Barna, Cornel and Litoiu, Marin},
year = {2016},
pages = {22 - 32},
address = {Chicago, IL, United states},
abstract = {Large-scale software systems like Amazon and eBay must be load tested to ensure they can handle hundreds and millions of current requests in the field. Load testing usually lasts for a few hours or even days and generates large volumes of system behavior data (execution logs and counters). This data must be properly analyzed to check whether there are any performance problems in a load test. However, the sheer size of the data prevents effective manual analysis. In addition, unlike functional tests, there is usually no test oracle associated with a load test. To cope with these challenges, there have been many analysis techniques proposed to automatically detect problems in a load test by comparing the behavior of the current test against previous test(s). Unfortunately, none of these techniques compare their performance against each other. In this paper, we have proposed a framework, which evaluates and compares the effectiveness of different test analysis techniques. We have evaluated a total of 23 test analysis techniques using load testing data from three open source systems. Based on our experiments, we have found that all the test analysis techniques can effectively build performance models using data from both buggy or non-buggy tests and flag the performance deviations between them. It is more cost-effective to compare the current test against two recent previous test(s), while using testing data collected under longer sampling intervals (&le; 180 seconds). Among all the test analysis techniques, Control Chart, Descriptive Statistics and Regression Tree yield the best performance. Our evaluation framework and findings can be very useful for load testing practitioners and researchers. To encourage further research on this topic, we have made our testing data publicity available to download. &copy; 2016 IEEE.},
key = {Software testing},
keywords = {Cost effectiveness;Internet;Load testing;Open source software;Open systems;Testing;Verification;},
note = {Analysis techniques;Descriptive statistics;Evaluation framework;Large-scale software systems;Open source system;Performance Model;Performance problems;Sampling interval;},
URL = {http://dx.doi.org/10.1109/ICST.2016.9},
} 


@inproceedings{20133016524771,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A distributed, cross-platform automation testing framework for GUI-driven applications},
journal = {Proceedings of 2nd International Conference on Computer Science and Network Technology, ICCSNT 2012},
author = {Yao, Yepeng and Wang, Xuren},
year = {2012},
pages = {723 - 726},
address = {Changchun, China},
abstract = {With the rapid development of computer technology, nowadays GUIs have been widely used in desktop applications and web applications. GUI-driven application testing is an emergent approach to software testing and plays a key role to assure software quality. This paper first discusses the various methods for testing GUI-driven applications, and then defines a GUI model and formally defines the test case and the test suite. Finally, it proposes a novel automated, distributed and cross-platform testing framework for GUI. Experiments conducted showed that the proposed testing architecture managed to use parallel cross-platform clusters to test heterogeneous applications whose technologies were incompatible with the testing framework. &copy; 2012 IEEE.},
key = {Graphical user interfaces},
keywords = {Automation;Computer science;Computer software selection and evaluation;Software testing;},
note = {Application testing;Automation testing;Computer technology;Cross-platform;Desktop applications;Distributed testing;Software Quality;Testing framework;},
URL = {http://dx.doi.org/10.1109/ICCSNT.2012.6526035},
} 


@inproceedings{20105013486840,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design of automatic performance test system for CPS},
journal = {2010 International Conference on Computer, Mechatronics, Control and Electronic Engineering, CMCE 2010},
author = {Xu, Wei and Xu, Huigang and Xie, Qi and Yang, Yunfei and Dai, Mei},
volume = {4},
year = {2010},
pages = {206 - 209},
abstract = {In order to satisfy the needs of comprehensive and accurate performance test for CPS (Control and Protective Switching), an automatic performance test system was studied in this paper. The hardware structure and software was introduced in detail; the hardware system was made up of the industrial control computer, the three-phase current generator, adjustable single-phase power, pneumatic fixture, and so on. The test system software developed by LabVIEW was mainly used to achieve the functions of data acquisition, data processing and data display. The designed system is able to automatically test all functions of different types of CPS, including measurement function, communication function, multiple protection function, and so on. Practical application shows that the test system has following properties: high precision, low cost, strong anti-interference and convenient maintenance. &copy; 2010 IEEE.<br/>},
key = {Computer control systems},
keywords = {Automatic testing;Computer hardware;Computer programming languages;Data acquisition;Data handling;Electric equipment protection;Hardware;Software testing;},
note = {Accurate performance;Automatic test system;Communication functions;Industrial control computer;LabViEW;Measurement function;Performance tests;Three-phase currents;},
URL = {http://dx.doi.org/10.1109/CMCE.2010.5610188},
} 


@article{20093812327320,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Measurement and control system for car clutch cover assembly comprehensive performance test rig},
journal = {Yi Qi Yi Biao Xue Bao/Chinese Journal of Scientific Instrument},
author = {Liu, Zhenzhong and Zhao, Lianyu and Liu, Qingjian and Wang, Taiyong},
volume = {30},
number = {SUPPL.},
year = {2009},
pages = {226 - 229},
issn = {02543087},
abstract = {The measurement and control system for car clutch cover assembly comprehensive performance test rig is designed and developed. In the system, the motion controller, acting as a client computer, controls the servo motors, and the industrial computer, acting as a host computer, acquires and processes signal, commands the client computer, and achieves the function of human-computer interaction. Procedure of the measurement and control system was designed with application of VC++6.0 software based on the object oriented method in the environment of Windows XP Embedded. The result shows that the system can test multi-specifications (&Phi;275-&Phi;430) clutch cover assembly and function well.<br/>},
key = {Computer control},
keywords = {Application programs;Clutches;Control systems;Human computer interaction;Object oriented programming;Servomotors;Vehicle performance;},
note = {Comprehensive performance;Host computers;Industrial computers;Measurement and control systems;Motion controller;Object oriented method;Test rigs;Windows XP;},
} 


@article{20111913969112,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Test component assignment and scheduling in a load testing environment},
journal = {Periodica Polytechnica Electrical Engineering},
author = {Eros, Levente and Bozoki, Ferenc},
volume = {52},
number = {3-4},
year = {2008},
pages = {145 - 152},
issn = {03246000},
abstract = {In this paper we introduce two major problems from the field of load (or performance) testing and our solutions for them. When testing the performance of a device (System Under Test - SUT), the test environment executes many software entities (the so-called test components) on the hosts of the test environment (testing hosts). Our goal is to maximize the load on the testing hosts by assigning the test components to them closely to optimal. The first problem to be solved is, thus, a special case of the task assignment problem for which many algorithms have been developed. Our solutions presented in this paper are, however, optimized for distributing load testing traffic in the case of which the possibilities and restrictions to be taken into account are very different from those of the classical task assignment case. The other problem we deal with is how to schedule test components running on the same testing host. Most of the papers written on scheduling focus on the characteristics of the generated load, but not on the way of generating it. These papers usually assume that the load can be generated by improving hardware resources. In this paper, however, we introduce a model and an algorithm which improves the efficiency of scheduling in a load testing environment with way less hardware resources. The algorithm is based on our novel concept of virtual threads. Our simulations have shown that by applying our solutions, the efficiency of load testing can be significantly increased. &copy; Periodica Polytechnica 2008.<br/>},
key = {Load testing},
keywords = {Combinatorial optimization;Computational complexity;Efficiency;Hardware;Scheduling;Software testing;Testing;},
note = {Distributing-load;Hardware resources;Software entities;System under test;Task assignment;Test components;Test Environment;Testing environment;},
URL = {http://dx.doi.org/10.3311/pp.ee.2008-3-4.03},
} 


@inproceedings{2004488472493,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Architecture and performance testing of a software GPS receiver for space-based applications},
journal = {Proceedings of the National Technical Meeting, Institute of Navigation},
author = {Gold, Kenn and Brown, Alison},
volume = {2004},
year = {2004},
pages = {624 - 635},
address = {San Diego, CA, United states},
abstract = {NAVSYS has modified the design of its Software GPS Receiver to optimize performance for various space-based scenarios. These include capabilities to track GPS satellites from missions that are at altitudes higher than the GPS constellation. The approach is based on Digital Beam Steering, which also presents significant advantages for multipath mitigation, which will improve kinematic carrier phase tracking and GPS interferometric attitude determination for orbital applications. In addition, the composite signal formed from the beam steering algorithms lends itself to antenna placement around the spacecraft body, which will result in continuous visibility, even for spinning satellites. Inertial aiding with the SGR has also been adapted for space applications including high dynamic scenarios in which it is difficult to track GPS. In order to test the modifications required for the Space-Software GPS Receiver (SSGR), the NAVSYS simulation tools suite has been augmented to account for orbital scenarios. This involved adding an interface to the GPS Toolbox product to accept orbital trajectories generated with Satellite Tool Kit. The Toolbox in turn drives the hardware simulations with the Advanced GPS Hybrid Simulator.},
key = {Global positioning system},
keywords = {Acoustic receivers;Algorithms;Computer simulation;Computer software;Geostationary satellites;Kinematics;Orbits;Space applications;Testing;Tracking (position);},
note = {Constellations;GPS signals;Hybrid simulators;Space-software GPS receiver (SSGR);},
} 


@inproceedings{20145000302487,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance evaluation of web based automation testing tools},
journal = {Proceedings of the 5th International Conference on Confluence 2014: The Next Generation Information Technology Summit},
author = {Angmo, Rigzin and Sharma, Monika},
year = {2014},
pages = {731 - 735},
address = {Noida, India},
abstract = {In today's 21<sup>st</sup> century era countless software applications are written as a web based application which runs in a web browsers. With new technologies and commercialization of I.T. sector, the web based system has undergoes frequent and rapid changes. Today Softwares are coded as a web based application, which help to access data from any part of the globe. Even the economic relevance of web based enhances the control and quality of software. The quality assurance of any system depends on its test. But to do manually testing in most of the cases is time consuming, expensive and hectic. For the better business purpose and to save time and money automation testing is required. There are variety of tools are available in the market for this. One of the best known tool is selenium suite which is a combination of different automation testing tool. In this paper we will discuss about the selenium suite. It provides testers with different framework for different test cases. The main objective of this paper is to find the best tool in selenium suite and then compare it with some other tool for same task. For this purpose, performance evaluation is done on the basis of some criteria.},
URL = {http://dx.doi.org/10.1109/CONFLUENCE.2014.6949287},
} 


@article{20154201402194,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {To What Extent is Stress Testing of Android TV Applications Automated in Industrial Environments?},
journal = {IEEE Transactions on Reliability},
author = {Jiang, Bo and Chen, Peng and Chan, Wing Kwong and Zhang, Xinchao},
volume = {65},
number = {3},
year = {2016},
pages = {1223 - 1239},
issn = {00189529},
abstract = {An Android-based smart television (TV) must reliably run its applications in an embedded program environment under diverse hardware resource conditions. Owing to the diverse hardware components used to build numerous TV models, TV simulators are usually not sufficiently high in fidelity to simulate various TV models and thus are only regarded as unreliable alternatives when stress testing such applications. Therefore, even though stress testing on real TV sets is tedious, it is the de facto approach to ensure the reliability of these applications in the industry. In this paper, we study to what extent stress testing of smart TV applications can be fully automated in the industrial environments. To the best of our knowledge, no previous work has addressed this important question. We summarize the findings collected from ten industrial test engineers who have tested 20 such TV applications in a real production environment. Our study shows that the industry required test automation supports on high-level GUI object controls and status checking, setup of resource conditions, and the interplay between the two. With such supports, 87% of the industrial test specifications of one TV model can be fully automated, and 71.4% of them were found to be fully reusable to test a subsequent TV model with major upgrades of hardware, operating system, and application. It represents a significant improvement with margins of 28% and 38%, respectively, compared with stress testing without such supports.<br/> &copy; 2015 IEEE.},
key = {Software testing},
keywords = {Android (operating system);Application programs;Automation;Computer software reusability;Drag reduction;Hardware;Reliability;Software reliability;Television;Television applications;Testing;},
note = {Android;Automated testing;Hardware components;Industrial environments;Production environments;Resource conditions;Stress Testing;Test case;},
URL = {http://dx.doi.org/10.1109/TR.2015.2481601},
} 


@inproceedings{20132216381521,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Model-based performance testing in the cloud using the MBPeT tool},
journal = {ICPE 2013 - Proceedings of the 2013 ACM/SPEC International Conference on Performance Engineering},
author = {Abbors, Fredrik and Ahmad, Tanwir and Truscan, Dragos and Porres, Ivan},
year = {2013},
pages = {423 - 424},
address = {Prague, Czech republic},
abstract = {We present an approach for performance testing of software services. We use Probabilistic Timed Automata to model the workload of the system, by describing how different user types interact with the system. We use these models to generate load in real-time and we measure different performance indicators. An in-house developed tool, MBPeT, is used to support our approach. We exemplify with an auction web service case study and show how performance information about the system under test can be collected. &copy; 2013 Authors.},
key = {Load testing},
keywords = {Automata theory;Benchmarking;Software testing;Web services;},
note = {load generation;Model based testing;Performance indicators;Performance testing;Probabilistic timed automata;Software services;System under test;User type;},
URL = {http://dx.doi.org/10.1145/2479871.2479937},
} 


@inproceedings{20083111421965,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Action-driven automation test framework for Graphical User Interface (GUI) software testing},
journal = {AUTOTESTCON (Proceedings)},
author = {Feng, Li and Zhuang, Sheng},
year = {2007},
pages = {22 - 27},
address = {Baltimore, MD, United states},
abstract = {In this paper we describe the design and implementation of an action-driven automation test framework especially for GUI software testing. The idea of action-driven automation test framework comes from the core concept of "Quality Assurance (QA)". Better quality can be ensured by increasing the coverage of test cases on the software but the process of creating large number of test cases has to be optimized. With this goal the framework was designed to primarily increase the efficiency and flexibility in composing test cases and simplify the process of learning the test cases. This paper describes the background, features, and implementation details of the framework.<br/>},
key = {Software testing},
keywords = {Automation;Graphical user interfaces;Quality assurance;Testing;},
note = {Automation tests;Design and implementations;Graphical user interfaces (GUI);GUI software;Process of learning;Test case;},
URL = {http://dx.doi.org/10.1109/AUTEST.2007.4374197},
} 


@article{20103513195106,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A Web performance testing framework and its mixed performance modeling process},
journal = {Jisuanji Yanjiu yu Fazhan/Computer Research and Development},
author = {Ming, Zhong and Yin, Jianfei and Yang, Wei and Wang, Hui and Xiao, Zhijiao},
volume = {47},
number = {7},
year = {2010},
pages = {1192 - 1200},
issn = {10001239},
abstract = {Methods of pure performance testing or single analytical modeling, such as queueing network model, etc, have their limitation on the accuracy of performance indexes measurement, the validity of performance forecasting, and the controlling of testing iteration due to the complexity of Web systems. A Web performance modeling framework supporting mixed performance modeling is proposed. It uses different performance modeling methods for different kinds of performance indexes to derive closed form functions and their hypothesis of measurement. The regression analysis and testing are used on the training data to estimate the parameters of the closed form functions. To demonstrate the feasibility and validity of this framework, a real-world Web community system (igroot.com) is studied under the framework. For the indexes of system response time and scalability, a mixed modeling method is proposed by combining queueing network reduction and extended universal scalability model US-&gamma;. Compared with other practical system performance testing methods, such as universal scalability model US, the model accuracy of performance forecasting is greatly improved and the cost of software and hardware used in the process is greatly reduced. The error rate of estimated response time is within 4 percent, the error rate of estimated throughout saturation point is within 1 percent, and the error rate of estimated infimum of buckle point is within 5 percent. Correlating the scalability model and threads data of the Web server, an HTTP processing bottleneck at the architecture level is identified.<br/>},
key = {Queueing networks},
keywords = {Distributed computer systems;Errors;HTTP;Iterative methods;Queueing theory;Regression analysis;Response time (computer systems);Scalability;Software testing;Testing;},
note = {Analysis and testing;Performance forecasting;Performance Model;Performance testing;Queueing network model;Scalability modeling;Software and hardwares;System response time;},
} 


@inproceedings{20112814145531,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Autonomic load-testing framework},
journal = {Proceedings of the 8th ACM International Conference on Autonomic Computing, ICAC 2011 and Co-located Workshops},
author = {Barna, Cornel and Litoiu, Marin and Ghanbari, Hamoun},
year = {2011},
pages = {91 - 100},
abstract = {In this paper, we present a method for performance testing of transactional systems. The methods models the system under test, finds the software and hardware bottlenecks and generate the workloads that saturate them. The framework is autonomic, the model and workloads are determined during the performance test execution by measuring the system performance, fitting a performance model and by analytically computing the number and mix of users that will saturate the bottlenecks. We model the software system using a two-layer queuing model and use analytical techniques to find the workload mixes that change the bottlenecks in the system. Those workload mixes become stress vectors and initial starting points for the stress test cases. The rest of test cases are generated based on a feedback loop that drives the software system towards the worst case behaviour. &copy; 2011 ACM.<br/>},
key = {Software testing},
keywords = {Load testing;Queueing theory;},
note = {Autonomic Systems;Performance Model;Performance testing;Software and hardwares;Stress Testing;System under test;Testing framework;Transactional systems;},
URL = {http://dx.doi.org/10.1145/1998582.1998598},
} 


@inproceedings{20134316874468,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing framework for rest-based web applications},
journal = {Proceedings of the International Symposium on the Physical and Failure Analysis of Integrated Circuits, IPFA},
author = {Kao, Chia Hung and Lin, Chun Cheng and Chen, Juei-Nan},
year = {2013},
pages = {349 - 354},
address = {Nanjing, Jiangsu, China},
abstract = {Recently, enterprises, organizations, and software companies are building more and more web applications to provide their services over the Internet. In order to fulfill various requirements, the complexity of web applications nowadays is increasing dramatically. As a result, the performance characteristics of web applications, including response time, throughput, etc, become more critical than before and should be taken into careful consideration. If the response time of a web application is poor, users may lose their interests even the function of the web application is correct. Therefore, how to execute performance testing on a complex web application systematically and efficiently will be an important issue. In this paper, a performance testing framework for REST-based web applications is introduced. The performance testing framework aims to provide software testers with an integrated process from test cases design, test scripts generation, to test execution. Based on the test cases designed by software testers and the appropriate software artifacts preserved by the framework (e.g., API document), the framework generates the corresponding performance test scripts, which can be executed by specific performance test tools. This helps software testers to focus more in the design of performance test cases. In addition, effort needed to understand the design and implementation of the application and to learn the operation of testing tools decrease. Thus, the efficiency of performance testing can be highly facilitated. &copy; 2013 IEEE.},
key = {Software testing},
keywords = {Applications;Design;Industry;World Wide Web;},
note = {Design and implementations;Performance characteristics;Performance testing;Performance testing framework;Performance tests;Software artifacts;Software company;WEB application;},
URL = {http://dx.doi.org/10.1109/QSIC.2013.32},
} 


@inproceedings{20083211434602,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Software realization and performance testing of des cryptographic algorithm on the .NET platform},
journal = {The Experience of Designing and Application of CAD Systems in Microelectronics - Proceedings of the 9th International Conference, CADSM 2007},
author = {Yakovyna, Vitaly and Fedasyuk, Dmytro and Seniv, Maxym},
year = {2007},
pages = {386 - 388},
address = {Lviv-Polyana, Ukraine},
abstract = {The software realization of DES symmetric encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested and it was shown, that the encryption rate is 11.1 Mb/sec on the Intel Celeron D 351 3.2GHz processor, while the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.<br/>},
key = {Cryptography},
keywords = {Computer aided design;Microelectronics;Software testing;},
note = {.NET;CryptoAPI;Cryptographic algorithms;Cryptographic software;DES algorithms;Development environment;Software implementation;Symmetric cryptography;},
URL = {http://dx.doi.org/10.1109/CADSM.2007.4297591},
} 


@inproceedings{20083211434604,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The Performance testing of RSA algorithm software realization},
journal = {The Experience of Designing and Application of CAD Systems in Microelectronics - Proceedings of the 9th International Conference, CADSM 2007},
author = {Yakovyna, Vitaly and Fedasyuk, Dmytro and Seniv, Maxym and Bilas, Orest},
year = {2007},
pages = {390 - 392},
address = {Lviv-Polyana, Ukraine},
abstract = {The software realization of RSA public key encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested. The present paper shows, that the encryption rate is 306.4&plusmn;0.6 kbytes/sec, while the coefficient of encryption time increasing with file size increasing is 3.299. It is concluded that the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.<br/>},
key = {Computer aided design},
keywords = {Microelectronics;Public key cryptography;Software testing;},
note = {.NET;Cryptographic software;Development environment;Flexible architectures;Operation performance;Public key encryption algorithms;RSA algorithms;Software implementation;},
URL = {http://dx.doi.org/10.1109/CADSM.2007.4297593},
} 


@inproceedings{20132416416305,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Radiation Belt Storm Probes (RBSP) Flight Software stress testing: Case study and lessons learned},
journal = {IEEE Aerospace Conference Proceedings},
author = {Finnigan, Jeremiah},
year = {2013},
issn = {1095323X},
address = {Big Sky, MT, United states},
abstract = {This paper presents a case study of the Radiation Belt Storm Probes (RBSP) mission Command and Data Handling (C&amp;DH) Flight Software stress testing program. Background information on the motivation for stress testing embedded software, and the general principles and goals of a stress test are provided as an introduction. Details of the stress test program that was implemented for the RBSP C&amp;DH Flight Software are presented and discussed. This discussion includes the design and development of a test framework that was implemented to incrementally build the test scenarios, increase the productivity of the RBSP stress test team, and facilitate reuse for regression testing. Results of the RBSP stress test program are summarized, and lessons learned that may be useful for future embedded software test programs are documented. &copy; 2013 IEEE.},
key = {Software testing},
keywords = {C (programming language);Data handling;Embedded software;Probes;Radiation belts;Storms;Test facilities;Testing;},
note = {Background information;Design and Development;Flight Software;Lessons learned;Mission command;Regression testing;Stress Testing;Test framework;},
URL = {http://dx.doi.org/10.1109/AERO.2013.6496814},
} 


@inproceedings{20094712476045,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Mine pump comprehensive performance testing system based on labview},
journal = {2009 International Conference on Measuring Technology and Mechatronics Automation, ICMTMA 2009},
author = {Wang, Guimei and Jiao, Shanlin and Song, Hui},
volume = {1},
year = {2009},
pages = {300 - 303},
address = {Zhangjiajie, Hunan, China},
abstract = {The pump is one of the key equipments for the safety production of coal mine. It bears the important task to discharge all the underground water. However, the performance efficiency of the water pump will be declined, in the long run. Therefore, in order to ensure the safety production, users should check and test the pump performance regularly, to test if every target pump has live up to the "Coal Mine Safety Regulations". The ultimate goal in finding the fault in time, eliminating hidden dangers, reducing accidents, and saving maintenance costs can be attained. Virtual instrument is the production of modern computer and instrument technology combined in-depth, and is an important technology of computer-assisted testing area. The core idea is "software replacing hardware". The paper introduces the virtual instrument technology into the field of pump performance testing, and designs the mine pump comprehensive performance testing system based on Labview. The system takes software development environment-LabVIEW as platform and based on personal computer, and realizes the function that pump's import and export of water pressure, flow, speed, power, and other signals measured in real-time and dynamic displayed. It uses the polynomial fitting module of LabVIEW to fit the performance curve, and shows the performance curve by the waveform display. At the same time, it uses the Web Publishing Tool of LabVIEW to release the testing interface to the internet, and realizes its network communication function. Compared with traditional instruments, the pump performance testing system which based on Virtual instrument run stably, have strongly data analytical and processing functions, beautiful interface, easy operation, strongly visual function, highly testing precision. &copy; 2009 IEEE.<br/>},
key = {Instrument testing},
keywords = {Coal mines;Computer programming languages;Computer testing;Curve fitting;Data handling;Digital instruments;Groundwater;Mining machinery;Personal computers;Pumps;Software design;},
note = {Comprehensive performance;Computer assisted testing;LabViEW;Network communications;Performance efficiency;Software development environment;Testing systems;Virtual instrument technology;},
URL = {http://dx.doi.org/10.1109/ICMTMA.2009.179},
} 


@inproceedings{20171403536765,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A framework for composing heterogeneous service tools involved in load testing lifecycle},
journal = {Applied System Innovation - Proceedings of the International Conference on Applied System Innovation, ICASI 2015},
author = {Lee, Shin-Jie and Lin, You-Chen and Lin, Kun-Hui and You, Jie-Lin},
year = {2016},
pages = {1075 - 1080},
address = {Osaka, Japan},
abstract = {Load testing is the process of applying ordinary stress to a software system to determine the system performance under normal conditions. In a typical load testing lifecycle, three kinds of service tools are involved: test case recording service tools that make testers easier to generate test cases through a web browsing-like behavior; test case execution service tools that exercise test cases with simulations of a large number of concurrent users; system resource monitoring service tools that provide information of system footprints during the test case executions. However, using these three kinds of service tools one by one to complete a load testing may require extra effort on operating and configuring each service. In this paper, we proposed a framework for composing the three types of service tools as an integrated service for load testing. A raw test case recorded by Badboy tool is automatically converted into an expanded test case that can be executed by JMeter. JMeter and Cacti are then automatically invoked by the framework. The execution time period of JMeter is automatically identified as the input to Cacti for resource monitoring of the system under test. The test report together with system footprints is also automatically generated. In the experimental evaluation, the result shows that the framework significantly save time on operating and configuring the load testing service tools than the traditional approach under a t-test. &copy; 2016 Taylor & Francis Group.},
key = {Software testing},
keywords = {Automatic test pattern generation;Life cycle;Load testing;Monitoring;Network function virtualization;},
note = {Automatically generated;Experimental evaluation;Heterogeneous services;Integrated service;Resource monitoring;System footprints;System under test;Traditional approaches;},
} 


@article{20172903952609,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {OFBench: Performance Test Suite on OpenFlow Switches},
journal = {IEEE Systems Journal},
author = {Lin, Ying-Dar and Lai, Yu-Kuen and Wang, Chen-You and Lai, Yuan-Cheng},
year = {2017},
issn = {19328184},
abstract = {Performance issues of OpenFlow switches are attracting a lot of attention owing to the potential large-scale deployment of software-defined devices. This paper presents the OFBench which is an automatic test suite for evaluating the performance of OpenFlow switches. The design, as part of the Automation Control Test System (ACTS) development, is based on a controller-agent architecture which allows the development of test cases that are written in a high-level script language. In addition to the end-to-end measurement methodology, novel methods are proposed to further profile the internal performance metrics, which are difficult to get due to the black-box nature of the device under test. The prototype of this suite currently comprises five test cases to evaluate five performance metrics, which are action time, pipeline time, buffer size, pipeline efficiency, and timeout accuracy. OpenFlow switches are evaluated and three issues are observed associated with switches during the testing. First, some switches may not be well implemented in the design of apply-action instructions. Second, some switches suffer from random crashes with a high volume of bursty packet-in traffic. Finally, the timer of idle-timeout is often not reset properly with matching flow entry. IEEE},
key = {Computer network performance evaluation},
keywords = {Computer networks;High level languages;Pipelines;Software defined networking;Software testing;Testing;},
note = {Automation controls;End-to-end measurement;Internal performance;Large-scale deployment;Openflow;performance evaluation;Performance metrics;system performance;},
URL = {http://dx.doi.org/10.1109/JSYST.2017.2720758},
} 


@inproceedings{20085211804749,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Test component assignment in a performance testing environment},
journal = {SoftCom 2008: 16th International Conference on Software, Telecommuncations and Computer Networks},
author = {Eros, Levente and Csondes, Tibor},
year = {2008},
pages = {399 - 403},
address = {Split-Dubrovnik, Croatia},
abstract = {In this paper we are going to introduce the problem of assigning test components to hosts of a performance (or load) testing environment, and its two novel solutions. When testing the performance of a device (System Under Test - SUT), the test environment simulates the latter real-life environment of the SUT. The number of hosts in the test environment is however way less than the number of hosts the SUT will have to serve in its real-life environment. Thus, real-life hosts are simulated by software entities, the so-called test components that have to be optimally assigned and then executed on the hosts of the test environment (testing hosts). Our goal is to emulate all the test components by as few testing hosts as possible, that is, to maximize the load on the testing hosts. The problem to be solved is a special case of the task assignment problem for which many solutions have been developed. Our solutions presented in this paper are, however, optimized for distributing load testing traffic. Thus the possibilities and restrictions we had to take into account are very different from those of the classical task assignment case. One of the solutions we present extends existing bin packing heuristics, while the other one solves a series of integer linear programs to make the assignments. Our simulations have shown that by applying our solutions, the average load level on testing hosts can be significantly increased.<br/>},
key = {Software testing},
keywords = {Combinatorial optimization;Computer networks;Integer programming;Load testing;Testing;},
note = {Distributing-load;Integer linear programs;Performance testing;Software entities;System under test;Task assignment;Test Environment;Testing environment;},
URL = {http://dx.doi.org/10.1109/SOFTCOM.2008.4669518},
} 


@inproceedings{20133516679859,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic load testing of web application in SaaS model},
journal = {Advances in Intelligent Systems and Computing},
author = {Stupiec, Emil and Walkowiak, Tomasz},
volume = {224},
year = {2013},
pages = {421 - 430},
issn = {21945357},
address = {Brunow, Poland},
abstract = {Necessity of monitoring in combination with the actual complexity of the e-services creates a need for constructing systems for active monitoring of various types of web services. Usually those systems are high-availability services, that require on one hand ingenious software solutions and on the other hand reliable hardware architecture. The created systems need to be flexible enough to satisfy customers requirements. This paper introduces an example solution of a system, that implement functional monitor of services provided in SaaS model. The provided system allows to check certain functionalities or whole service by running functional/load tests scenarios that are automatically generated, based on specially prepared user model. &copy; Springer International Publishing Switzerland 2013.},
key = {Software as a service (SaaS)},
keywords = {Automatic test pattern generation;Customer satisfaction;Web services;},
note = {Active monitoring;Automatically generated;E-services;Hardware architecture;High availability;Software solution;User Modeling;WEB application;},
URL = {http://dx.doi.org/10.1007/978-3-319-00945-2_38},
} 


@inproceedings{20162202446849,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing as a service for web applications},
journal = {2015 IEEE 7th International Conference on Intelligent Computing and Information Systems, ICICIS 2015},
author = {Ali, Amira and Badr, Nagwa},
year = {2015},
pages = {356 - 361},
address = {Cairo, Egypt},
abstract = {Software testing is a vital activity that is undertaken during software engineering life cycle to ensure software quality and reliability. Performance testing is a type of software testing that is done to shows how web application behaves under a certain workload. Cloud computing as an emerging technology can be used in the field of software engineering to provide cloud testing in order to overcome all deficiencies of conventional testing by leveraging cloud computing resources. As a result, testing-as-a-service (TaaS) is introduced as a service model that performs all testing activities in fully automated manner, on demand with a pay-for use basis. Moreover, TaaS increases testing efficiency and reduces time and cost required for testing. In this paper, performance TaaS framework for web applications is introduced which provides all performance testing activities including automatic test case generation and test execution. In addition, the proposed framework addresses many issues as: maximize resource utilization and continuous monitoring to ensure system reliability. &copy; 2015 IEEE.},
key = {Software testing},
keywords = {Application programs;Cloud computing;Computer software selection and evaluation;Information systems;Intelligent computing;Life cycle;Software engineering;Software reliability;World Wide Web;},
note = {Automatic test-case generations;Continuous monitoring;Emerging technologies;JMeter;Performance testing;Software engineering life-cycle;TaaS;Web application testing;},
URL = {http://dx.doi.org/10.1109/IntelCIS.2015.7397245},
} 


@article{20143017976582,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Development of an integrated web-based system with a pile load test database and pre-analyzed data},
journal = {Geomechanics and Engineering},
author = {Chen, Yit-Jin and Liao, Ming-Ru and Lin, Shiu-Shin and Huang, Jen-Kai and Marcos, Maria Cecilia M.},
volume = {7},
number = {1},
year = {2014},
pages = {37 - 53},
issn = {2005307X},
abstract = {A Web-based pile load test (WBPLT) system was developed and implemented in this study. Object-oriented and concept-based software design techniques were adopted to integrate the pile load test database into the system. A total of 673 case histories of pile load test were included in the database. The data consisted of drilled shaft and driven precast concrete pile axial load tests in drained, undrained, and gravel loading conditions as well as pre-analyzed data and back-calculated design parameters. Unified modeling language, a standard software design tool, was utilized to design the WBPLT system architecture with five major concept-based components. These components provide the static structure and dynamic behavior of system message flows in a visualized manner. The open-source Apache Web server is the building block of the WBPLT system, and PHP Web programming language implements the operation of the WBPLT components, particularly the automatic translation of user query into structured query language. A simple search and inexpensive query can be implemented through the Internet browser. The pile load test database is helpful, and data can be easily retrieved and utilized worldwide for research and advanced applications. &copy; 2014 Techno-Press, Ltd.<br/>},
key = {Piles},
keywords = {Database systems;Internet;Load testing;Object oriented programming;Object-oriented databases;Open source software;Open systems;Precast concrete;Program translators;Query languages;Query processing;Software design;Software testing;Unified Modeling Language;Websites;},
note = {Advanced applications;Apache web server;Automatic translation;Design parameters;Software design techniques;Structured Query Language;System architectures;Web based;},
URL = {http://dx.doi.org/10.12989/gae.2014.7.1.037},
} 


@article{20114614512790,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Investigation on performance testing and evaluation of PReWebD: A.NET technique for implementing web application},
journal = {IET Software},
author = {Kalita, M. and Bezboruah, T.},
volume = {5},
number = {4},
year = {2011},
pages = {357 - 365},
issn = {17518806},
abstract = {A prototype research web application based on Visual Studio platform is developed with.NET as framework, Internet Information Server (IIS) (Version: 5.1) as web server and Microsoft Standard Query Language (SQL) Server (Version: 2005) as database server to study the performance and evaluation of the.NET technique used for developing the web application. The authors call it the PReWebD. As the performance is one of the most important features of a web application, to evaluate the performance, testing of PReWebD has been carried out using Mercury LoadRunner (Version 8.0) for validation and to study some other attributes like scalability, reliability etc. The performance depends on parameters such as hits/s, response time, throughput, errors/s etc. These parameters for PReWebD are tested with different stress levels. The statistical testing and analysis is done to assure the stability, reliability and quality of the application. Here the authors report in details the architecture, testing procedure, result of performance testing as well as the results of statistical analysis on recorded data of PReWebD. &copy; 2011 The Institution of Engineering and Technology.<br/>},
key = {Quality control},
keywords = {Query languages;Query processing;Reliability analysis;Software prototyping;Visual languages;Windows operating system;},
note = {Data-base servers;Important features;Internet information servers;Performance testing;Standard query languages;Statistical testing;Testing procedure;WEB application;},
URL = {http://dx.doi.org/10.1049/iet-sen.2010.0139},
} 


@inproceedings{20114014404035,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Designing approach analysis on small-scale software performance testing tools},
journal = {Proceedings of 2011 International Conference on Electronic and Mechanical Engineering and Information Technology, EMEIT 2011},
author = {Meng, Xiangfeng},
volume = {8},
year = {2011},
pages = {4254 - 4257},
address = {Harbin, China},
abstract = {Currently, most software performance testing tools in the market are large ones designated for enterprises. Aiming at the demand of small-sized and individual customers' conduction of software performance testing, the paper proposes an approach for designing and realizing a small tool for testing. Core design refers to simulating multi-user concurrent operation by simultaneous execution of multithreading and measuring performance of the system tested through whether each threading responses in a correct manner as well as testing data such as period of responding. Testing tool, which is realized by Java language, consists of three modules of case management, test implementation and test report. Multiple designing modes are utilized in a combined manner during designing, which makes the designing scheme a simple one with high efficiency and easy to expand. The market of performance testing is developing in a rapid manner and researching software performance test is gaining increasingly significance. &copy; 2011 IEEE.<br/>},
key = {Software testing},
keywords = {Commerce;Multitasking;},
note = {Concurrent operations;designing approach;designing mode;Individual customers;Measuring performance;Software performance;Software performance testing;Testing tools;},
URL = {http://dx.doi.org/10.1109/EMEIT.2011.6023983},
} 


@article{20143600057828,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Towards virtualized and automated software performance test architecture},
journal = {Multimedia Tools and Applications},
author = {Kim, Gwang-Hun and Kim, Yeon-Gyun and Chung, Kyung-Yong},
volume = {74},
number = {20},
year = {2015},
pages = {8745 - 8759},
issn = {13807501},
abstract = {In this paper, we propose the towards virtualized and automated software performance test architecture. In general, test engineers use the public performance testwares such as Load Runner, Silk Performer to validate the performance efficiency of their own systems. In case that they do not allowed to use the performance testwares due to the technical limitations in the testwares, most testers should perform the testing in manually. According to the waste of computer and human resources resulted from the situation, we need to propose the test automation scheme by using the virtualization technology to prevent the dissipation in the test environment which has limited resources. The system architecture considered efficient usage of computer resources and test automation to reduce human acts are addressed mainly in this paper. we describe our proposed method which deals with the system architecture and test automation procedures. In our system architecture, we will show how to use the virtual machines and the types of the virtual machines for performance measurement. In addition, the six steps of the test automation are introduced for the automated testing procedures. Finally, a number of experiments show that the proposed schemes allow offering the possibility for automated software performance testing by using the virtualization.<br/> &copy; 2013, Springer Science+Business Media New York.},
key = {Software testing},
keywords = {Automation;Computer architecture;Network security;Virtual machine;Virtual reality;Virtualization;},
note = {Performance efficiency;Performance measurements;Performance testing;Software performance engineerings;Software performance testing;Technical limitations;Test Automation;Virtualization technologies;},
URL = {http://dx.doi.org/10.1007/s11042-013-1536-3},
} 


@inproceedings{2005028788142,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Architecture and performance testing of a software GPS receiver for space-based applications},
journal = {IEEE Aerospace Conference Proceedings},
author = {Gold, Kenn and Brown, Alison},
volume = {4},
year = {2004},
pages = {2404 - 2415},
issn = {1095323X},
address = {Big Sky, MT, United states},
abstract = {Space-based GPS technology presents significant challenges over Earth-based systems. These include visibility issues for rotating platforms and tracking of GPS satellites from spacecraft that are in higher orbits than the GPS, realtime resolution of carrier phase ambiguities, and different dynamics during various mission phases. NAVSYS has developed a software GPS receiver that makes use of 3-dimensional Digital Beam Steering technology and inertial aiding to address these issues. This approach offers several advantages including all around visibility for spinning satellites, tracking of weak GPS signals, reduction of multipath, and reprogrammability to accommodate different mission phases. Additionally, a suite of simulation tools based around the NAVSYS Matlab Toolbox and Advanced GPS Hybrid Simulation products have been built to allow testing for simulated space environments. The receiver architecture and test tools are described in this paper.},
key = {Global positioning system},
keywords = {Computer architecture;Computer simulation;Computer software;Orbits;Satellites;Signal processing;Signal to noise ratio;Space applications;},
note = {Digital beam steering technology;Goddard space flight center (GSFC);Precision applications;Satellite signals;},
URL = {http://dx.doi.org/10.1109/AERO.2004.1368035},
} 


@inproceedings{20124015495162,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Expertus: A generator approach to automate performance testing in IaaS clouds},
journal = {Proceedings - 2012 IEEE 5th International Conference on Cloud Computing, CLOUD 2012},
author = {Jayasinghe, Deepal and Swint, Galen and Malkowski, Simon and Li, Jack and Wang, Qingyang and Park, Junhee and Pu, Calton},
year = {2012},
pages = {115 - 122},
address = {Honolulu, HI, United states},
abstract = {Cloud computing is an emerging technology paradigm that revolutionizes the computing landscape by providing on-demand delivery of software, platform, and infrastructure over the Internet. Yet, architecting, deploying, and configuring enterprise applications to run well on modern clouds remains a challenge due to associated complexities and non-trivial implications. The natural and presumably unbiased approach to these questions is thorough testing before moving applications to production settings. However, thorough testing of enterprise applications on modern clouds is cumbersome and error-prone due to a large number of relevant scenarios and difficulties in testing process. We address some of these challenges through Expertus - -a flexible code generation framework for automated performance testing of distributed applications in Infrastructure as a Service (IaaS) clouds. Expertus uses a multi-pass compiler approach and leverages template-driven code generation to modularly incorporate different software applications on IaaS clouds. Expertus automatically handles complex configuration dependencies of software applications and significantly reduces human errors associated with manual approaches for software configuration and testing. To date, Expertus has been used to study three distributed applications on five IaaS clouds with over 10,000 different hardware, software, and virtualization configurations. The flexibility and extensibility of Expertus and our own experience on using it shows that new clouds, applications, and software packages can easily be incorporated. &copy; 2012 IEEE.<br/>},
key = {Infrastructure as a service (IaaS)},
keywords = {Application programs;Automation;Clouds;Codes (symbols);Program compilers;Scalability;Software testing;Testing;},
note = {Aspect;Code Generation;Datacenter;Emulab;IaaS;Multi-tier;Open Cirrus;Performance;Template;},
URL = {http://dx.doi.org/10.1109/CLOUD.2012.98},
} 


@article{20130515969956,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Towards an interface-based automation testing framework for sirverlight applications},
journal = {Information Technology Journal},
author = {Tang, Jingfan and Zhu, Qin and Jiang, Ming},
volume = {12},
number = {4},
year = {2013},
pages = {829 - 834},
issn = {18125638},
abstract = {Nowadays software applications are increasingly becoming large in scale and complexity, thus, Graphical User Interface (GUI) testing plays a formal important role in ensuring the correctness and reliability of software applications. A variety of approaches in the area of GUI testing have emerged in recent years. One notable trend is Model-Based Testing (MBT) which creates an abstract test model that simulates the anticipated behavior of the System Under Testing (SUT) by using some software generated tools to generate model tests. This study highlights the designing as well as the presentation of a new automation testing framework for silverlight applications with particular focuses upon the integration of the Spec Explorer based MBT with a free web framework called WebAii. Both of the tools are available as open source. Spec Explorer can be used to generate the test cases automatically, while WebAii is used to simulate human action and operation processes to complete the test execution in an automated way. &copy; 2013 Asian Network for Scientific Information.},
key = {Software testing},
keywords = {Automation;Graphical user interfaces;Software reliability;Testing;},
note = {Automation testing;GUI testing;Human actions;Model based testing;Model tests;Open sources;Operation process;Software applications;Spec Explorer;Test case;Test execution;Test models;WebAii;},
URL = {http://dx.doi.org/10.3923/itj.2013.829.834},
} 


@article{2001516768189,
language = {German},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {LCC/RAM performance test for Wiener Linien tramway stock using the CaLCC&reg data collection system module},
title = {LCC/RAM-Performancenachweis fur die stracenbahnfahrzeuge der Wiener Linien unter einsatz des moduls CaLCC&reg-DataCollectionSystem},
journal = {ZEV-Zeitschrift fuer Eisenbahnwesen und Verkehrstechnik - Journal for Railway and Transport},
author = {Lehotzky, P. and Trescher, C.},
volume = {125},
number = {9-10},
year = {2001},
pages = {371 - 373},
issn = {09410589},
abstract = {A software tool is presented which makes it possible to store and evaluate the life cycle cost (LCC) data of a vehicle fleet. Wiener Linien use this tool for the purpose of implementing a performance test and for determining parameters for the application of a bonus/penalty system that has been agreed upon between the vehicle manufacturer and operator.},
key = {Railroad rolling stock},
keywords = {Computer aided software engineering;Cost benefit analysis;Data acquisition;Data reduction;Information retrieval systems;Performance;},
note = {Bonus-penalty system;Data collection system module;Life cycle cost;},
} 


@article{20111813948297,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and performance test of spacecraft test and operation software},
journal = {Acta Astronautica},
author = {Wang, Guohua and Cui, Yan and Wang, Shuo and Meng, Xiaofeng},
volume = {68},
number = {11-12},
year = {2011},
pages = {1774 - 1781},
issn = {00945765},
abstract = {Main test processor (MTP) software is the key element of Electrical Ground Support Equipment (EGSE) for spacecraft test and operation used in the Chinese Academy of Space Technology (CAST) for years without innovation. With the increasing demand for a more efficient and agile MTP software, the new MTP software was developed. It adopts layered and plug-in based software architecture, whose core runtime server provides message queue management, share memory management and process management services and forms the framework for a configurable and open architecture system. To investigate the MTP softwares performance, the test case of network response time, test sequence management capability and data-processing capability was introduced in detail. Test results show that the MTP software is common and has higher performance than the legacy one. &copy; 2011 Elsevier Ltd. All rights reserved.<br/>},
key = {Software testing},
keywords = {Aerospace ground support;Computer architecture;Data handling;Ground supports;Information management;Network architecture;Spacecraft equipment;},
note = {Electrical ground support equipments;Main test processor;Management capabilities;Open architecture systems;Performance tests;Process management;Processing capability;Space technologies;},
URL = {http://dx.doi.org/10.1016/j.actaastro.2011.02.002},
} 


@inproceedings{20174404329102,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A Multi-objective Metaheuristic Approach to Search-Based Stress Testing},
journal = {IEEE CIT 2017 - 17th IEEE International Conference on Computer and Information Technology},
author = {Gois, Nauber and Porfirio, Pedro and Coelho, Andre},
year = {2017},
pages = {55 - 62},
address = {Helsinki, Finland},
abstract = {Nowadays applications need to deal with a large number of concurrent requests. These systems must be stress tested to ensure that they can function correctly under a load. In this context, a research field called Search-based Software Testing has become increasingly important. Most of the search-based test methods are based on single objective optimization. In the case of multi-objective optimization of tests, usually researchers assign different weight values to different objectives and combine them as a single objective. This research paper verifies the use of a multi-objective algorithm in search-based stress testing. The NSGA-II algorithm was implemented in the IAdapter tool using the jMetal framework. IAdapter is a JMeter plugin used for performing search-based stress tests. jMetal is an object-oriented Java-based framework for multi-objective optimization with metaheuristics. One experiment was conducted to validate the proposed approach. &copy; 2017 IEEE.},
key = {Multiobjective optimization},
keywords = {Heuristic methods;Object oriented programming;Optimization;Software testing;Testing;},
note = {Concurrent requests;Multi objective algorithm;Multi-objective metaheuristics;NSGA-II algorithm;Pareto frontiers;Search-based software testing;Single objective optimization;Stress test;},
URL = {http://dx.doi.org/10.1109/CIT.2017.19},
} 


@inproceedings{20083611505910,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Yet another performance testing framework},
journal = {Proceedings of the Australian Software Engineering Conference, ASWEC},
author = {Chen, Shiping and Moreland, David and Nepal, Surya and Zic, John},
year = {2008},
pages = {170 - 179},
address = {Perth, WA, Australia},
abstract = {Performance testing is one of the vital activities spanning the whole life cycle of software engineering. While there are a consideruble number of performance testing products and open source tools available, they are either too expensive and complicated for small projects, or too specific and simple for diverse performance tests. This paper presents a general-purpose testing framework for both simple and small, and complicated and large-scale performance testing. Our framework proposes an abstraction to facilitate performance testing by separating the application logic from the common performance testing functionalities. This leads to a set of general-purpose data models and components, which form the core of the framework. The framework has been prototyped on both.NET and Java platforms and was used for a number of performance-related projects. &copy; 2008 IEEE.<br/>},
key = {Software testing},
keywords = {Life cycle;Open source software;},
note = {Application logic;Java platforms;Open source tools;Performance testing;Performance testing framework;Performance tests;Testing framework;Whole life cycles;},
URL = {http://dx.doi.org/10.1109/ASWEC.2008.4483205},
} 


@inproceedings{20140817357128,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A performance testing tool for source code},
journal = {Applied Mechanics and Materials},
author = {Luo, Jun and Yang, Wei},
volume = {490-491},
year = {2014},
pages = {1553 - 1559},
issn = {16609336},
address = {Beijing, China},
abstract = {With the rapid development of the information age, computer software develops toward systematization and complication. In application areas such as commerce, finance and medical treatment, the performance of software is attracting more and more attention which even becomes one of the important factors to determine whether users are willing to use a piece of software. Currently, static checking tools are mostly designed to check the code errors but pay little attention to the performance problems. In order to detect the defects in source code that may cause performance problems, this paper designs and achieves a performance testing tool based on static analysis method. The experiments of detecting several open source projects using our testing tool demonstrate that it can quickly find the defects in source code with high accuracy rate. The result of defection removing shows that it can significantly reduce the memory consumption of software, and it can effectively improve software performance. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Static analysis},
keywords = {Application programs;Computer programming languages;Defects;Tools;},
note = {Code analysis;Memory consumption;Open source projects;Performance optimizations;Performance problems;Performance testing;Software performance;Static analysis method;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.490-491.1553},
} 


@inproceedings{1995012422340,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Prototype-driven approach to application-level performance testing: A case study of a large finance application},
journal = {Proceedings of the Symposium on Assessment of Quality Software Development Tools},
author = {Grossman, D. and Staton, C.J. and Bailey, B. and McCabe, M.C. and Latts, A. and Frieder, O. and Bock, C. and Roberts, D.},
year = {1994},
pages = {125 - 135},
address = {Washington, DC, USA},
abstract = {We present an approach to application-level performance testing. This uses a popular test tool, TPNS (Teleprocessing Network Simulator) to simulate performance of an application. Our approach hinges upon a simple prototype to verify that the system performance falls within acceptable bounds. Once the initial prototype is developed, detailed tuning may take place. We present a case study in which we tested the performance of a large finance application. This approach led to critical performance tuning improvement. Due to this improvement, the average user response time in our simulations was reduced from 30 seconds to under 1.5 seconds. This simulation has been verified by actual system usage during the first two months of live operation in which the average response time has indeed been under 1.5 seconds.},
key = {Database systems},
keywords = {Computer aided analysis;Computer networks;Computer operating systems;Computer simulation;Computer software selection and evaluation;Data processing;Product design;Program diagnostics;Response time (computer systems);Standards;Systems analysis;},
note = {Application level testing;Database management systems (DMBS);Initial production usage performance problems;Performance tuning;System level testing;Teleprocessing network simulator (TPNS);},
} 


@article{20120714765457,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and performance testing of moving coil linear motor for Stirling generator},
journal = {Dianji yu Kongzhi Xuebao/Electric Machines and Control},
author = {Jia, Hong-Shu and Hong, Guo-Tong and Chen, Hou-Lei},
volume = {15},
number = {12},
year = {2011},
pages = {21 - 25},
issn = {1007449X},
abstract = {In order to develop linear motor for free piston Stirling generator, moving coil linear motor structure was designed. Magnetic field of the motor was obtained by finite element simulation and testing, and the output characteristic were studied. The calculated results of magnetic field using the finite element software ANSYS meet the experimental results, and the results show that magnetic flux density achieved 626 mT at the air-gap is 6 mm. Experimental system for testing output characteristics of the moving coil motor was established. Output characteristics testing of moving coil linear motor was conducted. The results show that effective output voltage increases linearly with displacement at constant magnetic field strength, coil length and moving frequency. The slope is the function of coil impedance and external load. Moreover, the output voltage increases at load resistance under conditions of same input voltage at a constant coil displacement. The calculatied natrual frequency is 16.5 Hz. The output current of the motor decreases with the increasing of work frequency away from the system natural frequency, and the efficiency of the system is 20%.<br/>},
key = {Linear motors},
keywords = {Finite element method;Magnetic devices;Magnetic fields;Magnetic flux;Pistons;},
note = {Constant magnetic fields;Experimental system;Finite element simulations;Finite element software;Frequency;Moving coils;Output characteristics;Stirling generators;},
} 


@inproceedings{20064610243750,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test tool for RFID middleware: Parameters, design, implementation, and features},
journal = {8th International Conference Advanced Communication Technology, ICACT 2006 - Proceedings},
author = {Lee, Jongyoung and Kim, Naesoo},
volume = {1},
year = {2006},
pages = {149 - 152},
address = {Phoenix Park, Korea, Republic of},
abstract = {Recently, Major software vendors(such as Sun, IBM, Oracle) introduce RFID middleware product which process RFID tag data cause of extending RFID related technology and application. RFID middleware which receives tag data from reader, internal process receiving data, and transmit result to application acts key role of applying RFID technology to application. In this paper, we define parameters for RFID middleware performance and introduce design of performance test tool of RFID middleware.},
key = {Middleware},
keywords = {Computer software;Data reduction;Identification (control systems);Parameter estimation;},
note = {Performance test tool;RFID technology;Software testing;},
} 


@inproceedings{20093412261037,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test of a 100 kW HTS generator operating at 67 K-77 K},
journal = {IEEE Transactions on Applied Superconductivity},
author = {Wen, Huaming and Bailey, Wendell and Goddard, Kevin and Al-Mosawi, Maitham and Beduz, Carlo and Yang, Yifeng},
volume = {19},
number = {3},
year = {2009},
pages = {1652 - 1655},
issn = {10518223},
abstract = {A systematic test program is in progress to fully characterize a 100 kW HTS synchronous generator which was successfully constructed in 2004. The machine was one of the first HTS synchronous generator/motors to operate at liquid nitrogen temperatures while achieving a power rating relevant to practical application. It has a conventional 3-phase stator and a cold rotor with a magnetic core and a superconducting winding consisting of 10 HTS Bi2223 pancake coils separated by magnetic flux diverters. The test program includes a series of tests at various speeds, field currents and temperatures (65 K-77 K) with the machine in open circuit to determine the critical currents of the HTS rotor, the waveform and harmonic characteristics of generated voltage at different levels of iron saturation. Stationary measurements of the rotor critical current are carried out using dc current in the stator windings to quantify the influence of stator field on the performance of the superconducting winding. The voltages and temperatures of the rotor are measured using a radio frequency telemetry system. &copy; 2009 IEEE.<br/>},
key = {Electric generators},
keywords = {AC generator motors;High temperature superconductors;Rotors (windings);Software testing;Stators;Superconducting coils;Superconducting devices;Synchronous generators;Winding;},
note = {Bscco coils;Harmonic characteristics;High temperature superconducting;HTS motors;Liquid nitrogen temperature;Performance tests;Rotating superconducting machines;Superconducting winding;},
URL = {http://dx.doi.org/10.1109/TASC.2009.2017832},
} 


@article{20135217144592,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {High speed NAND Flash image recorder load test system},
journal = {Hongwai yu Jiguang Gongcheng/Infrared and Laser Engineering},
author = {Xu, Yonggang and Ren, Guoqiang and Wu, Qinzhang and Wu, Wei},
volume = {42},
number = {10},
year = {2013},
pages = {2858 - 2864},
issn = {10072276},
abstract = {In order to determine the stability of the NAND Flash image recorder and the peak recording speed, reducing the amount of manual testing, a new load test system was designed. To solve the problem of stability test, speed load model based on exponential regression and test time control model based on the lognormal distribution were proposed. To test the peak recording speed, the test methods combining hardware with software based on climbing search algorithm and speed dichotomy was praser. The hardware data generator was designed, whose speed was software adjustable according to valid data duty cycle mechanism. Climbing search algorithm rough determined the peak recording speed range, and then the speed dichotomy approached the peak recording speed; the test report was transferred to PC for display through the serial port and Gigabit Ethernet. Experimental results show that the speed load regulation accuracy is up to 0.1 MB/s; the speed load range is from 0 to 1600 MB/s; verification of read back data using hardware has no clock delay; the tested NAND Flash recorder connecting with 8 SLC NAND Flash chips has the peak recording speed of 240.12 MB/s; under the speed load 200 MB/s, the NAND Flash record controller can work well continuously for more than 24 h. The load test system can be used for load test of other transmission and recording system because of its universal architecture.},
key = {Search engines},
keywords = {Convergence of numerical methods;Hardware;Image recording;Learning algorithms;Load testing;Software testing;Speed;System stability;},
note = {Climbing search;Exponential regression;Gigabit Ethernet;Log-normal distribution;NAND Flash;Recording systems;Search Algorithms;Test systems;},
} 


@article{20133816763078,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing system of trailer axle based on virtual instrument},
journal = {Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering},
author = {Wu, Weibin and Zhao, Ben and Hong, Tiansheng and Zhao, Wenfeng and Deng, Xiaoling and Zhu, Yuqing and Ruan, Shaomeng},
volume = {29},
number = {SUPPL1},
year = {2013},
pages = {25 - 31},
issn = {10026819},
abstract = {The axle is one of the most important components directly relating the safety operation of vehicles. However, the testing method of axle on site used in China is backward and inefficient, while checking failures occur now and then. But the theory of reliability design of fatigue, which has been well developed, is difficult to be applied to the test of axle on site. In recent years, the computing automotive technology is advocated at abroad to solve the complicated problem of how to put the reliability analysis of fatigue into practice. This paper realized the 3D simulation of testing system through the Pro/E software as well as constructed the system, which was based on the trailer axle testing system prototype. The system hardware was comprised of support, guide, sensors, AC servo motor and servo driver; meanwhile, the system software adapted the modularized idea in order to divide the monolithic construction into five parts, including main operation control module and 4 testing modules. Every testing module was constituted by 5 submodules. The system software program was written by LabVIEW. It drove the linkage device by controlling the rotation of the servo motor and loaded the simulated axle through two pressure heads, then the displacement and pressure were collected as feedback through the data acquisition card. The displacement-voltage linear relationship of A/B pressure head was obtained through experiments on displacement sensors before system test. By calibrating the straight-line equation, the result was that the maximum locating relative error is 5.207%, and the absolute value of average relative error was 1.4%. The voltage-load linear relationship of A/B pressure head was obtained by accurate positioning of load. Analyzed by software SPSS, in the equation of the load stress and voltage linear regression, the result was that R &gt; 0.994, Sig. &lt; 0.05, thus regression was significant. According the constructed testing system, the performance of fatigue, stiffness, strength, and stress of the simulated axle were tested and analyzed. In fatigue test, flaw occurred after 821 times vibration and efficacy was lost after 1067 times vibration; in stiffness test, spot D almost stayed unchanged and the displacements of spot C and E ranged from 60 to 63 mm; in strength test, the maximum displacement of sensor E was 66.622 mm; in stress test, the maximum displacement of spot E was 66.751 mm, and the maximum stress was 259.444 MPa. The system was steady. The simulated test had been lasting for one month and no bug was found. Therefore, the result generally meets the project requirement.},
key = {Axles},
keywords = {AC generator motors;Computer software;Digital devices;Fatigue of materials;Fatigue testing;Instruments;Reliability theory;Sensors;Servomotors;Stiffness;},
note = {Automotive technology;Average relative error;Data acquisition cards;Intensity;LabViEW;Linear relationships;Maximum displacement;Performance tests;},
URL = {http://dx.doi.org/10.3969/j.issn.1002-6819.2013.z1.004},
} 


@inproceedings{20095212580689,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stress testing the Logical Decision Making Server of a surveillance system},
journal = {1st International Conference on Advances in System Testing and Validation Lifecycle, VALID 2009},
author = {Nieminen, Mikko and Raty, Tomi and Palokangas, Jukka},
year = {2009},
pages = {98 - 103},
address = {Porto, Portugal},
abstract = {The current generation of distributed and automated physical location surveillance systems faces high demands for robustness and reliability. We present and evaluate the design of the Logical Decision Making Server (LDMS), a rule-based automated decision making component used in the Single Location Surveillance Point (SLSP) system. To validate the robustness of the LDMS design for operation in the SLSP environment, we design and conduct a stress test experiment in which large load of TCP/IP input messages is sent instantaneously to the LDMS prototype implementation using the Nethawk EAST software. The stress test results are compared to measurements obtained during a real-life scenario. The LDMS is observed to withstand a significant amount of load without crashing, and its performance is can be considered sufficient for the SLSP system needs. A detailed analysis of results however shows an increase in the latency resulting from an extreme temporal load. We identify potential areas in the design to be improved if demands for higher response rates arise. The research is based on the construction of the related publications and technologies, and the results are established from the testing and validation of the implemented LDMS within the SLSP system. &copy; 2009 IEEE.<br/>},
key = {Decision making},
keywords = {Life cycle;Monitoring;Security systems;Software testing;Space surveillance;System theory;},
note = {Automated decision making;Component;Current generation;Logical decisions;Physical locations;Prototype implementations;Stress Testing;Surveillance systems;},
URL = {http://dx.doi.org/10.1109/VALID.2009.16},
} 


@inproceedings{20171703611671,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {LTTC: A load testing tool for cloud},
journal = {Advances in Intelligent Systems and Computing},
author = {Geetha Devasena, M.S. and Krishna Kumar, V. and Kingsy Grace, R.},
volume = {508},
year = {2017},
pages = {689 - 698},
issn = {21945357},
address = {Ahmedabad, India},
abstract = {Software testing is the process of software engineering to free the software from bugs. Load testing is one of the techniques in software testing and is used to find the maximum load that software can handle without affecting its performance. Load testing is used to test the cloud services that are running in a cloud. All the resources in a cloud are used by the cloud users based on their demand. Using cloud, it is easy to gather the required load for a particular application by forming clusters. If the required load is coming from different clusters and it is not known quantitatively then the problem of load balancing is raised. The proposed load testing tool avoids the problem of getting unequal loads coming from different clusters by distributing the same amount of load to all the clusters. Also the proposed load testing tool for cloud is used to find the maximum number of simultaneous users for a particular cloud system is to handle. &copy; Springer Nature Singapore Pte Ltd. 2017.},
key = {Load testing},
keywords = {Program debugging;Resource allocation;Software engineering;Software testing;},
note = {Cloud services;Cloud systems;Cloud testing;Maximum load;Running-in;},
URL = {http://dx.doi.org/10.1007/978-981-10-2750-5_70},
} 


@inproceedings{20113314234219,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Home care web services evaluation by stress testing},
journal = {Communications in Computer and Information Science},
author = {Krejcar, Ondrej and Motalova, Leona},
volume = {171 CCIS},
year = {2011},
pages = {238 - 248},
issn = {18650929},
abstract = {Development of software applications result in complete application or solution. The last phase of developing process is the final testing of developed solution. The goal of our paper has focused on this problem in case of web services. The developed testing application can be used for any other software solutions with web service interface. The developed test environment, including application developed for the stress testing is based on Microsoft .NET Framework technology. Our stress testing application allows testing of selected problem areas to find any limitations before the tested developing solution will be set up at customer. By the help of our test application, the hardware solution for the server was selected on the base of selected home care agency needs. &copy; 2011 Springer-Verlag.<br/>},
key = {Web services},
keywords = {Application programs;Hardware;Mobile devices;Response time (computer systems);Software testing;Websites;},
note = {Developing process;Developing solutions;Hardware solutions;Software applications;SQL servers;Stress Testing;Test applications;Web service interface;},
URL = {http://dx.doi.org/10.1007/978-3-642-22729-5_20},
} 


@inproceedings{1998254178939,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing in a client-server environment},
journal = {CMG Proceedings},
author = {Merton, Joseph K.},
volume = {1},
year = {1997},
pages = {594 - 601},
address = {Orlando, FL, USA},
abstract = {As an enterprise grows and adapts to changing business conditions, performance of client-server systems is affected by workload changes caused by growth, functional application changes, and configuration changes in hardware, software, or network topology. This paper presents a case study of the implementation of performance testing in a client-server environment. It describes performance testing objectives, evaluation and selection of performance testing software, construction of a performance testing environment, construction and execution of test cases, and evaluation of results.},
key = {Online systems},
keywords = {Computer aided software engineering;Computer networks;Computer software selection and evaluation;Response time (computer systems);Systems analysis;},
note = {Client/server environment;},
} 


@inproceedings{20104213294741,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Distributed agent-based performance testing framework on Web Services},
journal = {Proceedings 2010 IEEE International Conference on Software Engineering and Service Sciences, ICSESS 2010},
author = {Hao, Dan and Chen, Yinghui and Tang, Fan and Qi, Feng},
year = {2010},
pages = {90 - 94},
abstract = {Web Services are applied widely in the field of information technology, and performance testing for Web Services applications has become an important problem. This paper introduces the method of performance testing, and proposes a framework of agent-based performance testing on Web Services, which includes TestFlow Generator, Scenario Creator, Test Manager, Load Generation Agent and Test Analyzer. And the implementation of kernel modules in the framework is introduced especially. To realize the load allocation to distributed Load Generation Agents from Test Manager, a queue-based allocation strategy is given. &copy; 2010 IEEE.<br/>},
key = {Web services},
keywords = {Load testing;Managers;Software engineering;Websites;},
note = {Agent based;Allocation strategy;Distributed agents;Distributed loads;Kernel modules;Load allocation;Performance testing;Performance testing framework;},
URL = {http://dx.doi.org/10.1109/ICSESS.2010.5552290},
} 


@inproceedings{20121214869057,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and implementation of cloud-based performance testing system for web services},
journal = {Proceedings of the 2011 6th International ICST Conference on Communications and Networking in China, CHINACOM 2011},
author = {Zhang, Li and Chen, Yinghui and Tang, Fan and Ao, Xiong},
year = {2011},
pages = {875 - 880},
address = {Harbin, China},
abstract = {Nowadays testing plays an important role in software development process. While software testing is expensive and time-consuming, sufficient testing is hard, especially for a distributed system using web services technique in the real circumstance. The development of cloud computing provides us new ideas to solve these testing problems. To address these issues, we propose a framework which integrates cloud computing and performance testing technologies. In this paper, first we present the architecture of the cloud-based performance testing system for web services (CPTS), which is a portable, extensible and easy-to-use framework for generating and submitting test workloads to computing clouds. Then, we show the process how to use CPTS to run a performance test and present the concept of dynamic migration in CPTS. Finally, we present our experiences with CPTS in Amazon EC2. We found that the CPTS allows a user to easily set up and test a web services system on the cloud and improve test effectively. &copy; 2011 IEEE.<br/>},
key = {Web services},
keywords = {Cloud computing;Software design;Software testing;Testing;Virtual machine;Websites;},
note = {Cloud-based;Computing clouds;Design and implementations;Distributed systems;Dynamic migration;Performance testing;Performance tests;Software development process;},
URL = {http://dx.doi.org/10.1109/ChinaCom.2011.6158278},
} 


@inproceedings{20170503293412,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Study of performance testing of information system based on domestic CPU and OS},
journal = {Proceedings - 2016 3rd International Conference on Trustworthy Systems and Their Applications, TSA 2016},
author = {Li, Dong and Xiong, Jing and Yang, Chunhui},
year = {2016},
pages = {112 - 116},
address = {Wuhan, Hubei, China},
abstract = {In order to evaluate the performance of of information system based on domestic CPU and OS, through the introduction of the background of basic hardware and software based on domestic, we expound the domestic information system performance testing principle and method, according to the testing results of existing mature commercial performance testing tool LoadRunner can not reflect the user experience of time, and can not be directly used for testing the information system which based on domestic CPU/OS, this paper put forward the two kinds of testing schemes that base on user experience of LoadRunner and JMeter domestic information system performance test, and test two kinds of improved schemes, through the comparison of the test data and the user experience time of the two schemes, the variance of the test scheme based on JMeter is smaller than LoadRunner test scheme 70.49%. The results show that the test results of the JMeter scheme are more close to the user experience than LoadRunner. &copy; 2016 IEEE.},
key = {Software testing},
keywords = {Information systems;Testing;},
note = {Domistic Operating System(OS);Hardware and software;Improved scheme;Infrastructure software;Performance testing;Performance tests;Test tools;User experience;},
URL = {http://dx.doi.org/10.1109/TSA.2016.27},
} 


@inproceedings{20181504992142,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A new method for SSD black-box performance test},
journal = {Progress in Electromagnetics Research Symposium},
author = {Xie, Qiyou},
year = {2017},
pages = {1116 - 1122},
issn = {15599450},
address = {St. Petersburg, Russia},
abstract = {In the past decade, NAND Flash has stood out from numerous non-volatile storage mediums. The NAND Flash based Solid State Disk (SSD) has been widely used in many storing required fields such as embedded applications and data center. A new and efficient SSD black-box performance test method is revising in this paper. The designed test system contains time parameter getter, excitation signal generator, buffer unit, write/read controller and SSD. With the application of the proposed method, not only the influence of TRIM mechanism could been analyzed, but also the test precision is increased significantly. To verify the validity and performance of our test system, the IOPS, response time and write/read bandwidth of the universal testing software (IOMETER, HDTUNE, etc.) and SATA protocol analyzer are presented and compared with our method in detail.<br/> &copy; 2018 Electromagnetics Academy. All rights reserved.},
key = {Software testing},
keywords = {Flash-based SSDs;Memory architecture;NAND circuits;Testing;},
note = {Embedded application;Excitation signals;Performance tests;Protocol analyzers;Solid state disks (SSD);Testing software;Time parameter;Trim mechanisms;},
URL = {http://dx.doi.org/10.1109/PIERS.2017.8261912},
} 


@inproceedings{20143718153940,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing open source products for the TMT event service},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Gillies, K. and Bhate, Yogesh},
volume = {9152},
year = {2014},
pages = {The Society of Photo-Optical Instrumentation Engineers (SPIE) - },
issn = {0277786X},
address = {Montreal, QC, Canada},
abstract = {The software system for TMT is a distributed system with many components on many computers. Each component integrates with the overall system using a set of software services. The Event Service is a publish-subscribe message system that allows the distribution of demands and other events. The performance requirements for the Event Service are demanding with a goal of over 60 thousand events/second. This service is critical to the success of the TMT software architecture; therefore, a project was started to survey the open source and commercial market for viable software products. A trade study led to the selection of five products for thorough testing using a specially constructed computer/network configuration and test suite. The best performing product was chosen as the basis of a prototype Event Service implementation. This paper describes the process and performance tests conducted by Persistent Systems that led to the selection of the product for the prototype Event Service. &copy; 2014 SPIE.<br/>},
key = {Open systems},
keywords = {Commerce;Middleware;Open source software;Software design;Software testing;},
note = {Commercial market;Distributed systems;Open source products;Performance requirements;Performance testing;Performance tests;Software products;Software services;},
URL = {http://dx.doi.org/10.1117/12.2057148},
} 


@inproceedings{20101712879826,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Software performance testing scheme using virtualization technology},
journal = {Proceedings of the 4th International Conference on Ubiquitous Information Technologies and Applications, ICUT 2009},
author = {Kim, Gwang-Hun and Moon, Hui-Choun and Song, Gi-Pyeung and Shin, Seok-Kyu},
year = {2009},
address = {Fukuoka, Japan},
abstract = {In this paper, we propose software performance testing scheme using virtualization technology. Generally, people have used software performance testing tool such as load runner and silk performer. However, people should perform software performance testing manually in case of the situation that people cannot use testing tool. It needs a lot of resources such as human resource and computing resource. Therefore, we propose software performance testing scheme using virtualization technology to reduce resource consumption. Proposed scheme can reduce computer resource consumption because virtualization technology can make a number of virtual computers with a small number of physical computers. Also proposed scheme can reduce human resource consumption because, in proposed scheme, management computer can control keyboard and mouse of virtual computers automatically. Simulation result shows that proposed scheme has possibility to be used for software performance testing. &copy; 2009 IEEE.<br/>},
key = {Software testing},
keywords = {Computer resource management;Human resource management;Load testing;Virtual reality;Virtualization;},
note = {Computer resources;Computing resource;Performance testing;Resource consumption;Software performance engineerings;Software performance testing;Test Automation;Virtualization technologies;},
URL = {http://dx.doi.org/10.1109/ICUT.2009.5405721},
} 


@article{20134817030778,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Automation testing software that aid in efficiency increase of regressionprocess},
journal = {Recent Patents on Computer Science},
author = {Bhatt, Alok N. and Babu Rajasekhara, M. and Bhatt, Anuja J.},
volume = {6},
number = {2},
year = {2013},
pages = {107 - 114},
issn = {18744796},
abstract = {Accuracy of any software release to the market depends on how efficiently it has been debugged. Debugging is a systematic procedure, used to identify and figure out the cause of defects or any anomaly that the software has and make the software behave as expected. The issues generated by the customer of any company are logged into a database, wherein issues are picked up selected, solved and reverted back to the customers. After solving an issue, it may happen that the issue affects other components which results into a greater number of bugs. The resultant issues are called regression issues. The objective of this paper is to propose and implement a client-server, object-oriented, multiple plat form supporting frame work called RATS Framework which automates the process of regression and thereby helps debug engineers to solve time-consuming regression issues at a faster rate. It automates the process with the help of web-scrapping algorithm (W-S-A) that includes HTML/XML parsing to extract the needed content in the form of GUI-Web Objects, than using Network-Binary Search Algorithm (N/W-BS-A) and Change Finder Algorithm, a variant of Binary Search method, RATS finds out the nearest pass/fail driver build and change in the driver build that cause the new defect in the driver respectively. Because the RATS Framework does this at runtime, client-server approach has to be followed making use of Remote Identification and Installation-Algorithm. Hence RATS framework is a cost effective and time efficient approach for regression issues. The present article has the discussion of few of the patents relevant to automation testing software. &copy; 2013 Bentham Science Publishers.},
key = {Program debugging},
keywords = {Algorithms;Cost effectiveness;Defects;Graphical user interfaces;Object oriented programming;Rats;Regression analysis;Software testing;},
note = {Client server;Cost effective;GUI-Web objects;Multiple platforms;Object oriented;Time-efficient;},
} 


@inproceedings{20182105218919,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Enhancement of automation testing system using Yocto project},
journal = {Proceedings of the International Conference on Electronics, Communication and Aerospace Technology, ICECA 2017},
author = {Khandelwal, Harita and Mankodi, Parthesh and Prajapati, Ritesh},
volume = {2017-January},
year = {2017},
pages = {697 - 700},
address = {Coimbatore, India},
abstract = {Nowadays, in industries, Testing has become one of the important tasks. Testing is necessary for an effective performance of product and software applications. When companies having a mass production of hardware boards, it is necessary to do testing of each and every module of hardware like SPI, UART, GPIO, PWM, ADC, USB, Ethernet. If we do testing manually then it will significantly take more time, which we can be reduced by automation testing. But the solution is not an automation testing because automation testing also requires the same amount of system, for example for 300 boards 300 system is required. The only difference in manual and automation testing is that in automation testing it will require less human effort. Now we are focusing more on developing a solution in which many tests can be done on one single system i.e. for 300 boards only one system is required for testing hence this problem can be solved by Yocto Project. Yocto project have build the tool named Bitbake which is written in Python language, which works on multithreading and scheduling so that simultaneously you can test more boards on a single system. In this paper we did automation testing of GPIO pins using Yocto project.<br/> &copy; 2017 IEEE.},
key = {Software testing},
keywords = {Application programs;Automation;Hardware;},
note = {Automation testing;Bitbake;Effective performance;Mass production;Open embedded;PYTHON language;Software applications;Yocto project;},
URL = {http://dx.doi.org/10.1109/ICECA.2017.8203630},
} 


@inproceedings{20072610680510,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Patterns and tools for performance testing},
journal = {2006 IEEE International Conference on Electro Information Technology},
author = {Stankovic, Nenad},
year = {2006},
pages = {152 - 157},
address = {East Lansing, MI, United states},
abstract = {The growth of software applications in size and complexity is being followed by a number of specific nonfunctional requirements such as portability, interoperability, and availability on various platforms. Most often, these have been addressed by middleware or programming environment. In addition, easy customizability, adaptability, and sharing of components facilitates the development cycle. These should be understood and applied in a broader sense, i.e. to byproducts created during the development process such as programs for functional and performance testing. Much time is spent on developing test programs but their quality and quality of thus obtained results varies largely if the process is not standardized and automated. In this paper we present our experience with performance testing of a large scale suite of gateways that are used for the seamless integration of heterogeneous communication networks. We analyze the commercial and public domain tools for load generation and motivate our decision to define an in-house framework and build a distributed tool for performance, testing that is also not restricted by licensing issues and is readily available to everyone involved. Our tool is built on Visper, the object-oriented distributed programming middleware. The suitability and adaptability of the Visper model for rapid application development and the quality of produced result have proven our decision correct.},
key = {Software testing},
keywords = {Computer aided software engineering;Data transfer rates;Gateways (computer networks);Interoperability;Middleware;Object oriented programming;Process control;},
note = {Distributed tools;Heterogeneous communication networks;Object oriented distributed programming;},
URL = {http://dx.doi.org/10.1109/EIT.2006.252109},
} 


@inproceedings{20073910823930,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of microturbine generator system fueled by biodiesel},
journal = {Proceedings of the ASME Turbo Expo},
author = {Chiang, Hsiao-Wei D. and Chiang, I-Che and Li, Hsin-Lung},
volume = {1},
year = {2007},
pages = {459 - 466},
address = {Montreal, Que., Canada},
abstract = {Using microturbine generator systems for distributed power generation has become the recent trend. To face the impact of the global energy crisis, one of the options is to use biofuels including biodiesel. To this end, this program is to perform study on biodiesel microturbine testing and analysis. A 150kW microturbine generator set with twin rotating disk regenerators was used. Designed as a vehicular microturbine engine, the twin rotating ceramic disk regenerators dramatically improve fuel consumption by transferring heat energy from the exhaust gas stream to compressor discharge. This paper involved testing of the microturbine generator set at different load conditions using 10%-30% biodiesel fuel. A software program was used to predict the performance of the microturbine generator set at different operating conditions in order to compare with the test results. Both biodiesel and petrodiesel fuels are used on the microturbine generator system in this study and the results will be compared. Copyright &copy; 2007 by ASME.},
key = {Turbines},
keywords = {Biodiesel;Compressors;Electric generators;Fuel consumption;Rotating disks;Thermal energy;Vehicles;},
note = {Compressor discharges;Global energy crisis;Rotating disk regenerators;},
URL = {http://dx.doi.org/10.1115/GT2007-28075},
} 


@article{2005509546962,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stereo vision measurement system qualification and preliminary performance test results},
journal = {European Space Agency, (Special Publication) ESA SP},
author = {Finotello, R. and Losito, S. and Mondellini, C. and Rossi, G. and Zampato, M.},
number = {603},
year = {2005},
pages = {617 - 623},
issn = {03796566},
address = {Munich, Germany},
abstract = {The paper presents the Stereo Vision Measurement System. The system has been developed at proto-flight model level and features the stereo vision processing for in space measurement of the environment geometry. The SVMS subsystems and the relevant qualification tests are presented. Preliminary evaluations of the performances of the software system by using the laboratory prototype are included.},
key = {Computer software},
keywords = {Space research;Stereo vision;},
note = {Environment geometry;Space measurement;Stereo vision processing;},
} 


@inproceedings{20122515136087,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Peer-to-peer load testing},
journal = {Proceedings - IEEE 5th International Conference on Software Testing, Verification and Validation, ICST 2012},
author = {Meira, Jorge Augusto and Almeida, Eduardo Cunha De and Le Traon, Yves and Sunye, Gerson},
year = {2012},
pages = {642 - 647},
address = {Montreal, QC, Canada},
abstract = {Nowadays the large-scale systems are common-place in any kind of applications. The popularity of the web created a new environment in which the applications need to be highly scalable due to the data tsunami generated by a huge load of requests (i.e., connections and business operations). In this context, the main question is to validate how far the web applications can deal with the load generated by the clients. Load testing is a technique to analyze the behavior of the system under test upon normal and heavy load conditions. In this work we present a peer-to-peer load testing approach to isolate bottleneck problems related to centralized testing drivers and to scale up the load. Our approach was tested in a DBMS as study case and presents satisfactory results. &copy; 2012 IEEE.<br/>},
key = {Load testing},
keywords = {Large scale systems;Peer to peer networks;Software testing;Verification;},
note = {Bottleneck problem;Business operation;Heavy load conditions;Peer to peer;Scale-up;Study case;System under test;WEB application;},
URL = {http://dx.doi.org/10.1109/ICST.2012.153},
} 


@article{20091011939177,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {CLIF, a framework based on Fractal for flexible, distributed load testing},
journal = {Annales des Telecommunications/Annals of Telecommunications},
author = {Dillenseger, Bruno},
volume = {64},
number = {1-2},
year = {2009},
pages = {101 - 120},
issn = {00034347},
abstract = {The context of this work is performance evaluation of IT systems based on load testing. It typically consists in generating a flow of requests on a system under test, and to measure response times, request throughput, or computing resource usage. A quick overview of available load testing platforms shows that there exist hundreds of such platforms, including in the open source domain. However, many testers still tend to develop their own ad hoc load testing tooling. Why? This paper starts by looking for possible answers to this question, in order to introduce the CLIF load injection framework, which intends not to be yet another load testing platform. Based on the Fractal component model, the CLIF open source project aims at addressing key issues such as flexibility, adaptation, and scalability. We give here details about CLIF's architecture and associated tools as well as some feedback from a bunch of practical utilizations. &copy; 2008 Institut TELECOM and Springer-Verlag.<br/>},
key = {Load testing},
keywords = {Fractals;Open source software;Software testing;},
note = {Component-based software engineering;Computing resource;Distributed systems;Fractal component models;IS performance evaluation;Open source projects;Performance evaluations;Testing platforms;},
URL = {http://dx.doi.org/10.1007/s12243-008-0067-9},
} 


@inproceedings{20134416927580,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Keyword driven automation test},
journal = {Applied Mechanics and Materials},
author = {Wu, Zhong Qian and Li, Jin Zhe and Liao, Zeng Zeng},
volume = {427-429},
year = {2013},
pages = {652 - 655},
issn = {16609336},
address = {Chongqing, China},
abstract = {In order to improve software reusability of automated test scripts, presents a keyword-driven test automation framework (KDTFA). First, the current existing automated testing framework for inductive analysis; then raised KDTFA system architecture; finally, an example of the android interface application framework and the existing framework for KDTFA actual contrast verification results show that the framework has a reduced scale of test scripts to improve the overall test efficiency and other advantages. &copy; (2013) Trans Tech Publications, Switzerland.},
key = {Testing},
keywords = {Automation;Computer software reusability;Industrial electronics;Information technology;Mechanical engineering;},
note = {Automated testing;Interface applications;KDTFA;Keyword driven;Mobile;System architectures;Test automation frameworks;Verification results;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.427-429.652},
} 


@inproceedings{20110713665094,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Development of an improved GUI automation test system based on Event-flow graph},
journal = {Proceedings - International Conference on Computer Science and Software Engineering, CSSE 2008},
author = {Yongzhong, Lu and Danping, Yan and Songlin, Nie and Chun, Wang},
volume = {2},
year = {2008},
pages = {712 - 715},
address = {Wuhan, Hubei, China},
abstract = {A more highly automated graphic user interface (GUI) test model, which is based on the event-flow graph, is proposed. In the model, an automation tool is first used to carry out reverse engineering for a GUI test sample so as to obtain the event-flow graph. Then an improved ant colony optimization algorithm and a goal-directed searching approach are adopted to create GUI test sample cases. Moreover, a corresponding prototype system based on Microsoft UI automation framework is developed. &copy; 2008 IEEE.<br/>},
key = {Flow graphs},
keywords = {Ant colony optimization;Automation;Graphic methods;Graphical user interfaces;Reverse engineering;Software engineering;},
note = {Automation tests;Automation tools;Event-flow graph;Goal directed;Graphic user interface (GUI);Improved ant colony optimization;Prototype system;Test Modeling;},
URL = {http://dx.doi.org/10.1109/CSSE.2008.1336},
} 


@inproceedings{20101312803729,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Using TTCN-3 in performance test for service application},
journal = {Proceedings - 7th ACIS International Conference on Software Engineering Research, Management and Applications, SERA09},
author = {Shan, Min and Wang, Xianrong and Zhao, Lijun and Guo, Lili},
year = {2009},
pages = {253 - 258},
address = {Haikou, China},
abstract = {Service applications are applicable to provide services for requests of users from network. Due to the fact that they have to endure a big number of concurrent requests, the performance of service applications running under specific arrival rate of requests should be assessed. To measure the performance of a service application, Multi-party testing context is needed to simulate a number of concurrent requests and collect the responses. TTCN-3 is a test description language; it provides basic language elements for multi-party testing context that can be used in performance tests. This paper proposes a general approach of using TTCN-3 in multiparty performance testing service application. To this aim, a model of service application is presented, and performance testing framework for service applications is discussed. This testing framework is realized for a typical application by developing a reusable TTCN-3 abstract test suite. &copy; 2009 IEEE.<br/>},
key = {Application programs},
keywords = {Computer software reusability;Engineering research;Testing;},
note = {Concurrent requests;Description languages;Performance testing;Performance testing framework;Service applications;Testing framework;TTCN-3;Typical application;},
URL = {http://dx.doi.org/10.1109/SERA.2009.18},
} 


@inproceedings{20140617272628,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Comparison of hardware based and software based stress testing of memory IO interface},
journal = {Midwest Symposium on Circuits and Systems},
author = {Querbach, Bruce and Puligundla, Sudeep and Becerra, Daniel and Schoenborn, Zale T. and Chiang, Patrick},
year = {2013},
pages = {637 - 640},
issn = {15483746},
address = {Columbus, OH, United states},
abstract = {In post-silicon testing and validation of circuit functionality, an effective IO stress pattern can identify bugs quickly and provide adequate test coverage. A lot of work has been done to identify the right stress patterns specific to each IO interface. While some patterns can be generic enough to apply to all IOs, other patterns are interface topology specific. In addition to identifying the worst-case pattern, tradeoffs between test-time and test coverage must be made depending on the test goals. Pseudo Random Bit Stream (PRBS) generators are commonly used to generate test patterns because of the adequate frequency content in the PRBS patterns, the ease of implementation, and minimal gate count. This paper introduces an Advanced Pattern Generator and Checker (APGC) based on PRBS that retains all the aforementioned advantages. The APGC was implemented for a DDR memory interface where different LFSRs beat against each other spatially on neighboring IO lanes while rotating this form of aggressor-victim pattern in time. The results of the APGC stress patterns are compared to a form of advanced software-based learning algorithm based patterns that exhaustively search this complete parameter space. The comparison of APGC to software showed that the measured bit error rate (BER) plotted on a Q-scale of both methods is similar for the Receiver side. On the Transmitter side, APGC showed less eye opening than the software. In addition to the margin comparison, on the test execution side, APGC can speed up the test and validation execution time compared to the software by 32 to 2048 times depending on aggressor victim lane width of 8 to 64 lanes. &copy; 2013 IEEE.<br/>},
key = {Software testing},
keywords = {Bit error rate;Testing;},
note = {Advanced softwares;Aggressor-victim;Circuit functionality;Frequency contents;Parameter spaces;Pattern generator;Pseudo random bit stream;Worst case pattern;},
URL = {http://dx.doi.org/10.1109/MWSCAS.2013.6674729},
} 


@inproceedings{20181104908213,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {VST: A virtual stress testing framework for discovering bugs in SSD flash-translation layers},
journal = {IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD},
author = {Liu, Ren-Shuo and Chang, Yun-Sheng and Hung, Chih-Wen},
volume = {2017-November},
year = {2017},
pages = {283 - 290},
issn = {10923152},
address = {Irvine, CA, United states},
abstract = {Flash translation layers (FTLs) are the core embedded software (also known as firmware) of NAND flash-based solid-state drives (SSDs). The relentless pursuit of high-performance SSDs renders FTLs increasingly complex and intricate. Therefore, testing and validating FTLs are crucial and challenging tasks. Directly testing and validating FTLs on SSD hardware are common practices though, they are time-consuming and cumbersome because 1) the testing speed is limited by the hardware speed of SSDs and 2) just reproducing bugs can be challenging, let alone locating and root causing the bugs. This work presents virtual stress testing (VST), a simulation framework to enable executing SSD FTLs on PCs or servers against virtual SRAM, DRAM, and flash emulated by host-side main memory. FTL function calls, such as moving data from flash to DRAM, are served by the VST framework. Therefore, VST can test FTLs without SSD hardware requirements nor SSD speed limitations, and root causing bugs becomes manageable tasks. We apply VST to representative SSD design, OpenSSD, which is actively utilized and maintained by SSD and FTL communities. Experimental results show that VST can test FTLs at a speed up to 375 GB/s, which is several hundred times faster than directly testing FTLs on SSD hardware. Moreover, we successfully discover seven new FTL bugs in the OpenSSD design using VST, which is a solid evidence of VST's bug-discovering effectiveness.<br/> &copy; 2017 IEEE.},
key = {Flash-based SSDs},
keywords = {Computer aided design;Computer hardware;Computer software;Data storage equipment;Digital storage;Dynamic random access storage;Embedded software;Embedded systems;Firmware;Flash memory;Hardware;Integrated circuit design;Program debugging;Software testing;Static random access storage;},
note = {Common practices;Data storage systems;Disk drive;Flash translation layer;Function calls;Simulation framework;Software debugging;Systems simulation;},
URL = {http://dx.doi.org/10.1109/ICCAD.2017.8203790},
} 


@inproceedings{20133516681315,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The design of comprehensive performance test-bed of automobile electric power steering system},
journal = {Applied Mechanics and Materials},
author = {He, Ze Gang and Tai, Xiao Hong and Shen, Rong Wei and Han, Jiong Gang},
volume = {333-335},
year = {2013},
pages = {2301 - 2304},
issn = {16609336},
address = {Guilin, China},
abstract = {A kind of comprehensive performance test-bed of automobile electric power steering system was designed. IPC was applied to the main control system. Testing software was developed based on Visual Basic. AC servo system was assembled to respectively simulate input torque and load torque, the manual input torque can also be realized by operating steering wheel. The motion control card MPC08 is used to control the motion of Servo motor. Test data is collected by using multi-function data collection card. The lifting gears were assembled to install input/output shaft servo motor and EPS. Test results show that the test-bed can verify the control strategies and accurately detect the assist characteristic of EPS. &copy; (2013) Trans Tech Publications, Switzerland.},
key = {Software testing},
keywords = {AC generator motors;Servomechanisms;Visual BASIC;},
note = {AC servo systems;Assist characteristic;Automobile electric;Comprehensive performance;Data collection card;Designed;Electric power steering system;Motion control card;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.333-335.2301},
} 


@article{20072410652855,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research on the load testing system based on CORBA and its implementation},
journal = {Shanghai Ligong Daxue Xuebao/Journal of University of Shanghai for Science and Technology},
author = {Hu, Min and Yang, Wei-Min and Lin, Chun-Xiao},
volume = {29},
number = {2},
year = {2007},
pages = {189 - 194},
issn = {10076735},
abstract = {The load testing system based on CDRBA is described, and the constitution, structure, and module design of the system as well as some related key techniques are discussed. The application of the system will improve the efficiency of the test of the software under distributed calculating environment, so as to guarantee the software quality.},
} 


@inproceedings{20174804450705,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Comparative analysis of automated load testing tools: Apache JMeter, Microsoft Visual Studio (TFS), LoadRunner, Siege},
journal = {International Conference on Communication Technologies, ComTech 2017},
author = {Abbas, Rabiya and Sultan, Zainab and Bhatti, Shahid Nazir},
year = {2017},
pages = {39 - 44},
address = {Rawalpindi, Pakistan},
abstract = {Software testing is the process of testing, verifying and validating the user's requirements. During whole software development, testing is an ongoing process. Black Box, White Box testing and grey box testing are the three main types of software testing. In Black box testing, user doesn't know intrinsic logics and design of system. In white box testing, Tester knows the intrinsic logic of code. In Grey box testing, Tester has little bit knowledge about the internal structure, code and working of the system. It is commonly used in case of Integration testing. Load testing is the type of testing which helps us to analyze the performance of the system under heavy load or under Zero load. With the help of a automated load Testing Tools, we can do it in better way. The intention for writing this research is to carry out a comparison of four automated load testing tools i.e. Apache JMeter, HP LoadRunner, Microsoft Visual Studio (TFS), Siege based on certain criteria i.e. test scripts generation, plug-in support, result reports, application support and cost. The main focus is to study and analyze these load testing tools and identify which tool is best and more efficient [10]. We assume this comparative analysis can help in selecting the most appropriate tool and motivates the use of open source load testing tools.<br/> &copy; 2017 IEEE.},
key = {Black-box testing},
keywords = {Automation;Integration testing;Load testing;Open source software;Software design;Software engineering;Software testing;Studios;Testing;},
note = {Automated testing;Comparative analysis;Grey-box testing;Internal structure;Manual testing;Stress test;Testing tools;White-box testing;},
URL = {http://dx.doi.org/10.1109/COMTECH.2017.8065747},
} 


@inproceedings{20141817656858,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A performance testing and optimization tool for system developed by python language},
journal = {IET Conference Publications},
author = {Fan, Haojie and Mu, Yongmin},
volume = {2013},
number = {637 CP},
year = {2013},
pages = {24 - 27},
address = {Beijing, China},
abstract = {With a wide range of Python language in developing programs, More and more programmers choose to use the Python language for systems development, it gradually becomes scientific computing, web and games' Choice Awards. However, the performance of python is always a headache for developers. For reasonable selection of functions in base library, the usage of third-party plug-ins functions and methods, and the design of custom functions, the problem whether they are the best choices for general developers is difficult to make a positive answer. After the systems performance bottleneck occurs, it is particularly important to determine where to tune and how to tune. Through the analysis and dynamic tracking of source code, with the built-in method in Python, we can get information about the system to be optimized, included: functions, grammatical structures, running time of each function, the relationship between function calls etc. This information provides an effective basis for further optimization of the system. Experimental results show that the system optimized by the tool has a significantly improvement.<br/>},
key = {Computer software},
keywords = {Computer games;Computers;High level languages;},
note = {Developing projects;Grammatical structure;Optimization tools;Performance testing;Python;System optimizations;Systems development;Systems performance;},
URL = {http://dx.doi.org/10.1049/cp.2013.2086},
} 


@inproceedings{20103713223214,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Load testing and performance monitoring tools in use with AJAX based web applications},
journal = {MIPRO 2010 - 33rd International Convention on Information and Communication Technology, Electronics and Microelectronics, Proceedings},
author = {Krizanic, J. and Grguric, A. and Momondor, M. and Lazarevski, P.},
year = {2010},
pages = {428 - 434},
address = {Opatija, Croatia},
abstract = {In order to deliver quality assured software and avoid potential costs caused by unstable software, software testing is essential in software lifecycle. Load testing is one of the testing types with high importance. It is usually accompanied by performance monitoring of the hosting environment. In the case of web applications which are today widely used, one fact is obvious: most of web applications are public and used by vast number of users, which are making a considerable traffic load on hosting environments and web applications. Load testing and performance monitoring become facilitated with existing tools aimed for load testing and performance monitoring. In the paper we analyze and compare several existing tools which facilitate load testing and performance monitoring, in order to find the most appropriate tools by criteria such as ease of use, supported features, and license. Selected tools were put in action in the real environment, through several web applications. For the case study one of the web applications is used in order to introduce different capabilities of tools, including distributed testing, assembling of test scenario from previously recorded usage scenarios, security support, results analysis, monitoring of key parameters, and reporting and alerting about changes of these parameters.<br/>},
key = {Load testing},
keywords = {Microelectronics;Monitoring;Software testing;},
note = {AJAX;Distributed testing;Performance monitoring;Real environments;Security support;Software life cycles;Usage scenarios;WEB application;},
} 


@inproceedings{20171603585111,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Directed automated memory performance testing},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Chattopadhyay, Sudipta},
volume = {10206 LNCS},
year = {2017},
pages = {38 - 55},
issn = {03029743},
address = {Uppsala, Sweden},
abstract = {Understanding software non-functional properties (e.g. time, energy and security) requires deep understanding of the execution platform. The design of caches plays a crucial role in impacting software performance (for low latency of caches) and software security (for cache being used as a side channel). We present CATAPULT, a novel test generation framework to systematically explore the cache behaviour of an arbitrary program. Our framework leverages dynamic symbolic execution and satisfiability modulo theory (SMT) solvers for generating test inputs. We show the application of CATAPULT in testing timing-related properties and testing cache side-channel vulnerabilities in several open-source programs, including applications from OpenSSL and Linux GDK libraries. &copy; Springer-Verlag GmbH Germany 2017.},
key = {Software testing},
keywords = {Application programs;Computer operating systems;Open source software;},
note = {Dynamic symbolic executions;Execution platforms;Memory performance;Non functional properties;Open source projects;Satisfiability modulo Theories;Software performance;Software security;},
URL = {http://dx.doi.org/10.1007/978-3-662-54580-5_3},
} 


@inproceedings{20112714122900,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Model-based performance testing (NIER track)},
journal = {Proceedings - International Conference on Software Engineering},
author = {Barna, Cornel and Litoiu, Marin and Ghanbari, Hamoun},
year = {2011},
pages = {872 - 875},
issn = {02705257},
abstract = {In this paper, we present a method for performance testing of transactional systems. The methods models the system under test, finds the software and hardware bottlenecks and generate the workloads that saturate them. The framework is adaptive, the model and workloads are determined during the performance test execution by measuring the system performance, fitting a performance model and by analytically computing the number and mix of users that will saturate the bottlenecks. We model the software system using a two layers queuing model and use analytical techniques to find the workload mixes that change the bottlenecks in the system. Those workload mixes become stress vectors and initial starting points for the stress test cases. The rest of test cases are generated based on a feedback loop that drives the software system towards the worst case behaviour. &copy; 2011 ACM.<br/>},
key = {Software testing},
keywords = {Adaptive systems;Queueing theory;},
note = {Performance Model;Performance testing;Performance tests;Software and hardwares;Software systems;Stress Testing;System under test;Transactional systems;},
URL = {http://dx.doi.org/10.1145/1985793.1985930},
} 


@inproceedings{20120714762022,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Synthesizable verification IP to stress test system-on-chip emulation and prototyping platforms},
journal = {2011 International Symposium on Integrated Circuits, ISIC 2011},
author = {Shankar, Subramanian Shiva and Shankar, Jayaratnam Siva},
year = {2011},
pages = {609 - 612},
address = {SingaporeSingapore, Singapore},
abstract = {One of the biggest challenges today with Pre-silicon System-on-Chip verification is to stress out the SoC to uncover as many corner case design issues by injecting heavy real time data traffic into the system. The inherent efficiency and the performance of the Emulation and FPGA prototyping systems make them the ideal platforms to run these tests. A typical solution is to inject data traffic through protocol exercisers with proprietary hardware (vendor specific slow down solutions) which can bridge the emulated DUT with a real time device or use software API's with transaction based SCE-MI communication infrastructure. The need for a complex input output interface makes the former difficult to be used with all emulators / FPGA prototyping systems while SCE-MI communication infrastructure being protocol specific is a disadvantage. So, a synthesizable verification architecture compliant with SCE-MI 2.0 infrastructure through which the protocol specific traffic is injected through industry standard interfaces. i.e. PIPE (PCIe), UTMI (USB), MII (Ethernet) based on user configured stimuli has been designed and implemented. Being synthesizable, the verification environment can run in both emulation and prototyping platforms effectively stress testing the complete system. &copy; 2011 IEEE.<br/>},
key = {System-on-chip},
keywords = {Application specific integrated circuits;Design for testability;Network architecture;Pipe;Programmable logic controllers;},
note = {Communication infrastructure;FPGA prototyping;Industry standards;Prototyping platform;Prototyping systems;Stress Testing;UTMI;Verification environment;},
URL = {http://dx.doi.org/10.1109/ISICir.2011.6131936},
} 


@inproceedings{20124315601080,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling and analysis of CPU usage in safety-critical embedded systems to support stress testing},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Nejati, Shiva and Di Alesio, Stefano and Sabetzadeh, Mehrdad and Briand, Lionel},
volume = {7590 LNCS},
year = {2012},
pages = {759 - 775},
issn = {03029743},
address = {Innsbruck, Austria},
abstract = {Software safety certification needs to address non-functional constraints with safety implications, e.g., deadlines, throughput, and CPU and memory usage. In this paper, we focus on CPU usage constraints and provide a framework to support the derivation of test cases that maximize the chances of violating CPU usage requirements. We develop a conceptual model specifying the generic abstractions required for analyzing CPU usage and provide a mapping between these abstractions and UML/MARTE. Using this model, we formulate CPU usage analysis as a constraint optimization problem and provide an implementation of our approach in a state-of-the-art optimization tool. We report an application of our approach to a case study from the maritime and energy domain. Through this case study, we argue that our approach (1) can be applied with a practically reasonable overhead in an industrial setting, and (2) is effective for identifying test cases that maximize CPU usage. &copy; 2012 Springer-Verlag.<br/>},
key = {Safety engineering},
keywords = {Abstracting;Computer software selection and evaluation;Constrained optimization;Embedded systems;Safety testing;},
note = {Conceptual model;Constraint optimization problems;Industrial settings;Model and analysis;Optimization tools;Safety-critical embedded systems;Software safety;State of the art;},
URL = {http://dx.doi.org/10.1007/978-3-642-33666-9_48},
} 


@inproceedings{20164102888346,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A search based approach for stress-testing integrated circuits},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Eljuse, Basil and Walkinshaw, Neil},
volume = {9962 LNCS},
year = {2016},
pages = {80 - 95},
issn = {03029743},
address = {Raleigh, NC, United states},
abstract = {In order to reduce software complexity and be power efficient, hardware platforms are increasingly incorporating functionality that was traditionally administered at a software-level (such as cache management). This functionality is often complex, incorporating multiple processors along with a multitude of design parameters. Such devices can only be reliably tested at a &lsquo;system&rsquo; level, which presents various testing challenges; behaviour is often non-deterministic (from a software perspective), and finding suitable test sets to &lsquo;stress&rsquo; the system adequately is often an inefficient, manual activity that yields fixed test sets that can rarely be reused. In this paper we investigate this problem with respect to ARM&rsquo;s Cache Coherent Interconnect (CCI) Unit. We present an automated search-based testing approach that combines a parameterised testgeneration framework with the hill-climbing heuristic to find test sets that maximally &lsquo;stress&rsquo; the CCI by producingmuch larger numbers of data stall cycles than the corresponding manual test sets. &copy; Springer International Publishing AG 2016.},
key = {Software testing},
keywords = {Integrated circuit interconnects;Integrated circuits;Reconfigurable hardware;Software engineering;},
note = {Automated searches;Cache coherent interconnect;Cache management;Design parameters;Hardware platform;Multiple processors;Software complexity;Stress Testing;},
URL = {http://dx.doi.org/10.1007/978-3-319-47106-8_6},
} 


@inproceedings{20105013472951,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Practical end-to-end performance testing tool for high speed 3G-based networks},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Shinbo, Hiroyuki and Tagami, Atsushi and Ano, Shigehiro and Hasegawa, Toru and Suzuki, Kenji},
volume = {6435 LNCS},
year = {2010},
pages = {205 - 220},
issn = {03029743},
abstract = {High speed IP communication is a killer application for 3rd generation (3G) mobile systems. Thus 3G network operators should perform extensive tests to check whether expected end-to-end performances are provided to customers under various environments. An important objective of such tests is to check whether network nodes fulfill requirements to durations of processing packets because a long duration of such processing causes performance degradation. This requires testers (persons who do tests) to precisely know how long a packet is hold by various network nodes. Without any tool's help, this task is time-consuming and error prone. Thus we propose a multi-point packet header analysis tool which extracts and records packet headers with synchronized timestamps at multiple observation points. Such recorded packet headers enable testers to calculate such holding durations. The notable feature of this tool is that it is implemented on off-the shelf hardware platforms, i.e., lap-top personal computers. The key challenges of the implementation are precise clock synchronization without any special hardware and a sophisticated header extraction algorithm without any drop. &copy; 2010 IFIP International Federation for Information Processing.<br/>},
key = {3G mobile communication systems},
keywords = {Computer hardware;Hardware;Mechanical clocks;Personal computers;Software testing;Synchronization;Technology transfer;},
note = {Clock Synchronization;End-to-end performance;Header extraction;IP communications;Killer-application;Off-the-shelf hardwares;Packet header;Performance degradation;},
URL = {http://dx.doi.org/10.1007/978-3-642-16573-3_15},
} 


@inproceedings{20151600754435,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research on performance test method of lane departure warning system with PreScan},
journal = {Lecture Notes in Electrical Engineering},
author = {Zhang, Qiang and Chen, Daxing and Li, Yusheng and Li, Keqiang},
volume = {328},
year = {2015},
pages = {445 - 453},
issn = {18761100},
address = {Opole, Poland},
abstract = {A performance test method of lane departure warning system (LDWS) with PreScan software is proposed. In the process of virtual integration, the LDWS camera is located in the front of a computer monitor displaying virtual environment so as to capture pictures including lane marks and other information. Vehicle dynamic model and maneuver model run on a real-time computer, which represents a virtual vehicle and communicates with LDWS controller with CAN bus. The results show that the method will make it easier to create various test scenarios, which can save time and cost by transferring complex testing catalogues to the laboratory. The dangers presented in vehicle experiments in some critical scenarios can also be reduced. The repeatable model-based method makes it more convenient to locate the problem, which would make it easier to compare and assess the performance of LDWS produced by different companies objectively.<br/> &copy; Springer-Verlag Berlin Heidelberg 2015.},
key = {Software testing},
keywords = {Testing;Vehicles;Virtual reality;},
note = {Lane-departure-warning systems;Model-based method;Real time simulations;Real-time computer;Test scenario;Vehicle dynamic model;Vehicle experiment;Virtual integration;},
URL = {http://dx.doi.org/10.1007/978-3-662-45043-7_45},
} 


@article{1996363246637,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Deriving workloads for performance testing},
journal = {Software - Practice and Experience},
author = {Avritzer, Alberto and Weyuker, Elaine J.},
volume = {26},
number = {6},
year = {1996},
pages = {613 - 633},
issn = {00380644},
abstract = {An approach is presented to compare the performance of an existing production platform and a proposed replacement architecture. The traditional approach to such a comparison is to develop software for the proposed platform, build the new architecture, and collect performance measurements on both the existing system in production and the new system in the development environment. In this paper we propose a new way to design an application-independent workload for doing such a performance evaluation. We demonstrate the applicability of our approach by describing our experience using it to help an industrial organization determine whether or not a proposed architecture would be adequate to meet their organization's performance requirements.},
key = {Computer software},
keywords = {Computer architecture;Computer software portability;Performance;Software engineering;},
note = {Benchmark tuning;Performance testing;Workloads;},
URL = {http://dx.doi.org/10.1002/(SICI)1097-024X(199606)26:6<613::AID-SPE23>3.0.CO;2-5},
} 


@article{20130415938517,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Challenges on amazon cloud in load balancing, performance testing and upgrading},
journal = {Advances in Intelligent Systems and Computing},
author = {Shah, Himanshu and Wankhede, Paresh and Borkar, Anup},
volume = {203},
year = {2013},
pages = {31 - 40},
issn = {21945357},
abstract = {Web application hosting in a data centre is clouded with quite a few issues ranging from hardware provisioning, software installation and maintaining the servers. Traditional data-centre techniques need production grade hardware to test application's behavior/performance under expected peak load. This could be costly and procuring hardware could be very time consuming causing delays in software delivery. Cloud (Infrastructure-as-a- Service) can be an answer to this. Cloud Computing provides production grade server instances at very cheap rates. This whitepaper is divided into two sub parts: first part details out the typical web application setup on Amazon Web Services cloud (AWS) [Ref 2], challenges faced during the setup and resolution for the same, while the second part talks about the observations made during load testing using Apache JMeter performance testing tool on AWS cloud. Three different application setup topologies (single tier, two tier and three tier) are tested and findings and learning from it are discussed here. This whitepaper only highlights the pitfalls encountered and possible resolutions for each and is not a comment on performance of Amazon cloud. The whitepaper endeavors to find out the best architecture which would give maximum return on investment. &copy; Springer-Verlag Berlin Heidelberg 2013.},
key = {Computer hardware},
keywords = {Hardware;Profitability;Web services;},
note = {Amazon web services;Data centres;Peak load;Performance testing;Return on investments;Software installations;Test applications;WEB application;},
URL = {http://dx.doi.org/10.1007/978-3-642-35461-8},
} 


@article{20172803930321,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and performance testing of production performance determination system for boar},
journal = {Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering},
author = {Xiong, Benhai and Jiang, Linshu and Yang, Liang and Pan, Xiaohua},
volume = {33},
number = {9},
year = {2017},
pages = {174 - 179},
issn = {10026819},
abstract = {In order to monitor feeding behavior of sows and further attain the sow's precise feeding, an intelligent production performance testing system was designed in this study, which played functions in sows' automatic identification, body weight perception, automatic feeding data acquisition and data analysis simultaneously. The system was composed of electric ear tag identification module, precise feed flow control module, feed trough and boar weighing module, data communication and remote control module. The mechanical device system was constituted of feeding bin, brackets, railing and blocking apron. The mechanical device system was constituted of feeder's vertical wall, weighting platform, flapper, feed loading device, feed bin, control box, switch of discharge and ear tag recognizer. Electronic control systems included microprocessor (LPC1766, ARM Cortex-M3, Working temperature -40-105&#8451;, Operating voltage 2.0-3.6 V, flash 256 K, low power consumption et al.), RS232 reader port, data storage chip (the default storage capacity is 256 KB), circuit of watchdog, weighing circuit, exterior-drivers circuit, JTAG connector circuit and stabilivolt source circuit. Among above, the sensor used for pigs weighing was Delux ADS1232 which had 2 rate options, 10 times per second and 80 times per second, with high precision and large range of features. The performance testing experiment revealed that: 1) the system's precision meets the monitoring requirement of sow production performance. The discharge rate of feeder depended on the level of feed in stock bin, and the average amount of unloading feed was 93&plusmn;2 g at one time; the range of pig weighing was 0-200 kg with the precision error below 10 g, and the dynamic weighing error was below 0.5% of pig's weight. 2) The feeding behavior monitor for 40 gilts (25-60 kg) showed that the frequency of free feed intake was 10-12 times per day, the average feed time was 78 min, the feed conversion ratio was 2.33:1, and their weight gain was converged to the Gompertz curves (e.g. W<inf>t</inf>=172.1exp(-4.0187exp(-0.0122*t)), W<inf>t</inf>means body weight, kg; t means day old, day), the predicted decreasing daily weight gain of growing pigs by Gompertz curve occurred at day 111-117, with corresponding inflection point weight in the range of 63-64 kg. The observed and predicted results above could precisely determine the growth performance, indicating that the software systems and hardware devices could satisfy the requirement of growth performance determination in sows. 3) The wiper motor rather than early stepping motor was used in feed discharging control system, which reduced the cost of production. In addition, the combined wiper motor with cylindrical scraper structure decreased the discharge rate of feeder and improved the precision of unloading control system. 4) The core chip in control system was imported, multi-redundant, and protection systems were applied in circuit design. Multiply functional verification was adopted in software writing. The redundancy design in software and hardware eliminated the interference of power, electrical machine and electromagnetic wave, and improved the systems' reliability and stability. 5) The collected data could be saved or transferred, which facilitates the accumulation of pig production, data mining and sow breeding. &copy; 2017, Editorial Department of the Transactions of the Chinese Society of Agricultural Engineering. All right reserved.},
key = {Identification (control systems)},
keywords = {Anthropometry;Automation;Bins;Control systems;Data acquisition;Digital storage;Electric discharges;Electromagnetic waves;Feeding;Hardware;Integrated circuit manufacture;Mammals;Models;Printed circuit design;Redundancy;Software reliability;Software testing;Unloading;Verification;Weighing;},
note = {Automatic identification;Boar;Data collection;Electronic control systems;Functional verification;Performance measurements;Production performance;Reliability and stability;},
URL = {http://dx.doi.org/10.11975/j.issn.1002-6819.2017.09.022},
} 


@inproceedings{1998094000254,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Simplifying motor performance testing in the production environment},
journal = {Proceedings of the Electrical/Electronics Insulation Conference},
author = {Leonard, Donald C.},
year = {1997},
pages = {185 - 190},
issn = {03622479},
address = {Rosemont, IL, USA},
abstract = {The objective of this paper is to illustrate how performance test systems on the factory floor can be enhanced by utilizing the power and speed of integral computer hardware and software to automate and simplify tasks typically performed in the production environment. The first part of this paper discusses why the test system is needed to perform additional tasks. The second section defines the relationships between various departments within the organization, and the test system. The third section discusses the benefits of integrating additional functions into the test system. The final sections of the paper discusses incorporating artificial intelligence and networking to simplify tasks associated with the production environment.},
key = {Electric motors},
keywords = {Artificial intelligence;Automatic testing;Computer hardware;Computer integrated manufacturing;Computer software;Decision making;Factory automation;Performance;},
note = {Factory floor;Performance testing;},
} 


@inproceedings{20140917393351,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Static analysis driven cache performance testing},
journal = {Proceedings - Real-Time Systems Symposium},
author = {Banerjee, Abhijeet and Chattopadhyay, Sudipta and Roychoudhury, Abhik},
year = {2013},
pages = {319 - 329},
issn = {10528725},
address = {Vancouver, BC, Canada},
abstract = {Real-time, embedded software are constrained by several non-functional requirements, such as timing. With the ever increasing performance gap between the processor and the main memory, the performance of memory subsystems often pose a significant bottleneck in achieving the desired performance for a real-time, embedded software. Cache memory plays a key role in reducing the performance gap between a processor and main memory. Therefore, analyzing the cache behaviour of a program is critical for validating the performance of an embedded software. In this paper, we propose a novel approach to automatically generate test inputs that expose the cache performance issues to the developer. Each such test scenario points to the specific parts of a program that exhibit anomalous cache behaviour along with a set of test inputs that lead to such undesirable cache behaviour. We build a framework that leverages the concepts of both static cache analysis and dynamic test generation to systematically compute the cache-performance stressing test inputs. Our framework computes a test-suite which does not contain any false positives. This means that each element in the test-suite points to a real cache performance issue. Moreover, our test generation framework provides an assurance of the test coverage via a well-formed coverage metric. We have implemented our entire framework using Chronos worst case execution time (WCET) analyzer and LLVM compiler infrastructure. Several experiments suggest that our test generation framework quickly converges towards generating cache-performance stressing test cases. We also show the application of our generated test-suite in design space exploration and cache performance optimization. &copy; 2013 IEEE.<br/>},
key = {Software testing},
keywords = {Cache memory;Embedded software;Interactive computer systems;Program compilers;Real time systems;Static analysis;},
note = {Cache performance;Design space exploration;Memory subsystems;Non-functional requirements;Performance testing;Static cache analysis;Test generations;Worst-case execution time;},
URL = {http://dx.doi.org/10.1109/RTSS.2013.39},
} 



