@INPROCEEDINGS{8070136, 
author={X. Xie and Z. Yang and J. Yu and W. Zhang}, 
booktitle={2016 5th International Conference on Computer Science and Network Technology (ICCSNT)}, 
title={Design and implementation of bank financial business automation testing framework based on QTP}, 
year={2016}, 
volume={}, 
number={}, 
pages={143-147}, 
abstract={The current software testing in the aspects of industrial benefits gradually causes the attention of the domestic financial bank. The innovation of software technology, the increase of software scale and the shortened developing period make the traditional manual testing meeting enormous challenges, while the development of automated testing technology has promoted the progress of the software testing industry. Because of the particularity of financial and banking services, the bank is under an obligation to ensure the quality and reliability of software. Therefore it's vital to test the software. In specific practice, although the powerful third-party testing tools can be used as a solution, it is hard to rely on certain tool to implement automated testing, hence a framework of automated test is required to be introduced for testing, which intends to handle high efficiency and high-quality testing for software automation. This paper proposes a kind of software automation testing framework based on QTP, mainly targeting on the core of the bank, credit, online banking to test the function of the three major operations. The framework is a secondary development based on QTP and mainly for regression testing of software, which integrates techniques including object recognition, data-driven, and keyword-driven technology, checkpoint technology, to proceed business-level testing. The paper expatiated on four issues, which were the test system design, the test standardization, the testing framework design and the testing of the implementation. The practical application shows that the framework can improve the operational efficiency, reduce the test cost, and guarantee the smooth progress of the software automation testing.}, 
keywords={bank data processing;object recognition;program testing;software quality;software reliability;QTP;automated testing technology;bank financial business automation testing framework;banking service;business-level testing;domestic financial bank;financial services;keyword-driven technology;object recognition;online banking;regression testing;software automation testing;software quality;software reliability;software scale;software technology;software testing industry;test cost;test standardization;test system design;testing framework design;third-party testing tools;Automation;Libraries;Object recognition;Software;Standardization;Testing;Tools;QTP automated testing tool;software testing;test automation framework}, 
doi={10.1109/ICCSNT.2016.8070136}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{623350, 
author={D. C. Roberts and D. A. Grossman and O. Frieder and R. Bernstein and E. Bisfiop}, 
booktitle={Proceedings of Sixth International Conference on Computer Communications and Networks}, 
title={Performance testing of communication protocols for three-tier computing: results for ICA and X window protocols}, 
year={1997}, 
volume={}, 
number={}, 
pages={450-455}, 
abstract={We present the results of performance tests to compare two protocols for three-tier computing using the Windows NT operating system. Three-tier computing features a data server for stored databases (Tier 1), an application server that runs applications (Tier 2), and a simple client program that runs on desktop machines that presents the user interface (Tier 3). Three protocols are available to communicate between Tier 2 and 3: intelligence computer architecture (ICA) with and without data compression, and X Window. We measured the performance of the three protocols in a multi-user environment in which we simulated the workload imposed by typical users. We found that, for Microsoft Office 97 and Lotus Notes applications, the X Window protocol uses approximately twice the network bandwidth of ICA, without compression. We also found that compressed ICA generates roughly one third less network traffic than uncompressed ICA at a cost of 20% of additional processor utilization}, 
keywords={client-server systems;computer architecture;data compression;network servers;performance evaluation;program testing;protocols;testing;ICA protocols;Lotus Notes applications;Microsoft Office 97;Tier 1;Tier 2;Tier 3;Windows NT operating system;X window protocols;application server;client program;communication protocols;data compression;data server;desktop machines;intelligence computer architecture;multi-user environment;network bandwidth;network traffic;performance testing;stored databases;three-tier computing;user interface;Application software;Computer architecture;Computer interfaces;Independent component analysis;Machine intelligence;Operating systems;Protocols;Spatial databases;System testing;User interfaces}, 
doi={10.1109/ICCCN.1997.623350}, 
ISSN={1095-2055}, 
month={Sep},}
@INPROCEEDINGS{7359004, 
author={S. Kiran and A. Mohapatra and R. Swamy}, 
booktitle={2015 International Symposium on Technology Management and Emerging Technologies (ISTMET)}, 
title={Experiences in performance testing of web applications with Unified Authentication platform using Jmeter}, 
year={2015}, 
volume={}, 
number={}, 
pages={74-78}, 
abstract={Unified Authentication platform is a Single sign-on (SSO) mechanism which is integrated into Web applications to remove the necessity for multiple application-specific login credentials. Unified Authentication platform (UAP) is a unique platform developed by MIMOS with capability to support multiple authentication mechanism and can be integrated to any Web application to provide Single Sign On (SSO) solution. Performance testing of such web applications using UAP poses some unique challenges because the Jmeter script does not capture all the dynamic values, such as SAML Request, Relay State, Signature Algorithm, Authorization State, Cookie Time, Persistent ID (PID), JSession ID and Shibboleth, generated using single sign-on mechanism of Unified Authentication Platform. This paper explains some of the challenges & experiences to identify an appropriate solution for conducting performance testing on such web application.}, 
keywords={Internet;authorisation;program testing;software performance evaluation;Jmeter script;MIMOS;SSO mechanism;UAP;Web applications;performance testing;single sign-on mechanism;unified authentication platform;Authentication;Browsers;Computer architecture;Generators;MIMO;Servers;Testing;Jmeter;Performance Testing;Single Sign-On;Unified Authentication Platform}, 
doi={10.1109/ISTMET.2015.7359004}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{1602358, 
author={D. Draheim and J. Grundy and J. Hosking and C. Lutteroth and G. Weber}, 
booktitle={Conference on Software Maintenance and Reengineering (CSMR'06)}, 
title={Realistic load testing of Web applications}, 
year={2006}, 
volume={}, 
number={}, 
pages={11 pp.-70}, 
abstract={We present a new approach for performing load testing of Web applications by simulating realistic user behaviour with stochastic form-oriented analysis models. Realism in the simulation of user behaviour is necessary in order to achieve valid testing results. In contrast to many other user models, Web site navigation and time delay are modelled stochastically. The models can be constructed from sample data and can take into account effects of session history on user behaviour and the existence of different categories of users. The approach is implemented in an existing architecture modelling and performance evaluation tool and is integrated with existing methods for forward and reverse engineering}, 
keywords={Web sites;delays;human factors;resource allocation;reverse engineering;software architecture;software performance evaluation;stochastic processes;Web application;Web site navigation;architecture modelling;forward engineering;load testing;performance evaluation tool;reverse engineering;stochastic form-oriented analysis models;time delay;user behaviour;Analytical models;Application software;Computational modeling;Computer science;Delay effects;Navigation;Performance evaluation;Software testing;Software tools;Stochastic processes}, 
doi={10.1109/CSMR.2006.43}, 
ISSN={1534-5351}, 
month={March},}
@INPROCEEDINGS{6274032, 
author={M. Kamra and R. Manna}, 
booktitle={2012 IEEE Eighth World Congress on Services}, 
title={Performance of Cloud-Based Scalability and Load with an Automation Testing Tool in Virtual World}, 
year={2012}, 
volume={}, 
number={}, 
pages={57-64}, 
abstract={The development in cloud computing provides limitless capacity which provides opportunity to evaluate an application performance based on its nature to scale. This paper aims at the analysis of Performance using the Google App Engine(cloud computing paradigm). Virtual Office application is chosen as example to perform experiment of testing the scalability in turn maintaining the performance. An Automation Testing Tool - Test Harness has been used to perform the scale testing of the application while being deployed on the cloud. Results have seen shown in the form of request type and response times(Average time taken/request). Taken into account the consideration that when the application load goes up the Google Cloud expands(increases instance hours) without affecting the running application.}, 
keywords={Web sites;cloud computing;program testing;software performance evaluation;Google App Engine;application performance;automation testing tool;cloud computing;cloud-based scalability;scale testing;test harness;virtual office application;virtual world;Automation;Cloud computing;Google;Scalability;Servers;Teleworking;Testing;API;CPU;GAE;QPS}, 
doi={10.1109/SERVICES.2012.54}, 
ISSN={2378-3818}, 
month={June},}
@INPROCEEDINGS{4669518, 
author={L. Eros and T. Csondes}, 
booktitle={2008 16th International Conference on Software, Telecommunications and Computer Networks}, 
title={Test component assignment in a performance testing environment}, 
year={2008}, 
volume={}, 
number={}, 
pages={399-403}, 
abstract={In this paper we are going to introduce the problem of assigning test components to hosts of a performance (or load) testing environment, and its two novel solutions. When testing the performance of a device (system under test-SUT), the test environment simulates the latter real-life environment of the SUT. The number of hosts in the test environment is however way less than the number of hosts the SUT will have to serve in its real-life environment. Thus, real-life hosts are simulated by software entities, the so-called test components that have to be optimally assigned and then executed on the hosts of the test environment (testing hosts). Our goal is to emulate all the test components by as few testing hosts as possible, that is, to maximize the load on the testing hosts. The problem to be solved is a special case of the task assignment problem for which many solutions have been developed. Our solutions presented in this paper are, however, optimized for distributing load testing traffic. Thus the possibilities and restrictions we had to take into account are very different from those of the classical task assignment case. One of the solutions we present extends existing bin packing heuristics, while the other one solves a series of integer linear programs to make the assignments. Our simulations have shown that by applying our solutions, the average load level on testing hosts can be significantly increased.}, 
keywords={automatic test software;bin packing;digital simulation;integer programming;linear programming;SUT;bin packing heuristic;integer linear program;load testing traffic distribution;performance testing environment;real-life host simulation;software entity;system under test;test component assignment;Emulation;Environmental economics;Heuristic algorithms;Informatics;Software testing;Stress;System testing;Telecommunication traffic;Traffic control}, 
doi={10.1109/SOFTCOM.2008.4669518}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{4636415, 
author={Jingfan Tang and Xiaohua Cao and A. Ma}, 
booktitle={2008 IEEE International Conference on Automation and Logistics}, 
title={Towards adaptive framework of keyword driven automation testing}, 
year={2008}, 
volume={}, 
number={}, 
pages={1631-1636}, 
abstract={This paper presents an adaptive framework of keyword-driven automation testing to support the conversion of the keyword-based test cases into different kinds of test scripts automatically to be executed by different test applications under different test environments (such as GUI environment, database environment, etc.). XML is used to describe the keyword-based commands for the test case. An engine is provided in this framework to parse the XML file and dispatch the command sequences to the different test drivers according to the driver type pre-defined in the command. The test driver is responsible for dispatching the commands to the corresponding test applications to generate the test scripts automatically according to the keywords in the commands. The test scripts will be executed by the test applications on the system-under-test under different test environments. All the test results will be recorded into a log repository for generating all kinds of the test reports.}, 
keywords={XML;program compilers;program testing;XML file parsing;adaptive framework;automation engine layer;keyword driven automation testing;keyword-based command sequence;keyword-based test case conversion;log repository;test driver layer;test execution layer;test report;test script;Application software;Automatic testing;Databases;Educational institutions;Graphical user interfaces;Logistics;Robotics and automation;Software testing;System testing;XML;Keyword Driven;adaptive;automation testing}, 
doi={10.1109/ICAL.2008.4636415}, 
ISSN={2161-8151}, 
month={Sept},}
@INPROCEEDINGS{6253496, 
author={D. Jayasinghe and G. Swint and S. Malkowski and J. Li and Q. Wang and J. Park and C. Pu}, 
booktitle={2012 IEEE Fifth International Conference on Cloud Computing}, 
title={Expertus: A Generator Approach to Automate Performance Testing in IaaS Clouds}, 
year={2012}, 
volume={}, 
number={}, 
pages={115-122}, 
abstract={Cloud computing is an emerging technology paradigm that revolutionizes the computing landscape by providing on-demand delivery of software, platform, and infrastructure over the Internet. Yet, architecting, deploying, and configuring enterprise applications to run well on modern clouds remains a challenge due to associated complexities and non-trivial implications. The natural and presumably unbiased approach to these questions is thorough testing before moving applications to production settings. However, thorough testing of enterprise applications on modern clouds is cumbersome and error-prone due to a large number of relevant scenarios and difficulties in testing process. We address some of these challenges through Expertus---a flexible code generation framework for automated performance testing of distributed applications in Infrastructure as a Service (IaaS) clouds. Expertus uses a multi-pass compiler approach and leverages template-driven code generation to modularly incorporate different software applications on IaaS clouds. Expertus automatically handles complex configuration dependencies of software applications and significantly reduces human errors associated with manual approaches for software configuration and testing. To date, Expertus has been used to study three distributed applications on five IaaS clouds with over 10,000 different hardware, software, and virtualization configurations. The flexibility and extensibility of Expertus and our own experience on using it shows that new clouds, applications, and software packages can easily be incorporated.}, 
keywords={cloud computing;program compilers;program testing;software packages;Expertus;IaaS clouds;Infrastructure as a Service;Internet;automated performance testing;cloud computing;distributed applications;enterprise applications;generator approach;multipass compiler approach;software packages;template-driven code generation;Automation;Cloud computing;Clouds;Testing;Weaving;XML;Aspect;Automation;Clouds;Code Generation;Datacenter;EC2;Emulab;IaaS;Multi-Tier;Open Cirrus;Performance;Scalability;Template;Testing}, 
doi={10.1109/CLOUD.2012.98}, 
ISSN={2159-6182}, 
month={June},}
@INPROCEEDINGS{8203790, 
author={R. S. Liu and Y. S. Chang and C. W. Hung}, 
booktitle={2017 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)}, 
title={VST: A virtual stress testing framework for discovering bugs in SSD flash-translation layers}, 
year={2017}, 
volume={}, 
number={}, 
pages={283-290}, 
abstract={Flash translation layers (FTLs) are the core embedded software (also known as firmware) of NAND flash-based solid-state drives (SSDs). The relentless pursuit of high-performance SSDs renders FTLs increasingly complex and intricate. Therefore, testing and validating FTLs are crucial and challenging tasks. Directly testing and validating FTLs on SSD hardware are common practices though, they are time-consuming and cumbersome because 1) the testing speed is limited by the hardware speed of SSDs and 2) just reproducing bugs can be challenging, let alone locating and root causing the bugs. This work presents virtual stress testing (VST), a simulation framework to enable executing SSD FTLs on PCs or servers against virtual SRAM, DRAM, and flash emulated by host-side main memory. FTL function calls, such as moving data from flash to DRAM, are served by the VST framework. Therefore, VST can test FTLs without SSD hardware requirements nor SSD speed limitations, and root causing bugs becomes manageable tasks. We apply VST to representative SSD design, OpenSSD, which is actively utilized and maintained by SSD and FTL communities. Experimental results show that VST can test FTLs at a speed up to 375 GB/s, which is several hundred times faster than directly testing FTLs on SSD hardware. Moreover, we successfully discover seven new FTL bugs in the OpenSSD design using VST, which is a solid evidence of VST's bug-discovering effectiveness.}, 
keywords={DRAM chips;NAND circuits;SRAM chips;embedded systems;flash memories;DRAM;FTL bugs;NAND flash-based solid-state drives;SSD FTLs;SSD flash-translation layers;VST framework;byte rate 375.0 GByte/s;core embedded software;firmware;flash translation layers;hardware speed;high-performance SSD;host-side main memory;representative SSD design;simulation framework;testing speed;virtual SRAM;virtual stress testing;Computer bugs;Hardware;Random access memory;Servers;Software;Stress;Testing;Embedded software;data storage systems;disk drives;flash memories;software debugging;software testing;systems simulation}, 
doi={10.1109/ICCAD.2017.8203790}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{8334473, 
author={B. Haarmann and C. Martens and H. Petzka and G. Napolitano}, 
booktitle={2018 IEEE 12th International Conference on Semantic Computing (ICSC)}, 
title={A Mighty Dataset for Stress-Testing Question Answering Systems}, 
year={2018}, 
volume={}, 
number={}, 
pages={278-281}, 
abstract={The general goal of semantic question answering systems is to provide correct answers to natural language queries, given a number of structured datasets. The increasing broad deployment of question answering (QA) systems in everyday life requires a comparable and reliable rating of how well QA systems perform and how scalable they are. In order to achieve this, we developed a massive dataset of more than 2 million natural language questions and their SPARQL queries for the DBpedia dataset. We combined natural language processing and linked open data to automatically generate this large amount of valid question-query pairs. Our aim is to assist the benchmarking or scoring of QA systems in terms of answering questions in a range of languages, retrieving answers from heterogeneous sources or answering massive amounts of questions within a limited time. This dataset represents an ideal choice for stress-testing systems' scalability, speed and correctness. As such it has already been included into the Large-scale QA task of the Question Answering Over Linked Data (QALD) Challenge and the HOBBIT project Question Answering Benchmark.}, 
keywords={Linked Data;natural language processing;query processing;question answering (information retrieval);DBpedia dataset;HOBBIT project Question Answering Benchmark;QA systems;SPARQL queries;combined natural language processing;natural language questions;semantic question answering systems;stress-testing Question Answering systems;stress-testing systems;valid question-query pairs;Benchmark testing;Knowledge discovery;Linked data;Natural languages;Resource description framework;Standards;Task analysis;Benchmark;DBpedia;Question-Answering;Semantics}, 
doi={10.1109/ICSC.2018.00054}, 
ISSN={}, 
month={Jan},}
@INPROCEEDINGS{5562998, 
author={B. Ma and B. Chen and X. Bai and J. Huang}, 
booktitle={2010 10th International Conference on Quality Software}, 
title={Design of BDI Agent for Adaptive Performance Testing of Web Services}, 
year={2010}, 
volume={}, 
number={}, 
pages={435-440}, 
abstract={As services are dynamic discovered and bound in the open Internet environment, testing has to be exercised continuously and online to verify and validate the continuous changes and to ensure the quality of the integrated service-based system. During this process, testing strategies have to be adapted in accordance to the changes in the environment and target systems. Software agents are characterized by context awareness, autonomous decision making and social collaboration capabilities. The paper introduces the design of BDI (Believe-Decision-Intention) agents to facilitate adaptive performance testing of Web Services. The BDI model specifies the necessary test knowledge, test goal and action plan to carry out test and adaptive schedule. Performance testing is defined as a scheduling problem to select the workload and test cases in order to achieve the goal of performance abnormal detection. A two-level control architecture is built. At the TR (Test Runner) level, the BDI agents control the workload of concurrent requests. At the TC (Test Coordinator) level, the BDI agents control the complexity of test cases. Agents communicate and collaborate with each other to share knowledge and test plan. The paper introduces the design of the BDI model, the adaptation rules and the control architecture. Case study is exercised to illustrate the adaptive testing process based on the design of BDI agents.}, 
keywords={Adaptation model;Collaboration;Complexity theory;Computer architecture;Load modeling;Testing;Time factors;BDI agent;Web Services;adaptive testing;performance testing}, 
doi={10.1109/QSIC.2010.69}, 
ISSN={1550-6002}, 
month={July},}
@INPROCEEDINGS{6425016, 
author={X. Yang and Z. Chen}, 
booktitle={2012 International Conference on Image Analysis and Signal Processing}, 
title={An improved wavelet denoising method used in electrical throttle performance testing}, 
year={2012}, 
volume={}, 
number={}, 
pages={1-4}, 
abstract={In this paper, an electrical throttle performance test system is designed mainly focusing on its potentiometer and function tests. An improved denoising algorithm based upon the wavelet transform is proposed in non-stationary testing environment. In the experiment, the virtual instrument is used to call the denoising module and processes the acquiring signals. It is proved that its effect is obviously more excellent than conventional algorithms. This test system is then used in actual assembly line. Good parts can be sorted out efficiently and the quality of assembly line is improved.}, 
keywords={assembling;automotive engineering;fuel systems;mechanical testing;signal denoising;wavelet transforms;assembly line;electrical throttle performance testing;nonstationary testing environment;virtual instrument;wavelet denoising;wavelet transform;Algorithm design and analysis;Educational institutions;Noise;Noise reduction;Testing;Wavelet transforms;electrical throttle;performance test;wavelet denoising}, 
doi={10.1109/IASP.2012.6425016}, 
ISSN={2156-0110}, 
month={Nov},}
@INPROCEEDINGS{7574810, 
author={A. Shen and M. Kuzlu and M. Pipattanasomporn and S. Rahman and L. Chen}, 
booktitle={2016 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)}, 
title={A performance testing method for embedded software platforms}, 
year={2016}, 
volume={}, 
number={}, 
pages={135-140}, 
abstract={Performance testing is an important process in the embedded software development. It can detect bugs, help improve software quality and test the system reliability. The objective of this paper is to propose a performance testing method for embedded software platforms. A case study to evaluate the applicability of the proposed method is discussed. Performance tests are performed on three different platforms and test results are compared.}, 
keywords={embedded systems;program debugging;program testing;software performance evaluation;software quality;software reliability;bug detection;embedded software development;embedded software platforms;performance testing;software quality;system reliability;Embedded software;Hardware;Monitoring;Software performance;Testing;Thermostats;Performance testing;embedded software;multi-agent;open source}, 
doi={10.1109/CYBER.2016.7574810}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{7280280, 
author={T. Arnold and A. C. Adewole and R. Tzoneva}, 
booktitle={2015 International Conference on the Industrial and Commercial Use of Energy (ICUE)}, 
title={Performance testing and assessment of multi-vendor protection schemes using proprietary protocols and the IEC 61850 standard}, 
year={2015}, 
volume={}, 
number={}, 
pages={284-290}, 
abstract={The International Electrotechnical Commission (IEC) developed a global standard for power system communication permitting Intelligent Electronic Devices (IEDs) to interoperate within the smart grid environment. However, in order for electric power utility companies to adopt IEC 61850 standard-based devices with confidence, it is necessary to carry out performance tests and evaluations to allay their fears. This paper presents an evaluation of the performance of IEC 61850 standard-based devices with respect to their speed, security, and dependability of operation. The study was implemented using multi-vendor IEDs configured for a Permissive Overreaching Transfer Trip (POTT) communication scheme with conventional proprietary protocols and the IEC 61850 Generic Object Oriented Substation Events (GOOSE) messages based on hardware-in-the-loop simulations with the Real-Time Digital Simulator (RTDS). RSCAD software was used in the modelling of a typical power system network protected by two multi-vendor distance protection IEDs using a lab-scale testbed designed and implemented for the investigations relating to this paper. Real-time simulations for various fault locations and fault resistances were carried out. The results obtained demonstrated the dependability and security of the operation of the IEC 61850-based POTT communication scheme with faster operating times compared with the conventional POTT communication scheme based on vendor-specific proprietary protocols. This paper could serve as a reference to electric power utility companies as they adopt IEC 61850 standard-based devices in their networks.}, 
keywords={IEC standards;electricity supply industry;fault location;power engineering computing;power system faults;protocols;smart power grids;substation automation;substation protection;GOOSE messages;IEC 61850 generic object oriented substation events;IEC 61850 standard-based devices;International Electrotechnical Commission;POTT communication scheme;RSCAD software;RTDS;electric power utility companies;fault locations;fault resistances;hardware-in-the-loop simulations;intelligent electronic devices;multïvendor distance protection IED;multivendor IED;multivendor protection schemes;permissive overreaching transfer trip;power system communication;power system network;real-time digital simulator;smart grid environment;vendor-specific proprietary protocols;Delays;IEC Standards;Impedance;Protocols;Distance protection;GOOSE;IEC 61850;Intelligent Electronic Devices;POTT;real-time digital simulation}, 
doi={10.1109/ICUE.2015.7280280}, 
ISSN={2166-0581}, 
month={Aug},}
@INPROCEEDINGS{8304099, 
author={M. A. Putri and H. N. Hadi and F. Ramdani}, 
booktitle={2017 International Conference on Sustainable Information Engineering and Technology (SIET)}, 
title={Performance testing analysis on web application: Study case student admission web system}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={Websites usage for universities selection entrance (admission) are most visited websites in daily activity, thus its performance is critical. The ability of web applications either to control or to process users' requests determines its reliability. Furthermore, those websites which process students admission in Universitas Brawijaya and Politeknik Negeri Malang certainly engage massive volume of data and information that requires the highest level of reliability. Therefore, there is absolutely needed appropriate testing performances to measure the level of a certain application based on reliability rate. This measurement is used to determine responses, throughput, capability, and system scalability upon workload given. This research has a contribution to present testing performance concepts, goals, targets, types, and tools of Apache JMeter which is engaged for web assessment including detects mistake and error that relates to application performance and helps to improve the level of application performance as expected.}, 
keywords={Internet;Web services;Web sites;educational institutions;Politeknik Negeri Malang;Universitas Brawijaya;application performance;appropriate testing performances;daily activity;performance testing analysis;process students admission;reliability rate;student admission web system;system scalability;testing performance concepts;universities selection entrance;users;web application;websites usage;Computer science;Reliability;Servers;Software;Stress;Testing;Tools;jmeter;performance testing;testing;website}, 
doi={10.1109/SIET.2017.8304099}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{8065747, 
author={R. Abbas and Z. Sultan and S. N. Bhatti}, 
booktitle={2017 International Conference on Communication Technologies (ComTech)}, 
title={Comparative analysis of automated load testing tools: Apache JMeter, Microsoft Visual Studio (TFS), LoadRunner, Siege}, 
year={2017}, 
volume={}, 
number={}, 
pages={39-44}, 
abstract={Software testing is the process of testing, verifying and validating the user's requirements. During whole software development, testing is an ongoing process. Black Box, White Box testing and grey box testing are the three main types of software testing. In Black box testing, user doesn't know intrinsic logics and design of system. In white box testing, Tester knows the intrinsic logic of code. In Grey box testing, Tester has little bit knowledge about the internal structure, code and working of the system. It is commonly used in case of Integration testing. Load testing is the type of testing which helps us to analyze the performance of the system under heavy load or under Zero load. With the help of a automated load Testing Tools, we can do it in better way. The intention for writing this research is to carry out a comparison of four automated load testing tools i.e. Apache JMeter, HP LoadRunner, Microsoft Visual Studio (TFS), Siege based on certain criteria i.e. test scripts generation, plug-in support, result reports, application support and cost. The main focus is to study and analyze these load testing tools and identify which tool is best and more efficient [10]. We assume this comparative analysis can help in selecting the most appropriate tool and motivates the use of open source load testing tools.}, 
keywords={program testing;public domain software;software tools;Black box testing;Integration testing;LoadRunner;Microsoft Visual Studio;Siege;TFS;Zero load;apache JMeter;application support;automated load testing tools;comparative analysis;grey box testing;heavy load;intrinsic logic;open source load testing tools;plug-in support;result reports;software testing;test scripts generation;white box testing;Automation;Manuals;Software;Software testing;Tools;Visualization;Testing;automated testing;load testing;manual testing;stress test;testing tools}, 
doi={10.1109/COMTECH.2017.8065747}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{6419531, 
author={Đ. Miljković and S. Bojić and M. Đukić and M. Jovanović}, 
booktitle={2012 20th Telecommunications Forum (TELFOR)}, 
title={Automation testing of Graphical User Interface}, 
year={2012}, 
volume={}, 
number={}, 
pages={1609-1612}, 
abstract={In this paper is explained one solution for automation of testing Graphical User Interface. The paper gives a description of the problem, the concept of a solution and a description of the implementation of such a solution in order to confirm the above concept. Validation of the implementation was carried out on graphical tool for the development of software for audio target platform.}, 
keywords={graphical user interfaces;program testing;software engineering;audio target platform;automation testing;graphical tool;graphical user interface;software development;Automation;Browsers;Electronic mail;Graphical user interfaces;Manuals;Testing;XML;GUI;GUIPlayer;Lua;XML;ispitivanje}, 
doi={10.1109/TELFOR.2012.6419531}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{8011376, 
author={G. Meyer}, 
booktitle={PCIM Asia 2017; International Exhibition and Conference for Power Electronics, Intelligent Motion, Renewable Energy and Energy Management}, 
title={Enhanced Power Electronics System for High-Performance Testing of Motor Control Units in a Power HIL Environment}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={Hardware-in-the-loop (HIL) simulation is an established test method for analyzing motor control units (MCUs). For highly integrated drive controllers, the controller and the power electronics must be tested at the electric power level (emulation). Using this method requires specific power electronics for emulation. This paper introduces a special hardware solution that is based on an interleaved switching, three-level neutral-point-clamped (NPC) inverter and a sophisticated model-predictive control algorithm to establish a high-bandwidth electronic load for testing electronic power systems.}, 
keywords={}, 
doi={}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{8122351, 
author={D. Shang and X. Zhang and J. Han and X. Xu}, 
booktitle={2017 IEEE 3rd Information Technology and Mechatronics Engineering Conference (ITOEC)}, 
title={MultiModal-database-XJTU: An available database for biometrics recognition with its performance testing}, 
year={2017}, 
volume={}, 
number={}, 
pages={521-526}, 
abstract={The current need for large multimodal databases to evaluate automatic biometrics recognition systems has motivated the development of the XJTU multimodal database. The main purpose has been to consider a large scale population, with statistical significance, in a real multimodal procedure, and including several sources of variability that can be found in real environments. The acquisition process, contents and availability of the single-session baseline corpus are fully described. Some experiments showing consistency of data through the different acquisition sites and assessing data quality are also presented. MultiModal-Database-XJTU, a new multimodal database, is presented. The database consists of fingerprint images acquired with sensor, frontal face images from a camera, iris images from a Cannon scanner, and voice utterances acquired with a microphone. The MultiModal-Database-XJTU includes real multimodal data from 102 individuals. In this contribution, the acquisition setup and protocol are outlined, and the contents of the database are described. The database will be publicly available for research purposes.}, 
keywords={biometrics (access control);feature extraction;fingerprint identification;MultiModal-database-XJTU;XJTU multimodal database;automatic biometrics recognition systems;data quality;multimodal data;multimodal procedure;Authentication;Databases;Face;Feature extraction;Fingerprint recognition;Fingers;Multi-focus image fusion;Perfect reconstruction;Quantum particle swarm optimization;Superior speed}, 
doi={10.1109/ITOEC.2017.8122351}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{5984849, 
author={S. Duttagupta and R. Mansharamani}, 
booktitle={2011 International Symposium on Performance Evaluation of Computer Telecommunication Systems}, 
title={Extrapolation tool for load testing results}, 
year={2011}, 
volume={}, 
number={}, 
pages={69-76}, 
abstract={Load testing of IT applications is fraught with the challenges of time to market, quality of results, high cost of commercial tools, and accurately representing production like scenarios. It would help IT projects to be able to test with a small number of users and extrapolate to scenarios with much larger number of users. This in turn will cut down cycle times and costs and allow for a variety of extrapolations closer to production. We present a simple extrapolation technique based on statistical empirical modeling, which we have found to be more than 90% accurate across a range of applications running across a number of hardware servers. The technique has currently been validated for scenarios where the hardware is the bottleneck and is extensible to a wider range of scenarios as well.}, 
keywords={extrapolation;program testing;statistical analysis;IT applications;IT projects;extrapolation tool;load testing results;statistical empirical modeling;Extrapolation;Linear regression;Load modeling;Servers;Testing;Throughput;Time factors;Extrapolation;S-Curves;load testing;regression}, 
doi={}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{6459909, 
author={A. Underbrink and A. Potter and H. Jaenisch and D. J. Reifer}, 
booktitle={2012 IEEE Conference on Technologies for Homeland Security (HST)}, 
title={Application stress testing Achieving cyber security by testing cyber attacks}, 
year={2012}, 
volume={}, 
number={}, 
pages={556-561}, 
abstract={Application stress testing applies the concept of computer network penetration testing to software applications. Since software applications may be attacked - from inside or outside a protected network boundary - they are threatened by actions and conditions which cause delays, disruptions, or failures. Stress testing exposes software systems to simulated cyber attacks, revealing potential weaknesses and vulnerabilities in their implementation. By using such testing, these internal weaknesses and vulnerabilities can be discovered earlier in the software development life cycle, corrected prior to deployment, and lead to improved software quality. Application stress testing is a process and software prototype for verifying the quality of software applications under severe operating conditions. Since stress testing is rarely - if at all - performed today, the possibility of deploying critical software systems that have been stress tested provides a much stronger indication of their ability to withstand cyber attacks. Many possible attack vectors against critical software can be verified as true threats and mitigated prior to deployment. This improves software quality and serves as a tremendous risk reduction for critical software systems used in government and commercial enterprises. The software prototype models and verifies failure conditions of a system under test (SUT). The SUT is first executed in a virtual environment and its normal operational modes are observed. A normal behavior model is generated in order to predict failure conditions based on attack models and external SUT interfaces. Using off-the-shelf software tools, the predictions are verified in the virtual environment by stressing the executing SUT with attacks against the SUT. Results are presented to testers and system developers for dispensation or mitigation.}, 
keywords={computer network security;program testing;program verification;risk analysis;safety-critical software;software prototyping;software quality;software tools;virtual reality;SUT;application stress testing;commercial enterprises;computer network penetration testing;critical software system;cyber attack testing;cyber security;delay;failure analysis;formal verification;government enterprises;off-the-shelf software tools;potential weaknesses revealing;protected network boundary;risk reduction;software application;software development life cycle;software prototype model;software quality;software systems;software vulnerability;system under test;virtual environment;Databases;Monitoring;Prototypes;Software systems;Stress;Testing;application testing;attack;penetration testing;softwaer quality;software assurance}, 
doi={10.1109/THS.2012.6459909}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{5669732, 
author={H. J. Jo and J. G. Hwang and K. M. Lee}, 
booktitle={ICCAS 2010}, 
title={Proposal of automated performance testing tool for vital software in train control system}, 
year={2010}, 
volume={}, 
number={}, 
pages={1151-1155}, 
abstract={In accordance with the development of recent computer technology, the dependency of train control system on the computer software is being increased further, and accordingly, the testing for the safety and reliability of train control system software became more important. Hence, the safety assurance of the vital software running on the train control system is very critical task and yet, not many works have been done. While much efforts have been reported to improve electronic hardware's safety, not so much systematic approaches to evaluate software's safety. In this paper, we suggested an automated tool for performance testing in train control system, and presented its result of implementation. The testing items in the implemented tool had referred to the international standards in relation to the software for train control system, such as IEC 61508 and IEC 62279. In these international standards, 'performance testing' for train control system S/W has to be recommended highly.}, 
keywords={IEC standards;program testing;railway engineering;railway safety;IEC 61508;IEC 62279;automated performance testing tool;computer software;electronic hardware safety;international standard;performance testing;reliability testing;safety assurance;safety testing;train control system;Control systems;Monitoring;Rail transportation;Safety;Software;Standards;Testing;Performance testing;Software safety;Train control system}, 
doi={10.1109/ICCAS.2010.5669732}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{204204, 
author={T. P. Parker and C. W. Webb}, 
booktitle={1992 Proceedings 42nd Electronic Components Technology Conference}, 
title={A study of failures identified during board level environmental stress testing}, 
year={1992}, 
volume={}, 
number={}, 
pages={177-184}, 
abstract={AT&T has investigated and implemented environmental stress testing (EST) in the production of a variety of circuit board designs as a means of reducing the incidence of early life failures. EST techniques include thermal cycling, random vibration, and others. These techniques have proven more effective than traditional burn-in techniques. In addition, studies have revealed that functional monitoring during thermal stressing of circuit cards more than doubles the effectiveness of EST. Outgoing quality audits and customer first month failure rates have improved by factors of two to four since the implementation of EST}, 
keywords={environmental testing;failure analysis;life testing;printed circuit testing;production testing;EST techniques;board level environmental stress testing;circuit board designs;early life failures;first month failure rates;functional monitoring;random vibration;thermal cycling;Application software;Assembly;Circuit testing;Failure analysis;Life testing;Manufacturing processes;Printed circuits;Production;Thermal stresses;Total quality management}, 
doi={10.1109/ECTC.1992.204204}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{7286553, 
author={Xi Chen and Hao Guo and P. Crossley}, 
booktitle={2015 IEEE Power Energy Society General Meeting}, 
title={Performance testing of IEC 61850 based architecture for UK National Grid standardised Substation automation solutions}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={Traditional protection and control systems in many UK National Grid Substations are reaching the end of their asset design life. This provides an opportunity to investigate whether new architecture that deploys Intelligent Electronic Device (IED) technology can deliver a reliable solution that is economically appropriate and delivers long life. The application of IEDs that utilize the IEC61850 based process bus reduces the life-time cost of the secondary systems and improves flexibility and functionality by accommodating high-speed peer-to-peer communications. The interconnectivity of devices on a single network offers significant benefits including a plug and play approach to future system changes. However, it requires interoperability among multi-vendor protection relays and control devices over an operating life of many decades. The realisation of this requires significant and detailed testing to help National Grid gain confidence in the use of these technologies. In this paper the substation architecture and the associated Power Networks are modelled in RTDS with faults applied at different locations on the transmission lines. The paper presents the results of interoperability tests involving multi-vendor Merging Unit (MU) and IED devices, which are then used to evaluate the functional performance of distance protection schemes.}, 
keywords={open systems;power grids;relay protection;substation automation;substation protection;IEC61850 based process bus;IED technology;RTDS;UK National Grid Standardised Substation automation solutions;asset design life;control devices;distance protection schemes;high-speed peer-to-peer communications;intelligent electronic device technology;interoperability tests;lifetime cost;multi-vendor merging unit;multi-vendor protection relays;plug and play approach;power networks;secondary systems;transmission lines;Circuit faults;IEC Standards;Interoperability;Merging;Substations;Tagging;IEC61850;Interoperability;Power System Reliability;Substation Automation;Substation Protection}, 
doi={10.1109/PESGM.2015.7286553}, 
ISSN={1932-5517}, 
month={July},}
@INPROCEEDINGS{6070157, 
author={J. Amelot and Y. S. Li-Baboud and C. Vasseur and J. Fletcher and D. Anand and J. Moyne}, 
booktitle={2011 IEEE International Symposium on Precision Clock Synchronization for Measurement, Control and Communication}, 
title={An IEEE 1588 Performance Testing Dashboard for Power Industry requirements}, 
year={2011}, 
volume={}, 
number={}, 
pages={132-137}, 
abstract={The numerous time synchronization performance requirements in the Smart Grid necessitates a set of common metrics and test methods. The test methods help to verify the ability of the network system and its components to meet the power industry's accuracy, reliability and interoperability criteria for next-generation substations. In order to develop viable metrics and test methods, an IEEE 1588 Testbed for the power industry has been established. To ease the challenges of testing, monitoring and analysis of the results, a software-based testing dashboard was designed and implemented. The dashboard streamlines the performance testing process by converging multiple tests for accuracy, reliability and interoperability into a centralized interface. The dashboard enables real-time visualization and analysis of the results. The paper details the design and implementation of the IEEE 1588 Power Industry Performance Testing Dashboard as well as an update of the preliminary findings from the testbed.}, 
keywords={open systems;power engineering computing;power generation reliability;smart power grids;substations;synchronisation;IEEE 1588;dashboard streamlines;interoperability;next-generation substations;power industry performance testing dashboard;reliability;smart grid;software-based testing dashboard;time synchronization;Frequency synchronization;Power industry;Robustness;Switches;Synchronization;Time frequency analysis;IEEE 1588;PMU;conformance testing;test methods;time synchronization}, 
doi={10.1109/ISPCS.2011.6070157}, 
ISSN={1949-0305}, 
month={Sept},}
@INPROCEEDINGS{622253, 
author={R. Mahmoudi and J. L. Tauritz}, 
booktitle={Proceedings of 1997 Wireless Communications Conference}, 
title={Performance testing of the North American CDMA system, using an envelope simulator}, 
year={1997}, 
volume={}, 
number={}, 
pages={84-88}, 
abstract={The growing use of spread spectrum techniques for personal communications (PCS) in Japan and USA is proving to be an enormous stimulus for the study of system impact on component design. New and innovative techniques are required to translate system criteria into component specifications. In this paper we have studied the performance of the “North American Digital Cellular IS-95” system proposed by QUALCOMM, under the influence of spurious signals using the new “Circuit Envelope Simulator” in HP-EESOF's Microwave Design System, MDS. The implemented functional blocks facilitate the generation of proper (noisy) CDMA (reverse and forward) signals, which are then used to program an arbitrary wave generator in order to create actual test signals. Additionally, these functional blocks can be replaced with equivalent circuits, consisting of passive and active elements, etc. For illustrative purposes, we discuss the application of these signals to two real amplifiers, one linear and one nonlinear. The measured results are critically compared with the simulation results}, 
keywords={cellular radio;code division multiple access;digital radio;digital simulation;personal communication networks;spread spectrum communication;telecommunication equipment testing;Circuit Envelope Simulator;HP-EESOF's Microwave Design System;North American CDMA system;North American Digital Cellular IS-95;QUALCOMM;equivalent circuits;functional blocks;linear amplifiers;nonlinear amplifier;performance testing;personal communications;spread spectrum techniques;Circuit noise;Circuit simulation;Circuit testing;Multiaccess communication;Noise generators;Personal communication networks;Signal design;Signal generators;Spread spectrum communication;System testing}, 
doi={10.1109/WCC.1997.622253}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6337826, 
author={M. Yan and H. Sun and X. Wang and X. Liu}, 
booktitle={2012 IEEE International Conference on Cluster Computing}, 
title={Building a TaaS Platform for Web Service Load Testing}, 
year={2012}, 
volume={}, 
number={}, 
pages={576-579}, 
abstract={Web services are widely known as the building blocks of typical service oriented applications. The performance of such an application system is mainly dependent on that of component web services. Thus the effective load testing of web services is of great importance to understand and improve the performance of a service oriented system. However, existing Web Service load testing tools ignore the real characteristics of the practical running environment of a web service, which leads to inaccurate test results. In this work, we present WS-TaaS, a load testing platform for web services, which enables load testing process to be as close as possible to the real running scenarios. In this way, we aim at providing testers with more accurate performance testing results than existing tools. WS-TaaS is developed on the basis of our existing Cloud PaaS platform: Service4All. First, we provide detailed analysis of the requirements of Web Service load testing and present the conceptual architecture and design of key components. Then we present the implementation details of WS-TaaS on the basis of Service4All. Finally, we perform a set of experiments based on the testing of real web services, and the experiments illustrate that WS-TaaS can efficiently facilitate the whole process of Web Service load testing.}, 
keywords={Web services;cloud computing;program testing;software tools;Cloud PaaS platform;Service4All;TaaS platform;WS-TaaS;Web service load testing tools;load testing platform;service oriented system;typical service oriented applications;Cloud computing;Computer architecture;Monitoring;Testing;cloud computing;load testing;testing as a service;web services}, 
doi={10.1109/CLUSTER.2012.20}, 
ISSN={1552-5244}, 
month={Sept},}
@INPROCEEDINGS{5581372, 
author={L. Xu and W. Zhang and L. Chen}, 
booktitle={2010 Seventh Web Information Systems and Applications Conference}, 
title={Modeling Users' Visiting Behaviors for Web Load Testing by Continuous Time Markov Chain}, 
year={2010}, 
volume={}, 
number={}, 
pages={59-64}, 
abstract={Virtual users with high quality are the preconditions to ensure the effect of load testing for Web applications. The existed tools for load testing usually generate virtual users with randomly choosing user sessions, manually generating user sessions or mining Log files, which causing such problems as non-real workload, subjectivity or difficult to update. Therefore we set each virtual user with a corresponding configure file, and these files determine the visiting paths, visiting moments and stay time of virtual users based on the Continuous Time Markov Chain. So we firstly finish the pretreatment for Log files, then construct the user visiting model, and next generate the virtual users, lastly carry out the load testing. In this way, we can obtain more reliable results for Web application load testing than the existed methods.}, 
keywords={Markov processes;Web services;data mining;program testing;virtual reality;Web load testing;continuous time Markov chain;log files mining;user visiting model;virtual users;Electromagnetic compatibility;Load modeling;Markov processes;Testing;Time factors;Web pages;Continuous Time Markov Chain;load testing;virtual user}, 
doi={10.1109/WISA.2010.47}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6297158, 
author={L. Nagowah and G. Sowamber}, 
booktitle={2012 International Conference on Computer Information Science (ICCIS)}, 
title={A novel approach of automation testing on mobile devices}, 
year={2012}, 
volume={2}, 
number={}, 
pages={924-930}, 
abstract={Mobile phones and mobile applications have now become an integral part of our everyday life. Mobile application testing plays a pivotal role in making the mobile applications more reliable and defect free. Existing test automation tools have been tailored to perform mobile test automation through mobile emulators. Other tools require the mobile device where the application is installed, to be connected to a computer so that the tests can be run. Obviously, the results obtained from emulators often differ from those obtained on actual mobile devices. To our best knowledge only a few solutions for creating automated tests of mobile applications exist and their functionality is very limited. In this paper, we introduce the idea of implementing a mobile test automation framework MobTAF which performs mobile test automation on the mobile device where connection to a computer is not required. The framework moves the testing infrastructure to the phone, to support test situations that cannot easily be replicated with an emulator. A prototype application was then implemented to test the mobile automation framework, MobTAF. The results prove that MobTAF framework is an efficient way of performing mobile application tests directly on the mobile devices.}, 
keywords={mobile computing;mobile handsets;program testing;MobTAF framework;automated tests;automation testing;defect free;mobile application testing;mobile devices;mobile emulators;mobile phones;mobile test automation framework;prototype application;test automation tools;testing infrastructure;Automation;Generators;Layout;Mobile communication;Robustness;Testing;XML;mobile application testing;mobile device test automation;mobile test automation framework;mobile testing;software testing}, 
doi={10.1109/ICCISci.2012.6297158}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{790205, 
author={C. G. Niederstrasser and C. A. Kitts and M. A. Swartwout}, 
booktitle={1999 IEEE Aerospace Conference. Proceedings (Cat. No.99TH8403)}, 
title={Design and performance testing of a satellite health beacon receiving station}, 
year={1999}, 
volume={5}, 
number={}, 
pages={241-251 vol.5}, 
abstract={As part of its space operations research program, Stanford University's Space Systems Development Laboratory (SSDL) is implementing an automated state of health assessment and notification system for spacecraft. Onboard the spacecraft, this system consists of software that filters telemetry to derive a health assessment and a periodic beacon that broadcasts this assessment to the ground. Throughout the world, a network of low-cost receiving stations receives the beacon signal and relays it to a central mission control center via the Internet. This paper addresses the design and development of a beacon receiving station. Each station is designed to be approximately an order of magnitude lower in price than a conventional two-way ground station. Emphasis is placed on making sure the station is highly autonomous, requiring little or no assistance from the host site. The stations are made up of only three separate components-an antenna, a receiver, and a personal computer}, 
keywords={aerospace test facilities;automatic test equipment;automatic testing;computerised monitoring;ground support systems;receiving antennas;satellite ground stations;signal processing;telecommunication computing;Stanford University;antenna;beacon signal;central mission control center;cost;health assessment;performance testing;periodic beacon;personal computer;satellite health beacon receiving station;telemetry;two-way ground station;Information filtering;Information filters;Laboratories;Operations research;Relays;Satellite broadcasting;Software systems;Space vehicles;Telemetry;Testing}, 
doi={10.1109/AERO.1999.790205}, 
ISSN={}, 
month={},}
@INPROCEEDINGS{5533420, 
author={J. Križanić and A. Grgurić and M. Mošmondor and P. Lazarevski}, 
booktitle={The 33rd International Convention MIPRO}, 
title={Load testing and performance monitoring tools in use with AJAX based web applications}, 
year={2010}, 
volume={}, 
number={}, 
pages={428-434}, 
abstract={In order to deliver quality assured software and avoid potential costs caused by unstable software, software testing is essential in software lifecycle. Load testing is one of the testing types with high importance. It is usually accompanied by performance monitoring of the hosting environment. In the case of web applications which are today widely used, one fact is obvious: most of web applications are public and used by vast number of users, which are making a considerable traffic load on hosting environments and web applications. Load testing and performance monitoring become facilitated with existing tools aimed for load testing and performance monitoring. In the paper we analyze and compare several existing tools which facilitate load testing and performance monitoring, in order to find the most appropriate tools by criteria such as ease of use, supported features, and license. Selected tools were put in action in the real environment, through several web applications. For the case study one of the web applications is used in order to introduce different capabilities of tools, including distributed testing, assembling of test scenario from previously recorded usage scenarios, security support, results analysis, monitoring of key parameters, and reporting and alerting about changes of these parameters.}, 
keywords={Application software;Assembly;Costs;Licenses;Monitoring;Performance analysis;Security;Software quality;Software testing;Telecommunication traffic;AJAX;load testing;performance monitoring;web applications}, 
doi={}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{7780247, 
author={A. Amirante and T. Castaldi and L. Miniero and S. P. Romano}, 
booktitle={2016 Principles, Systems and Applications of IP Telecommunications (IPTComm)}, 
title={Jattack: a WebRTC load testing tool}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={We present Jattack, an automated stressing tool for the analysis of the performance of WebRTC-enabled server-side components. Jattack has been initially conceived with the primary objective of performing a thorough scalability analysis of the well-known Janus WebRTC gateway. As such, it re-uses most of the Janus core stack components in order to reliably emulate the behavior of a dynamically adjustable number of WebRTC clients. The specific testing .scenario can indeed be programmatically reproduced by writing a small "controller" component, which takes on the responsibility of properly orchestrating the scenario itself. The general-purpose nature of the tool, together with its flexibility deriving from the controller-based programmable approach, makes Jattack also suitable for stress-testing other WebRTC-enabled servers.}, 
keywords={Internet;program testing;Jattack;WebRTC load testing tool;WebRTC-enabled server-side components;automated stressing tool;stress-testing;Browsers;Media;Scalability;Servers;Stress;Testing;WebRTC}, 
doi={}, 
ISSN={}, 
month={Oct},}
@ARTICLE{1191406, 
author={L. Angrisani and A. Baccigalupi and G. D'Angiolo}, 
journal={IEEE Transactions on Instrumentation and Measurement}, 
title={A frame-level measurement apparatus for performance testing of ATM equipment}, 
year={2003}, 
volume={52}, 
number={1}, 
pages={20-26}, 
abstract={Performance testing of asynchronous transfer mode (ATM) equipment is dealt with here. The attention is principally paid to frame-level metrics, recently proposed by the ATM Forum because of their suitability to reflect user-perceived performance better than traditional cell-level metrics. Following the suggestions of the ATM Forum, more and more network engineers and production managers are interested today in these metrics, thus increasing the need of instruments and measurement solutions appropriate to their estimation. Trying to satisfy this exigency, a new VME extension for instrumentation (VXI) based measurement apparatus is proposed in the paper. The apparatus features a suitable software, developed by the authors, which allows the evaluation of the aforementioned metrics by simply making use of common ATM analyzers; only two VXI line interfaces, capable of managing the physical and ATM layers, are, in fact, adopted. Some details concerning ATM technology and its hierarchical structure, as well as the main differences between frames, specific to the ATM adaptation layer, and cells, characterizing the underlying ATM layer, are first given. Both the hardware and software solutions of the measurement apparatus are then described in detail, paying particular attention to the measurement procedures implemented. In the end, the performance of a new ATM device is assessed through the proposed apparatus.}, 
keywords={asynchronous transfer mode;automatic test equipment;telecommunication computing;telecommunication equipment testing;ATM equipment;VME extension;VXI instrumentation;frame-level metric;measurement apparatus;performance testing;Asynchronous transfer mode;B-ISDN;Delay;Instruments;Laboratories;Manufacturing;Particle measurements;Quality of service;Software measurement;Testing}, 
doi={10.1109/TIM.2003.809063}, 
ISSN={0018-9456}, 
month={Feb},}
@INPROCEEDINGS{6606651, 
author={H. Malik and H. Hemmati and A. E. Hassan}, 
booktitle={2013 35th International Conference on Software Engineering (ICSE)}, 
title={Automatic detection of performance deviations in the load testing of Large Scale Systems}, 
year={2013}, 
volume={}, 
number={}, 
pages={1012-1021}, 
abstract={Load testing is one of the means for evaluating the performance of Large Scale Systems (LSS). At the end of a load test, performance analysts must analyze thousands of performance counters from hundreds of machines under test. These performance counters are measures of run-time system properties such as CPU utilization, Disk I/O, memory consumption, and network traffic. Analysts observe counters to find out if the system is meeting its Service Level Agreements (SLAs). In this paper, we present and evaluate one supervised and three unsupervised approaches to help performance analysts to 1) more effectively compare load tests in order to detect performance deviations which may lead to SLA violations, and 2) to provide them with a smaller and manageable set of important performance counters to assist in root-cause analysis of the detected deviations. Our case study is based on load test data obtained from both a large scale industrial system and an open source benchmark application. The case study shows, that our wrapper-based supervised approach, which uses a search-based technique to find the best subset of performance counters and a logistic regression model for deviation prediction, can provide up to 89% reduction in the set of performance counters while detecting performance deviations with few false positives (i.e., 95% average precision). The study also shows that the supervised approach is more stable and effective than the unsupervised approaches but it has more overhead due to its semi-automated training phase.}, 
keywords={input-output programs;program testing;public domain software;regression analysis;software performance evaluation;unsupervised learning;CPU utilization;LSS;SLA violations;automatic performance deviation detection;deviation prediction;disk I-O;large scale systems;load testing;logistic regression model;machine learning;memory consumption;network traffic;open source benchmark application;performance counters;root-cause analysis;run-time system properties;search-based technique;service level agreements;wrapper-based supervised approach;Control charts;Large-scale systems;Logistics;Monitoring;Principal component analysis;Radiation detectors;Testing;Machine Learning;Performance;Signature}, 
doi={10.1109/ICSE.2013.6606651}, 
ISSN={0270-5257}, 
month={May},}
@INPROCEEDINGS{4273012, 
author={M. D. Barros and J. Shiau and C. Shang and K. Gidewall and H. Shi and J. Forsmann}, 
booktitle={37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)}, 
title={Web Services Wind Tunnel: On Performance Testing Large-Scale Stateful Web Services}, 
year={2007}, 
volume={}, 
number={}, 
pages={612-617}, 
abstract={New versions of existing large-scale web services such as Passport.comcopy have to go through rigorous performance evaluations in order to ensure a high degree of availability. Performance testing (such as benchmarking, scalability, and capacity tests) of large-scale stateful systems in managed test environments has many different challenges, mainly related to the reproducibility of production conditions in live data centers. One of these challenges is creating a dataset in a test environment that mimics the actual dataset in production. Other challenges involve the characterization of load patterns in production based on log analysis and proper load simulation via reutilization of data from the existing dataset. The intent of this paper is to describe practical approaches to address some of the aforementioned challenges through the use of various novel techniques. For example, this paper discusses data sanitization, which is the alteration of large datasets in a controlled manner to obfuscate sensitive information, preserving data integrity, relationships, and data equivalence classes. This paper also provides techniques for load pattern characterization via the application of Markov chains to custom and generic logs, as well as general guidelines for the development of cache-based load simulation tools tailored for the performance evaluation of stateful systems.}, 
keywords={Web services;program testing;security of data;software performance evaluation;Markov chains;Web services wind tunnel;cache-based load simulation tools;data integrity;data sanitization;log analysis;performance testing;Availability;Benchmark testing;Environmental management;Large-scale systems;Pattern analysis;Production systems;Reproducibility of results;Scalability;System testing;Web services}, 
doi={10.1109/DSN.2007.102}, 
ISSN={1530-0889}, 
month={June},}
@INPROCEEDINGS{5563862, 
author={Ni Jin and Wang Mingming and Wang Jiangqing}, 
booktitle={2010 3rd International Conference on Computer Science and Information Technology}, 
title={Realization on intelligent GUI automation testing based-on .NET}, 
year={2010}, 
volume={1}, 
number={}, 
pages={14-17}, 
abstract={Points out the obvious deficiencies in capture/playback mechanism at present, aiming at difficulties of maintenance and extension in constantly altered GUI elements, presents a new GUI automation testing solution - Building AUILibrary. It can search, identify all the controls, trigger all kinds of mouse and keyboard events, execute data driving verification roundly and accurately, trace and record execution process and save the locale when exception occurs, implement flexible and effective GUI automation testing indeed.}, 
keywords={graphical user interfaces;program testing;software tools;user interface management systems;.NET framework;AUILibrary;capture mechanism;data driving verification;intelligent GUI automation testing;playback mechanism;Automation;Computers;Graphical user interfaces;Indexes;Software;GUI;Software testing;automation}, 
doi={10.1109/ICCSIT.2010.5563862}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{5514222, 
author={G. Li and N. Tan}, 
booktitle={2010 Third International Conference on Information and Computing}, 
title={Design and Implementation of Remote Monitoring and Control System for Freight Train Load Testing}, 
year={2010}, 
volume={1}, 
number={}, 
pages={117-120}, 
abstract={The key technology of the fatigue reliability design and test evaluation of freight train is to establish freight train load spectrum based on operating conditions. Design a set of remote monitoring and control system for the establishment of loading spectrum's actual needs. The system uses GPS technology for vehicle location, speed and other information, through the GPRS technology to build car-side with the ground control center of the interaction channel. Using the ARM7 microprocessors, transplant embedded μC/OS-II operating system, realized the hardware management and task scheduling. The system can achieve vehicle-side with the ground control center data exchange. Through the ground control center monitoring software running real-time get the vehicles and the test equipment status, timely adjustment of test equipment. At the same time enables automatic vehicle equipment. The system basically meet the needs of the overloaded train load test research requirements can be a steady, accurate and complete remote monitoring and control functions.}, 
keywords={Global Positioning System;automatic test equipment;computerised monitoring;microprocessor chips;operating systems (computers);packet radio networks;rail traffic;scheduling;traffic engineering computing;ARM7 microprocessors;GPRS technology;GPS technology;automatic vehicle equipment;data exchange;embedded μC/OS-II operating system;fatigue reliability design;freight train load spectrum;freight train load testing;ground control center;hardware management;remote monitoring;task scheduling;train car-side;Automatic control;Control systems;Fatigue;Global Positioning System;Land vehicles;Loading;Remote monitoring;Road vehicles;System testing;Test equipment;#NAME?}, 
doi={10.1109/ICIC.2010.36}, 
ISSN={2160-7443}, 
month={June},}
@INPROCEEDINGS{7102628, 
author={E. Rodrigues and M. Bernardino and L. Costa and A. Zorzo and F. Oliveira}, 
booktitle={2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)}, 
title={PLeTsPerf - A Model-Based Performance Testing Tool}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={Performance testing is a highly specialized task, since it requires that a performance engineer knows the application to be tested, its usage profile, and the infrastructure where it will execute. Moreover, it requires that testing teams expend a considerable effort and time on its automation. In this paper, we present the PLeTsPerf, a model-based performance testing tool to support the automatic generation of scenarios and scripts from application models. PLetsPerf is a mature tool, developed in collaboration with an IT company, which has been used in several works, experimental studies and pilot studies. We present an example of use to demonstrate the process of generating test scripts and scenarios from UML models to test a Web application. We also present the lessons learned and discuss our conclusions about the use of the tool.}, 
keywords={Internet;program testing;PLeTsPerf tool;UML model;Unified Modeling Language;Web application;model-based performance testing tool;scenario generation;script generation;Companies;Generators;Load modeling;Software;Testing;Unified modeling language;Visualization}, 
doi={10.1109/ICST.2015.7102628}, 
ISSN={2159-4848}, 
month={April},}
@INPROCEEDINGS{6068597, 
author={A. J. Mercer and R. K. James and G. Bennett and P. Patel and C. Johnston and J. Cai}, 
booktitle={2011 IEEE International Conference on RFID-Technologies and Applications}, 
title={Performance testing of RFID systems with RF-harsh materials}, 
year={2011}, 
volume={}, 
number={}, 
pages={537-543}, 
abstract={Radio Frequency Identification (RFID) has been adopted to track items in supply chain, healthcare, and manufacturing applications. Hospitals and factories, however, are difficult environments for radiowave propagation. Cinder block walls with steel rebar, metal obstructions, and RF noise present significant obstacles to RFID system performance. Tagging lossy materials in these environments, such as metals and liquids, can also degrade the performance of RFID systems. In a previous paper [1] we simulated the RF-harsh conditions prevalent in these environments to evaluate UHF RFID system performance. In this paper, we utilize the same laboratory environment to measure RFID system performance when RF-harsh materials are tagged. These tests serve to examine the effect of water and plastic car parts on RFID system performance in an RF harsh environment. We show that the problems posed when tagging RF-harsh materials can be mitigated with either the strategic placement of tags on the item, or the careful choice of tags. While UHF RFID systems can be used in the presence of RF-harsh circumstances, the system architecture must be carefully tested in order to minimize the effects of performance-hindering RF obstacles.}, 
keywords={radiofrequency identification;radiowave propagation;RF-harsh materials;UHF RFID system;performance testing;radio frequency identification;radiowave propagation;Antennas;Belts;Materials;Metals;Radio frequency;Radiofrequency identification;RFID;UHF (Ultra High Frequency);automotive materials;liquids;manufacturing;materials testing;multipath;performance evaluation;radio;radiowave propagation}, 
doi={10.1109/RFID-TA.2011.6068597}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6180593, 
author={T. Sidhu and M. Kanabar and P. Parikh}, 
booktitle={2011 International Conference on Advanced Power System Automation and Protection}, 
title={Configuration and performance testing of IEC 61850 GOOSE}, 
year={2011}, 
volume={2}, 
number={}, 
pages={1384-1389}, 
abstract={The IEC 61850 standard part 8-1 proposes Generic Object Oriented Substation Event (GOOSE) message for time critical applications over the Ethernet network. In order to cover the wide range of applications and achieve flexibility in implementation, GOOSE messages are kept generic in the standard. However, this flexibility leads to configuration problem achieving multi-vendor interoperability. Therefore, some efforts have been carried out in this work to present a systematic GOOSE configuration approach, as well as, verification and performance testing of the GOOSE. First part of this paper configuration of Ethernet switched network, including IEEE 1588 based time synchronization, Rapid Spanning Tree Protocol (RSTP), and IEEE 802.1Q based Quality of Services (QoS). In the second part, the paper leads to step-by-step configuration process comprising IEC 61850 data modeling, datasets of GOOSE within individual IEDs, and system integration of GOOSE. Finally, the verification of configured GOOSE messages is presented using network analyzer tools, and performance testing time delay) over the network is carried out for various network scenarios.}, 
keywords={local area networks;object-oriented methods;open systems;power engineering computing;quality of service;substation automation;synchronisation;Ethernet switched network;IEC 61850 GOOSE performance testing;IEC 61850 data modeling;IEEE 1588 based time synchronization;IEEE 802.1Q based quality of services;QoS;RSTP;generic object oriented substation event message;multivendor interoperability;network analyzer tools;rapid spanning tree protocol;substation automation systems;systematic GOOSE configuration approach;Automation;Bridges;Data models;IEC standards;Power systems;Switches;Testing;Ethernet switched networks;GOOSE;IEC 61850;substation automation systems}, 
doi={10.1109/APAP.2011.6180593}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6526035, 
author={Y. Yao and X. Wang}, 
booktitle={Proceedings of 2012 2nd International Conference on Computer Science and Network Technology}, 
title={A distributed, cross-platform automation testing framework for GUI-driven applications}, 
year={2012}, 
volume={}, 
number={}, 
pages={723-726}, 
abstract={With the rapid development of computer technology, nowadays GUIs have been widely used in desktop applications and web applications. GUI-driven application testing is an emergent approach to software testing and plays a key role to assure software quality. This paper first discusses the various methods for testing GUI-driven applications, and then defines a GUI model and formally defines the test case and the test suite. Finally, it proposes a novel automated, distributed and cross-platform testing framework for GUI. Experiments conducted showed that the proposed testing architecture managed to use parallel cross-platform clusters to test heterogeneous applications whose technologies were incompatible with the testing framework.}, 
keywords={Internet;graphical user interfaces;program testing;software architecture;software quality;GUI model;GUI-driven application testing;Web applications;computer technology;cross-platform automation testing framework;desktop applications;distributed automation testing framework;graphical user interfaces;parallel cross-platform clusters;software quality assurance;software testing;test case;test suite;testing architecture;GUI-driven applications;automation testing;cross-platform testing;distributed testing framework}, 
doi={10.1109/ICCSNT.2012.6526035}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6885425, 
author={W. Naheman and Jianxin Wei}, 
booktitle={Proceedings 2013 International Conference on Mechatronic Sciences, Electric Engineering and Computer (MEC)}, 
title={Review of NoSQL databases and performance testing on HBase}, 
year={2013}, 
volume={}, 
number={}, 
pages={2304-2309}, 
abstract={NoSQL (Not Only SQL) is the generic term of a kind of non-relational database products. This paper, firstly, lists the disadvantages of traditional relational databases, introduces NoSQL databases including their advantages, disadvantages and their application status. Then, a comparison is made between NoSQL databases and SQL database, also another comparison between different NoSQL products. Finally, we introduce the architecture and data model of HBase database, which is a representative of NoSQL databases, and did some performance tests on HBase database, including the column family test, the sort test, the random read/write test and the query test. Test results show that written and query speed of HBase is slow under a single machine environment, but can be significantly improved in multimachine cluster environment.}, 
keywords={SQL;data models;relational databases;software performance evaluation;HBase database;HBase performance testing;NoSQL databases;Not Only SQL database;SQL database;column family test;data model;machine cluster environment;nonrelational database products;query test;random read-write test;single machine environment;sort test;Availability;Blogs;Computer architecture;Distributed databases;Manuals;HBase;NoSQL databases;performance testing;relational database}, 
doi={10.1109/MEC.2013.6885425}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{5632110, 
author={F. Kreit and G. Barberio and C. Subramanian and I. Kostanic and J. P. Pinelli}, 
booktitle={2010 First International Conference on Sensor Device Technologies and Applications}, 
title={Performance Testing of the Wireless Sensor Network System for Hurricane Monitoring}, 
year={2010}, 
volume={}, 
number={}, 
pages={63-72}, 
abstract={A wireless pressure monitoring system was developed by Florida Institute of Technology to measure wind induced pressure on low-rise structures during hurricanes. This study presents tests made to evaluate the performance of the sensors and their ability to measure accurate pressure variations. To test the reliability of the pressure sensors, a series of tests were designed. The resulting measurements were then compared to secondary references. The measurements were also compared to the basic Bernoulli theory. Further, the wind tunnel measurement allowed for the development of the first comparative computational fluid dynamics simulation and experimental results. Due to the components packaging in the remote, the sensor case cannot be completely streamlined. The resulting shape caused some aerodynamic disturbances. In order to study the sensor shape's influence on the pressure measurements, different experiments were set up. Specifically, by using a roof shaped ramp model mounted on a van, a highway test was performed, allowing examination of the error caused by the sensor's shape. Another test was performed at the University of Florida Hurricane Simulator to study the gust (unsteady) effects. This test revealed that the sensors were sensitive to mechanical vibrations. The paper addresses the sensor network systems topic of the conference.}, 
keywords={atmospheric measuring apparatus;atmospheric pressure;computational fluid dynamics;geophysical fluid dynamics;pressure measurement;pressure sensors;storms;wind;wireless sensor networks;Bernoulli theory;Florida Institute of Technology;University of Florida Hurricane Simulator;comparative CFD simulation;computational fluid dynamics;hurricane monitoring;low rise structures;pressure variation measurement;roof shaped ramp model;sensor case shape;sensor performance;wind induced pressure;wind tunnel measurement;wireless pressure monitoring system;wireless sensor network performance testing;Atmospheric measurements;Electron tubes;Fluid flow measurement;Pressure measurement;Sea measurements;Semiconductor device measurement;Wind speed;Multi-sensors;Performance testing;Wireless network}, 
doi={10.1109/SENSORDEVICES.2010.19}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{4588501, 
author={A. Habul and E. Kurtovic}, 
booktitle={ITI 2008 - 30th International Conference on Information Technology Interfaces}, 
title={Load testing an AJAX application}, 
year={2008}, 
volume={}, 
number={}, 
pages={729-732}, 
abstract={This paper presents a methodology for load testing an Ajax application. WebLOAD, an open source tool for performance testing, is used to simulate a huge number of client requests to the server. The load testing is used to evaluate and compare different scenarios on the system performance. In order to avoid misleading results, load testing of Ajax applications should incorporate not only server-side but also client-side code, because it can have a significant impact in determining the generated load.}, 
keywords={Java;XML;performance evaluation;program testing;public domain software;AJAX;WebLOAD;client- side code;load testing;open source tool;performance testing;server-side code;Databases;Delay;Frequency;HTML;Java;Load modeling;Network servers;System performance;System testing;XML;Ajax;load testing;workload model}, 
doi={10.1109/ITI.2008.4588501}, 
ISSN={1330-1012}, 
month={June},}
@ARTICLE{7234834, 
author={M. Hempel and J. W. Tomm and D. Venables and V. Rossin and E. Zucker and T. Elsaesser}, 
journal={Journal of Lightwave Technology}, 
title={Long-Term Aging and Quick Stress Testing of 980-nm Single-Spatial Mode Lasers}, 
year={2015}, 
volume={33}, 
number={21}, 
pages={4450-4456}, 
abstract={Single-spatial mode lasers emitting at 980 nm are studied during continuous-wave long-term operation and ultra-high power short-term operation (stress-test) up to 13.5 W. We find that both tests eventually activate the same degradation mechanism, namely internal catastrophic optical damage. In the case of ultra-high power operation, we show that the mechanism that initializes this effect is a lateral widening of the optical mode, resulting in increased absorption outside the waveguide. Defects formed during long-term aging may eventually lead to the same effect. Stress testing allows for activation of several degradation mechanisms in a device one after the other and for distinguishing between mechanisms induced by aging and independent ones. Stress tests could pave the way toward more time-efficient testing, e.g., for comparison of different technology variants in development.}, 
keywords={Aging;Cameras;Cavity resonators;Degradation;Monitoring;Optical pulses;Temperature measurement;Semiconductor device measurements;reliability;semiconductor diodes;semiconductor lasers},
doi={10.1109/JLT.2015.2475605}, 
ISSN={0733-8724}, 
month={Nov},}
@ARTICLE{206935, 
author={T. P. Parker and C. W. Webb}, 
journal={IEEE Transactions on Components, Hybrids, and Manufacturing Technology}, 
title={A study of failures identified during board level environmental stress testing}, 
year={1992}, 
volume={15}, 
number={6}, 
pages={1086-1092}, 
abstract={AT&T has investigated and implemented environmental stress testing (EST) in the production of a variety of circuit board designs as a means of reducing the incidence of early life failures. EST techniques include thermal cycling (TC), random vibration, etc. These techniques have proven more effective than traditional burn-in techniques. In addition, studies have revealed that functional monitoring during thermal stressing of circuit cards more than doubles the effectiveness of EST. Outgoing quality audits and customer first month failure rates have improved by factors of two to four since the implementation of EST}, 
keywords={environmental testing;failure analysis;life testing;printed circuit testing;quality control;AT&T;EST;board level environmental stress testing;burn-in techniques;circuit board designs;customer first month failure rates;early life failures;environmental stress testing;functional monitoring;outgoing quality audits;random vibration;study of failures;temperature cycling;thermal cycling;thermal stressing;Application software;Assembly;Circuit testing;Failure analysis;Human factors;Life testing;Manufacturing processes;Production;Thermal stresses;Total quality management}, 
doi={10.1109/33.206935}, 
ISSN={0148-6411}, 
month={Dec},}
@INPROCEEDINGS{5571539, 
author={T. Gao and Y. Ge and G. Wu and J. Ni}, 
booktitle={2010 Ninth International Symposium on Distributed Computing and Applications to Business, Engineering and Science}, 
title={A Reactivity-based Framework of Automated Performance Testing for Web Applications}, 
year={2010}, 
volume={}, 
number={}, 
pages={593-597}, 
abstract={To improve the reliability and feasibility of web applications, performance testing is very important for satisfying users. For reducing the cost and improve the efficiency of performance testing, we propose a new reactivity-based performance testing framework in this paper. We also provide a complete approach to generate test cases automatically from original web logs. First our approach retrieves user patterns through logs at the server side. Then, metrics derived from users' perspective are applied and usage pattern from client side are gained. At last test case can be generated automatically by solving an optimization problem through an evolutionary algorithm.}, 
keywords={Internet;automatic test pattern generation;client-server systems;evolutionary computation;performance evaluation;Web application;Web logs;automated reactivity-based performance testing framework;evolutionary algorithm;optimization problem;test case generation;user pattern retrieval;Load modeling;Measurement;Servers;Software;Testing;Time factors;Unified modeling language;automated test case generation;performance testing;testing framework;web applications}, 
doi={10.1109/DCABES.2010.127}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{4017687, 
author={N. Stankovic}, 
booktitle={2006 IEEE International Conference on Electro/Information Technology}, 
title={Patterns and Tools for Performance Testing}, 
year={2006}, 
volume={}, 
number={}, 
pages={152-157}, 
abstract={The growth of software applications in size and complexity is being followed by a number of specific nonfunctional requirements such as portability, interoperability, and availability on various platforms. Most often, these have been addressed by middleware or programming environment. In addition, easy customizability, adaptability, and sharing of components facilitates the development cycle. These should be understood and applied in a broader sense, i.e. to byproducts created during the development process such as programs for functional and performance testing. Much time is spent on developing test programs but their quality and quality of thus obtained results varies largely if the process is not standardized and automated. In this paper we present our experience with performance testing of a large scale suite of gateways that are used for the seamless integration of heterogeneous communication networks. We analyze the commercial and public domain tools for load generation and motivate our decision to define an in-house framework and build a distributed tool for performance, testing that is also not restricted by licensing issues and is readily available to everyone involved. Our tool is built on Visper, the object-oriented distributed programming middleware. The suitability and adaptability of the Visper model for rapid application development and the quality of produced result have proven our decision correct}, 
keywords={distributed programming;middleware;object-oriented programming;program testing;software prototyping;Visper;distributed tool;heterogeneous communication networks;large scale gateways suite;load generation;nonfunctional requirements;object-oriented distributed programming middleware;software applications;software engineering;software testing;software tools;test programs;Application software;Automatic testing;Availability;Communication networks;Large scale integration;Licenses;Middleware;Object oriented programming;Performance analysis;Programming environments;Software testing;software engineering;software tools}, 
doi={10.1109/EIT.2006.252109}, 
ISSN={2154-0357}, 
month={May},}
@ARTICLE{6313588, 
author={M. R. Dhote and G. G. Sarate}, 
journal={IEEE Software}, 
title={Performance Testing Complexity Analysis on Ajax-Based Web Applications}, 
year={2013}, 
volume={30}, 
number={6}, 
pages={70-74}, 
abstract={The Ajax model of Web applications development has rapidly gained popularity because it promises to bring the richness and responsiveness of desktop applications to the Web. Ajax implementations differ fundamentally from other Web implementations - mainly in making asynchronous requests for parts of a Webpage. Techniques routinely used for performance testing traditional Web applications must be modified and enhanced to suit the needs of Ajax-based applications. Using a general example, the authors of this article examine the unique challenges of carrying out performance testing for Ajax-based applications and offer approaches and tools for overcoming them.}, 
keywords={Internet;program testing;software metrics;Ajax-based Web applications;Webpage;performance testing complexity analysis;Browsers;Complexity theory;Internet;Servers;Software measurement;Statistical analysis;Testing;Ajax;performance testing;performance testing and tools;software quality and testing;stress testing}, 
doi={10.1109/MS.2012.132}, 
ISSN={0740-7459}, 
month={Nov},}
@INPROCEEDINGS{7377639, 
author={P. Brčić}, 
booktitle={2015 23rd Telecommunications Forum Telfor (TELFOR)}, 
title={Performance testing of EMC xtremio all-flash storage system}, 
year={2015}, 
volume={}, 
number={}, 
pages={1020-1023}, 
abstract={EMC XtremIO is one of the most advanced all-Flash data storage systems which is becoming an integral part of medim and enterprise data centers. The paper represents implementation of EMC XtremIO storage system for VDI, and adopted, implemented and validated methodology for testing performance of storage systems. There were generated and released three groups of different intense load tests, during which the data was collected, created tables and graphs. Finally was generated detailed analysis of the results.}, 
keywords={flash memories;program testing;EMC XtremIO all-flash storage system;load tests;storage system testing performance;Electromagnetic compatibility;Monitoring;Optical fiber testing;Servers;Synthetic aperture sonar;Virtual machining;All-Flash;XtremIO;data centri;performanse;sistem za skladi¿¿tenje podataka}, 
doi={10.1109/TELFOR.2015.7377639}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{5486954, 
author={J. l. Tang and Y. j. Liu and F. s. Wu}, 
booktitle={2010 2nd International Conference on Advanced Computer Control}, 
title={Virtual experiment system for metal creep performance testing based on VRML}, 
year={2010}, 
volume={4}, 
number={}, 
pages={140-143}, 
abstract={A virtual experiment system for metal creep performance testing is built by virtual reality modeling language (VRML). The structure, function and design principles of the system are described and its implementation procedure is also discussed. The key development process, including object modeling, 3D scene building, VRML connecting to the real-time database, design of interactive virtual 3D scene and complex virtual interaction, is illustrated in this paper. In addition, the following key problems have been solved during the system realization: virtual models building and geometrical transforming, database designing and optimizing, 3D virtual experimental scenes combining dynamically, the realization of database accessing and the communication of virtual entities.}, 
keywords={computer testing;database management systems;human computer interaction;virtual reality languages;3D scene building;complex virtual interaction;geometrical transforming;interactive virtual 3D scene;metal creep performance testing;object modeling;real time database;virtual entities;virtual experiment system;virtual reality modeling language;Buildings;Communication system control;Computer simulation;Creep;Instruments;Layout;Spatial databases;System testing;Virtual environment;Virtual reality;VRML;creep performance test;metal;virtual experiment}, 
doi={10.1109/ICACC.2010.5486954}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{7780234, 
author={L. Dong and X. Jing and Y. Chunhui}, 
booktitle={2016 Third International Conference on Trustworthy Systems and their Applications (TSA)}, 
title={Study of Performance Testing of Information System Based on Domestic CPU and OS}, 
year={2016}, 
volume={}, 
number={}, 
pages={112-116}, 
abstract={In order to evaluate the performance of of information system based on domestic CPU and OS, through the introduction of the background of basic hardware and software based on domestic, we expound the domestic information system performance testing principle and method, according to the testing results of existing mature commercial performance testing tool LoadRunner can not reflect the user experience of time, and can not be directly used for testing the information system which based on domestic CPU/OS, this paper put forward the two kinds of testing schemes that base on user experience of LoadRunner and JMeter domestic information system performance test, and test two kinds of improved schemes, through the comparison of the test data and the user experience time of the two schemes, the variance of the test scheme based on JMeter is smaller than LoadRunner test scheme 70.49%. The results show that the test results of the JMeter scheme are more close to the user experience than LoadRunner.}, 
keywords={information systems;microprocessor chips;operating systems (computers);performance evaluation;JMeter domestic information system performance test;LoadRunner domestic information system performance test;OS;domestic CPU;domestic information system performance testing method;domestic information system performance testing principle;performance evaluation;Browsers;Hardware;Information systems;Operating systems;Rendering (computer graphics);Servers;Testing;JMeter test tool;LoadRunner test tool;domestic CPU;domestic infrastructure software;domistic Operating System(OS);information system;performance test}, 
doi={10.1109/TSA.2016.27}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6413663, 
author={M. Yan and H. Sun and X. Wang and X. Liu}, 
booktitle={2012 IEEE 18th International Conference on Parallel and Distributed Systems}, 
title={WS-TaaS: A Testing as a Service Platform for Web Service Load Testing}, 
year={2012}, 
volume={}, 
number={}, 
pages={456-463}, 
abstract={Web services are widely known as the building blocks of typical service oriented applications. The performance of such an application system is mainly dependent on that of component web services. Thus the effective load testing of web services is of great importance to understand and improve the performance of a service oriented system. However, existing Web Service load testing tools ignore the real characteristics of the practical running environment of a web service, which leads to inaccurate test results. In this work, we present WS-TaaS, a load testing platform for web services, which enables load testing process to be as close as possible to the real running scenarios. In this way, we aim at providing testers with more accurate performance testing results than existing tools. WS-TaaS is developed on the basis of our existing Cloud PaaS platform: Service4All. First, we briefly introduce the functionalities and main components of Service4All. Second, we provide detailed analysis of the requirements of Web Service load testing and present the conceptual architecture and design of key components. Third, we present the implementation details of WS-TaaS on the basis of Service4All. Finally, we perform a set of experiments based on the testing of real web services, and the experiments illustrate that WS-TaaS can efficiently facilitate the whole process of Web Service load testing. Especially, comparing with existing testing tools, WS-TaaS can obtain more effective and accurate test results.}, 
keywords={Web services;cloud computing;performance evaluation;program testing;service-oriented architecture;Service4All;WS-TaaS;Web service load testing tools;building blocks;cloud PaaS platform;component Web services;service oriented applications;service oriented system performance;testing as a service platform;Cloud computing;Monitoring;Runtime;Testing;cloud computing;load testing;testing as a service;web services}, 
doi={10.1109/ICPADS.2012.69}, 
ISSN={1521-9097}, 
month={Dec},}
@ARTICLE{1413639, 
author={A. Helmy and S. Gupta}, 
journal={IEEE Communications Letters}, 
title={FOTG: fault-oriented stress testing of IP multicast}, 
year={2005}, 
volume={9}, 
number={4}, 
pages={375-377}, 
abstract={Network simulators provide a useful tool, for protocol evaluation. However, the results depend heavily on the simulated scenarios, especially for complex protocols such as multicast. There has been little work on scenario generation. In this work we present a fault-oriented test generation (FOTG) algorithm for automated stress testing of multicast protocols. FOTG processes an extended FSM model and uses a mix of forward and backward search techniques. Unlike traditional verification approaches, instead of starting from initial states, FOTG starts from a fault and uses cause-effect relations for automatic topology synthesis then uses backward implication to generate tests. Using FOTG we test various mechanisms commonly employed by multicast routing and validate our results through simulation.}, 
keywords={IP networks;multicast protocols;routing protocols;search problems;telecommunication network topology;FOTG algorithm;FSM model;IP multicast routing;automated stress testing;backward search technique;fault-oriented test generation;forward search technique;network simulator;protocol evaluation;topology synthesis;traditional verification approach;Automatic testing;Engines;Multicast algorithms;Multicast protocols;Robustness;Routing protocols;Stress;System testing;Topology;Very large scale integration}, 
doi={10.1109/LCOMM.2005.1413639}, 
ISSN={1089-7798}, 
month={April},}
@INPROCEEDINGS{7591820, 
author={A. Dinh and F. M. Bui and T. Nguyen}, 
booktitle={2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, 
title={An accelerometer based system to measure myocardial performance index during stress testing}, 
year={2016}, 
volume={}, 
number={}, 
pages={4877-4880}, 
abstract={Stress testing is used to measure the performance of the heart in an elevated stress state, in order to monitor or diagnose certain heart problems. Many measurements can be used to determine the performance of the heart, with the Tei index being the measurement of interest in this work. The Tei index has been used as a reliable method to evaluate systolic and diastolic performance, as it overcomes some limitations of the classical echocardiographic indices. It is calculated based on the time intervals derived from echocardiography. This paper presents an exploratory study, which uses an accelerometer to record mechanical events occurring in each cardiac cycle, also known as the seismocardiogram (SCG). From timing measurements corresponding to various events in the heart, a metric for myocardial performance is calculated based on the Tei index. The use of SCG in addition to ECG has the potential to provide further insights about the heart during stress testing, since the SCG quantifies mechanical actions of the heart.}, 
keywords={accelerometers;biomedical equipment;electrocardiography;ECG;Tei index;accelerometer based system;cardiac cycle;diastolic performance;heart problem diagnosis;mechanical events;myocardial performance index measurements;seismocardiogram;stress state;stress testing;systolic performance;timing measurements;Accelerometers;Electrocardiography;Heart;Indexes;Sensors;Stress;Valves;Accelerometry;Diastole;Echocardiography;Exercise Test;Female;Heart;Heart Function Tests;Humans;Male;Systole;Wireless Technology}, 
doi={10.1109/EMBC.2016.7591820}, 
ISSN={1557-170X}, 
month={Aug},}
@ARTICLE{8085385, 
author={P. Fang and X. Ma and X. Li and X. Qiu and R. Gerhard and X. Zhang and G. Li}, 
journal={IEEE Sensors Journal}, 
title={Fabrication, Structure Characterization, and Performance Testing of Piezoelectret-Film Sensors for Recording Body Motion}, 
year={2018}, 
volume={18}, 
number={1}, 
pages={401-412}, 
abstract={During muscle contractions, radial-force distributions are generated on muscle surfaces due to muscle-volume changes, from which the corresponding body motions can be recorded by means of so-called force myography (FMG). Piezo-or ferroelectrets are flexible piezoelectric materials with attractive materials and sensing properties. In addition to several other applications, they are suitable for detecting force variations by means of wearable devices. In this paper, we prepared piezoelectrets from cellular polypropylene films by optimizing the fabrication procedures, and developed an FMG-recording system based on piezoelectret sensors. Different hand and wrist movements were successfully detected on able-bodied subjects with the FMG system. The FMG patterns were evaluated and identified by means of linear discriminant analysis and artificial neural network algorithms, and average motion-classification accuracies of 96.1% and 94.8%, respectively, were obtained. This paper demonstrates the feasibility of using piezoelectret-film sensors for FMG and may thus lead to alternative methods for detecting body motion and to related applications, e.g., in biomedical engineering or structural-health monitoring.}, 
keywords={biomedical measurement;biomedical transducers;cellular biophysics;computerised instrumentation;electrets;force measurement;force sensors;medical computing;motion measurement;muscle;neural nets;piezoelectric thin films;piezoelectric transducers;polymer films;polymer foams;recorders;thin film sensors;FMG-recording system;artificial neural network algorithm;biomedical engineering;body motion detection;body motion recording;cellular polypropylene film;ferroelectret;force myography;force sensor;linear discriminant analysis;muscle contraction;muscle surface generation;performance testing;piezoelectret-film sensor;piezoelectric material;radial-force distribution;structural-health monitoring;structure characterization;wearable device;Accelerometers;Dynamics;Electrodes;Films;Force;Muscles;Sensors;Forcemyography;film sensor;motion registration;piezoelectret;wearable}, 
doi={10.1109/JSEN.2017.2766663}, 
ISSN={1530-437X}, 
month={Jan},}
@INPROCEEDINGS{7515456, 
author={R. Gao and Z. M. Jiang and C. Barna and M. Litoiu}, 
booktitle={2016 IEEE International Conference on Software Testing, Verification and Validation (ICST)}, 
title={A Framework to Evaluate the Effectiveness of Different Load Testing Analysis Techniques}, 
year={2016}, 
volume={}, 
number={}, 
pages={22-32}, 
abstract={Large-scale software systems like Amazon and eBay must be load tested to ensure they can handle hundreds and millions of current requests in the field. Load testing usually lasts for a few hours or even days and generates large volumes of system behavior data (execution logs and counters). This data must be properly analyzed to check whether there are any performance problems in a load test. However, the sheer size of the data prevents effective manual analysis. In addition, unlike functional tests, there is usually no test oracle associated with a load test. To cope with these challenges, there have been many analysis techniques proposed to automatically detect problems in a load test by comparing the behavior of the current test against previous test(s). Unfortunately, none of these techniques compare their performance against each other. In this paper, we have proposed a framework, which evaluates and compares the effectiveness of different test analysis techniques. We have evaluated a total of 23 test analysis techniques using load testing data from three open source systems. Based on our experiments, we have found that all the test analysis techniques can effectively build performance models using data from both buggy or non-buggy tests and flag the performance deviations between them. It is more cost-effective to compare the current test against two recent previous test(s), while using testing data collected under longer sampling intervals (≥180 seconds). Among all the test analysis techniques, Control Chart, Descriptive Statistics and Regression Tree yield the best performance. Our evaluation framework and findings can be very useful for load testing practitioners and researchers. To encourage further research on this topic, we have made our testing data publicity available to download.}, 
keywords={control charts;large-scale systems;program testing;public domain software;regression analysis;statistics;trees (mathematics);Amazon;control chart;descriptive statistics;eBay;large-scale software systems;load testing analysis;open source systems;regression tree;Data mining;Data models;Load modeling;Queueing analysis;Radiation detectors;Testing;Topology}, 
doi={10.1109/ICST.2016.9}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{6281507, 
author={J. P. H. Knauss and C. Warren and D. Kearns}, 
booktitle={PES T D 2012}, 
title={An innovative approach to smart automation testing at National Grid}, 
year={2012}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={Upon completion of a successful Distribution Automation (DA) Pilot Project centered in National Grid's upstate New York service territory, it was determined that the reliability improvements delivered by the pilot demonstration justified a much more comprehensive effort to further evaluate additional Smart Grid technologies. The vision was to conduct experiments with a full suite of Smart Grid technologies including: AMI; Home Area Network and energy management systems; Automatic Fault Isolation & System Restoration; advanced feeder monitoring; distribution transformer monitoring; single pole tripping and Pulse Closing technology on distribution line reclosers; advanced capacitor control with independent pole operation; faulted circuit indicators with 2-way communication capability; and distribution fault locating capability. This vision came to be known as National Grid's Smart Grid Pilot proposal. Many challenges exist with such a comprehensive approach from public and personnel safety, to ensuring interoperability between devices and systems of different manufacture. In order to determine which technologies would provide the most benefit to National Grid's customer base, a means was needed to prequalify the various types of products available before large scale deployments were initiated. Looking at the large number of Smart Grid device suppliers, architectures and products available, we realized that the optimum solution would be to build a facility wherein a wide range of Smart Grid technologies could be installed and systematically put through their paces; i.e. actually tested in as near a real-world atmosphere as practical. Thus was born the National Grid “Smart Technology Centre” or STC. Soon thereafter, National Grid's Utility of the Future engineering team designed, engineered, and constructed a truly innovative test fixture that enabled system level testing on complex distribution networks to ensure process safety during field de- loyment. One of only a few known organizations in the U.S., National Grid has in-house capability to truly test and evaluate an end-to-end Smart distribution system architecture where systems such as automated fault isolation and system restoration can be evaluated. This paper will discuss interoperability testing that National Grid embarked upon to prepare for its proposed Smart Grid Pilot demonstration and will detail the lengths that were taken in creating a test site where medium voltage Smart Grid technologies could be fully evaluated to ensure that the various applications would play well with each other prior to actually being deployed in the field. Furthermore, this paper will focus on providing an overview of the system level testing and technical evaluation of distribution protection and control equipment with automated fault isolation and system restoration capabilities. It will also detail a number of lessons learned from this effort and discuss future plans for smart technology evaluation as a basis for an educational platform and workforce training tool.}, 
keywords={automatic testing;control equipment;electrical safety;fault location;open systems;power distribution control;power distribution protection;power distribution reliability;power engineering computing;power system restoration;smart power grids;2-way communication capability;AMI;DA Pilot Project;National Grid;New York service territory;STC;Smart Technology Centre;advanced capacitor control;advanced feeder monitoring;automatic fault isolation;automatic system restoration;complex distribution network testing;control equipment;distribution automation;distribution fault locating capability;distribution line reclosers;distribution protection;distribution transformer monitoring;educational platform;end-to-end smart distribution system architecture;energy management systems;faulty circuit indicators;home area network;interoperability;large scale deployments;medium voltage smart grid technologies;personnel safety;process safety;public safety;pulse closing technology;reliability improvements;single pole tripping;smart automation testing;smart grid device suppliers;smart grid pilot demonstration;smart technology evaluation;system level testing;workforce training tool;Automation;Circuit faults;Control systems;Monitoring;Safety;Smart grids;Testing}, 
doi={10.1109/TDC.2012.6281507}, 
ISSN={2160-8555}, 
month={May},}
@INPROCEEDINGS{5635852, 
author={Y. Liu and B. Du and S. Wang and H. Yang and X. Wang}, 
booktitle={2010 First International Conference on Pervasive Computing, Signal Processing and Applications}, 
title={Design and Implementation of Performance Testing Utility for RTSP Streaming Media Server}, 
year={2010}, 
volume={}, 
number={}, 
pages={193-196}, 
abstract={RTSP has been widely used in a variety of streaming media applications and streaming service providers hope to choose a high-performance streaming media server to meet their needs, so it is an important research topic about how to evaluate the serving performance of RTSP streaming media server. This paper analyzes the performance metric of streaming media applications comprehensively, and proposes an approach to design and implement a Performance Testing Utility for RTSP Streaming Server. According to different stress test, the utility mainly evaluates a streaming server's performance in the case of delivering a large number of concurrent streams and quantifies the statistics of various performance metrics. The tool utilizes multi-thread mechanism to create multiple pseudo-terminal instances to simulate a certain number of concurrent users for sending RTSP signals, receives media flow by a special IP address, analyzes RTP packets, and counts the related performance metrics value of the server. Experiments validate the efficiency and accuracy of the tool.}, 
keywords={media streaming;multi-threading;multimedia servers;performance evaluation;protocols;IP address;RTP packets;RTSP streaming media server;multiple pseudo-terminal instances;multithread mechanism;performance metric;performance testing utility;real-time streaming protocol;streaming server performance evaluation;streaming service providers;Measurement;Media;Protocols;Real time systems;Servers;Streaming media;Testing;Concurrent streams;Media flow;Performance metrics;Streaming media server;Testing utility}, 
doi={10.1109/PCSPA.2010.55}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{7793853, 
author={F. Schloegl and M. Buescher and K. Diwold and S. Lehnhoff and L. Fischer and F. Zeilinger and T. Gawron-Deutsch}, 
booktitle={IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society}, 
title={Performance testing Smart Grid applications using a distributed co-simulation approach}, 
year={2016}, 
volume={}, 
number={}, 
pages={6305-6310}, 
abstract={Co-simulation is an established approach for Smart Grid simulations as it allows to break down the very complex system into sub-systems. The modularity of co-simulation environments makes easy to distribute it across different sites. One reason for such a distribution may be, that this way confidential software can stay within its secure domain. However the transmission of data between the sites is time consuming. This paper demonstrates how Smart Grid applications can be tested using a co-simulation approach. It investigates the costs of such an approach by measuring the time required for data transmission in a case study.}, 
keywords={data communication;power system security;smart power grids;data transmission;distributed cosimulation;smart grid;Computational modeling;Data models;Hardware;Load modeling;Smart grids;Software;Topology}, 
doi={10.1109/IECON.2016.7793853}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6958400, 
author={J. Zhou and B. Zhou and S. Li}, 
booktitle={2014 14th International Conference on Quality Software}, 
title={LTF: A Model-Based Load Testing Framework for Web Applications}, 
year={2014}, 
volume={}, 
number={}, 
pages={154-163}, 
abstract={Performance evaluation is an important approach for various systems to guarantee the quality of their services. However, most performance evaluation tasks face a problem: how to model the system workload? Traditional workload models have limitations when it comes to modeling different workloads. In this paper, we propose a workload model for characterizing and generating synthetic web workloads. First, we introduce a Context-based Sequential Action Model to describe users that exhibit similar access patterns. Next, we present a Workload Parameter Specification Language to describe workload parameters for workload generation. Then, we introduce our load-testing framework based on the proposed model. The representativeness and features of our model are demonstrated by comparing it to other models. Experiments show that our framework can generate accurate and stable synthetic workloads.}, 
keywords={Internet;software performance evaluation;specification languages;LTF;Web applications;context-based sequential action model;model-based load testing framework;performance evaluation;synthetic Web workloads;workload generation;workload model;workload parameter specification language;Computational modeling;Context;Context modeling;Load modeling;Testing;Unified modeling language;load testing;model;performance;workload characterization}, 
doi={10.1109/QSIC.2014.53}, 
ISSN={1550-6002}, 
month={Oct},}
@INPROCEEDINGS{524640, 
author={K. Roy and R. K. Roy and A. Chatterjee}, 
booktitle={1995 International Symposium on VLSI Technology, Systems, and Applications. Proceedings of Technical Papers}, 
title={Stress testing of combinational VLSI circuits using existing test sets}, 
year={1995}, 
volume={}, 
number={}, 
pages={93-98}, 
abstract={We present a stress testing method which can provide an attractive low-cost alternative to burn-in. The technique is based on reordering of test vectors such that a desired circuit activity or electrical stress is generated across the VLSI chip while achieving a high coverage for stuck-at defects. The test methodology can also be used to generate localized electrical or thermal stress in a circuit. Such testing procedure can be important for weeding out circuits with infant mortality problems. Experimental results on benchmark circuits show that the stress requirements can be changed by more than a factor of 4 by reordering the stuck-at test vectors}, 
keywords={CMOS logic circuits;VLSI;combinational circuits;integrated circuit testing;integrated logic circuits;logic testing;combinational VLSI circuits;infant mortality problems;localized electrical stress;localized thermal stress;stress testing method;stuck-at defects;test vectors reordering;Circuit faults;Circuit testing;Costs;Current density;Monitoring;National electric code;Ovens;Temperature;Thermal stresses;Very large scale integration}, 
doi={10.1109/VTSA.1995.524640}, 
ISSN={1524-766X}, 
month={May},}
@INPROCEEDINGS{7436040, 
author={A. Shojaee and N. Agheli and B. Hosseini}, 
booktitle={2015 2nd International Conference on Knowledge-Based Engineering and Innovation (KBEI)}, 
title={Cloud-based load testing method for web services with VMs management}, 
year={2015}, 
volume={}, 
number={}, 
pages={170-176}, 
abstract={Due to the increased loading the large number of users connected to pervasive web services during the past decade, their load testing and providing the needed resources in low time and cost, requires more attention. In this context cloud computing technology offers new ideas to solve such problems and has reduced the concern of large and complex testing systems. In this research in order to improve the quality and performance of web applications load testing, we proposed a method for web applications load testing based on cloud computing. The proposed method uses the existing facilities in the cloud including pool of computing resources without initial cost, unlimited data storage and cloud computing managerial procedures, containing the actual load generating and multi-user concurrency testing, that lead to improved load testing flexibility, time and operational costs. Moreover, in this load testing method, in order to manage resources and virtual machines, significant improvement is achieved by use of appropriate allocation, reducing performance and unnecessary migration avoiding methods. Through evaluation section of the proposed method through a simulated test environment, it is shown that cloud-based load testing in comparison with traditional methods of load testing, improves factors such as effort, cost and time.}, 
keywords={Web services;cloud computing;program testing;resource allocation;ubiquitous computing;virtual machines;VM management;Web applications load testing performance;Web applications load testing quality;cloud computing technology;cloud-based load testing method;computing resources pool;load generation;multiuser concurrency testing;pervasive Web services;resource management;virtual machines;Cloud computing;Decision support systems;Handheld computers;Systems architecture;Testing;Virtual machining;Cloud Computing;Load Testing;VMs;Web Service}, 
doi={10.1109/KBEI.2015.7436040}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{367502, 
author={H. A. Chan}, 
booktitle={1994 Proceedings. 44th Electronic Components and Technology Conference}, 
title={A formulation to optimize stress testing}, 
year={1994}, 
volume={}, 
number={}, 
pages={1020-1027}, 
abstract={Although hard-defects may be detectable in factory tests, weak products may exhibit failures or degrade only under certain stress conditions. Without stress testing, these weak products may often be shipped to customers causing early failures in the field. A candidate product for stress testing needs to get more business benefits to more than pay off the cost of stress testing. A business measure of the success of the stress testing program is the net benefit, which is the total benefit minus the total cost of the program. The optimum stress testing program maximizes this net benefit. A given unit of a product has a probability of encountering a maximum stress X during its product life. It also has a probability of possessing a product yield strength Y, which is the maximum stress the unit can survive without failure. While the strength distribution depends on the design and manufacture processes, the distribution of the maximum stress is determined by the customers' environment. A convenient picture is to construct the contour map of the joint probability distribution of X and Y. In this contour map, a unit falling in the Y<X region will fail during its product life, whereas one falling in the Y>X region will not result in field failure. The effects of stress testing at a given maximum stress level, XST, are shown by a dividing line on the product strength into stress test failure and stress test pass. The units in the contour map are then divided into four regions by the Y=X line and the XST line. The cost and benefits may now be evaluated for each region. Now the value of XST is a free parameter that determines the relative size of each region. The second free parameter is the fraction of units going through stress testing. These two parameters may be adjusted to maximize the net benefit of the stress testing program}, 
keywords={circuit optimisation;environmental stress screening;environmental testing;failure analysis;integrated circuit yield;life testing;probability;production testing;contour map;early failures;factory tests;joint probability distribution;maximum stress;net benefit;product life;product yield strength;stress conditions;stress test failure;stress test pass;stress testing;Circuit testing;Costs;Degradation;Electronic equipment testing;Manufacturing processes;Probability distribution;Process design;Production facilities;Stress measurement;System testing}, 
doi={10.1109/ECTC.1994.367502}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{5325380, 
author={H. Kim and B. Choi and W. E. Wong}, 
booktitle={2009 Third IEEE International Conference on Secure Software Integration and Reliability Improvement}, 
title={Performance Testing of Mobile Applications at the Unit Test Level}, 
year={2009}, 
volume={}, 
number={}, 
pages={171-180}, 
abstract={With the rapid growth of the wireless market and the development of various mobile devices, innovative methods and technologies to produce high-quality mobile applications and reduce time to market have been emerging. Mobile applications are often characterized by an array of limitations such as the short development lifecycle to gain a competitive advantage and difficulties to update once released. Hence, rigorous testing on the applications is required before distribution to the market, including structural white-box, functional black-box, integration and system testing. Although recently performance testing at the system test level has become crucial given its direct connection with the product quality improvement, most such tests are confined to the areas of load, usability, and stress testing. Moreover, the implementation itself is insufficient due to the limitations of the development environment. This paper proposes a method to support performance testing utilizing a database established through benchmark testing in emulator-based test environment at the unit test level. It also presents the tool that supports the proposed method of performance testing and verifies the reliability of performance test results through experiments.}, 
keywords={integrated software;program testing;emulator-based test environment;functional black-box;integration;mobile applications;performance testing;structural white-box;system testing;unit test level;wireless market;Application software;Benchmark testing;Computer science;Databases;Mobile computing;Process control;Software performance;Software testing;Stress;System testing;emulator-based test;mobile application;performance test;unit test}, 
doi={10.1109/SSIRI.2009.28}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{929479, 
author={L. Angrisani and A. Baccigalupi and G. D'Angiolo}, 
booktitle={IMTC 2001. Proceedings of the 18th IEEE Instrumentation and Measurement Technology Conference. Rediscovering Measurement in the Age of Informatics (Cat. No.01CH 37188)}, 
title={A frame-level measurement apparatus for performance testing of ATM equipment}, 
year={2001}, 
volume={3}, 
number={}, 
pages={1630-1635 vol.3}, 
abstract={Performance testing of ATM equipment is here dealt with. In particular, the attention is paid to frame-level metrics, recently proposed by the ATM forum because of their suitability to reflect user-perceived performance better than traditional cell-level metrics. Following the suggestions of the ATM forum, more and more network engineers and production managers are nowadays interested in these metrics, thus increasing the need of instruments and measurement solutions appropriate to their estimation. Trying to satisfy this exigency, a new VXI-based measurement apparatus is proposed in the paper. The apparatus features a suitable software, developed by the authors, which allows the evaluation of the aforementioned metrics by making simply use of common ATM analyzers; only two VXI line interfaces, capable of managing both the physical and ATM layer, are, in fact, adopted. At first, some details about the hierarchical structure of the ATM technology as used as the main differences between frames, peculiar to the ATM adaptation layer, and cells characterizing the lower ATM layer are given. Then, both the hardware and software solutions of the measurement apparatus are described in detail with a particular attention to the measurement procedures implemented. At the end the performance of a new ATM device, developed by Ericsson, is assessed in terms of frame-level metrics by means of the proposed apparatus}, 
keywords={asynchronous transfer mode;automatic test equipment;performance evaluation;peripheral interfaces;telecommunication equipment testing;ATM adaptation layer;ATM equipment;Ericsson;VXI line interfaces;VXI-based measurement apparatus;common ATM analyzers;frame-level measurement;frame-level metrics;hardware;hierarchical structure;performance testing;software;user-perceived performance;3G mobile communication;Asynchronous transfer mode;B-ISDN;Communication switching;GSM;Particle measurements;Quality of service;Software measurement;Telecommunication switching;Testing}, 
doi={10.1109/IMTC.2001.929479}, 
ISSN={1091-5281}, 
month={},}
@INPROCEEDINGS{4297593, 
author={V. Yakovyna and D. Fedasyuk and M. Seniv and O. Bilas}, 
booktitle={2007 9th International Conference - The Experience of Designing and Applications of CAD Systems in Microelectronics}, 
title={The Performance Testing of RSA Algorithm Software Realization}, 
year={2007}, 
volume={}, 
number={}, 
pages={390-392}, 
abstract={The software realization of RSA public key encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested. The present paper shows, that the encryption rate is 306.4 plusmn 0.6 kbytes/sec, while the coefficient of encryption time increasing with file size increasing is 3.299. It is concluded that the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.}, 
keywords={application program interfaces;network operating systems;public key cryptography;.NET platform;CryptoAPI;RSA algorithm software realization;RSA public key encryption algorithm;coefficient-of-encryption time;cryptographic software;encryption rate;flexible architecture independent tool;public-key cryptography;secure implementation;Algorithm design and analysis;Application software;Costs;Hardware;Public key;Public key cryptography;Software algorithms;Software performance;Software quality;Software testing;.NET;Operation performance;Public-key cryptography;RSA algorithm;Software realization}, 
doi={10.1109/CADSM.2007.4297593}, 
ISSN={}, 
month={Feb},}
@INPROCEEDINGS{4639351, 
author={A. Bertolino and G. De Angelis and A. Sabetta}, 
booktitle={2008 23rd IEEE/ACM International Conference on Automated Software Engineering}, 
title={VCR: Virtual Capture and Replay for Performance Testing}, 
year={2008}, 
volume={}, 
number={}, 
pages={399-402}, 
abstract={This paper proposes a novel approach to performance testing, called virtual capture and replay (VCR), that couples capture and replay techniques with the checkpointing capabilities provided by the latest virtualization technologies. VCR enables software performance testers to automatically take a snapshot of a running system when certain critical conditions are verified, and to later replay the scenario that led to those conditions. Several in-depth analyses can be separately carried out in the laboratory just by rewinding the captured scenario and replaying it using different probes and analysis tools.}, 
keywords={program testing;virtual reality;VCR;checkpointing capabilities;software performance testing;virtual capture;virtual replay;virtualization technologies;Automatic testing;Checkpointing;Monitoring;Paper technology;Performance analysis;Software performance;Software testing;Space technology;System testing;Video recording}, 
doi={10.1109/ASE.2008.58}, 
ISSN={1938-4300}, 
month={Sept},}
@INPROCEEDINGS{4297591, 
author={V. Yakovyna and D. Fedasyuk and M. Seniv}, 
booktitle={2007 9th International Conference - The Experience of Designing and Applications of CAD Systems in Microelectronics}, 
title={Software Realization and Performance Testing of DES Cryptographic Algorithm on the .NET Platform}, 
year={2007}, 
volume={}, 
number={}, 
pages={386-388}, 
abstract={The software realization of DES symmetric encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested and it was shown, that the encryption rate is 11.1 Mb/sec on the Intel Celeron D 351 3.2 GHz processor, while the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.}, 
keywords={computer software;cryptography;.NET platform;DES symmetric encryption algorithm;Intel Celeron D 351 3.2 GHz processor;data encryption standard;software implementation;software realization;Algorithm design and analysis;Application software;Cryptography;Hardware;Protection;Software algorithms;Software performance;Software quality;Software testing;Software tools;.NET;CryptoAPI;DES algorithm;Software realization;Symmetric cryptography}, 
doi={10.1109/CADSM.2007.4297591}, 
ISSN={}, 
month={Feb},}
@INPROCEEDINGS{5777983, 
author={Zhang Xinfeng and Shen Yong and SongGe}, 
booktitle={2011 International Conference on Electric Information and Control Engineering}, 
title={Stress testing on car remote monitoring system}, 
year={2011}, 
volume={}, 
number={}, 
pages={1715-1718}, 
abstract={A virtual on-board concurrent user based remote monitoring system stress testing method is proposed. First, the scenario of maximum concurrent users is obtained through system analysis and the method is proposed. Second, the virtual on-board concurrent users are realized by computer data generation and coding according to package protocol. Finally, a case study of stress testing is done. It is turned out that the remote monitoring system's performance can be effectively evaluated by such test method, and the maximum number of concurrent users also can be predicted.}, 
keywords={automobile industry;automotive engineering;computerised monitoring;mechanical engineering computing;stress analysis;car remote monitoring system;computer data coding;computer data generation;package protocol;stress testing method;system analysis;virtual on-board concurrent user;Real time systems;Remote monitoring;Servers;Software;Stress;Testing;New energy Car;Remote monitoring system;Stress Test;virtual on-board terminal}, 
doi={10.1109/ICEICE.2011.5777983}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{659249, 
author={H. H. Schurig and M. A. Kruer and M. N. Levesque and E. M. Gaddy and W. J. Andiario}, 
booktitle={IECEC-97 Proceedings of the Thirty-Second Intersociety Energy Conversion Engineering Conference (Cat. No.97CH6203)}, 
title={Performance testing of the 5 kW EOS AM-1 flexible solar array blanket}, 
year={1997}, 
volume={1}, 
number={}, 
pages={550-555 vol.1}, 
abstract={A GaAs/Ge flexible solar array blanket has been developed for use on the NASA/GSFC remote sensing EOS AM-1 spacecraft. This single wing array has been designed to provide 5 kW of power after five years in a low Earth polar orbit. The blanket configuration includes design features such as thin GaAs/Ge cell stacks mounted on a large flexible, hinged substrate, parallel connected solar cell strings providing high voltage output, a printed circuit harness, and a multi-layer jumper bus providing electrical continuity between the cell strings and the printed circuit harness. This work was contracted to TRW Space and Electronics Group in 1993 by Lockheed Martin Missiles & Space (LMMS). This paper presents the essential design of the EOS AM-1 solar array blanket, and summarizes the results of a qualification test program designed to demonstrate adequate design margins and to assess the performance of the mechanical and electrical components after exposure to a simulated mission space environment. It also reviews the complexities of performing electrical output testing on a 8.9 m×5.0 m deployed solar array blanket under AM0 conditions}, 
keywords={III-V semiconductors;aerospace testing;artificial satellites;elemental semiconductors;gallium arsenide;germanium;photovoltaic power systems;semiconductor device testing;solar cell arrays;space vehicle power plants;5 kW;5 m;8.9 m;AM0 conditions;EOS AM-1 spacecraft;GaAs-Ge;design features;flexible solar array blanket;low Earth polar orbit;mission space environment;performance testing;qualification test program;single wing array;Earth Observing System;Flexible printed circuits;Gallium arsenide;Missiles;NASA;Photovoltaic cells;Remote sensing;Space vehicles;Testing;Voltage}, 
doi={10.1109/IECEC.1997.659249}, 
ISSN={}, 
month={Jul},}
@INPROCEEDINGS{7492562, 
author={C. Gavrilă and C. Z. Kertész}, 
booktitle={2016 International Conference on Development and Application Systems (DAS)}, 
title={Automated performance testing of end-to-end streaming solutions over HbbTV architecture}, 
year={2016}, 
volume={}, 
number={}, 
pages={135-138}, 
abstract={This paper presents an automated test execution environment designed to analyze the accessibility, reliability and streaming performance of an end-to-end Hybrid broadcast broadband TV (HbbTV) solution. Its purpose is to provide the means for the TV providers to test their HbbTV solution by simulating real-world scenarios and online functioning in a local, offline environment, before making it available for the end users. This way, common problems like server overload, poor streaming quality and HbbTV incorrect functionality can be foreseen and corrected.}, 
keywords={Computer architecture;Digital TV;Measurement;Servers;Simple object access protocol;Testing;Automated testing;HbbTV;Network conditions simulation;Streaming media;Web services}, 
doi={10.1109/DAAS.2016.7492562}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{6154026, 
author={X. Yan and F. Wen and C. Fan and X. Wang}, 
booktitle={2011 First International Conference on Instrumentation, Measurement, Computer, Communication and Control}, 
title={Performance Testing of Open Laboratory Management System Based on LoadRunner}, 
year={2011}, 
volume={}, 
number={}, 
pages={164-167}, 
abstract={Open Laboratory Management System provides an open virtual experiment environment for students, so that its system performance immediately impacts the quality of students learning. According to analyze the performance requirements of Open Laboratory Management System, the author discovers performance testing points, implements automated performance testing for performance testing points of the system based on Load Runner. In this paper, taking the students login for example, it elaborates testing process and provides the reference for system optimization.}, 
keywords={computer aided instruction;laboratories;program testing;virtual reality;LoadRunner;open laboratory management system;student learning;student login;testing process;virtual experiment environment;Educational institutions;Laboratories;Monitoring;Protocols;Time factors;LoadRunner;Open Laboratory Management System;performance testing}, 
doi={10.1109/IMCCC.2011.50}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{651034, 
author={D. C. Leonard}, 
booktitle={Proceedings: Electrical Insulation Conference and Electrical Manufacturing and Coil Winding Conference}, 
title={Simplifying motor performance testing in the production environment}, 
year={1997}, 
volume={}, 
number={}, 
pages={185-190}, 
abstract={The objective of this paper is to illustrate how performance test systems on the factory floor can be enhanced by utilizing the power and speed of integral computer hardware and software to automate and simplify tasks typically performed in the production environment. The first part of this paper discusses why the test system is needed to perform additional tasks. The second section defines the relationships between various departments within the organization, and the test system. The third section discusses the benefits of integrating additional functions into the test system. The final sections of the paper discusses incorporating artificial intelligence and networking to simplify tasks associated with the production environment}, 
keywords={artificial intelligence;automatic testing;computer networks;electric motors;machine testing;power engineering computing;production testing;additional functions integration;artificial intelligenc;integral computer hardware;integral computer software;motor performance testing;networking;production environment;test system}, 
doi={10.1109/EEIC.1997.651034}, 
ISSN={0362-2479}, 
month={Sep},}
@INPROCEEDINGS{472644, 
author={Chih-Ang Chen and S. K. Gupta}, 
booktitle={Electro/94 International. Conference Proceedings. Combined Volumes.}, 
title={BIST/DFT for performance testing of bare dies and MCMs}, 
year={1994}, 
volume={}, 
number={}, 
pages={803-812}, 
abstract={High emphasis on performance and high cost of MCM repairs necessitates a frame work for performance testing of dies, substrates, and final MCMs. Application of performance tests to bare dies is very expensive due to the need for small and high speed probes and ATE, BIST, scan, and boundary scan can provide a framework to accomplish performance testing in a cost effective manner. It has been shown that traditional BIST, scan, and boundary scan techniques do not provide the framework for performance testing. Special BIST and scan design techniques that can be employed to guarantee high coverage of delay faults are described. Typically, these techniques produce BIST test pattern generators and scan chain designs that require slightly increased hardware overhead over conventional BIST/scan. However, they can drastically decrease the complexity of bare die performance testing. Furthermore, when used in combination with the proposed enhanced boundary scan design, they provide a framework for detection and diagnosis of dynamic failures}, 
keywords={built-in self test;fault diagnosis;multichip modules;substrates;BIST;MCMs;bare dies;boundary scan;delay faults;dynamic failures;performance testing;scan;Built-in self-test;Circuit faults;Costs;Delay;Economic forecasting;Integrated circuit interconnections;Logic testing;Parasitic capacitance;Probes;System testing}, 
doi={10.1109/ELECTR.1994.472644}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{6532032, 
author={S. Rangaraj and D. Kwon and M. Pei and J. Hicks and G. Leatherman and A. Lucero and T. Wilson and S. Streit and J. He}, 
booktitle={2013 IEEE International Reliability Physics Symposium (IRPS)}, 
title={Accelerated stress testing methodology to risk assess silicon-package thermomechanical failure modes resulting from moisture exposure under use condition}, 
year={2013}, 
volume={}, 
number={}, 
pages={5C.3.1-5C.3.5}, 
abstract={IC components are exposed to moisture and thermal cycles during chip-package-board assembly and in their end use conditions. Moisture exposure influences the mechanical integrity of silicon backend dielectrics, assembly/packaging materials and packages. Reliability performance under accelerated stresses that simulate use conditions are often a critical factor in choice of materials, processing options and design rules. A complete assessment of the cumulative environmental exposure from chip-package assembly, shipment/storage, board system assembly, through end-customer use is required to guarantee product performance and reliability. This paper will detail these end user environments and use failure mode/mechanism specific acceleration models to develop accurate accelerated life testing plans and requirements. These requirements will then be compared to JEDEC standards based requirements and a need for re-calibration of these standards to more appropriate temperatures and stress durations will be highlighted.}, 
keywords={assembling;failure analysis;integrated circuit packaging;integrated circuit reliability;integrated circuit testing;life testing;risk management;stress analysis;IC components;JEDEC standards;accelerated life testing plans;accelerated stress testing methodology;assembly-packaging materials;board system assembly;chip-package-board assembly;cumulative environmental exposure;design rules;end user environments;failure mode-mechanism specific acceleration models;mechanical integrity;moisture cycle;moisture exposure;processing options;product performance;reliability performance;risk assessment;silicon backend dielectrics;silicon-package thermomechanical failure modes;standard re-calibration;stress durations;thermal cycle;through end-customer use;Acceleration;Materials;Mathematical model;Moisture;Reliability;Standards;Stress;HAST;JEDEC standard;acceleration model;moisture;thermal cyclin;use conditions}, 
doi={10.1109/IRPS.2013.6532032}, 
ISSN={1541-7026}, 
month={April},}
@INPROCEEDINGS{6605950, 
author={C. H. Kao and C. C. Lin and J. N. Chen}, 
booktitle={2013 13th International Conference on Quality Software}, 
title={Performance Testing Framework for REST-Based Web Applications}, 
year={2013}, 
volume={}, 
number={}, 
pages={349-354}, 
abstract={Recently, enterprises, organizations, and software companies are building more and more web applications to provide their services over the Internet. In order to fulfill various requirements, the complexity of web applications nowadays is increasing dramatically. As a result, the performance characteristics of web applications, including response time, throughput, etc, become more critical than before and should be taken into careful consideration. If the response time of a web application is poor, users may lose their interests even the function of the web application is correct. Therefore, how to execute performance testing on a complex web application systematically and efficiently will be an important issue. In this paper, a performance testing framework for REST-based web applications is introduced. The performance testing framework aims to provide software testers with an integrated process from test cases design, test scripts generation, to test execution. Based on the test cases designed by software testers and the appropriate software artifacts preserved by the framework (e.g., API document), the framework generates the corresponding performance test scripts, which can be executed by specific performance test tools. This helps software testers to focus more in the design of performance test cases. In addition, effort needed to understand the design and implementation of the application and to learn the operation of testing tools decrease. Thus, the efficiency of performance testing can be highly facilitated.}, 
keywords={Internet;program testing;Internet;REST-based Web applications;performance test scripts;performance test tools;performance testing framework;representational state transfer;software artifacts;software companies;software testers;test cases design;test execution;test scripts generation;Complexity theory;Computer architecture;Engines;Software;Testing;Time factors;XML;Performance testing;software testing;web application}, 
doi={10.1109/QSIC.2013.32}, 
ISSN={1550-6002}, 
month={July},}
@INPROCEEDINGS{7968862, 
author={L. Capelli and S. Sironi}, 
booktitle={2017 ISOCS/IEEE International Symposium on Olfaction and Electronic Nose (ISOEN)}, 
title={Monitoring odour emisssions from an oil gas plant: Electronic nose performance testing in the field}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-3}, 
abstract={This paper focuses on performance testing of electronic noses for environmental odour monitoring in terms of their capability of correctly classifying odours at low odour concentrations. The studied case concerns the realization of an electronic nose network for the continuous monitoring of odour emissions from a crude oil extraction and separation plant. The novelty of the work consists in the fact that performance testing, which is typically carried out in laboratory before installation in the field for environmental odour monitoring outside the plant boundaries, in this case was carried out after installation with the aim of testing the instruments performances in the effective working conditions. This involved the necessity to develop a specific and repeatable procedure to obtain samples at known quality and concentration in the field. Electronic nose performance was evaluated in terms of classification accuracy, which produced satisfactory results towards the considered olfactory classes.}, 
keywords={chemical variables measurement;crude oil;electronic noses;gas industry;crude oil extraction;electronic nose network;environmental odour emisssion monitoring;gas plant;oil plant;olfactory class;performance testing;separation plant;Earth Observing System;Electronic noses;Instruments;Liquids;Monitoring;Oils;Testing;continuous odour monitoring;electronic nose;odour concentration;performance testing;sample preparation}, 
doi={10.1109/ISOEN.2017.7968862}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{6974152, 
author={S. Lee and J. Y. Jo and Y. Kim}, 
booktitle={2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
title={Performance testing of web-based data visualization}, 
year={2014}, 
volume={}, 
number={}, 
pages={1648-1653}, 
abstract={Many scientific applications generate massive data that requires visualization. For example, the Nevada Solar Energy-Water-Environmental Nexus project has been generating a large amount of environmental monitoring data in textual format. As the data is available on the web, a web-based visualization tool is desirable for the project rather than a standalone tool. This research analyzes the processing mechanisms of four popular web-based data visualization tools, that is, Google Charts, Flex, OFC, D3, and compares their performances. A standalone visualization tool, JfreeChart, have been also used for comparison. The processing times have been divided into three segments, layout time, data transformation time, and rendering time, and separately measured. The actual temperature data from the Nevada Nexus project has been used for testing in different scales ranging from 100 to 100,000 data points. The result shows that each visualization tool has its own ideal environment.}, 
keywords={Internet;data visualisation;environmental monitoring (geophysics);rendering (computer graphics);scientific information systems;D3;Flex;Google Charts;JfreeChart;Nevada Solar Energy-Water-Environmental Nexus project;OFC;Web-based data visualization tools;data transformation time;environmental monitoring data;layout time;performance testing;rendering time;scientific applications;standalone visualization tool;textual format;Browsers;Data visualization;Flexible printed circuits;Google;Libraries;Rendering (computer graphics);Servers;D3.js;Data Visualization;Flex;Google Charts;JFreeChart;Open Flash Chart;Sensor Data}, 
doi={10.1109/SMC.2014.6974152}, 
ISSN={1062-922X}, 
month={Oct},}
@INPROCEEDINGS{4483205, 
author={S. Chen and D. Moreland and S. Nepal and J. Zic}, 
booktitle={19th Australian Conference on Software Engineering (aswec 2008)}, 
title={Yet Another Performance Testing Framework}, 
year={2008}, 
volume={}, 
number={}, 
pages={170-179}, 
abstract={Performance testing is one of the vital activities spanning the whole life cycle of software engineering. While there are a considerable number of performance testing products and open source tools available, they are either too expensive and complicated for small projects, or too specific and simple for diverse performance tests. This paper presents a general-purpose testing framework for both simple and small, and complicated and large-scale performance testing. Our framework proposes an abstraction to facilitate performance testing by separating the application logic from the common performance testing functionalities. This leads to a set of general-purpose data models and components, which form the core of the framework. The framework has been prototyped on both .NET and Java platforms and was used for a number of performance-related projects.}, 
keywords={Java;program testing;software performance evaluation;.NET platform;Java platform;general-purpose data model;general-purpose testing framework;performance testing framework;performance testing product;software engineering;Australia;Automatic testing;Data models;Grinding machines;Java;Life testing;Logic testing;Prototypes;Software engineering;Software testing}, 
doi={10.1109/ASWEC.2008.4483205}, 
ISSN={1530-0803}, 
month={March},}
@INPROCEEDINGS{4036666, 
author={B. H. Lim and J. R. Kim and K. H. Shim}, 
booktitle={2006 IEEE International Conference on Multimedia and Expo}, 
title={Hierarchical Load Testing Architecture using Large Scale Virtual Clients}, 
year={2006}, 
volume={}, 
number={}, 
pages={581-584}, 
abstract={In this work, we develop a hierarchical load testing architecture using large scale virtual clients to reduce the testing time and ensure the stability of the server for distributed applications. It explicitly secures the stability of the servers for networked virtual environment and at the same time, it elaborately generates actual loads for testing the performance of the servers. Our agent based load testing architecture provides variety of interactions of virtual entities in the virtual worlds to perform realistic simulations. Simulation results illustrate that our proposed architecture ensures the stability and capacity of the servers for both massively multiplayer online games and peer-to-peer network games}, 
keywords={client-server systems;computer games;peer-to-peer computing;performance evaluation;software agents;distributed application;hierarchical agent based load testing architecture;large scale networked virtual client-server environment;multiplayer online games;peer-to-peer network games;Computational modeling;Computer architecture;Computer industry;Electronic equipment testing;Large-scale systems;Network servers;Pervasive computing;Stability;System testing;Virtual environment}, 
doi={10.1109/ICME.2006.262475}, 
ISSN={1945-7871}, 
month={July},}
@INPROCEEDINGS{6903204, 
author={J. Zhou and B. Zhou and S. Li}, 
booktitle={2014 IEEE 38th International Computer Software and Applications Conference Workshops}, 
title={Automated Model-Based Performance Testing for PaaS Cloud Services}, 
year={2014}, 
volume={}, 
number={}, 
pages={644-649}, 
abstract={Recently, cloud computing has become popular for its unique advantages. Many applications have been migrated to cloud as web services. However, evaluating the performance of cloud services is non-trivial. Performance testing is one of the dominant techniques for evaluating system performance. In this paper, we present a model and template-based approach that automatically generates test scripts and test cases to measure service performance in an enterprise private cloud. We describe how load is generated automatically from our tool. Our empirical study shows the proposed approach can significantly decrease the cost of performance testing and help reveal potential performance issues.}, 
keywords={Web services;cloud computing;program testing;software performance evaluation;PaaS cloud services;Web services;automated model;cloud computing;enterprise private cloud;performance testing;Automation;Cloud computing;Computational modeling;Context;Load modeling;Testing;automated;cloud;performance testing;web service}, 
doi={10.1109/COMPSACW.2014.108}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{664526, 
author={J. Bisgrove and R. Dayao and B. Houser and T. Jones and J. C. Mayes and M. McGinnis and M. Schmidt and G. Skyles and B. K. Tan}, 
booktitle={1997 IEEE International Symposium on Semiconductor Manufacturing Conference Proceedings (Cat. No.97CH36023)}, 
title={Integrated test facility (ITF)-automation testing to support Intel's manufacturing output}, 
year={1997}, 
volume={}, 
number={}, 
pages={D17-D21}, 
abstract={To meet the challenges of increasing automation and the potential for downtime, the current Virtual Factory Joint Automation Managers (JAM) worked with Components Automation Systems (CAS), the central engineering group responsible for the automation system, to create an Integrated Test Facility (ITF). ITF's mission is to conduct volume integrated testing of the automation suite prior to production release and to ensure that the automation suite does not hinge factory ramp. The ITF is a complete factory automation system running simulated production wafers. Established in January 1996, the ITF tests new automation product changes integrated into a complete factory manufacturing automation system and certifies that they can run in high volume. Integrated with CAS automation processes, the ITF is a key part of a process that delivers quality software}, 
keywords={factory automation;production engineering computing;production testing;test facilities;automation testing;factory manufacturing automation system;factory ramp;integrated test facility;manufacturing output;production release;quality software;simulated production wafers;volume integrated testing;Automatic testing;Content addressable storage;Engineering management;Fasteners;Manufacturing automation;Production facilities;Production systems;System testing;Test facilities;Virtual manufacturing}, 
doi={10.1109/ISSM.1997.664526}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{4637713, 
author={J. Xie and X. Ye and B. Li and F. Xie}, 
booktitle={2008 10th IEEE International Conference on High Performance Computing and Communications}, 
title={A Configurable Web Service Performance Testing Framework}, 
year={2008}, 
volume={}, 
number={}, 
pages={312-319}, 
abstract={More and more softwares based on web service technologies are developed. Before their releases on the Internet, it is necessary to evaluate these systems' performance, especially their response time under different workload pressures. However, existing performance testing benchmarks and tools for web service applications are difficult to adapt to various user-specific testing purposes. This paper proposes a configurable web service performance testing framework which contains client module, application server module and database module. Client module, by using the network cooperation method that one central client drives several other clients, adapts to a great number of concurrent customers to request web services. Application server module contains web services under testing and external supporting web services, each of which is configured as a plug-in. The process to realize mixed ratio of web service interactions is similar to dealing cards and adapts to different commercial application characteristics. In database module, the data model including table and attribute dependence can be customized, and the data scale initialization can be resized according to the topology of above dependence. As such, this framework allows testers to dynamically define their data model, customize their scale of database, configure their transaction characteristics, deploy their application strategies and confirm their performance metrics..}, 
keywords={Web services;client-server systems;data models;program testing;Internet;attribute dependence;client-server module;configurable Web service performance testing;data model;database module;table dependence;user-specific testing purpose;Application software;Benchmark testing;Data models;Delay;Internet;Measurement;Network servers;Topology;Transaction databases;Web services;benchmark;framework;performance testing;web service}, 
doi={10.1109/HPCC.2008.53}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{5276470, 
author={M. Z. Mas'ud and A. H. Yaacob and N. M. Ahmad}, 
booktitle={2006 International Conference on Computing Informatics}, 
title={Network performance testing on VM based autonomous web server}, 
year={2006}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={As online services increasingly play vital roles in modern society, the possibilities and opportunities offered are limitless, unfortunately, so too are the risks and chances of malicious intrusions. Intrusion detection systems (IDSs) has been widely used as an important component in protecting online service towards Web attacks and evasions. Yet, today's architectures for intrusion detection force the IDS designer to make a difficult choice to place IDS, so that it can protect itself from a direct attack. To address these challenges, this paper introduces a novel framework to safeguard IDS from a direct attack. Simply called zero administrative server (ZAS), the system incorporates IDS in a virtual machine (VM) environment. VM offers strong isolation for IDS from the monitored services and provides significant resistance to malicious attacks. Moreover, this VM based WWW server has the ability to monitor the network traffic to the running services; analyse the information obtained and detect the intrusion; alienate the intruder from the services; and reconstruct the corrupted data or damaged files caused by the evasion. In this paper, we demonstrate ZAS by exposing it to several attacking tools as well as to show the effects it takes on the network performance in terms of TCP throughput and application-to-application round trip time.}, 
keywords={Web services;security of data;virtual machines;VM based autonomous Web server;Web attacks;intrusion detection systems;malicious attacks;network performance testing;online services;virtual machine;zero administrative server;File servers;Intrusion detection;Network servers;Protection;Testing;Virtual machine monitors;Virtual machining;Virtual manufacturing;Web server;World Wide Web;Checksum;Intrusion Detection System;Virtual Machine;WWW Server}, 
doi={10.1109/ICOCI.2006.5276470}, 
ISSN={2166-5710}, 
month={June},}
@INPROCEEDINGS{7219669, 
author={T. Kanstrén and P. Aho and A. Lämsä and H. Martin and J. Liikka and M. Seppänen}, 
booktitle={2015 IEEE International Conference on Technologies for Practical Robot Applications (TePRA)}, 
title={Robot-assisted smartphone performance testing}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={This paper describes experiences and lessons learned in applying an approach of using a physical robot for testing overall smartphone device performance based on user profiles. The process consists of capturing user actions, abstracting them to usage profiles, transforming these into test models, and generating test cases from the models. The goal is to support performance testing of touch screen devices and applications in a realistic test environment. To achieve this, the tests are based on real-world generated user profiles and executed using a real physical robot, simulating the actual user. Our performance testing targets different attributes of performance such as response times, power and resource usage, and software/hardware aging. Use of different hardware and software configurations in the test scenarios is considered. This work has been performed in close collaboration with industry partners in robotics provider and user industries.}, 
keywords={program testing;robots;smart phones;software maintenance;software performance evaluation;hardware aging;hardware configuration;overall smartphone device performance testing;physical robot;power usage;resource usage;response times;robot-assisted smartphone performance testing;software aging;software configuration;touch screen devices;user profiles;Electronic mail;Markov processes;Performance evaluation;Robot kinematics;Service robots;Testing}, 
doi={10.1109/TePRA.2015.7219669}, 
ISSN={2325-0526}, 
month={May},}
@ARTICLE{370727, 
author={D. E. Pachucki}, 
journal={IEEE Transactions on Components, Packaging, and Manufacturing Technology: Part A}, 
title={Environmental stress testing experiment using the Taguchi method}, 
year={1995}, 
volume={18}, 
number={1}, 
pages={3-9}, 
abstract={Manufacturing process improvements which increase productivity, decrease test process time, and improve customer satisfaction are highly desirable in today's marketplace. The application of environmental stress screening (ESS) is a method of achieving these improvements. ESS is the application of stresses applied beyond product specification limits in order to find latent product defects. Utilizing ESS achieves increased robustness and lower infant mortality. An experiment was performed to identify the significance or relevancy of the selected stresses for application in the printed wiring board (PWA) production process by using a statistically significant controlled method. The design of experiments statistical approach (analysis of variance), is applied, combined with the Taguchi two-level, seven-factor design method. This experiment concentrated on three stresses (temperature cycling, random vibration, and power cycling) and two diagnostic levels: a prom-based (programmable memory chip), power-on self test (POST), and a functional diagnostic test suite, contained on disk storage. Note that this was not an optimization experiment. Once the significance to the production process is identified, future optimizing of temperature cycling, power cycling, and vibration screens, will be conducted. Also, voltage margining was not included so as to reduce the complexity of the experiment-treatment factors and interactions. Experimental results and conclusions on the effectiveness of different stress regimens are presented in this paper}, 
keywords={automatic testing;covariance analysis;design of experiments;dynamic testing;environmental stress screening;environmental testing;human resource management;life testing;printed circuit manufacture;printed circuit testing;production testing;Taguchi method;analysis of variance;customer satisfaction;design of experiments;diagnostic levels;environmental stress testing;functional diagnostic test suite;infant mortality;latent product defects;power cycling;power-on self test;printed wiring board production;productivity;prom-based diagnostics;random vibration;robustness;statistically significant controlled method;stress regimens;temperature cycling;test process time;Automatic testing;Customer satisfaction;Design methodology;Electronic switching systems;Manufacturing processes;Production;Productivity;Robustness;Stress;Temperature}, 
doi={10.1109/95.370727}, 
ISSN={1070-9886}, 
month={Mar},}
@INPROCEEDINGS{6032540, 
author={C. Barna and M. Litoiu and H. Ghanbari}, 
booktitle={2011 33rd International Conference on Software Engineering (ICSE)}, 
title={Model-based performance testing: NIER track}, 
year={2011}, 
volume={}, 
number={}, 
pages={872-875}, 
abstract={In this paper, we present a method for performance testing of transactional systems. The methods models the system under test, finds the software and hardware bottlenecks and generate the workloads that saturate them. The framework is adaptive, the model and workloads are determined during the performance test execution by measuring the system performance, fitting a performance model and by analytically computing the number and mix of users that will saturate the bottlenecks. We model the software system using a two layers queuing model and use analytical techniques to find the workload mixes that change the bottlenecks in the system. Those workload mixes become stress vectors and initial starting points for the stress test cases. The rest of test cases are generated based on a feedback loop that drives the software system towards the worst case behaviour.}, 
keywords={program control structures;program testing;queueing theory;feedback loop;model-based performance testing NIER track;performance test execution;queuing model;stress test cases;stress vectors;system under test;transactional systems;Adaptation models;Computational modeling;Hardware;Software;Stress;Testing;Time factors;adaptive system;performance models;performance testing;stress testing}, 
doi={10.1145/1985793.1985930}, 
ISSN={0270-5257}, 
month={May},}
@INPROCEEDINGS{8282262, 
author={C. Y. Lo and Y. W. Hua and W. C. Yu and Y. M. Chuang}, 
booktitle={2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, 
title={Functional verification and performance testing for OpenAirinterface (OAI) eNodeB}, 
year={2017}, 
volume={}, 
number={}, 
pages={1456-1459}, 
abstract={In this paper we develop and build an open air interface(OAI) eNodeB test platform for system developers to implement the network function verification and system performance evaluation for LTE network. In this test platform it also includes commercially available instruments such as EXFO EPC Simulator, Cobham TM UE Emulator and Cobham Data Generator to make this test platform performing the basic LTE network functions. The performances of this developed OAIeNodeB platform have been compared with the commercial LTE small cell eNodeB system, which is considered as the bench mark system based on Gemteck eNodeB, for proposed system parameters and various test cases .}, 
keywords={Long Term Evolution;performance evaluation;Cobham Data Generator;Cobham TM UE Emulator;EXFO EPC Simulator;Gemteck eNodeB;LTE network functions;developed OAIeNodeB platform;network function verification;open air interface eNodeB test platform;system performance evaluation;5G;B4G;EPC Emulator;OAI (Openairinterface);Open Source;UE Emulator;Verification Platform;eNodeB Emulator}, 
doi={10.1109/APSIPA.2017.8282262}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{755123, 
author={Qingxin Chen and V. Sorokine}, 
booktitle={1999 IEEE MTT-S International Topical Symposium on Technologies for Wireless Applications (Cat. No. 99TH8390)}, 
title={A fast simulation technique for performance testing of the RF/IF chain of CDMA receivers}, 
year={1999}, 
volume={}, 
number={}, 
pages={23-28}, 
abstract={We propose an improved approach to the simulation of the CDMA forward link. The simulator achieves its computational efficiency by adopting a simplified CDMA system model without compromising much of its practicality. Additional reduction in the computational complexity is obtained by implementing bit level operations for certain receiver tasks. Improved processing algorithms are also introduced, which further facilitates the simulation process. The rationale behind the development of the simulator as well as many techniques involved could prove beneficial to a CDMA receiver designer in terms of shortening the design cycle and reducing the computational power requirements.}, 
keywords={code division multiple access;computational complexity;digital simulation;land mobile radio;radio receivers;signal processing;telecommunication equipment testing;CDMA forward link;CDMA receivers;RF/IF chain;bit level operations;computational complexity reduction;computational efficiency;computational power requirements reduction;design cycle;fast simulation technique;mobile radio;performance testing;processing algorithms;system model;Additive white noise;Computational modeling;Context modeling;Fading;Multiaccess communication;Power system modeling;Radio frequency;Signal generators;Space technology;Testing}, 
doi={10.1109/MTTTWA.1999.755123}, 
ISSN={}, 
month={Feb},}
@INPROCEEDINGS{8031452, 
author={N. Gois and P. Porfírio and A. Coelho}, 
booktitle={2017 IEEE International Conference on Computer and Information Technology (CIT)}, 
title={A Multi-objective Metaheuristic Approach to Search-Based Stress Testing}, 
year={2017}, 
volume={}, 
number={}, 
pages={55-62}, 
abstract={Nowadays applications need to deal with a large number of concurrent requests. These systems must be stress tested to ensure that they can function correctly under a load. In this context, a research field called Search-based Software Testing has become increasingly important. Most of the search-based test methods are based on single objective optimization. In the case of multi-objective optimization of tests, usually researchers assign different weight values to different objectives and combine them as a single objective. This research paper verifies the use of a multi-objective algorithm in search-based stress testing. The NSGA-II algorithm was implemented in the IAdapter tool using the jMetal framework. IAdapter is a JMeter plugin used for performing search-based stress tests. jMetal is an object-oriented Java-based framework for multi-objective optimization with metaheuristics. One experiment was conducted to validate the proposed approach.}, 
keywords={Java;Pareto optimisation;concurrency control;genetic algorithms;program testing;search problems;IAdapter tool;JMeter plugin;NSGA-II algorithm;Software Testing;concurrent requests;jMetal framework;multiobjective algorithm;multiobjective metaheuristic approach;multiobjective optimization;object-oriented Java-based framework;search-based stress testing;search-based test methods;single objective optimization;weight values;Genetic algorithms;Load modeling;Search problems;Software;Stress;Testing;Time factors;Multi-Objective Metaheuristic;Pareto Frontier;Search-Based Stress Test}, 
doi={10.1109/CIT.2017.19}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{7414168, 
author={D. Kaulbars and F. Schweikowski and C. Wietfeld}, 
booktitle={2015 IEEE Globecom Workshops (GC Wkshps)}, 
title={Spatially Distributed Traffic Generation for Stress Testing the Robustness of Mission-Critical Smart Grid Communication}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Resilient Smart Grids require very robust communication infrastructures, which allow to support the control of the Smart Grid even and especially in critical situations. Current network quality assurance processes, such as drive tests in wireless systems, typically focus on cell coverage and quality of service parameters (e.g., max. data rate) at a specific geographical position, without considering the impact of overload situations. Therefore, this paper introduces a methodology for stress testing a communication infrastructure for Smart Grids by synchronized, distributed so-called Smart Traffic Generators (STGs). Due to their low cost, the STGs become a permanent part of the infrastructure and enable a network operator independent, continuous network quality monitoring. A case study leveraging a LTE deployment demonstrates how the proposed approach can prove the fulfillment of Quality of Service (QoS) requirements of time critical Smart Grid applications, even in stress situations with high cell load. Although, the proposed approach has been introduced for Smart Grids, it can also be used for ensuring the communication resilience for other critical infrastructures, e.g., public safety networks.}, 
keywords={Long Term Evolution;carrier transmission on power lines;quality of service;smart power grids;telecommunication traffic;mission-critical smart grid communication;network quality monitoring;quality of service;spatially distributed traffic generation;stress testing;Generators;Long Term Evolution;Mobile communication;Mobile computing;Quality of service;Smart grids;Stress}, 
doi={10.1109/GLOCOMW.2015.7414168}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{5634372, 
author={X. Wang and B. Zhou and W. Li}, 
booktitle={International Symposium on Parallel and Distributed Processing with Applications}, 
title={Model Based Load Testing of Web Applications}, 
year={2010}, 
volume={}, 
number={}, 
pages={483-490}, 
abstract={In this paper, a usage model is proposed to simulate users' behaviors realistically in load testing of web applications, and another relevant workload model is proposed to help generate realistic load for load testing. It also demonstrates an eclipse-based load testing tool “Load Testing Automation Framework (LTAF)” which is based on these two models and can perform load testing of web applications easily and automatically. Furthermore, these models and tools were successfully applied into a representative web-based system from a big Corporation.}, 
keywords={Internet;program testing;Load Testing Automation Framework;Web applications;Web-based system;eclipse-based load testing tool;model based load testing;usage model;user behaviors;File systems;Load modeling;Markov processes;Navigation;Servers;Testing;Unified modeling language;Load Model;Load Testing;Markov Chains;Performance Engineering;Usage Model}, 
doi={10.1109/ISPA.2010.24}, 
ISSN={2158-9178}, 
month={Sept},}
@INPROCEEDINGS{4652394, 
author={A. Young and T. Holt and M. Elsayed and A. Neuber and M. Kristiansen and L. L. Altgilbers and A. H. Stults}, 
booktitle={2007 16th IEEE International Pulsed Power Conference}, 
title={Fuse and load testing with mid-sized, high energy density flux compression generators}, 
year={2007}, 
volume={2}, 
number={}, 
pages={1165-1168}, 
abstract={Compact Pulsed Power Systems (CPPSs) require power sources that are small in size yet can produce the necessary electrical energy required to drive a given load. Helical Flux Compression Generators (HFCGs) are attractive for single shot applications due to their rapid conversion of chemical energy to electrical energy. Mid-sized generators occupy little total volume (∼4,000-cm3 total with a compressible volume of ∼300-cm3 in the present generator design), while the high explosives used in an HFCG provide an energy density of ∼8,000 MJ/m3. Consistent output current and energy gain from shot to shot are key variables in the ability of an HFCG to drive CPPSs effectively. An investigation into the practicality of using mid-sized HFCGs as the driver for single shot CPPSs is presented. Data and waveforms from generators fired into 3 μH inductive loads are shown, with results measuring the generator’s performance as a driver for an inductive energy storage (IES) system. Results are also shown from adding a power conditioning system to the output of the HFCG, where the measurements demonstrate the ability of an HFCG to drive high impedance loads. The effectiveness of a mid-sized HFCG as drivers for these systems will be evaluated.}, 
keywords={Chemicals;Energy measurement;Energy storage;Explosives;Fuses;Impedance measurement;Power conditioning;Power measurement;Pulse power systems;Testing}, 
doi={10.1109/PPPS.2007.4652394}, 
ISSN={2158-4915}, 
month={June},}
@ARTICLE{4163031, 
author={M. J. Johnson and C. W. Ho and E. M. Maximilien and L. Williams}, 
journal={IEEE Software}, 
title={Incorporating Performance Testing in Test-Driven Development}, 
year={2007}, 
volume={24}, 
number={3}, 
pages={67-73}, 
abstract={Our performance-testing approach required manually inspecting the performance logs. During the project's development, JUnit-based performance testing tools, such as JUnitPerf, weren't available. Such tools provide better visibility of performance problems than manual inspection of performance logs. Although we believe manual inspection of performance trends is necessary, specifying the bottom-line performance in assert-based test cases can complement the use of performance log files, making the TFP testing results more visible to the developers. We're investigating the design of assert-based performance testing to improve the TFP process. Another direction of future work is automatic performance test generation. In this project, we relied on the performance architect's experience to identify the execution paths and measurement points for performance testing. We can derive this crucial information for performance testing from the performance requirements and system design. We plan to find guidelines for specifications of performance requirements and system design to make the automation possible}, 
keywords={formal specification;formal verification;program testing;software performance evaluation;systems analysis;JUnit-based performance testing tool;assert-based test case;automatic performance test generation;performance requirement specification;system design;test-driven development;Delay;Java;Printers;Process design;Software performance;Software testing;Switches;System software;System testing;Throughput;performance measures;test execution;testing strategies}, 
doi={10.1109/MS.2007.77}, 
ISSN={0740-7459}, 
month={May},}
@INPROCEEDINGS{693672, 
author={A. Helmy and D. Estrin}, 
booktitle={Proceedings. Sixth International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems (Cat. No.98TB100247)}, 
title={Simulation-based `STRESS' testing case study: a multicast routing protocol}, 
year={1998}, 
volume={}, 
number={}, 
pages={36-43}, 
abstract={We propose a method for using simulation to analyze the robustness of multiparty (multicast-based) protocols in a systematic fashion. We call our method Systematic Testing of Robustness by Examination of Selected Scenarios (STRESS). STRESS aims to cut the time and effort needed to explore pathological cases of a protocol during its design. This paper has two goals: (1) to describe the method, and (2) to serve as a case study of robustness analysis of multicast routing protocols. We aim to offer design tools similar to those used in CAD and VLSI design, and demonstrate how effective systematic simulation can be in studying protocol robustness}, 
keywords={digital simulation;local area networks;multicast communication;performance evaluation;telecommunication computing;telecommunication network routing;transport protocols;CAD;LAN;VLSI design;design tools;multicast routing protocols;multiparty protocols;pathological cases;robustness analysis;scenario generation;simulation-based STRESS testing;systematic robustness testing;systematic simulation;Analytical models;Computational modeling;Computer aided software engineering;Computer science;Multicast protocols;Network topology;Routing protocols;Stress;System testing;Unicast}, 
doi={10.1109/MASCOT.1998.693672}, 
ISSN={}, 
month={Jul},}
@INPROCEEDINGS{7813849, 
author={R. Khan and M. Amjad}, 
booktitle={2016 International Conference on Computing, Communication and Automation (ICCCA)}, 
title={Web application's performance testing using HP LoadRunner and CA Wily introscope tools}, 
year={2016}, 
volume={}, 
number={}, 
pages={802-806}, 
abstract={This paper cover the importance of performance testing of the web application. The performance of any web application has been depend on the some different type of the testing process like load testing, soak testing, smoke testing and stress testing etc. In this paper we applied smoke testing on a web application. This web application has been developed for the customer before delivering the software to the customer it is duty of tester to test all the aspects of the software and deliver error free and reliable software to the customer. Reliability has its own most important role in the software industry. In this paper performance testing has been performed using HP LoadRunner and CA Wily Introscope tools.}, 
keywords={DP industry;Internet;program testing;software performance evaluation;software reliability;software tools;CA Wily Introscope tool;HP LoadRunner;Web application performance testing;smoke testing;software industry;software reliability;Business;Scalability;Servers;Software;Testing;Throughput;Uniform resource locators;HP LoadRunner;Load Testng;Perforamance Testing;Software Testing;Wily Introscope Tools}, 
doi={10.1109/CCAA.2016.7813849}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{6802679, 
author={X. Baiquan}, 
booktitle={2014 Sixth International Conference on Measuring Technology and Mechatronics Automation}, 
title={Design of Platform for Performance Testing Based on JADE}, 
year={2014}, 
volume={}, 
number={}, 
pages={251-254}, 
abstract={For solving the problems presently such as coordination of the virtual users' act and the real-time acquisition of information, based on agent and JADE, this paper brings forward an architecture model of the platform for performance testing. JADE is multi-agent development environment which supports the management and communications control for agents. The principle of JADE is described and the basic method to design a platform for performance testing based on JADE is introduced, and offers a technology approach to realize the platform for performance testing.}, 
keywords={Java;multi-agent systems;program testing;software performance evaluation;JADE;Java Agent Development Framework;multiagent development environment;open source software;performance testing platform design;real-time information acquisition;virtual users act coordination;Automation;Mechatronics;Agent;JADE;Platform for performance testing}, 
doi={10.1109/ICMTMA.2014.63}, 
ISSN={2157-1473}, 
month={Jan},}
@INPROCEEDINGS{7793156, 
author={A. H. Kadam and R. Menon and S. S. Williamson}, 
booktitle={IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society}, 
title={Traction inverter performance testing using mathematical and real-time controller-in-the-loop Permanent Magnet Synchronous Motor emulator}, 
year={2016}, 
volume={}, 
number={}, 
pages={6651-6656}, 
abstract={In the development stage of electric vehicle drive, simulation plays a vital role. It's a powerful tool which allows the developer to investigate various control strategies and test hardware systems in harmless work environment. The software simulations platform does have constraints. In that the complex mathematical operations take longer time to solve and eventually increases the overall simulation time and cannot perform the real-time operation. This simulation further needs to be converted to the target processor's language, either assembly or C- language, which will operate in the drive system. However, if a real-time simulation environment could be comprehended, then the real processor used in the system could be incorporated in the simulation. This eventually will eliminate the chance of introducing error during code translation as well as reduce simulation time. Also, the target controller could be tested within the simulation before introducing it the actual system. This paper discuss a concept of controller-in-loop simulation, which can be used to simulate the entire system in real-time. A simple dynamic model of Permanent Magnet Synchronous Motor is simulated with MATLAB/Simulink as well as on a TMS320F28069 digital signal processor from Texas Instruments Inc. Comparative study of simulation results of both the platforms, demonstrate that although MATLAB/Simulink provides excellent GUI and functionality, it fails to performs real-time simulation which can be accomplished with controller-in-simulation.}, 
keywords={digital signal processing chips;invertors;machine control;microcontrollers;permanent magnet motors;synchronous motors;GUI;MATLAB;Simulink;TMS320F28069 digital signal processor;controller-in-the-loop permanent magnet synchronous motor emulator;traction inverter performance testing;Digital signal processing;Frequency control;Integrated circuits;MATLAB;Mathematical model;Real-time systems;Stators;Control systems;electric machines;emulation;modeling;motor drives;power electronics}, 
doi={10.1109/IECON.2016.7793156}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{7752106, 
author={G. E. Subtirelu and M. Dobriceanu and M. Linca}, 
booktitle={2016 IEEE International Power Electronics and Motion Control Conference (PEMC)}, 
title={Virtual instrumentation for no-load testing of induction motor}, 
year={2016}, 
volume={}, 
number={}, 
pages={854-859}, 
abstract={The main objective of this paper is to solve a practical and current problem, by taking advantage of the virtual instrumentation in testing electrical machines. The abilities of virtual instrumentation are used to data acquisition, measurement and analyze the values of no-load testing's parameters for three-phase induction motor. The virtual measurement system bench is designed and consist from two principal components: the hardware components (six LEM transducers for measuring three voltages and three currents; elements for signal conditioning and power transducers; USB multifunction Input / Output module; a personal computer) and the software components (operating system for the computer; drivers for the acquisition and manipulation of data; virtual instrument for calculation and graphical presentation of results). The LabVIEW graphical programming environment is used for designing virtual instrument. This virtual measurement system bench is an easy to use device which can be used in engineering education laboratories from universities or in electrical machines testing workbenches; it is capable of data acquisition, storage or memorization on different media, visualization of different graphs or analysis on-line or off-line of the results obtained. The virtual measurement system described in the paper can work independently (in the Simulation mode or Real time Acquisition mode) or integrated as part of a future complex virtual system for measurement and analysis in the domain of electrical machines testing workbenches.}, 
keywords={data acquisition;graph theory;induction motors;machine testing;virtual instrumentation;LEM transducers;LabVIEW graphical programming environment;USB multifunction input-output module;data acquisition;electrical machines testing;engineering education laboratories;no-load testing;personal computer;power transducers;signal conditioning;three-phase induction motor;virtual instrumentation;virtual measurement system;Artificial intelligence;Current measurement;Data acquisition;Induction motors;Instruments;Testing;Voltage measurement}, 
doi={10.1109/EPEPEMC.2016.7752106}, 
ISSN={}, 
month={Sept},}