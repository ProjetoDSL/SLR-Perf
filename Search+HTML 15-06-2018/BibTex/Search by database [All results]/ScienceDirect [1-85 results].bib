@article{Gojare2015341,
title = "Analysis and Design of Selenium WebDriver Automation Testing Framework ",
journal = "Procedia Computer Science ",
volume = "50",
number = "",
pages = "341 - 346",
year = "2015",
note = "Big Data, Cloud and Computing Challenges ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.04.038",
url = "https://www.sciencedirect.com/science/article/pii/S1877050915005396",
author = "Satish Gojare and Rahul Joshi and Dhanashree Gaigaware",
keywords = "Web applications",
keywords = "Automation testing",
keywords = "selenium webdriver",
keywords = "Automation testing framework. ",
abstract = "Abstract Nowadays, number of software system has been implemented as web-based applications. These web applications are very complex. It is very difficult to test such complex web applications. Automation testing uses automation tools to reduce human intervention and repeatable tasks. In this paper we have designed and implemented automation testing framework for testing web applications. This new automation testing framework has been implemented using selenium WebDriver tool. Using this framework tester can easily write their test cases efficiently and in less time. Tester need not to study the selenium webdriver tool in detail. This framework is helpful to developer to analyze their code due to screen shot property of framework. This framework produces the customized test report to tester. It is very easy to maintain and repair the test suite for new release of the application using this framework. "
}
@article{Sioutas2015211,
title = "D-P2P-Sim+: A novel distributed framework for \{P2P\} protocols performance testing ",
journal = "Journal of Systems and Software ",
volume = "100",
number = "",
pages = "211 - 233",
year = "2015",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2014.11.001",
url = "https://www.sciencedirect.com/science/article/pii/S0164121214002416",
author = "S. Sioutas and E. Sakkopoulos and A. Panaretos and D. Tsoumakos and P. Gerolymatos and G. Tzimas and Y. Manolopoulos",
keywords = "Distributed storage systems",
keywords = "IoT and Web 2.0 applications",
keywords = "P2P data management ",
abstract = "Abstract In recent technologies like IoT (Internet of Things) and Web 2.0, a critical problem arises with respect to storing and processing the large amount of collected data. In this paper we develop and evaluate distributed infrastructures for storing and processing large amount of such data. We present a distributed framework that supports customized deployment of a variety of indexing engines over million-node overlays. The proposed framework provides the appropriate integrated set of tools that allows applications processing large amount of data, to evaluate and test the performance of various application protocols for very large scale deployments (multi million nodes–billions of keys). The key aim is to provide the appropriate environment that contributes in taking decisions regarding the choice of the protocol in storage \{P2P\} systems for a variety of big data applications. Using lightweight and efficient collection mechanisms, our system enables real-time registration of multiple measures, integrating support for real-life parameters such as node failure models and recovery strategies. Experiments have been performed at the PlanetLab network and at a typical research laboratory in order to verify scalability and show maximum re-usability of our setup. D-P2P-Sim+ framework is publicly available at http://code.google.com/p/d-p2p-sim/downloads/list. "
}
@article{VarelaGonzález2013122,
title = "Performance testing of LiDAR exploitation software ",
journal = "Computers & Geosciences ",
volume = "54",
number = "",
pages = "122 - 129",
year = "2013",
note = "",
issn = "0098-3004",
doi = "https://doi.org/10.1016/j.cageo.2012.12.001",
url = "https://www.sciencedirect.com/science/article/pii/S0098300412004050",
author = "M. Varela-González and H. González-Jorge and B. Riveiro and P. Arias",
keywords = "Mobile LiDAR",
keywords = "LiDAR software",
keywords = "Software stress test ",
abstract = "Mobile LiDAR systems are being used widely in recent years for many applications in the field of geoscience. One of most important limitations of this technology is the large computational requirements involved in data processing. Several software solutions for data processing are available in the market, but users are often unknown about the methodologies to verify their performance accurately. In this work a methodology for LiDAR software performance testing is presented and six different suites are studied: \{QT\} Modeler, AutoCAD Civil 3D, Mars 7, Fledermaus, Carlson and TopoDOT (all of them in x64). Results depict as QTModeler, TopoDOT and AutoCAD Civil 3D allow the loading of large datasets, while Fledermaus, Mars7 and Carlson do not achieve these powerful performance. AutoCAD Civil 3D needs large loading time in comparison with the most powerful softwares such as \{QTModeler\} and TopoDOT. Carlson suite depicts the poorest results among all the softwares under study, where point clouds larger than 5 million points cannot be loaded and loading time is very large in comparison with the other suites even for the smaller datasets. AutoCAD Civil 3D, Carlson and TopoDOT show more threads than other softwares like QTModeler, Mars7 and Fledermaus. "
}
@article{He2016247,
title = "An \{MDE\} performance testing framework based on random model generation ",
journal = "Journal of Systems and Software ",
volume = "121",
number = "",
pages = "247 - 264",
year = "2016",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2016.04.044",
url = "https://www.sciencedirect.com/science/article/pii/S0164121216300292",
author = "Xiao He and Tian Zhang and Chang-Jun Hu and Zhiyi Ma and Weizhong Shao",
keywords = "Model-related operation",
keywords = "Performance testing",
keywords = "Model generation",
keywords = "Model-driven engineering ",
abstract = "Abstract The scalability of model-related operations (e.g., model transformations), when they are to be applied in industrial model-driven engineering, becomes an important issue. However, there is a lack of an automated performance testing framework for those operations, since the existing ones for ordinary programs are ill-suited. Such a framework is required to provide the function of creating and organizing test cases, and the ability of generating test input of large size automatically, because large scale models are not widely available, making it hard to test the performance and coverage of those operations without any bias. This paper proposes a performance testing framework, integrated with a random model generation algorithm, for model-related operations. The framework, based on a test model, can be used to specify and arrange test cases into test suites. And the model generation algorithm can generate a random model correctly and efficiently, according to the metamodel and user-defined constraints. Finally, we present two case studies, one experiment in randomness, and two experiments in generation efficiency to evaluate the framework and algorithm. Results show that the framework is competent to support performance testing of model-related operations, and the algorithm is random and efficient enough to generate test data for performance testing. "
}
@article{Pan200971,
title = "Robust performance testing for digital forensic tools ",
journal = "Digital Investigation ",
volume = "6",
number = "1–2",
pages = "71 - 81",
year = "2009",
note = "",
issn = "1742-2876",
doi = "https://doi.org/10.1016/j.diin.2009.02.003",
url = "https://www.sciencedirect.com/science/article/pii/S1742287609000279",
author = "Lei Pan and Lynn M. Batten",
keywords = "Digital forensic tool testing",
keywords = "Experimental errors",
keywords = "Performance testing",
keywords = "CFReDS project",
keywords = "EESAG ",
abstract = "In previous work, the authors presented a theoretical lower bound on the required number of testing runs for performance testing of digital forensic tools. However, experimental errors are inevitable in laboratory settings, occurring as measurement errors or as random errors and can result in practical situations where the number of testing runs is far from the theoretical bound. This paper adapts our former work to tolerate such errors in the testing results. The contribution of our new methodology enables the tester to achieve performance testing results of high quality from a manageable number of observations and in a dynamic but controllable way. This is of particular interest to forensic testers who do not have access to sophisticated equipment and who can allocate only a small amount of time to testing. "
}
@article{Breeden2016649,
title = "Incorporating lifecycle and environment in loan-level forecasts and stress tests ",
journal = "European Journal of Operational Research ",
volume = "255",
number = "2",
pages = "649 - 658",
year = "2016",
note = "",
issn = "0377-2217",
doi = "https://doi.org/10.1016/j.ejor.2016.06.008",
url = "https://www.sciencedirect.com/science/article/pii/S0377221716304283",
author = "Joseph L. Breeden",
keywords = "Forecasting",
keywords = "Risk",
keywords = "Banking",
keywords = "Time series",
keywords = "Age-Period-Cohort models ",
abstract = "Abstract The new \{FASB\} current expected credit loss (CECL) proposal, IASB’s \{IFRS\} 9, and regulatory stress testing all require that the industry move toward forecasting probabilities of future events, rather than simply rank-ordering loans. Even more importantly, effective loan pricing requires this same forward-looking, loan-level forecasting. We created a loan-level version of Age-Period-Cohort (APC) models suitable for forecasting individual loan performance at a point-in-time or for the loan’s lifetime. The \{APC\} literature explains that any model of loan performance must make either an explicit or implicit assumption around the embedded model specification error between age of the loan, vintage origination date, and performance date. We have made this assumption explicit and implemented a technique using augmented macroeconomic history to stabilize the analysis. The preceding steps provide robust estimates of lifecycle and environmental impacts. We then use a Generalized Linear Model (GLM) with a population odds offset for each age/time combination derived from the lifecycle and environment functions in order to estimate origination and behavior scores. Analyzing a small \{US\} auto loan portfolio, we demonstrate that this model is robust out-of-sample and out-of-time for predicting both rank-ordering and probabilities by inserting the odds offset appropriate for the environment being modeled. In addition to producing loan-level forecasts and stress tests, the scores produced have higher rank-order performance out-of-sample and out-of-time than standard scores. The scores prove to be robust years into the future with no measurable degradation in performance because of the stabilizing effect of the offset factor during model construction. "
}
@article{Trubiani2018329,
title = "Exploiting load testing and profiling for Performance Antipattern Detection ",
journal = "Information and Software Technology ",
volume = "95",
number = "",
pages = "329 - 345",
year = "2018",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2017.11.016",
url = "https://www.sciencedirect.com/science/article/pii/S0950584917302276",
author = "Catia Trubiani and Alexander Bran and André van Hoorn and Alberto Avritzer and Holger Knoche",
keywords = "Software performance engineering",
keywords = "Software performance antipatterns",
keywords = "Empirical data",
keywords = "Load testing and profiling ",
abstract = "Abstract Context: The performance assessment of complex software systems is not a trivial task since it depends on the design, code, and execution environment. All these factors may affect the system quality and generate negative consequences, such as delays and system failures. The identification of bad practices leading to performance flaws is of key relevance to avoid expensive rework in redesign, reimplementation, and redeployment. Objective: The goal of this manuscript is to provide a systematic process, based on load testing and profiling data, to identify performance issues with runtime data. These performance issues represent an important source of knowledge as they are used to trigger the software refactoring process. Software characteristics and performance measurements are matched with well-known performance antipatterns to document common performance issues and their solutions. Method: We execute load testing based on the characteristics of collected operational profile, thus to produce representative workloads. Performance data from the system under test is collected using a profiler tool to create profiler snapshots and get performance hotspot reports. From such data, performance issues are identified and matched with the specification of antipatterns. Software refactorings are then applied to solve these performance antipatterns. Results: The approach has been applied to a real-world industrial case study and to a representative laboratory study. Experimental results demonstrate the effectiveness of our tool-supported approach that is able to automatically detect two performance antipatterns by exploiting the knowledge of domain experts. In addition, the software refactoring process achieves a significant performance gain at the operational stage in both case studies. Conclusion: Performance antipatterns can be used to effectively support the identification of performance issues from load testing and profiling data. The detection process triggers an antipattern-based software refactoring that in our two case studies results in a substantial performance improvement. "
}
@article{Ahmad2018,
title = "Identifying worst-case user scenarios for performance testing of web applications using Markov-chain workload models ",
journal = "Future Generation Computer Systems ",
volume = "",
number = "",
pages = " - ",
year = "2018",
note = "",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2018.01.042",
url = "https://www.sciencedirect.com/science/article/pii/S0167739X18301341",
author = "Tanwir Ahmad and Dragos Truscan and Ivan Porres",
keywords = "Performance testing",
keywords = "Markov chain",
keywords = "Genetic algorithms",
keywords = "Graph-search algorithms ",
abstract = "Abstract The poor performance of web-based systems can negatively impact the profitability and reputation of the companies that rely on them. Finding those user scenarios which can significantly degrade the performance of a web application is very important in order to take necessary countermeasures, for instance, allocating additional resources. Furthermore, one would like to understand how the system under test performs under increased workload triggered by the worst-case user scenarios. In our previous work, we have formalized the expected behavior of the users of web applications by using probabilistic workload models and we have shown how to use such models to generate load against the system under test. As an extension, in this article, we suggest a performance space exploration approach for inferring the worst-case user scenario in a given workload model which has the potential to create the highest resource utilization on the system under test with respect to a given resource. We propose two alternative methods: one which identifies the exact worst-case user scenario of the given workload model, but it does not scale up for models with a large number of loops, and one which provides an approximate solution which, in turn, is more suitable for models with a large number of loops. We conduct several experiments to show that the identified user scenarios do provide in practice an increased resource utilization on the system under test when compared to the original models. "
}
@article{Cappelletti1997473,
title = "Cast: An electrical stress test to monitor single bit failures in flash-EEPROM structures ",
journal = "Microelectronics Reliability ",
volume = "37",
number = "3",
pages = "473 - 481",
year = "1997",
note = "",
issn = "0026-2714",
doi = "https://doi.org/10.1016/0026-2714(95)00214-6",
url = "https://www.sciencedirect.com/science/article/pii/0026271495002146",
author = "P. Cappelletti and R. Bez and D. Cantarelli and D. Nahmad and L. Ravazzi",
abstract = "To increase yield and reliability of flash-EEPROM devices, great effort has been devoted to improve the way of monitoring the tunnel oxide quality, both as regards the electrical measurements and the related test structures. The most popular test is an electrical stress to evaluate the charge or the electric field at breakdown on large area or edge intensive capacitors. Although the capacitor test is a fundamental means to evaluate the oxide quality, it can not detect the subtle defects which are responsible for the most likely flash-EEPROM failure mechanisms such as the single bit over-erasure or failure after an electrical stress. To overcome this difficulty the cell array stress test (CAST, patent pending) has been conceived: by means of a suitable test structure it is possible to detect defective cells in a flash-EEPROM array. Correlation with actual flash-EEPROM yield is demonstrated. This test can be used either as a short-loop monitor for process control and improvement or as an end-of-process wafer level screening. "
}
@article{Garousi2008161,
title = "Traffic-aware stress testing of distributed real-time systems based on \{UML\} models using genetic algorithms ",
journal = "Journal of Systems and Software ",
volume = "81",
number = "2",
pages = "161 - 185",
year = "2008",
note = "Model-Based Software Testing ",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2007.05.037",
url = "https://www.sciencedirect.com/science/article/pii/S0164121207001239",
author = "Vahid Garousi and Lionel C. Briand and Yvan Labiche",
keywords = "Stress testing",
keywords = "Performance testing",
keywords = "Model-based testing",
keywords = "Distributed systems",
keywords = "Real-time systems",
keywords = "UML",
keywords = "Network traffic",
keywords = "Genetic algorithms ",
abstract = "This paper presents a model-driven, stress test methodology aimed at increasing chances of discovering faults related to network traffic in distributed real-time systems (DRTS). The technique uses the \{UML\} 2.0 model of the distributed system under test, augmented with timing information, and is based on an analysis of the control flow in sequence diagrams. It yields stress test requirements that are made of specific control flow paths along with time values indicating when to trigger them. The technique considers different types of arrival patterns (e.g., periodic) for real-time events (common to DRTSs), and generates test requirements which comply with such timing constraints. Though different variants of our stress testing technique already exist (that stress different aspects of a distributed system), they share a large amount of common concepts and we therefore focus here on one variant that is designed to stress test the system at a time instant when data traffic on a network is maximal. Our technique uses genetic algorithms to find test requirements which lead to maximum possible traffic-aware stress in a system under test. Using a real-world \{DRTS\} specification, we design and implement a prototype \{DRTS\} and describe, for that particular system, how the stress test cases are derived and executed using our methodology. The stress test results indicate that the technique is significantly more effective at detecting network traffic-related faults when compared to test cases based on an operational profile. "
}
@article{Easterly2010107,
title = "Using a vision sensor system for performance testing of satellite-based tractor auto-guidance ",
journal = "Computers and Electronics in Agriculture ",
volume = "72",
number = "2",
pages = "107 - 118",
year = "2010",
note = "",
issn = "0168-1699",
doi = "https://doi.org/10.1016/j.compag.2010.03.004",
url = "https://www.sciencedirect.com/science/article/pii/S0168169910000724",
author = "Dwight R. Easterly and Viacheslav I. Adamchuk and Michael F. Kocher and Roger M. Hoy",
keywords = "Auto-guidance",
keywords = "Auto-steering",
keywords = "GNSS",
keywords = "GPS",
keywords = "Receiver",
keywords = "Tractor testing",
keywords = "Standard ",
abstract = "A vision sensing system for the measurement of auto-guidance pass-to-pass and long-term errors was implemented to test the steering performance of tractors equipped with auto-guidance systems. The developed test system consisted of an optical machine vision sensor rigidly mounted on the rear of the tested tractor. The center of the drawbar hitch pin point was used as the reference from which to measure the deviation of the tractor's actual travel path from its desired path. The system was built and calibrated to a measurement accuracy of better than 2 mm. To evaluate the sensor, two auto-guidance systems equipped with RTK-level \{GNSS\} receivers were tested and the results for different travel speeds compared. Pass-to-pass and long-term errors were calculated using the relative positions of a reference at a collocated point when the tractor was operated in opposite directions within 15 min and more than 1 h apart, respectively. In addition to variations in speed, two different auto-guidance steering stabilization distances allowed for comparison of two different definitions of steady-state operation of the system. For the analysis, non-parametric cumulative distributions were generated to determine error values that corresponded to 95% of the cumulative distribution. Both auto-guidance systems provided 95% cumulative error estimates comparable to 51 mm (2 in.) claims and even smaller during Test A. Higher travel speeds (especially 5.0 m/s) significantly increased measured auto-guidance error, but no significant difference was observed between pass-to-pass and long-term error estimates. The vision sensor testing system could be used as a means to implement the auto-guidance test standard under development by the International Standard Organization (ISO). Third-party evaluation of auto-guidance performance will increase consumer awareness of the potential performance of products provided by a variety of vendors. "
}
@article{Choi2004237,
title = "Performance test and analysis for an adaptive load balancing mechanism on distributed server cluster systems ",
journal = "Future Generation Computer Systems ",
volume = "20",
number = "2",
pages = "237 - 247",
year = "2004",
note = "Modeling and simulation in supercomputing and telecommunications ",
issn = "0167-739X",
doi = "https://doi.org/10.1016/S0167-739X(03)00138-9",
url = "https://www.sciencedirect.com/science/article/pii/S0167739X03001389",
author = "Eunmi Choi",
keywords = "Cluster computing",
keywords = "Load balancing",
keywords = "LVS (Linux Virtual Server)",
keywords = "Performance counter",
keywords = "Scalability",
keywords = "Availability ",
abstract = "As the next generation of Internet services requires more highly scalable and available server systems, the cost-effective cluster of a large number of distributed computers becomes a popular solution. In this paper, we investigate to design and develop a server load balancing mechanism on cluster architecture, called the \{ALBM\} cluster. In order to construct the more scalable and reliable Internet service system, the \{ALBM\} cluster system consists of independent but co-operable components. The \{ALBM\} cluster system supports adaptive load balancing among servers via its adaptive load balancer (ALB) component in Layer 4 level and Layer 7 level. The Management Station (M-Station) and the Administrator Console are in charge of cluster management, system configuration management, and performance counter management. The Node Service is a system-level agent that is deployed into a server node. The node management and cluster management are the major tasks of the agent. Beside, the \{ALBM\} cluster is a flexible open system whose features of functionality can change or be easily expanded without affecting the rest of the system. In this paper, we also present a set of our experimental results to compare the performance of the \{ALBM\} cluster with that of \{LVS\} scheduling cluster system. We compare performance results of the \{ALBM\} with RR, LC, and \{WLC\} scheduling algorithms of a \{LVS\} cluster in both of homogeneous and heterogeneous system environments. "
}
@article{Frankiewicz1991127,
title = "Adaptive fiducial point detector for \{ECG\} stress testing systems ",
journal = "International Journal of Bio-Medical Computing ",
volume = "28",
number = "1–2",
pages = "127 - 135",
year = "1991",
note = "",
issn = "0020-7101",
doi = "https://doi.org/10.1016/0020-7101(91)90032-A",
url = "https://www.sciencedirect.com/science/article/pii/002071019190032A",
author = "Zygmunt Frankiewicz and Jacek Leski",
keywords = "Fiducial point detection",
keywords = "ECG signals ",
abstract = "The paper deals with the problem of fiducial point detection in noisy exercise \{ECG\} signals. Performance of the averaging process depends on the detector's repeatability. The paper proposes an adaptive algorithm for optimization of the detector. The structure of the detector is well known and often used. Characteristics of the last filter are matched to the current signal and bandpass filter impulse response. The new method was tested using real \{ECG\} signals. Results indicated that the \{FP\} jittering was reduced to almost one half. "
}
@article{Huang2016221,
title = "Updating reliability of single piles and pile groups by load tests ",
journal = "Computers and Geotechnics ",
volume = "73",
number = "",
pages = "221 - 230",
year = "2016",
note = "",
issn = "0266-352X",
doi = "https://doi.org/10.1016/j.compgeo.2015.12.003",
url = "https://www.sciencedirect.com/science/article/pii/S0266352X1500258X",
author = "Jinsong Huang and Richard Kelly and Dianqinq Li and Chuangbing Zhou and Scott Sloan",
keywords = "System reliability",
keywords = "Pile group",
keywords = "Load test",
keywords = "Bayesian updating ",
abstract = "Abstract Pile load tests are used to refine designs and for quality assurance. They can also be used to verify the reliability of piles and pile groups. Stochastic methods have previously been developed to verify the reliability of single piles. A general stochastic method to verify the reliability of pile groups is developed in this paper. The method can be used to assess the reliability of groups where pile tests have been conducted to the ultimate capacity, to below the ultimate capacity but exceeding specified capacity, and where pile tests fail to achieve the specified capacity. In the latter case, the method allows decisions to be made as to whether the reliability of the entire pile group is satisfactory or whether additional piles need to be installed. "
}
@article{Capdehourat20181,
title = "High density emulation platform for Wi-Fi performance testing ",
journal = "Ad Hoc Networks ",
volume = "70",
number = "",
pages = "1 - 13",
year = "2018",
note = "",
issn = "1570-8705",
doi = "https://doi.org/10.1016/j.adhoc.2017.11.007",
url = "https://www.sciencedirect.com/science/article/pii/S1570870517302056",
author = "Germán Capdehourat and Germán Álvarez and Martín Álvarez and Pedro Porteiro and Fernando Bagalciague",
keywords = "\{IEEE\} 802.11",
keywords = "Client emulation",
keywords = "Performance testing ",
abstract = "Abstract The \{IEEE\} 802.11 standard has become the basis of one of the most successful wireless communication technologies of all time. Originally created to provide wireless connectivity for a few devices, a couple of decades later it may support thousands of users in a single wireless LAN. This fact has made 802.11 a relevant research topic, and as it happens with other wireless technologies, many of the work carried out is based on simulations. In particular, studies for scenarios with high user density are usually performed this way, in many cases leading to conclusions which do not apply to real world situations. This mismatch can be due to multiple factors, such as the specific protocol implementations or the hardware and drivers used. In this article we present a novel 802.11-based testing platform, which aims to bridge the gap between simulations and the real world, in order to carry out research work for typical high density scenarios. The platform is compatible with standard 802.11-based wireless cards on the market and it was tested with two different radios, The validation metrics considered were the \{TCP\} throughput, the airtime utilization and the effective data rate, with relative errors ranging from 0 up to 15%. The potential of the tool is illustrated with real world measurements from two example use cases in education facilities: a school classroom and a conference room. The results indicate this might be the first step towards an open platform to enable active Wi-Fi performance testing for large scale scenarios. Further emulation capabilities are shown with different application tests already integrated to the platform, such as QoE tests for YouTube video playback or e-learning platforms. "
}
@article{Dobai2013196,
title = "SAT-based generation of compressed skewed-load tests for transition delay faults ",
journal = "Microprocessors and Microsystems ",
volume = "37",
number = "2",
pages = "196 - 205",
year = "2013",
note = "Digital System Safety and Security ",
issn = "0141-9331",
doi = "https://doi.org/10.1016/j.micpro.2012.09.002",
url = "https://www.sciencedirect.com/science/article/pii/S0141933112001640",
author = "Roland Dobai and Marcel Balaz",
keywords = "Test generation",
keywords = "Test compression",
keywords = "Transition delay fault",
keywords = "Skewed-load",
keywords = "Fault coverage",
keywords = "Test length ",
abstract = "Skewed-load tests ensure application of delay tests to logic cores of system-on-chip with only one storage element per cell in the wrapper boundary register and in the internal scan chain. This resolves the test area problem but the fault coverage and the test application time still require optimization efforts. The satisfiability-based test pattern generator of compressed skewed-load tests for transition delay fault is proposed. It represents a new efficient approach for generating compressed skewed-load tests because the test is gradually generated without the need of a pre-generated set of initialization and excitation vectors. Two optimization methods are also proposed. The first method, the wrapper cell ordering method, increases the fault coverage by reducing the shift dependence of skewed-load tests. The second method, the fault ordering method, ensures shorter tests by determining the order in which the faults will be targeted during the test generation and consequently, the new test vectors can overlap the test sequence in the greatest degree. The proposed methods were evaluated over benchmark circuits and the experimental results show higher fault coverages and shorter test lengths. "
}
@incollection{Chapman2016295,
title = "Chapter 10 - Traffic performance testing in the network ",
editor = "Chapman, Chris ",
booktitle = "Network Performance and Security ",
publisher = "Syngress",
edition = "",
address = "Boston",
year = "2016",
pages = "295 - 317",
isbn = "978-0-12-803584-9",
doi = "https://doi.org/10.1016/B978-0-12-803584-9.00010-X",
url = "https://www.sciencedirect.com/science/article/pii/B978012803584900010X",
author = "Chris Chapman",
keywords = "network performance streams",
keywords = "flows",
keywords = "traffic analysis ",
abstract = "Abstract We show how you may use open source tools to measure network performance. We cover key performance topics like streams and flows, as well as how to set them up and measure them. Last, we discuss how to interpret results. "
}
@article{Gao2018294,
title = "Causal data science for financial stress testing ",
journal = "Journal of Computational Science ",
volume = "26",
number = "",
pages = "294 - 304",
year = "2018",
note = "",
issn = "1877-7503",
doi = "https://doi.org/10.1016/j.jocs.2018.04.003",
url = "https://www.sciencedirect.com/science/article/pii/S1877750317311377",
author = "Gelin Gao and Bud Mishra and Daniele Ramazzotti",
keywords = "Stress testing",
keywords = "Graphical models",
keywords = "Causality",
keywords = "Suppes-Bayes Causal Networks",
keywords = "Classification",
keywords = "Decision trees ",
abstract = "Abstract The most recent financial upheavals have cast doubt on the adequacy of some of the conventional quantitative risk management strategies, such as VaR (Value at Risk), in many common situations. Consequently, there has been an increasing need for verisimilar financial stress testings, namely simulating and analyzing financial portfolios in extreme, albeit rare scenarios. Unlike conventional risk management which exploits statistical correlations among financial instruments, here we focus our analysis on the notion of probabilistic causation, which is embodied by Suppes-Bayes Causal Networks (SBCNs); \{SBCNs\} are probabilistic graphical models that have many attractive features in terms of more accurate causal analysis for generating financial stress scenarios. In this paper, we present a novel approach for conducting stress testing of financial portfolios based on \{SBCNs\} in combination with classical machine learning classification tools. The resulting method is shown to be capable of correctly discovering the causal relationships among financial factors that affect the portfolios and thus, simulating stress testing scenarios with a higher accuracy and lower computational complexity than conventional Monte Carlo simulations. "
}
@article{Post20081673,
title = "Saline soak tests to determine the short-term reliability of an in situ thin film resistance temperature detector ",
journal = "Microelectronics Reliability ",
volume = "48",
number = "10",
pages = "1673 - 1682",
year = "2008",
note = "",
issn = "0026-2714",
doi = "https://doi.org/10.1016/j.microrel.2008.05.002",
url = "https://www.sciencedirect.com/science/article/pii/S0026271408001261",
author = "Julian W. Post and A. Bhattacharyya",
abstract = "With an objective to assess the short-term reliability of thin film, encapsulated resistance temperature detectors (RTDs) in corrosive environments, these were placed in aqueous soak solutions of double de-ionized water (DDI) and phosphate buffered solution (PBS) or saline for eight weeks. They were removed weekly in order to characterize the effects of the solutions on their electrical properties, as well as their thermal response. The solutions were analyzed weekly as well with an FT-IR spectrometer in order to determine if chemical reactions took place during the soak tests and optical micrographic studies were carried out too. The \{RTDs\} appeared not to suffer degradation during the period of study. Nonetheless, it turned out that the soak tests offer a user-friendly and safe approach to remove the Benzocyclobutene (BCB) layer; this is an issue that is likely to be of some interest in the electronics fabrication community. "
}
@article{Unsever2015255,
title = "Numerical analyses of load tests on model foundations in dry sand ",
journal = "Computers and Geotechnics ",
volume = "63",
number = "",
pages = "255 - 266",
year = "2015",
note = "",
issn = "0266-352X",
doi = "https://doi.org/10.1016/j.compgeo.2014.10.005",
url = "https://www.sciencedirect.com/science/article/pii/S0266352X14001888",
author = "Y.S. Unsever and T. Matsumoto and M.Y. Özkan",
keywords = "Piled raft",
keywords = "Vertical load test",
keywords = "Horizontal load test",
keywords = "Numerical modelling",
keywords = "Hardening soil model ",
abstract = "Abstract In this study, a series of vertical and cyclic horizontal load tests on 3-pile piled raft model were carried out in dry sand to investigate the piled raft behaviour under combined loads. Also, numerical modelling of experiments were carried out by using \{FEM\} software, \{PLAXIS\} 3D. Hardening soil model was employed to model the sand, and elastic model was used for the pile and the raft. Soil parameters were estimated from consolidated drained triaxial tests carried on the sand samples and pile parameters were estimated from simple bending tests. It is seen that the behaviour of piled raft is considerably influenced by the interaction of the raft and the piles, and that it is not possible to estimate piled raft behaviour by examining its components individually. "
}
@incollection{Reeser20011051,
title = "Using stress test results to drive performance modeling: A case study in “Gray-Box” vendor analysis ",
editor = "Jorge Moreira de Souza, Nelson L.S. da Fonseca and Edmundo A. de Souza e Silva",
booktitle = "Teletraffic Engineering in the Internet EraProceedings of the International Teletraffic Congress - ITC-I7",
publisher = "Elsevier",
year = "2001",
volume = "4",
pages = "1051 - 1061",
series = "Teletraffic Science and Engineering ",
issn = "1388-3437",
doi = "https://doi.org/10.1016/S1388-3437(01)80191-8",
url = "https://www.sciencedirect.com/science/article/pii/S1388343701801918",
author = "P. Reeser",
abstract = "In this case study, we present the results of analysis of a Java-based vendor product that performs dynamic Web page construction in a distributed environment. Since the vendor's scripts are proprietary, we must rely on “gray-box” stress test results to identify performance bottlenecks and determine system capacity. We present a methodology for reverse-engineering stress test results to build performance models of the system internals, and use those models to “see” inside the box. This approach provided significant insights into the performance of the vendor's proprietary code, and afforded us better leverage in the vendor management process. In particular, the approach identified significant bottlenecks in the Java code that prevented the system from fully utilizing the hardware resources. The approach also exposed the system's behavior under overload, and revealed the need for overload controls. Based on our success, we recommend that stress testing be incorporated into the software development process, especially when development consists largely of integrating external vendor components. Furthermore, in the case of vendor-provided software, this approach offers perhaps the only way to “see” inside the code, and in the case of new programming languages such as Java, exposes anomalies that could not be predicted from past experience. "
}
@article{Bruce2018274,
title = "A multi-lake comparative analysis of the General Lake Model (GLM): Stress-testing across a global observatory network ",
journal = "Environmental Modelling & Software ",
volume = "102",
number = "",
pages = "274 - 291",
year = "2018",
note = "",
issn = "1364-8152",
doi = "https://doi.org/10.1016/j.envsoft.2017.11.016",
url = "https://www.sciencedirect.com/science/article/pii/S1364815216311562",
author = "Louise C. Bruce and Marieke A. Frassl and George B. Arhonditsis and Gideon Gal and David P. Hamilton and Paul C. Hanson and Amy L. Hetherington and John M. Melack and Jordan S. Read and Karsten Rinke and Anna Rigosi and Dennis Trolle and Luke Winslow and Rita Adrian and Ana I. Ayala and Serghei A. Bocaniov and Bertram Boehrer and Casper Boon and Justin D. Brookes and Thomas Bueche and Brendan D. Busch and Diego Copetti and Alicia Cortés and Elvira de Eyto and J. Alex Elliott and Nicole Gallina and Yael Gilboa and Nicolas Guyennon and Lei Huang and Onur Kerimoglu and John D. Lenters and Sally MacIntyre and Vardit Makler-Pick and Chris G. McBride and Santiago Moreira and Deniz Özkundakci and Marco Pilotti and Francisco J. Rueda and James A. Rusak and Nihar R. Samal and Martin Schmid and Tom Shatwell and Craig Snorthheim and Frédéric Soulignac and Giulia Valerio and Leon van der Linden and Mark Vetter and Brigitte Vinçon-Leite and Junbo Wang and Michael Weber and Chaturangi Wickramaratne and R. Iestyn Woolway and Huaxia Yao and Matthew R. Hipsey",
keywords = "Lake model",
keywords = "Stratification",
keywords = "GLM",
keywords = "Model assessment",
keywords = "Global observatory data",
keywords = "Network science ",
abstract = "Abstract The modelling community has identified challenges for the integration and assessment of lake models due to the diversity of modelling approaches and lakes. In this study, we develop and assess a one-dimensional lake model and apply it to 32 lakes from a global observatory network. The data set included lakes over broad ranges in latitude, climatic zones, size, residence time, mixing regime and trophic level. Model performance was evaluated using several error assessment metrics, and a sensitivity analysis was conducted for nine parameters that governed the surface heat exchange and mixing efficiency. There was low correlation between input data uncertainty and model performance and predictions of temperature were less sensitive to model parameters than prediction of thermocline depth and Schmidt stability. The study provides guidance to where the general model approach and associated assumptions work, and cases where adjustments to model parameterisations and/or structure are required. "
}
@article{Gaone2018253,
title = "Large-scale shallow foundation load tests on soft clay – At the National Field Testing Facility (NFTF), Ballina, NSW, Australia ",
journal = "Computers and Geotechnics ",
volume = "93",
number = "",
pages = "253 - 268",
year = "2018",
note = "Ballina Embankment Prediction Symposium ",
issn = "0266-352X",
doi = "https://doi.org/10.1016/j.compgeo.2017.05.008",
url = "https://www.sciencedirect.com/science/article/pii/S0266352X17301180",
author = "F.M. Gaone and S. Gourvenec and J.P. Doherty",
keywords = "Shallow foundations",
keywords = "Field testing",
keywords = "Soft clay ",
abstract = "Abstract This paper presents field test data from four instrumented rigid square pad foundations on soft clay that were brought to failure under concentric vertical loading. The test programme comprised two unconsolidated undrained (UU) foundation tests as well as two consolidated undrained (CU) tests. In the latter case the two foundations were preloaded to a proportion of the \{UU\} capacity and the soil was allowed to consolidate before being brought to undrained failure. In this paper, the site works and testing procedures are presented along with the load- and time-settlement responses of all four foundations. Horizontal stress and pore pressure data are presented for the two \{CU\} tests. The undrained and consolidated undrained load-settlement responses are shown to agree well with theoretical and numerical predictions. Results from the \{UU\} tests were the subject of a prediction exercise, summarised in a companion paper presented in this special issue. "
}
@article{Kar2013164,
title = "Comparison study on reliability performance for polymer core solder balls under multiple reflow and \{HTS\} stress tests ",
journal = "Microelectronics Reliability ",
volume = "53",
number = "1",
pages = "164 - 173",
year = "2013",
note = "Reliability of Micro-Interconnects in 3D \{IC\} Packages ",
issn = "0026-2714",
doi = "https://doi.org/10.1016/j.microrel.2012.07.032",
url = "https://www.sciencedirect.com/science/article/pii/S0026271412003836",
author = "Yap Boon Kar and Tan Cai Hui and Ramasamy Agileswari and Calvin Lo",
abstract = "Drop ball reliability for Ball Grid Array (BGA) package on lead-free product is a major reliability concern. Integrating a polymer core in the solder ball could be a good strategy to dissipate stress better compared to the purely metallic solder ball. However, the diffusion rate of the copper is much faster than the diffusion rate of the solder. Hence, Kirkendall voids starts forming and causing crack between the interface of copper and solder. This could affect the solder joint as well as the solder ball drop reliability especially when subjected to high temperature stress. The new polymer core solder ball with 1 μm thickness of nickel (Ni) coated on the copper (polymer core/copper/nickel/solder) could offer better solder ball joint and drop reliability performance. This work studies the effects of \{IMC\} growth, solder ball shear strength and drop test reliability. Subsequently, the failure modes were observed after multiple reflow (up to 5 times) and \{HTS\} stress tests. The \{IMC\} formation was observed under the high power scope with magnification 50× via the mechanical cross-section and was measured using an analytical software tool. Solder ball shear test was carried out to measure the solder joint performance after multiple reflow and \{HTS\} stress tests via the Dage 4000 series bond tester. Drop reliability test was carried out via the packing drop test. From this study, we could conclude that the polymer core solder ball with an additional Ni layer coating demonstrates better performance than the polymer core solder ball without Ni layer. The same observation applies to the solder ball shear strength, drop reliability performance in multiple reflow and \{HTS\} stress tests. The \{IMC\} thickness for polymer core solder ball without additional Ni layer is much thicker than the polymer core solder ball with an additional Ni layer, most probably because Ni could limit the Cu diffusion into the solder, thus resulting in better reliability performance. "
}
@article{Gao2017272,
title = "Efficient Simulation of Financial Stress Testing Scenarios with Suppes-Bayes Causal Networks ",
journal = "Procedia Computer Science ",
volume = "108",
number = "",
pages = "272 - 284",
year = "2017",
note = "International Conference on Computational Science, \{ICCS\} 2017, 12-14 June 2017, Zurich, Switzerland ",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2017.05.167",
url = "https://www.sciencedirect.com/science/article/pii/S1877050917307500",
author = "Gelin Gao and Bud Mishra and Daniele Ramazzotti",
keywords = "stress Testing",
keywords = "Graphical Models",
keywords = "Causality",
keywords = "Suppes-Bayes Causal Networks",
keywords = "Classification",
keywords = "Decision Trees ",
abstract = "Abstract The most recent financial upheavals have cast doubt on the adequacy of some of the conventional quantitative risk management strategies, such as VaR (Value at Risk), in many common situations. Consequently, there has been an increasing need for verisimilar financial stress testings, namely simulating and analyzing financial portfolios in extreme, albeit rare scenarios. Unlike conventional risk management which exploits statistical correlations among financial instruments, here we focus our analysis on the notion of probabilistic causation, which is embodied by Suppes-Bayes Causal Networks (SBCNs), \{SBCNs\} are probabilistic graphical models that have many attractive features in terms of more accurate causal analysis for generating financial stress scenarios. In this paper, we present a novel approach for conducting stress testing of financial portfolios based on \{SBCNs\} in combination with classical machine learning classification tools. The resulting method is shown to be capable of correctly discovering the causal relationships among financial factors that affect the portfolios and thus, simulating stress testing scenarios with a higher accuracy and lower computational complexity than conventional Monte Carlo Simulations. "
}
@article{Lin2012106,
title = "Design and implementation of a drilled shaft load test database ",
journal = "Computers and Geotechnics ",
volume = "41",
number = "",
pages = "106 - 113",
year = "2012",
note = "",
issn = "0266-352X",
doi = "https://doi.org/10.1016/j.compgeo.2011.12.001",
url = "https://www.sciencedirect.com/science/article/pii/S0266352X11001959",
author = "Shiu-Shin Lin and Maria Cecilia M. Marcos and Hsin-Wen Chang and Yit-Jin Chen",
keywords = "Database",
keywords = "MySQL program",
keywords = "Drilled shafts",
keywords = "Load tests ",
abstract = "This paper details the development and potential of the drilled shaft load test (DSLT) database in which 351 case histories of static load tests from various countries can be freely retrieved and utilized worldwide. Employing the Entity-Relationship (ER) model to the structure design of the database provides considerable flexibility and extensibility while the open source MySQL server systematically compiles the historic data. \{DSLT\} enables quick browsing, inexpensive query, and utility of data as pile design tools or as relevant data for advanced research. Moreover, it can serve as a data platform for a centralized storage of information among interested pile data holders worldwide. "
}
@article{Mitra2013365,
title = "Cost Optimized Set of Primes Generation with Cellular Automata for Stress Testing in Distributed Computing ",
journal = "Procedia Technology ",
volume = "10",
number = "",
pages = "365 - 372",
year = "2013",
note = "First International Conference on Computational Intelligence: Modeling Techniques and Applications (CIMTA) 2013 ",
issn = "2212-0173",
doi = "https://doi.org/10.1016/j.protcy.2013.12.372",
url = "https://www.sciencedirect.com/science/article/pii/S2212017313005343",
author = "Arnab Mitra and Anirban Kundu",
keywords = "Distributed Computing",
keywords = "Stress Testing",
keywords = "Torture Testing",
keywords = "Primes",
keywords = "Fermat Primality",
keywords = "Cellular Automata (CA)",
keywords = "Equal Length Cellular Automata (ELCA) ",
abstract = "Abstract A sophisticated approach towards generation procedure of set of prime numbers using Cellular Automata (CA) has been reported here. Unique property of “Primality” found in prime numbers, has initiated a vast application and requirements for primes in many engineering and scientific applications. In this research, we have put an emphasis on cost efficient generation procedure for set of primes using \{CA\} for stress testing in distributed computing. An n-cell null boundary CA, have been considered to generate set of primes in cost effective method. Primality in generated pattern by \{CA\} has been verified with Fermat Primality Test. Proposed design for generation of primes to perform stress testing, is a cost effective solution. Physical implementation of system is cheap, since \{CA\} provides better flexibility and physical solution in designing the necessary hardware circuits at nominal cost. "
}
@article{Ataei2005678,
title = "Sensor fusion of a railway bridge load test using neural networks ",
journal = "Expert Systems with Applications ",
volume = "29",
number = "3",
pages = "678 - 683",
year = "2005",
note = "",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2005.04.038",
url = "https://www.sciencedirect.com/science/article/pii/S0957417405000849",
author = "Sh. Ataei and A.A. Aghakouchak and M.S. Marefat and S. Mohammadzadeh",
keywords = "Learning theory",
keywords = "Neural networks",
keywords = "Sensor fusion",
keywords = "Railway bridge",
keywords = "Lad test",
keywords = "Model updating ",
abstract = "Field testing of bridge vibrations induced by passage of vehicle is an economic and practical form of bridge load testing. Data processing of this type of tests are usually carried out in a system identification framework using output measurements techniques which are categorized as parametric or nonparametric methods. These methods are based on the theory of probability. Learning theory which stems its origin from two separate disciplines of statistical learning theory and neural networks, presents an efficient and robust framework for data processing of such tests. In this article, the linear two layer feed forward neural network (NN) with back propagation learning rule has been adapted for strain and displacement sensors fusion of a railway bridge load test. The trained \{NN\} has been used for structural analysis and finite element (FE) model updating. "
}
@article{Ju2015910,
title = "Behavioral technology credit scoring model with time-dependent covariates for stress test ",
journal = "European Journal of Operational Research ",
volume = "242",
number = "3",
pages = "910 - 919",
year = "2015",
note = "",
issn = "0377-2217",
doi = "https://doi.org/10.1016/j.ejor.2014.10.054",
url = "https://www.sciencedirect.com/science/article/pii/S0377221714008765",
author = "Yonghan Ju and Song Yi Jeon and So Young Sohn",
keywords = "Technology credit scoring",
keywords = "Stress test",
keywords = "Time-varying covariate",
keywords = "Survival analysis ",
abstract = "Abstract Technology based loan default is related not only to technology-oriented attributes (management, technology, profitability and marketability), and firm-specific characteristics but also to the economic situation after the loan. However, the default phenomenon for technology based loan has not reflected the change of economic situation. We propose a framework of utilizing a time varying Cox hazard proportional model in the context of technology based credit scoring. The proposed model is used for stress test with various scenarios of lending portfolio and economic situations. The results indicate that the firms with higher management score than average have the lower loan default rates than the firms with higher profitability or marketability score than average due to the effect of manager's knowledge and experience and fund supply ability when they are exposed under the same economic condition. In scenario test, we found the highest default rate under stable exchange rate with high consumer price index. Moreover, firms with a high level of marketability factors turn out to be significantly affected by economic conditions in terms of technology credit risk. We expect the result of this study can provide valuable feedback for the management of technology credit fund for SMEs. "
}
@article{Antonelo2018598,
title = "Reservoir computing for detection of steady state in performance tests of compressors ",
journal = "Neurocomputing ",
volume = "275",
number = "",
pages = "598 - 607",
year = "2018",
note = "",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2017.09.005",
url = "https://www.sciencedirect.com/science/article/pii/S0925231217314765",
author = "Eric Aislan Antonelo and Carlos Alberto Flesch and Filipe Schmitz",
keywords = "Reservoir computing",
keywords = "Echo state networks",
keywords = "Subspace projection",
keywords = "Unsupervised learning",
keywords = "Detection of steady state",
keywords = "Refrigeration compressors ",
abstract = "Abstract Fabrication of devices in industrial plants often includes undergoing quality assurance tests or tests that seek to determine some attributes or capacities of the device. For instance, in testing refrigeration compressors, we want to find the true refrigeration capacity of the compressor being tested. Such test (also called an episode) may take up to four hours, being an actual hindrance to applying it to the total number of compressors produced. This work seeks to reduce the time spent on such industrial trials by employing Recurrent Neural Networks (RNNs) as dynamical models for detecting when a test is entering the so-called steady-state region. Specifically, we use Reservoir Computing (RC) networks which simplify the learning of \{RNNs\} by speeding up training time and showing convergence to a global optimum. Also, this work proposes a self-organized subspace projection method for \{RC\} networks which uses information from the beginning of the episode to define a cluster to which the episode belongs to. This assigned cluster defines a particular binary input that shifts the operating point of the reservoir to a subspace of trajectories for the duration of the episode. This new method is shown to turn the \{RC\} model robust in performance with respect to varying combination of reservoir parameters, such as spectral radius and leak rate, when compared to a standard \{RC\} network. "
}
@article{Jones2018304,
title = "Performance testing of work shoes labeled as slip resistant ",
journal = "Applied Ergonomics ",
volume = "68",
number = "",
pages = "304 - 312",
year = "2018",
note = "",
issn = "0003-6870",
doi = "https://doi.org/10.1016/j.apergo.2017.12.008",
url = "https://www.sciencedirect.com/science/article/pii/S0003687017302739",
author = "Taylor Jones and Arian Iraqi and Kurt Beschorner",
keywords = "Coefficient of friction",
keywords = "Shoe outsole",
keywords = "Slip and fall accidents ",
abstract = "Abstract The variability in friction and slip propensity across slip resistant (SR) shoes is poorly understood. This study aimed to quantify the impact of shoe design features on the available coefficient of friction (ACOF) across shoes labeled as SR. Differences in \{ACOF\} and the slipping rate across \{SR\} shoes were also quantified. Twelve shoes were tested across five types of flooring and three contaminant conditions using a whole shoe mechanical slip tester. Geometric and hardness parameters were measured to determine the effect of heel outsole design on ACOF. The rate of slipping was evaluated for three of the shoes on vinyl tile with canola oil using human subjects. Differences in \{ACOF\} were significant across shoe outsole designs (p &lt; .001). \{ACOF\} was correlated with geometrical and hardness parameters. Rate of slipping was lower for the highest \{ACOF\} shoe (p &lt; .001). This information can be used to guide \{SR\} shoe selection and design. "
}
@article{Che201436,
title = "Passive performance testing of network protocols ",
journal = "Computer Communications ",
volume = "51",
number = "",
pages = "36 - 47",
year = "2014",
note = "",
issn = "0140-3664",
doi = "https://doi.org/10.1016/j.comcom.2014.06.001",
url = "https://www.sciencedirect.com/science/article/pii/S0140366414002096",
author = "Xiaoping Che and Stephane Maag",
keywords = "Passive testing",
keywords = "Performance testing",
keywords = "Session Initiation Protocol ",
abstract = "Abstract Complementary to performance evaluation, performance testing of communicating protocols is a qualitative and quantitative test of a system, aiming at checking whether performance requirements of protocols have been satisfied under certain conditions. It raises an interesting issue of accurately formalizing specified performance requirements by taking consideration of data values of the protocol messages. In this paper, we present a novel logic-based testing approach to check protocol performance requirements through real execution traces and formally specified properties. In order to evaluate and assess our methodology, we develop a prototype and present experiments through a set of Session Initiation Protocol (SIP) properties. Finally, a performance benchmark method is proposed and relevant verdicts and discussions are provided. "
}
@article{Cai2016635,
title = "Effects of stress-loading test methods on the degradation of light-emitting diode modules ",
journal = "Microelectronics Reliability ",
volume = "64",
number = "",
pages = "635 - 639",
year = "2016",
note = "Proceedings of the 27th European Symposium on Reliability of Electron Devices, Failure Physics and AnalysisProceedings of the 27th European Symposium on Reliability of Electron Devices, Failure Physics and Analysis ",
issn = "0026-2714",
doi = "https://doi.org/10.1016/j.microrel.2016.07.009",
url = "https://www.sciencedirect.com/science/article/pii/S0026271416301561",
author = "Miao Cai and Daoguo Yang and Jianna Zheng and Jianlin Huang and Dongjing Liu and Jing Xiao and Ping Zhang and Guoqi Zhang and Xianping Chen",
keywords = "\{LED\} lamp module",
keywords = "Step-down stress accelerated degradation testing",
keywords = "Step-up stress accelerated degradation testing",
keywords = "Constant stress accelerated degradation testing",
keywords = "Degradation",
keywords = "Capability of heat dissipation ",
abstract = "Abstract This study investigates the degradation of light-emitting diode (LED) lamp modules by various stress–load test approaches, namely, step-up stress accelerated degradation testing, step-down stress accelerated degradation testing (SDSADT), and constant stress accelerated degradation testing. Two types of commercial \{LED\} lamps with different capabilities of heat dissipation (CHDs) are utilized in the experiment. LM-80 testing on two types of \{LED\} packages is further implemented to reproduce the degradation reaction of Lamp B. Result shows that \{SDSADT\} can effectively alleviate the initial increase in optical parameters. Lamp B with a strong \{CHD\} exhibits a similar lumen decay rate at each stress of step stress testing; this similarity implies that the decay rate of Lamp B is only related to the current loaded stress. The lumen decay rate of the initial decay paths for Lamp B as the thermal stress increases exhibits a parabolic law. This parabolic pattern is also detected in the LM-80 testing for the \{LED\} packages and is explained by the strong \{CHD\} of Lamp B. The thermally induced mechanisms, which influence the optical emission of LEDs, should be responsible for the parabolic decay law. Moreover, the color shift of the \{LED\} modules with increasing loaded stresses is more sensitive than lumen degradation. "
}
@article{Hu201481,
title = "Ontology-based scenario modeling and analysis for bank stress testing ",
journal = "Decision Support Systems ",
volume = "63",
number = "",
pages = "81 - 94",
year = "2014",
note = "1. Business Applications of Web of Things 2. Social Media Use in Decision Making ",
issn = "0167-9236",
doi = "https://doi.org/10.1016/j.dss.2013.08.009",
url = "https://www.sciencedirect.com/science/article/pii/S0167923613002224",
author = "Daning Hu and Jiaqi Yan and J. Leon Zhao and Zhimin Hua",
keywords = "Bank stress testing",
keywords = "Ontology",
keywords = "Scenario modeling",
keywords = "Plausibility check ",
abstract = "Abstract The 2008 banking crisis demonstrated that there is a lack of effective methods for modeling and analyzing “exceptional but plausible” risk scenarios in bank stress testing. Existing stress testing practices mainly focus on modeling probability-based risk factors and events in banking systems using historical data. Rare (low probability) risk events that can cause financial crises in banking systems, such as the bankruptcy of Lehman Brothers, are largely ignored due to the lack of appropriate modeling and analysis methods. To address this problem, we propose an approach called Banking Event-driven Scenario-oriented Stress Testing (or simply, BESST) which has two main components: 1) an ontology-based event-driven scenario model (OESM), and 2) two analysis methods based on \{OESM\} for scenario recommendation and plausibility checking. The proposed \{BESST\} approach provides bank stress testing stakeholders an effective method for modeling and analyzing financial crisis scenarios that are rare but often have significant consequences. "
}
@article{Bahi20071680,
title = "Sequential environmental stresses tests qualification for automotive components ",
journal = "Microelectronics Reliability ",
volume = "47",
number = "9–11",
pages = "1680 - 1684",
year = "2007",
note = "18th European Symposium on Reliability of Electron Devices, Failure Physics and Analysis ",
issn = "0026-2714",
doi = "https://doi.org/10.1016/j.microrel.2007.07.004",
url = "https://www.sciencedirect.com/science/article/pii/S0026271407002569",
author = "M.A. Bahi and P. Lecuyer and H. Fremont and J-P. Landesman",
abstract = "The purpose is to create a new qualification methodology for plastic encapsulated electronic components used in an automotive environment at high temperature. It is based on the acceleration of failure mechanisms like ball bond lift (due to intermetallic Au–Al thickness growth), by combination of environmental stresses. The delamination measurement was used as an indicator of potential assembly weaknesses. An optimized package sequential qualification test flow is proposed. "
}
@article{González2009673,
title = "Reliability analysis of temperature step-stress tests on III–V high concentrator solar cells ",
journal = "Microelectronics Reliability ",
volume = "49",
number = "7",
pages = "673 - 680",
year = "2009",
note = "",
issn = "0026-2714",
doi = "https://doi.org/10.1016/j.microrel.2009.04.001",
url = "https://www.sciencedirect.com/science/article/pii/S0026271409001115",
author = "José Ramón González and Manuel Vázquez and Neftalí Núñez and Carlos Algora and Ignacio Rey-Stolle and Beatriz Galiana",
abstract = "III–V high concentrator solar cells are promising candidates for reducing the cost of photovoltaic electricity in terrestrial applications. However, the knowledge on the reliability of these devices is still scarce. Solar panels based on III–V high concentrator solar cells are about to be commercially available, and must compete with conventional systems based on silicon which have guarantees of approximately 25 years. This paper presents results of step-stress accelerated ageing tests carried out on these solar cells. Data have been analyzed according to Weibull reliability function. This analysis yields a lower value of the \{MTTF\} of 2.02 × 105 h (i.e. about 69.2 years assuming 8 h of average operation per day in a year) for a confidence interval of 90%. "
}
@article{Winter200799,
title = "Model-driven Transformation-based Generation of Java Stress Tests ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "174",
number = "1",
pages = "99 - 114",
year = "2007",
note = "Proceedings of the 7th International Workshop on Rule Based Programming (RULE 2006) ",
issn = "1571-0661",
doi = "https://doi.org/10.1016/j.entcs.2006.10.022",
url = "https://www.sciencedirect.com/science/article/pii/S1571066107001569",
author = "Victor L. Winter",
keywords = "program transformation",
keywords = "strategic programming",
keywords = "Java class initialization",
keywords = "&lt;clinit&gt; method",
keywords = "JVM",
keywords = "TL",
keywords = "HATS ",
abstract = "This paper describes a practical application of transformation-based analysis and code generation. An overview is given of an approach for automatically constructing Java stress tests whose execution exercises all “interesting” class initialization sequence possibilities for a given class hierarchy. "
}
@article{Nowogrodzki201522,
title = "Stress tests for medics keep tabs on their health ",
journal = "New Scientist ",
volume = "228",
number = "3045",
pages = "22 - ",
year = "2015",
note = "",
issn = "0262-4079",
doi = "https://doi.org/10.1016/S0262-4079(15)31507-4",
url = "https://www.sciencedirect.com/science/article/pii/S0262407915315074",
author = "Anna Nowogrodzki"
}
@article{Tsai2011205,
title = "A wavelet based method for estimating the damping ratio in statnamic pile load tests ",
journal = "Computers and Geotechnics ",
volume = "38",
number = "2",
pages = "205 - 216",
year = "2011",
note = "",
issn = "0266-352X",
doi = "https://doi.org/10.1016/j.compgeo.2010.11.007",
url = "https://www.sciencedirect.com/science/article/pii/S0266352X10001618",
author = "Pei-hsun Tsai and Zheng-yi Feng and Shang-yuh Lin",
keywords = "Statnamic load test",
keywords = "Damping coefficient",
keywords = "Continuous wavelet transform ",
abstract = "A wavelet based method is proposed to evaluate the time-dependent damping ratio in statnamic load tests by the continuous wavelet transform and half-power bandwidth method. The displacement along the pile during a statnamic test is described by a linear shape function, although the pile is assumed to be a single degree of freedom system (SDOF). The damping ratio is calculated by the half-power bandwidth method from the time–frequency spectra of continuous wavelet transform for the statnamic pile load test. A numerical simulation and two field statnamic tests were analyzed to verify the applicability of the proposed method, and the outcomes were compared with the results obtained using the unloading point method (UPM) and a method in literature. The damping ratio obtained with the proposed method is satisfactory and provides an additional interpretation measure for statnamic load tests. "
}
@article{Bucur201522,
title = "Characterizing topological bottlenecks for data delivery in \{CTP\} using simulation-based stress testing with natural selection ",
journal = "Ad Hoc Networks ",
volume = "30",
number = "",
pages = "22 - 45",
year = "2015",
note = "",
issn = "1570-8705",
doi = "https://doi.org/10.1016/j.adhoc.2015.02.005",
url = "https://www.sciencedirect.com/science/article/pii/S1570870515000426",
author = "Doina Bucur and Giovanni Iacca and Pieter-Tjerk de Boer",
keywords = "Routing",
keywords = "Collection Tree Protocol",
keywords = "Performance evaluation",
keywords = "Data delivery ratio ",
abstract = "Abstract Routing protocols for ad-hoc networks, e.g., the Collection Tree Protocol (CTP), are designed with simple node-local behaviour, but are deployed on testbeds with uncontrollable physical topology; exhaustively verifying the protocol on all possible topologies at design time is not tractable. We obtain topological insights on \{CTP\} performance, to answer the question: Which topological patterns cause \{CTP\} data routing to fail? We stress-test \{CTP\} with a quantitative testing method which searches for topologies using evolutionary algorithms combined with protocol simulation. The method iteratively generates new test topologies, such that the execution of the protocol over these topologies shows increasingly worse data-delivery ratios (DDR). We obtain a large set of example topologies of different network sizes up to 50 nodes, network densities, data rates, table sizes, and radio-frequency noise models, which, although connected, trigger a data delivery of nearly zero. We summarize these topologies into three types of topological problems, the root cause of which is the presence of certain asymmetric links and cycles, combined with a certain size of the routing table. We verify causality, i.e., show that randomly generated topologies having these particular features do cause low \{DDR\} in CTP. This testing methodology, while computationally intensive, is sound, fully automated and has better coverage over the corner cases of protocol behaviour than testing a protocol over manually crafted or random topologies. "
}
@incollection{Chapman20161,
title = "Chapter 1 - Introduction to practical security and performance testing ",
editor = "Chapman, Chris ",
booktitle = "Network Performance and Security ",
publisher = "Syngress",
edition = "",
address = "Boston",
year = "2016",
pages = "1 - 14",
isbn = "978-0-12-803584-9",
doi = "https://doi.org/10.1016/B978-0-12-803584-9.00001-9",
url = "https://www.sciencedirect.com/science/article/pii/B9780128035849000019",
author = "Chris Chapman",
keywords = "attack",
keywords = "DDoS",
keywords = "malware",
keywords = "penetration testing",
keywords = "volumetric attack",
keywords = "quality of experience (QoE)",
keywords = "perceptual user experience",
keywords = "firewall",
keywords = "IPS/IDS",
keywords = "proxy server",
keywords = "botnet",
keywords = "cross site scripting attack (XSS)",
keywords = "worm",
keywords = "virus",
keywords = "trojan horse attack",
keywords = "zero-day attack",
keywords = "SQL injection attack",
keywords = "hard QoE errors",
keywords = "soft QoE errors ",
abstract = "Abstract I will introduce the reader to some basic security concepts including types of attacks, best practices including description. Then network security devices and their subfunctions will be introduced. Finally, the user will understand what perception user experience is, how it is measured, the difference between soft and hard errors, and how users formulate quality of experience. "
}
@article{Beriro201275,
title = "Comments on “Empirical modelling of plate load test moduli of soil via gene expression programming” by Ali Mollahasani, Amir Hossein Alavi and Amir Hossein Gandomi [Computers and Geotechnics 38 (2011) 281–286] ",
journal = "Computers and Geotechnics ",
volume = "39",
number = "",
pages = "75 - 78",
year = "2012",
note = "",
issn = "0266-352X",
doi = "https://doi.org/10.1016/j.compgeo.2011.08.012",
url = "https://www.sciencedirect.com/science/article/pii/S0266352X11001431",
author = "Darren J. Beriro and Robert J. Abrahart and C. Paul Nathanail"
}
@article{Mollahasani201273,
title = "Reply to Comments on “Empirical modelling of plate load test moduli of soil via gene expression programming” by Ali Mollahasani, Amir Hossein Alavi, Amir Hossein Gandomi [Computers and Geotechnics 38 (2011) 281–286] ",
journal = "Computers and Geotechnics ",
volume = "39",
number = "",
pages = "73 - 74",
year = "2012",
note = "",
issn = "0266-352X",
doi = "https://doi.org/10.1016/j.compgeo.2011.08.009",
url = "https://www.sciencedirect.com/science/article/pii/S0266352X11001406",
author = "Ali Mollahasani and Amir Hossein Alavi and Amir Hossein Gandomi"
}
@article{Bortolan2015378,
title = "Noise processing in exercise \{ECG\} stress test for the analysis and the clinical characterization of \{QRS\} and T wave alternans ",
journal = "Biomedical Signal Processing and Control ",
volume = "18",
number = "",
pages = "378 - 385",
year = "2015",
note = "",
issn = "1746-8094",
doi = "https://doi.org/10.1016/j.bspc.2015.02.003",
url = "https://www.sciencedirect.com/science/article/pii/S1746809415000154",
author = "G. Bortolan and I. Christov and I. Simova and I. Dotsinsky",
keywords = "Signal filtering",
keywords = "Noise suppression",
keywords = "Principal Component Analysis",
keywords = "ECG stress test",
keywords = "Alternans ",
abstract = "Abstract The aim of this study is to analyze different sources of noise in \{ECG\} recordings from stress tests in order to obtain reliable parameters and measurements for the analysis of T-wave and QRS-complex alternans (TWA &amp; QRSA). Simple methods for eliminating common sources of noise like power-line interference, baseline drift and electromyographic noise were used. The pre-processing phase considered the detection of steep slope/spike, low amplitude signal, and flat line or missing lead artefacts. The detection of \{TWA\} and \{QRSA\} was based on Principal Component Analysis indices and wave amplitudes considering all the leads. A particular database of 106 \{ECG\} records during stress testing was considered. The signal quality analysis performed in this study has permitted to obtain reliable and noise-tolerant measurements of \{TWA\} and \{QRSA\} indices. The different diagnostic groups were used for the evaluation of the clinical significance of the alternans. Men have significantly higher values of \{QRSA\} than women. Smokers have significantly higher \{TWA\} values as compared with non-smokers. Significant negative correlation was obtained between age and both \{TWA\} and QRSA. Correlations between \{TWA\} and \{QRSA\} and the double product of arterial hypertension and the maximal heart rate during the stress test were statistically significant, positive and relatively strong. "
}
@article{Glavanovics20071790,
title = "Flexible active cycle stress testing of smart power switches ",
journal = "Microelectronics Reliability ",
volume = "47",
number = "9–11",
pages = "1790 - 1794",
year = "2007",
note = "18th European Symposium on Reliability of Electron Devices, Failure Physics and Analysis ",
issn = "0026-2714",
doi = "https://doi.org/10.1016/j.microrel.2007.07.065",
url = "https://www.sciencedirect.com/science/article/pii/S0026271407003216",
author = "Michael Glavanovics and Helmut Köck and Vladimir Košel and Tobias Smorodin",
abstract = "Active cycle stress testing of smart power switches is conventionally performed either with current pulses of constant amplitude or with waveforms derived by switching inductive loads. A flexible test system is introduced that is capable of generating arbitrary current pulse shapes, which is verified experimentally on a typical smart power switch. It is demonstrated by a test run that pulses with different shape and amplitude but equal thermal stress derived from thermal simulation lead to comparable cycle life time. "
}
@article{Chen2012822,
title = "Strength determination of high-power \{LED\} die using point-load and line-load tests ",
journal = "Microelectronics Reliability ",
volume = "52",
number = "5",
pages = "822 - 829",
year = "2012",
note = "Reliability of High-Power \{LED\} Packaging and Assembly ",
issn = "0026-2714",
doi = "https://doi.org/10.1016/j.microrel.2011.06.028",
url = "https://www.sciencedirect.com/science/article/pii/S0026271411002277",
author = "C.H. Chen and M.Y. Tsai",
abstract = "The strength of high-power light emitting diode (LED) dies, cut from wafers with a laser, has to be determined for the need of design and quality control in order to assure the good reliability of packages in manufacturing and service. The objective of this study is to determine the strength of high-power \{LED\} die with a size of 1 × 1 × 0.1 mm3 by point-load test (PLT) and line-load test (LLT) associated with a plate-on-elastic-foundation configuration. \{ANSYS\} (one of commercial finite element codes) analysis is used to calculate the stress distributions of the die under both \{PLT\} and LLT. The \{ANSYS\} models of the \{PLT\} and \{LLT\} are validated by comparing with experimental force–displacement curves, and the results are further used to convert the die failure force from the tests into the die strength. The mechanism of tensile-stress dominated die strength has been discussed and validated in detail via these test results and analyses. The results of the \{PLT\} and \{LLT\} also indicate that for the die failure on chip surface, the average die strengths are about 1.44 \{GPa\} and 1.52 \{GPa\} from the \{PLTs\} with two different-radius pins, and about 1.2 \{GPa\} from the LLT. On the other hand, for failures on sapphire surface, the average die strengths are reasonably about 1.49 \{GPa\} and 1.26 \{GPa\} from the two PLTs, but the average one from the \{LLT\} is about 0.64 \{GPa\} (with less than 50% of the values from the PLT). The inconsistent data between two \{PLT\} and \{LLT\} for failure on sapphire surfaces were found to result from the edge chipping of the die specimen observed by scanning electron microscopy. It was also observed that the thin-layer GaN material has to be taken into account in the \{ANSYS\} analyses with a bi-material model of the \{LED\} die for precisely determining the die strength for failure on the chip surface. Otherwise, these strength data would be overestimated by a few tens of percent with a uni-material model of the \{LED\} die. All in all, this study has successfully demonstrated that the \{LED\} die strength can be determined by these feasible, easy-to-use and reliable test methods. "
}
@incollection{Olexa2005213,
title = "Chapter 8 - Network Performance Testing and Troubleshooting ",
editor = "Olexa, Ron ",
booktitle = "Implementing 802.11, 802.16, and 802.20 Wireless Networks ",
publisher = "Newnes",
edition = "",
address = "Burlington",
year = "2005",
pages = "213 - 222",
isbn = "978-0-7506-7808-7",
doi = "https://doi.org/10.1016/B978-075067808-7/50010-9",
url = "https://www.sciencedirect.com/science/article/pii/B9780750678087500109",
author = "Ron Olexa",
abstract = "Publisher Summary Radio frequency related network problems manifest themselves in numerous ways. The connection to the network may be unstable, the connection speed may be slow, the user may notice slow response to network queries, or there may be noticeable “holes” in the desired coverage area. The most common cause of such problems is low signal-to-noise ratio (SNR). This can be caused by too much path attenuation, higher than expected interference levels, or the result of impaired antenna systems or failing hardware. Another cause is client “bouncing,” which is the tendency for a client at the edge of coverage of two or more base stations to bounce from base station to base station in search of better signal strength. This is the result of low \{SNR\} coupled with the search threshold levels set in the client. This problem is quite common in 802.11 systems but may not be a problem in more complex solutions. "
}
@article{Hernandez20072732,
title = "Optimal estimation of the relevant information coming from a variable reluctance proximity sensor placed in a car undergoing performance tests ",
journal = "Mechanical Systems and Signal Processing ",
volume = "21",
number = "7",
pages = "2732 - 2739",
year = "2007",
note = "",
issn = "0888-3270",
doi = "https://doi.org/10.1016/j.ymssp.2007.02.005",
url = "https://www.sciencedirect.com/science/article/pii/S0888327007000362",
author = "Wilmar Hernandez",
keywords = "Wheel speed sensor",
keywords = "Adaptive noise canceller",
keywords = "Inverse QR-RLS adaptive filter ",
abstract = "Today's automotive industry has a soaring interest in efficient, reliable and robust sensors able to make intelligent driving decisions that can save millions of lives every year. To that end, the sensors used in today's cars are being provided with microprocessors and application-specific integrated circuit technologies that incorporate a certain amount of intelligence into the sensors themselves. In this paper, an inverse square-root adaptive filtering algorithm for recursive least-squares estimation (QR-RLS) is used to improve the response of a wheel speed sensor placed in a car undergoing performance tests. Such an algorithm is used to carry out an optimal estimation of the relevant signal coming from the sensor, which is buried in a broad-band noise background where we have little knowledge of the noise characteristics. The results of the experiment are satisfactory, a significant improvement of 32.5 dB in the signal-to-noise ratio at the QR-RLS adaptive filter output was achieved. Also, in order to compare classical filtering techniques with optimal adaptive filtering techniques, the signal coming from the wheel speed sensor was also filtered by using a second-order lowpass digital Butterworth filter. The results of comparing the aforementioned filters show that the optimal adaptive filter is superior to the classical filter. "
}
@article{Hélou2002313,
title = "Performance testing of a negotiation platform ",
journal = "Information and Software Technology ",
volume = "44",
number = "5",
pages = "313 - 330",
year = "2002",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/S0950-5849(01)00215-4",
url = "https://www.sciencedirect.com/science/article/pii/S0950584901002154",
author = "Charles Hélou and Rachida Dssouli and Teodor-Gabriel Crainic",
abstract = "Accessible from all over the world, the \{EC\} became an indispensable element to our society. It allows the use of electronic systems to exchange products, services and information between the different existent users. During these exchanges, it is very important to assure a good quality of service. However, the enormous expansion of the Internet users push its resources to the maximum of its limits, which provoke, in many cases, an important degradation in its performance. Consequently, it is primordial to analyze the capacity of servers in order to handle heavy workloads that are growing considerably as a function of the number of users. It is, therefore, necessary to conduct performance tests before servers' deployment in order to detect any imperfection and predict their behavior under stress. In this context, this paper present a simplified performance evaluation of the “alpha” version of a negotiation platform called Generic Negotiation Platform (GNP) dated on September 2000. This platform is still under development. Many performance factors could be examined in this evaluation. However, we considered only the response time factor because of its important impact on auctions and negotiations applications. We mostly oriented this study to give us an idea about the variation of the average response time of the server as a function of the number of users and the type of different transactions. We also tried to evaluate the effect of the auctions' rules on the server average response time. We limited our study to the close and open auctions at the second price. This study followed the traditional way of doing performance tests. Therefore, we fixed our test objectives and criterion and then create our own scripts. Once the nature of the workload of the server was specified, we created an adequate benchmark to generate requests to the server. Afterwards, the average response time of each considered transaction was collected. In order to interpret these results properly, we calculated the standard deviation and the coefficient of variation of each set of values. "
}
@article{Mollahasani2011281,
title = "Empirical modeling of plate load test moduli of soil via gene expression programming ",
journal = "Computers and Geotechnics ",
volume = "38",
number = "2",
pages = "281 - 286",
year = "2011",
note = "",
issn = "0266-352X",
doi = "https://doi.org/10.1016/j.compgeo.2010.11.008",
url = "https://www.sciencedirect.com/science/article/pii/S0266352X1000162X",
author = "Ali Mollahasani and Amir Hossein Alavi and Amir Hossein Gandomi",
keywords = "Soil deformation moduli",
keywords = "Soil physical properties",
keywords = "Gene expression programming",
keywords = "Nonlinear modeling ",
abstract = "New empirical models were developed to predict the soil deformation moduli using gene expression programming (GEP). The principal soil deformation parameters formulated were secant (Es) and reloading (Er) moduli. The proposed models relate Es and Er obtained from plate load-settlement curves to the basic soil physical properties. The best \{GEP\} models were selected after developing and controlling several models with different combinations of the influencing parameters. The experimental database used for developing the models was established upon a series of plate load tests conducted on different soil types at depths of 1–24 m. To verify the applicability of the derived models, they were employed to estimate the soil moduli of a part of test results that were not included in the analysis. The external validation of the models was further verified using several statistical criteria recommended by researchers. A sensitivity analysis was carried out to determine the contributions of the parameters affecting Es and Er. The proposed models give precise estimates of the soil deformation moduli. The Es prediction model provides considerably better results in comparison with the model developed for Er. The simplified formulation for Es significantly outperforms the empirical equations found in the literature. The derived models can reliably be employed for pre-design purposes. "
}
@incollection{AGerteisen1995277,
title = "Massive parallel implementation of the aircraft euler method and performance tests on different computational platforms ",
editor = "Ecer, A. and Hauser, J. and Leca, P.  and Periaux, J. ",
booktitle = "Parallel Computational Fluid Dynamics 1993 ",
publisher = "North-Holland",
edition = "",
address = "Amsterdam",
year = "1995",
pages = "277 - 285",
isbn = "978-0-444-81999-4",
doi = "https://doi.org/10.1016/B978-044481999-4/50159-6",
url = "https://www.sciencedirect.com/science/article/pii/B9780444819994501596",
author = "Edgar A. Gerteisen and Antony Jameson",
abstract = "Publisher Summary The aircraft Euler method, so-called airplane code, is a finite element based technique for solving the Euler equations combined with a method for constructing tetrahedral meshes. The attractiveness of an unstructured approach along with the demand of shortened turnaround times motivates a massively parallel implementation. The numerical method of airplane code and the guidelines for the parallelization strategy are outlined in this chapter. Performance results of the method have been carried out considering different massively parallel computational platforms, which demonstrate the portability of the current implementation. The results indicate that an efficient communication network is most crucial for parallel computing, especially with respect to scalability. The communication speed as well as the interconnection topology will be more important for modern parallel systems, which are based on latest processor technologies. This statement, however, refers to more or less communication intense algorithms well-known in computational fluid dynamics and may be totally different for other kind of scientific applications. "
}
@article{Rao1994229,
title = "Reliability physics of electronic devices through material characterization and environmental stress testing techniques ",
journal = "Microelectronics Reliability ",
volume = "34",
number = "2",
pages = "229 - 245",
year = "1994",
note = "",
issn = "0026-2714",
doi = "https://doi.org/10.1016/0026-2714(94)90105-8",
url = "https://www.sciencedirect.com/science/article/pii/0026271494901058",
author = "S.U.M. Rao",
abstract = "This paper describes the approach of reliability physics to develop and produce electronic devices with an acceptable yield and reliability. The importance of material characterization techniques for process monitoring and product failure analysis is discussed. The potential and significance of environmental stress testing which has established as a distinct technique is explained. The technique is used to understand wear-out (Defect) failure mechanism and for reliability prediction. As can be seen that reliability physics acts as a ‘Midwife’ for the development of better or new device and/or technology with desired reliability level. "
}
@article{Cividini2011287,
title = "A numerical interpretation of load tests on vibro-piles ",
journal = "Computers and Geotechnics ",
volume = "38",
number = "2",
pages = "287 - 297",
year = "2011",
note = "",
issn = "0266-352X",
doi = "https://doi.org/10.1016/j.compgeo.2010.11.009",
url = "https://www.sciencedirect.com/science/article/pii/S0266352X10001631",
author = "Annamaria Cividini and Livio Locatelli and Alessio Contini and Giancarlo Gioda",
keywords = "Load–settlement data",
keywords = "Piles",
keywords = "Granular soil",
keywords = "Finite element analyses ",
abstract = "The finite element interpretation is discussed of two load tests carried out on instrumented vibro-piles in a granular deposit. A first back analysis, aimed at assessing the improvement of the mechanical characteristics of soil induced by the vibratory construction process, highlights an apparent contradiction between the experimental variation of the axial load along the pile and the numerical results. This suggests introducing as a free variable, in addition to the elastic and shear strength parameters of the granular soil, also the increase of the nominal diameter of pile caused by vibrations. The second back analysis provides some insight into the variation of the diameter with depth and leads to an acceptable interpretation, from the engineering standpoint, of the load tests. On these bases a quantitative comparison is presented between the calculated load–settlement diagram of the vibro-pile and that of a “standard” pile constructed without vibrations in the same granular deposit. "
}
@article{Everett20115,
title = "Stress-testing Europe's critical infrastructure ",
journal = "Computer Fraud & Security ",
volume = "2011",
number = "7",
pages = "5 - 7",
year = "2011",
note = "",
issn = "1361-3723",
doi = "https://doi.org/10.1016/S1361-3723(11)70071-9",
url = "https://www.sciencedirect.com/science/article/pii/S1361372311700719",
author = "Cath Everett",
abstract = "Opinion is currently divided over whether the first pan-European test centering on the protection of critical national infrastructure is likely to lead to the introduction of new legislation in the area. Europe's first test of whether it could cope with a massive cyber-attack generated some useful lessons. The aim was to understand how well participating member states could collaborate to counter 320 simulated attempts by hackers to paralyse the Internet. However, the exercise also raised questions over whether more legislation might be required to ensure that organisations in both the public and private sector are able to co-operate more effectively. And it highlighted the need for the private sector – not involved in the exercise – to get involved directly in national cyber-security, as Cath Everett discovers. "
}
@article{Cramer2006363,
title = "The \{ADS40\} Vaihingen/Enz geometric performance test ",
journal = "\{ISPRS\} Journal of Photogrammetry and Remote Sensing ",
volume = "60",
number = "6",
pages = "363 - 374",
year = "2006",
note = "Digital Aerial Cameras ",
issn = "0924-2716",
doi = "https://doi.org/10.1016/j.isprsjprs.2006.05.004",
url = "https://www.sciencedirect.com/science/article/pii/S0924271606000578",
author = "Michael Cramer",
keywords = "ADS40",
keywords = "push-broom",
keywords = "georeferencing",
keywords = "performance",
keywords = "GPS/inertial ",
abstract = "This paper presents the main results of a comprehensive \{ADS40\} performance analysis conducted at the Vaihingen/Enz test field. As such it represents one example of an independent in-flight performance study for one of the new and commercially operational digital airborne camera systems. Based on a large number of well coordinated and defined object points, which served as independent check points, the absolute geometric accuracy of the \{ADS40\} from true operational data has been verified. Empirical analysis of data from flying heights ranging from 1500 m to 4000 m proved the \{ADS40\} geometric accuracy to be in the range of 1–2 μm at image scale for horizontal coordinates and 0.03–0.05‰ of the flying height for vertical components. This is fully within specification for airborne imaging. "
}
@article{McGenn20122880,
title = "Development of an \{RF\} \{IV\} waveform based stress test procedure for use on GaN \{HFETs\} ",
journal = "Microelectronics Reliability ",
volume = "52",
number = "12",
pages = "2880 - 2883",
year = "2012",
note = "27th \{JEDEC\} Reliability Of Compound Semiconductors Workshop (ROCS 2012) ",
issn = "0026-2714",
doi = "https://doi.org/10.1016/j.microrel.2012.09.007",
url = "https://www.sciencedirect.com/science/article/pii/S0026271412004490",
author = "William McGenn and Michael J. Uren and Johannes Benedikt and Paul J. Tasker",
abstract = "This paper reports on the development of an \{RF\} \{IV\} waveform based stress test procedure. \{DC\} and low-voltage \{RF\} characterisation was carried out before and after high power \{RF\} stress. \{RF\} waveform measurements showed that the exact change in the \{RF\} load line induced during \{RF\} degradation cannot be directly inferred from the \{DC\} or low power \{RF\} measurement. The \{RF\} degradation takes the form of a knee-walkout, a small pinch-off shift consistent with charge trapping and defect generation, and in addition gate leakage occurs once the \{RF\} voltage exceeds a critical voltage. "
}
@article{Basu2011329,
title = "Comparing simulation models for market risk stress testing ",
journal = "European Journal of Operational Research ",
volume = "213",
number = "1",
pages = "329 - 339",
year = "2011",
note = "",
issn = "0377-2217",
doi = "https://doi.org/10.1016/j.ejor.2011.02.023",
url = "https://www.sciencedirect.com/science/article/pii/S0377221711001780",
author = "Sanjay Basu",
keywords = "Risk management",
keywords = "Volatility updation",
keywords = "Tail diversification",
keywords = "Simulation models",
keywords = "Fat-tailed distributions ",
abstract = "The subprime crisis has reminded us that effective stress tests should not only combine subjective scenarios with historical data, but also be probabilistic. In this paper, we combine three hypothetical shocks, of varying degrees, with more than six years of daily data on USD-INR and Euro-INR. Our objective is to compare six simulation-based stress models for foreign exchange positions. We find that while volatility-weighted historical simulation is the best model for volatility persistence, jump diffusion based Monte Carlo simulation is better at capturing correlation breakdown. Loss estimates from very fat-tailed distributions are not sensitive to the severity of stress scenarios. "
}
@article{Bailón2010299,
title = "Analysis of heart rate variability during exercise stress testing using respiratory information ",
journal = "Biomedical Signal Processing and Control ",
volume = "5",
number = "4",
pages = "299 - 310",
year = "2010",
note = "",
issn = "1746-8094",
doi = "https://doi.org/10.1016/j.bspc.2010.05.005",
url = "https://www.sciencedirect.com/science/article/pii/S1746809410000418",
author = "Raquel Bailón and Luca Mainardi and Michele Orini and Leif Sörnmo and Pablo Laguna",
keywords = "Heart rate variability",
keywords = "Exercise stress testing",
keywords = "Respiratory frequency",
keywords = "Time–frequency analysis",
keywords = "Parametric decomposition ",
abstract = "This paper presents a novel method for the analysis of heart rate variability (HRV) during exercise stress testing enhanced with respiratory information. The instantaneous frequency and power of the low frequency (LF) and high frequency (HF) bands of the \{HRV\} are estimated by parametric decomposition of the instantaneous autocorrelation function (ACF) as a sum of damped sinusoids. The instantaneous \{ACF\} is first windowed and filtered to reduce the cross terms. The inclusion of respiratory information is proposed at different stages of the analysis, namely, the design of the filter applied to the instantaneous ACF, the parametric decomposition, and the definition of a dynamic \{HF\} band. The performance of the method is evaluated on simulated data as well as on a stress testing database. The simulation results show that the inclusion of respiratory information reduces the estimation error of the amplitude of the \{HF\} component from 3.5% to 2.4% in mean and related \{SD\} from 3.0% to 1.7% when a tuned time smoothing window is used at an \{SNR\} of 15 dB. Results from the stress testing database show that information on respiratory frequency produces \{HF\} power estimates which closely resemble those from the simulations which exhibited lower SD. The mean \{SD\} of these estimates with respect to their mean trends is reduced by 84% (from 0.74 × 1 0 − 3 s−2 to 0.12 × 1 0 − 3 s−2). The analysis of \{HRV\} in the stress testing database reveals a significant decrease in the power of both the \{LF\} and \{HF\} components around peak stress. "
}
@incollection{Jacob2008747,
title = "\{CHAPTER\} 23 - Performance Testing ",
editor = "Jacob, Bruce and Ng, Spencer W.  and Wang, David T. ",
booktitle = "Memory Systems ",
publisher = "Morgan Kaufmann",
edition = "",
address = "San Francisco",
year = "2008",
pages = "747 - 761",
isbn = "978-0-12-379751-3",
doi = "https://doi.org/10.1016/B978-012379751-3.50025-4",
url = "https://www.sciencedirect.com/science/article/pii/B9780123797513500254",
author = "Bruce Jacob and Spencer W. Ng and David T. Wang"
}
@article{Rodrigues2013898,
title = "An evolutionary strategy enhanced with a local search technique for the space allocation problem in architecture, Part 2: Validation and performance tests ",
journal = "Computer-Aided Design ",
volume = "45",
number = "5",
pages = "898 - 910",
year = "2013",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/j.cad.2013.01.003",
url = "https://www.sciencedirect.com/science/article/pii/S0010448513000055",
author = "Eugénio Rodrigues and Adélio Rodrigues Gaspar and Álvaro Gomes",
keywords = "Evolutionary strategy",
keywords = "Stochastic hill climbing",
keywords = "Space allocation problem",
keywords = "Space planning ",
abstract = "The first part of this paper proposed a hybrid evolutionary technique which helps architects to generate sets of floor plans in the early design stage. The algorithm is an enhanced Evolutionary Strategy (ES) with a Stochastic Hill Climbing (SHC) technique. In this second part, the validity and performance of the technique is examined. Four tests are conducted. Three validation tests are used to determine the ability of the algorithm to replicate a floor plan made by an architect; the ability to produce a set of different floor plan designs by comparing the results with a well-known enumerated floor plan solution; its capability to work with less constrained problems, and to control the variation in the floor plan form with different compactness evaluators’ weights. The last test determines the evolving behavior, the breakdown of the evaluators’ performance for the objective function, and the robustness of the algorithm. The methodologies used in the tests and the problem specifications are presented. Results and observations on the evaluators’ weights and their importance and the limitations of the technique are analyzed and discussed. Finally, the conclusion to this part of the paper is made. "
}
@article{Shen2001247,
title = "Investigation of point-to-point performance test of touch trigger probes on coordinate-measuring machines ",
journal = "Robotics and Computer-Integrated Manufacturing ",
volume = "17",
number = "3",
pages = "247 - 254",
year = "2001",
note = "",
issn = "0736-5845",
doi = "https://doi.org/10.1016/S0736-5845(00)00056-9",
url = "https://www.sciencedirect.com/science/article/pii/S0736584500000569",
author = "Yin-Lin Shen and Sung-Ho Moon",
keywords = "Probe performance test",
keywords = "Sampling plan",
keywords = "Pretravel error ",
abstract = "A major factor contributing to the total measuring error of coordinate measuring machines (CMMs) is the performance of the probing sub-system. Probing test methods are typically used to detect errors due to the probing sub-system. The probe performance evaluation method specified in the \{ANSI\} \{B89\} standard is investigated in this paper. The sampling plan associated in the probe performance evaluation was tested by using experimental probing data from a CMM. Research findings indicate that the performance of touch trigger probes is overestimated due to a systematic bias in the vertical direction of the best-fit reference ball center in the probe performance test. A two-latitude sampling plan synthesis method based on a pretravel model for touch trigger probes is proposed in this paper. The proposed method can be used to accurately identify the reference ball center in the performance test of touch trigger probes. "
}
@article{Babaoglu20092562,
title = "Assessment of exercise stress testing with artificial neural network in determining coronary artery disease and predicting lesion localization ",
journal = "Expert Systems with Applications ",
volume = "36",
number = "2, Part 1",
pages = "2562 - 2566",
year = "2009",
note = "",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2007.11.013",
url = "https://www.sciencedirect.com/science/article/pii/S0957417407005611",
author = "Ismail Babaoglu and Omer Kaan Baykan and Nazif Aygul and Kurtulus Ozdemir and Mehmet Bayrak",
keywords = "Artificial neural networks",
keywords = "Exercise stress testing",
keywords = "Coronary artery disease ",
abstract = "The aim of this study is to show the artificial neural network (ANN) on determination of coronary artery disease existence and localization of lesion based upon exercise stress testing (EST) data. \{EST\} and coronary angiography were performed on 330 patients. The data studied acquiring 27 verifying features was normalized employing z-score method. To select training and test data, 10-fold cross-validation methods were involved and multi-layered perceptron neural network was employed for the classification. The interpretation of \{EST\} using \{ANN\} proved 91%, 73% and 65% diagnostic accuracy for the left main coronary (LMCA), left anterior descending and left circumflex coronary arteries, respectively. Besides, 69% for the right coronary artery is also predicted. For the LMCA, a 94% negative predictive value (NPV) was obtained. This high percentage of \{NPV\} encourages the elimination of \{LMCA\} lesions. Some knowledge can also be obtained about lesion localization, besides diagnosing of coronary artery disease by the assessment of \{EST\} via ANN. "
}
@article{Comodromos2003505,
title = "Numerical assessment of axial pile group response based on load test ",
journal = "Computers and Geotechnics ",
volume = "30",
number = "6",
pages = "505 - 515",
year = "2003",
note = "",
issn = "0266-352X",
doi = "https://doi.org/10.1016/S0266-352X(03)00017-X",
url = "https://www.sciencedirect.com/science/article/pii/S0266352X0300017X",
author = "Emilios M. Comodromos and Christos T. Anagnostopoulos and Michael K. Georgiadis",
keywords = "Pile groups",
keywords = "Pile tests numerical analysis",
keywords = "Non-linear soil–pile interaction ",
abstract = "Axial pile load tests are considered within the design procedure of most major construction projects that include pile foundations, aiming to determine both the ultimate bearing capacity and the pile stiffness at working load level. Commonly used pile spacings of 3–4 pile diameters between the test pile and the reaction piles cause significant interaction with drastic effect on to the load-settlement relationship. The objective of this paper is to evaluate the influence of this interaction on both bearing capacity and stiffness of single piles and pile groups. For this purpose, a back analysis of a pile load test was initially performed which facilitated the determination of the single pile response and the verification of the soil properties. Subsequently, a numerical analysis was carried out to establish load-displacement relationships for several different layouts of pile groups. Based on these non-linear analyses the effect of the interaction was quantified for both the pile load test and pile group layouts examined. "
}
@article{Robertson19937,
title = "It security testing, a practical guide — part 5: Security stress/loading testing ",
journal = "Computer Audit Update ",
volume = "1993",
number = "3",
pages = "7 - 10",
year = "1993",
note = "",
issn = "0960-2593",
doi = "https://doi.org/10.1016/0960-2593(93)90041-X",
url = "https://www.sciencedirect.com/science/article/pii/096025939390041X",
author = "Bernard Robertson and David Pullen"
}
@article{Bosc2000747,
title = "Thermal characterization of \{LDMOS\} transistors for accelerating stress testing ",
journal = "Microelectronics Journal ",
volume = "31",
number = "9–10",
pages = "747 - 752",
year = "2000",
note = "",
issn = "0026-2692",
doi = "https://doi.org/10.1016/S0026-2692(00)00054-9",
url = "https://www.sciencedirect.com/science/article/pii/S0026269200000549",
author = "J.M Bosc and P Dupuy and J Gil and J.M Dorkel and G Sarrabayrouse",
keywords = "Semiconductor industry",
keywords = "Multi-pulse testing",
keywords = "Energy pulse characterization ",
abstract = "The time to market is a major concern in the high-technology industry and when designing new products, the development cycle time becomes critical. Indeed, when a delay occurs in the development schedule, the potential market share of the designed product can be drastically decreased. In this context, developing accelerated stress testing (AST) in order to assess quickly the long-term behavior of a semiconductor becomes extremely useful. In this paper we show an example of how thermal characterization including simulation can be used to define a consistent \{AST\} for power ICs. "
}
@article{tagkey1996537,
title = "Environmental stress testing experiment using the Taguchi method : \{DENNIS\} E. PACHUCKI. \{IEEE\} Transactions on Components, Packaging, and Manufacturing Technology, Part A, 18(1), 3 (March 1995) ",
journal = "Microelectronics Reliability ",
volume = "36",
number = "4",
pages = "537 - ",
year = "1996",
note = "",
issn = "0026-2714",
doi = "https://doi.org/10.1016/0026-2714(96)84390-3",
url = "https://www.sciencedirect.com/science/article/pii/0026271496843903",
key = "tagkey1996537"
}
@article{tagkey1984177,
title = "Probablistic models for proof load testing: Grigoriu, M and Hall, W B J. Struct. Division ASCE, Vol 110 No 2 (February 1984) pp 260–274 ",
journal = "Computer-Aided Design ",
volume = "16",
number = "3",
pages = "177 - ",
year = "1984",
note = "",
issn = "0010-4485",
doi = "https://doi.org/10.1016/0010-4485(84)90046-0",
url = "https://www.sciencedirect.com/science/article/pii/0010448584900460",
key = "tagkey1984177"
}
@article{tagkey1996543,
title = "The benefits of stress testing : H. \{ANTHONY\} CHAN. \{IEEE\} Transactions on Components, Packaging and Manufacturing Technology, Part A, 18(1), 23 (March 1995) ",
journal = "Microelectronics Reliability ",
volume = "36",
number = "4",
pages = "543 - ",
year = "1996",
note = "",
issn = "0026-2714",
doi = "https://doi.org/10.1016/0026-2714(96)84419-2",
url = "https://www.sciencedirect.com/science/article/pii/0026271496844192",
key = "tagkey1996543"
}
@article{tagkey19941426,
title = "Performance testing of cellular modems : Mike Mukund and Fred Mohajer. Test and Measurement World, 63 (January 1993) ",
journal = "Microelectronics Reliability ",
volume = "34",
number = "8",
pages = "1426 - ",
year = "1994",
note = "",
issn = "0026-2714",
doi = "https://doi.org/10.1016/0026-2714(94)90255-0",
url = "https://www.sciencedirect.com/science/article/pii/0026271494902550",
key = "tagkey19941426"
}
@article{tagkey19941422,
title = "A study of failures identified during board level environmental stress testing : T. Paul Parker and Cathy W. Webb. \{IEEE\} Transactions on Components, Hybrids, and Manufacturing Technology, 15(6), 1086 (1992) ",
journal = "Microelectronics Reliability ",
volume = "34",
number = "8",
pages = "1422 - ",
year = "1994",
note = "",
issn = "0026-2714",
doi = "https://doi.org/10.1016/0026-2714(94)90238-0",
url = "https://www.sciencedirect.com/science/article/pii/0026271494902380",
key = "tagkey19941422"
}
@article{Pryor1974360,
title = "A computer program for stress test data processing ",
journal = "Computers and Biomedical Research ",
volume = "7",
number = "4",
pages = "360 - 368",
year = "1974",
note = "",
issn = "0010-4809",
doi = "https://doi.org/10.1016/0010-4809(74)90012-3",
url = "https://www.sciencedirect.com/science/article/pii/0010480974900123",
author = "T.Allan Pryor and J.Douglas Ridges"
}
@article{McCallum1986426,
title = "Benchmark results for microcomputers and large computers: Performance tests on \{IBM\} and \{DEC\} Vax ",
journal = "Data Processing ",
volume = "28",
number = "8",
pages = "426 - 433",
year = "1986",
note = "",
issn = "0011-684X",
doi = "https://doi.org/10.1016/0011-684X(86)90426-0",
url = "https://www.sciencedirect.com/science/article/pii/0011684X86904260",
author = "John C McCallum",
keywords = "data processing",
keywords = "benchmarks",
keywords = "microcomputers",
keywords = "computer performance ",
abstract = "Three commonly used benchmark programs: the Whetsone, the Dhrystone, and the Sieve, were run on an \{IBM\} PC, an \{IBM\} PC/AT, a Vax 11/785 and a Vax 8600 computer. The results show very large differences in performances predicted by the different benchmarks. "
}
@article{tagkey1991278,
title = "Job related physical performance tests : Purswell, J.L., Ratliff, R., and Hughes, A. In: B. Das (Ed), Advances in industrial ergonomics and safety — II, Taylor &amp; Francis, London, 1990, pp 453–459, 14 refs ",
journal = "Applied Ergonomics ",
volume = "22",
number = "4",
pages = "278 - ",
year = "1991",
note = "",
issn = "0003-6870",
doi = "https://doi.org/10.1016/0003-6870(91)90275-M",
url = "https://www.sciencedirect.com/science/article/pii/000368709190275M",
key = "tagkey1991278"
}
@article{tagkey19821186,
title = "Highly accelerated temperature and humidity stress test technique (HAST) ",
journal = "Microelectronics Reliability ",
volume = "22",
number = "6",
pages = "1186 - ",
year = "1982",
note = "",
issn = "0026-2714",
doi = "https://doi.org/10.1016/S0026-2714(82)80601-X",
url = "https://www.sciencedirect.com/science/article/pii/S002627148280601X",
key = "tagkey19821186"
}
@article{Dillon1981169,
title = "The role of ergonomics in the development of performance tests for furniture ",
journal = "Applied Ergonomics ",
volume = "12",
number = "3",
pages = "169 - 175",
year = "1981",
note = "",
issn = "0003-6870",
doi = "https://doi.org/10.1016/0003-6870(81)90006-5",
url = "https://www.sciencedirect.com/science/article/pii/0003687081900065",
author = "Jane Dillon",
abstract = "The development of realistic performance tests for furniture has been the subject of a continuing research programme. Such tests are necessary to ensure that furniture is both durable and safe to use: This paper discusses the general philosophy that tests should be based on the actual use to which furniture is likely to be subjected. The forces which act on a piece of furniture may be conveniently divided into two categories — functional and non-functional. The former occurs when the activity is one for which the furniture was designed, while non-functional use covers misuse for which the furniture was not specifically intended but which inevitably occurs and which must be considered in its design. The success of performance tests depends largely on the reproduction of service loads and ergonomics has played an important role in the recording and measuring of human behaviour in relation to different types of furniture. This has led to the development of test rigs to reproduce loads occuring in practice. A number of examples are discussed. The comparison of results obtained from these tests with the performance of furniture in everyday use has shown that the tests do adequately reproduce the type of failure which is likely to occur in practice. "
}
@article{Groocock1963191,
title = "Accelerated life testing and over-stress testing of transistors ",
journal = "Microelectronics Reliability ",
volume = "2",
number = "3",
pages = "191 - 204",
year = "1963",
note = "",
issn = "0026-2714",
doi = "https://doi.org/10.1016/0026-2714(63)90004-0",
url = "https://www.sciencedirect.com/science/article/pii/0026271463900040",
author = "J.M. Groocock",
abstract = "The advantages and disadvantages of accelerated life tests compared with conventional life tests are discussed and the methods by which accelerated life tests are used are examined. The physical basis of accelerated life tests in reaction kinetics is described and the methods by which the Arrhenius equation and the Eyring equation can be used to relate time to failure and temperature are discussed. On the basis of the Arrhenius equation and using the log normal failure distribution the results of temperature storage accelerated life tests on germanium alloy transistors are used to make predictions about life behaviour at lower temperatures. These predictions are compared with the results of long-term life tests on several hundred transistors extending to 20,000 hr. The results are then used to compare constant stress and step stress accelerated life tests. Electrical over-stress tests are described in which germanium alloy transistors are subjected to very high power pulses of short duration and silicon planar transistors have high currents passed through their emitter junctions in the reverse direction. Mechanical over-stress tests are exemplified by centrifuge tests on germanium alloy transistors. It is shown for one transistor type that the failure distribution, although in all cases normal, is markedly dependent upon the direction of stress. "
}
@article{tagkey1992357,
title = "Advances in industrial ergonomics and safety \{III\} : Purswell, J L, McCauley, P Merrick C ‘Job related physical performance tests for firefighters’ in Karwowski, W and Yates, J W (eds) Taylor &amp; Francis, London (1991) pp 499–504 (10 refs) ",
journal = "Applied Ergonomics ",
volume = "23",
number = "5",
pages = "357 - ",
year = "1992",
note = "",
issn = "0003-6870",
doi = "https://doi.org/10.1016/0003-6870(92)90345-V",
url = "https://www.sciencedirect.com/science/article/pii/000368709290345V",
key = "tagkey1992357"
}
@article{tagkey1984231,
title = "All change for the pound. Human performance tests with different versions of the proposed \{UK\} One Pound coin : Bruce, V., et alErgonomics, 1983, 26.3, 215–227 ",
journal = "Applied Ergonomics ",
volume = "15",
number = "3",
pages = "231 - ",
year = "1984",
note = "",
issn = "0003-6870",
doi = "https://doi.org/10.1016/0003-6870(84)90089-9",
url = "https://www.sciencedirect.com/science/article/pii/0003687084900899",
key = "tagkey1984231"
}
@article{tagkey1984585,
title = "Mo-gate \{MOS\} devices stability under long-term positive bias-temperature stressing test : Tadatoshi Nozaki, Hidekazu Okabayashi and Kohei Higuchi. \{IEEE\} 21st Ann. Proc. Reliab. Phys. 178 (1983) ",
journal = "Microelectronics Reliability ",
volume = "24",
number = "3",
pages = "585 - ",
year = "1984",
note = "",
issn = "0026-2714",
doi = "https://doi.org/10.1016/0026-2714(84)90505-5",
url = "https://www.sciencedirect.com/science/article/pii/0026271484905055",
key = "tagkey1984585"
}
@article{tagkey1983588,
title = "Accelerated stress testing of terrestrial solar cells : J. W. Lathrop, D. C. Hawkins, J. L. Prince and H. A. Walker. \{IEEE\} Trans. Reliab.R-31 (3), 258 (1982) ",
journal = "Microelectronics Reliability ",
volume = "23",
number = "3",
pages = "588 - ",
year = "1983",
note = "",
issn = "0026-2714",
doi = "https://doi.org/10.1016/0026-2714(83)91196-4",
url = "https://www.sciencedirect.com/science/article/pii/0026271483911964",
key = "tagkey1983588"
}
@article{tagkey1965302,
title = "A review of step-stress testing : D. S. Peck, Bell Laboratories Record42, 327 (1964) ",
journal = "Microelectronics Reliability ",
volume = "4",
number = "3",
pages = "302 - ",
year = "1965",
note = "",
issn = "0026-2714",
doi = "https://doi.org/10.1016/0026-2714(65)90101-0",
url = "https://www.sciencedirect.com/science/article/pii/0026271465901010",
key = "tagkey1965302"
}
@article{tagkey1969250,
title = "Physical analysis of stress testing for failure of electronic components : C. F. Kooi, \{IEEE\} Trans. Reliab.R17, June (1968), p. 80 ",
journal = "Microelectronics Reliability ",
volume = "8",
number = "3",
pages = "250 - ",
year = "1969",
note = "",
issn = "0026-2714",
doi = "https://doi.org/10.1016/0026-2714(69)90039-0",
url = "https://www.sciencedirect.com/science/article/pii/0026271469900390",
key = "tagkey1969250"
}
@article{tagkey1971412,
title = "Differential pressure test: A quantitative stress test method for bonded beam-leaded devices : E. J. Boore and D. M. Sutter. Proc. 21st Electronic Components Conf. Washing D.C., U.S.A., 10–12 May (1971), p. 2 ",
journal = "Microelectronics Reliability ",
volume = "10",
number = "6",
pages = "412 - ",
year = "1971",
note = "",
issn = "0026-2714",
doi = "https://doi.org/10.1016/0026-2714(71)90014-X",
url = "https://www.sciencedirect.com/science/article/pii/002627147190014X",
key = "tagkey1971412"
}
@article{Balieu1980111,
title = "Performance testing for improving the level of respiratory protection in a fire brigade : Annals of Occupational Hygiene 1978, 21.4, 351–361. ",
journal = "Applied Ergonomics ",
volume = "11",
number = "2",
pages = "111 - ",
year = "1980",
note = "",
issn = "0003-6870",
doi = "https://doi.org/10.1016/0003-6870(80)90222-7",
url = "https://www.sciencedirect.com/science/article/pii/0003687080902227",
author = "E. Balieu and L. Spindler"
}
@article{Cleveland1934636,
title = "Loud speakers, theory, performance, testing and design: by N. W. McLachlan, D.Sc. (Engineering), London. 399 pages, illustrations, tables, 16 × 23.5 cms. Oxford, Clarendon Press, 1934 ",
journal = "Journal of the Franklin Institute ",
volume = "218",
number = "5",
pages = "636 - 637",
year = "1934",
note = "",
issn = "0016-0032",
doi = "https://doi.org/10.1016/S0016-0032(34)90743-2",
url = "https://www.sciencedirect.com/science/article/pii/S0016003234907432",
author = "T.K. Cleveland"
}

