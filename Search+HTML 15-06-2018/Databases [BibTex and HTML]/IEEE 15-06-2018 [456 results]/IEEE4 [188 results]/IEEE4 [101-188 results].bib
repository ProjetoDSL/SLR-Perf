@INPROCEEDINGS{6748556, 
author={Haojie Fan and Yongmin Mu}, 
booktitle={International Conference on Cyberspace Technology (CCT 2013)}, 
title={A performance testing and optimization tool for system developed by Python language}, 
year={2013}, 
volume={}, 
number={}, 
pages={24-27}, 
abstract={With a wide range of Python language in developing programs, More and more programmers choose to use the Python language for systems development, it gradually becomes scientific computing, web and games' Choice Awards. However, the performance of python is always a headache for developers. For reasonable selection of functions in base library, the usage of third-party plug-ins' functions and methods, and the design of custom functions, the problem whether they are the best choices for general developers is difficult to make a positive answer. After the system's performance bottleneck occurs, it is particularly important to determine where to tune and how to tune. Through the analysis and dynamic tracking of source code, with the built-in method in Python, we can get information about the system to be optimized, included: functions, grammatical structures, running time of each function, the relationship between function calls etc. This information provides an effective basis for further optimization of the system. Experimental results show that the system optimized by the tool has a significantly improvement.}, 
keywords={Performance testing;Python;System Optimization}, 
doi={10.1049/cp.2013.2086}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6825689, 
author={J. Mukherjee and M. Wang and D. Krishnamurthy}, 
booktitle={2014 IEEE Seventh International Conference on Software Testing, Verification and Validation Workshops}, 
title={Performance Testing Web Applications on the Cloud}, 
year={2014}, 
volume={}, 
number={}, 
pages={363-369}, 
abstract={Web applications are increasingly resorting to public cloud platforms such as the Amazon Web Services (AWS) Elastic Compute Cloud (EC2). However, previous studies have shown that the virtualized infrastructures used in a cloud environment can introduce performance issues. Hence, it is crucial to test the performance of the cloud to support Web applications. This is challenging because the performance effect of the cloud platform cannot be easily isolated from other extraneous factors. In this paper, we present a systematic experimental process to address this challenge. Following our proposed process, we test the performance of Web applications running on different types of AWS EC2 instances. Results suggest that Web server response times can fluctuate up to 1000% for the same workload under certain circumstances such as instance type, time-of-the-day, and day-of-the-week.}, 
keywords={Web services;cloud computing;software performance evaluation;virtualisation;AWS EC2 instances;Amazon Web Services Elastic Compute Cloud;Web application performance testing;Web server response time;cloud environment;instance type;performance issues;public cloud platform;virtualized infrastructure;Bandwidth;Generators;Testing;Time factors;Web servers}, 
doi={10.1109/ICSTW.2014.57}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{7377638, 
author={J. Kričković and Đ. Miljković and M. Đukić}, 
booktitle={2015 23rd Telecommunications Forum Telfor (TELFOR)}, 
title={Automation testing of Bootloader for target DSP platform}, 
year={2015}, 
volume={}, 
number={}, 
pages={1016-1019}, 
abstract={In this paper is given the implementation of solutions for automated testing of Bootloader on the target DSP platform. Existing tools for manual testing do not meet the challenges of developing modern products, and its necessity for higher percentages of automation. The aim is to save time testing, reducing the occurrence of errors during testing due to human factors, and the ability that testing may execute a person who has no previous knowledge of a given field.}, 
keywords={digital signal processing chips;human factors;program testing;Bootloader;automation testing;human factor;software testing;target DSP platform;Automation;Digital signal processing;Electronic mail;Field programmable gate arrays;Hardware design languages;Linux;Testing;Bootloader;Python;TeraTerm;ispitivanje}, 
doi={10.1109/TELFOR.2015.7377638}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{5968369, 
author={Y. Fang-ying}, 
booktitle={2011 Chinese Control and Decision Conference (CCDC)}, 
title={The credit risk macro stress testing of the Chinese banking system}, 
year={2011}, 
volume={}, 
number={}, 
pages={1198-1203}, 
abstract={In order to test the overall credit risk of loans of China's banking system, a macroeconomic credit risk model is designed, including a multiple linear regression model describing default probability, and a set of regression models describing macroeconomic environment. Studies show that bank loan default rates and key macroeconomic factors are related. Then stress tests are implemented one by one according to different shocks. The results showed that most banks continue to profit even at 90% confidence level when estimated risk of loss, reflecting a moderate credit risk in the banking system. However, if confidence level rises to 99% when estimated risk of loss, the banking system will face significant losses. The results show that it is necessary to prevent the credit risk of real estate loans and government debt.}, 
keywords={banking;credit transactions;macroeconomics;probability;profitability;regression analysis;risk management;Chinese banking system;bank loan;confidence level;credit risk macrostress testing;default probability;default rate;government debt;linear regression model;macroeconomic credit risk model;macroeconomic environment;profit;real estate loan;Banking;Economic indicators;Electric shock;Equations;Macroeconomics;Mathematical model;Stress}, 
doi={10.1109/CCDC.2011.5968369}, 
ISSN={1948-9439}, 
month={May},}
@INPROCEEDINGS{4346025, 
author={A. J. Young and T. A. Holt and M. A. Elsayed and A. A. Neuber and M. Kristiansen and L. L. Altgilbers and A. H. Stults}, 
booktitle={2007 IEEE 34th International Conference on Plasma Science (ICOPS)}, 
title={Fuse and Load Testing with Mid-Sized, High Energy Density Flux Compression Generators}, 
year={2007}, 
volume={}, 
number={}, 
pages={719-719}, 
abstract={Compact pulsed power systems require power sources that are small in size yet can produce the necessary electrical energy required to drive the system. Helical magnetic flux compression generators (HFCGs) are attractive for single shot applications due to their rapid conversion of chemical energy to electrical energy. The small total volume of a generator coupled with the energy density of the fast-reacting high explosives makes mid-sized HFCGs an appealing option as sources in single shot compact pulsed power systems. Consistent output current and energy gain from shot to shot are key variables in the ability of an HFCG to drive compact pulsed power systems efficiently.}, 
keywords={electric fuses;pulse generators;pulsed power supplies;compact pulsed power systems;fuse testing;helical magnetic flux compression generators;high energy density flux compression generators;load testing;Electronic equipment testing;Explosives;Fuses;Impedance;Power generation;Pulse compression methods;Pulse generation;Pulse power systems;Pulse shaping methods;Switches}, 
doi={10.1109/PPPS.2007.4346025}, 
ISSN={0730-9244}, 
month={June},}
@INPROCEEDINGS{8233806, 
author={B. Wunderle and J. Heilmann and D. May and J. Arnold and J. Hirscheider and J. Bauer and R. Schacht and J. Vogel and M. A. Ras}, 
booktitle={2017 23rd International Workshop on Thermal Investigations of ICs and Systems (THERMINIC)}, 
title={Modelling and characterisation of a grease pump-out test stand and its use for accelerated stress testing of thermal greases}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Thermal greases allow a low stress bond at low bond line thicknesses (BLT) at medium thermal conductivities and simple application, all of which make it an alternative to solders, thermal adhesives or pads. It is widely used in power and microprocessor applications, most of which involve large areas to be used for heat transfer. However, for years thermal overload failure of power modules and chips has been a pressing problem due to pump-out of thermal grease as die or module thermal interface material (TIM): Most thermal greases are Bingham fluids and thus no solids, so they can be squeezed out from in between the gap, driven by thermo-mechanical action of the adjacent layers as e.g. DCB substrate or silicon chip with the heat sink. Today, thermal greases have to be qualified in lengthy stress tests in a product relevant environment which consumes substantial resources as often a system test is required. Therefore, a fast test is necessary which accelerates testing and thus allows a fast screening of market-available greases on one hand, and guidelines for material development on the other. For that purpose this paper addresses this topic in a combined simulative and experimental manner, where at the same time a novel test procedure is proposed for accelerated grease pump-out testing (GPOT) in the framework of a completely new approach, combining loading with in-situ failure analytical techniques and decoupling thermal from mechanical loading.}, 
keywords={adhesion;adhesives;failure analysis;greases;heat sinks;integrated circuit packaging;integrated circuit reliability;life testing;microprocessor chips;thermal conductivity;thermal management (packaging);thermal resistance;thermal stresses;accelerated grease pump-out;accelerated stress testing;grease pump-out test;stress tests;thermal adhesives;thermal conductivities;thermal grease;thermal interface material module;thermal overload failure;Conductivity;Life estimation;Loading;Stress;Testing;Thermal conductivity;Thermal stresses}, 
doi={10.1109/THERMINIC.2017.8233806}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6728886, 
author={A. Banerjee and S. Chattopadhyay and A. Roychoudhury}, 
booktitle={2013 IEEE 34th Real-Time Systems Symposium}, 
title={Static Analysis Driven Cache Performance Testing}, 
year={2013}, 
volume={}, 
number={}, 
pages={319-329}, 
abstract={Real-time, embedded software are constrained by several non-functional requirements, such as timing. With the ever increasing performance gap between the processor and the main memory, the performance of memory subsystems often pose a significant bottleneck in achieving the desired performance for a real-time, embedded software. Cache memory plays a key role in reducing the performance gap between a processor and main memory. Therefore, analyzing the cache behaviour of a program is critical for validating the performance of an embedded software. In this paper, we propose a novel approach to automatically generate test inputs that expose the cache performance issues to the developer. Each such test scenario points to the specific parts of a program that exhibit anomalous cache behaviour along with a set of test inputs that lead to such undesirable cache behaviour. We build a framework that leverages the concepts of both static cache analysis and dynamic test generation to systematically compute the cache-performance stressing test inputs. Our framework computes a test-suite which does not contain any false positives. This means that each element in the test-suite points to a real cache performance issue. Moreover, our test generation framework provides an assurance of the test coverage via a well-formed coverage metric. We have implemented our entire framework using Chronos worst case execution time (WCET) analyzer and LLVM compiler infrastructure. Several experiments suggest that our test generation framework quickly converges towards generating cache-performance stressing test cases. We also show the application of our generated test-suite in design space exploration and cache performance optimization.}, 
keywords={cache storage;embedded systems;program compilers;program diagnostics;software performance evaluation;Chronos worst case execution time;LLVM compiler infrastructure;WCET analyzer;anomalous cache behaviour;cache performance optimization;cache-performance stressing test cases;coverage metric;design space exploration;dynamic test generation;real-time embedded software;static cache analysis;test coverage;test-suite;Abstracts;Cache memory;Embedded software;Instruments;Performance analysis;Testing;Cache performance;Performance testing;Test generation}, 
doi={10.1109/RTSS.2013.39}, 
ISSN={1052-8725}, 
month={Dec},}
@INPROCEEDINGS{4392122, 
author={C. Xing and G. Zhang and M. Chen}, 
booktitle={2007 International Symposium on Communications and Information Technologies}, 
title={Research on universal network performance testing model}, 
year={2007}, 
volume={}, 
number={}, 
pages={780-784}, 
abstract={Network performance testing is one of the key components in optimizing network resource configuration and improving network performance. Existing performance testing tools usually focus on single performance parameters, and lack of the ability to satisfy integrated testing demands of network administrators. In this paper, a universal network performance testing model based on policy scheduling is proposed, which integrates many kinds of performance testing tools into a single system, and provides a uniform testing interface to network administrators. Universal Probe (UP) is the key component of such a model, thus a detailed study is given on UP, which includes UP architecture, policy-based UP cooperation, mobility, and UP deployment under resource constraints. At last, a practical Network Monitor and Measurement System that designed based on the discussed concepts is presented.}, 
keywords={computer network management;computer network reliability;monitoring;optimisation;scheduling;network monitor-measurement system;network resource configuration optimization;policy scheduling;uniform testing interface;universal network performance testing model;universal probe;Information technology;Testing}, 
doi={10.1109/ISCIT.2007.4392122}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{171303, 
author={J. A. Hadfield}, 
booktitle={12th International Conference on Telecommunications Energy}, 
title={Development of an economical, software-controlled battery load testing system}, 
year={1990}, 
volume={}, 
number={}, 
pages={553-555}, 
abstract={Battery discharge capacity tests have traditionally been performed manually, although several mechanized systems are commercially available. A need was identified at the Manitoba Telephone System (MTS) to accurately and economically load test batteries in the field, to verify the capacity of new installations as well as to assist determining the true end-of-life of existing strings. The development of an economical, software-controlled system for testing -48 volt battery strings in the telephone environment is discussed.<>}, 
keywords={automatic test equipment;battery testers;power supplies to apparatus;secondary cells;telephone equipment;-48 V;Canada;automatic testing;battery testers;development;discharge capacity;end-of-life;load testing;software;telephone equipment;Automatic testing;Batteries;Electronic equipment testing;Environmental economics;Prototypes;Software standards;Software testing;System testing;Telephony;Voltage}, 
doi={10.1109/INTLEC.1990.171303}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6023983, 
author={X. Meng}, 
booktitle={Proceedings of 2011 International Conference on Electronic Mechanical Engineering and Information Technology}, 
title={Designing approach analysis on small-scale software performance testing tools}, 
year={2011}, 
volume={8}, 
number={}, 
pages={4254-4257}, 
abstract={Currently, most software performance testing tools in the market are large ones designated for enterprises. Aiming at the demand of small-sized and individual customers' conduction of software performance testing, the paper proposes an approach for designing and realizing a small tool for testing. Core design refers to simulating multi-user concurrent operation by simultaneous execution of multithreading and measuring performance of the system tested through whether each threading responses in a correct manner as well as testing data such as period of responding. Testing tool, which is realized by Java language, consists of three modules of case management, test implementation and test report. Multiple designing modes are utilized in a combined manner during designing, which makes the designing scheme a simple one with high efficiency and easy to expand. The market of performance testing is developing in a rapid manner and researching software performance test is gaining increasingly significance.}, 
keywords={Java;automatic test software;concurrency control;multi-threading;program testing;software performance evaluation;software tools;Java language;case management;multithreading;multiuser concurrent operation;small-scale software performance testing tool design;test implementation;test report;Databases;Educational institutions;Instruction sets;Presses;Servers;Software performance;Testing;designing approach;designing mode;small-scaled testing tool;software performance test}, 
doi={10.1109/EMEIT.2011.6023983}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{604303, 
author={K. H. Sueker}, 
booktitle={1997 IEEE International Electric Machines and Drives Conference Record}, 
title={A static dynamometer for load testing large variable frequency motor drives}, 
year={1997}, 
volume={}, 
number={}, 
pages={WB1/9.1-WB1/9.3}, 
abstract={The static dynamometer, an apparent oxymoron, is a system which allows full load testing of variable frequency motor drives with no rotating equipment and only minimal demand from the power line. By inserting a reactor between the drive output and the line from which it is powered, the drive can be made to appear as a synchronous generator. This arrangement offers a practical alternative to the motor-generator sets usually employed for load testing. The required equipment consists of a set of power reactors approximating 10% of the drive rating, a contactor and a phase locked loop circuit for regulating the drive phase relative to the line. The static dynamometer is in production use on variable speed drives from 20 to 5000 hp and 480 to 4160 V. There are no intrinsic limits to either power or voltage for its application}, 
keywords={dynamometers;machine testing;motor drives;variable speed drives;20 to 5000 hp;480 to 4160 V;drive rating;load testing;motor-generator sets;phase locked loop circuit;power reactors;production experience;static dynamometer;synchronous generator;variable frequency motor drives;variable speed drives;Circuit testing;Frequency;Inductors;Motor drives;Phase locked loops;Production;Synchronous generators;System testing;Variable speed drives;Voltage}, 
doi={10.1109/IEMDC.1997.604303}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{5614034, 
author={R. Mansharamani and A. Khanapurkar and B. Mathew and R. Subramanyan}, 
booktitle={2010 IEEE 34th Annual Computer Software and Applications Conference Workshops}, 
title={Performance Testing: Far from Steady State}, 
year={2010}, 
volume={}, 
number={}, 
pages={341-346}, 
abstract={The dot com era ushered in a number of industry standard load testing tools. While there is no doubt that these tools have helped improve the quality of IT systems, performance testing in the IT industry is far from steady state. There are still severe gaps between performance test results and production systems performance in IT projects. This paper proposes a number of areas where performance testing needs to improve radically, several of which can be incorporated in to load testing tools. Examples are also provided of simple analytics during single user performance testing to demonstrate the effectiveness of this extra but necessary step in the testing process.}, 
keywords={DP industry;Internet;electronic commerce;performance evaluation;testing;IT system quality;industry standard load testing tools;production systems;single user performance testing;Databases;Extrapolation;Industries;Testing;Throughput;Time factors;Tuning;load testing tools;performance emulation;performance testing;think time variability}, 
doi={10.1109/COMPSACW.2010.66}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{6200165, 
author={J. A. Meira and E. C. d. Almeida and Y. Le Traon and G. Sunye}, 
booktitle={2012 IEEE Fifth International Conference on Software Testing, Verification and Validation}, 
title={Peer-to-Peer Load Testing}, 
year={2012}, 
volume={}, 
number={}, 
pages={642-647}, 
abstract={Nowadays the large-scale systems are common-place in any kind of applications. The popularity of the web created a new environment in which the applications need to be highly scalable due to the data tsunami generated by a huge load of requests (i.e., connections and business operations). In this context, the main question is to validate how far the web applications can deal with the load generated by the clients. Load testing is a technique to analyze the behavior of the system under test upon normal and heavy load conditions. In this work we present a peer-to-peer load testing approach to isolate bottleneck problems related to centralized testing drivers and to scale up the load. Our approach was tested in a DBMS as study case and presents satisfactory results.}, 
keywords={Internet;peer-to-peer computing;program testing;Web applications;centralized testing drivers;large-scale systems;peer-to-peer load testing;system under test;Cloud computing;Computer architecture;Databases;Large-scale systems;Peer to peer computing;Scalability;Testing;large-scale systems;load testing;peer-to-peer}, 
doi={10.1109/ICST.2012.153}, 
ISSN={2159-4848}, 
month={April},}
@ARTICLE{638869, 
author={T. Suryanarayana and J. L. Bhattacharya and K. S. N. Raju and K. A. Durga Prasad}, 
journal={IEEE Transactions on Energy Conversion}, 
title={Development and performance testing of a 200 kVA damperless superconducting generator}, 
year={1997}, 
volume={12}, 
number={4}, 
pages={330-336}, 
abstract={A 200 kVA, 3000 RPM superconducting generator has been developed and tested. The rotor has been wound with superconducting wire of Nb-Ti alloy. A closed-circuit liquid helium system has been designed and installed for cooling the superconducting windings. The stator carries the air-gap type armature windings and a laminated-iron flux-shield. A new concept in the design of superconducting generators with high short-circuit ratio (more than 5) has been introduced. This eliminates the requirement of an electromagnetic damper and quick response excitation system. The generator has been comprehensively tested in the superconducting state. Open-circuit and sustained short-circuit tests, three-phase sudden short-circuit tests, synchronization with the grid and parallel operation with power systems have been conducted. The synchronous machine was operated up to its rated kVA in the four quadrants-as a generator and as a condenser with leading and lagging power factors. A few special tests on superconducting generators, which were not reported earlier, such as direct-online starting of a 20 hp squirrel-cage induction motor and negative phase sequence tests have also been performed successfully. Test results and conclusions are given}, 
keywords={electric generators;machine testing;rotors;stators;superconducting machines;superconducting magnets;20 hp;200 kVA;NbTi;air-gap type armature windings;closed-circuit liquid helium system;damperless superconducting generator;laminated-iron flux-shield;open-circuit tests;performance testing;short-circuit ratio;short-circuit tests;stator;superconducting windings cooling;superconducting wire rotor;Air gaps;Cooling;Helium;Induction generators;Rotors;Stators;Superconducting filaments and wires;Superconducting transmission lines;System testing;Wounds}, 
doi={10.1109/60.638869}, 
ISSN={0885-8969}, 
month={Dec},}
@INPROCEEDINGS{6525558, 
author={Q. Gao and W. Wang and G. Wu and X. Li and J. Wei and H. Zhong}, 
booktitle={2013 IEEE Seventh International Symposium on Service-Oriented System Engineering}, 
title={Migrating Load Testing to the Cloud: A Case Study}, 
year={2013}, 
volume={}, 
number={}, 
pages={429-434}, 
abstract={Cloud computing has emerged as a new paradigm for the delivery of computing resources. It brings great opportunities to software testing, especially to load testing. In this paper, we focus on migrating conventional load testing tools to the cloud, for which the two significant issues are about multi-tenancy and load simulating resource management. We propose a four layer model for cloud-based load testing, along with the approach of test request admission control and scheduling to solve these issues. We carried out a concrete case study on our proposed approach and made the efficiency of cloud-based load testing shown successfully by two contrast experiments.}, 
keywords={cloud computing;program testing;resource allocation;scheduling;cloud computing;cloud-based load testing;computing resource delivery;four layer model;load simulating resource management;load testing migration;multitenancy;scheduling;software testing;test request admission control;Admission control;Databases;Load modeling;Monitoring;Resource management;Software;Testing;cloud computing;load testing;migrating}, 
doi={10.1109/SOSE.2013.59}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{4155356, 
author={L. Pan and L. M. Batten}, 
booktitle={Systematic Approaches to Digital Forensic Engineering, 2007. SADFE 2007. Second International Workshop on}, 
title={A Lower Bound on Effective Performance Testing for Digital Forensic Tools}, 
year={2007}, 
volume={}, 
number={}, 
pages={117-130}, 
abstract={The increasing complexity and number of digital forensic tasks required in criminal investigations demand the development of an effective and efficient testing methodology, enabling tools of similar functionalities to be compared based on their performance. Assuming that the tool tester is familiar with the underlying testing platform and has the ability to use the tools correctly, we provide a numerical solution for the lower bound on the number of testing cases needed to determine comparative capabilities of any set of digital forensic tools. We also present a case study on the performance testing of password cracking tools, which allows us to confirm that the lower bound on the number of testing runs needed is closely related to the row size of certain orthogonal arrays. We show how to reduce the number of test runs by using knowledge of the underlying system}, 
keywords={computer crime;digital forensic tools;password cracking tools;performance testing;Blindness;Digital forensics;High performance computing;Home computing;Information technology;Kernel;Linux;Software performance;Software testing;System testing;Abstraction Layer Model;Orthogonal Arrays;Partition Testing;SADFE;Software Performance.}, 
doi={10.1109/SADFE.2007.2}, 
ISSN={}, 
month={April},}
@ARTICLE{7298477, 
author={B. Jiang and P. Chen and W. K. Chan and X. Zhang}, 
journal={IEEE Transactions on Reliability}, 
title={To What Extent is Stress Testing of Android TV Applications Automated in Industrial Environments?}, 
year={2016}, 
volume={65}, 
number={3}, 
pages={1223-1239}, 
abstract={An Android-based smart television (TV) must reliably run its applications in an embedded program environment under diverse hardware resource conditions. Owing to the diverse hardware components used to build numerous TV models, TV simulators are usually not sufficiently high in fidelity to simulate various TV models and thus are only regarded as unreliable alternatives when stress testing such applications. Therefore, even though stress testing on real TV sets is tedious, it is the de facto approach to ensure the reliability of these applications in the industry. In this paper, we study to what extent stress testing of smart TV applications can be fully automated in the industrial environments. To the best of our knowledge, no previous work has addressed this important question. We summarize the findings collected from ten industrial test engineers who have tested 20 such TV applications in a real production environment. Our study shows that the industry required test automation supports on high-level GUI object controls and status checking, setup of resource conditions, and the interplay between the two. With such supports, 87% of the industrial test specifications of one TV model can be fully automated, and 71.4% of them were found to be fully reusable to test a subsequent TV model with major upgrades of hardware, operating system, and application. It represents a significant improvement with margins of 28% and 38%, respectively, compared with stress testing without such supports.}, 
keywords={Android (operating system);automatic testing;digital television;graphical user interfaces;production engineering computing;program testing;reliability;Android-based smart TV;Android-based smart television;TV simulators;hardware resource conditions;high-level GUI object controls;industrial environments;industrial test specifications;operating system;reliability;status checking;stress testing;test automation;Androids;Automation;Humanoid robots;Smart phones;Stress;TV;Testing;Android;TV;automated testing;reliability;software reuse;stress testing;test case creation}, 
doi={10.1109/TR.2015.2481601}, 
ISSN={0018-9529}, 
month={Sept},}
@INPROCEEDINGS{5254473, 
author={Z. Wandan and J. Ningkang and Z. Xubo}, 
booktitle={2009 Ninth International Conference on Hybrid Intelligent Systems}, 
title={Design and Implementation of a Web Application Automation Testing Framework}, 
year={2009}, 
volume={2}, 
number={}, 
pages={316-318}, 
abstract={In this paper the problems in the automation testing of GUI based Web applications are discussed. A new automation testing framework based on the concept of object feature set and dynamic searching policy is proposed. The design and implementation of it are both given. The framework working using result shows that it makes the testing more convenient and efficient with less resources and time cost but higher testing coverage.The ability of maintenance and stability are both improved.}, 
keywords={Internet;graphical user interfaces;program testing;GUI;Internet technology;Web application automation testing framework;Web application maintenance;dynamic searching policy;object feature set;software development cycle;Application software;Automatic control;Automatic testing;Costs;Design automation;Graphical user interfaces;Java;Programming;Software testing;System testing;Web application testing;automation testing framework;dynamic searching technology}, 
doi={10.1109/HIS.2009.175}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6496814, 
author={J. Finnigan}, 
booktitle={2013 IEEE Aerospace Conference}, 
title={Radiation Belt Storm Probes (RBSP) Flight Software stress testing: Case study and lessons learned}, 
year={2013}, 
volume={}, 
number={}, 
pages={1-12}, 
abstract={This paper presents a case study of the Radiation Belt Storm Probes (RBSP) mission Command and Data Handling (C&DH) Flight Software stress testing program. Background information on the motivation for stress testing embedded software, and the general principles and goals of a stress test are provided as an introduction. Details of the stress test program that was implemented for the RBSP C&DH Flight Software are presented and discussed. This discussion includes the design and development of a test framework that was implemented to incrementally build the test scenarios, increase the productivity of the RBSP stress test team, and facilitate reuse for regression testing. Results of the RBSP stress test program are summarized, and lessons learned that may be useful for future embedded software test programs are documented.}, 
keywords={aerospace computing;aerospace testing;embedded systems;probes;program testing;radiation belts;regression analysis;software reusability;team working;C&DH flight software stress testing program;RBSP flight software stress testing;RBSP stress test team productivity;command and data handling flight software stress testing program;embedded software test programs;radiation belt storm probes;regression testing reusability;test framework design;test framework development;Computer architecture;Loading;Planning;Software;Space vehicles;Stress;Testing}, 
doi={10.1109/AERO.2013.6496814}, 
ISSN={1095-323X}, 
month={March},}
@INPROCEEDINGS{4299917, 
author={X. Shu and F. Maurer}, 
booktitle={International Conference on Software Engineering Advances (ICSEA 2007)}, 
title={A Tool for Automated Performance Testing of Java3D Applications in Agile Environments}, 
year={2007}, 
volume={}, 
number={}, 
pages={35-35}, 
abstract={Following the agile philosophy that all core features of a system need an automated test harness, performance requirements also need such a check when they are essential for the success of a project. The purpose of this paper is to describe a tool, J3DPerfUnit, which supports automated performance testing for Java3D applications in agile environments. We elicited tool requirements from domain experts through a survey and evaluated J3DPerfUnit using code from our partner's bioinformatics project and Java3D official tutorials. The evaluation pointed out that the tool is effective in detecting performance problems and in identifying where they come from when loading/unloading a 3D object.}, 
keywords={Java;program testing;rendering (computer graphics);software metrics;Java3D application;agile environment;automated performance testing;graphics rendering;software metrics;Application software;Automatic testing;Availability;Bioinformatics;Computer science;Engines;Java;Layout;System testing;Tree graphs}, 
doi={10.1109/ICSEA.2007.11}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{5445814, 
author={L. Motalova and O. Krejcar}, 
booktitle={2010 Second International Conference on Computer Engineering and Applications}, 
title={Stress Testing Data Access via a Web Service for Determination of Adequate Server Hardware for Developed Software Solution}, 
year={2010}, 
volume={1}, 
number={}, 
pages={329-333}, 
abstract={The aim of this project is stress testing of the system for data management and planning of the operations developed for home care agencies which has to be upgrading of the current system based on the older database of Microsoft Access product. The part of the system is a mobile application that allows employees to edit the records of patients directly in the terrain. The whole system, including applications developed for the stress testing is based on Microsoft technology .NET. Our Stress Testing application allows testing a selected problem areas to find any limitations before the tested developing solution will be set up at customer. By the help of our test application, the hardware solution for the server was selected on the base of selected home care agency needs.}, 
keywords={Web services;file servers;information retrieval;program testing;software tools;Microsoft access product database;Microsoft technology .NET;Web service;adequate server hardware;data management system;home care agency;stress testing data access;Databases;Displays;Hardware;Random number generation;Software testing;Stress;System testing;Time factors;Time measurement;Web services;data access;software;stress testing;web services}, 
doi={10.1109/ICCEA.2010.72}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{6569717, 
author={G. Canfora and F. Mercaldo and C. A. Visaggio and M. DAngelo and A. Furno and C. Manganelli}, 
booktitle={2013 IEEE Sixth International Conference on Software Testing, Verification and Validation}, 
title={A Case Study of Automating User Experience-Oriented Performance Testing on Smartphones}, 
year={2013}, 
volume={}, 
number={}, 
pages={66-69}, 
abstract={We have developed a platform named Advanced Test Environment (ATE) for supporting the design and the automatic execution of UX tests for applications running on Android smartphones. The platform collects objective metrics used to estimate the UX. In this paper, we investigate the extent that the metrics captured by ATE are able to approximate the results that are obtained from UX testing with real human users. Our findings suggest that ATE produces UX estimations that are comparable to those reported by human users. We have also compared ATE with three widespread benchmark tools that are commonly used in the industry, and the results show that ATE outperforms these tools.}, 
keywords={Linux;automatic testing;program testing;smart phones;software performance evaluation;ATE;Android smartphones;UX estimations;UX test design;UX testing;advanced test environment;automatic UX test execution;objective metrics;user experience-oriented performance testing automation;Conferences;Software testing;android;mobile applications;smartphone;software testing;usability;user experience}, 
doi={10.1109/ICST.2013.16}, 
ISSN={2159-4848}, 
month={March},}
@INPROCEEDINGS{315756, 
author={D. Grossman and C. J. Staton and B. Bailey and M. C. McCabe and A. Latts and O. Frieder and C. Bock and D. Roberts}, 
booktitle={Proceedings of 3rd Symposium on Assessments of Quality Software Development Tools}, 
title={A prototype-driven approach to application-level performance testing: a case study of a large finance application}, 
year={1994}, 
volume={}, 
number={}, 
pages={125-135}, 
abstract={We present an approach to application-level performance testing. This uses a popular test tool, TPNS (Teleprocessing Network Simulator) to simulate performance of an application. Our approach hinges upon a simple prototype to verify that the system performance falls within acceptable bounds. Once the initial prototype is developed, detailed tuning may take place. We present a case study in which we tested the performance of a large finance application. This approach led to critical performance tuning improvement. Due to this improvement, the average user response time in our simulations was reduced from 30 seconds to under 1.5 seconds. This simulation has been verified by actual system usage during the first two months of live operation in which the average response time has indeed been under 1.5 seconds}, 
keywords={accounts data processing;performance evaluation;program testing;software prototyping;TPNS;Teleprocessing Network Simulator;application-level performance testing;large finance application;prototype-driven approach;system performance;test tool;user response time;Computer aided software engineering;Computer bugs;Database systems;Finance;Financial management;Information technology;Operating systems;Prototypes;System testing;Technology management}, 
doi={10.1109/AQSDT.1994.315756}, 
ISSN={}, 
month={Jun},}
@INPROCEEDINGS{4658079, 
author={Z. M. Jiang and A. E. Hassan and G. Hamann and P. Flora}, 
booktitle={2008 IEEE International Conference on Software Maintenance}, 
title={Automatic identification of load testing problems}, 
year={2008}, 
volume={}, 
number={}, 
pages={307-316}, 
abstract={Many software applications must provide services to hundreds or thousands of users concurrently. These applications must be load tested to ensure that they can function correctly under high load. Problems in load testing are due to problems in the load environment, the load generators, and the application under test. It is important to identify and address these problems to ensure that load testing results are correct and these problems are resolved. It is difficult to detect problems in a load test due to the large amount of data which must be examined. Current industrial practice mainly involves time-consuming manual checks which, for example, grep the logs of the application for error messages. In this paper, we present an approach which mines the execution logs of an application to uncover the dominant behavior (i.e., execution sequences) for the application and flags anomalies (i.e., deviations) from the dominant behavior. Using a case study of two open source and two large enterprise software applications, we show that our approach can automatically identify problems in a load test. Our approach flags < 0.01% of the log lines for closer analysis by domain experts. The flagged lines indicate load testing problems with a relatively small number of false alarms. Our approach scales well for large applications and is currently used daily in practice.}, 
keywords={program testing;public domain software;software engineering;automatic identification;enterprise software;load testing;open source software;Catalogs;Computer bugs;Databases;Generators;Monitoring;Software;Testing}, 
doi={10.1109/ICSM.2008.4658079}, 
ISSN={1063-6773}, 
month={Sept},}
@INPROCEEDINGS{5202971, 
author={G. Wang and S. Jiao and H. Song}, 
booktitle={2009 International Conference on Measuring Technology and Mechatronics Automation}, 
title={Mine Pump Comprehensive Performance Testing System Based on Labview}, 
year={2009}, 
volume={1}, 
number={}, 
pages={300-303}, 
abstract={The pump is one of the key equipments for the safety production of coal mine. It bears the important task to discharge all the underground water. However, the performance efficiency of the water pump will be declined, in the long run. Therefore, in order to ensure the safety production, users should check and test the pump performance regularly ,to test if every target pump has live up to the ldquoCoal Mine Safety Regulationsrdquo. The ultimate goal in finding the fault in time, eliminating hidden dangers, reducing accidents,and saving maintenance costs can be attained. Virtual instrument is the production of modern computer and instrument technology combined in-depth, and is an important technology of computer-assisted testing area. The core idea is "software replacing hardware". The paper introduces the virtual instrument technology into the field of pump performance testing, and designs the mine pump comprehensive performance testing system based on Labview. The system takes software development environment-LabVIEW as platform and based on personal computer, and realizes the function that pumppsilas import and export of water pressure, flow, speed, power, and other signals measured in real-time and dynamic displayed. It uses the polynomial fitting module of LabVIEW to fit the performance curve,and shows the performance curve by the waveform display. At the same time,it uses the Web Publishing Tool of LabVIEW to release the testing interface to the internet,and realizes its network communication function. Compared with traditional instruments,the pump performance testing system which based on Virtual instrument run stably, have strongly data analytical and processing functions, beautiful interface, easy operation, strongly visual function, highly testing precision.}, 
keywords={mining;mining equipment;polynomial approximation;pumps;safety;virtual instrumentation;LabVIEW;coal mine safety production;coal mine safety regulations;computer-assisted testing;mine pump comprehensive performance testing system;network communication function;polynomial fitting module;virtual instrument technology;Costs;Hardware;Instruments;Microcomputers;Paper technology;Product safety;Production;Programming;Safety devices;System testing;labview;pump;testing system}, 
doi={10.1109/ICMTMA.2009.179}, 
ISSN={2157-1473}, 
month={April},}
@INPROCEEDINGS{7551414, 
author={Y. Zhang and D. Meisner and J. Mars and L. Tang}, 
booktitle={2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)}, 
title={Treadmill: Attributing the Source of Tail Latency through Precise Load Testing and Statistical Inference}, 
year={2016}, 
volume={}, 
number={}, 
pages={456-468}, 
abstract={Managing tail latency of requests has become one of the primary challenges for large-scale Internet services. Data centers are quickly evolving and service operators frequently desire to make changes to the deployed software and production hardware configurations. Such changes demand a confident understanding of the impact on one's service, in particular its effect on tail latency (e.g., 95th-or 99th-percentile response latency of the service). Evaluating the impact on the tail is challenging because of its inherent variability. Existing tools and methodologies for measuring these effects suffer from a number of deficiencies including poor load tester design, statistically inaccurate aggregation, and improper attribution of effects. As shown in the paper, these pitfalls can often result in misleading conclusions. In this paper, we develop a methodology for statistically rigorous performance evaluation and performance factor attribution for server workloads. First, we find that careful design of the server load tester can ensure high quality performance evaluation, and empirically demonstrate the inaccuracy of load testers in previous work. Learning from the design flaws in prior work, we design and develop a modular load tester platform, Treadmill, that overcomes pitfalls of existing tools. Next, utilizing Treadmill, we construct measurement and analysis procedures that can properly attribute performance factors. We rely on statistically-sound performance evaluation and quantile regression, extending it to accommodate the idiosyncrasies of server systems. Finally, we use our augmented methodology to evaluate the impact of common server hardware features with Facebook production workloads on production hardware. We decompose the effects of these features on request tail latency and demonstrate that our evaluation methodology provides superior results, particularly in capturing complicated and counter-intuitive performance behaviors. By tuning the hardware features - s suggested by the attribution, we reduce the 99th-percentile latency by 43% and its variance by 93%.}, 
keywords={Internet;computer centres;computer network performance evaluation;regression analysis;Facebook production workloads;Treadmill;counter-intuitive performance behaviors;data centers;large-scale Internet services;modular load tester platform;performance evaluation;performance factor attribution;precise load testing;production hardware configurations;quantile regression;request tail latency management;server hardware features;server load tester;server systems;server workloads;service operators;software hardware configurations;statistical inference;statistically-sound performance evaluation;Hardware;Histograms;Production;Servers;Testing;Web and internet services;data center;load testing;tail latency}, 
doi={10.1109/ISCA.2016.47}, 
ISSN={1063-6897}, 
month={June},}
@INPROCEEDINGS{7555000, 
author={C. Zhou and D. Du and Z. Cao and Y. Wang and X. Yang}, 
booktitle={2016 35th Chinese Control Conference (CCC)}, 
title={Assets overlapping networks and stress testing on stability of financial systems}, 
year={2016}, 
volume={}, 
number={}, 
pages={10385-10389}, 
abstract={Financial networks, creating potential propagation channels for shocks in crises, are widely viewed as a key factor to systemic stability. In this paper, we develop a dynamic model of deleveraging in an overlapping network of assets. We study the deleveraging spirals driven by the interaction between fire sales and confidence effects, and show how distress is amplified and propagated throughout the network. Using the regulatory data from the Peoples Bank of China (PBC), we construct the assets overlapping network and then apply the model to the system. The result suggests that: (1) the mutually reinforcing effects of fire sales and confidence can contribute to contagion significantly; (2) The vulnerability of the system are largely dependant on the distribution of large illiquid assets. Our model provides a ready-to-use yet powerful stress testing tool for macro-prudential regulation.}, 
keywords={asset management;finance;PBC;Peoples Bank of China;assets overlapping networks;confidence effects;deleveraging dynamic model;deleveraging spirals;financial systems stability;fire sales;illiquid assets;macroprudential regulation;stress testing;Electric shock;Heuristic algorithms;Investment;Portfolios;Stability analysis;Stress;Testing;Confidence Effects;Deleveraging;Financial Networks;Stress Testing;Systemic Risk}, 
doi={10.1109/ChiCC.2016.7555000}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{8278490, 
author={N. Ibhar and W. Flores and R. León}, 
booktitle={2017 IEEE 37th Central America and Panama Convention (CONCAPAN XXXVII)}, 
title={Design of a low-cost teleoperated robotic arm: Assembly and performance testing}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={At present, robots are widely used in various tasks, whether for industrial or even domestic uses. Thus, for certain tasks it has become necessary to operate the robot in an intuitive and safe way. The vast majority of current robotic hands do not completely replace the functionality of a hand and can not be used in environments which are designed for the use of a human hand. Thus, this document shows the design of a hybrid system with robotic hand and prosthesis applications. The design of a biomechanically controlled, functional and anthropomorphic robotic arm is shown, which demonstrates that it is feasible to design a real-time, low-cost, robotic arm.}, 
keywords={biomechanics;human-robot interaction;manipulator dynamics;prosthetics;robot dynamics;telerobotics;anthropomorphic robotic arm;biomechanically controlled arm;domestic uses;functional arm;human hand;hybrid system design;industrial uses;low-cost teleoperated robotic arm;performance testing;prosthesis;robotic hand;robotic hands;robots;Manipulators;Service robots;Silicon compounds;Task analysis;Testing;Torque;Human-robot interaction;Humanoid robots;Robot control;Telerobotics}, 
doi={10.1109/CONCAPAN.2017.8278490}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{4340515, 
author={l. liu and w. wei and j. li}, 
booktitle={2007 International Conference on Wireless Communications, Networking and Mobile Computing}, 
title={Wireless Communication System Automation Testing Framework}, 
year={2007}, 
volume={}, 
number={}, 
pages={2981-2984}, 
abstract={This article intends to introduce a leading next generation wireless protocol oriented automation testing framework - WiCAT system. This framework supports multiple protocol messaging testing by simulating the wireless equipments and implementing the telecommunication system logic. WiCAT provides high-efficiency and low-cost performance basing on a distributed, expandable and extensible architecture.}, 
keywords={automatic test software;electronic messaging;mobile radio;protocols;telecommunication computing;telecommunication equipment testing;WiCAT system;multiple protocol messaging testing;next generation wireless protocol;telecommunication system logic;wireless communication system automation testing;Automatic testing;Automation;Computer architecture;Graphical user interfaces;Local area networks;System testing;User interfaces;Utility programs;Wireless application protocol;Wireless communication}, 
doi={10.1109/WICOM.2007.740}, 
ISSN={2161-9646}, 
month={Sept},}
@INPROCEEDINGS{5067800, 
author={P. O. Iversen and K. Rutkowski and S. Issartel and L. Foged and A. Scannavini}, 
booktitle={2009 3rd European Conference on Antennas and Propagation}, 
title={Radiated performance testing of diversity and MIMO enabled terminals}, 
year={2009}, 
volume={}, 
number={}, 
pages={1069-1071}, 
abstract={This paper discuss general methods available for test and design engineers for testing radiated performances of multi-antenna enabled terminals in a controlled environment such as anechoic chambers. Methods for testing SIMO (Single-input Multi-Output), and MIMO (Multi-Input Multi-Output) performances in both passive and active way are highlighted. Information such as user defined propagation channel characteristic can be taking into account in passive measurements and is currently being investigated for the active testing.}, 
keywords={MIMO communication;antenna arrays;antenna radiation patterns;diversity reception;wireless channels;MIMO enabled terminals;diversity testing;multiantenna enabled terminals;passive measurements;propagation channel characteristics;radiated performance testing;Anechoic chambers;Antenna arrays;Antenna radiation patterns;Antennas and propagation;Current measurement;Design engineering;MIMO;Performance evaluation;Polarization;System testing}, 
doi={}, 
ISSN={2164-3342}, 
month={March},}
@INPROCEEDINGS{5658927, 
author={N. Nie and J. Guo and J. Fu and Z. Feng}, 
booktitle={2010 2nd International Workshop on Database Technology and Applications}, 
title={Reliability and Performance Testing Model of Web-Based User Login and Access Control}, 
year={2010}, 
volume={}, 
number={}, 
pages={1-4}, 
abstract={In order to test the performance, reliability and security of Web-based system, the paper generates the test scripts template and establishes testing model of system login and access control. Then some Web-based systems are tested by automation test tools. The performance, reliability and security problems of Web login process can be traced and diagnosed. The test result shows that Web-based system can be verified and improved by the test script template of multi-users secure login and resources access control.}, 
keywords={Internet;authorisation;computer network security;performance evaluation;Web based user login;access control;multiuser secure login;performance testing model;reliability testing model;test script template;Access control;Correlation;Driver circuits;Software reliability;Testing}, 
doi={10.1109/DBTA.2010.5658927}, 
ISSN={2167-1923}, 
month={Nov},}
@INPROCEEDINGS{6949287, 
author={R. Angmo and M. Sharma}, 
booktitle={2014 5th International Conference - Confluence The Next Generation Information Technology Summit (Confluence)}, 
title={Performance evaluation of web based automation testing tools}, 
year={2014}, 
volume={}, 
number={}, 
pages={731-735}, 
abstract={In today's 21st century era countless software applications are written as a web based application which runs in a web browsers. With new technologies and commercialization of I.T. sector, the web based system has undergoes frequent and rapid changes. Today Softwares are coded as a web based application, which help to access data from any part of the globe. Even the economic relevance of web based enhances the control and quality of software. The quality assurance of any system depends on its test. But to do manually testing in most of the cases is time consuming, expensive and hectic. For the better business purpose and to save time and money automation testing is required. There are variety of tools are available in the market for this. One of the best known tool is selenium suite which is a combination of different automation testing tool. In this paper we will discuss about the selenium suite. It provides testers with different framework for different test cases. The main objective of this paper is to find the best tool in selenium suite and then compare it with some other tool for same task. For this purpose, performance evaluation is done on the basis of some criteria.}, 
keywords={Internet;program testing;software performance evaluation;software quality;software tools;Web based application;Web based automation testing tools;Web browsers;performance evaluation;selenium suite;software applications;software quality;Automation;Browsers;Information technology;Performance evaluation;Software;Software testing;Automation testing;Performance;Selenium;Test case;Watir-webdriver;Web applications}, 
doi={10.1109/CONFLUENCE.2014.6949287}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{5279915, 
author={M. Nieminen and T. Raty and J. Palokangas}, 
booktitle={2009 First International Conference on Advances in System Testing and Validation Lifecycle}, 
title={Stress Testing the Logical Decision Making Server of a Surveillance System}, 
year={2009}, 
volume={}, 
number={}, 
pages={98-103}, 
abstract={The current generation of distributed and automated physical location surveillance systems faces high demands for robustness and reliability. We present and evaluate the design of the Logical Decision Making Server (LDMS), a rule-based automated decision making component used in the Single Location Surveillance Point (SLSP) system. To validate the robustness of the LDMS design for operation in the SLSP environment, we design and conduct a stress test experiment in which large load of TCP/IP input messages is sent instantaneously to the LDMS prototype implementation using the Nethawk EAST software. The stress test results are compared to measurements obtained during a real-life scenario. The LDMS is observed to withstand a significant amount of load without crashing, and its performance is can be considered sufficient for the SLSP system needs. A detailed analysis of results however shows an increase in the latency resulting from an extreme temporal load. We identify potential areas in the design to be improved if demands for higher response rates arise. The research is based on the construction of the related publications and technologies, and the results are established from the testing and validation of the implemented LDMS within the SLSP system.}, 
keywords={decision support systems;digital simulation;logic design;network servers;performance evaluation;transport protocols;video surveillance;Nethawk EAST software;TCP/IP input messages;automated decision making;environment for automated systems testing;logical decision making server;rule-based component;stress testing;surveillance system;Decision making;Logic testing;Robustness;Software prototyping;Software testing;Stress;Surveillance;System testing;TCPIP;Vehicle crash testing;decision making;stress testing;surveillance}, 
doi={10.1109/VALID.2009.16}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{7883617, 
author={H. Kapoh and E. S. Lumunon and N. A. E. Sajangbati}, 
booktitle={2016 International Conference on Knowledge Creation and Intelligent Computing (KCIC)}, 
title={Design model material requirement of coconut flour production and performance testing based multi user in North Sulawesi}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-7}, 
abstract={There has been many previous studies that discuss the control for the production of coconut flour and raw material inventory. But a system or a computer-based model for coconut flour industry in North Sulawesi has not or does not exist. For that reason, coconut flour industries also require tools on in running the business as developed in this study. The problem in this research is how to make the design of the model material production requirement of coconut flour-based multi-user to control the production of industrial centers in North Sulawesi coconut flour and how to test the model. The model generated in this study have been through a survey in the industrial district of coconut flour to get the data that will be used analysis, so that a complete picture processing system coconut flour and can describe the problem also the solution clearly in order to get the system needs a model along the test by using a test black box the program and the respondents used for the performance test in order to know the program's ability to interact with users. The collected data is then analyzed and designed using some design method that is data flow diagrams, use case diagram, entity relationship diagrams and material requirements planning methods. Results of the test will indicate that all functions on the system works well and test the respondent for 30 and 60 minutes resulting in a 60% and 63% of respondents were taken as many as 30 answered easily using the model application.}, 
keywords={design engineering;food processing industry;materials requirements planning;production engineering computing;raw materials inventory;North Sulawesi;coconut flour industry;coconut flour production;computer-based model;data flow diagrams;design model material requirement;entity relationship diagrams;industrial centers;material requirements planning methods;model material production requirement;performance testing based multiuser;picture processing system;raw material inventory;use case diagram;Companies;Computational modeling;Industries;Planning;Production;Raw materials;Testing;coconut flour;design;model;multi-user;production;testing}, 
doi={10.1109/KCIC.2016.7883617}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{4041302, 
author={L. Liu and J. Lin and Z. Li and J. Li}, 
booktitle={2006 IEEE Asia-Pacific Conference on Services Computing (APSCC'06)}, 
title={State Machine Based CDMA Stress Testing Service System}, 
year={2006}, 
volume={}, 
number={}, 
pages={625-628}, 
abstract={This paper introduces a system model of CDMA stress testing service platform based on state machine technology. This system provides an efficient service oriented solution on protocol and stress testing of CDMA system, with high performance and automatic capability. The concurrent multitask mechanism and the state machine framework enable the high performance and automatic capability of this system. And the scalable distributed architecture offers the maximum flexibility of deployment}, 
keywords={code division multiple access;computer architecture;finite state machines;protocols;stress analysis;CDMA stress testing service system;concurrent multitask mechanism;protocol;scalable distributed architecture;state machine;Communication system control;Computer architecture;Electronic equipment testing;Hardware;Mobile communication;Multiaccess communication;Protocols;Software testing;Stress;System testing;Service;State Machine;Stress Testing}, 
doi={10.1109/APSCC.2006.93}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{5454995, 
author={Y. Pu and M. Xu}, 
booktitle={2009 First International Conference on Information Science and Engineering}, 
title={Load Testing for Web Applications}, 
year={2009}, 
volume={}, 
number={}, 
pages={2954-2957}, 
abstract={The performance testing criteria was analyzed, including response time, concurrency users, throughout and performance counter. Performance testing is necessary for the system reliability. Load testing can be used for software troubleshooting and optimizing. With the LoadRunner and TestDirector testing tools, a load testing scheme based on an online examination system was designed.}, 
keywords={Internet;program testing;software performance evaluation;LoadRunner testing tools;TestDirector testing tools;Web application;concurrency users;load testing;online examination system;performance counter;performance testing criteria;response time;software troubleshooting;system reliability;Application software;Automatic testing;Computer bugs;Concurrent computing;Delay;Reliability engineering;Software performance;Software testing;System performance;System testing}, 
doi={10.1109/ICISE.2009.720}, 
ISSN={2160-1283}, 
month={Dec},}
@INPROCEEDINGS{1285473, 
author={H. A. Chan}, 
booktitle={Annual Symposium Reliability and Maintainability, 2004 - RAMS}, 
title={Accelerated stress testing for both hardware and software}, 
year={2004}, 
volume={}, 
number={}, 
pages={346-351}, 
abstract={Accelerated stress testing (AST) has been used in electronic, electromechanical, and mechanical systems to achieve robustness with high reliability primarily for hardware. For software products, the reliability program is often conducted separate from any hardware accelerated stress testing. Yet, many systems are consist of concurrent software and hardware issues. In addition, the stress testing processes were primarily adopted by those responsible to develop and manufacture hardware. For example, the stresses usually include temperature extremes, thermal cycles, vibrations, etc. These stresses are effective in accelerating latent hardware defects from degradable, marginal, or intermittent failures to hard failures so that root cause analyses and corrective actions may be made. Although experiments had indicated that software faults and hardware defects are related, the available formulation of the fundamental principles was still based on hardware systems. AST for software and for operating systems have been discussed in [M. Werner, et al., "Improving Customer Satisfaction via Accelerated Stress Testing of General Purpose Computer Operating Systems"] and [M. Werner, et al., 2002], but a fundamental understanding of AST for software is lacking. In order to generalize the fundamentals of accelerated stress testing to address both software and hardware, we need to define accelerated stress testing for software and to address whether they are needed, i.e., whether there are effective methods to achieve high software reliability. The basic reliability concepts categorize systems into different categories according to the presence of defects and faults and whether these weaknesses are explicit enough. The concepts for both hardware and software reliability separate the notion of defects and faults from failures. It further conceptually separates the notion of stressing and the notion of detection. The fundamental concept is that all failures except the explicit ones must be manifested under certain stress conditions. There is then a threshold stress level beyond which a system fails. The cumulative effect of stresses is included by defining time as one type of stress. Both hardware and software systems have marginal weakness, and degradable weakness. The process o- f recovery and repair are also examined for both hardware and software events. The basic reliability principles in accelerated stress testing for both software and hardware systems are combined and explained in this paper. While [M. Werner, et al., "Improving Customer Satisfaction via Accelerated Stress Testing of General Purpose Computer Operating Systems"] and [M. Werner, et al., 2002] also address the needs and advantages of AST for software, an effective software AST program requires efficient tools yet to be developed. The benefits should justify the needed further research and development in this area.}, 
keywords={conformance testing;life testing;software reliability;stress analysis;accelerated stress testing;corrective actions;hardware defects;hardware reliability;reliability program;root cause analysis;software faults;software reliability;Customer satisfaction;Hardware;Life estimation;Operating systems;Software reliability;Software systems;Software testing;Software tools;System testing;Thermal stresses}, 
doi={10.1109/RAMS.2004.1285473}, 
ISSN={}, 
month={},}
@INPROCEEDINGS{103992, 
author={P. A. Singer}, 
booktitle={Military Communications Conference, 1989. MILCOM '89. Conference Record. Bridging the Gap. Interoperability, Survivability, Security., 1989 IEEE}, 
title={Trends in VLF/LF modem performance testing}, 
year={1989}, 
volume={}, 
number={}, 
pages={581-584 vol.2}, 
abstract={The author reviews the historical development of digital VLF/LF modem testing. He discusses the introduction of test equipment in the following four major functional areas: (a) transmit simulation, (b) channel simulation, (c) noise and interference generation, and (d) reception characterization. He demonstrates two major trends: (1) the use of general-purpose hardware and off-line software replacing special-purpose hardware; (2) Gaussian noise, atmospheric laboratory test environments being replaced by tailored simulated electromagnetic interference and atmospheric noise}, 
keywords={automatic test equipment;digital simulation;electronic equipment testing;modems;performance evaluation;Gaussian noise;LF;VLF;atmospheric laboratory test environments;atmospheric noise;channel simulation;digital modem;electromagnetic interference;general-purpose hardware;interference generation;modem performance testing;noise generation;off-line software;reception characterization;test equipment;transmit simulation;Atmospheric modeling;Electromagnetic interference;Gaussian noise;Hardware;Low-frequency noise;Modems;Noise generators;Test equipment;Testing;Working environment noise}, 
doi={10.1109/MILCOM.1989.103992}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{5458557, 
author={Q. Wu and Y. Wang}, 
booktitle={2010 Second International Workshop on Education Technology and Computer Science}, 
title={Performance Testing and Optimization of J2EE-Based Web Applications}, 
year={2010}, 
volume={2}, 
number={}, 
pages={681-683}, 
abstract={J2EE-based Web applications are becoming increasingly ubiquitous and with their increasing adoption, the performance is the attention focus and the most important factor of evaluating the system by users. In this paper, we present a systematic solution for performance testing and optimization of J2EE-based Web applications. The solution helps to identify and eliminate bottlenecks in the application design and ensures that systems are designed to meet their quality of service requirements. This paper firstly analyses the architecture of J2EE-based Web applications and performance testing principle, and then improves the JMeter testing framework for meeting the more concurrent users. Lastly, performance testing for J2EE-based Web applications is done; it finds performance bottlenecks and puts forward optimum measures, and compares the performance with the former one.}, 
keywords={Internet;Java;program testing;software performance evaluation;J2EE-based Web applications optimization;JMeter testing framework;concurrent users;performance testing;quality of service requirements;systematic solution;Application software;Business;Delay;Educational institutions;Nonhomogeneous media;Performance analysis;Scalability;Service oriented architecture;System performance;System testing;JMeter;Web applications;distributed;optimization;performance}, 
doi={10.1109/ETCS.2010.583}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{7980227, 
author={B. Chapuis and B. Garbinato}, 
booktitle={2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)}, 
title={Scaling and Load Testing Location-Based Publish and Subscribe}, 
year={2017}, 
volume={}, 
number={}, 
pages={2543-2546}, 
abstract={The rise of the Internet of things (IoT) poses massive scalability issues for location-based services. More particularly, location-aware publish and subscribe services are struggling to scale out the computation of matches between publications and subscriptions that continuously update their location. In this demonstration paper, we propose a novel distributed and horizontally scalable architecture for location-aware publish and subscribe. Our middleware architecture relies on a multi-step routing mechanism based on consistent hashing and range partitioning. To demonstrate its scalability, we present a traffic data generator, which, in contrast to existing generators, can be used to perform real-time load tests. Finally, we show that our architecture can be deployed on a small 10-node cluster and can process up to 80,000 location updates per second producing 25,000 matches per seconds.}, 
keywords={Internet of Things;message passing;middleware;Internet of Things;location-aware publish and subscribe services;location-based services;middleware architecture;multi-step routing mechanism;traffic data generator;Computer architecture;Generators;Middleware;Real-time systems;Roads;Routing;Scalability}, 
doi={10.1109/ICDCS.2017.234}, 
ISSN={1063-6927}, 
month={June},}
@INPROCEEDINGS{6334582, 
author={J. Wu}, 
booktitle={2012 IEEE AUTOTESTCON Proceedings}, 
title={Stress testing software to determine fault tolerance for hardware failure and anomalies}, 
year={2012}, 
volume={}, 
number={}, 
pages={294-298}, 
abstract={Today's military systems rely for their performance on combinations of hardware and software. While testing of hardware performance during design, development and operation is well understood, the testing of software is less mature. In particular, the effect of hardware failures in the field on software performance, and therefore systems performance, is all-too-often overlooked or is tested in a far less rigorous manner that that applied to Hardware failures alone. Numerous examples exist of major system failures driven by software anomalies but triggered by Hardware failures, with consequences that range from degraded mission performance to weapons system destruction and operator fatalities. Measuring software development quality and fault tolerance is a challenging task. Many software test methods focus on source-code only approach (unit tests, modular test) and neglect the impacts caused by hardware anomalies or failures. Such missing test coverage can and will result in potential degraded software performance quality, thereby adding to project cost and delaying schedule. It can also result in far more disastrous consequences for the warfighters. This paper will discuss the general nature of the hardware-failure-software anomaly - system failure flow-down. It will then describe techniques that exist for system software testing and will highlight extensions of these techniques to focus on an effective and comprehensive software testing that includes performance prediction and hardware failure fault tolerance. The end result is a suite of test methods that, when properly applied, offer a systematic and comprehensive analysis of prime software behaviors under a range of hardware field failure conditions.}, 
keywords={fault tolerant computing;military computing;missiles;program testing;software metrics;software performance evaluation;software quality;delaying schedule;fault tolerance measurement;hardware anomalies;hardware failure fault tolerance;hardware field failure conditions;hardware performance testing;missing test coverage;mission performance degradation;operator fatalities;performance prediction;project cost;software anomalies;software behavior comprehensive analysis;software development quality measurement;software performance;software testing;source code;stress testing software;system failure flow-down;warfighters;weapon system destruction;Embedded systems;Fault detection;Hardware;Monitoring;Real-time systems;Voltage control}, 
doi={10.1109/AUTEST.2012.6334582}, 
ISSN={1088-7725}, 
month={Sept},}
@INPROCEEDINGS{5272178, 
author={O. Hamed and N. Kafri}, 
booktitle={2009 First International Conference on Networked Digital Technologies}, 
title={Performance testing for web based application architectures (.NET vs. Java EE)}, 
year={2009}, 
volume={}, 
number={}, 
pages={218-224}, 
abstract={Having an efficient web application is a challenge that we need to achieve when architecting web applications in the development process. This research follows a performance modeling approach that aims to utilize load testing tools to give ideas about performance issues early in the development life cycle for applications implemented using Java Enterprise Edition (Java EE) or .NET platform. Thus, it helps system architects to choose between competitive frameworks. To achieve this, the applications are subjected to artificial workload. Direct measurements are obtained on the specified application scenarios using different tools. Parasoft WebKing and Hewlett-Packard LoadRunner were used for this purpose. Later on, the obtained results indicate that, Java EE performs better than .NET. by means of response time and memory utilization.}, 
keywords={Java;program testing;software architecture;software performance evaluation;Hewlett-Packard LoadRunner;Java Enterprise Edition;Parasoft WebKing;Web based application architectures;artificial workload;development life cycle;load testing tools;performance testing;Analytical models;Application software;Automatic testing;Computational modeling;Delay;Java;Performance analysis;Scalability;Service oriented architecture;System testing}, 
doi={10.1109/NDT.2009.5272178}, 
ISSN={2155-8728}, 
month={July},}
@INBOOK{5444092, 
author={Gail D. Baura}, 
booktitle={System Theory and Practical Applications of Biomedical Signals}, 
title={Pharmacologic Stress Testing Using Closed-Loop Drug Delivery}, 
year={2002}, 
volume={}, 
number={}, 
pages={0-}, 
abstract={
This chapter contains sections titled:

Pharmacokinetics and Pharmacodynamics

Control Theory

Problem Significance

Closed-Loop Drug Infusion in Pharmacological Stress Tests

Summary

References

Peripheral Insulin Kinetics Exercises

}, 
keywords={Absorption;Biomedical monitoring;Blood flow;Drug delivery}, 
doi={10.1109/9780471683179.ch14}, 
ISSN={}, 
publisher={Wiley-IEEE Press}, 
isbn={9780471683179}, 
url={https://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5444092},}
@INPROCEEDINGS{6158278, 
author={Li Zhang and Yinghui Chen and Fan Tang and Xiong Ao}, 
booktitle={2011 6th International ICST Conference on Communications and Networking in China (CHINACOM)}, 
title={Design and implementation of cloud-based performance testing system for web services}, 
year={2011}, 
volume={}, 
number={}, 
pages={875-880}, 
abstract={Nowadays testing plays an important role in software development process. While software testing is expensive and time-consuming, sufficient testing is hard, especially for a distributed system using web services technique in the real circumstance. The development of cloud computing provides us new ideas to solve these testing problems. To address these issues, we propose a framework which integrates cloud computing and performance testing technologies. In this paper, first we present the architecture of the cloud-based performance testing system for web services (CPTS), which is a portable, extensible and easy-to-use framework for generating and submitting test workloads to computing clouds. Then, we show the process how to use CPTS to run a performance test and present the concept of dynamic migration in CPTS. Finally, we present our experiences with CPTS in Amazon EC2. We found that the CPTS allows a user to easily set up and test a web services system on the cloud and improve test effectively.}, 
keywords={Web services;cloud computing;program testing;software performance evaluation;Amazon EC2;CPTS;Web services;cloud computing;cloud-based performance testing system;distributed system;dynamic migration;software development process;software testing;Cloud computing;Dispatching;Dynamic scheduling;Monitoring;Servers;Testing;cloud computing;dynamic migration;performance testing;virtual machine;web services}, 
doi={10.1109/ChinaCom.2011.6158278}, 
ISSN={}, 
month={Aug},}
@ARTICLE{7740990, 
author={S. Omidshafiei and A. A. Agha-Mohammadi and Y. F. Chen and N. K. Ure and S. Y. Liu and B. T. Lopez and R. Surati and J. P. How and J. Vian}, 
journal={IEEE Control Systems}, 
title={Measurable Augmented Reality for Prototyping Cyberphysical Systems: A Robotics Platform to Aid the Hardware Prototyping and Performance Testing of Algorithms}, 
year={2016}, 
volume={36}, 
number={6}, 
pages={65-87}, 
abstract={Planning, control, perception, and learning are current research challenges in multirobot systems. The transition dynamics of the robots may be unknown or stochastic, making it difficult to select the best action each robot must take at a given time. The observation model, a function of the robots' sensor systems, may be noisy or partial, meaning that deterministic knowledge of the team's state is often impossible to attain. Moreover, the actions each robot can take may have an associated success rate and/or a probabilistic completion time. Robots designed for real-world applications require careful consideration of such sources of uncertainty, regardless of the control scheme or planning or learning algorithms used for a specific problem. Understanding the underlying mechanisms of planning algorithms can be challenging due to the latent variables they often operate on. When performance testing such algorithms on hardware, the simultaneous use of the debugging and visualization tools available on a workstation can be difficult. This transition from experimentation to implementation becomes especially challenging when the experiments need to replicate some feature of the software tool set in hardware, such as simulation of visually complex environments. This article details a robotics prototyping platform, called measurable augmented reality for prototyping cyberphysical systems (MAR-CPS), that directly addresses this problem, allowing for the real-time visualization of latent state information to aid hardware prototyping and performance testing of algorithms.}, 
keywords={augmented reality;control engineering computing;cyber-physical systems;data visualisation;mobile robots;path planning;robot vision;software prototyping;software tools;MAR-CPS;hardware prototyping;latent state information;measurable augmented reality for prototyping cyberphysical systems;performance testing;planning algorithm;real-time visualization;robot sensor system;robotic platform;software tool set;Algorithm design and analysis;Augmented reality;Central Processing Unit;Cyber-physical systems;Planning;Robot sensing systems;Robots}, 
doi={10.1109/MCS.2016.2602090}, 
ISSN={1066-033X}, 
month={Dec},}
@INPROCEEDINGS{6111055, 
author={L. Zhizhong and W. Sen and X. Jun and N. Bo and J. Hongliang and X. Hua}, 
booktitle={2011 7th Asia-Pacific International Conference on Lightning}, 
title={Performance testing and comprehensive evaluation on large grounding connection}, 
year={2011}, 
volume={}, 
number={}, 
pages={983-989}, 
abstract={To comprehensively evaluate the safety of large grounding connection, testing and action principle of the main factors that impact the safe operation of grounding connection, were analyzed and studied, and the following conclusions were drew by theoretical analysis and simulation research. While evaluating step voltage and touch voltage, it's inadvisable to consider seasonal factors during the selection of soil resistivity; the testing direction of step voltage and touch voltage should be selected based on simulation computation for getting reliable data; eligibility criterion on electric integrity of grounding connection should not be 200mΩ but appropriately lowered; corrosion evaluation of grounding connection can be get rudely by analogized ways, which need the adding appropriate monitoring point in the corner of the grounding grid. Finally, the grading criterion and reference methods of weight value for the testing results of safe operation factors of grounding connection is proposed for establishing a quantified evaluation system of grading grounding connection, detailing the state evaluation system of large grounding connection.}, 
keywords={earthing;power grids;grounding connection;grounding grid;soil resistivity;step voltage;touch voltage;Corrosion;Electric potential;Grounding;Immune system;Resistance;Testing;Thermal stability;Grounding connection;comprehensive evaluation;grading criterion;grounding grid;integrity of grounding connection;quantified evaluation}, 
doi={10.1109/APL.2011.6111055}, 
ISSN={}, 
month={Nov},}
@ARTICLE{4319794, 
author={H. C. Kyle}, 
journal={IEEE Transactions on Aerospace}, 
title={Compatibility and Performance Testing of Communications Systems}, 
year={1965}, 
volume={AS-3}, 
number={2}, 
pages={139-143}, 
abstract={During the normal progress of design, fabrication, and integration of communications subsystems for spacecraft and for ground installations, every effort is made to assure that the equipment meets certain specifications relating to performance, environment, reliability, and interface capability. These specifications are based on the best available definition of requirements and interface characteristics of complementing subsystems. Frequently, in the field of manned spaceflight, the spacecraft subsystems, the launch vehicle subsystems, and the ground systems must be designed and constructed concurrently. This means that the operating and interface characteristics of one subsystem are not available for use by the engineers in the design of the other subsystems. Close technical liaison among the various engineering groups is essential in the accomplishment of overall systems' integrity. Component and subsystem testing has been developed to a high degree, but the results of these are necessarily limited. They cannot validate the overall systems' performance and compatibility. It is considered mandatory that the interfacing subsystems be mated to form a complete system in a controlled test environment as early as practicable in any program, especially in one involving communications systems as new and as complex as those for Apollo. This must be accomplished at such a phase in the program that corrective engineering details can be fed back to the cognizant design, fabrication, or integration groups involved in time for necessary modifications prior to the beginning of the flight phase.}, 
keywords={Aerospace engineering;Automotive engineering;Communication system control;Control systems;Design engineering;Fabrication;Land vehicles;Road vehicles;Space vehicles;System testing}, 
doi={10.1109/TA.1965.4319794}, 
ISSN={0536-1516}, 
month={June},}
@INPROCEEDINGS{1368035, 
author={K. Gold and A. Brown}, 
booktitle={2004 IEEE Aerospace Conference Proceedings (IEEE Cat. No.04TH8720)}, 
title={Architecture and performance testing of a software GPS receiver for space-based applications}, 
year={2004}, 
volume={4}, 
number={}, 
pages={2404-2416 Vol.4}, 
abstract={Space-based GPS technology presents significant challenges over Earth-based systems. These include visibility issues for rotating platforms and tracking of GPS satellites from spacecraft that are in higher orbits than the GPS, realtime resolution of carrier phase ambiguities, and different dynamics during various mission phases. NAVSYS has developed a software GPS receiver that makes use of 3-dimensional digital beam steering technology and inertial aiding to address these issues. This approach offers several advantages including all round visibility for spinning satellites, tracking of weak GPS signals, reduction of multipath, and reprogrammability to accommodate different mission phases. Additionally, a suite of simulation tools based on the NAVSYS Matlab Toolbox and Advanced GPS Hybrid simulation products have been built to allow testing for simulated space environments. The receiver architecture and test tools are described in this paper.}, 
keywords={Global Positioning System;aerospace computing;artificial satellites;beam steering;hybrid simulation;radio receivers;real-time systems;satellite tracking;software radio;telecommunication equipment testing;3-dimensional digital beam steering technology;Earth based systems;GPS hybrid simulation products;GPS satellite tracking;GPS signal tracking;Matlab toolbox;NAVSYS;carrier phase ambiguity;multipath reduction;realtime resolution;receiver architecture;rotating platforms;simulated space environment;software GPS receiver;space based applications;spinning satellites;Application software;Beam steering;Computer architecture;Global Positioning System;Orbits;Satellites;Software performance;Software testing;Space technology;Space vehicles}, 
doi={10.1109/AERO.2004.1368035}, 
ISSN={1095-323X}, 
month={March},}
@INPROCEEDINGS{7764458, 
author={B. Wunderle and T. Onken and J. Heilmann and D. Silbernagl and J. Arnold and T. Bieniek and R. Pufall}, 
booktitle={2016 6th Electronic System-Integration Technology Conference (ESTC)}, 
title={Reliability of sputtered thin aluminium films under accelerated stress testing by vibration loading and modeling}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-14}, 
abstract={Aluminium is still one of the most important contact metallisations for power electronic chips like MOSFETs or IGBTs. With a large difference in thermal expansion coefficients (CTEs) between aluminium and silicon and the temperatures generated in hot-spots during high power transients, these layers are prone to failure due to thermo-mechanical fatigue. Usually lifetime assessment is done by subjecting dedicated test specimens to standardised stress tests as e.g. active or passive thermal cycling. This paper proposes a novel method for accelerated stress testing and lifetime modelling of thin aluminium films in the high-cycle fatigue regime by isothermal mechanical loading. The proposed novel test method is suggested to complement or replace resource-demanding thermal cycling tests and allow simple in-situ monitoring of failure.}, 
keywords={semiconductor device reliability;thermal expansion;vibrations;CTE;IGBT;MOSFET;accelerated stress testing;active thermal cycling;high power transients;high-cycle fatigue regime;hot-spots;isothermal mechanical loading;lifetime modelling;passive thermal cycling;power electronic chips;sputtered thin aluminium films reliability;thermal expansion coefficients;thermomechanical fatigue;thin aluminium films;vibration loading;vibration modeling;Aluminum;Fatigue;Life estimation;Silicon;Stress;Testing}, 
doi={10.1109/ESTC.2016.7764458}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6674729, 
author={B. Querbach and S. Puligundla and D. Becerra and Z. T. Schoenborn and P. Chiang}, 
booktitle={2013 IEEE 56th International Midwest Symposium on Circuits and Systems (MWSCAS)}, 
title={Comparison of hardware based and software based stress testing of memory IO interface}, 
year={2013}, 
volume={}, 
number={}, 
pages={637-640}, 
abstract={In post-silicon testing and validation of circuit functionality, an effective IO stress pattern can identify bugs quickly and provide adequate test coverage. A lot of work has been done to identify the right stress patterns specific to each IO interface. While some patterns can be generic enough to apply to all IOs, other patterns are interface topology specific. In addition to identifying the worst-case pattern, tradeoffs between test-time and test coverage must be made depending on the test goals. Pseudo Random Bit Stream (PRBS) generators are commonly used to generate test patterns because of the adequate frequency content in the PRBS patterns, the ease of implementation, and minimal gate count. This paper introduces an Advanced Pattern Generator and Checker (APGC) based on PRBS that retains all the aforementioned advantages. The APGC was implemented for a DDR memory interface where different LFSRs beat against each other spatially on neighboring IO lanes while rotating this form of aggressor-victim pattern in time. The results of the APGC stress patterns are compared to a form of advanced software-based learning algorithm based patterns that exhaustively search this complete parameter space. The comparison of APGC to software showed that the measured bit error rate (BER) plotted on a Q-scale of both methods is similar for the Receiver side. On the Transmitter side, APGC showed less eye opening than the software. In addition to the margin comparison, on the test execution side, APGC can speed up the test and validation execution time compared to the software by 32 to 2048 times depending on aggressor victim lane width of 8 to 64 lanes.}, 
keywords={automatic test pattern generation;electronic engineering computing;error statistics;integrated circuit testing;learning (artificial intelligence);peripheral interfaces;random number generation;semiconductor storage;APGC stress pattern;BER;DDR memory interface;IO stress pattern;LFSR;PRBS generators;Q-scale;advanced pattern generator and checker;aggressor-victim pattern;bit error rate;bug identification;circuit functionality validation;gate count;hardware based stress testing;interface topology;memory IO interface;post-silicon testing;pseudorandom bit stream generators;software based stress testing;software-based learning algorithm;test coverage;test execution;test pattern generation;test time;worst-case pattern}, 
doi={10.1109/MWSCAS.2013.6674729}, 
ISSN={1548-3746}, 
month={Aug},}
@INPROCEEDINGS{6159734, 
author={Ren Mingqiu and Cai Jinyan and Zhu Yuanqing and Han Zhuangzhi}, 
booktitle={Proceedings of 2011 IEEE CIE International Conference on Radar}, 
title={Design of radar ECCM performance testing system and its semi-physical simulation experiment}, 
year={2011}, 
volume={2}, 
number={}, 
pages={1058-1062}, 
abstract={This paper describes the theory, design, implementation, simulation and testing of a radar ECCM performance testing system capable of generating target echo, clutter and jamming signal for radar ECM/ECCM experiment. With the help of the proposed testing system, the jamming styles and parameters can be smartly intercalated with a variety of simulation scenarios. The rubs are resolved such as radar states data acquisition, echo real time simulation and display & control terminals setup of signal environment. Then a radar ECM semi-physical simulation experiment is applied to measure six typical ECCM performance indexes in the signal environment generated by the testing system. Experiment and data processing results show the testing platform is valid and practical. The testing system can be used to solve problems such as radar ECCM performance evaluation, radar advanced design and ECCM strategies when the equipment is relatively small in tracking and guidance phase.}, 
keywords={electronic countermeasures;jamming;radar clutter;radar tracking;target tracking;testing;data processing;echo real time simulation;guidance phase;jamming signal;radar ECCM performance testing system;radar clutter;radar states data acquisition;semiphysical simulation experiment;target echo;tracking phase;Electronic countermeasures;Jamming;Radar antennas;Radar tracking;Target tracking;Testing;Radar ECCM;active jamming;evaluation index;semi-physical simulation experiment;testing system}, 
doi={10.1109/CIE-Radar.2011.6159734}, 
ISSN={1097-5764}, 
month={Oct},}
@INPROCEEDINGS{6493621, 
author={Y. Kim and L. K. John and S. Pant and S. Manne and M. Schulte and W. L. Bircher and M. S. S. Govindan}, 
booktitle={2012 45th Annual IEEE/ACM International Symposium on Microarchitecture}, 
title={AUDIT: Stress Testing the Automatic Way}, 
year={2012}, 
volume={}, 
number={}, 
pages={212-223}, 
abstract={Sudden variations in current (large di/dt) can lead to significant power supply voltage droops and timing errors in modern microprocessors. Several papers discuss the complexity involved with developing test programs, also known as stress marks, to stress the system. Authors of these papers produced tools and methodologies to generate stress marks automatically using techniques such as integer linear programming or genetic algorithms. However, nearly all of the previous work took place in the context of single-core systems, and results were collected and analyzed using cycle-level simulators. In this paper, we measure and analyze di/dt issues on state-of-the-art multi-core x86 systems using real hardware rather than simulators. We build on an existing single-core stress mark generation tool to develop an Automated DI/dT stress mark generation framework, referred to as AUDIT, to generate di/dt stress marks quickly and effectively for multicore systems. We showcase AUDIT's capabilities to adjust to micro architectural and architectural changes. We also present a dithering algorithm to address thread alignment issues on multi-core processors. We compare standard benchmarks, existing di/dt stress marks, and AUDIT-generated stress marks executing on multi-threaded, multi-core systems with complex out-of-order pipelines. Finally, we show how stress analysis using simulators may lead to flawed insights about di/dt issues.}, 
keywords={integrated circuit testing;microprocessor chips;multiprocessing systems;stress analysis;AUDIT capabilities;AUDIT-generated stress marks;automated DI-dT stress mark generation framework;cycle-level simulators;dithering algorithm;genetic algorithms;integer linear programming;microarchitectural changes;microprocessors;multicore processors;multithreaded multicore systems;out-of-order pipelines;power supply voltage droops;single-core stress mark generation tool;single-core systems;stress analysis;stress testing;test programs;thread alignment issues;timing errors;di/dt;genetic algorithm;hardware measurement;inductive noise;low power;power distribution network;stressmark generation;voltage droop}, 
doi={10.1109/MICRO.2012.28}, 
ISSN={1072-4451}, 
month={Dec},}
@ARTICLE{5977130, 
author={M. Kalita and T. Bezboruah}, 
journal={IET Software}, 
title={Investigation on performance testing and evaluation of PReWebD: a .NET technique for implementing web application}, 
year={2011}, 
volume={5}, 
number={4}, 
pages={357-365}, 
abstract={A prototype research web application based on Visual Studio platform is developed with .NET as framework, Internet Information Server (IIS) (Version: 5.1) as web server and Microsoft Standard Query Language (SQL) Server (Version: 2005) as database server to study the performance and evaluation of the .NET technique used for developing the web application. The authors call it the PReWebD. As the performance is one of the most important features of a web application, to evaluate the performance, testing of PReWebD has been carried out using Mercury LoadRunner (Version 8.0) for validation and to study some other attributes like scalability, reliability etc. The performance depends on parameters such as hits/s, response time, throughput, errors/s etc. These parameters for PReWebD are tested with different stress levels. The statistical testing and analysis is done to assure the stability, reliability and quality of the application. Here the authors report in details the architecture, testing procedure, result of performance testing as well as the results of statistical analysis on recorded data of PReWebD.}, 
keywords={Internet;SQL;network operating systems;program testing;software architecture;software performance evaluation;statistical testing;.NET technique;Internet Information Server;Mercury LoadRunner;Microsoft Standard Query Language;PReWebD;SQL server;Visual Studio platform;Web application;Web server;architecture;database server;performance evaluation;performance testing;statistical analysis;statistical testing;stress level}, 
doi={10.1049/iet-sen.2010.0139}, 
ISSN={1751-8806}, 
month={August},}
@INPROCEEDINGS{7998430, 
author={A. P. Samoylenko and A. I. Panychev and S. A. Panychev}, 
booktitle={2017 International Siberian Conference on Control and Communications (SIBCON)}, 
title={Evaluation of telecommunication system reliability via stress testing}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={The problem of evaluating reliability of telecommunication systems in general, and their components is considered. The method of forecasting the reliability of a telecommunications system designed according to the results of stress testing is proposed. The essence of the proposed method is to use the emissions of a random process as a diagnostic parameter that displays the trajectory of a monitored quantity values. As a quantitative measure of reliability used system average uptime. The simulation for normal distribution law of a random parameters with different correlation functions is carried out. The estimation of the average uptime for various sizes of tolerance range of parameters is calculated. It is shown that the theory of random processes emissions is an adequate mathematical apparatus for the formalization of the results of stress testing.}, 
keywords={mathematical analysis;telecommunication network reliability;diagnostic parameter;different correlation functions;mathematical apparatus;monitored quantity values;normal distribution law;random parameters;random process emissions;stress testing;system average uptime;telecommunication system reliability;Monitoring;Random processes;Reliability;Stress;Telecommunications;Testing;Trajectory;average uptime;emissions of a random process;forced testing;reliability;stress test;survivability;telecommunication system;the trajectory of a random parameter;tolerance domain}, 
doi={10.1109/SIBCON.2017.7998430}, 
ISSN={}, 
month={June},}
@ARTICLE{4302730, 
author={S. Pakin}, 
journal={IEEE Transactions on Parallel and Distributed Systems}, 
title={The Design and Implementation of a Domain-Specific Language for Network Performance Testing}, 
year={2007}, 
volume={18}, 
number={10}, 
pages={1436-1449}, 
abstract={CONCEPTUAL is a toolset designed specifically to help measure the performance of high-speed interconnection networks such as those used in workstation clusters and parallel computers. It centers around a high-level domain-specific language, which makes it easy for a programmer to express, measure, and report the performance of complex communication patterns. The primary challenge in implementing a compiler for such a language is that the generated code must be extremely efficient so as not to misattribute overhead costs to the messaging library. At the same time, the language itself must not sacrifice expressiveness for compiler efficiency, or there would be little point in using a high-level language for performance testing. This paper describes the CONCEPTUAL language and the CONCEPTUAL compiler's novel code-generation framework. The language provides primitives for a wide variety of idioms needed for performance testing and emphasizes a readable syntax. The core code-generation technique, based on unrolling CONCEPTUAL programs into sequences of communication events, is simple yet enables the efficient implementation of a variety of high-level constructs. The paper further explains how CONCEPTUAL implements time-bounded loops - even those that comprise blocking communication - in the absence of a time-out mechanism as this is a somewhat unique language/implementation feature.}, 
keywords={computational linguistics;high level languages;message passing;program compilers;program control structures;program testing;software performance evaluation;specification languages;CONCEPTUAL language;blocking communication;code generation;domain-specific language;high-level language;high-speed interconnection networks;messaging library;network performance testing;parallel computers;program compiler;readable syntax;time-bounded loops;time-out mechanism;workstation clusters;Computer networks;Concurrent computing;Costs;Domain specific languages;High performance computing;Libraries;Multiprocessor interconnection networks;Programming profession;Testing;Workstations;Interprocessor communications;Measurement techniques;Specialized application languages}, 
doi={10.1109/TPDS.2007.1065}, 
ISSN={1045-9219}, 
month={Oct},}
@INPROCEEDINGS{6008948, 
author={M. A. S. Netto and S. Menon and H. V. Vieira and L. T. Costa and F. M. de Oliveira and R. Saad and A. Zorzo}, 
booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
title={Evaluating Load Generation in Virtualized Environments for Software Performance Testing}, 
year={2011}, 
volume={}, 
number={}, 
pages={993-1000}, 
abstract={Before placing a software system into production, it is necessary to guarantee it provides users with a certain level of Quality-of-Service. Intensive performance testing is then necessary to achieve such a level and the tests require an isolated computing environment. Virtualization can therefore play an important role for saving energy costs by reducing the number of servers required to run performance tests and for allowing performance isolation when executing multiple tests in the same computing infrastructure. Load generation is an important component in performance testing as it simulates users interacting with the target application. This paper presents our experience in using a virtualized environment for load generation aimed at performance testing. We measured several performance metrics and varied system load, number of virtual machines per physical resource, and the CPU pinning schema for comparison of virtual and physical machines. The two main findings from our experiments are that physical machines produced steadier and faster response times under heavy load and that the pinning schema is an important aspect when setting up a virtualized environment for load generation.}, 
keywords={program testing;software metrics;software performance evaluation;virtual machines;virtualisation;isolated computing environment;load generation;performance metrics;quality-of-service;software performance testing;virtual machines;virtualization;virtualized environment;Generators;Measurement;Servers;Testing;Throughput;Time factors;Virtual machining}, 
doi={10.1109/IPDPS.2011.244}, 
ISSN={1530-2075}, 
month={May},}
@INPROCEEDINGS{6119091, 
author={S. Tangadpalliwar and K. Sandrasegaran and M. Raymond and A. Moitra and F. Madani}, 
booktitle={2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing}, 
title={Benchmarking Embedded Devices for Broadband Performance Testing}, 
year={2011}, 
volume={}, 
number={}, 
pages={321-327}, 
abstract={Real time monitoring of broadband performance parameters is critical for estimating the user experience of new broadband services like VoIP, IPTV, Gaming and Video. This information is of interest to service providers themselves for efficient network design and maintenance and government regulatory bodies for analyzing ISPs, regions and national benchmarking. A web-based system TRUEE (Tool for Real-time User Experience Estimation) is a distributed system that incorporates independent modules such as standalone measurement devices installed at customer premises, data centers, test servers and web-clients for remote monitoring and management of the system. The focus of this paper is to discuss the process of benchmarking three commercial embedded devices with PC as reference device representing an end user system for accessing broadband services. This work is part of the ongoing development process of TRUEE. This benchmarking process is of significant importance for making an informed decision on the suitability of an embedded device capable of providing desired accuracy and consistency in estimation of the broadband performance parameters. Based on literature review, online forum reviews and cost analysis three devices based on ARM viz. SheevaPlug, Texas Instrument's BeagleBoard-xM and Gumstix Overo are selected for benchmarking. Results show that Marvell's SheevaPlug outperforms the other two devices in accurately measuring the broadband parameters on its network interface.}, 
keywords={Internet;benchmark testing;broadband networks;embedded systems;performance evaluation;ARM based device;Gumstix Overo;ISP analysis;Marvell SheevaPlug;TRUEE;Texas Instrument's BeagleBoard-xM;Web-based system;Web-clients;benchmarking embedded device;broadband performance parameter;broadband performance testing;broadband service;customer premises;data center;distributed system;end user system;government regulatory body;national benchmarking;network interface;real time monitoring;region benchmarking;remote monitoring;service provider;test servers;tool for real-time user experience estimation;Bandwidth;Benchmark testing;Broadband communication;Jitter;Linux;Performance evaluation;Throughput;Benchmarking;Broadband;Embedded device;Network Monitoring;Performance Testing}, 
doi={10.1109/DASC.2011.71}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{7819257, 
author={E. Siivola and S. Sierla and H. Niemistö and T. Karhela and V. Vyatkin}, 
booktitle={2016 IEEE 14th International Conference on Industrial Informatics (INDIN)}, 
title={Requirement verification in simulation-based automation testing}, 
year={2016}, 
volume={}, 
number={}, 
pages={740-743}, 
abstract={The emergence of the Industrial Internet results in an increasing number of complicated temporal interdependencies between automation systems and the processes to be controlled. There is a need for verification methods that scale better than formal verification methods and which are more exact than testing. Simulation-based runtime verification is proposed as such a method, and an application of Metric temporal logic is presented as a contribution. The practical scalability of the proposed approach is validated against a production process designed by an industrial partner, resulting in the discovery of requirement violations.}, 
keywords={Internet;automation;digital simulation;formal verification;production engineering computing;temporal logic;testing;formal verification;industrial Internet emergence;metric temporal logic;production process;requirement verification;simulation-based automation testing;simulation-based runtime verification;Automation;Leaching;Metals;Monitoring;Runtime;Slurries;Testing}, 
doi={10.1109/INDIN.2016.7819257}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{8250706, 
author={P. Seth and N. Rane and A. Wagh and A. Katade and S. Sahu and N. Malhotra}, 
booktitle={2017 International Conference on Intelligent Computing and Control Systems (ICICCS)}, 
title={Uberisation of mobile automation testing}, 
year={2017}, 
volume={}, 
number={}, 
pages={181-183}, 
abstract={Mobile phones and mobile applications have now become an essential part of everyday life. To make Mobile applications more reliable and error free, mobile application testing is important. Currently only a few techniques exist for creating automate tests of mobile applications and their functionality is very limited. In this paper, we introduce the new way of implementing a mobile test automation platform which performs mobile test automation from mobile devices itself. The main aim of automating the testing process is to develop a high quality and optimized applications to deliver efficient results to the customer.}, 
keywords={mobile computing;mobile handsets;program testing;Mobile phones;mobile application testing;mobile automation testing;mobile devices;mobile test automation platform;Androids;Automation;Mobile applications;Mobile communication;Mobile handsets;Testing;Tools;Device automation;Mobile app testing;Software Engineering;Software quality;Test Automation;Wireless testing}, 
doi={10.1109/ICCONS.2017.8250706}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{1625700, 
author={Bum Hyun Lim and Jin Ryong Kim and Kwang Hyun Shim}, 
booktitle={2006 8th International Conference Advanced Communication Technology}, 
title={A load testing architecture for networked virtual environment}, 
year={2006}, 
volume={1}, 
number={}, 
pages={5 pp.-848}, 
abstract={In this work, we develop a load testing architecture for networked virtual environment to reduce the testing time and ensure the stability of the server for distributed applications. It explicitly secures the stability of the server for networked virtual environment and at the same time, it elaborately generates actual loads for testing the performance of the server. Our agent based load testing architecture provides variety of interactions of virtual entities in the virtual worlds to perform realistic simulations. Simulation results show that our proposed architecture ensures the stability and capacity of the servers}, 
keywords={client-server systems;resource allocation;distributed applications;load testing architecture;networked virtual environment;server stability;virtual client;Analytical models;Databases;Discrete event simulation;Environmental management;Large-scale systems;Libraries;Network servers;Protocols;Testing;Virtual environment;Load test;beta test;game simulator;networked virtual environment;stress test;virtual client}, 
doi={10.1109/ICACT.2006.206095}, 
ISSN={}, 
month={Feb},}
@INPROCEEDINGS{5552290, 
author={D. Hao and Y. Chen and F. Tang and F. Qi}, 
booktitle={2010 IEEE International Conference on Software Engineering and Service Sciences}, 
title={Distributed agent-based performance testing framework on Web Services}, 
year={2010}, 
volume={}, 
number={}, 
pages={90-94}, 
abstract={Web Services are applied widely in the field of information technology, and performance testing for Web Services applications has become an important problem. This paper introduces the method of performance testing, and proposes a framework of agent-based performance testing on Web Services, which includes TestFlow Generator, Scenario Creator, Test Manager, Load Generation Agent and Test Analyzer. And the implementation of kernel modules in the framework is introduced especially. To realize the load allocation to distributed Load Generation Agents from Test Manager, a queue-based allocation strategy is given.}, 
keywords={Load modeling;Monitoring;Resource management;Schedules;Testing;Web services;Web Services;allocation strategy;load generation;performance testing}, 
doi={10.1109/ICSESS.2010.5552290}, 
ISSN={2327-0586}, 
month={July},}
@INPROCEEDINGS{7203126, 
author={Z. M. J. Jiang}, 
booktitle={2015 IEEE/ACM 37th IEEE International Conference on Software Engineering}, 
title={Load Testing Large-Scale Software Systems}, 
year={2015}, 
volume={2}, 
number={}, 
pages={955-956}, 
abstract={Large-scale software systems (e.g., Amazon and Dropbox) must be load tested to ensure that they can service thousands or millions of concurrent requests every day. In this technical briefing, we will describe the state of research and practices in the area of load testing. We will focus on the techniques used in the three phases of a load test: (1) designing a load test, (2) executing a load test, and (3) analyzing the results of a load test. This technical briefing is targeted at load testing practitioners and software engineering researchers interested in testing and analyzing the behavior of large-scale software systems.}, 
keywords={program testing;Amazon;Dropbox;large-scale software system load testing;Computer science;Conferences;Monitoring;Software engineering;Software systems;Testing;load testing;performance;scalability;software testing}, 
doi={10.1109/ICSE.2015.304}, 
ISSN={0270-5257}, 
month={May},}
@INPROCEEDINGS{5366326, 
author={Z. Liang and L. Jianhua and W. Ruofei and G. Xiaobin}, 
booktitle={2009 International Conference on Energy and Environment Technology}, 
title={Design of Performance Testing System for Train Air Conditioning}, 
year={2009}, 
volume={1}, 
number={}, 
pages={85-89}, 
abstract={The design of performance testing system for train air conditioning was done according to the NATIONAL STANDARD TB/T 1804-2003. The cooling capacity was measured by means of air enthalpy difference method. The hardware part of the test system consists of data collection unit and test instrument, while the software is programmed with Visual Basic 6.0, accompanied with the Microsoft Access database. The PLC unit and the touch screen are employed for local control of the system to achieve precise adjustment to the temperature and humidity of environmental chamber, the speed and flow of air. In view of the system characteristics of complex nonlinearity and being difficult to control exactly, test system adopts a fuzzy PID control based on plc to control experimental parameters such as temperature and humidity.}, 
keywords={Visual BASIC;air conditioning;computerised instrumentation;fuzzy control;programmable controllers;test equipment;three-term control;touch sensitive screens;visual programming;Microsoft Access database;National Standard TB/T 1804-2003;PLC unit;Visual Basic 6.0;air enthalpy difference method;cooling capacity;data collection unit;environmental chamber humidity;fuzzy PID control;performance testing system;programmable logic controller;test instrument;touch screen;train air conditioning;Air conditioning;Control systems;Cooling;Hardware;Humidity control;Nonlinear control systems;Programmable control;Software testing;System testing;Temperature control;data acquisition;fuzzy control;performance test system;train air conditioning}, 
doi={10.1109/ICEET.2009.27}, 
ISSN={}, 
month={Oct},}
@ARTICLE{4314840, 
author={P. D. Baxter and V. Lang and A. Anouchi}, 
journal={IEEE Transactions on Instrumentation and Measurement}, 
title={A Microprocessor-Based Positive Displacement Measurement System for Diesel Pump and Injector Performance Testing}, 
year={1979}, 
volume={28}, 
number={4}, 
pages={317-320}, 
abstract={New stringent emissions and economy requirements for the burgeoning diesel engine market have resulted in development of a new entirely digital microprocessor-based fuel delivery measurement system. The system uses a unique inherently digital transducer and a microprocessor for measurement and control.}, 
keywords={Diesel engines;Displacement measurement;Engine cylinders;Fluid flow measurement;Fuels;Maintenance;Pressure measurement;System testing;Transducers;Velocity measurement}, 
doi={10.1109/TIM.1979.4314840}, 
ISSN={0018-9456}, 
month={Dec},}
@ARTICLE{1377198, 
author={A. Avritzer and E. J. Weyuker}, 
journal={IEEE Transactions on Software Engineering}, 
title={The role of modeling in the performance testing of e-commerce applications}, 
year={2004}, 
volume={30}, 
number={12}, 
pages={1072-1083}, 
abstract={An e-commerce scalability case study is presented in which both traditional performance testing and performance modeling were used to help tune the application for high performance. This involved the creation of a system simulation model as well as the development of an approach for test case generation and execution. We describe our experience using a simulation model to help diagnose production system problems, and discuss ways that the effectiveness of performance testing efforts was improved by its use.}, 
keywords={Java;electronic commerce;program testing;resource allocation;software performance evaluation;e-commerce;production system diagnosis;software performance modeling;software performance testing;test case generation;workload characterization;Aerospace testing;Computer architecture;Databases;Helium;Java;Monitoring;Production systems;Scalability;Software testing;System testing}, 
doi={10.1109/TSE.2004.107}, 
ISSN={0098-5589}, 
month={Dec},}
@INPROCEEDINGS{6317675, 
author={C. Williamette and E. Hansen}, 
booktitle={2012 38th IEEE Photovoltaic Specialists Conference}, 
title={Development of electrical performance testing standards for the acceptance of solar photovoltaic projects based on field experience and observation}, 
year={2012}, 
volume={}, 
number={}, 
pages={000554-000559}, 
abstract={As-built performance requirements are becoming more common in Interconnection Applications (IAs) and Power Purchase Agreements (PPAs). Often overlooked as, “just the last step in the commissioning process,” it is important to understand the scope of the testing requirements before committing to the agreement. The worst case scenario is when your project has design flaws that prevent it from meeting requirements. By the time the system is discovered to be failing, it can be too late and too costly to fix. Understanding standards for performance testing can help guide project design to ensure better success meeting those requirements later on.}, 
keywords={commissioning;interconnections;photovoltaic power systems;solar power stations;standards;PPA;commissioning process;electrical performance testing standards;field experience;interconnection applications;power purchase agreements;solar PV systems;solar photovoltaic projects;Indexes;Inverters;Irrigation;Monitoring;Soil;Wiring;Current-voltage characteristics;Performance Analysis;Soil measurements;Solar energy;System analysis and design;Thermal analysis}, 
doi={10.1109/PVSC.2012.6317675}, 
ISSN={0160-8371}, 
month={June},}
@INPROCEEDINGS{5405721, 
author={G. h. Kim and H. c. Moon and G. P. Song and S. K. Shin}, 
booktitle={Proceedings of the 4th International Conference on Ubiquitous Information Technologies Applications}, 
title={Software Performance Testing Scheme Using Virtualization Technology}, 
year={2009}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={In this paper, we propose software performance testing scheme using virtualization technology. Generally, people have used software performance testing tool such as load runner and silk performer. However, people should perform software performance testing manually in case of the situation that people cannot use testing tool. It needs a lot of resources such as human resource and computing resource. Therefore, we propose software performance testing scheme using virtualization technology to reduce resource consumption. Proposed scheme can reduce computer resource consumption because virtualization technology can make a number of virtual computers with a small number of physical computers. Also proposed scheme can reduce human resource consumption because, in proposed scheme, management computer can control keyboard and mouse of virtual computers automatically. Simulation result shows that proposed scheme has possibility to be used for software performance testing.}, 
keywords={software performance evaluation;virtual machines;computer management;computing resource;human resource;software performance testing;virtual computers;virtualization technology;Automatic control;Computational modeling;Human resource management;Keyboards;Mice;Performance evaluation;Physics computing;Resource virtualization;Software performance;Software testing}, 
doi={10.1109/ICUT.2009.5405721}, 
ISSN={1976-0035}, 
month={Dec},}
@ARTICLE{4015510, 
author={D. Krishnamurthy and J. A. Rolia and S. Majumdar}, 
journal={IEEE Transactions on Software Engineering}, 
title={A Synthetic Workload Generation Technique for Stress Testing Session-Based Systems}, 
year={2006}, 
volume={32}, 
number={11}, 
pages={868-882}, 
abstract={Enterprise applications are often business critical but lack effective synthetic workload generation techniques to evaluate performance. These workloads are characterized by sessions of interdependent requests that often cause and exploit dynamically generated responses. Interrequest dependencies must be reflected in synthetic workloads for these systems to exercise application functions correctly. This poses significant challenges for automating the construction of representative synthetic workloads and manipulating workload characteristics for sensitivity analyses. This paper presents a technique to overcome these problems. Given request logs for a system under study, the technique automatically creates a synthetic workload that has specified characteristics and maintains the correct interrequest dependencies. The technique is demonstrated through a case study involving a TPC-W e-commerce system. Results show that incorrect performance results can be obtained by neglecting interrequest dependencies, thereby highlighting the value of our technique. The study also exploits our technique to investigate the impact of several workload characteristics on system performance. Results establish that high variability in the distributions of session length, session idle times, and request service times can cause increased contention among sessions, leading to poor system responsiveness. To the best of our knowledge, these are the first results of this kind for a session-based system. We believe our technique is of value for studies where fine control over workload is essential}, 
keywords={electronic commerce;performance evaluation;program testing;TPC-W e-commerce system;e-commerce system;enterprise application;performance evaluation;sensitivity analyses;stress testing session-based system;synthetic workload generation technique;Application software;Character generation;Computer Society;Delay;Occupational stress;Sensitivity analysis;Stress control;System performance;System testing;Web server;Internet applications;Performance of systems;Web servers.;electronic commerce;measurement techniques;modeling techniques;software engineering;testing tools}, 
doi={10.1109/TSE.2006.106}, 
ISSN={0098-5589}, 
month={Nov},}
@INPROCEEDINGS{6933530, 
author={G. H. Hwang and C. Wu-Lee and Y. H. Tung and C. J. Chuang and S. F. Wu}, 
booktitle={2014 IEEE 5th International Conference on Software Engineering and Service Science}, 
title={Implementing TaaS-based stress testing by MapReduce computing model}, 
year={2014}, 
volume={}, 
number={}, 
pages={137-140}, 
abstract={In this paper we propose to employ the MapReduce computing model to implement a Testing as a Service (TaaS) for stress testing. We focus on stress testing for heavy-weight network transactions. The computation power of MapReduce computing system is used to simulate concurrent network transactions issued by a lot of users. The user first describes the testing scenario which he wants to be simulate in a testing script. The TaaS platform analyzes the testing script and then automatically distributes required testing data including details of transactions and files into a MapReduce computing system. We propose three different schemes to distribute testing data and measure their performances. We compare them with the popular stress testing tool JMeter and find out that our scheme can always have the tested system deliver higher error rate during the stress testing.}, 
keywords={distributed programming;program testing;JMeter;MapReduce computing model;TaaS-based stress testing;testing as a service;Computational modeling;Computer crashes;Error analysis;Instruction sets;Servers;Stress;Hadoop;MapReduce;Stress testing}, 
doi={10.1109/ICSESS.2014.6933530}, 
ISSN={2327-0586}, 
month={June},}
@INPROCEEDINGS{8329877, 
author={J. Wienke and D. Wigand and N. Koster and S. Wrede}, 
booktitle={2018 Second IEEE International Conference on Robotic Computing (IRC)}, 
title={Model-Based Performance Testing for Robotics Software Components}, 
year={2018}, 
volume={}, 
number={}, 
pages={25-32}, 
abstract={In complex technical systems like robotics platforms, a manifold of issues can impair their dependability. While common testing and simulation methods largely focus on functional aspects, the utilization of resources like CPU, network bandwidth, or memory is only rarely tested systematically. With this contribution we propose a novel Domain-Specific Language (DSL) for modeling performance tests for individual robotics components with the aim to establish a systematic testing process for detecting regressions regarding the resource utilization. This DSL builds upon a testing framework from previous research and aims to significantly reduce the effort and complexity for creating performance tests. The DSL is built using the MPS language workbench and provides a feature-rich editor with modern editing aids. An evaluation indicates that developing performance tests requires only one third of the work in comparison to the original Java-based API.}, 
keywords={C language;control engineering computing;embedded systems;formal specification;object-oriented programming;product development;program diagnostics;public domain software;robots;specification languages;DSL;Domain-Specific Language;MPS language workbench;complex technical systems;editing aids;feature-rich editor;model-based performance tests;performance testing;resource utilization;robotics platforms;robotics software components;simulation methods;systematic testing process;DSL;Resource management;Robots;Software;Testing;Tools;Unified modeling language;CBSE;DSL;MPS;performance;performance testing;resource awareness;testing}, 
doi={10.1109/IRC.2018.00013}, 
ISSN={}, 
month={Jan},}
@INPROCEEDINGS{527964, 
author={D. Le and I. Karolik and R. Smith and A. J. Mcgovern and C. Curette and J. Ulbin and M. Zarubaiko and C. Henry and L. Stevens}, 
booktitle={Proceedings., International Test Conference}, 
title={Environmental Stress Testing with Boundary-Scan}, 
year={1994}, 
volume={}, 
number={}, 
pages={307-313}, 
abstract={Environmental Stress Testing (EST) enhances product quality and reliability by detecting latent or marginal defects in a product. For EST to be effective, testing of a product must achieve a high fault coverage so that as many EST-induced defects can be detected. By utilizing Boundary-Scan (IEEE Std 1149.1-1990), EST can achieve a high fault coverage and at the same time, minimize test cost. The paper describes a complete infrastructure, both software and hardware, for using Boundary-Scan (B-S) in EST. In addition, the paper shows a simplified control mechanism to select individual circuit packs for Boundary-Scan testing. This control mechanism minimizes the number of wires required to drive the control interface and thus, the number of wires in the cable that connects a tester to the backplane of a system under test and across which Boundary-Scan tests are executed. Finally, the paper presents and discusses some study results for evaluating the effectiveness of monitored EST}, 
keywords={IEEE standards;automatic testing;boundary scan testing;environmental stress screening;production testing;IEEE Std 1149.1;boundary scan testing;control;control interface;effectiveness;environmental stress testing;fault coverage;latent defects;marginal defects;product quality;reliability;test cost;Circuit faults;Circuit testing;Control systems;Costs;Electrical fault detection;Fault detection;Hardware;Stress;System testing;Wires}, 
doi={10.1109/TEST.1994.527964}, 
ISSN={1089-3539}, 
month={Oct},}
@INPROCEEDINGS{7397245, 
author={A. Ali and N. Badr}, 
booktitle={2015 IEEE Seventh International Conference on Intelligent Computing and Information Systems (ICICIS)}, 
title={Performance testing as a service for web applications}, 
year={2015}, 
volume={}, 
number={}, 
pages={356-361}, 
abstract={Software testing is a vital activity that is undertaken during software engineering life cycle to ensure software quality and reliability. Performance testing is a type of software testing that is done to shows how web application behaves under a certain workload. Cloud computing as an emerging technology can be used in the field of software engineering to provide cloud testing in order to overcome all deficiencies of conventional testing by leveraging cloud computing resources. As a result, testing-as-a-service (TaaS) is introduced as a service model that performs all testing activities in fully automated manner, on demand with a pay-for use basis. Moreover, TaaS increases testing efficiency and reduces time and cost required for testing. In this paper, performance TaaS framework for web applications is introduced which provides all performance testing activities including automatic test case generation and test execution. In addition, the proposed framework addresses many issues as: maximize resource utilization and continuous monitoring to ensure system reliability.}, 
keywords={Web services;program testing;software performance evaluation;software quality;Web applications;automatic test case generation;cloud computing resources;cloud testing;continuous monitoring;performance testing;software engineering life cycle;software quality;software reliability;software testing;system reliability;testing-as-a-service;Fault tolerance;Fault tolerant systems;Software;Testing;Virtualization;Cloud Computing;JMeter;Performance Testing;TaaS;web Application Testing}, 
doi={10.1109/IntelCIS.2015.7397245}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{284630, 
author={J. A. Jodice and S. Harpham}, 
booktitle={Developments in the Use of Global Positioning Systems}, 
title={`End-to-end transient simulation for protection system performance testing'}, 
year={1994}, 
volume={}, 
number={}, 
pages={6/1-6/5}, 
abstract={Formatted according to the new IEEE Standard C37.111, 1992 (COMTRADE), digital information describing power system disturbances controls a test system which produces transient simulation signals for analyzing protective relay performance. Global positioning system (GPS) satellite timing signals are used to synchronize two remotely located test systems for performing transient end-to-end simulation tests. DFR records of actual events and Electromagnetic Transient Program (EMTP) simulations of multiple fault events, played back through satellite-synchronized end-to-end test systems have proven comprehensive analytical tools-virtually eliminating the need for costly and dangerous staged fault tests generally performed at a limited number of locations}, 
keywords={digital simulation;electrical faults;power system analysis computing;power system protection;radionavigation;relay protection;satellite relay systems;software packages;synchronisation;Electromagnetic Transient Program;GPS;Global Positioning System;IEEE Standard C37.111;digital fault recorders;digital simulation;end-to-end simulation;multiple fault events;performance testing;power system disturbances;protective relay performance;satellite timing signals;synchronisation;transient simulation signals}, 
doi={}, 
ISSN={}, 
month={Feb},}
@INPROCEEDINGS{6008274, 
author={W. Xu and C. Lv}, 
booktitle={2011 2nd International Conference on Intelligent Control and Information Processing}, 
title={Research of virtual reality in industrial design manufacture and performance testing}, 
year={2011}, 
volume={1}, 
number={}, 
pages={403-405}, 
abstract={Virtual reality (VR) is a new method of visual operating and interacting of complex data can be realized by computers, in which one would have an immersed sense to observe and operate objects in three dimensions timely and unboundedly. VR is a new developing technique and a complex simulation tool for industry, it builds a simulated environment in which researchers can do many things such as driving, operating, designing and performance test in a unaffected way. Performance test plays an important role in vehicle design. Most of interactive processing in virtual vehicle manufacturing is perfect, but many deep interactive functions are under emphasis such as performance test after manufacturing, variation and recording of performance parameters. Research of VRML combining with JavaScript is presented in this paper, and vehicle designing and manufacturing, testing system are built based on it, in which we can real-time and dynamic control the car through keyboard and mouse, and get the real-time performance parameters.}, 
keywords={Java;automatic test software;automobile manufacture;performance evaluation;production engineering computing;virtual manufacturing;virtual reality languages;JavaScript;VRML;industrial design manufacture;interactive processing;performance testing;simulation tool;vehicle design;virtual reality;virtual vehicle manufacturing;visual interaction;Computational modeling;Shape}, 
doi={10.1109/ICICIP.2011.6008274}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{5456825, 
author={Xiao-yang Guo and Ying-hui Chen and Xue-song Qiu and Fan Tang}, 
booktitle={2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics (CAR 2010)}, 
title={Design and implementation of performance testing model for Web Services}, 
year={2010}, 
volume={1}, 
number={}, 
pages={353-356}, 
abstract={The performance testing model for Web Services is proposed. Aiming to enhance testing efficiency and automation, the model provides a multi-machine joint testing model and strategy model. The former is used to share the heavy load to multiple units, which could also be called load balance model, and the latter is used to simulate a realistic Web Services running environment. The model has been applied to an original web services testing software, and proved to be a feasible way for performance testing for web services.}, 
keywords={Web services;program testing;resource allocation;software performance evaluation;heavy load share;load balance model;multi-machine joint testing model;realistic Web services running environment;software performance testing model;Asia;Automatic control;Automatic testing;Informatics;Laboratories;Load modeling;Robotics and automation;Service oriented architecture;Software testing;Web services;load balance;multi-machine testing;performance testing;strategy model;web services}, 
doi={10.1109/CAR.2010.5456825}, 
ISSN={1948-3414}, 
month={March},}
@INPROCEEDINGS{5729579, 
author={R. W. Y. Habash and V. Groza and Y. Yang and C. Blouin and P. Guillemette}, 
booktitle={2011 Sixth IEEE International Symposium on Electronic Design, Test and Application}, 
title={Performance Testing and Control of a Small Wind Energy Converter}, 
year={2011}, 
volume={}, 
number={}, 
pages={263-268}, 
abstract={Responding to more demand in coming years, the task of the small wind energy industry requires progress on several fronts-from public policy initiatives, to technology development, to market growth. Enhanced technologies such as contra-rotating blades, transmission systems, lubrication, airfoils, generators, and power electronics will lower cost and increase energy production. This paper mainly considers two key technological points of a small wind energy converter (SWEC) namely, the performance of the rotor system and induction generator. Small-scale prototypes have been built to experimentally verify the performance of the SWEC. Wind tunnel tests of the power output, power coefficient, and turbine speed were carried out to ascertain the aerodynamic power conversion and the operation capability at lower wind speeds. The results demonstrated a significant increase in performance compared to a single-rotor system of the same type. Another aspect of development and test is to present a comparative performance evaluation between a standard induction generator and an efficient but with modified design (TRIAS Generator) as a realistic solution of clean power for grid-connected SWECs. The paper also discusses issues related to control and monitoring of SWEC.}, 
keywords={aerodynamics;asynchronous generators;power convertors;power generation control;power grids;power markets;rotors;wind power plants;wind tunnels;wind turbines;aerodynamic power conversion;grid connected SWEC;induction generator;market growth;performance testing;public policy;rotor system;small scale prototype;small wind energy converter control;technology development;wind energy industry;wind tunnel;Blades;Generators;Induction motors;Rotors;Wind energy;Wind speed;Wind turbines;Small wind generator;contra-rotating system;induction generator}, 
doi={10.1109/DELTA.2011.55}, 
ISSN={}, 
month={Jan},}
@ARTICLE{801951, 
author={P. K. Ghosh and L. G. Durante}, 
journal={IEEE Transactions on Power Systems}, 
title={Measurement performance testing for nonsinusoidal environments}, 
year={1999}, 
volume={14}, 
number={4}, 
pages={1526-1532}, 
abstract={A comparative study of the measurement accuracy capabilities of solid state watthour meters and other commercially available measurement instruments was performed. This study proposes a set of mathematically designed "waveforms" that could be used as a standard for the uniform, meaningful and reproducible evaluation testing of solid state watthour meters designed for use in nonsinusoidal environments. The test waveforms were theoretically developed based on an extensive database of field captured distorted waveforms that, in most cases, were monitored and recorded during power quality investigations over the last five years. Experimentation was performed using both the theoretically developed waveforms and the field captured waveforms.}, 
keywords={calibration;harmonic distortion;power measurement;power supply quality;power system harmonics;watthour meters;measurement accuracy;measurement instruments;measurement performance testing;nonsinusoidal supply environments;power quality;solid state watthour meters;Electric variables measurement;Guidelines;Harmonic distortion;Laboratories;Power system harmonics;Power systems;Semiconductor materials;Solid state circuits;Testing;Watthour meters}, 
doi={10.1109/59.801951}, 
ISSN={0885-8950}, 
month={Nov},}
@ARTICLE{4112302, 
author={R. E. Lee and M. T. Bishop}, 
journal={IEEE Transactions on Power Apparatus and Systems}, 
title={Performance Testing of the Ratio Ground Relay on a Four-Wire Distribution Feeder}, 
year={1983}, 
volume={PAS-102}, 
number={9}, 
pages={2943-2949}, 
abstract={Digital fault investigations on six Pennsylvania Power and Light 12 kV distribution feeders led to the development of a prototype Ratio Ground Relay to theoretically provide better detection of broken conductor faults. Further assessment of the relay's performance was provided through analog computer tests followed by staged fault testing on an operating distribution feeder. Performance tests are described and documented. These positive test results provided the incentive to monitor the performance of the Ratio Ground Relay on several PP&L distribution feeders.}, 
keywords={Analog computers;Circuit faults;Circuit testing;Conductors;Digital relays;Fault detection;Impedance;Performance evaluation;Power system relaying;Prototypes}, 
doi={10.1109/TPAS.1983.318145}, 
ISSN={0018-9510}, 
month={Sept},}
@ARTICLE{536458, 
author={D. Grossman and M. C. McCabe and C. Staton and B. Bailey and O. Frieder and D. C. Roberts}, 
journal={IEEE Software}, 
title={Performance testing a large finance application}, 
year={1996}, 
volume={13}, 
number={5}, 
pages={50-54}, 
abstract={The case study presented in the paper shows how a simple prototype can be used to verify, before production, that a system will perform at an acceptable level under realistic conditions. The study involves the first implementation of American Management System's Federal Financial System (FFS), a financial accounting application, in a customer information control system (CICS) DB2 environment running on a large IBM mainframe}, 
keywords={accounts data processing;financial data processing;program testing;program verification;relational databases;software performance evaluation;American Management System;DB2 environment;Federal Financial System;IBM mainframe;case study;customer information control system;financial accounting application;large finance application;performance testing;program verification;relational database;simple prototype;Control systems;Database systems;Delay;Environmental management;Finance;Financial management;Information technology;Operating systems;Performance evaluation;Production systems;Prototypes;Stress;System testing;Technology management;Testing}, 
doi={10.1109/52.536458}, 
ISSN={0740-7459}, 
month={Sep},}
@INPROCEEDINGS{6131250, 
author={S. Duttagupta and M. Nambiar}, 
booktitle={2011 UKSim 5th European Symposium on Computer Modeling and Simulation}, 
title={Performance Extrapolation for Load Testing Results of Mixture of Applications}, 
year={2011}, 
volume={}, 
number={}, 
pages={424-429}, 
abstract={Load testing of IT applications faces the challenge of providing high quality test results that would represent the performance in production like scenarios, without incurring high cost of commercial load testing tools. It would help IT projects to be able to test with a small number of users and extrapolate to scenarios with much larger number of users. Such an extrapolation strategy when applied to mixture of application workloads running on a shared server environment must take into consideration application characteristics (CPU/IO intensive, memory bound) as well the server capabilities. The goal is to predict the performance of mixture workload, the maximum throughput offered by the application mix and the maximum number of users supported by the system before the throughput starts degrading. In this paper, we propose an extrapolation strategy that analyses a system workload mix based on its service demand on various resources and extrapolates its performance using simple empirical modeling techniques. Moreover, its ability to extrapolate throughput of an application mixture even if there is a change in the mixture, can help in capacity planning of the system.}, 
keywords={extrapolation;program testing;IT application;application mixture;empirical modeling technique;extrapolation strategy;information technology;load testing;Extrapolation;Load modeling;Production;Servers;Telecommunications;Testing;Throughput;Extrapolation;S-curve;load Testing;mixture of applications;multi-classes of job}, 
doi={10.1109/EMS.2011.56}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6449887, 
author={M. Singh and R. Singh}, 
booktitle={2012 2nd IEEE International Conference on Parallel, Distributed and Grid Computing}, 
title={Load Testing of web frameworks}, 
year={2012}, 
volume={}, 
number={}, 
pages={592-596}, 
abstract={This document deals with a comparative analysis on the web frame works namely Spring3.0 MVC, Struts 2.0, JSF 1.2x and Wickets. A detailed study is given on the behavior of the frameworks when they are utilized in the front end and at the backend JPA is used to make communication with the database. The Database utilized is Oracle 10g. Load Testing of all the applications is done using J-meter.}, 
keywords={Internet;database management systems;online front-ends;program testing;J-meter;JSF 1.2x;Oracle 10g;Spring3.0 MVC;Struts 2.0;Web frameworks;Wickets;backend JPA;database;front end;load testing;Bandwidth;Color;Information filters;Process control;Springs;Throughput;JSF 1.2x;Spring3.0 MVC;Struts 2.0;Wickets and JPA}, 
doi={10.1109/PDGC.2012.6449887}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6927571, 
author={A. Freitas and R. Vieira}, 
booktitle={2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)}, 
title={An Ontology for Guiding Performance Testing}, 
year={2014}, 
volume={1}, 
number={}, 
pages={400-407}, 
abstract={Software test is a technique to obtain information about software systems quality. Performance test is a type of software test that aims at evaluating software performance at a given load scenario, but it requires specialized knowledge about tools, activities and metrics of the domain. Since ontology is a promising knowledge representation technique, this paper presents a literature review to identify trends and compare researches of ontologies in the fields of software testing and software performance. Also, to investigate this issue from a practical perspective, it was developed an ontology for representing the core knowledge of performance testing. This paper presents the ontology and compare it with related ones. Then, semantic technologies are explored to demonstrate the practical feasibility of developing ontology-based applications for assisting testers with performance test planning and management.}, 
keywords={ontologies (artificial intelligence);program testing;software management;software performance evaluation;software quality;knowledge representation technique;ontology;performance test management;performance test planning;performance testing guidance;semantic technologies;software performance evaluation;software systems quality;software testing;Measurement;OWL;Ontologies;Software performance;Software testing}, 
doi={10.1109/WI-IAT.2014.62}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{7066184, 
author={J. Li and Q. Li and T. Bi and H. Liu and K. Xu and F. Sun}, 
booktitle={2014 IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC)}, 
title={PMUs performance testing and evaluation in China}, 
year={2014}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Phasor measurement units (PMU) are taking an increasingly important role in power system dynamic security monitoring and control. However, traditional Discrete Fourier Transforms (DFT) used by PMUs cannot obtain accurate phasor measurements during frequency excursion and transient events, being limited by its static phasor model. Therefore, the performance of PMUs under both static and dynamic conditions is fundamental. In this paper, the averaging effect of DFT is explored, which results in the measurement errors of PMUs under dynamic conditions. Then, a PMU testing system is introduced. With that, a centralized test aiming to improve the performance of M-class PMUs in China is accomplished by evaluating the PMUs from seven manufactures in China under static and dynamic conditions. The testing results show that the PMUs under test can satisfy most requirements in the standard by improving their algorithms. The testing data is analyzed to demonstrate the correctness of the theoretical derivation of the averaging effect of DFT.}, 
keywords={discrete Fourier transforms;phasor measurement;power system control;power system security;China;DFT;M-class PMU measurement error;PMU performance evaluation;discrete Fourier transform;frequency excursion;phasor measurement unit performance testing;power system dynamic control;power system dynamic security monitoring;static phasor model;Discrete Fourier transforms;Frequency measurement;Phasor measurement units;Power system dynamics;Standards;Testing;Time measurement;Discrete Fourier transforms (DFT);dynamic phasor algorithm;phasor measurement units (PMU);power system measurements;power system transients}, 
doi={10.1109/APPEEC.2014.7066184}, 
ISSN={2157-4839}, 
month={Dec},}
@INPROCEEDINGS{7015753, 
author={P. Bot and C. Vatamanu and D. Gavrilut and R. M. Benchea}, 
booktitle={2014 Second Workshop on Anti-malware Testing Research (WATeR)}, 
title={Performance testing framework: Evaluating the impact on the system speed}, 
year={2014}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={The world we live in now is defined by the word “speed” and any device, technology, or system that doesn't keep up is rejected or replaced immediately. Because of this, one of the biggest concerns today is “optimization”. Its purpose is to reduce the impact on the user's device. The Anti-Virus industry is also confronting with this challenge. Although the first concern is to keep the user safe, providing a flawless protection, it is crucial to reduce the impact brought on the user's system, preventing him to disable or uninstall the AV solution and thus remaining unprotected. The increased number of malware types/families as well as their complexity generated the need for complicated detection methods, which means a constant evaluation is needed. Because of these reasons, our antimalware laboratory has developed a generic framework for measuring the impact that the AV solutions have on the system they are installed on. This system was designed to be easily configurable, managing the big number of changes that occur every day and fast so that every update released to the users can be tested. Also, this framework is used to test and develop new technologies that improve the performance of our AV product.}, 
keywords={DP industry;data protection;invasive software;program testing;software performance evaluation;AV solution;antivirus industry;flawless protection;malware type;performance testing framework;system speed impact;Computers;Databases;Gold;Laboratories;Operating systems;Servers;generic framework;impact;performance;user interaction}, 
doi={10.1109/WATeR.2014.7015753}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{8203630, 
author={H. Khandelwal and P. Mankodi and R. Prajapati}, 
booktitle={2017 International conference of Electronics, Communication and Aerospace Technology (ICECA)}, 
title={Enhancement of automation testing system using Yocto project}, 
year={2017}, 
volume={1}, 
number={}, 
pages={697-700}, 
abstract={Nowadays, in industries, Testing has become one of the important tasks. Testing is necessary for an effective performance of product and software applications. When companies having a mass production of hardware boards, it is necessary to do testing of each and every module of hardware like SPI, UART, GPIO, PWM, ADC, USB, Ethernet. If we do testing manually then it will significantly take more time, which we can be reduced by automation testing. But the solution is not an automation testing because automation testing also requires the same amount of system, for example for 300 boards 300 system is required. The only difference in manual and automation testing is that in automation testing it will require less human effort. Now we are focusing more on developing a solution in which many tests can be done on one single system i.e. for 300 boards only one system is required for testing hence this problem can be solved by Yocto Project. Yocto project have build the tool named Bitbake which is written in Python language, which works on multithreading and scheduling so that simultaneously you can test more boards on a single system. In this paper we did automation testing of GPIO pins using Yocto project.}, 
keywords={automatic test software;Bitbake tool;GPIO pins;Python language;Yocto Project;automation testing system;multithreading;scheduling;Automation;Hardware;Licenses;Pins;Software;Testing;Tools;Automation;Bitbake;Open embedded;Yocto project}, 
doi={10.1109/ICECA.2017.8203630}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{883774, 
author={B. M. Subraya and S. V. Subrahmanya}, 
booktitle={Proceedings First Asia-Pacific Conference on Quality Software}, 
title={Object driven performance testing of Web applications}, 
year={2000}, 
volume={}, 
number={}, 
pages={17-26}, 
abstract={Performance of many Web sites depends on the load on the site at peak time under varying conditions. Performance testing is normally conducted in reasonably simulated environment with the help of performance testing tools. However, performance of a Web site depends on various parameters and each parameter must be tested under varying stress levels. It is not possible to draw a common denominator for performance parameters to test the Web site due to complexity of Web sites. Different parts of the Web site must be tested with different parameters under varying condition and stress level. In such circumstances, it is necessary to decompose the Web site into many components, which represents the behavior of various business components. These business components are mapped to various objects that truly represent the behavior and structure of the part of the web site. These objects are subjected to performance testing with different parameters and stress levels. This paper addresses the new testing process, which uses the concept of decomposing the behavior of the Web site into testable components, which are mapped onto testable objects. These testable objects are subjected to performance testing under varied performance parameters and stress levels}, 
keywords={computational complexity;information resources;program testing;programming environments;software performance evaluation;Web applications;Web sites;complexity;object driven performance testing;performance parameters;simulated environment;Acoustic testing;Application software;Cities and towns;Consumer electronics;Electronic commerce;Life testing;Software testing;Stress;System testing;Time to market}, 
doi={10.1109/APAQ.2000.883774}, 
ISSN={}, 
month={},}
@ARTICLE{945309, 
author={R. Pendurkar and A. Chatterjee and Y. Zorian}, 
journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
title={Switching activity generation with automated BIST synthesis for performance testing of interconnects}, 
year={2001}, 
volume={20}, 
number={9}, 
pages={1143-1158}, 
abstract={A novel scheme of synthesizing nonlinear feedback shift register structures that can be superimposed on the boundary of the component of a system under test to generate interconnect switching activities that resemble real life interconnect switching profiles is proposed. The goal is to perform at-speed interconnect test while simultaneously capturing the dynamic switching effects such as crosstalk and ground bounce, as accurately as possible during interconnect built-in self-test. A library of nonlinear feedback shift register structures called precharacterized test pattern generators (P-TPGs) is constructed. Components of P-TPGs can be modeled using Markov chain and can be interconnected together in specific ways to recreate the switching activity profile of the interconnections being tested. The unique advantage of this scheme is that there is no simulation overhead since P-TPG components are precharacterized by solving Markov equations analytically. An integrated genetic algorithm-based search and optimization technique for finding the best P-TPG component among various possible implementations and matching its activity profiles with those of the interconnections under test has been designed and implemented synthesis for testability allows generation of the worst case interconnect switching activities. Experimental results confirm the validity of our approach}, 
keywords={Markov processes;automatic testing;built-in self test;crosstalk;design for testability;genetic algorithms;integrated circuit interconnections;integrated circuit testing;shift registers;Markov chain;automated BIST synthesis;crosstalk;design for testability;genetic algorithm;ground bounce;interconnect performance testing;nonlinear feedback shift register;precharacterized test pattern generator;search optimization;switching activity;Automatic testing;Built-in self-test;Crosstalk;Feedback;Libraries;Life testing;Nonlinear dynamical systems;Performance evaluation;Shift registers;System testing}, 
doi={10.1109/43.945309}, 
ISSN={0278-0070}, 
month={Sep},}
@INPROCEEDINGS{6354629, 
author={N. Baltas and T. Field}, 
booktitle={2012 Ninth International Conference on Quantitative Evaluation of Systems}, 
title={Continuous Performance Testing in Virtual Time}, 
year={2012}, 
volume={}, 
number={}, 
pages={13-22}, 
abstract={In this paper we show how program code and performance models can be made to cooperate seamlessly to support continuous software performance testing throughout the development lifecycle. We achieve this by extending our existing VEX tool for executing programs in virtual time so that events that occur during normal execution and those that occur during the simulation of a performance model can be scheduled on a single global virtual time line. The execution time of an incomplete component of an application is thus estimated by a performance model, whilst that of existing code is measured by instrumentation that is added dynamically at program load time. A key challenge is to be able to map some or all of the resources in a performance model to the real resources of the host platform on which the application is running. We outline a continuous performance engineering methodology that exploits our unified framework and illustrate the principles involved byway of a simple Java application development case study.}, 
keywords={Java;program testing;software performance evaluation;software tools;Java application development;VEX tool;continuous performance engineering methodology;continuous software performance testing;development lifecycle;performance model;program code;program execution;program load time;virtual time;Computational modeling;Instruction sets;Java;Predictive models;Real-time systems;Resumes;Schedules;Modelling Queueing networks;Software Performance;Virtual execution}, 
doi={10.1109/QEST.2012.26}, 
ISSN={}, 
month={Sept},}