@article{20164302941951 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {WESSBAS: extraction of probabilistic workload specifications for load testing and performance predictiona model-driven approach for session-based application systems},
journal = {Software and Systems Modeling},
author = {Vogele, Christian and van Hoorn, Andre and Schulz, Eike and Hasselbring, Wilhelm and Krcmar, Helmut},
volume = {17},
number = {2},
year = {2018},
pages = {443 - 477},
issn = {16191366},
abstract = {The specification of workloads is required in order to evaluate performance characteristics of application systems using load testing and model-based performance prediction. Defining workload specifications that represent the real workload as accurately as possible is one of the biggest challenges in both areas. To overcome this challenge, this paper presents an approach that aims to automate the extraction and transformation of workload specifications for load testing and model-based performance prediction of session-based application systems. The approach (WESSBAS) comprises three main components. First, a system- and tool-agnostic domain-specific language (DSL) allows the layered modeling of workload specifications of session-based systems. Second, instances of this DSL are automatically extracted from recorded session logs of production systems. Third, these instances are transformed into executable workload specifications of load generation tools and model-based performance evaluation tools. We present transformations to the common load testing tool Apache JMeter and to the Palladio Component Model. Our approach is evaluated using the industry-standard benchmark SPECjEnterprise2010 and the World Cup 1998 access logs. Workload-specific characteristics (e.g., session lengths and arrival rates) and performance characteristics (e.g., response times and CPU utilizations) show that the extracted workloads match the measured workloads with high accuracy.<br/> &copy; 2016, The Author(s).},
key = {Load testing},
keywords = {Computer programming languages;Extraction;Forecasting;Modeling languages;Problem oriented languages;Specifications;},
note = {Domain specific languages;Industry-standard benchmarks;Model driven approach;Performance characteristics;Performance evaluation tools;Performance Model;Performance prediction;Testing and modeling;},
URL = {http://dx.doi.org/10.1007/s10270-016-0566-5},
} 


@inproceedings{20171903655033 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {AutoPerf: Automated load testing and resource usage profiling of multi-tier internet applications},
journal = {ICPE 2017 - Proceedings of the 2017 ACM/SPEC International Conference on Performance Engineering},
author = {Apte, Varsha and Viswanath, T.V.S. and Gawali, Devidas and Kommireddy, Akhilesh and Gupta, Anshul},
year = {2017},
pages = {115 - 126},
address = {L'Aquila, Italy},
abstract = {A multi-tier Internet server application needs to be analyzed for its performance before it is released. Performance analysis is usually done by (a) load testing of the application on a testbed and (b) building a performance model of the application. While there are a plethora of Web load-generator tools available, there are two problems with these tools: one, the tests have to be configured manually, which can lead to a time-consuming trial-and-error process until the desired performance charts in the appropriate load ranges are obtained; and two, the load generator tools do not produce output that is directly useful for creating a performance model of the application. In this paper, we present AutoPerf, a load generator tool designed to meet two distinct goals, named capacity analysis and profiling. The goal of capacity analysis is to run a comprehensive load test on a Web application, in an appropriately chosen range, at a minimal number of load levels, while still producing an accurate graph of throughput and response time vs load levels. The goal of profiling is to generate a detailed server resource usage profile per request type, without instrumenting the application code. This data (e.g. CPU execution time by Web server for one request) is crucial for parameterizing performance models of the application. AutoPerf intelligently plans and configures its load tests by using analytical results from queuing theory along with some heuristics. Results show that AutoPerf is able to run performance tests very efficiently while still producing an accurate chart of performance metrics. &copy; 2017 ACM.},
key = {Load testing},
keywords = {Queueing theory;},
note = {Capacity analysis;Comprehensive loads;Multi-tier internets;Performance;Performance analysis;Performance metrics;Profilers;Trial-and-error process;},
URL = {http://dx.doi.org/10.1145/3030207.3030222},
} 


@article{20174304293205 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Application and performance test of a small aerosol sensor for the measurement of aerosolized DNA strands},
journal = {Aerosol and Air Quality Research},
author = {Yang, Wenming and Zhu, Rong and Zhang, Chao and Li, Zheng},
volume = {17},
number = {10},
year = {2017},
pages = {2358 - 2366},
issn = {16808584},
abstract = {There is an immediate need for aerosol measuring sensors to monitor the size and concentration of DNA strand aerosols in PCR systems. We evaluate the performance of a previously developed small aerosol sensor for its potential use as a component in measuring DNA strand aerosols in PCR system chambers. A detailed derivation of the working principle is presented along with the principles used to determine the dimensions of the stages and the operational parameters. After characterizing the aerosolized DNA strands, experiments were conducted to identify their relationship with measured currents. The experimental results indicate that for aerosolized Escherichia coli DNA strands, the sensor is capable of measuring concentrations from 10<sup>2</sup>cm<sup>&ndash;3</sup>to 10<sup>5</sup>cm<sup>&ndash;3</sup>(from 10<sup>3</sup>cm<sup>&ndash;3</sup>to 10<sup>5</sup>cm<sup>&ndash;3</sup>for particles smaller than 102 nm) and sizes from 100 bp to 1000 bp. There was a slight difference between the results of the sensor and its theoretical model. The sensor exhibited good sensitivity to different concentrations and can detect every 150 bp of strands, indicating its effectiveness in monitoring ultrafine DNA strand aerosols for PCR systems and other applications. &copy; Taiwan Association for Aerosol Research.},
key = {Polymerase chain reaction},
keywords = {Aerosols;DNA;Escherichia coli;},
note = {Aerosol measurement;DNA strands;Measured currents;Operational parameters;Performance tests;Theoretical modeling;Ultrafine;},
URL = {http://dx.doi.org/10.4209/aaqr.2017.01.0054},
} 


@inproceedings{20172103685017 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling expands value of performance testing for big data applications},
journal = {ICPE 2017 - Companion of the 2017 ACM/SPEC International Conference on Performance Engineering},
author = {Zibitsker, Boris and Lupersolsky, Alex},
year = {2017},
pages = {119 - 123},
address = {L'Aquila, Italy},
abstract = {Performance testing of Big Data applications is performed typically on small test environment with limited volume of data. The results of these types of tests do not take into consideration differences between test and production hardware and software environment and contention for resources with many applications in production environments. In this paper we will review application of the modeling for extending the results of performance testing, predicting how new application will perform in production environment. We will review how modeling results can be used to evaluate different options and justify decisions during design, development, implementation and performance management of the production environment. &copy; 2017 ACM.},
key = {Big data},
keywords = {Application programs;Benchmarking;Software testing;},
note = {Big data applications;Data infrastructure;Performance assurances;Performance engineering;Performance Model;Performance prediction;Performance testing;},
URL = {http://dx.doi.org/10.1145/3053600.3053624},
} 


@article{20174004236999 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Empirical study on the discrepancy between performance testing results from virtual and physical environments},
journal = {Empirical Software Engineering},
author = {Arif, Muhammad Moiz and Shang, Weiyi and Shihab, Emad},
year = {2017},
pages = {1 - 29},
issn = {13823256},
abstract = {Large software systems often undergo performance tests to ensure their capability to handle expected loads. These performance tests often consume large amounts of computing resources and time since heavy loads need to be generated. Making it worse, the ever evolving field requires frequent updates to the performance testing environment. In practice, virtual machines (VMs) are widely exploited to provide flexible and less costly environments for performance tests. However, the use of VMs may introduce confounding overhead (e.g., a higher than expected memory utilization with unstable I/O traffic) to the testing environment and lead to unrealistic performance testing results. Yet, little research has studied the impact on test results of using VMs in performance testing activities. To evaluate the discrepancy between the performance testing results from virtual and physical environments, we perform a case study on two open source systems &ndash; namely Dell DVD Store (DS2) and CloudStore. We conduct the same performance tests in both virtual and physical environments and compare the performance testing results based on the three aspects that are typically examined for performance testing results: 1) single performance metric (e.g. CPU Time from virtual environment vs. CPU Time from physical environment), 2) the relationship among performance metrics (e.g. correlation between CPU and I/O) and 3) performance models that are built to predict system performance. Our results show that 1) A single metric from virtual and physical environments do not follow the same distribution, hence practitioners cannot simply use a scaling factor to compare the performance between environments, 2) correlations among performance metrics in virtual environments are different from those in physical environments 3) statistical models built based on the performance metrics from virtual environments are different from the models built from physical environments suggesting that practitioners cannot use the performance testing results across virtual and physical environments. In order to assist the practitioners leverage performance testing results in both environments, we investigate ways to reduce the discrepancy. We find that such discrepancy can be reduced by normalizing performance metrics based on deviance. Overall, we suggest that practitioners should not use the performance testing results from virtual environment with the simple assumption of straightforward performance overhead. Instead, practitioners should consider leveraging normalization techniques to reduce the discrepancy before examining performance testing results from virtual and physical environments. &copy; 2017 Springer Science+Business Media, LLC},
key = {Software testing},
keywords = {Open source software;Open systems;Virtual reality;},
note = {Large software systems;Performance metrices;Performance metrics;Performance testing;Physical environments;Software performance;Software performance engineerings;Testing environment;},
URL = {http://dx.doi.org/10.1007/s10664-017-9553-x},
} 


@article{20174404356082 ,
language = {Japanese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Development of exterior wall framework system  result of following performance test for relative story displacement},
journal = {AIJ Journal of Technology and Design},
author = {Hashizume, Keisuke and Iijima, Kazushige and Ueda, Toshihide},
volume = {23},
number = {55},
year = {2017},
pages = {777 - 782},
issn = {13419463},
abstract = {The unique exterior wall framework system, using the unique shaped transoms and the fastener was developed to have a high following performance for relative story displacement. This system will make it possible to construct various walls corresponding to diversity of design and ensure safety for earthquake at the same time.},
key = {Technology},
note = {Exterior walls;Performance tests;Surface elements;},
URL = {http://dx.doi.org/10.3130/aijt.23.777},
} 


@inproceedings{20171703591122 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {PHOEBE: an automation framework for the effective usage of diagnosis tools in the performance testing of clustered systems},
journal = {Software - Practice and Experience},
author = {Portillo-Dominguez, A. Omar and Perry, Philip and Magoni, Damien and Murphy, John},
volume = {47},
number = {11},
year = {2017},
pages = {1837 - 1874},
issn = {00380644},
abstract = {The identification of performance issues and the diagnosis of their root causes are time-consuming and complex tasks, especially in clustered environments. To simplify these tasks, researchers have been developing tools with built-in expertise for practitioners. However, various limitations exist in these tools that prevent their efficient usage in the performance testing of clusters (e.g. the need of manually analysing huge volumes of distributed results). In a previous work, we introduced a policy-based adaptive framework (PHOEBE) that automates the usage of diagnosis tools in the performance testing of clustered systems, in order to improve a tester's productivity, by decreasing the effort and expertise needed to effectively use such tools. This paper extends that work by broadening the set of policies available in PHOEBE, as well as by performing a comprehensive assessment of PHOEBE in terms of its benefits, costs and generality (with respect to the used diagnosis tool). The performed evaluation involved a set of experiments in assessing the different trade-offs commonly experienced by a tester when using a performance diagnosis tool, as well as the time savings that PHOEBE can bring to the performance testing and analysis processes. Our results have shown that PHOEBE can drastically reduce the effort required by a tester to do performance testing and analysis in a cluster. PHOEBE also exhibited consistent behaviour (i.e. similar time-savings and resource utilisations), when applied to a set of commonly used diagnosis tools, demonstrating its generality. Finally, PHOEBE proved to be capable of simplifying the configuration of a diagnosis tool. This was achieved by addressing the identified trade-offs without the need for manual intervention from the tester. Copyright &copy; 2017 John Wiley &amp; Sons, Ltd. Copyright &copy; 2017 John Wiley & Sons, Ltd.},
key = {Cluster computing},
keywords = {Commerce;Economic and social effects;},
note = {Adaptive framework;Comprehensive assessment;Manual intervention;Performance analysis;Performance diagnosis;Performance issues;Performance testing;System performance;},
URL = {http://dx.doi.org/10.1002/spe.2500},
} 


@article{20172803930321 ,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and performance testing of production performance determination system for boar},
journal = {Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering},
author = {Xiong, Benhai and Jiang, Linshu and Yang, Liang and Pan, Xiaohua},
volume = {33},
number = {9},
year = {2017},
pages = {174 - 179},
issn = {10026819},
abstract = {In order to monitor feeding behavior of sows and further attain the sow's precise feeding, an intelligent production performance testing system was designed in this study, which played functions in sows' automatic identification, body weight perception, automatic feeding data acquisition and data analysis simultaneously. The system was composed of electric ear tag identification module, precise feed flow control module, feed trough and boar weighing module, data communication and remote control module. The mechanical device system was constituted of feeding bin, brackets, railing and blocking apron. The mechanical device system was constituted of feeder's vertical wall, weighting platform, flapper, feed loading device, feed bin, control box, switch of discharge and ear tag recognizer. Electronic control systems included microprocessor (LPC1766, ARM Cortex-M3, Working temperature -40-105&#8451;, Operating voltage 2.0-3.6 V, flash 256 K, low power consumption et al.), RS232 reader port, data storage chip (the default storage capacity is 256 KB), circuit of watchdog, weighing circuit, exterior-drivers circuit, JTAG connector circuit and stabilivolt source circuit. Among above, the sensor used for pigs weighing was Delux ADS1232 which had 2 rate options, 10 times per second and 80 times per second, with high precision and large range of features. The performance testing experiment revealed that: 1) the system's precision meets the monitoring requirement of sow production performance. The discharge rate of feeder depended on the level of feed in stock bin, and the average amount of unloading feed was 93&plusmn;2 g at one time; the range of pig weighing was 0-200 kg with the precision error below 10 g, and the dynamic weighing error was below 0.5% of pig's weight. 2) The feeding behavior monitor for 40 gilts (25-60 kg) showed that the frequency of free feed intake was 10-12 times per day, the average feed time was 78 min, the feed conversion ratio was 2.33:1, and their weight gain was converged to the Gompertz curves (e.g. W<inf>t</inf>=172.1exp(-4.0187exp(-0.0122*t)), W<inf>t</inf>means body weight, kg; t means day old, day), the predicted decreasing daily weight gain of growing pigs by Gompertz curve occurred at day 111-117, with corresponding inflection point weight in the range of 63-64 kg. The observed and predicted results above could precisely determine the growth performance, indicating that the software systems and hardware devices could satisfy the requirement of growth performance determination in sows. 3) The wiper motor rather than early stepping motor was used in feed discharging control system, which reduced the cost of production. In addition, the combined wiper motor with cylindrical scraper structure decreased the discharge rate of feeder and improved the precision of unloading control system. 4) The core chip in control system was imported, multi-redundant, and protection systems were applied in circuit design. Multiply functional verification was adopted in software writing. The redundancy design in software and hardware eliminated the interference of power, electrical machine and electromagnetic wave, and improved the systems' reliability and stability. 5) The collected data could be saved or transferred, which facilitates the accumulation of pig production, data mining and sow breeding. &copy; 2017, Editorial Department of the Transactions of the Chinese Society of Agricultural Engineering. All right reserved.},
key = {Identification (control systems)},
keywords = {Anthropometry;Automation;Bins;Control systems;Data acquisition;Digital storage;Electric discharges;Electromagnetic waves;Feeding;Hardware;Integrated circuit manufacture;Mammals;Models;Printed circuit design;Redundancy;Software reliability;Software testing;Unloading;Verification;Weighing;},
note = {Automatic identification;Boar;Data collection;Electronic control systems;Functional verification;Performance measurements;Production performance;Reliability and stability;},
URL = {http://dx.doi.org/10.11975/j.issn.1002-6819.2017.09.022},
} 


@inproceedings{20181104908213 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {VST: A virtual stress testing framework for discovering bugs in SSD flash-translation layers},
journal = {IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD},
author = {Liu, Ren-Shuo and Chang, Yun-Sheng and Hung, Chih-Wen},
volume = {2017-November},
year = {2017},
pages = {283 - 290},
issn = {10923152},
address = {Irvine, CA, United states},
abstract = {Flash translation layers (FTLs) are the core embedded software (also known as firmware) of NAND flash-based solid-state drives (SSDs). The relentless pursuit of high-performance SSDs renders FTLs increasingly complex and intricate. Therefore, testing and validating FTLs are crucial and challenging tasks. Directly testing and validating FTLs on SSD hardware are common practices though, they are time-consuming and cumbersome because 1) the testing speed is limited by the hardware speed of SSDs and 2) just reproducing bugs can be challenging, let alone locating and root causing the bugs. This work presents virtual stress testing (VST), a simulation framework to enable executing SSD FTLs on PCs or servers against virtual SRAM, DRAM, and flash emulated by host-side main memory. FTL function calls, such as moving data from flash to DRAM, are served by the VST framework. Therefore, VST can test FTLs without SSD hardware requirements nor SSD speed limitations, and root causing bugs becomes manageable tasks. We apply VST to representative SSD design, OpenSSD, which is actively utilized and maintained by SSD and FTL communities. Experimental results show that VST can test FTLs at a speed up to 375 GB/s, which is several hundred times faster than directly testing FTLs on SSD hardware. Moreover, we successfully discover seven new FTL bugs in the OpenSSD design using VST, which is a solid evidence of VST's bug-discovering effectiveness.<br/> &copy; 2017 IEEE.},
key = {Flash-based SSDs},
keywords = {Computer aided design;Computer hardware;Computer software;Data storage equipment;Digital storage;Dynamic random access storage;Embedded software;Embedded systems;Firmware;Flash memory;Hardware;Integrated circuit design;Program debugging;Software testing;Static random access storage;},
note = {Common practices;Data storage systems;Disk drive;Flash translation layer;Function calls;Simulation framework;Software debugging;Systems simulation;},
URL = {http://dx.doi.org/10.1109/ICCAD.2017.8203790},
} 


@inproceedings{20171603585111 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Directed automated memory performance testing},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Chattopadhyay, Sudipta},
volume = {10206 LNCS},
year = {2017},
pages = {38 - 55},
issn = {03029743},
address = {Uppsala, Sweden},
abstract = {Understanding software non-functional properties (e.g. time, energy and security) requires deep understanding of the execution platform. The design of caches plays a crucial role in impacting software performance (for low latency of caches) and software security (for cache being used as a side channel). We present CATAPULT, a novel test generation framework to systematically explore the cache behaviour of an arbitrary program. Our framework leverages dynamic symbolic execution and satisfiability modulo theory (SMT) solvers for generating test inputs. We show the application of CATAPULT in testing timing-related properties and testing cache side-channel vulnerabilities in several open-source programs, including applications from OpenSSL and Linux GDK libraries. &copy; Springer-Verlag GmbH Germany 2017.},
key = {Software testing},
keywords = {Application programs;Computer operating systems;Open source software;},
note = {Dynamic symbolic executions;Execution platforms;Memory performance;Non functional properties;Open source projects;Satisfiability modulo Theories;Software performance;Software security;},
URL = {http://dx.doi.org/10.1007/978-3-662-54580-5_3},
} 


@article{20173804193684 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Rational decision framework for designing pile-load test programs},
journal = {Geotechnical Testing Journal},
author = {Najjar, S. and Saad, G. and Abdallah, Y.},
volume = {40},
number = {2},
year = {2017},
pages = {302 - 316},
issn = {01496115},
abstract = {There is currently an inconsistency in the recommendations that are available in pile-design codes and practices regarding the required number of proof-load tests and the level of the proof loads for piles. In this paper, a pre-posterior decision-making framework is proposed to allow for selecting the optimal pile-load test program that would result in the maximum expected benefit to a project, while maintaining a target level of reliability in the pile design at the site. This proposed methodology is original, practical, and is based on site-specific information that is unique to any given project. The proposed methodology is based on a robust Bayesian approach that allows for updating the capacity distribution of piles at a site, given the results of the proof-load test program. The efficiency of the proposed decision framework is demonstrated by applying it on a practical design example that involves piles that are driven in a site consisting of medium-dense sand. Results indicate that: (1) the optimum proof-load level that results in the maximum benefit to the example project is 1.5 times the design load, (2) the optimum number of tests is a function of the number of piles (superstructure load) and the costs of the pile construction and testing, (3) as the number of piles in the site increases, the optimal required number of proof-load tests also increase, with the optimum number of pile-load tests being around 1 % to 2 % of the total number of piles at the site, and (4) the optimal number of pile-load tests increases as the cost of pile construction and installation increases and as the cost of implementing the pile test program decreases. Copyright &copy; 2017 by ASTM International.},
key = {Piles},
keywords = {Bayesian networks;Costs;Decision making;Decision theory;Load testing;Reliability;Reliability analysis;Software testing;Statistical tests;Test facilities;Testing;},
note = {Bayesian approaches;Capacity distribution;Decision framework;Decision-making frameworks;Deep foundations;Field testing;Pile test program;Site-specific information;},
URL = {http://dx.doi.org/10.1520/GTJ20160088},
} 


@inproceedings{20152701007652 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {PLeTsPerf - A Model-Based Performance Testing Tool},
journal = {2015 IEEE 8th International Conference on Software Testing, Verification and Validation, ICST 2015 - Proceedings},
author = {Rodrigues, Elder and Bernardino, Maicon and Costa, Leandro and Zorzo, Avelino and Oliveira, Flavio},
year = {2015},
pages = {Graz University of Technology (TU Graz); IEEE Computer Society - },
address = {Graz, Austria},
abstract = {Performance testing is a highly specialized task, since it requires that a performance engineer knows the application to be tested, its usage profile, and the infrastructure where it will execute. Moreover, it requires that testing teams expend a considerable effort and time on its automation. In this paper, we present the PLeTsPerf, a model-based performance testing tool to support the automatic generation of scenarios and scripts from application models. PLetsPerf is a mature tool, developed in collaboration with an IT company, which has been used in several works, experimental studies and pilot studies. We present an example of use to demonstrate the process of generating test scripts and scenarios from UML models to test a Web application. We also present the lessons learned and discuss our conclusions about the use of the tool. &copy; 2015 IEEE.},
key = {Software testing},
keywords = {Model checking;Unified Modeling Language;Verification;},
note = {Application models;Automatic Generation;Model based testing;Model-based OPC;Performance testing;Pilot studies;Testing tools;WEB application;},
URL = {http://dx.doi.org/10.1109/ICST.2015.7102628},
} 


@inproceedings{20164102888346 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A search based approach for stress-testing integrated circuits},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Eljuse, Basil and Walkinshaw, Neil},
volume = {9962 LNCS},
year = {2016},
pages = {80 - 95},
issn = {03029743},
address = {Raleigh, NC, United states},
abstract = {In order to reduce software complexity and be power efficient, hardware platforms are increasingly incorporating functionality that was traditionally administered at a software-level (such as cache management). This functionality is often complex, incorporating multiple processors along with a multitude of design parameters. Such devices can only be reliably tested at a &lsquo;system&rsquo; level, which presents various testing challenges; behaviour is often non-deterministic (from a software perspective), and finding suitable test sets to &lsquo;stress&rsquo; the system adequately is often an inefficient, manual activity that yields fixed test sets that can rarely be reused. In this paper we investigate this problem with respect to ARM&rsquo;s Cache Coherent Interconnect (CCI) Unit. We present an automated search-based testing approach that combines a parameterised testgeneration framework with the hill-climbing heuristic to find test sets that maximally &lsquo;stress&rsquo; the CCI by producingmuch larger numbers of data stall cycles than the corresponding manual test sets. &copy; Springer International Publishing AG 2016.},
key = {Software testing},
keywords = {Integrated circuit interconnects;Integrated circuits;Reconfigurable hardware;Software engineering;},
note = {Automated searches;Cache coherent interconnect;Cache management;Design parameters;Hardware platform;Multiple processors;Software complexity;Stress Testing;},
URL = {http://dx.doi.org/10.1007/978-3-319-47106-8_6},
} 


@article{20153101095169 ,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test of a new type heat exchange tube with internally revolved rib in once-through steam generator},
journal = {Hedongli Gongcheng/Nuclear Power Engineering},
author = {Zhao, Guozheng},
volume = {36},
number = {3},
year = {2015},
pages = {24 - 27},
issn = {02580926},
abstract = {Looking for high-performance and minimized heat exchange tube is one of the way for improving the performance of Once-through steam generator (OTSG). This paper introduced the thermal-hydraulic experimental research on a new type heat exchange tube with internally revolved rib. The test system and the experiment model were presented. The heat transfer coefficient of the heat exchange tube and the influence of pitch on Nu were analyzed under different mass flow. The revolved rib showed a distinctive improvement on heat transfer performance under high Re condition, and minimizing the pitch was a good choice to enhance the heat exchange. &copy;, 2015, Yuan Zi Neng Chuban She. All right reserved.},
key = {Steam generators},
keywords = {Heat exchangers;Heat transfer;Tubes (components);},
note = {Experiment modeling;Experimental research;Heat transfer performance;Heat-exchange tubes;Internally revolved rib;Once through steam generator;OTSG;Thermal hydraulics;},
URL = {http://dx.doi.org/10.13832/j.jnpe.2015.03.0024},
} 


@article{20144700216949 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Axis geometrical errors analysis through a performance test to evaluate kinematic error in a five axis tilting-rotary table machine tool},
journal = {Precision Engineering},
author = {Alessandro, Velenosi and Gianni, Campatelli and Antonio, Scippa},
volume = {39},
year = {2015},
pages = {224 - 233},
issn = {01416359},
abstract = {Geometrical work piece errors in milling process are commonly generated by different error sources. Axis geometrical errors, such as the straightness error for linear axis and the offset location error of the origin of rotary axis, introduce kinematic error in the tool path. Direct measurement of kinematic error requires special devices such as laser interferometers, grid plate encoders or double ball bars, which impose production stop and specialized staff. These problems could be analyzed using indirect measurements obtained by means of a cutting performance test that is already a standard for three axis machine tools. Because of the different architectures of five-axis milling machines these tests are hardly standardizable, therefore this paper proposes a devised easy-to-use and time efficient cutting performance test to identify and quantify axis geometrical errors for a five axis tilting-rotary table machine tool. This test can be performed as a periodical checkup or, in case of production, as a re-start test. The main goal of this study is to develop a kinematic analytical model capable of correlating the work-piece geometrical errors to the axis geometrical errors of the machine tool. The model has been implemented on a multi-body software in order to simulate the axes motion sequence of the performance test and validated to decouple the kinematic error into the geometrical axis errors. The developed models have demonstrated to be capable of correcting a generic five axis tool path by predicting the tool-path error displacement. The overall validation of this approach has been carried out by comparing the simulated and experimentally measured profile of the NAS 979 standard five axis contouring cone frustum profile.<br/> &copy; 2014 Elsevier Inc.},
key = {Errors},
keywords = {Cutting tools;Geometry;Interferometers;Kinematics;Laser interferometry;Machine tools;Milling (machining);Milling machines;Software testing;Testing;},
note = {Accuracy;Cutting test;Different architectures;Five-axis machine tools;Indirect measurements;Kinematic error;Laser interferometer;Straightness errors;},
URL = {http://dx.doi.org/10.1016/j.precisioneng.2014.09.007},
} 


@inproceedings{20161302168818 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Sparkbench  A spark performance testing suite},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Agrawal, Dakshi and Butt, Ali and Doshi, Kshitij and Larriba-Pey, Josep-L. and Li, Min and Reiss, Frederick R. and Raab, Francois and Schiefer, Berni and Suzumura, Toyotaro and Xia, Yinglong},
volume = {9508},
year = {2016},
pages = {26 - 44},
issn = {03029743},
address = {Kohala Coast, HI, United states},
abstract = {Spark has emerged as an easy to use, scalable, robust and fast system for analytics with a rapidly growing and vibrant community of users and contributors. It is multipurpose&mdash;with extensive and modular infrastructure for machine learning, graph processing, SQL, streaming, statistical processing, and more. Its rapid adoption therefore calls for a performance assessment suite that supports agile development, measurement, validation, optimization, configuration, and deployment decisions across a broad range of platform environments and test cases. Recognizing the need for such comprehensive and agile testing, this paper proposes going beyond existing performance tests for Spark and creating an expanded Spark performance testing suite. This proposal describes several desirable properties flowing from the larger scale, greater and evolving variety, and nuanced requirements of different applications of Spark. The paper identifies the major areas of performance characterization, and the key methodological aspects that should be factored into the design of the proposed suite. The objective is to capture insights from industry and academia on how to best characterize capabilities of Spark-based analytic platforms and provide cost-effective assessment of optimization opportunities in a timely manner. &copy; Springer International Publishing Switzerland 2016.},
key = {Benchmarking},
keywords = {Artificial intelligence;Big data;Cost effectiveness;Learning systems;},
note = {Agile development;Graph processing;Methodological aspects;Performance assessment;Performance characterization;Performance testing;Performance tests;Statistical processing;},
URL = {http://dx.doi.org/10.1007/978-3-319-31409-9_3},
} 


@article{20165103138448 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Study on application of WSN in circuit design and performance test of energy management},
journal = {Romanian Review Precision Mechanics, Optics and Mechatronics},
author = {Ma, Yan-Li and Liu, Yu and Dong, Bei-Bei and Chen, Gui-Qiang and Zhang, Xiao},
volume = {2016},
number = {50},
year = {2016},
pages = {253 - 258},
issn = {15845982},
abstract = {In recent years, with the development of science and technology, wireless sensor network (WSN) technology, one of the most important technology in the world, has received considerable attention from both expert and scholar and enterprises. Energy consumption and supply of the node are the key problems to be solved in the development and application of WSN technology. Based on these issues, WSN was used in circuit design and performance test. Based on the main research background of solar energy and wind energy, energy management circuit is designed and its strategy is studied. Existing application technology is used to settle problems occurred during the application of WSN. Two-circuit ways to collect solar energy and different performances of lithium battery and super-capacitor are studied based on energy storage. Weak current test system is used as an effective means to debug low-power circuits. Star configuration of WSN test platform is established based on designed energy capture node of electric system. Independent charging efficiency test is used to conclude result that under the test environment, energy collection of node satisfies its continuous and effective work. Thus, this circuit is proved to be practical and feasible, and theoretical and technical support is provided for applying WSN. In conclusion, this circuit is worthy widely promotion. &copy; 2016, Editura Cefin. All rights reserved.},
key = {Wireless sensor networks},
keywords = {Energy management;Energy utilization;Integrated circuit manufacture;Lithium batteries;Low power electronics;Program debugging;Sensor nodes;Solar energy;Timing circuits;Wind power;},
note = {Application technologies;Charging efficiency;Development and applications;Development of science and technologies;Energy collection;Low-power circuit;Technical support;Weak currents;},
} 


@inproceedings{20162102421542 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Challenges with applying performance testing methods for systems deployed on shared environments with indeterminate competing workloads: Position paper},
journal = {ICPE 2016 Companion - Companion Publication for 7th ACM/SPEC International Conference on Performance Engineering},
author = {Bondi, Andre B.},
year = {2016},
pages = {41 - 44},
address = {Delft, Netherlands},
abstract = {There is a tendency to move production environments from corporate-owned data centers to cloud-based services. Users who do not maintain a private production environment might not wish to maintain a private performance test environment either. The application of performance engineering methods to the development and delivery of software systems is complicated when the form and or parameters of the target deployment environment cannot be controlled or determined. The difficulty of diagnosing the causes of performance issues during testing or production may be increased by the presence of highly variable workloads on the target platform that compete with the application of interest for resources in ways that might be hard to determine. In particular, performance tests might be conducted in virtualized environments that introduce factors influencing customer-affecting metrics (such as transaction response time) and observed resource usage. Observed resource usage metrics in virtualized environments can have different meanings from those in a native environment. Virtual machines may suffer delays in execution. We explore factors that exacerbate these complications. We argue that these complexities reinforce the case for rigorously using software performance engineering methods rather than diminishing it. We also explore possible performance testing methods for mitigating the risk associated with these complexities.},
key = {Software testing},
keywords = {Application programs;Testing;Virtual reality;},
note = {Cloud performance;Performance engineering;Performance issues;Performance measurements;Performance testing;Production environments;Software performance engineerings;Virtualized environment;},
URL = {http://dx.doi.org/10.1145/2859889.2859895},
} 


@inproceedings{20165203175826 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Virtual instrumentation for no-load testing of induction motor},
journal = {Proceedings - 2016 IEEE International Power Electronics and Motion Control Conference, PEMC 2016},
author = {Subtirelu, Gheorghe-Eugen and Dobriceanu, Mircea and Linca, Mihaita},
year = {2016},
pages = {854 - 859},
address = {Varna, Bulgaria},
abstract = {The main objective of this paper is to solve a practical and current problem, by taking advantage of the virtual instrumentation in testing electrical machines. The abilities of virtual instrumentation are used to data acquisition, measurement and analyze the values of no-load testing's parameters for three-phase induction motor. The virtual measurement system bench is designed and consist from two principal components: the hardware components (six LEM transducers for measuring three voltages and three currents; elements for signal conditioning and power transducers; USB multifunction Input / Output module; a personal computer) and the software components (operating system for the computer; drivers for the acquisition and manipulation of data; virtual instrument for calculation and graphical presentation of results). The LabVIEW graphical programming environment is used for designing virtual instrument. This virtual measurement system bench is an easy to use device which can be used in engineering education laboratories from universities or in electrical machines testing workbenches; it is capable of data acquisition, storage or memorization on different media, visualization of different graphs or analysis on-line or off-line of the results obtained. The virtual measurement system described in the paper can work independently (in the Simulation mode or Real time Acquisition mode) or integrated as part of a future complex virtual system for measurement and analysis in the domain of electrical machines testing workbenches. &copy; 2016 IEEE.},
key = {Electric variables measurement},
keywords = {Automobile engines;Computer graphics;Computer hardware;Computer operating systems;Data acquisition;Data visualization;Digital instruments;Digital storage;Distance education;Electric machinery;Induction motors;Load testing;Motion control;Personal computers;Power control;Power electronics;Transducers;},
note = {Graphical presentations;Labview graphical programming;Measurement and analysis;Principal Components;Real time acquisition;Three phase induction motor;Virtual Instrumentation;Virtual measurement system;},
URL = {http://dx.doi.org/10.1109/EPEPEMC.2016.7752106},
} 


@article{20143600057828 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Towards virtualized and automated software performance test architecture},
journal = {Multimedia Tools and Applications},
author = {Kim, Gwang-Hun and Kim, Yeon-Gyun and Chung, Kyung-Yong},
volume = {74},
number = {20},
year = {2015},
pages = {8745 - 8759},
issn = {13807501},
abstract = {In this paper, we propose the towards virtualized and automated software performance test architecture. In general, test engineers use the public performance testwares such as Load Runner, Silk Performer to validate the performance efficiency of their own systems. In case that they do not allowed to use the performance testwares due to the technical limitations in the testwares, most testers should perform the testing in manually. According to the waste of computer and human resources resulted from the situation, we need to propose the test automation scheme by using the virtualization technology to prevent the dissipation in the test environment which has limited resources. The system architecture considered efficient usage of computer resources and test automation to reduce human acts are addressed mainly in this paper. we describe our proposed method which deals with the system architecture and test automation procedures. In our system architecture, we will show how to use the virtual machines and the types of the virtual machines for performance measurement. In addition, the six steps of the test automation are introduced for the automated testing procedures. Finally, a number of experiments show that the proposed schemes allow offering the possibility for automated software performance testing by using the virtualization.<br/> &copy; 2013, Springer Science+Business Media New York.},
key = {Software testing},
keywords = {Automation;Computer architecture;Network security;Virtual machine;Virtual reality;Virtualization;},
note = {Performance efficiency;Performance measurements;Performance testing;Software performance engineerings;Software performance testing;Technical limitations;Test Automation;Virtualization technologies;},
URL = {http://dx.doi.org/10.1007/s11042-013-1536-3},
} 


@inproceedings{20140917370063 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test and bottle analysis based on scientific research management platform},
journal = {2013 10th International Computer Conference on Wavelet Active Media Technology and Information Processing, ICCWAMTIP 2013},
author = {Li, Ping and Shi, Dong and Li, Jianping},
year = {2013},
pages = {218 - 221},
address = {Chengdu, Sichuan, China},
abstract = {The performance and service quality of a Web system become more and more important along with the development of Web application technology and popularization of Web application rapidly. There are many particularities and difficulties in the testing of web applications as to traditional application, especially in performance testing, such as unpredictable load, reality of designing scenario and veracity of analysis bottleneck. This paper which based on traditional Web system performance testing theory and used the testing tool named LoadRunner to analyze how to detect the shortage of Web system performance precisely. The method has been implemented in System of scientific research management platform, and has been obtained anticipative result. This paper has divide the web system method into six processes based on the Web system performance testing: Making performance testing plan, build performance testing environment, record and develop testing script, foundation testing scene, play the monitor scene and analysis testing result. And also gives Web performance test the general step. &copy; 2013 IEEE.<br/>},
key = {Load testing},
keywords = {Bottles;Websites;},
note = {Bottleneck analysis;Foundation testing;Loadrunner;Performance testing;Performance tests;Scientific researches;WEB application;Web performance;},
URL = {http://dx.doi.org/10.1109/ICCWAMTIP.2013.6716635},
} 


@inproceedings{20141017429873 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {An evaluation of client-side dependencies of search engines by load testing},
journal = {5th International Conference on Advances in System Testing and Validation Lifecycle, VALID 2013, Held at SoftNet 2013},
author = {Sefer, Emine and Aykanat, Sinem},
year = {2013},
pages = {61 - 65},
address = {Venice, Italy},
abstract = {Nowadays, web based large-scale systems, such as search engines, are widely used. The popularity of search engines created a new environment in which the applications need to be highly scalable due to the data tsunami generated by a huge load of requests. In this context, the main problem is to validate how far the web applications especially search engines can deal with the load generated by the clients. Load testing, in general, refers to the practice of accessing the system behavior under load. In this paper, we study on search engine performances' dependencies related to network bandwidth and Internet browsers in aspect of load testing. We observed that search engines' speed is dependent on Internet browsers and network bandwidth.<br/>},
key = {Search engines},
keywords = {Bandwidth;Large scale systems;Life cycle;Load testing;System theory;},
note = {Client sides;Internet browsers;Network bandwidth;Search engine performance;System behaviors;Under loads;WEB application;Web based;},
} 


@article{20113614302583 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Application and performance test of a micro-machined unipolar charger for real-time measurements of exhaust particles from a diesel engine vehicle},
journal = {Journal of Aerosol Science},
author = {Lee, Sang-Gu and Hyun, Junho and Park, Dongho and Hwang, Jungho and Kim, Yong-Jun},
volume = {42},
number = {11},
year = {2011},
pages = {747 - 758},
issn = {00218502},
abstract = {Characterization of particulate matter (PM) emitted from diesel vehicle exhaust requires a real-time measurement sensor to record particle concentrations under transient tests. Recently, a micro-machined unipolar charger (MUC) based on a micro-electromechanical system (MEMS) was introduced and evaluated to test aerosol particles on a laboratory scale. We present the performance characteristics of the MUC for its potential use as a sensor for diesel PM emissions. A correlation equation was derived from particle loss experiments and tandem differential mobility analyzer (TDMA) measurements in the laboratory, which was used to convert the current measurement datum into a total particle number concentration. Under various idling and driving conditions of a diesel vehicle, the electrical signals from the MUC were verified to have followed the trend of the total number concentrations of diesel PM measured using a condensation particle counter (CPC). When the diesel PM concentrations measured using the CPC were within the range of 2&times;10<sup>4</sup>-2&times;10<sup>5</sup>#/cm<sup>3</sup>, the total number concentrations, estimated using a correlation equation, were in agreement with the CPC data. &copy; 2011 Elsevier Ltd.<br/>},
key = {Particles (particulate matter)},
keywords = {Diesel engines;Diesel locomotives;Electric corona;MEMS;Time division multiple access;Time measurement;Vehicles;},
note = {Condensation particle counters;Corona discharges;Micro electromechanical system (MEMS);Micro-machined;Particle number concentration;Tandem differential mobility analyzers;Total number concentrations;Unipolar charging;},
URL = {http://dx.doi.org/10.1016/j.jaerosci.2011.07.003},
} 


@inproceedings{20141717624803 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Downhole tools oil-immersion automation test system design},
journal = {Applied Mechanics and Materials},
author = {Shang, Chun Min and Zhang, Dong Mei and Zhang, Xin Ming},
volume = {543-547},
year = {2014},
pages = {930 - 933},
issn = {16609336},
address = {Beijing, China},
abstract = {According to the relationship of pressure and volume of the downhole tool oil-immersion test system during the pressuring process, the mathematical models of the pressure control was deduced about the downhole tool experiment system, based on the model, a test system of the multi function, high precision, high index, intelligent automation was designed and manufactured. The control system has friendly interface, manual/automatic and scene/remote control function, the test parameters and test process is free to set according to the actual needs of test tool, reports and graphs can be produce automatically, the test site achieve unattended operation that improving testing process safety. Test and application show that pressure control capacity of 150Mpa, pressure control accuracy of 0.35%FS. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Tools},
keywords = {Automation;Automobile manufacture;Information technology;Mathematical models;Packers;Pressure control;Safety testing;},
note = {Automation controls;Automation tests;Control functions;Down-hole tool;Experiment system;Intelligent automation;Multi-functions;Oil-immersion;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.543-547.930},
} 


@article{20181905163736 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Standard Guide for Thermal Performance Testing of Cryogenic Insulation Systems},
journal = {Standard Guide for Thermal Performance Testing of Cryogenic Insulation Systems},
year = {2013},
abstract = {Scope: This guide provides information for the laboratory measurement of the steady-state thermal transmission properties and heat flux of thermal insulation systems under cryogenic conditions. Thermal insulation systems may be composed of one or more materials that may be homogeneous or non-homogeneous; flat, cylindrical, or spherical; at boundary conditions from near absolute zero or 4 K up to 400 K; and in environments from high vacuum to an ambient pressure of air or residual gas. The testing approaches presented as part of this guide are distinct from, and yet complementary to, other ASTM thermal test methods including C177, C518, and C335. A key aspect of this guide is the notion of an insulation system, not an insulation material. Under the practical use environment of most cryogenic applications even a single-material system can still be a complex insulation system (1-3).<sup>2</sup>To determine the inherent thermal properties of insulation materials, the standard test methods as cited in this guide should be consulted. The function of most cryogenic thermal insulation systems used in these applications is to maintain large temperature differences thereby providing high levels of thermal insulating performance. The combination of warm and cold boundary temperatures can be any two temperatures in the range of near 0 K to 400 K. Cold boundary temperatures typically range from 4 K to 100 K, but can be much higher such as 300 K. Warm boundary temperatures typically range from 250 K to 400 K, but can be much lower such as 40 K. Large temperature differences up to 300 K are typical. Testing for thermal performance at large temperature differences with one boundary at cryogenic temperature is typical and representative of most applications. Thermal performance as a function of temperature can also be evaluated or calculated in accordance with Practices C1058 or C1045 when sufficient information on the temperature profile and physical modeling are available. The range of residual gas pressures for this Guide is from 10<sup>-7</sup>torr to 10<sup>+3</sup>torr (1.33<sup>-5</sup>Pa to 133 kPa) with different purge gases as required. Corresponding to the applications in cryogenic systems, three sub-ranges of vacuum are also defined: High Vacuum (HV) from &lt;10<sup>-6</sup>torr to 10<sup>-3</sup>torr (1.333<sup>-4</sup>Pa to 0.133 Pa) [free molecular regime], Soft Vacuum (SV) from 10<sup>-2</sup>torr to 10 torr (from 1.33 Pa to 1,333 Pa) [transition regime], No Vacuum (NV) from 100 torr to 1000 torr (13.3 kPa to 133 kPa) [continuum regime]. Thermal performance can vary by four orders of magnitude over the entire vacuum pressure range. Effective thermal conductivities can range from 0.010 mW/m-K to 100 mW/m-K. The primary governing factor in thermal performance is the pressure of the test environment. High vacuum insulation systems are often in the range from 0.05 mW/m-K to 2 mW/m-K while non-vacuum systems are typically in the range from 10 mW/m-K to 30 mW/m-K. Soft vacuum systems are generally between these two extremes (4). Of particular demand is the very low thermal conductivity (very high thermal resistance) range in sub-ambient temperature environments. For example, careful delineation of test results in the range of 0.01 mW/m-K to 1 mW/m-K (from R-value 14,400 to R-value 144) is required as a matter of normal engineering applications for many cryogenic insulation systems (5-7). The application of effective thermal conductivity values to multilayer insulation (MLI) systems and other combinations of diverse materials, because they are highly anisotropic and specialized, must be done with due caution and full provision of supporting technical information (8). The use of heat flux (W/m<sup>2</sup>) is, in general, more suitable for reporting the thermal performance of MLI systems (9-11). This guide covers different approaches for thermal performance measurement in sub-ambient temperature environments. The test apparatuses (apparatus) are divided into two categories: boiloff calorimetry and electrical power. Both absolute and comparative apparatuses are included. This guide sets forth the general design requirements necessary to construct and operate a satisfactory test apparatus. A wide variety of apparatus constructions, test conditions, and operating conditions are covered. Detailed designs are not given but must be developed within the constraints of the general requirements. Examples of different cryogenic test apparatuses are found in the literature (12). These apparatuses include boiloff types (13-17) as well as electrical types (18-21). These testing approaches are applicable to the measurement of a wide variety of specimens, ranging from opaque solids to porous or transparent materials, and a wide range of environmental conditions including measurements conducted at extremes of temperature and with various gases and over a range of pressures. Of particular importance is the ability to test highly anisotropic materials and systems such as multilayer insulation (MLI) systems (22-25). Other test methods are limited in this regard and do not cover the testing of MLI and other layered systems under the extreme cryogenic and vacuum conditions that are typical for these systems. In order to ensure the level of precision and accuracy expected, users applying this standard must possess a working knowledge of the requirements of thermal measurements and testing practice and of the practical application of heat transfer theory relating to thermal insulation materials and systems. Detailed operating procedures, including design schematics and electrical drawings, should be available for each apparatus to ensure that tests are in accordance with this Guide. In addition, automated data collecting and handling systems connected to the apparatus must be verified as to their accuracy. Verification can be done by calibration and comparing data sets, which have known results associated with them, using computer models. It is impractical to establish all details of design and construction of thermal insulation test equipment and to provide procedures covering all contingencies associated with the measurement of heat flow, extremely delicate thermal balances, high vacuum, temperature measurements, and general testing practices. The user may also find it necessary, when repairing or modifying the apparatus, to become a designer or builder, or both, on whom the demands for fundamental understanding and careful experimental technique are even greater. The test methodologies given here are for practical use and adaptation as well as to enable future development of improved equipment or procedures. This guide does not specify all details necessary for the operation of the apparatus. Decisions on sampling, specimen selection, preconditioning, specimen mounting and positioning, the choice of test conditions, and the evaluation of test data shall follow applicable ASTM Test Methods, Guides, Practices or Product Specifications or governmental regulations. If no applicable standard exists, sound engineering judgment that reflects accepted heat transfer principles must be used and documented. This guide allows a wide range of apparatus design and design accuracy to be used in order to satisfy the requirements of specific measurement problems. Compliance with a further specified test method should include a report with a discussion of the significant error factors involved as well the uncertainty of each reported variable. The values stated in SI units are to be regarded as the standard. The values given in parentheses are for information only. Either SI or Imperial units may be used in the report, unless otherwise specified. Safety precautions including normal handling and usage practices for the cryogen of use. Prior to operation of the apparatus with any potentially hazardous cryogen or fluid, a complete review of the design, construction, and installation of all systems shall be conducted. Safety practices and procedures regarding handling of hazardous fluids have been extensively developed and proven through many years of use. For systems containing hydrogen, particular attention shall be given to ensure the following precautions are addressed: (1) adequate ventilation in the test area, (2) prevention of leaks, (3) elimination of ignition sources, (4) fail safe design, and (5) redundancy provisions for fluid fill and vent lines. This standard does not purport to address all of the safety concerns, if any, associated with its use. It is the responsibility of the user of this standard to establish appropriate safety and health practices and determine the applicability of regulatory limitations prior to use. Major sections within this standard are arranged as follows: (Table Presented)<br/> &copy;2013 ASTM International. All rights reserved.},
key = {Thermal insulation},
keywords = {Anisotropy;Construction equipment;Cryogenics;Data handling;Equipment testing;Hazards;Heat flux;Heating equipment;Materials testing;Multilayers;Permafrost;Software testing;Tapes;Temperature;Temperature measurement;Thermal conductivity;Thermal insulating materials;Vacuum applications;},
note = {Effective thermal conductivity;Environmental conditions;Governmental regulations;Low thermal conductivity;Temperature environments;Thermal insulation materials;Thermal insulation systems;Thermal performance testing;},
URL = {http://dx.doi.org/10.1520/C1774},
versions = {1},
} 


@inproceedings{20112714122900 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Model-based performance testing (NIER track)},
journal = {Proceedings - International Conference on Software Engineering},
author = {Barna, Cornel and Litoiu, Marin and Ghanbari, Hamoun},
year = {2011},
pages = {872 - 875},
issn = {02705257},
abstract = {In this paper, we present a method for performance testing of transactional systems. The methods models the system under test, finds the software and hardware bottlenecks and generate the workloads that saturate them. The framework is adaptive, the model and workloads are determined during the performance test execution by measuring the system performance, fitting a performance model and by analytically computing the number and mix of users that will saturate the bottlenecks. We model the software system using a two layers queuing model and use analytical techniques to find the workload mixes that change the bottlenecks in the system. Those workload mixes become stress vectors and initial starting points for the stress test cases. The rest of test cases are generated based on a feedback loop that drives the software system towards the worst case behaviour. &copy; 2011 ACM.<br/>},
key = {Software testing},
keywords = {Adaptive systems;Queueing theory;},
note = {Performance Model;Performance testing;Performance tests;Software and hardwares;Software systems;Stress Testing;System under test;Transactional systems;},
URL = {http://dx.doi.org/10.1145/1985793.1985930},
} 


@inproceedings{20114114421459 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stress test model of cascading failures in power grids},
journal = {NAPS 2011 - 43rd North American Power Symposium},
author = {Liao, Huaiwei and Ilic, Marija},
year = {2011},
pages = {Northeastern University College of Engineering; Power and Energy Society (IEEE PES) - },
address = {Boston, MA, United states},
abstract = {Cascading failures in electric power systems are one of the major causes of large power blackouts. The operators in control centers of electric power systems need an online tool to monitor the risk of cascading failures when transferring large quantities of power over long distances. In this paper, we propose a two-stage stress test model of cascading failures. The stress test model is intended to emulate the effect of security-constrained economic dispatch (SCED) in support of the required power transfer level, and at the same time, to account for relay actions in response to a given set of severe disturbances, called maximum credible disturbances. The model includes an inner stage, which simulates cascading outages due to relay actions in the system at a given state under disturbances, and an outer stage, which moves the operating point of the system as the power transfer increases as a result of SCED. We use the stress test model to simulate cascading failures in a real 3000-bus power system when increasing its power transfer level in different directions. &copy; 2011 IEEE.<br/>},
key = {Outages},
keywords = {Electric fault currents;Electric load dispatching;Electric power system control;Electric power systems;Electric power transmission networks;Energy transfer;Online systems;Scheduling;},
note = {Cascading failures;Cascading outages;On-line tools;Operating points;Power grids;Power System;Power transfers;Security-constrained economic dispatch;},
URL = {http://dx.doi.org/10.1109/NAPS.2011.6025200},
} 


@inproceedings{20132416416305 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Radiation Belt Storm Probes (RBSP) Flight Software stress testing: Case study and lessons learned},
journal = {IEEE Aerospace Conference Proceedings},
author = {Finnigan, Jeremiah},
year = {2013},
issn = {1095323X},
address = {Big Sky, MT, United states},
abstract = {This paper presents a case study of the Radiation Belt Storm Probes (RBSP) mission Command and Data Handling (C&amp;DH) Flight Software stress testing program. Background information on the motivation for stress testing embedded software, and the general principles and goals of a stress test are provided as an introduction. Details of the stress test program that was implemented for the RBSP C&amp;DH Flight Software are presented and discussed. This discussion includes the design and development of a test framework that was implemented to incrementally build the test scenarios, increase the productivity of the RBSP stress test team, and facilitate reuse for regression testing. Results of the RBSP stress test program are summarized, and lessons learned that may be useful for future embedded software test programs are documented. &copy; 2013 IEEE.},
key = {Software testing},
keywords = {C (programming language);Data handling;Embedded software;Probes;Radiation belts;Storms;Test facilities;Testing;},
note = {Background information;Design and Development;Flight Software;Lessons learned;Mission command;Regression testing;Stress Testing;Test framework;},
URL = {http://dx.doi.org/10.1109/AERO.2013.6496814},
} 


@inproceedings{20134817032605 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven generative framework for automated OMG DDS performance testing in the cloud},
journal = {SPLASH 2013 - Proceedings of the 2013 Companion Publication for Conference on Systems, Programming, and Applications: Software for Humanity},
author = {An, Youngho and Kuroda, Takayuki and Gokhale, Aniruddha and Tambe, Sumant and Sorbini, Andrea},
year = {2013},
pages = {93 - 94},
address = {Indianapolis, IN, United states},
abstract = {The Object Management Group's (OMG) Data Distribution Service (DDS) provides many configurable policies which determine end-to-end quality of service (QoS) delivered to the applications. It is challenging, however, to predict the application's performance in terms of latencies, throughput, and resource usage because diverse combinations of QoS configurations influence QoS of applications in different ways. To overcome this problem, design-time formal methods have been applied with mixed success, but a lack of sufficient accuracy in prediction, tool support, and understanding of formalism has prevented wider adoption of the formal techniques. A promising approach to address this challenge is to emulate application behavior and gather data on the QoS parameters of interest by experimentation. To realize this approach, we have developed a middleware framework that uses model-driven generative mechanisms to automate performance testing of a large number of DDS QoS configuration combinations that can be deployed and tested on a cloud platform. Copyright &copy; 2013 by the Association for Computing Machinery, Inc. (ACM).},
key = {Quality of service},
keywords = {Application programs;Computer systems programming;},
note = {Data distribution services;End-to-end quality of service;Generative programming;Middleware frameworks;Model-driven Engineering;Object management groups;Performance testing;Publish/subscribe;},
URL = {http://dx.doi.org/10.1145/2508075.2508096},
} 


@inproceedings{20140617272628 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Comparison of hardware based and software based stress testing of memory IO interface},
journal = {Midwest Symposium on Circuits and Systems},
author = {Querbach, Bruce and Puligundla, Sudeep and Becerra, Daniel and Schoenborn, Zale T. and Chiang, Patrick},
year = {2013},
pages = {637 - 640},
issn = {15483746},
address = {Columbus, OH, United states},
abstract = {In post-silicon testing and validation of circuit functionality, an effective IO stress pattern can identify bugs quickly and provide adequate test coverage. A lot of work has been done to identify the right stress patterns specific to each IO interface. While some patterns can be generic enough to apply to all IOs, other patterns are interface topology specific. In addition to identifying the worst-case pattern, tradeoffs between test-time and test coverage must be made depending on the test goals. Pseudo Random Bit Stream (PRBS) generators are commonly used to generate test patterns because of the adequate frequency content in the PRBS patterns, the ease of implementation, and minimal gate count. This paper introduces an Advanced Pattern Generator and Checker (APGC) based on PRBS that retains all the aforementioned advantages. The APGC was implemented for a DDR memory interface where different LFSRs beat against each other spatially on neighboring IO lanes while rotating this form of aggressor-victim pattern in time. The results of the APGC stress patterns are compared to a form of advanced software-based learning algorithm based patterns that exhaustively search this complete parameter space. The comparison of APGC to software showed that the measured bit error rate (BER) plotted on a Q-scale of both methods is similar for the Receiver side. On the Transmitter side, APGC showed less eye opening than the software. In addition to the margin comparison, on the test execution side, APGC can speed up the test and validation execution time compared to the software by 32 to 2048 times depending on aggressor victim lane width of 8 to 64 lanes. &copy; 2013 IEEE.<br/>},
key = {Software testing},
keywords = {Bit error rate;Testing;},
note = {Advanced softwares;Aggressor-victim;Circuit functionality;Frequency contents;Parameter spaces;Pattern generator;Pseudo random bit stream;Worst case pattern;},
URL = {http://dx.doi.org/10.1109/MWSCAS.2013.6674729},
} 


@inproceedings{20142717896700 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Application of the OPC technology in the no-load test platform of the metro bogie},
journal = {Advanced Materials Research},
author = {Ren, Guang Sheng and Gai, Lei and Yin, Xiao Qing},
volume = {945-949},
year = {2014},
pages = {2062 - 2066},
issn = {10226680},
abstract = {The generation of the OPC technology makes each data source communicate flexibly in the industrial control environment. This paper takes the no-load test platform of the metro bogie as an example to design a lower and upper computer measurement and control system which is consist of IPC and PLC by the OPC technology. The OPC client is developed based on the platform of Visual Basic. By using the different communication mode, it is realized to access the OPC server data. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Technology},
keywords = {Bogies (railroad rolling stock);Data processing;Manufacture;},
note = {Communication mode;Industrial controls;Measurement and control systems;Metro;Opc technologies;Test platforms;Upper computer;VB;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMR.945-949.2062},
} 


@inproceedings{20132216378712 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research of load testing and result application based on loadrunner},
journal = {Proceedings of the 2012 National Conference on Information Technology and Computer Science, CITCS 2012},
author = {Zhang, Hui-Li and Zhang, Shu and Li, Xiao-Jie and Zhang, Pei and Liu, Shao-Bo},
year = {2012},
pages = {1069 - 1072},
address = {Lanzhou, China},
abstract = {In this paper, we made the plan of a load testing, and got results by means of the LoadRunner which is an automatic testing tool. We fully considered the characteristics of the electronic commerce application, designed the reasonable test cases, and simulated the practical scenario. In the process of running LoadRunner, we arranged the appropriate transactions and rendezvous, and designed the truthful test network environment. The plan was applied to the load testing phase of the telecommunication equipment sales system of special products. We analyzed the load testing results, proposed the improving measures, and realized the optimization of the telecommunication equipment sales system. &copy; 2012. The authors - Published by Atlantis Press.},
key = {Information technology},
keywords = {Automatic testing;Computer science;Load testing;Telecommunication equipment;},
note = {Electronic commerce applications;Loadrunner;Test case;Test network;Test scripts;Testing phase;Transaction;},
} 


@article{20134817030778 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Automation testing software that aid in efficiency increase of regressionprocess},
journal = {Recent Patents on Computer Science},
author = {Bhatt, Alok N. and Babu Rajasekhara, M. and Bhatt, Anuja J.},
volume = {6},
number = {2},
year = {2013},
pages = {107 - 114},
issn = {18744796},
abstract = {Accuracy of any software release to the market depends on how efficiently it has been debugged. Debugging is a systematic procedure, used to identify and figure out the cause of defects or any anomaly that the software has and make the software behave as expected. The issues generated by the customer of any company are logged into a database, wherein issues are picked up selected, solved and reverted back to the customers. After solving an issue, it may happen that the issue affects other components which results into a greater number of bugs. The resultant issues are called regression issues. The objective of this paper is to propose and implement a client-server, object-oriented, multiple plat form supporting frame work called RATS Framework which automates the process of regression and thereby helps debug engineers to solve time-consuming regression issues at a faster rate. It automates the process with the help of web-scrapping algorithm (W-S-A) that includes HTML/XML parsing to extract the needed content in the form of GUI-Web Objects, than using Network-Binary Search Algorithm (N/W-BS-A) and Change Finder Algorithm, a variant of Binary Search method, RATS finds out the nearest pass/fail driver build and change in the driver build that cause the new defect in the driver respectively. Because the RATS Framework does this at runtime, client-server approach has to be followed making use of Remote Identification and Installation-Algorithm. Hence RATS framework is a cost effective and time efficient approach for regression issues. The present article has the discussion of few of the patents relevant to automation testing software. &copy; 2013 Bentham Science Publishers.},
key = {Program debugging},
keywords = {Algorithms;Cost effectiveness;Defects;Graphical user interfaces;Object oriented programming;Rats;Regression analysis;Software testing;},
note = {Client server;Cost effective;GUI-Web objects;Multiple platforms;Object oriented;Time-efficient;},
} 


@inproceedings{20124215564648 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance of cloud-based scalability and load with an automation testing tool in virtual world},
journal = {Proceedings - 2012 IEEE 8th World Congress on Services, SERVICES 2012},
author = {Kamra, Madhvi and Manna, Ratnamala},
year = {2012},
pages = {57 - 64},
address = {Honolulu, HI, United states},
abstract = {The development in cloud computing provides limitless capacity which provides opportunity to evaluate an application performance based on its nature to scale. This paper aims at the analysis of Performance using the Google App Engine(cloud computing paradigm). Virtual Office application is chosen as example to perform experiment of testing the scalability in turn maintaining the performance. An Automation Testing Tool - Test Harness has been used to perform the scale testing of the application while being deployed on the cloud. Results have seen shown in the form of request type and response times(Average time taken/request). Taken into account the consideration that when the application load goes up the Google Cloud expands(increases instance hours) without affecting the running application. &copy; 2012 IEEE.<br/>},
key = {Load testing},
keywords = {IEEE Standards;Mobile computing;Platform as a Service (PaaS);Program processors;Scalability;Virtual reality;},
note = {Analysis of performance;Application performance;Automation testing;Google app engines;Running applications;Test harness;Virtual office;Virtual worlds;},
URL = {http://dx.doi.org/10.1109/SERVICES.2012.54},
} 


@inproceedings{20144900278479 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {LTF: A model-based load testing framework for web applications},
journal = {Proceedings - International Conference on Quality Software},
author = {Zhou, Junzan and Zhou, Bo and Li, Shanping},
year = {2014},
pages = {154 - 163},
issn = {15506002},
address = {Dallas, TX, United states},
abstract = {Performance evaluation is an important approach for various systems to guarantee the quality of their services. However, most performance evaluation tasks face a problem: how to model the system workload? Traditional workload models have limitations when it comes to modeling different workloads. In this paper, we propose a workload model for characterizing and generating synthetic web workloads. First, we introduce a Context-based Sequential Action Model to describe users that exhibit similar access patterns. Next, we present a Workload Parameter Specification Language to describe workload parameters for workload generation. Then, we introduce our load-testing framework based on the proposed model. The representativeness and features of our model are demonstrated by comparing it to other models. Experiments show that our framework can generate accurate and stable synthetic workloads.<br/> &copy; 2014 IEEE.},
key = {Load testing},
keywords = {Models;Quality control;Specification languages;},
note = {Parameter specification;performance;Performance evaluations;Synthetic workloads;System workloads;Testing framework;Workload characterization;Workload generation;},
URL = {http://dx.doi.org/10.1109/QSIC.2014.53},
} 


@inproceedings{20142417826528 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A web automation testing framework over cloud},
journal = {Applied Mechanics and Materials},
author = {Chen, Min Gang and Zhong, Wen Bin and Chen, Wen Jie and Hu, Yun and Cai, Li Zhi},
volume = {556-562},
year = {2014},
pages = {6149 - 6153},
issn = {16609336},
address = {Shanghai, China},
abstract = {With the increasingly fast-paced software releasing or updating, research on the method of an efficient software automation testing framework based on cloud computing has become particularly important. In this paper, we propose an automation testing framework over cloud. We also describe some key technologies in the aspect of the design of hierarchical test case and automatic distribution of test cases in the cloud computing environment. Testing experiments show that our framework can take advantage of on-demand testing resources in the cloud to improve the efficiency of automation testing. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Software testing},
keywords = {Automation;Cloud computing;Computer systems;Information technology;},
note = {Automation testing;Cloud computing environments;Cloud testing;Key technologies;Software automation;TaaS;Testing resources;Web automation;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.556-562.6149},
} 


@inproceedings{20130315908070 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing challenges  solutions for asynchronous systems},
journal = {37th International Conference Computer Measurement Group},
author = {Mudujutla, Guru and Hampaiah, Uppara and Jandhyala, Srinivas},
year = {2011},
address = {Washington, DC, United states},
abstract = {This paper presents challenges faced in typical Asynchronous Systems Performance Testing (ASPT) and workaround solutions applied for them. An Enterprise Service Fulfillment (ESF) system consists of Business Gateways, Application Integrators Customer Relationship Management (CRM) Systems, Order Fulfillment Systems, Fault Resolution Systems and series of other back-end systems such as billing, revenue assurance, work order management, MIS etc. It uses web services, queue communications with high volumes of different business transactions. Stringent business Service Level Agreement (SLAs) (like individual component response times, throughputs, utilizations and End to End (E2E) response times), scaled down test environment and unavailability of back-end components in test environment poses some unique challenges during performance testing of asynchronous systems. This paper elaborates these challenges and presents suitable workaround solutions devised to handle asynchronous transactions for complete performance testing thus providing an assurance on the asynchronous SLAs before the business goes live.},
key = {Response time (computer systems)},
keywords = {Telecommunication systems;Web services;},
note = {Asynchronous system;Backend system;Business service;Business transaction;Customer relationship management systems;End to end;Enterprise services;Individual components;Order fulfillment;Performance testing;Resolution systems;Revenue assurance;Test Environment;Work order management;},
} 


@article{20130415938517 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Challenges on amazon cloud in load balancing, performance testing and upgrading},
journal = {Advances in Intelligent Systems and Computing},
author = {Shah, Himanshu and Wankhede, Paresh and Borkar, Anup},
volume = {203},
year = {2013},
pages = {31 - 40},
issn = {21945357},
abstract = {Web application hosting in a data centre is clouded with quite a few issues ranging from hardware provisioning, software installation and maintaining the servers. Traditional data-centre techniques need production grade hardware to test application's behavior/performance under expected peak load. This could be costly and procuring hardware could be very time consuming causing delays in software delivery. Cloud (Infrastructure-as-a- Service) can be an answer to this. Cloud Computing provides production grade server instances at very cheap rates. This whitepaper is divided into two sub parts: first part details out the typical web application setup on Amazon Web Services cloud (AWS) [Ref 2], challenges faced during the setup and resolution for the same, while the second part talks about the observations made during load testing using Apache JMeter performance testing tool on AWS cloud. Three different application setup topologies (single tier, two tier and three tier) are tested and findings and learning from it are discussed here. This whitepaper only highlights the pitfalls encountered and possible resolutions for each and is not a comment on performance of Amazon cloud. The whitepaper endeavors to find out the best architecture which would give maximum return on investment. &copy; Springer-Verlag Berlin Heidelberg 2013.},
key = {Computer hardware},
keywords = {Hardware;Profitability;Web services;},
note = {Amazon web services;Data centres;Peak load;Performance testing;Return on investments;Software installations;Test applications;WEB application;},
URL = {http://dx.doi.org/10.1007/978-3-642-35461-8},
} 


@inproceedings{20133216598213 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing framework for smart grid communication network},
journal = {IOP Conference Series: Earth and Environmental Science},
author = {Quang, D.N. and See, O.H. and Chee, L.L. and Xuen, C.Y. and Karuppiah, S.},
volume = {16},
number = {1},
year = {2013},
issn = {17551307},
address = {Beijing, China},
abstract = {Smart grid communication network is comprised of different communication mediums and technologies. Performance evaluation is one of the main concerns in smart grid communication system. In any smart grid communication implementation, to determine the performance factor of the network, a testing of an end-to-end process flow is required. Therefore, an effective and coordinated testing procedure plays a crucial role in evaluating the performance of smart grid communications. In this paper, a testing framework is proposed as a guideline to analyze and assess the performance of smart grid communication network. &copy; Published under licence by IOP Publishing Ltd.},
key = {Smart power grids},
keywords = {Communication;},
note = {Communication medium;End-to-end process;Performance factors;Performance testing framework;Smart Grid Communications;Testing framework;Testing procedure;},
URL = {http://dx.doi.org/10.1088/1755-1315/16/1/012147},
} 


@inproceedings{20113614311923 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Wireless network performance test in hybrid wired/wireless network system},
journal = {Proceedings of the World Congress on Intelligent Control and Automation (WCICA)},
author = {Jiang, Dezhi and Fei, Minrui and Wang, Haikuan and Li, Tongtao},
year = {2011},
pages = {1029 - 1034},
abstract = {Recently, considerable researches on wireless networks have been carried in industrial automation. A great deal of wireless control and monitoring systems are introduced in certain problematic parts of the process industry to improve the productivity and efficiency. However, the control and monitor application requires high standard performances, such as reliability, real-timing and accuracy. Therefore a comprehensive performance assessment is needed to test the property of the wireless network so as to optimize the network protocol and improve the network communication quality. This paper studies the wireless network in the integrated wired/wireless fieldbus system and proposes a method to acquire a set of key indicators of wireless networks. Then, a test device is designed to acquire the performance indicators of the system. The wireless protocols are analysed according to the performance indicators. The results show that the test for the performance of wireless networks can be realized by the method mentioned. &copy; 2011 IEEE.<br/>},
key = {Wireless networks},
keywords = {Benchmarking;Internet protocols;Network protocols;},
note = {Comprehensive performance assessments;Control and monitor;IEEE 802.15.4a;Industrial automation;Network communications;Performance indicators;Process industries;Protocol conversion;},
URL = {http://dx.doi.org/10.1109/WCICA.2011.5970672},
} 


@inproceedings{20130916071124 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {New device design and performance test on gas generator in automobile airbag},
journal = {Proceedings - 2012 International Conference on Control Engineering and Communication Technology, ICCECT 2012},
author = {Tan, Yingxin and Yu, Cunjuan},
year = {2012},
pages = {484 - 487},
address = {Shenyang, Liaoning, China},
abstract = {An new test device to test gas generator performance in automobile airbag is built. It is made up of inflator jar, sliding track, lifting device and data acquisition system. This system can produce an analog signal which is similar to the impact signal of automobile crash. For get suitable data of acceleration and the duration of impact, lots of experiments have been done. When lifting height of inflator jar is 280mm, acceleration peak value is from 80.5g to 90.2g and dash duration is from 6ms to 8ms. They can meet require to detonate gas generator. There were five groups gas generators from SHANXI Jinheng auto-parts Co., LTD was tested and changing track of pressure and acceleration can be known clearly. Then forty-four gas generators contrast test were done separately in China and in USA. Test results from our designed device were very similar to USA device. It was confirmed that the device designed to test gas generator performance by ourselves was successful. &copy; 2012 IEEE.},
key = {Gas generators},
keywords = {Accidents;Automobiles;Communication;},
note = {airbag;Analog signals;Auto-parts;Contrast tests;Data acquisition system;Impact signals;Lifting devices;Lifting height;Mechanical design;New devices;Peak values;Performance tests;Pressure tests;Test device;},
URL = {http://dx.doi.org/10.1109/ICCECT.2012.77},
} 


@inproceedings{20130916048097 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {WS-TaaS: A testing as a service platform for Web Service load testing},
journal = {Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS},
author = {Yan, Minzhi and Sun, Hailong and Wang, Xu and Liu, Xudong},
year = {2012},
pages = {456 - 463},
issn = {15219097},
address = {Singapore, Singapore},
abstract = {Web services are widely known as the building blocks of typical service oriented applications. The performance of such an application system is mainly dependent on that of component web services. Thus the effective load testing of web services is of great importance to understand and improve the performance of a service oriented system. However, existing Web Service load testing tools ignore the real characteristics of the practical running environment of a web service, which leads to inaccurate test results. In this work, we present WS-TaaS, a load testing platform for web services, which enables load testing process to be as close as possible to the real running scenarios. In this way, we aim at providing testers with more accurate performance testing results than existing tools. WS-TaaS is developed on the basis of our existing Cloud PaaS platform: Service4All. First, we briefly introduce the functionalities and main components of Service4All. Second, we provide detailed analysis of the requirements of Web Service load testing and present the conceptual architecture and design of key components. Third, we present the implementation details of WS-TaaS on the basis of Service4All. Finally, we perform a set of experiments based on the testing of real web services, and the experiments illustrate that WS-TaaS can efficiently facilitate the whole process of Web Service load testing. Especially, comparing with existing testing tools, WS-TaaS can obtain more effective and accurate test results. &copy; 2012 IEEE.},
key = {Web services},
keywords = {Cloud computing;Computer systems;Experiments;Load testing;Websites;},
note = {Accurate performance;Application systems;Building blockes;Conceptual architecture;Service oriented application;Service Oriented Systems;Testing as a services;Testing platforms;Testing process;Testing tools;Whole process;},
URL = {http://dx.doi.org/10.1109/ICPADS.2012.69},
} 


@inproceedings{20135017083200 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven generative framework for automated OMG DDS performance testing in the cloud},
journal = {SPLASH Indianapolis 2013; GPCE 2013 - Proceedings of the 12th International Conference on Generative Programming: Concepts and Experiences},
author = {An, Kyoungho and Kuroda, Takayuki and Gokhale, Aniroddha and Tambe, Sumant and Sorbini, Andrea},
year = {2013},
pages = {179 - 182},
address = {Indianapolis, IN, United states},
abstract = {The Object Management Group's (OMG) Data Distribution Service (DDS) provides many configurable policies which determine end-to-end quality of service (QoS) of applications. It is challenging to predict the system's performance in terms of latencies, throughput, and resource usage because diverse combinations of QoS configurations influence QoS of applications in different ways. To overcome this problem, design-time formal methods have been applied with mixed success, but lack of sufficient accuracy in prediction, tool support, and understanding of formalism has prevented wider adoption of the formal techniques. A promising approach to address this challenge is to emulate system behavior and gather data on the QoS parameters of interest by experimentation. To realize this approach, which is preferred over formal methods due to their limitations in accurately predicting QoS, we have developed a model-based automatic performance testing framework with generative capabilities to reduce manual efforts in generating a large number of relevant QoS configurations that can be deployed and tested on a cloud platform. This paper describes our initial efforts in developing and using this technology. &copy; 2013 ACM.},
key = {Quality of service},
keywords = {Distributed computer systems;Forecasting;},
note = {Data distribution services;End-to-end quality of service;Generative programming;Model-driven Engineering;Object management groups;Performance testing;Performance testing framework;Publish/subscribe;},
URL = {http://dx.doi.org/10.1145/2517208.2517216},
} 


@inproceedings{20124415618550 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A novel approach of automation testing on mobile devices},
journal = {2012 International Conference on Computer and Information Science, ICCIS 2012 - A Conference of World Engineering, Science and Technology Congress, ESTCON 2012 - Conference Proceedings},
author = {Nagowah, Leckraj and Sowamber, Gayeree},
volume = {2},
year = {2012},
pages = {924 - 930},
address = {Kuala Lumpur, Malaysia},
abstract = {Mobile phones and mobile applications have now become an integral part of our everyday life. Mobile application testing plays a pivotal role in making the mobile applications more reliable and defect free. Existing test automation tools have been tailored to perform mobile test automation through mobile emulators. Other tools require the mobile device where the application is installed, to be connected to a computer so that the tests can be run. Obviously, the results obtained from emulators often differ from those obtained on actual mobile devices. To our best knowledge only a few solutions for creating automated tests of mobile applications exist and their functionality is very limited. In this paper, we introduce the idea of implementing a mobile test automation framework MobTAF which performs mobile test automation on the mobile device where connection to a computer is not required. The framework moves the testing infrastructure to the phone, to support test situations that cannot easily be replicated with an emulator. A prototype application was then implemented to test the mobile automation framework, MobTAF. The results prove that MobTAF framework is an efficient way of performing mobile application tests directly on the mobile devices. &copy; 2012 IEEE.<br/>},
key = {Software testing},
keywords = {Application programs;Automation;Mobile computing;Mobile devices;Telephone sets;},
note = {Automation testing;Mobile application testing;Mobile applications;Mobile device test automations;Mobile test automation frameworks;Mobile testing;Test automation tool;Testing infrastructure;},
URL = {http://dx.doi.org/10.1109/ICCISci.2012.6297158},
} 


@inproceedings{20140917393351 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Static analysis driven cache performance testing},
journal = {Proceedings - Real-Time Systems Symposium},
author = {Banerjee, Abhijeet and Chattopadhyay, Sudipta and Roychoudhury, Abhik},
year = {2013},
pages = {319 - 329},
issn = {10528725},
address = {Vancouver, BC, Canada},
abstract = {Real-time, embedded software are constrained by several non-functional requirements, such as timing. With the ever increasing performance gap between the processor and the main memory, the performance of memory subsystems often pose a significant bottleneck in achieving the desired performance for a real-time, embedded software. Cache memory plays a key role in reducing the performance gap between a processor and main memory. Therefore, analyzing the cache behaviour of a program is critical for validating the performance of an embedded software. In this paper, we propose a novel approach to automatically generate test inputs that expose the cache performance issues to the developer. Each such test scenario points to the specific parts of a program that exhibit anomalous cache behaviour along with a set of test inputs that lead to such undesirable cache behaviour. We build a framework that leverages the concepts of both static cache analysis and dynamic test generation to systematically compute the cache-performance stressing test inputs. Our framework computes a test-suite which does not contain any false positives. This means that each element in the test-suite points to a real cache performance issue. Moreover, our test generation framework provides an assurance of the test coverage via a well-formed coverage metric. We have implemented our entire framework using Chronos worst case execution time (WCET) analyzer and LLVM compiler infrastructure. Several experiments suggest that our test generation framework quickly converges towards generating cache-performance stressing test cases. We also show the application of our generated test-suite in design space exploration and cache performance optimization. &copy; 2013 IEEE.<br/>},
key = {Software testing},
keywords = {Cache memory;Embedded software;Interactive computer systems;Program compilers;Real time systems;Static analysis;},
note = {Cache performance;Design space exploration;Memory subsystems;Non-functional requirements;Performance testing;Static cache analysis;Test generations;Worst-case execution time;},
URL = {http://dx.doi.org/10.1109/RTSS.2013.39},
} 


@inproceedings{20120114656330 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The research and design of NSL-oriented automation testing framework},
journal = {Advances in Intelligent and Soft Computing},
author = {Wang, Chongwen},
volume = {128},
year = {2011},
pages = {367 - 373},
issn = {18675662},
abstract = {By analyzing the Selenium and other open source testing tool, the lack of Selenium and the design of testing scripts are given to discuss and try to improve to resolve problems of NLS. These improvements include the using of page elements, enhancement of the response of the heavyweight component, optimization of testing scripts for multi-language versions. The parallel execution strategy for multilingual test cases has been provided, through which the users can execute test cases of multi-language in a great number of test servers at the same time, greatly improving the overall testing efficiency. The testing framework proposed has been applied to the actual web product globalization testing, and achieved very good results. &copy; Springer-Verlag Berlin Heidelberg 2011.<br/>},
key = {Open source software},
keywords = {Selenium;},
note = {Automation testing;Multi languages;Open sources;Parallel executions;Test case;Testing efficiency;Testing framework;Testing tools;},
URL = {http://dx.doi.org/10.1007/978-3-642-25989-0_60},
} 


@inproceedings{20143518112883 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and implementation of automation testing framework based on keyword driven},
journal = {Applied Mechanics and Materials},
author = {He, Zhong Hai and Zhang, Xiang and Zhu, Xiang Yin},
volume = {602-605},
year = {2014},
pages = {2142 - 2146},
issn = {16609336},
address = {Chongqing, China},
abstract = {For the purpose of settling problems in the present automated testing frameworks, the paper presents an automated testing framework based on keyword driven technology. At first, it summarized and analyzed the recent automated testing frameworks; and then it proposed the framework's system architecture, and also presented the key technology details of the framework. At last, this paper compared this paper's framework with the recent frameworks by the IP phone, which proved that this framework had superiority in reducing the scale of test scripts, raising the overall efficiency of testing and so on. &copy; (2014) Trans Tech Publications, Switzerland.},
key = {Software testing},
keywords = {Materials;Mechanics;},
note = {Automated testing;Automation testing;Design and implementations;Key technologies;Keyword driven;Overall efficiency;System architectures;Test scripts;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/AMM.602-605.2142},
} 


@inproceedings{20124315601080 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling and analysis of CPU usage in safety-critical embedded systems to support stress testing},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Nejati, Shiva and Di Alesio, Stefano and Sabetzadeh, Mehrdad and Briand, Lionel},
volume = {7590 LNCS},
year = {2012},
pages = {759 - 775},
issn = {03029743},
address = {Innsbruck, Austria},
abstract = {Software safety certification needs to address non-functional constraints with safety implications, e.g., deadlines, throughput, and CPU and memory usage. In this paper, we focus on CPU usage constraints and provide a framework to support the derivation of test cases that maximize the chances of violating CPU usage requirements. We develop a conceptual model specifying the generic abstractions required for analyzing CPU usage and provide a mapping between these abstractions and UML/MARTE. Using this model, we formulate CPU usage analysis as a constraint optimization problem and provide an implementation of our approach in a state-of-the-art optimization tool. We report an application of our approach to a case study from the maritime and energy domain. Through this case study, we argue that our approach (1) can be applied with a practically reasonable overhead in an industrial setting, and (2) is effective for identifying test cases that maximize CPU usage. &copy; 2012 Springer-Verlag.<br/>},
key = {Safety engineering},
keywords = {Abstracting;Computer software selection and evaluation;Constrained optimization;Embedded systems;Safety testing;},
note = {Conceptual model;Constraint optimization problems;Industrial settings;Model and analysis;Optimization tools;Safety-critical embedded systems;Software safety;State of the art;},
URL = {http://dx.doi.org/10.1007/978-3-642-33666-9_48},
} 


@article{20123115299507 ,
language = {Japanese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Thermal performance test and thermal environment survey of ceiling radiant cooling system},
journal = {AIJ Journal of Technology and Design},
author = {Ito, Sei and Kawashima, Minoru and Arai, Yoshito and Suzuki, Michiya and Murakami, Koji and Nobe, Tatsuo},
volume = {18},
number = {38},
year = {2012},
pages = {243 - 248},
issn = {13419463},
abstract = {An air conditioning system using ceiling radiant cooling panels and personal floor diffusers is designed. It is assumed that ceiling radiant cooling panels remove a cooling load and personal floor diffusers give both air-conditioned outlet air and an air current feeling for individuals. The experiment facility for the system is constructed, and the thermal performance test and the thermal environment survey are performed. This paper reports the results of the thermal performance test and the thermal environment survey of the system, and shows that the system removes a cooling load properly and can provide the comfortable thermal environment for individuals.<br/>},
key = {Cooling},
keywords = {Air conditioning;Ceilings;Floors;Surveys;},
note = {Air currents;Ceiling radiant cooling panels;Cooling load;Outlet air;Radiant cooling;Thermal environment;Thermal Performance;},
URL = {http://dx.doi.org/10.3130/aijt.18.243},
} 


@inproceedings{20114314452937 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Application of fuzzy and binary algorithm to regulation of load in locomotive load test},
journal = {2011 2nd International Conference on Mechanic Automation and Control Engineering, MACE 2011 - Proceedings},
author = {Tang, Chunqiu and Mo, Yimin and Wen, Zhou},
year = {2011},
pages = {96 - 99},
address = {Inner Mongolia, China},
abstract = {The purpose of locomotive load test is to examine and adjust the capability of locomotive often in its non-driving state, and it is a kind of important standard and means to estimate the quality of repairing locomotive in railway locomotive depot. There are two ways of load test at present. One is the water-resistor load test, the other is the dry resistor load test. Because the dry resistor-load test means does not pollute the environment and needs area less, its developing foreground is immense. To solve the difficulty that the current cannot be freely regulated continuously, for the first time, the model of weightier resistor network in digital circuit is applied to the locomotive dry resistor-load test system, which solves the problem of dry resistor-load test theoretically. It is proved by theory and test that the precision of dry resistor means can meet the request of locomotives constant power load test and reach the standard of water-resistor, so it can serve the application of the dry resistor-load test system. During the locomotive load test, the load of locomotive may be regulated so that the locomotive can be adapted run on all kinds of actual work state. According to the characteristic of weightier resistor, the control arithmetic, which is made up of fuzzy algorithm and binary algorithm, realizes the fast and exact regulation on locomotive load. This paperintroduces how to apply fuzzy and binary algorithm to regulate the dry resistor-load and explains the realization of the fuzzy and binary algorithm. &copy; 2011 IEEE.<br/>},
key = {Testing},
keywords = {Control theory;Engines;Fuzzy sets;Locomotives;Resistors;},
note = {Binary algorithms;Constant power load;Control arithmetic;Fuzzy algorithms;Railway locomotives;Regulation;Resistor load;Resistor network;},
URL = {http://dx.doi.org/10.1109/MACE.2011.5986866},
} 


@inproceedings{20114014404035 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Designing approach analysis on small-scale software performance testing tools},
journal = {Proceedings of 2011 International Conference on Electronic and Mechanical Engineering and Information Technology, EMEIT 2011},
author = {Meng, Xiangfeng},
volume = {8},
year = {2011},
pages = {4254 - 4257},
address = {Harbin, China},
abstract = {Currently, most software performance testing tools in the market are large ones designated for enterprises. Aiming at the demand of small-sized and individual customers' conduction of software performance testing, the paper proposes an approach for designing and realizing a small tool for testing. Core design refers to simulating multi-user concurrent operation by simultaneous execution of multithreading and measuring performance of the system tested through whether each threading responses in a correct manner as well as testing data such as period of responding. Testing tool, which is realized by Java language, consists of three modules of case management, test implementation and test report. Multiple designing modes are utilized in a combined manner during designing, which makes the designing scheme a simple one with high efficiency and easy to expand. The market of performance testing is developing in a rapid manner and researching software performance test is gaining increasingly significance. &copy; 2011 IEEE.<br/>},
key = {Software testing},
keywords = {Commerce;Multitasking;},
note = {Concurrent operations;designing approach;designing mode;Individual customers;Measuring performance;Software performance;Software performance testing;Testing tools;},
URL = {http://dx.doi.org/10.1109/EMEIT.2011.6023983},
} 


@inproceedings{20114014398894 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Recent successes and changes of the HPCMP sustained systems performance test},
journal = {Proceedings - 2010 DoD High Performance Computing Modernization Program Users Group Conference, HPCMP UGC 2010},
author = {Bennett, Paul M. and Brown, Laura L.},
year = {2011},
pages = {453 - 462},
address = {Schaumburg, IL, United states},
abstract = {The sustained systems performance (SSP) test has been implemented on certain High Performance Computing Modernization Program (HPCMP) HPC systems in order to quantitatively evaluate updates to system software, hardware repairs, job queuing policy modifications, and revisions to the job scheduler as necessary. The test employs codes used in the system acquisition cycle with proven migration capability to HPCMP HPC systems and non-empirical tests for numerical accuracy. Metrics such as compilation time, queue wait time, benchmark execution time, and total test throughput time are gathered and compared against metric data from previous tests to monitor the systems under test while minimizing impact to the users. Jobs failing to execute properly or in anomalously short or long times are investigated, and the results are reported to system administrators and center directors at each center for appropriate actions. During the past year, the SSP test has been instrumental in surfacing configuration issues with the PBS scheduler and performance issues on several HPC systems. Additionally, the frequency of the SSP test on systems procured in Technology Insertion 2009 (TI-09) and thereafter has increased, with attendant changes in the test cases comprising the test. The SSP test continues to play an important role in monitoring the quality of service delivering HPC to HPCMP users at the system, DoD Supercomputing Resource Center, and vendor levels. &copy; 2011 IEEE.<br/>},
key = {Software testing},
keywords = {Modernization;Quality of service;Scheduling;},
note = {High performance computing modernization programs;Numerical accuracy;Performance issues;Sustained systems;System acquisition;System administrators;Systems under tests;Technology insertion;},
URL = {http://dx.doi.org/10.1109/HPCMP-UGC.2010.46},
} 


@inproceedings{20132016337943 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The research of performance test method for Linux process scheduling},
journal = {Proceedings of the 2012 4th International Symposium on Information Science and Engineering, ISISE 2012},
author = {Lan, Yuqing and Xu, Hao and Liu, Xiaohui},
year = {2012},
pages = {216 - 219},
address = {Shanghai, China},
abstract = {Performance test plays a fundamental and irreplaceable role in the field of software test, especially in guaranteeing the quality and reliability of an operating system. The performance of the process scheduling subsystem directly affects the accuracy and stability of the whole operating system. Linux operating system vendors execute performance test almost in every period of the Linux operating system research and development to enhance their products' competitiveness. However, the lack of methods and tools for the Linux process scheduling performance test has caused great difficulties for Linux operating system vendors to evaluate and tune the Linux kernel performance. Therefore, in order to solve the issues mentioned above, this paper, based on the analysis of Linux process scheduling mechanism, proposes a Linux process scheduling performance test method, implements a Linux process scheduling performance test tool as well, and finally validates the tool experimentally. &copy; 2012 IEEE.},
key = {Computer operating systems},
keywords = {Benchmarking;Competition;Information science;Scheduling;Software reliability;Software testing;},
note = {Benchmark tests;linux;Performance analysis;Performance testing;Process scheduling;},
URL = {http://dx.doi.org/10.1109/ISISE.2012.54},
} 


@inproceedings{20125015790116 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Building a TaaS platform for web service load testing},
journal = {Proceedings - 2012 IEEE International Conference on Cluster Computing, CLUSTER 2012},
author = {Yan, Minzhi and Sun, Hailong and Wang, Xu and Liu, Xudong},
year = {2012},
pages = {576 - 579},
address = {Beijing, China},
abstract = {Web services are widely known as the building blocks of typical service oriented applications. The performance of such an application system is mainly dependent on that of component web services. Thus the effective load testing of web services is of great importance to understand and improve the performance of a service oriented system. However, existing Web Service load testing tools ignore the real characteristics of the practical running environment of a web service, which leads to inaccurate test results. In this work, we present WS-TaaS, a load testing platform for web services, which enables load testing process to be as close as possible to the real running scenarios. In this way, we aim at providing testers with more accurate performance testing results than existing tools. WS-TaaS is developed on the basis of our existing Cloud PaaS platform: Service4All. First, we provide detailed analysis of the requirements of Web Service load testing and present the conceptual architecture and design of key components. Then we present the implementation details of WS-TaaS on the basis of Service4All. Finally, we perform a set of experiments based on the testing of real web services, and the experiments illustrate that WS-TaaS can efficiently facilitate the whole process of Web Service load testing. &copy; 2012 IEEE.},
key = {Websites},
keywords = {Cloud computing;Cluster computing;Experiments;Load testing;Web services;},
note = {Accurate performance;Application systems;Building blockes;Conceptual architecture;Service loads;Service oriented application;Service Oriented Systems;Testing platforms;Testing process;Testing tools;Whole process;},
URL = {http://dx.doi.org/10.1109/CLUSTER.2012.20},
} 


@inproceedings{20130916048989 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Thermal performance testing of a high-temperature ESP motor for SAGD applications},
journal = {Proceedings - SPE Annual Technical Conference and Exhibition},
author = {Waldner, Leon and Wonitoy, Kelvin and Klaczek, Wayne and Noonan, Shauna},
volume = {6},
year = {2012},
pages = {4636 - 4644},
address = {San Antonio, TX, United states},
abstract = {During 2012, BakerHughes, ConocoPhillips and Nexen Inc. continued their research partnership [Waldner 2011] with a new experimental test program focused on the thermal performance of Electric Submersible Pump (ESP) systems for Steam Assisted Gravity Drainage (SAGD) applications, which was completed in the high-temperature flow loop at C-FER Technologies. Accurately monitoring the internal temperature of the ESP motor is a key consideration when trying to increase the operational longevity of an ESP system for any application; however, as the SAGD process develops, understanding this temperature profile has become more critical. This test program included several tests at various fluid temperatures and ESP operating conditions that helped determine the thermal performance of the ESP motor. Another unique aspect of this test program was the incorporation of two different temperature monitoring methods at approximately the same position on the internal and external base of the ESP motor: one internal probe positioned near the motor windings via a fiber optic sensor and one external skin temperature RTD positioned on the motor surface to monitor this important temperature differential. This paper presents the equipment and instrumentation used, and demonstrates some of the more interesting test results, thus providing further insight into the thermal performance of this ESP motor under representative SAGD conditions between 220&deg;C (428&deg;F) and 250&deg;C (482&deg;F). Copyright 2012, Society of Petroleum Engineers.},
key = {Mixed convection},
keywords = {Exhibitions;Temperature measuring instruments;Test facilities;},
note = {ConocoPhillips;Electric submersible pumps;Experimental test;Fluid temperatures;High temperature;High-temperature flows;Internal temperature;Motor windings;Operating condition;Skin temperatures;Steam-assisted gravity drainages;Temperature differential;Temperature monitoring;Temperature profiles;Test program;Thermal Performance;Thermal performance testing;},
} 


@inproceedings{20105013485991 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {XACML policy performance evaluation using a flexible load testing framework},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
author = {Butler, Bernard and Jennings, Brendan and Botvich, Dmitri},
year = {2010},
pages = {648 - 650},
issn = {15437221},
abstract = {The performance and scalability of access control systems is growing more important as organisations deploy ever more complex communications and content management systems. Fine-grained access control is becoming more pervasive, so decisions are more frequent and policy sets are larger. We outline a flexible performance testing framework that accepts XACML PDP implementations (in the server component) and submits representative access control requests (from the client component) in a representative temporal ordering. The framework includes instrumentation and analysis modules to support performance experiments. We describe an initial realization of the framework and report on initial experiments comparing the performance of the SunXACML and Enterprise XACML PDPs.<br/>},
key = {Access control},
keywords = {Distributed computer systems;Load testing;},
note = {Access control policies;Content management system;Performance and scalabilities;Performance evaluations;Performance experiment;Performance testing framework;Server components;Testing framework;},
URL = {http://dx.doi.org/10.1145/1866307.1866385},
} 


@inproceedings{20102913088766 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A methodology to support load test analysis},
journal = {Proceedings - International Conference on Software Engineering},
author = {Malik, Haroon},
volume = {2},
year = {2010},
pages = {421 - 424},
issn = {02705257},
address = {Cape Town, South africa},
abstract = {Performance analysts rely heavily on load testing to measure the performance of their applications under a given load. During the load test, analyst strictly monitor and record thousands of performance counters to measure the run time system properties such as CPU utilization, Disk I/O, memory consumption, network traffic etc. The most frustrating problem faced by analysts is the time spent and complexity involved in analysing these huge counter logs and finding relevant information distributed across thousands of counters. We present our methodology to help analysts by automatically identifying important performance counters for load test and comparing them across tests to find performance gain/loss. Further, our methodology help analysts to understand the root cause of a load test failure by finding previously solved problems in test repositories. A case study on load test data of a large enterprise application shows that our methodology can effectively guide performance analysts to identify and compare top performance counters across tests in limited time thereby archiving 88% counter data reduction. &copy; 2010 ACM.<br/>},
key = {Principal component analysis},
keywords = {Automation;Load testing;Radiation counters;Software engineering;Testing;},
note = {CPU utilization;Large enterprise;Memory consumption;Network traffic;Performance counters;Performance Gain;Run time systems;Test analysis;},
URL = {http://dx.doi.org/10.1145/1810295.1810408},
} 


@inproceedings{20083211434602 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Software realization and performance testing of des cryptographic algorithm on the .NET platform},
journal = {The Experience of Designing and Application of CAD Systems in Microelectronics - Proceedings of the 9th International Conference, CADSM 2007},
author = {Yakovyna, Vitaly and Fedasyuk, Dmytro and Seniv, Maxym},
year = {2007},
pages = {386 - 388},
address = {Lviv-Polyana, Ukraine},
abstract = {The software realization of DES symmetric encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested and it was shown, that the encryption rate is 11.1 Mb/sec on the Intel Celeron D 351 3.2GHz processor, while the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.<br/>},
key = {Cryptography},
keywords = {Computer aided design;Microelectronics;Software testing;},
note = {.NET;CryptoAPI;Cryptographic algorithms;Cryptographic software;DES algorithms;Development environment;Software implementation;Symmetric cryptography;},
URL = {http://dx.doi.org/10.1109/CADSM.2007.4297591},
} 


@article{20100512678735 ,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Application study on new flexible pressure sensor array in stress test of wind turbine blades},
journal = {Yi Qi Yi Biao Xue Bao/Chinese Journal of Scientific Instrument},
author = {Yue, Fengying and Li, Yonghong and Wang, Zhongshan and Wang, Enhuai},
volume = {30},
number = {SUPPL. 2},
year = {2009},
pages = {173 - 176},
issn = {02543087},
abstract = {It introduces a skin sensor array based on MEMS flexible belt pressure sensor and its composition. It introduces a stress test system applying to wind turbine blade in according with test requirement of stress analysis of large wind generator blade. It gives composition principles of the system physical picture and a part of test results Experiment shows the forces testing method using in the blade of wind power-generation is novel and workable and provides an effective means for blades design and experimental test.<br/>},
key = {Turbomachine blades},
keywords = {Belts;Electric power generation;Pressure;Pressure sensors;Sensors;Stress analysis;Testing;Turbine components;Wind power;Wind turbines;},
note = {Application studies;Experimental test;Flexible pressure sensors;Physical pictures;Test requirements;Testing method;Wind generator systems;Wind turbine blades;},
} 


@article{20073710811107 ,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Development of client-oriented computer integrated test and control system for thermal performance test},
journal = {Yi Qi Yi Biao Xue Bao/Chinese Journal of Scientific Instrument},
author = {Li, Fang and Weng, Wenbing and Wang, Hengshan and Liu, Zhanjie},
volume = {28},
number = {8},
year = {2007},
pages = {1445 - 1450},
issn = {02543087},
abstract = {High precision air conditioner performance test equipment should have good test and control means and client-friendly test software. The factors that influence air conditioner test precision were analyzed and a test and control system was designed. The test and control system is based on client-oriented principle; high performance measurement sensors, automatic control elements and touch-screen monitor are adopted, and critical control and data-acquisition software is written, which makes the system have good control precision, convenient operation, friendly interface and reliable performance. The system has been applied successfully in several air conditioner test equipment.},
} 


@article{20080111005563 ,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {BES III offline software system and performance test},
journal = {Hedianzixue Yu Tance Jishu/Nuclear Electronics and Detection Technology},
author = {Sun, Yong-Zhao and Li, Wei-Dong and Mao, Ze-Pu and Ma, Qiu-Mei and Ma, Xiang and Wang, Liang-Liang and Wang, Ji-Ke and Deng, Zi-Yan and You, Zheng-Yun and Wen, Shuo-Pin and Bian, Jian-Ming and Sun, Sheng-Sen and Zhu, Yong-Sheng and Liu, Huai-Min and Liu, Chun-Xiu and Wu, Ling-Hui and Li, Hai-Bo and Li, Gang and Zhang, Chang-Chun and Zhang, Ling and Zhang, Yao and Zhang, Xue-Yao and Zhang, Jian-Yong and Zou, Jia-Heng and Qiu, Jin-Fa and He, Miao and He, Kang-Lin and Ji, Xiao-Bin and Yang, Ming and Yuan, Chang-Zheng and Mao, Ya-Jun and Yu, Guo-Wei and Mo, Xiao-Hu and Yuan, Ye and Cao, Guo-Fu and Huang, Bin and Xie, Yu-Guang and Zang, Shi-Lei},
volume = {27},
number = {5},
year = {2007},
pages = {842 - 846},
issn = {02580934},
abstract = {The offline software for the BESIII experiment and the control flow for data processing are described. With the software tool, Tuning and Analysis Utilities (TAU), its system performance has been measured. The BESIII computing requirements have been re-estimated and results are consistent with the previous calculation in the BESIII Technical Design Report.},
} 


@inproceedings{20085211804750 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Scheduling in performance test environment},
journal = {SoftCom 2008: 16th International Conference on Software, Telecommuncations and Computer Networks},
author = {Bozoki, Ferenc and Csondes, Tibor},
year = {2008},
pages = {404 - 408},
address = {Split-Dubrovnik, Croatia},
abstract = {Nowadays automatic testing is getting more and more important in the telecommunication world. The sooner a fault is discovered the cheaper it is to correct it. If a fault is discovered during the development process the cost of the correction is significantly smaller. There are different test strategies, with different approaches like, Conformance Test, System Test and Performance Test. The System Test takes place after a successful Conformance Test. Performance Test is analyzing the load characteristics of the System Under Test (SUT). In this article we describe the main attributes of performance testing, where the main challenge is to generate the expected load without having as complex hardware as the SUT is itself. Most of the papers, presented in this subject are focusing on the characteristics of the generated load, but not the way how to achieve it. These papers usually have the assumption that the load can be generated by deploying more hardware resources. Other papers propose new extensions for test description languages such SDL or TTCN-3 [4]. In this article we intend to describe a Finite State Machine (FSM) based model and an algorithm which improves the efficiency of Scheduling in this Performance Test environment. We present an architecture based on the so called Virtual Threads, an algorithm to optimize the scheduling between these threads, and an example to demonstrate the algorithm.<br/>},
key = {Load testing},
keywords = {Automatic testing;Computer hardware;Computer networks;Hardware;Scheduling;Software testing;},
note = {Architecture-based;Description languages;Development process;Hardware resources;Load characteristics;Performance testing;Performance tests;System under test;},
URL = {http://dx.doi.org/10.1109/SOFTCOM.2008.4669519},
} 


@article{20091011939177 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {CLIF, a framework based on Fractal for flexible, distributed load testing},
journal = {Annales des Telecommunications/Annals of Telecommunications},
author = {Dillenseger, Bruno},
volume = {64},
number = {1-2},
year = {2009},
pages = {101 - 120},
issn = {00034347},
abstract = {The context of this work is performance evaluation of IT systems based on load testing. It typically consists in generating a flow of requests on a system under test, and to measure response times, request throughput, or computing resource usage. A quick overview of available load testing platforms shows that there exist hundreds of such platforms, including in the open source domain. However, many testers still tend to develop their own ad hoc load testing tooling. Why? This paper starts by looking for possible answers to this question, in order to introduce the CLIF load injection framework, which intends not to be yet another load testing platform. Based on the Fractal component model, the CLIF open source project aims at addressing key issues such as flexibility, adaptation, and scalability. We give here details about CLIF's architecture and associated tools as well as some feedback from a bunch of practical utilizations. &copy; 2008 Institut TELECOM and Springer-Verlag.<br/>},
key = {Load testing},
keywords = {Fractals;Open source software;Software testing;},
note = {Component-based software engineering;Computing resource;Distributed systems;Fractal component models;IS performance evaluation;Open source projects;Performance evaluations;Testing platforms;},
URL = {http://dx.doi.org/10.1007/s12243-008-0067-9},
} 


@inproceedings{20104413349348 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A reactivity-based framework of automated performance testing for web applications},
journal = {Proceedings - 9th International Symposium on Distributed Computing and Applications to Business, Engineering and Science, DCABES 2010},
author = {Gao, Tiantian and Ge, Yujia and Wu, Gongxin and Ni, Jinlong},
year = {2010},
pages = {593 - 597},
abstract = {To improve the reliability and feasibility of web applications, performance testing is very important for satisfying users. For reducing the cost and improve the efficiency of performance testing, we propose a new reactivity-based performance testing framework in this paper. We also provide a complete approach to generate test cases automatically from original web logs. First our approach retrieves user patterns through logs at the server side. Then, metrics derived from users' perspective are applied and usage pattern from client side are gained. At last test case can be generated automatically by solving an optimization problem through an evolutionary algorithm. &copy; 2010 IEEE.},
key = {Automatic test pattern generation},
keywords = {Distributed computer systems;Optimization;Web crawler;},
note = {Automated test case generation;Optimization problems;Performance testing;Performance testing framework;Server sides;Testing framework;Usage patterns;WEB application;},
URL = {http://dx.doi.org/10.1109/DCABES.2010.127},
} 


@inproceedings{20083911593688 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Load testing an AJAX application},
journal = {Proceedings of the International Conference on Information Technology Interfaces, ITI},
author = {Habul, Aida and Kurtovic, Ezudin},
year = {2008},
pages = {729 - 732},
issn = {13301012},
address = {Cavtat/Dubrovnik, Croatia},
abstract = {This paper presents a methodology for load testing an Ajax application. WebLOAD, an open source tool for performance testing, is used to simulate a huge number of client requests to the server. The load testing is used to evaluate and compare different scenarios on the system performance. In order to avoid misleading results, load testing of Ajax applications should incorporate not only server-side but also clientside code, because it can have a significant impact in determining the generated load.<br/>},
key = {Load testing},
note = {Ajax;Client request;Client sides;Open source tools;Performance testing;Server sides;Work-load models;},
URL = {http://dx.doi.org/10.1109/ITI.2008.4588501},
} 


@inproceedings{20080311027892 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Wireless communication system automation testing framework},
journal = {2007 International Conference on Wireless Communications, Networking and Mobile Computing, WiCOM 2007},
author = {Liu, Lan and Wei, Wenguo and Li, Jiachun},
year = {2007},
pages = {2981 - 2984},
address = {Shanghai, China},
abstract = {This article intends to introduce a leading next generation wireless protocol oriented automation testing framework-WiCAT system. This framework supports multiple protocol messaging testing by simulating the wireless equipments and implementing the telecommunication system logic. WiCAT provides high-efficiency and low-cost performance basing on a distributed, expandable and extensible architecture. &copy; 2007 IEEE.},
key = {Wireless telecommunication systems},
keywords = {Automation;Message passing;Mobile devices;Network protocols;},
note = {Automation testing;Wireless equipments;Wireless protocols;},
URL = {http://dx.doi.org/10.1109/WICOM.2007.740},
} 


@inbook{20172403758303 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Study on the Establishment of Dynamic Performance Test Environment for the Digital Protective Relay using RTDS},
journal = {Power Plants and Power Systems Control 2006},
author = {Jang, ByungTae and Choe, ChangYoul and Jung, GilJo},
year = {2007},
pages = {143 - 146},
abstract = {This chapter presents a study on the establishment of dynamic performance test environment for the digital protective relay using real time digital simulator (RTDS). A performance test of digital protective relay is divided into three parts, which include a static test, a dynamic test, and EMC test. Among these, a dynamic test the most important, but it is not easy to diffuse a technique for dynamic test because of the intricate approach to real time digital simulator. To solve these problems, Korea Electric Power Research Institute (KEPRI) has established environments for performance test, which consist of a system model and a performance test procedure for the dynamic test. Differing from the general test equipment, RTDS has a strong point to examine real time close-loop test. Since users should articulately use both software (PSCAD) and hardware (RTDS), it is difficult for the users to access a dynamic performance test. The system modeling was performed by using equivalent impedance data of transmission line, equivalent impedance data of bus, and no load loss data of transformer. When carrying out performance test of the digital protective relay by using RTDS in domestic and overseas organizations, engineers can utilize this procedure for examining reliability and propriety in terms of the result of performance verification test. &copy; 2007 Elsevier Ltd All rights reserved.},
key = {Software testing},
keywords = {Electric fault currents;Electromagnetic compatibility;Equipment testing;Equivalent circuits;Mechanisms;Relay protection;},
note = {Digital protective relay;Dynamic performance tests;Equivalent impedance;Korea electric power research institutes;Performance tests;Performance verification;Real time digital simulator;Test equipments;},
URL = {http://dx.doi.org/10.1016/B978-008046620-0/50024-4},
} 


@inproceedings{20063010030632 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Using genetic algorithms for early schedulability analysis and stress testing in real-time systems},
journal = {Genetic Programming and Evolvable Machines},
author = {Briand, Lionel C. and Labiche, Yvan and Shousha, Marwa},
volume = {7},
number = {2},
year = {2006},
pages = {145 - 170},
issn = {13892576},
abstract = {Reactive real-time systems have to react to external events within time constraints: Triggered tasks must execute within deadlines. It is therefore important for the designers of such systems to analyze the schedulability of tasks during the design process, as well as to test the system's response time to events in an effective manner once it is implemented. This article explores the use of genetic algorithms to provide automated support for both tasks. Our main objective is then to automate, based on the system task architecture, the derivation of test cases that maximize the chances of critical deadline misses within the system; we refer to this testing activity as stress testing. A second objective is to enable an early but realistic analysis of tasks' schedulability at design time. We have developed a specific solution based on genetic algorithms and implemented it in a tool. Case studies were run and results show that the tool (1) is effective at identifying test cases that will likely stress the system to such an extent that some tasks may miss deadlines, (2) can identify situations that were deemed to be schedulable based on standard schedulability analysis but that, nevertheless, exhibit deadline misses.},
key = {Genetic algorithms},
keywords = {Real time systems;Scheduling;Stress analysis;Systems analysis;},
note = {Critical deadline;Schedulability theory;Software verification and validation;System task architecture;},
URL = {http://dx.doi.org/10.1007/s10710-006-9003-9},
} 


@inproceedings{20090111821844 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic identification of load testing problems},
journal = {IEEE International Conference on Software Maintenance, ICSM},
author = {Jiang, Zhen Ming and Hassan, Ahmed E. and Hamann, Gilbert and Flora, Parminder},
year = {2008},
pages = {307 - 316},
address = {Beijing, China},
abstract = {Many software applications must provide services to hundreds or thousands of users concurrently. These applications must be load tested to ensure that they can function correctly under high load. Problems in load testing are due to problems in the load environment, the load generators, and the application under test. It is important to identify and address these problems to ensure that load testing results are correct and these problems are resolved. It is difficult to detect problems in a load test due to the large amount of data which must be examined. Current industrial practice mainly involves time-consuming manual checks which, for example, grep the logs of the application for error messages. In this paper, we present an approach which mines the execution logs of an application to uncover the dominant behavior (i.e., execution sequences) for the application and flags anomalies (i.e., deviations) from the dominant behavior. Using a case study of two open source and two large enterprise software applications, we show that our approach can automatically identify problems in a load test. Our approach flags &lt; 0.01% of the log lines for closer analysis by domain experts. The flagged lines indicate load testing problems with a relatively small number of false alarms. Our approach scales well for large applications and is currently used daily in practice. &copy; 2008 IEEE.<br/>},
key = {Load testing},
keywords = {Automation;Computer software maintenance;Enterprise software;Open source software;Open systems;Software testing;},
note = {Application under tests;Automatic identification;Domain experts;Execution sequences;Industrial practices;Large enterprise;Number of false alarms;Software applications;},
URL = {http://dx.doi.org/10.1109/ICSM.2008.4658079},
} 


@inproceedings{2005249153844 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {DiPerF: An automated distributed Performance testing framework},
journal = {Proceedings - IEEE/ACM International Workshop on Grid Computing},
author = {Dumitrescu, Catalin and Raicu, Ioan and Ripeanu, Matei and Foster, Ian},
year = {2004},
pages = {289 - 296},
issn = {15505510},
address = {Pittsburgh, PA, United states},
abstract = {We present DiPerF, a distributed performance-testing framework, aimed at simplifying and automating service performance evaluation. DiPerF coordinates a pool of machines that test a target service, collects and aggregates performance metrics, and generates performance statistics. The aggregate data collected provide information on service throughput, on service 'fairness' when serving multiple clients concurrently, and on the impact of network latency on service performance. Furthermore, using this data, it is possible to build predictive models that estimate a service performance given the service load. We have tested DiPerF on 100+ machines on two testbeds, Grid3 and PlanetLab, and explored the performance of job submission services (pre-WS GRAM and WS GRAM) included with Globus Toolkit&reg; 3.2. &copy; 2004 IEEE.},
key = {Distributed computer systems},
keywords = {Automation;Benchmarking;Data acquisition;Data reduction;HTTP;Local area networks;Mathematical models;Metric system;Quality of service;Synchronization;},
note = {DiPerF;Job submission services;Performance testing framework;Target services;},
URL = {http://dx.doi.org/10.1109/GRID.2004.21},
} 


@inproceedings{20151000615046 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Galileo test range: Performance test results},
journal = {ENC-GNSS 2008 - European Navigation Conference},
author = {Gottifredi, F. and Martinino, F. and Morante, Q. and Eleuteri, M. and Varriale, E. and Valle, V. and Pesci, G.},
year = {2008},
address = {Toulouse, France},
abstract = {The Galileo Test Range (GTR) project is an initiative of Regione Lazio in the frame of its support to the Italian technical research and innovation in satellite navigation. It is born as the Italian National permanent Laboratory for the experimentation and analysis of the Galileo Signal, for testing and certification of user terminals and support services for the development of application services. The development of the GTR is foreseen in two phases: - Phase A = Definition and Start up: implementation of the initial system, based on the generation on ground of navigation signals (GPS-like), using pseudolite technology (4 PSL), and to receive real signals coming from GPS, EGNOS and the new GIOVE-A Experimental Satellite. - Phase B = Full deployment and initialization of the GTR: implementation of the GTR final configuration, not only able to generate Galileo-like signals (from 9 PSL), but also to receive and process real signals coming from Galileo IOV satellites. The Phase A architecture is composed by the following macro segments: - The Analysis &amp; Control Centre composed by the Control Centre (CC) and all the specialized laboratories (i.e. Time, Orbitography, Synchronization, Integrity, R&amp;D); - The Experimental Area (covered by Differential Reference Stations) including the Test Area (covered by the Pseudolites - PSL) The 4 PSL deployed for the Phase A (2 fixed and 2 transportable) are equipped with the following main elements: &bull; an atomic reference clock composed by an OCXO locked to Rb oscillator in order to obtain good short and long term stability; &bull; a dual frequency GPS/SBAS Receiver Assembly; &bull; a GPS-like signal generator &bull; a directional antenna to disseminate the GPS-Like signal in the Test Area The PSL Receiver observables are sent to the GTR-CC and then to the Orbitography Laboratory Facility in charge of the Time Synchronization function of the GTR based on the SynchroNet product of TAS-I. The reference for this Synchronization is given by the Time Laboratory Facility, equipped with an Active Hydrogen Maser and 4 Caesium Clocks. The clock corrections are sent back to the PSL, uploaded in the Navigation Message and broadcasted to the Users in the Test Area. Users equipped with a GPS Receiver can connect it to a PC with a dedicated software (developed by TAS-I) that makes a data fusion between GPS satellites observables and PSL ones so as to compute a better 3D position. If required, the SW can compute a 2D solution using only the Pseudolite observables, Users can compute a 2D position. The PSLs guarantee in a flexible way, thanks to the transportable PSLs, an increased availability of GNSS-like signals in the Test Area that users can use to improve theirs navigation performances. The tests carried out show that the achievable performance in the Test Area with the 4 PSL of Phase A are in the order of 5 m in 3D and 3 m in 2D. With the upgrade foreseen in Phase B in number and type of signal, the performance achievable will improve and potential applications can be satisfied with the use of the PSL technology. The aims of this paper are to present the advantages of the availability of signals generated by PSLs (fixed and transportable) in a controlled area and to present the reached performances for the phase A of the GTR using PSLs. Furthermore it will be presented an overview on the potential applications for this technology that can be a good solution for all those environments that require augmentations in performance and availability (i.e. urban canyons, harbors, container movement, etc&mellip;).},
key = {Global positioning system},
keywords = {Clocks;Data fusion;Directive antennas;Geostationary satellites;Hydrogen masers;Laboratories;Navigation;Orbits;Satellites;Signal receivers;Synchronization;Testing;},
note = {Achievable performance;Application services;Laboratory facilities;Long term stability;Navigation messages;Navigation performance;Satellite navigation;Time synchronization;},
} 


@inproceedings{20152500949640 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Practical end-to-end performance testing tool for high speed 3G-based networks},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Shinbo, Hiroyuki and Tagami, Atsushi and Ano, Shigehiro and Hasegawa, Toru and Suzuki, Kenji},
volume = {6435},
year = {2010},
pages = {205 - 220},
issn = {03029743},
address = {Natal, Brazil},
abstract = {High speed IP communication is a killer application for 3rd generation (3G) mobile systems. Thus 3G network operators should perform extensive tests to check whether expected end-to-end performances are provided to customers under various environments. An important objective of such tests is to check whether network nodes fulfill requirements to durations of processing packets because a long duration of such processing causes performance degradation. This requires testers (persons who do tests) to precisely know how long a packet is hold by various network nodes. Without any tool&rsquo;s help, this task is time-consuming and error prone. Thus we propose a multi-point packet header analysis tool which extracts and records packet headers with synchronized timestamps at multiple observation points. Such recorded packet headers enable testers to calculate such holding durations. The notable feature of this tool is that it is implemented on off-the shelf hardware platforms, i.e., lap-top personal computers. The key challenges of the implementation are precise clock synchronization without any special hardware and a sophisticated header extraction algorithm without any drop &copy; IFIP International Federation for Information Processing 2010.},
key = {3G mobile communication systems},
keywords = {Clocks;Computer hardware;Hardware;Mechanical clocks;Personal computers;Software testing;Synchronization;Technology transfer;},
note = {Clock Synchronization;End-to-end performance;Header extraction;IP communications;Killer-application;Off-the-shelf hardwares;Packet header;Performance degradation;},
} 


@inproceedings{20103713223214 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Load testing and performance monitoring tools in use with AJAX based web applications},
journal = {MIPRO 2010 - 33rd International Convention on Information and Communication Technology, Electronics and Microelectronics, Proceedings},
author = {Krizanic, J. and Grguric, A. and Momondor, M. and Lazarevski, P.},
year = {2010},
pages = {428 - 434},
address = {Opatija, Croatia},
abstract = {In order to deliver quality assured software and avoid potential costs caused by unstable software, software testing is essential in software lifecycle. Load testing is one of the testing types with high importance. It is usually accompanied by performance monitoring of the hosting environment. In the case of web applications which are today widely used, one fact is obvious: most of web applications are public and used by vast number of users, which are making a considerable traffic load on hosting environments and web applications. Load testing and performance monitoring become facilitated with existing tools aimed for load testing and performance monitoring. In the paper we analyze and compare several existing tools which facilitate load testing and performance monitoring, in order to find the most appropriate tools by criteria such as ease of use, supported features, and license. Selected tools were put in action in the real environment, through several web applications. For the case study one of the web applications is used in order to introduce different capabilities of tools, including distributed testing, assembling of test scenario from previously recorded usage scenarios, security support, results analysis, monitoring of key parameters, and reporting and alerting about changes of these parameters.<br/>},
key = {Load testing},
keywords = {Microelectronics;Monitoring;Software testing;},
note = {AJAX;Distributed testing;Performance monitoring;Real environments;Security support;Software life cycles;Usage scenarios;WEB application;},
} 


@inproceedings{20083211434604 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {The Performance testing of RSA algorithm software realization},
journal = {The Experience of Designing and Application of CAD Systems in Microelectronics - Proceedings of the 9th International Conference, CADSM 2007},
author = {Yakovyna, Vitaly and Fedasyuk, Dmytro and Seniv, Maxym and Bilas, Orest},
year = {2007},
pages = {390 - 392},
address = {Lviv-Polyana, Ukraine},
abstract = {The software realization of RSA public key encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested. The present paper shows, that the encryption rate is 306.4&plusmn;0.6 kbytes/sec, while the coefficient of encryption time increasing with file size increasing is 3.299. It is concluded that the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.<br/>},
key = {Computer aided design},
keywords = {Microelectronics;Public key cryptography;Software testing;},
note = {.NET;Cryptographic software;Development environment;Flexible architectures;Operation performance;Public key encryption algorithms;RSA algorithms;Software implementation;},
URL = {http://dx.doi.org/10.1109/CADSM.2007.4297593},
} 


@inproceedings{2005028788142 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Architecture and performance testing of a software GPS receiver for space-based applications},
journal = {IEEE Aerospace Conference Proceedings},
author = {Gold, Kenn and Brown, Alison},
volume = {4},
year = {2004},
pages = {2404 - 2415},
issn = {1095323X},
address = {Big Sky, MT, United states},
abstract = {Space-based GPS technology presents significant challenges over Earth-based systems. These include visibility issues for rotating platforms and tracking of GPS satellites from spacecraft that are in higher orbits than the GPS, realtime resolution of carrier phase ambiguities, and different dynamics during various mission phases. NAVSYS has developed a software GPS receiver that makes use of 3-dimensional Digital Beam Steering technology and inertial aiding to address these issues. This approach offers several advantages including all around visibility for spinning satellites, tracking of weak GPS signals, reduction of multipath, and reprogrammability to accommodate different mission phases. Additionally, a suite of simulation tools based around the NAVSYS Matlab Toolbox and Advanced GPS Hybrid Simulation products have been built to allow testing for simulated space environments. The receiver architecture and test tools are described in this paper.},
key = {Global positioning system},
keywords = {Computer architecture;Computer simulation;Computer software;Orbits;Satellites;Signal processing;Signal to noise ratio;Space applications;},
note = {Digital beam steering technology;Goddard space flight center (GSFC);Precision applications;Satellite signals;},
URL = {http://dx.doi.org/10.1109/AERO.2004.1368035},
} 


@inproceedings{20105013472951 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Practical end-to-end performance testing tool for high speed 3G-based networks},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Shinbo, Hiroyuki and Tagami, Atsushi and Ano, Shigehiro and Hasegawa, Toru and Suzuki, Kenji},
volume = {6435 LNCS},
year = {2010},
pages = {205 - 220},
issn = {03029743},
abstract = {High speed IP communication is a killer application for 3rd generation (3G) mobile systems. Thus 3G network operators should perform extensive tests to check whether expected end-to-end performances are provided to customers under various environments. An important objective of such tests is to check whether network nodes fulfill requirements to durations of processing packets because a long duration of such processing causes performance degradation. This requires testers (persons who do tests) to precisely know how long a packet is hold by various network nodes. Without any tool's help, this task is time-consuming and error prone. Thus we propose a multi-point packet header analysis tool which extracts and records packet headers with synchronized timestamps at multiple observation points. Such recorded packet headers enable testers to calculate such holding durations. The notable feature of this tool is that it is implemented on off-the shelf hardware platforms, i.e., lap-top personal computers. The key challenges of the implementation are precise clock synchronization without any special hardware and a sophisticated header extraction algorithm without any drop. &copy; 2010 IFIP International Federation for Information Processing.<br/>},
key = {3G mobile communication systems},
keywords = {Computer hardware;Hardware;Mechanical clocks;Personal computers;Software testing;Synchronization;Technology transfer;},
note = {Clock Synchronization;End-to-end performance;Header extraction;IP communications;Killer-application;Off-the-shelf hardwares;Packet header;Performance degradation;},
URL = {http://dx.doi.org/10.1007/978-3-642-16573-3_15},
} 


@inproceedings{20084811737731 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A configurable web service performance testing framework},
journal = {Proceedings - 10th IEEE International Conference on High Performance Computing and Communications, HPCC 2008},
author = {Jingmin, Xie and Xiaojun, Ye and Li, Bin and Feng, Xie},
year = {2008},
pages = {312 - 319},
address = {Dalian, China},
abstract = {More and more softwares based on web service technologies are developed. Before their releases on the Internet, it is necessary to evaluate these systems' performance, especially their response time under different workload pressures. However, existing performance testing benchmarks and tools for web service applications are difficult to adapt to various user-specific testing purposes. This paper proposes a configurable web service performance testing framework which contains client module, application server module and database module. Client module, by using the network cooperation method that one central client drives several other clients, adapts to a great number of concurrent customers to request web services. Application server module contains web services under testing and external supporting web services, each of which is configured as a plug-in. The process to realize mixed ratio of web service interactions is similar to dealing cards and adapts to different commercial application characteristics. In database module, the data model including table and attribute dependence can be customized, and the data scale initialization can be resized according to the topology of above dependence. As such, this framework allows testers to dynamically define their data model, customize their scale of database, configure their transaction characteristics, deploy their application strategies and confirm their performance metrics. &copy; 2008 IEEE.<br/>},
key = {Web services},
keywords = {Benchmarking;Database systems;Digital storage;Topology;Websites;},
note = {Application Servers;Application strategies;Commercial applications;Performance metrics;Service interaction;Service performance;Web service applications;Web service technology;},
URL = {http://dx.doi.org/10.1109/HPCC.2008.53},
} 


@inproceedings{20094512426132 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Ultraviolet through infrared imager performance testing},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Mazzetta, Jason A. and Scopatz, Stephen D.},
volume = {7481},
year = {2009},
pages = {SPIE Europe - },
issn = {0277786X},
address = {Berlin, Germany},
abstract = {The objective of any imaging system is to optimize the amount of pertinent information collected from a scene. Whether it is used for artistic reproduction, scientific research, or camouflage detection, a camera has the same ultimate requirement. In the era of broadband, multi-spectral, hyperspectral, and fused sensor systems, both spectral and spatial data continue to play battling roles in determining which is dominant in how well an imaging system meets its definitive objective. Typically sensor testing requires hardware and software exclusively designed for the spectral region of interest. Thus an imaging system with ultraviolet through infrared imaging capabilities could require three or more separate test benches for sensor characterization. Obviously this not only increases the complexity, and subsequently the cost of testing, but also more importantly tends to produce discontinuous results. This paper will outline the hardware and software developed by the authors that employ identical test methods and shared optics to complete infrared, visible, and ultraviolet sensor performance analysis. Challenges encompassing multiple emitting source switching, splitting, and combining will be addressed along with new single fused type source designs. Decisions related to specifying optics and targets of sufficient quality and construction to provide coverage of the full spectral region will be discussed along with sample performance specifications and data. Test methodology controlled by a single automated software suite will be summarized including modulation transfer function, signal to noise ratio, uniformity, focus, distortion, intrascene dynamic range, and sensitivity. Selected examples of results obtained by this test set will be presented. &copy; 2009 SPIE.<br/>},
key = {Signal to noise ratio},
keywords = {Hardware;Hyperspectral imaging;Image segmentation;Imaging systems;Infrared devices;Infrared radiation;Optics;Software testing;Testing;Thermography (imaging);},
note = {Blackbody;Integrating spheres;Multi-spectral;Ultraviolet;Visible;},
URL = {http://dx.doi.org/10.1117/12.830536},
} 


@inproceedings{20094812516448 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Design and implementation of a web application automation testing framework},
journal = {Proceedings - 2009 9th International Conference on Hybrid Intelligent Systems, HIS 2009},
author = {Wandan, Zeng and Ningkang, Jiang and Xubo, Zhou},
volume = {2},
year = {2009},
pages = {316 - 318},
address = {Shenyang, China},
abstract = {In this paper the problems in the automation testing of GUI based Web applications are discussed. A new automation testing framework based on the concept of object feature set and dynamic searching policy is proposed. The design and implementation of it are both given. The framework working using result shows that it makes the testing more convenient and efficient with less resources and time cost but higher testing coverage. The ability of maintenance and stability are both improved. &copy; 2009 IEEE.<br/>},
key = {Automation},
keywords = {Intelligent systems;},
note = {Automation testing;Design and implementations;Dynamic searching;Feature sets;Time cost;WEB application;Web application testing;},
URL = {http://dx.doi.org/10.1109/HIS.2009.175},
} 


@inproceedings{2004528742400 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of a microturbine generator set with twin rotating disk regenerators},
journal = {Proceedings of the ASME Turbo Expo 2004},
author = {Chiang, Hsiao-Wei D. and Wang, Chun-Hao and Hsu, Chih-Neng},
volume = {6},
year = {2004},
pages = {37 - 44},
address = {Vienna, Austria},
abstract = {An investigation was conducted to study the performance of a 150 kW microturbine generator set with twin rotating disk regenerators, including testing and analyses. Originally designed as a vehicular microturbine engine, twin rotating ceramic disk regenerators were used to dramatically improve fuel consumption by transferring heat energy from the exhaust gas stream to compressor discharge. This microturbine engine consists of a gasifier assembly, a power turbine, a combustor, a regenerator system, a reduction and accessory drive gearbox, and a fuel management system. Because the microturbine engine did not come with the necessary start and control system (including electronic engine control unit), a start sequence was successfully developed and a manual control system installed. This paper reports on testing of the microturbine generator set at different load conditions using load banks. As a parallel effort, a software program was used to predict the performance of the microturbine generator set at different operating conditions in order to compare with the test results.},
key = {Turbines},
keywords = {Control systems;Disks (machine components);Gas generators;Mechanical testing;Performance;Regenerators;Rotors;Shafts (machine components);},
note = {Combined heat and power (CHP);Microturbine generators;Rotating disk regenerators;Vehicular microturbine engine;},
} 


@article{2006289996331 ,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Research and practice on performance test system for IKE protocol},
journal = {Zhongshan Daxue Xuebao/Acta Scientiarum Natralium Universitatis Sunyatseni},
author = {Sun, Wei-Ping and Yin, Xia and Shi, Xin-Gang},
volume = {45},
number = {SUPPL.},
year = {2006},
pages = {14 - 17},
issn = {05296579},
abstract = {The performance of the IKE protocol will much affect the performance of IPSec. In this paper, a test system for performance of IKE protocol was designed and verified. After having analyzed the test requirements of IKE's performance, this paper designed a black box test system which satisfies the performance test requirements. This test system is formed by the self-developed platform of protocol integrated test system, the extensible test suite and the IKE reference implementation. By using this test system, the IKE protocol performance was tested and the impacts of different parameters on the IKE protocol performance are analyzed. The feasibility of test system was verified.},
key = {Network protocols},
keywords = {Cryptography;Performance;Security of data;},
note = {Extensible test suite;Internet key exchange;Performance test;Protocol integrated test system;},
} 


@inproceedings{20082111274878 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {CROWNBench: A grid performance testing system using customizable synthetic workload},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Yang, Xing and Li, Xiang and Ji, Yipeng and Sha, Mo},
volume = {4976 LNCS},
year = {2008},
pages = {190 - 201},
issn = {03029743},
address = {Shenyang, China},
abstract = {The Grid middleware must be developed iteratively and incrementally, so Grid performance testing is critical for middleware developers of Grid system. Considering the special characters of Grid system, in order to gain meaningful and comprehensive results of performance testing, it is necessary to implement testing on real Grid environment with various types of workload. CROWNBench, as described in this paper, is a system for helping Grid middleware developers to evaluate middleware design and implement using customizable synthetic workload. Middleware developers can customize testing workload basing on the model of Grid workload derived from real workload traces, including its structure and parameters, and then workload is synthesized automatically and contained jobs will be submitted by CROWNBench in a distributed manner. CROWNBench defines several metrics for measuring Grid performance as automatic testing results. The experiment, which used CROWNBench to test the performance of Grid system with CROWN Grid middleware, shows that the system already finished have accomplished its prospective goal. It can implement Grid performance testing in an efficient, flexible, controllable, replayable and automatic way to help middleware developers evaluate and improve their products effectively. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Software testing},
keywords = {Grid computing;Middleware;Parameter estimation;Problem solving;Software design;},
note = {CROWNBench;Grid performance;Performance testing;Synthetic workloads;},
URL = {http://dx.doi.org/10.1007/978-3-540-78849-2_21},
} 


@inproceedings{20084811743376 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Towards adaptive framework of keyword driven automation testing},
journal = {Proceedings of the IEEE International Conference on Automation and Logistics, ICAL 2008},
author = {Tang, Jingfan and Cao, Xiaohua and Ma, Albert},
year = {2008},
pages = {1631 - 1636},
address = {Qingdao, China},
abstract = {This paper presents an adaptive framework of keyword-driven automation testing to support the conversion of the keyword-based test cases into different kinds of test scripts automatically to be executed by different test applications under different test environments (such as GUI environment, Database environment, etc.). XML is used to describe the keyword-based commands for the test case. An engine is provided in this framework to parse the XML file and dispatch the command sequences to the different test drivers according to the driver type pre-defined in the command. The test driver is responsible for dispatching the commands to the corresponding test applications to generate the test scripts automatically according to the keywords in the commands. The test scripts will be executed by the test applications on the system-under-test under different test environments. All the test results will be recorded into a log repository for generating all kinds of the test reports. &copy; 2008 IEEE.<br/>},
key = {Testing},
keywords = {Automation;XML;},
note = {Adaptive;Adaptive framework;Automation testing;Command sequences;Keyword driven;System under test;Test applications;Test Environment;},
URL = {http://dx.doi.org/10.1109/ICAL.2008.4636415},
} 


@inproceedings{20095012542547 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Network performance testing on VM based autonomous web server},
journal = {2006 International Conference on Computing and Informatics, ICOCI '06},
author = {Mas'ud, M. Zaki and Yaacob, Asrul H. and Ahmad, Nazrul M.},
year = {2006},
address = {Kuala Lumpur, Malaysia},
abstract = {As online services increasingly play vital roles in modern society, the possibilities and opportunities offered are limitless, unfortunately, so too are the risks and chances of malicious intrusions. Intrusion Detection Systems (IDSs) has been widely used as an important component in protecting online service towards web attacks and evasions. Yet, today's architectures for intrusion detection force the IDS designer to make a difficult choice to place IDS, so that it can protect itself from a direct attack. To address these challenges, this paper introduces a novel framework to safeguard IDS from a direct attack. Simply called Zero Administrative Server (ZAS), the system incorporates IDS in a Virtual Machine (VM) environment. VM offers strong isolation for IDS from the monitored services and provides significant resistance to malicious attacks. Moreover, this VM based WWW server has the ability to monitor the network traffic to the running services; analyse the information obtained and detect the intrusion; alienate the intruder from the services; and reconstruct the corrupted data or damaged files caused by the evasion. In this paper, we demonstrate ZAS by exposing it to several attacking tools as well as to show the effects it takes on the network performance in terms of TCP throughput and application-to-application round trip time. &copy; 2006 IEEE.<br/>},
key = {Intrusion detection},
keywords = {Computer crime;Network performance;Network security;Online systems;Virtual machine;Web services;},
note = {Administrative servers;Check sums;Corrupted data;Intrusion Detection Systems;Malicious attack;Network traffic;On-line service;Round-trip time;},
URL = {http://dx.doi.org/10.1109/ICOCI.2006.5276470},
} 


@inproceedings{20111013722289 ,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {A research on the torque converter performance test-bed control system},
journal = {Proceedings - International Conference on Electrical and Control Engineering, ICECE 2010},
author = {Gao, Yuanlou and Fei, Xiaoxing},
year = {2010},
pages = {3224 - 3226},
abstract = {According to the characteristics of test bed, using a motor driven program based on inverter with a speed sensor, and an eddy current dynamometer constant torsional loading scheme, it implements the stability of constant speed drive and torsional load for the torque converter test-bed, providing a good test environment for the performance test. This method is economical and practical, energy saving and environmental protective. The constant voltage-frequency ratio of frequency control method is applied in motor speed control, and a way of changing the excitation voltage to change the output torque of the eddy current dynamometer is used. The results show that the system achieve good control results. &copy; 2010 IEEE.<br/>},
key = {Electric machine control},
keywords = {Dynamometers;Eddy currents;Energy conservation;Equipment testing;Hydraulic torque converters;Software testing;Structural loads;Torque;},
note = {Constant voltage;Converter performance;Eddy current dynamometer;Excitation voltage;Motor-speed control;Performance tests;Test Environment;Torsional loadings;},
URL = {http://dx.doi.org/10.1109/iCECE.2010.787},
} 


@inproceedings{20101712879826 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Software performance testing scheme using virtualization technology},
journal = {Proceedings of the 4th International Conference on Ubiquitous Information Technologies and Applications, ICUT 2009},
author = {Kim, Gwang-Hun and Moon, Hui-Choun and Song, Gi-Pyeung and Shin, Seok-Kyu},
year = {2009},
address = {Fukuoka, Japan},
abstract = {In this paper, we propose software performance testing scheme using virtualization technology. Generally, people have used software performance testing tool such as load runner and silk performer. However, people should perform software performance testing manually in case of the situation that people cannot use testing tool. It needs a lot of resources such as human resource and computing resource. Therefore, we propose software performance testing scheme using virtualization technology to reduce resource consumption. Proposed scheme can reduce computer resource consumption because virtualization technology can make a number of virtual computers with a small number of physical computers. Also proposed scheme can reduce human resource consumption because, in proposed scheme, management computer can control keyboard and mouse of virtual computers automatically. Simulation result shows that proposed scheme has possibility to be used for software performance testing. &copy; 2009 IEEE.<br/>},
key = {Software testing},
keywords = {Computer resource management;Human resource management;Load testing;Virtual reality;Virtualization;},
note = {Computer resources;Computing resource;Performance testing;Resource consumption;Software performance engineerings;Software performance testing;Test Automation;Virtualization technologies;},
URL = {http://dx.doi.org/10.1109/ICUT.2009.5405721},
} 


@article{20083611516113 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance test of a 1 MW class HTS synchronous motor for industrial application},
journal = {Physica C: Superconductivity and its Applications},
author = {Kwon, Y.K. and Kim, H.M. and Baik, S.K. and Lee, E.Y. and Lee, J.D. and Kim, Y.C. and Lee, S.H. and Hong, J.P. and Jo, Y.S. and Ryu, K.S.},
volume = {468},
number = {15-20},
year = {2008},
pages = {2081 - 2086},
issn = {09214534},
abstract = {This paper deals with development activities of high temperature superconducting (HTS) synchronous motor at DOOSAN heavy industry and Korea Electrotechnology Research Institute (KERI) in Korea, and is sponsored by DAPAS program which is supported by Korean government. The final aim of the project is realization of HTS motor in the field of industry such as large driving pumps, fans and compressors for utility and industrial environments. At present time, 1 MW HTS motor is developed for the purpose to fully represent the design and manufacturing issues for the larger capacity machine. The number of pole and rotating speed of machine are 2 pole and 3600 rpm. The HTS field coil of the developed motor is cooled by way of neon thermosyphon mechanism and the stator coil is cooled by water through hollow copper conductor. This paper describes status of 1 MW HTS motor development, such as design, fabrication and performance test results, which was conducted at steady state in generator mode and motor mode. &copy; 2008 Elsevier B.V. All rights reserved.<br/>},
key = {Synchronous motors},
keywords = {Electric motors;High temperature superconductors;Poles;Stators;Superconducting coils;},
note = {Air-core stator;Development activity;High temperature superconducting;HTS field coil;Hts synchronous motors;Industrial environments;Manufacturing issue;Rotating cryogenic cooling system;},
URL = {http://dx.doi.org/10.1016/j.physc.2008.05.249},
} 


@inproceedings{2005048809225 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {VSTM: Virtual stress testing machine},
journal = {Proceedings of the International Conference on Parallel and Distributed Processing Techniques and Applications, PDPTA'04},
author = {Harris, R. and Ausin, A.M. and Angulo, J.S. and Valafar, F. and Impelluso, T.},
volume = {3},
year = {2004},
pages = {1345 - 1351},
address = {Las Vegas, NV, United states},
abstract = {Virtual stress testing machine is a client-server software environment with a distributed memory system. VSTM encompasses a stress testing machine, a server component that initiates and controls all processes, a computational finite element component, and a number of visualization components. The goal of this design is to provide a virtual stress analysis environment, in which a specimen undergoes a series of stress applications. The finite element component calculates the displacement (deformation) of the specimen under stress. The visualization clients read the results of the finite element analysis, and construct an image of the deformed specimen color-coded to indicate varying levels of stress. A multitude of applications have been envisioned for this system, including studies in medicine.},
key = {Computer software},
keywords = {Animation;Client server computer systems;Data processing;Distributed computer systems;Finite element method;Fluid mechanics;Virtual reality;Visualization;},
note = {Distributed Memory;Finite element codes;Stress Testing;Virtual stress testing machines (VSTM);},
} 


@article{20075110980797 ,
language = {Japanese},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Estimation of the tilt variations influenced by snow-removal and rainfall - Application of load test and tank model},
journal = {Zairyo/Journal of the Society of Materials Science, Japan},
author = {Shimizu, Takeshi and Onishi, Kyosuke and Matsuoka, Toshifumi and Fujita, Masato and Takahashi, Masaki},
volume = {56},
number = {9},
year = {2007},
pages = {839 - 845},
issn = {05145163},
abstract = {High-resolution tilt meters have been applied to measure subtle underground tilt variations. As one of the application of high-resolution tilt meters system, the tilt variations recorded by the tilt meter can be used to monitor the distribution of underground volumetric deformation for CO<inf>2</inf> injection. The signal recorded by the tilt meter is frequently affected by noises. In order to monitor the flow zone of injected CO<inf>2</inf> using the tilt meters, it is important to consider eliminating the tilt variations due to noises such as earth tide, ground vibration, temperature variation, atmospherical pressure change, rainfall, and snowfall. In this paper, using the tilt data obtained from the observation field in Yubari, Hokkaido where high-resolution tilt meters are installed during CO<inf>2</inf> injection test, we tried to estimate the tilt variations influenced by rainfall and snowfall. The tilt variations are theoretically determined by the elastic modulus of the surface soil in the field. First, we estimated the elastic modulus of the surface soil in the observation field using the load test and evaluated the tilt variations when removing snow using the estimated elastic modulus. Second, applying the tank model to precipitation data in the observation field, we estimated the tilt variations influenced by rainfall. The estimated tilt variations influenced by rainfall and removing snow are fit to tilt values observed in the field. Estimating tilt variations by rainfall and snow fall using the load test and the tank model is effective to evaluate the tilt variations influenced by the external factors. &copy; 2007 The Society of Materials Science.},
key = {Snow and ice removal},
keywords = {Carbon dioxide;Elastic moduli;Mathematical models;Rain;Signal analysis;},
note = {Load test;Tank model;Tilt meter;},
URL = {http://dx.doi.org/10.2472/jsms.56.839},
} 


@inproceedings{1993081001700 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Stress testing a non-existent application tools, methods, and results},
journal = {CMG Proceedings},
author = {Brey, Jack},
year = {1992},
pages = {520 - 529},
address = {Reno, NV, USA},
abstract = {How do you test an application that doesn't exist yet? How do you make an architectural decision when there are no similar applications in production anywhere? This case study covers the decision making process, the tools selected, the test plan, and the test results of an analysis used to choose between the use of a CASE tool and ACMS for a proposed application. The study involved use of both an analytic model and a benchmarking tool to establish the saturation point of a VAX 9000 under each alternative. The paper will discuss creation of the models, the results of the modeling activities, and the criteria that went into the actual decision.},
key = {Computer software},
keywords = {Decision theory;Testing;},
note = {Software development;},
} 


@article{1999284675977 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Network application performance testing for lotus notes},
journal = {CMG Transactions},
author = {Williams, Andrew},
number = {95},
year = {1999},
pages = {49 - 64},
abstract = {As customers move toward network applications, the problem of acceptable performance and user load stresses have not evaporated. Increasingly, customers need to simulate large network user loads to measure end-to-end response time and identify potential bottlenecks. This paper presents a methodology to achieve this and details results from real applications evaluations on an OS/2 and AIX Lotus Notes 4.1 environment. In all, thirty client machines were setup in a laboratory and linked to an additional set of seventy virtual users all exercising Lotus Notes application test cases to create a user load of 100 active concurrent users. During the process the clients and servers were monitored with various tools. The paper details the process used, a sample of the results, problems found in the process, the metrics required and future directions for network performance test solutions. It will focus mostly on the method of creating large, realistic loads for Lotus Notes applications - a topic largely ignored by the testing community up to this point in time. The subject will be of interest to any owner interested in implementing a network application or client/server application or a test specialist involved in testing these type of applications.},
key = {Computer applications},
keywords = {Client server computer systems;Computer software;Computer testing;Internet;Performance;Response time (computer systems);},
note = {Lotus notes;Network application performance testing;},
} 


@article{1995242672792 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Environmental stress testing experiment using the Taguchi method},
journal = {IEEE transactions on components, packaging, and manufacturing technology. Part A},
author = {Pachucki, Dennis E.},
volume = {18},
number = {1},
year = {1995},
pages = {3 - 9},
issn = {10709886},
abstract = {An environmental stress screening (ESS), a method for improving manufacturing process by applying stress beyond product specification detect latent defects in the product, was performed to find out the relevant stress used in the production of printed wiring boards. Three types of stress - random vibration, temperature cycling and power cycling - were emphasized. Experimental results were statistically obtained using the Taguchi design method.},
key = {Printed circuit manufacture},
keywords = {Application specific integrated circuits;Computer software;Data acquisition;Data storage equipment;Environmental testing;Microprocessor chips;Random processes;Statistical methods;Stresses;Thermal cycling;Vibrations (mechanical);},
note = {Analysis of variance;Environmental stress testing;Functional diagnostic test suite;Power cycling;Power on self test;Printed wiring board;Programmable memory chip;Random vibration;Taguchi method;Temperature cycling;},
URL = {http://dx.doi.org/10.1109/95.370727},
} 


@inproceedings{1998094000254 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Simplifying motor performance testing in the production environment},
journal = {Proceedings of the Electrical/Electronics Insulation Conference},
author = {Leonard, Donald C.},
year = {1997},
pages = {185 - 190},
issn = {03622479},
address = {Rosemont, IL, USA},
abstract = {The objective of this paper is to illustrate how performance test systems on the factory floor can be enhanced by utilizing the power and speed of integral computer hardware and software to automate and simplify tasks typically performed in the production environment. The first part of this paper discusses why the test system is needed to perform additional tasks. The second section defines the relationships between various departments within the organization, and the test system. The third section discusses the benefits of integrating additional functions into the test system. The final sections of the paper discusses incorporating artificial intelligence and networking to simplify tasks associated with the production environment.},
key = {Electric motors},
keywords = {Artificial intelligence;Automatic testing;Computer hardware;Computer integrated manufacturing;Computer software;Decision making;Factory automation;Performance;},
note = {Factory floor;Performance testing;},
} 


@inproceedings{1997483850455 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Performance testing of the North American CDMA system, using an envelope simulator},
journal = {Annual Wireless Communications Conference, Proceedings},
author = {Mahmoudi, R. and Tauritz, J.L.},
year = {1997},
pages = {84 - 88},
address = {Boulder, CA, USA},
abstract = {The growing use of spread spectrum techniques for personal communications (PCS) in Japan and USA is proving to be an enormous stimulus for the study of system impact on component design. New and innovative techniques are required to translate system criteria into component specifications. In this paper we have studied the performance of the `North American Digital Cellular, IS-95' system proposed by QUALCOMM, under the influence of spurious signals using the new `Circuit Envelope Simulator' in HP-EESOF'S Microwave Design System, MDS. The implemented functional blocks facilitate the generation of proper (noisy) CDMA (Reverse and Forward) signals, which are then used to program an arbitrary wave generator in order to create actual test signals. Additionally, these functional blocks can be replaced with equivalent circuits, consisting of passive and active elements, etc. For illustrative purposes, we discuss the application of these signals to two real amplifiers, one linear and one non-linear. The measured results are critically compared with the simulation results.},
key = {Spread spectrum communication},
keywords = {Active networks;Amplifiers (electronic);Bandwidth;Cellular radio systems;Communication channels (information theory);Computer simulation;Digital communication systems;Equivalent circuits;Passive networks;Personal communication systems;Radio links;Spurious signal noise;},
note = {Circuit envelope simulator;Code division multiple access (CDMA);},
} 


@inproceedings{20174004232566 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a structural load testing tool},
journal = {Proceedings of the 1996 ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 1996},
author = {Yang, Cheer-Sun D. and Pollock, Lori L.},
year = {1996},
pages = {201 - 208},
address = {San Diego, CA, United states},
abstract = {Load sensitive faults cause a program to fail when it is executed under a heavy load or over a long period of time, but may have no detrimental effect under small loads or short executions. In addition to testing the functionality of these programs, testing how well they perform under stress is very important. Current approaches to stress, or load, testing treat the system as a black box, generating test data based on parameters specified by the tester within an operational profile. In this paper, we advocate a structural approach to load testing. There exist many structural testing methods; however, their main goal is generating test data for executing all statements, branches, definition-use pairs, or paths of a program at least once, without consideration for executing any particular path extensively.Our initial work has focused on the identification of potentially load sensitive modules based on a static analysis of the module's code, and then limiting the stress testing to the regions of the modules that could be the potential causes of the load sensitivity. This analysis will be incorporated into a testing tool for structural load testing which takes a program as input, and automatically determines whether that program needs to be load tested, and if so, automatically generates test data for structural load testing of the program. &copy; 1996 ACM.},
key = {Software testing},
keywords = {Black-box testing;Load testing;Static analysis;Structural analysis;Structural loads;Test facilities;},
note = {Black boxes;Load sensitivities;Load-sensitive;Operational profile;Stress Testing;Structural approach;Structural testing;Testing tools;},
URL = {http://dx.doi.org/10.1145/229000.226318},
} 


@article{1998164083460 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Fetal monitor for non-stress-test screening at home},
journal = {Biomedical Instrumentation and Technology},
author = {Horio, Hiroyuki and Murakami, Masayoshi and Chiba, Yoshihide and Inada, Hiroshi},
volume = {32},
number = {1},
year = {1998},
pages = {39 - 47},
issn = {08998205},
abstract = {A fetal monitoring device that works on battery power was developed for non-stress-test (NST) screening at home. It is small and lightweight that a pregnant woman can monitor fetal Doppler ultrasound and record fetal heart rate (FHR) and uterine contraction data on an attached memory integrated circuits at any time and in any place way from a hospital. The physician can evaluate these data, transmitted via public telephone line, using built-in modem in the monitor. Pregnant women participated in an evaluation of the fetal monitoring system. 648 NST data were transmitted and 6.7 Mbytes were the total amount of data received. The main cause of noise in the data was zero-count data; this noise rate accounted for 4.1% of the data abnormalities.},
key = {Fetal monitoring},
keywords = {Data communication systems;Electronic medical equipment;},
note = {Fetal Doppler ultrasound;Fetal heart rate;Non stress test (NST) screening;},
} 


@article{1996363246637 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {Deriving workloads for performance testing},
journal = {Software - Practice and Experience},
author = {Avritzer, Alberto and Weyuker, Elaine J.},
volume = {26},
number = {6},
year = {1996},
pages = {613 - 633},
issn = {00380644},
abstract = {An approach is presented to compare the performance of an existing production platform and a proposed replacement architecture. The traditional approach to such a comparison is to develop software for the proposed platform, build the new architecture, and collect performance measurements on both the existing system in production and the new system in the development environment. In this paper we propose a new way to design an application-independent workload for doing such a performance evaluation. We demonstrate the applicability of our approach by describing our experience using it to help an industrial organization determine whether or not a proposed architecture would be adequate to meet their organization's performance requirements.},
key = {Computer software},
keywords = {Computer architecture;Computer software portability;Performance;Software engineering;},
note = {Benchmark tuning;Performance testing;Workloads;},
URL = {http://dx.doi.org/10.1002/(SICI)1097-024X(199606)26:6<613::AID-SPE23>3.0.CO;2-5},
} 


@article{1984070110764 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {'ASAP': A microcomputer-based automated safety and performance testing system},
journal = {Journal of clinical engineering},
author = {Eschelbach, R.E.},
volume = {9},
number = {1},
year = {1984},
pages = {21 - 27},
issn = {03638855},
abstract = {An HP-85 microcomputer programmed in BASIC was interfaced to a PEI 2000 safety analyzer via an HP-6942A Multiprogrammer and appropriate interface cards. This configuration allows automated safety and performance testing as well as report generation. The system is operated by means of a menu displayed on a built-in CRT and the keyboard. Data are displayed and then stored on the built-in cassette unit. Additional testing features are easily added with minimal software development, since all programming is in BASIC and all interface drivers are part of the hardware.},
key = {BIOMEDICAL EQUIPMENT},
keywords = {COMPUTER PROGRAMMING LANGUAGES - BASIC;COMPUTERS, MICROPROCESSOR - Medical Applications;DATA STORAGE, MAGNETIC - Tape;DISPLAY DEVICES - Medical Applications;MAINTENANCE - Computer Applications;},
note = {AUTOMATED PERFORMANCE TESTING;AUTOMATED SAFETY TESTING;MICROCOMPUTERS;},
} 


@inproceedings{1983040057378 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {MONITOR AND PERFORMANCE TEST EQUIPMENT IN COMBINATION WITH A CONTROL SYSTEM.},
author = {Nordmann, Th and Guebeli, H. and Vuilleumier, U.},
volume = {1},
year = {1982},
pages = {840 - 844},
address = {Brighton, Engl},
key = {DATA PROCESSING},
note = {ALUMINUM CASE;CONTROL SYSTEMS;FEEDBACK;HEAT BALANCE;PERFORMANCE TEST EQUIPMENT;SENSORS;},
} 


@inproceedings{1986060027550 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2018 Elsevier Inc.},
copyright = {Compendex},
title = {APPLICATION OF ELECTROMAGNETIC ENVIRONMENT SIMULATION TO RADAR PERFORMANCE TESTING, OPERABILITY ASSESSMENT AND TRAINING.},
author = {Michaels, John F.},
year = {1985},
pages = {125 - 129},
address = {Arlington, VA, USA},
abstract = {A description is given of the applicability of radar environment simulator systems (RESSs) to the shipboard, ground, and air environment in regard to radar testing, operability assessment, and operator/combat team training. A representative technical description of a delivered RESS is presented.},
key = {RADAR},
keywords = {RADAR SYSTEMS - Testing;},
note = {RADAR ENVIRONMENT SIMULATORS;TEAM TRAINING;},
} 



