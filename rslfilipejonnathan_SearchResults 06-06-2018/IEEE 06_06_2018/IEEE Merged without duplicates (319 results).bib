% Encoding: UTF-8

@InProceedings{Kiamilev1996,
  author    = {F. Kiamilev and R. Rozier and J. Rieve},
  title     = {A compact, low-cost, high-performance test fixture for electrical test and control of smart pixel integrated circuits},
  booktitle = {Digest IEEE/Leos 1996 Summer Topical Meeting. Advanced Applications of Lasers in Materials and Processing},
  year      = {1996},
  pages     = {63-64},
  month     = {Aug},
  abstract  = {We have developed a low-cost, compact test fixture that can supply and monitor high-speed electrical signals for smart pixel ICs packaged in an 84-pin PGA chip carrier.},
  doi       = {10.1109/LEOSST.1996.540746},
  keywords  = {field programmable gate arrays;integrated circuit packaging;integrated circuit testing;integrated optoelectronics;monitoring;smart pixels;test equipment;PGA chip carrier;compact low-cost high-performance test fixture;electrical test;high-speed electrical signal monitoring;smart pixel IC packaging;smart pixel integrated circuit control;smart pixel integrated circuit testing;Circuit testing;Clocks;EPROM;Electronics packaging;Field programmable gate arrays;Fixtures;Hardware design languages;Integrated circuit testing;Smart pixels;Sockets},
}

@InProceedings{Malandruccolo2009,
  author    = {V. Malandruccolo and M. Ciappa and W. Fichtner and H. Rothleitner},
  title     = {Novel Solution for the Built-in Gate Oxide Stress Test of LDMOS in Integrated Circuits for Automotive Applications},
  booktitle = {2009 14th IEEE European Test Symposium},
  year      = {2009},
  pages     = {67-72},
  month     = {May},
  abstract  = {Efficient screening procedures for the control of the gate oxide defectivity are vital to limit early failures especially in critical automotive applications. Traditional strategies based on burn-in and in-line tests are able to provide the required level of reliability but they are expensive and time consuming. This paper presents a novel approach to the gate stress test of Lateral Diffused MOS transistors based on an embedded circuitry that includes logic control, high voltage generation, and leakage current monitoring. The concept, advantages and the circuit for the proposed built-in gate stress test procedure are described in very detail and illustrated by circuit simulation.},
  doi       = {10.1109/ETS.2009.18},
  issn      = {1530-1877},
  keywords  = {automotive electronics;circuit simulation;integrated circuit testing;power MOSFET;power semiconductor switches;semiconductor device reliability;automotive applications;built-in gate oxide stress test;circuit simulation;embedded circuitry;gate oxide defectivity;high voltage generation;lateral diffused MOS transistors;leakage current monitoring;logic control;power FET-switches;Application specific integrated circuits;Automotive applications;Circuit testing;Integrated circuit reliability;Integrated circuit testing;Logic circuits;Logic testing;MOSFETs;Stress control;Voltage control;Burn-In;Gate Oxide Reliability;Gate Stress Test;Low Side Switch},
}

@InProceedings{Ping2012,
  author    = {C. Ping and H. Hongwei and Z. Yonghui},
  title     = {The performance test of U-shape antenna applied in tunnel detection},
  booktitle = {2012 14th International Conference on Ground Penetrating Radar (GPR)},
  year      = {2012},
  pages     = {109-114},
  month     = {June},
  abstract  = {Owing to the growth of population, thus increased land scarcity for normal surface road construct and improper city council planning it inflict more tunnel and underground structure constructed. As most of the constructed underground structures are subjected to severe adverse condition which need thorough inspection. To maintain the good inhabitable tunnel structure ground penetrating radar (GPR) always use as a measuring tools. GPR as an inspection tools in tunnel has been plague with series of setback. In this case a new type of antenna has been introduced in order to improve the performance in tunnel inspection. An emphasize part of the antenna design must be ensuring the directivity, bandwidth characteristic, radiation efficiency and the penetration depth. This research has been divided into three cases and those cases were performed in order to signify the characteristic of the antenna. Laboratory test and numerical simulation were carried out for the comparison and urged to the optimize solution. In this paper, Agilent E5060A ENA has been used for the laboratory test to examine the performance of the antenna. The FDTD method for numerical simulation is to prove the authenticity of the result of laboratory test. The test result illustrates that; the new designed antenna is suitable for tunnel inspection. The important improvement should be further carried out. Further studies must investigate the application of this type of antenna for the inspection of tunnel lining.},
  doi       = {10.1109/ICGPR.2012.6254843},
  keywords  = {antenna testing;ground penetrating radar;radar antennas;tunnels;U-shape antenna design;adverse condition;bandwidth characteristic;city council planning;ground penetrating radar;inhabitable tunnel structure;inspection tool;laboratory test;land scarcity;numerical simulation;penetration depth;radiation efficiency;surface road construct;tunnel detection;tunnel inspection;tunnel lining;underground structure;Antenna measurements;Antennas;Finite difference methods;Ground penetrating radar;Inspection;Laboratories;Numerical simulation;Antenna;ENA;FDTD;Ground Penetrating Radar;lining;tunnel},
}

@InProceedings{Trommer2016,
  author    = {R. Trommer and P. Quednau and L. P. Schmidt},
  title     = {Application of selected performance test scenarios on multi-channel UHF receivers},
  booktitle = {2016 German Microwave Conference (GeMiC)},
  year      = {2016},
  pages     = {73-76},
  month     = {March},
  abstract  = {In a preceding paper a multi-channel test signal generator for UHF radar applications was presented. The present contribution shows the application of this generator to test the performance of multi-channel receivers in selected scenarios. Exemplary measurement results are presented showing the usable dynamic range and the maximum packet reception rate for a secondary surveillance radar receiver and a smart meter data collector. Furthermore the direction-of-arrival estimation precision and the source separation capabilities of the receivers are tested under various conditions.},
  doi       = {10.1109/GEMIC.2016.7461559},
  keywords  = {UHF devices;direction-of-arrival estimation;radar receivers;search radar;signal generators;smart meters;source separation;UHF radar applications;direction-of-arrival estimation precision;maximum packet reception rate;multichannel UHF receivers;multichannel test signal generator;secondary surveillance radar receiver;selected performance test scenarios;smart meter data collector;source separation capabilities;usable dynamic range;Antenna arrays;Direction-of-arrival estimation;Estimation error;Radar;Receivers;Sensitivity;Signal generators},
}

@InProceedings{Lee2013,
  author    = {H. Y. Lee and J. A. Jeon and S. K. Yang and J. Lee and I. H. Park},
  title     = {Fabrication of Silicon-Photomultiplier multi arrays and the performance test},
  booktitle = {2013 IEEE Nuclear Science Symposium and Medical Imaging Conference (2013 NSS/MIC)},
  year      = {2013},
  pages     = {1-2},
  month     = {Oct},
  abstract  = {SiPM (Silicon Photomultiplier) is a semiconductor light diode comprised of many micropixels. Due to its positive characteristics, SiPM is considered as the next generation model of silicon photo amplifier. A photo-sensor made by multi arrays of SiPM sensors can even takes an image at the environment of old(dark) moon. Array of SiPMs with a minimum gap between the sensors is needed for some applications where a fine imaging of sources with low intensity radiations is required. We have attempted to fabricate SiPM sensors in various forms of arrays from the lithographic process in order to apply them in imaging astrophysical objects with low intensity. In the first process of the fabrication, we have produced various sizes of single SiPM sensors and also the arrays. The design includes unit sensors in the size of 0.5mm × 0.5mm, consisting of 103 micropixles with the maximum geometric efficiency of 70%. One of the arrays produced is 8 × 8 matrix of the unit sensors with the sensors gap of 60 um. We have tested the sensor arrays for the electrical characteristics and the dark rates. Details in the sensor and array design, the fabrication procedure, and the results of the performance test with the output from the first production are presented.},
  doi       = {10.1109/NSSMIC.2013.6829673},
  issn      = {1082-3654},
  keywords  = {amplifiers;elemental semiconductors;lithography;optical fabrication;photodetectors;photomultipliers;sensor arrays;silicon;Si;SiPM sensors;astrophysical object imaging;dark rates;electrical characteristics;lithographic process;next generation model;photosensor fabrication;semiconductor light diode;silicon photoamplifier;silicon photomultiplier multiarray fabrication;size 0.5 mm;Fabrication;Image sensors;Photonics;Sensor arrays;Sensor phenomena and characterization;Silicon},
}

@InProceedings{Yuhui2010,
  author    = {W. Yuhui and L. Xiaohui and J. Yunzhong and S. Xinshan},
  title     = {Parallelization and Performance Test to Multiple Objective Particle Swarm Optimization Algorithm},
  booktitle = {2010 International Forum on Information Technology and Applications},
  year      = {2010},
  volume    = {1},
  pages     = {216-223},
  month     = {July},
  abstract  = {In recent years, Model calibration and parameter estimation with high complexity is a common problem in many areas of researches, especially in environmental modeling. This paper proposes a comparatively simple technique on the parallel implement of Multi-objective Particle Swarm Optimization algorithm (MOPSO). The transformation of the sequential objective evaluation in the MOPSO is based on the Matlab parallel computing tool box. Two study cases of different complexity demonstrate that the parallel implementation resulted in a considerable time saving. The deviation of computational time indicates that MOPSO has the characteristic of randomness because of the crowding distance and the dominant ranking. The proposed parallel MOPSO therefore, provides an ideal means to solve global optimization problems that are comparatively with high complexity.},
  doi       = {10.1109/IFITA.2010.109},
  keywords  = {calibration;parallel processing;particle swarm optimisation;performance evaluation;Matlab;dominant ranking;global optimization problems;model calibration;multiple objective particle swarm optimization;parallel computing tool box;parallelization;parameter estimation;performance test;sequential objective evaluation;Algorithm design and analysis;Calibration;Complexity theory;Computational modeling;Mathematical model;Optimization;Program processors;MOPSO;Pareto front;Xinanjiang model;multi-processor;parallel},
}

@InProceedings{Kang2017,
  author    = {P. Z. Kang and T. Y. Yew and K. W. Shih and M. H. Hsieh and W. S. Chou and C. M. Fu and Y. C. Huang and W. Wang and Y. C. Peng and Y. H. Lee},
  title     = {A novel on-die GHz AC stress test methodology for high speed IO application},
  booktitle = {2017 IEEE International Reliability Physics Symposium (IRPS)},
  year      = {2017},
  pages     = {4C-3.1-4C-3.5},
  month     = {April},
  abstract  = {A new methodology and test circuit for evaluation of device reliability are presented. The stress conditions must emulate the real circuit operation, or similar to product-like environment. Existing methodology might not archive this purpose. In this paper, an on-die wave front generator was established in circuit level. Experiments in this study cover from mechanisms of off state, Bias Temperature Instability (BTI) and Hot Carrier Injection (HCI). Based on the extensive results, strong dependence of reliability to layout effect can be concluded. And the reliability guidelines and recommendations for high speed IO circuit design can be made.},
  doi       = {10.1109/IRPS.2017.7936314},
  keywords  = {high-speed integrated circuits;hot carriers;integrated circuit layout;semiconductor device reliability;semiconductor device testing;stress effects;BTI;HCI;bias temperature instability;device reliability evaluation;high speed IO circuit design;hot carrier injection;layout effect;on-die GHz AC stress test methodology;on-die wave front generator;stress conditions;test circuit;Clocks;Degradation;Human computer interaction;Integrated circuit reliability;Logic gates;Stress;AC Stress;BTI;HCI;High Speed IO Application;Off-State},
}

@InProceedings{Quan2010,
  author    = {X. Quan and L. Lu},
  title     = {Session-based performance test case generation for Web applications},
  booktitle = {2010 8th International Conference on Supply Chain Management and Information},
  year      = {2010},
  pages     = {1-7},
  month     = {Oct},
  abstract  = {There are many techniques and tools for Web application testing, but few of these address the procedure for gathering user session data accessed in a production environment to assist in testing Web application performance. In this paper, we present a session-based approach to automatically generate performance test cases by exploiting user session information taken from server logs. Such test cases are used for generating synthetic workload to evaluate performance. This paper illustrates the prototype implementation of our session-based performance test case generation approach.},
  keywords  = {Internet;program testing;Web application testing;server logs;session-based performance test case generation;user session information;Classification algorithms;Classification tree analysis;Entropy;Servers;Testing;Training;Web applications;decision tree;performance test;user session},
}

@InProceedings{Wu2010,
  author    = {P. Wu and B. Wu},
  title     = {Performance Test of Network Simulation Based on Split-Object Model},
  booktitle = {2010 International Forum on Information Technology and Applications},
  year      = {2010},
  volume    = {1},
  pages     = {189-192},
  month     = {July},
  abstract  = {The network simulation (NS) is an important issue in the study of network technology. However, The error between the network performance simulation on split-object model and the true network environment is considerable apparent. In order to obtain the NS result approaching the reality, in this paper, we analyze the structure of split-object mode and find reasons to cause the error. According to the definition of NS performance's index, we remodel the split-object model by choosing the proper function and equation in the control theory and deducing the logical coefficent in them. We further evaluate the efficiency and the availability of the new model under NS-2 platform. The results show that the new mode is more suitable for network simulation with higher accuracy.},
  doi       = {10.1109/IFITA.2010.10},
  keywords  = {computer network performance evaluation;mathematical analysis;NS performance index;NS-2 platform;control theory;logical coefficent;network simulation;network technology;performance test;split object model;true network environment;Analytical models;Computational modeling;Data models;Hardware;Indexes;Mathematical model;Runtime;mathematical analysis;network simulation;performance test;split-object model},
}

@InProceedings{Tada2017,
  author    = {K. Tada and A. Satake and K. Hashimura and Y. Ogashi and H. Masuda and T. Oka},
  title     = {Study of full load test method for large VSDS driven by non-regenerative VSI},
  booktitle = {2017 Petroleum and Chemical Industry Conference Europe (PCIC Europe)},
  year      = {2017},
  pages     = {1-9},
  month     = {May},
  abstract  = {Full load back-to-back test of VSDS's (Variable Speed Drive Systems) are sometimes required for oil and gas projects. VSI (Voltage Source Inverter) technology is becoming the drive system of choice for super large compressor drives, up to 100 MW. Special consideration /facilities are necessary to perform back-to- back tests for VSDS driven by VSI, because the type of converter used for such large VSI's is usually a diode rectifier without regenerative capability. To realize a back-to-back test for this type of VSDS, a VSI with regenerative converter, (usually adopting PWM converter topology), is necessary. But it is a heavy burden to prepare such super large VSI with regeneration capability purely as a test facility. This paper proposes a test method to increase the load test capacity of a back-to-back test facility up to two times the regenerative converter capacity. This idea is to apply a VSI with regenerative converter as a soft starter during start-up of back-to-back connected motor and generator system and as a constant voltage and constant frequency power supply during testing of VSDS. The proposed test facility is configured by direct connection of the load machine output to the input transformer of tested VSDS to circulate the load power directly. Only loss power and reactive power is supplied by VSI with regenerative converter.},
  doi       = {10.23919/PCICEurope.2017.8015057},
  keywords  = {PWM power convertors;starting;variable speed drives;voltage-source convertors;PWM converter topology;VSDS;VSI technology;back-to-back connected motor;constant frequency power supply;constant voltage power supply;diode rectifier;full load back-to-back test;generator system;load test capacity;loss power;reactive power;regenerative capability;regenerative converter;soft starter;super large compressor drives;variable speed drive systems;voltage source inverter technology;Generators;Inverters;Load modeling;Power supplies;Rectifiers;Synchronous motors;Test facilities},
}

@InProceedings{Li2013a,
  author    = {S. Li and X. Li and Y. Wu and K. Zhang},
  title     = {A Research on Comprehensive Performance Test System of High-Speed Motorized Spindle},
  booktitle = {2013 Third International Conference on Instrumentation, Measurement, Computer, Communication and Control},
  year      = {2013},
  pages     = {613-617},
  month     = {Sept},
  abstract  = {In order to produce the motorized spindle unit with high quality and performance and further improve its level of design and produce, a comprehensive performance test system for high-speed motorized spindle is built successfully, it can analyze the load characteristics, temperature rise, vibration, noise, accuracy and rigidity of high-speed motorized spindle unit in different working conditions. Experiments of above characteristics were also completed for a full-ceramic motorized spindle, and a series of results were attained, it supplies technical support to enhance its comprehensive performance and the manufacture technical level.},
  doi       = {10.1109/IMCCC.2013.137},
  keywords  = {ceramics;electric motors;machine bearings;machine testing;machine tool spindles;mechanical testing;shear modulus;comprehensive performance test system;full-ceramic motorized spindle;high-speed motorized spindle unit;manufacture technical level;rigidity;Accuracy;Ceramics;Lubrication;Noise;Temperature measurement;Temperature sensors;Vibrations;comprehensive performance test system;high-speed motorized spindle;temperature rise experiment;vibration experiment},
}

@InProceedings{Xin2011,
  author    = {Zhang Xin and Cai Ling},
  title     = {Study of integrative performance test system for the automobile engine control unit},
  booktitle = {2011 International Conference on Electric Information and Control Engineering},
  year      = {2011},
  pages     = {4495-4498},
  month     = {April},
  abstract  = {Aiming at the control complex of automobile engine control unit (ECU), a test system of the automobile engine control unit was designed . The system is composed of the input signal simulate module, measurement and control module, signal collection and disposal module, communication module etc. By means of simulating the signal of sensors, such as the crankshaft position sensor, the throttle position sensor, and the air temperature sensor, the engine operation environment and the real time condition were simulated and tested. The collected signal of the fuel injection and the ignition signal were analyzed. The development and testing of engine ECU were facilitated.},
  doi       = {10.1109/ICEICE.2011.5777060},
  keywords  = {automobiles;internal combustion engines;air temperature sensor;automobile engine control unit;communication module;control module;crankshaft position sensor;disposal module;engine operation environment;fuel injection;ignition signal;integrative performance test system;signal collection;throttle position sensor;Automobiles;Internal combustion engines;Motorcycles;Sensor systems;Temperature sensors;data collecting;engine ECU;performance test;sensor simulation},
}

@InProceedings{Wang2017,
  author    = {Y. Wang and L. Zhu and H. Zhao},
  title     = {Handover performance test and analysis in TD-LTE based CBTC train ground communication systems},
  booktitle = {2017 Chinese Automation Congress (CAC)},
  year      = {2017},
  pages     = {3655-3660},
  month     = {Oct},
  abstract  = {Most of the existing urban rail CBTC train ground communication systems are based on Wireless Local Networks (WLAN) technologies. With frequency interference and the increase of train speed, WLAN is incapable of meeting the requirements of CBTC train ground communication systems. Time Division-Long Term Evolution (TD-LTE) technology begins to be considered in urban rail transit systems. In this paper, we first design a TD-LTE based urban rail CBTC train ground communication systems, the handover procedure and handover requirements according to CBTC system principle are analyzed next. For verifing whether the designed TD-LTE based system meet the handover performance demands when trains travel in high speed CBTC systems, a laboratory test environment and a real field test environment are set up. Massive test results show that the handover performance of TD-LTE based urban rail CBTC train ground communication systems meets the demands of urban rail transit systems.},
  doi       = {10.1109/CAC.2017.8243415},
  keywords  = {Long Term Evolution;mobility management (mobile radio);railway communication;time division multiplexing;wireless LAN;CBTC system principle;CBTC train ground communication systems;TD-LTE based urban rail CBTC train ground communication systems;Time Division-Long Term Evolution technology;Wireless Local Networks technologies;handover procedure;handover requirements;high speed CBTC systems;train speed;urban rail transit systems;Handover;Long Term Evolution;Rails;Wireless LAN;Wireless communication;CBTC;TD-LTE;handover;train ground communication},
}

@InProceedings{Wang2015,
  author    = {H. Wang and J. Hu and L. Gao},
  title     = {Design and performance test of a test rig for grain flow sensor},
  booktitle = {2015 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)},
  year      = {2015},
  pages     = {1442-1445},
  month     = {June},
  abstract  = {In order to develop a grain flow sensor, a test rig was built. Three weighting sensors were mounted on the weighting bin in the test rig to calibrate grain flow sensor and verify the accuracy of grain flow sensor. A valve plate was inserted in the bottom of the feed bin. The feed flow could be controlled by adjusting opening of the valve plate. A weighting measurement model and a feed flow model were established respectively according to user manual and calibration experiments. Weighting accuracy and feed rate for the test rig was analyzed through experiments. Results showed that the maximum relative error of weighting was 1.12%, the minimum relative error was 0.36%, and the average relative error was 0.61%. The average relative error of feed flow ranging from 0.5 to 2.4 kg/s was less than 4%. The test rig developed is stable and reliable, and meets the requirements for development and testing of the grain flow sensor.},
  doi       = {10.1109/CYBER.2015.7288156},
  keywords  = {agriculture;calibration;crops;design engineering;flow sensors;precision engineering;test equipment;calibration;design;grain flow sensors;performance testing;test rig;weighting sensors;Accuracy;Calibration;Elevators;Feeds;Monitoring;Valves;Weight measurement;grain flow sensor;performance test;precision farming;test rigs},
}

@InProceedings{Matthys2002,
  author    = {K. Matthys and D. Vanhercke and S. Van Aken and K. De Groote and I. Coomans and P. Verdonck},
  title     = {Non-invasive assessment of hemodynamics in adolescents with arterial tonometry and Doppler ultrasound during a conventional stress test},
  booktitle = {Computers in Cardiology},
  year      = {2002},
  pages     = {517-520},
  month     = {Sept},
  abstract  = {Aiming to improve early diagnosis of people at cardiovascular risk, we are developing a custom set-up to allow an adequate hemodynamic analysis of heart function and arterial circulation properties, based on non-invasive acquisition of pressure (arterial tonometry) and flow (Doppler ultrasound techniques) waveforms. In an experimental setting 15 healthy volunteers were examined on a custom made supine bicycle. Able to record usable data throughout the bicycle test and automatically analyse derived hemodynamic parameters such as compliance, peripheral resistance, etc., we also applied the set-up in a real clinical environment. This research contributes to a more complete cardiovascular examination without significant additional discomfort for the patient or prolongation of the test protocol.},
  doi       = {10.1109/CIC.2002.1166823},
  issn      = {0276-6547},
  keywords  = {biomedical ultrasonics;blood flow measurement;blood pressure measurement;blood vessels;cardiovascular system;medical signal processing;Doppler ultrasound;adolescents;arterial circulation properties;arterial tonometry;automatic analysis;cardiovascular risk;clinical environment;compliance;data recording;diagnosis;healthy volunteers;heart function;noninvasive flow waveform acquisition;noninvasive hemodynamics assessment;noninvasive pressure waveform acquisition;peripheral resistance;stress test;supine bicycle;Bicycles;Cardiology;Heart;Hemodynamics;Hospitals;Laboratories;Probes;Stress;Testing;Ultrasonic imaging},
}

@InProceedings{Zhaohui2014,
  author    = {H. Zhaohui and L. Jixun and Y. Liu},
  title     = {Research on Anti-jamming Performance Test Planning of Active Radar Guided Air-to-Air Missile},
  booktitle = {2014 Seventh International Symposium on Computational Intelligence and Design},
  year      = {2014},
  volume    = {1},
  pages     = {15-17},
  month     = {Dec},
  abstract  = {With the air fight environment getting more and more complex, the anti-jamming performance of active radar guided air-to-air missile (ARGAAM) is noticed by all countries worldwide. This paper develops a new method to plan the anti-jamming performance test for ARGAAM characteristic. The method plans the missile anti-jamming performance test by flight test and digital simulation. Finally, the anti-jamming performance of ARGAAM is evaluated by example.},
  doi       = {10.1109/ISCID.2014.10},
  keywords  = {aerospace testing;interference suppression;jamming;missiles;radar interference;ARGAAM characteristics;active radar guided air-to-air missile;air fight environment;antijamming performance flight test planning;digital simulation;Atmospheric modeling;Data models;Global Positioning System;Jamming;Missiles;Performance evaluation;Planning;active radar guided air-to-air missile;anti-jamming performance;estimation;test planning},
}

@Article{Chen2018,
  author   = {T. Chen and F. Meng},
  title    = {Development and Performance Test of a Height-Adaptive Pesticide Spraying System},
  journal  = {IEEE Access},
  year     = {2018},
  volume   = {6},
  pages    = {12342-12350},
  abstract = {This paper investigate an adaptive pesticide spraying system according to the plants height. The system including a depth sensor and a spraying system with multiple nozzles at different height in vertical direction. The entire system is installed on an automatic guided vehicle. In order to implement precision spraying or automatic targeting, plant identification, and plant height calculation are critical for the system with fixed height of nozzles. The designed system will open one or combination of the nozzles of the spraying system since the plant height is identified. To address the plant height-adaptive challenge, a pesticide spraying system with plant height-adaptive is proposed based on a camera sensor to dealt with the figure of the plant. Both of the depth and color data of the figure are obtained and analyzed, the open or close state of the spraying system is optimized for different plants with different height. Various experimental results have demonstrated that the proposed system is considered as well.},
  doi      = {10.1109/ACCESS.2018.2813667},
  keywords = {agrochemicals;automatic guided vehicles;cameras;image sensors;nozzles;robot vision;spraying;sprays;automatic targeting plant identification;fixed height;height-adaptive pesticide spraying system;nozzles;plant height calculation;plant height-adaptive challenge;precision spraying;Acoustics;Cameras;Colored noise;Data processing;Image color analysis;Robot sensing systems;Spraying;Automatic guided vehicle;depth sensor;height-adaptive;precision spraying;signal processing},
}

@Article{Garousi2010,
  author   = {V. Garousi},
  title    = {A Genetic Algorithm-Based Stress Test Requirements Generator Tool and Its Empirical Evaluation},
  journal  = {IEEE Transactions on Software Engineering},
  year     = {2010},
  volume   = {36},
  number   = {6},
  pages    = {778-797},
  month    = {Nov},
  issn     = {0098-5589},
  abstract = {Genetic algorithms (GAs) have been applied previously to UML-driven stress test requirements generation with the aim of increasing chances of discovering faults relating to network traffic in distributed real-time systems. However, since evolutionary algorithms are heuristic, their performance can vary across multiple executions, which may affect robustness and scalability. To address this, we present the design and technical detail of a UML-driven, GA-based stress test requirements generation tool, together with its empirical analysis. The main goal is to analyze and improve the applicability, efficiency, and effectiveness and also to validate the design choices of the GA used in the tool. Findings of the empirical evaluation reveal that the tool is robust and reasonably scalable when it is executed on large-scale experimental design models. The study also reveals the main bottlenecks and limitations of the tools, e.g., there is a performance bottleneck when the system under test has a large number of sequence diagrams which could be triggered independently from each other. In addition, issues specific to stress testing, e.g., the impact of variations in task arrival pattern types, reveal that the tool generally generates effective test requirements, although the features of those test requirements might be different in different runs (e.g., different stress times from the test start time might be chosen). While the use of evolutionary algorithms to generate software test cases has been widely reported, the extent, depth, and detail of the empirical findings presented in this paper are novel and suggest that the proposed approach is effective and efficient in generating stress test requirements. It is hoped that the findings of this empirical study will help other SBSE researchers with the empirical evaluation of their own techniques and tools.},
  doi      = {10.1109/TSE.2010.5},
  keywords = {Unified Modeling Language;distributed algorithms;genetic algorithms;program testing;real-time systems;UML;distributed real time system;empirical analysis;genetic algorithm;software test cases;stress test requirement generation;Design for experiments;Evolutionary computation;Genetic algorithms;Large-scale systems;Real time systems;Robustness;Scalability;Stress;System testing;Telecommunication traffic;Index Term—Search-based testing;empirical analysis.;genetic algorithms;stress testing;test automation;test tools},
}

@InProceedings{Yuanlou2010,
  author    = {G. Yuanlou and F. Xiaoxing},
  title     = {A Research on the Torque Converter Performance Test-Bed Control System},
  booktitle = {2010 International Conference on Electrical and Control Engineering},
  year      = {2010},
  pages     = {3224-3226},
  month     = {June},
  abstract  = {According to the characteristics of test bed, using a motor driven program based on inverter with a speed sensor, and an eddy current dynamometer constant torsional loading scheme, it implements the stability of constant speed drive and torsional load for the torque converter test-bed, providing a good test environment for the performance test. This method is economical and practical, energy saving and environmental protective. The constant voltage-frequency ratio of frequency control method is applied in motor speed control, and a way of changing the excitation voltage to change the output torque of the eddy current dynamometer is used. The results show that the system achieve good control results.},
  doi       = {10.1109/iCECE.2010.787},
  keywords  = {drives;dynamometers;eddy currents;frequency control;invertors;machine control;stability;three-term control;torque convertors;velocity measurement;PID;constant speed drive stability;constant voltage-frequency ratio;eddy current dynamometer constant torsional loading scheme;excitation voltage;frequency control method;inverter;motor driven program;motor speed control;performance test;speed sensor;test-bed control system;torque converter;Automation;Control engineering;Eddy currents;Educational institutions;Torque converters;Voltage control;PID;eddy current dynamometer;hydraulic torque converter},
}

@InProceedings{Chae2012,
  author    = {Eunkyung Chae and Kangmi Lee and Kyung-hee Kim and Jaeho Lee},
  title     = {Performance test on radio communication device for train control system},
  booktitle = {2012 7th International Conference on Computing and Convergence Technology (ICCCT)},
  year      = {2012},
  pages     = {462-465},
  month     = {Dec},
  abstract  = {Train control system controls the headway and train route to prevent collisions and derailment of train on the basis of the train location. Radio communication based train control system can enhance the headway and safety of train in the manner of using radio communications instead of the wayside equipment such as the track circuit installed in the track. Radio communication based train control system uses the standard of IEEE 802.11 which uses an unlicensed frequency band because there is no dedicated frequency for railways. Since there is the risk where the frequency interference and other interference problems can be occurred because the unlicensed band might be used by various wireless devices, we analyzed wireless environments of Daebul Line which was selected as the test section, and in this paper, we measured the performance of radio communication device to be applied to the radio communication network and selected a optimized location which has no shaded area.},
  keywords  = {collision avoidance;radio equipment;rail traffic control;railway safety;wireless LAN;Daebul Line;IEEE 802.11standard;collision prevention;frequency interference;radio communication based train control system;radio communication device;radio communication network;train derailment prevention;train route control;unlicensed frequency band;wireless devices;Train control system;radio communications},
}

@InProceedings{Lee2007,
  author    = {Young-Ho Lee and Hae-Young Park and Eui-Cheol Nho and In-Dong Kim and Tae-Won Chun and Heung-Geun Kim and Nam-Sup Choi},
  title     = {Improved voltage disturbance generator for the performance test of the custom power devices},
  booktitle = {2007 International Conference on Electrical Machines and Systems (ICEMS)},
  year      = {2007},
  pages     = {175-179},
  month     = {Oct},
  abstract  = {An improved voltage disturbance generator is proposed. To test the performance of the custom power devices such as DVR, SSTS, dynamic UPS, etc., a voltage disturbance generator is necessary. The proposed generator has good features of high reliability, low cost, simple structure, high efficiency, and reduced voltage drop. The main switching device is SCR thyristor, and all the thyristors have natural commutation characteristics, which provides reliable system. The circuit analysis and operating principle of the proposed scheme are described in each mode of voltage sag, swell, outage, and unbalance. Simulation and experimental results show the usefulness of the proposed scheme.},
  keywords  = {network analysis;power supply quality;thyristors;SCR thyristor;circuit analysis;custom power devices;reduced voltage drop;reliability;voltage disturbance generator;Automation;Circuit simulation;Costs;Electronic equipment;Power generation;Switches;Testing;Thyristors;Uninterruptible power systems;Voltage fluctuations},
}

@InProceedings{Park1997,
  author    = {Jang-Hyun Park and Yea-Chul Rho},
  title     = {Performance test of Viterbi decoder for wideband CDMA system},
  booktitle = {Design Automation Conference, 1997. Proceedings of the ASP-DAC '97 Asia and South Pacific},
  year      = {1997},
  pages     = {19-23},
  month     = {Jan},
  abstract  = {This paper describes the design, the implementation, and the performance test of the Serial Viterbi decoder (SVD) using VHDL and FPGAs. The decoding scheme assumes the transmitted symbols were coded with a K=9, 32 Kbps, and rate 1/2 convolutional encoder with generator function g0=(753)8 and g1=(561)8 as defined in the JTC TAG-7 W-CDMA PCS standard. The SVD is designed using VHDL and implemented using FPGAs. The main algorithm is implemented in two Altera FLEX81500 FPGAs. The performance test results with 3DB Gaussian noise show that the SVD works well},
  doi       = {10.1109/ASPDAC.1997.600052},
  keywords  = {Gaussian noise;Viterbi decoding;broadband networks;code division multiple access;field programmable gate arrays;hardware description languages;logic CAD;telecommunication computing;telecommunication standards;testing;32 kbit/s;Altera FLEX81500;CDMA PCS standard;FPGA;Gaussian noise;Serial Viterbi decoder;VHDL;Viterbi decoder performance testing;convolutional encoder;decoding scheme;generator function;symbols;wideband CDMA system;Code standards;Convolutional codes;Decoding;Field programmable gate arrays;Gaussian noise;Multiaccess communication;Personal communication networks;System testing;Viterbi algorithm;Wideband},
}

@InProceedings{Tian2017,
  author    = {Y. Tian and J. Wei and M. Jiang and L. Zhang and F. Zhang and Q. Sui and W. Sun},
  title     = {Drive design and performance test of a tunable DFB laser},
  booktitle = {2017 Chinese Automation Congress (CAC)},
  year      = {2017},
  pages     = {4024-4027},
  month     = {Oct},
  abstract  = {In order to meet the requirements of TDLAS technology and to ensure the optical wavelength stability and the optical power stability of the laser light source, we design the DFB (distributed feedback) laser drive system using STM32 as the controller. The hardware circuit mainly includes drive current control circuit, constant temperature control circuit and laser optical power monitoring circuit. Then, the performance test of 1550nm DFB laser is carried out. Test condition is under the normal atmospheric temperature and ensuring constant control current. The test shows that the range of the laser output wavelength is 3pm and the optical power fluctuation is less than 0.005mW after preheating an hour. The stability of the optical wavelength and optical power is excellent.},
  doi       = {10.1109/CAC.2017.8243484},
  keywords  = {distributed feedback lasers;electric current control;laser beams;laser noise;laser stability;laser tuning;light sources;optical testing;semiconductor lasers;temperature control;DFB laser drive system;STM32;TDLAS technology;constant control current;constant temperature control circuit;distributed feedback;drive current control circuit;drive design;hardware circuit;laser light source;laser optical power monitoring circuit;laser output wavelength;normal atmospheric temperature;optical power fluctuation;optical power stability;optical wavelength stability;performance test;power 0.005 mW;test condition;tunable DFB laser;wavelength 1550.0 nm;wavelength 3.0 pm;Distributed feedback devices;Laser stability;Optical reflection;Power lasers;Semiconductor lasers;Temperature control;Constant current control;DFB Laser;Optical power stability;Optical wavelength stability;temperature control},
}

@InProceedings{Zhu2011,
  author    = {Xingwang Zhu and Xueli Nie and Yanli Lv and Fenying Guo and Yugui Su},
  title     = {Performance test of compound system for air conditioning and hot water},
  booktitle = {2011 International Conference on Materials for Renewable Energy Environment},
  year      = {2011},
  volume    = {2},
  pages     = {1153-1161},
  month     = {May},
  abstract  = {Air conditioning and hot water compound system in which air-cooling heat exchanger is connected with heat recovery heat exchanger in series is studied, system fundamentals and five running modes including single refrigerating mode, single heating mode, hot water mode, refrigerating and hot water mode and heating and hot water mode are introduced, and experimental research is developed. Experimental research on operation characteristics of refrigerating capacity, heating capacity and suction and discharge temperature and pressure show that the unit operates reliably long in different operation conditions and that the variation of characteristics is within a reasonable range. Coefficient of performance of the system in refrigerating and hot water mode and in heating and hot water mode is highest with the minimal value approximately 3.2 when the temperature of water tank climbs up to 55°C, as the service efficiency of the unit is improved by recovering the condenser heat to heat hot water. The system is avoided to operate in the region of maximum power, and had better operate in the variable flow region of capillary and large air volume and small temperature difference region as much as possible.},
  doi       = {10.1109/ICMREE.2011.5930543},
  keywords  = {air conditioning;cooling;heat exchangers;heat recovery;refrigeration;water;air conditioning;air cooling heat exchanger;coefficient of performance;compound system performance test;condenser heat recovery;discharge temperature;heat suction;heating capacity;hot water mode;hot water system;refrigeration capacity;single heating mode;single refrigerating mode;water tank;Discharges;Electromagnetic heating;Heat pumps;Heat recovery;Legged locomotion;Water heating;compound system for air conditioning and hot water;condenser heat recovery;energy-savingcomponent},
}

@InProceedings{Yongjie2017,
  author    = {F. Yongjie and C. Ying},
  title     = {Performance test of laser power meter verification system},
  booktitle = {2017 13th IEEE International Conference on Electronic Measurement Instruments (ICEMI)},
  year      = {2017},
  pages     = {132-135},
  month     = {Oct},
  abstract  = {Aimed at the requirements of laser equipment, a verification system of laser power meter is established. The system can realize the verification and calibration of laser power meter with wavelength of 532nm, 633nm, 1064nm and power measurement range of 0.1mW to 20W. The relative expanded uncertainty of the system reaches 2% (k=2). The composition and working principle of the system are described in detail. The test methods and measurement data are given for the main parameters of system performance test, such as power stability of laser, power monitoring ratio stability of laser power beam splitter monitoring and correcting device, correction factor of standard laser power meter. After the system test, the performance of the laser power meter verification system has been more perfectly examined.},
  doi       = {10.1109/ICEMI.2017.8265741},
  keywords  = {calibration;laser variables measurement;measurement uncertainty;optical beam splitters;optical testing;power measurement;power meters;calibration;laser equipment;laser power beam splitter monitoring;laser power correcting device;laser power meter verification system;power 0.1 mW to 20 W;power measurement;power monitoring ratio stability;system performance test;wavelength 1064.0 nm;wavelength 532.0 nm;wavelength 633.0 nm;Laser beams;Laser stability;Measurement by laser beam;Meters;Power lasers;Power measurement;Standards;Laser power meter;Optical metrology;Performance Test;Verification/Calibration},
}

@Article{Ruan2012,
  author   = {J. J. Ruan and N. Monnereau and D. Trémouilles and N. Mauran and F. Coccetti and N. Nolhier and R. Plana},
  title    = {An Accelerated Stress Test Method for Electrostatically Driven MEMS Devices},
  journal  = {IEEE Transactions on Instrumentation and Measurement},
  year     = {2012},
  volume   = {61},
  number   = {2},
  pages    = {456-461},
  month    = {Feb},
  issn     = {0018-9456},
  abstract = {This paper addresses an innovative solution to develop a circuit to perform accelerated stress tests of capacitive microelectromechanical-system (MEMS) switches and shows the use of instruments and equipment to monitor physical aging phenomena. A dedicated test circuit was designed and fabricated in order to meet the need for accelerated techniques for those structures. It integrated an in-house miniaturized circuit connected to additional test equipment (e.g., oscilloscopes and capacitance meters) that enabled the reliability characterization of capacitive switches. The accelerated stress test (AST) circuit generated an electrostatic-discharge-like impulse that stressed the device. This setup allowed the simultaneous measurement of the current and voltage waveforms, and the capacitance variation of the device under test after each stress. The results obtained using the miniature AST circuit were discussed and were correlated with results obtained using a commercial human-body-model tester as well as data from a cycling benchmark. The scope of this paper encompasses the theory, methodology, and practice of measurement; the development of a testing miniaturized board; and the analysis and representation of the information obtained from a set of measurements. As a result, it may contribute to the scientific and technical standards in the field of instrumentation and measurement of electrostactically actuated devices having insulating layers.},
  doi      = {10.1109/TIM.2011.2161937},
  keywords = {circuit reliability;circuit testing;electric current measurement;electrostatic discharge;life testing;microswitches;network synthesis;semiconductor device measurement;semiconductor device testing;test equipment;voltage measurement;MEMS switches;accelerated stress test circuit;accelerated stress test method;accelerated techniques;additional test equipment;capacitance variation;capacitive microelectromechanical-system switches;capacitive switches;current waveforms;cycling benchmark;device under test;electrostactically actuated devices;electrostatic-discharge-like impulse;electrostatically driven MEMS devices;human-body-model tester;in-house miniaturized circuit;innovative solution;insulating layers;miniature AST circuit;physical aging phenomena;reliability characterization;testing miniaturized board;voltage waveforms;Discharges;Life estimation;Micromechanical devices;Radio frequency;Reliability;Stress;Testing;Accelerated testing;charging;dielectric breakdown;electrostatic discharges (ESDs);microelectromechanical devices;reliability testing},
}

@InProceedings{Yamei2016,
  author    = {F. Yamei and L. Qing and H. Qi},
  title     = {Research and comparative analysis of performance test on SDN controller},
  booktitle = {2016 First IEEE International Conference on Computer Communication and the Internet (ICCCI)},
  year      = {2016},
  pages     = {207-210},
  month     = {Oct},
  abstract  = {The emergence of Software Defined Network(SDN) gives the demand of big data and network management a chance. SDN separates the control and forwarding in traditional network through OpenFlow protocol. In the software-defined network, SDN controller is an important integral part that is the core of SDN. In this paper, firstly we summarize the common SDN controller, and choose two popular, wider using open-source controllers(OpenDaylight and ONOS), analyze the implementation architecture and model framework of the two controllers. Then build the controller platform, simulate the underlying topology using IXIA test instruments, Cbench and Mininet to get the performance parameters and furthermore analyze the data.},
  doi       = {10.1109/CCI.2016.7778909},
  keywords  = {protocols;software defined networking;telecommunication network management;telecommunication network topology;Cbench;IXIA test instruments;Mininet;ONOS;OpenDaylight;OpenFlow protocol;SDN;network management;open-source controllers;software defined network;Network topology;Protocols;Switches;Throughput;Time factors;Topology;ONOS;OpenDaylight;SDN;Test},
}

@InProceedings{Lu2008,
  author    = {Y. Lu and D. Yan and S. Nie and C. Wang},
  title     = {Development of an Improved GUI Automation Test System Based on Event-Flow Graph},
  booktitle = {2008 International Conference on Computer Science and Software Engineering},
  year      = {2008},
  volume    = {2},
  pages     = {712-715},
  month     = {Dec},
  abstract  = {A more highly automated graphic user interface (GUI) test model, which is based on the event-flow graph, is proposed. In the model, an automation tool is first used to carry out reverse engineering for a GUI test sample so as to obtain the event-flow graph. Then an improved ant colony optimization algorithm and a goal-directed searching approach are adopted to create GUI test sample cases. Moreover, a corresponding prototype system based on Microsoft UI automation framework is developed.},
  doi       = {10.1109/CSSE.2008.1336},
  keywords  = {graph theory;graphical user interfaces;optimisation;program testing;search problems;GUI automation test system;ant colony optimization algorithm;event-flow graph;goal-directed searching;graphic user interface;reverse engineering;Ant colony optimization;Artificial intelligence;Automatic testing;Automation;Graphical user interfaces;Prototypes;Reverse engineering;Software engineering;Software testing;System testing},
}

@InProceedings{Yuqing2012,
  author    = {L. Yuqing and X. Hao and L. Xiaohui},
  title     = {The Research of Performance Test Method for Linux Process Scheduling},
  booktitle = {2012 Fourth International Symposium on Information Science and Engineering},
  year      = {2012},
  pages     = {216-219},
  month     = {Dec},
  abstract  = {Performance test plays a fundamental and irreplaceable role in the field of software test, especially in guaranteeing the quality and reliability of an operating system. The performance of the process scheduling subsystem directly affects the accuracy and stability of the whole operating system. Linux operating system vendors execute performance test almost in every period of the Linux operating system research and development to enhance their products' competitiveness. However, the lack of methods and tools for the Linux process scheduling performance test has caused great difficulties for Linux operating system vendors to evaluate and tune the Linux kernel performance. Therefore, in order to solve the issues mentioned above, this paper, based on the analysis of Linux process scheduling mechanism, proposes a Linux process scheduling performance test method, implements a Linux process scheduling performance test tool as well, and finally validates the tool experimentally.},
  doi       = {10.1109/ISISE.2012.54},
  issn      = {2160-1283},
  keywords  = {Linux;operating system kernels;program testing;scheduling;software performance evaluation;software reliability;Linux kernel performance;Linux operating system vendors;Linux process scheduling performance test tool;operating system accuracy;operating system quality;operating system reliability;operating system stability;process scheduling subsystem;software test;benchmark test;linux;performance analysis;performance testing;process scheduling},
}

@InProceedings{Lin2010,
  author    = {W. K. Lin and P. C. Wang and H. P. Wang},
  title     = {Using Thermoelectric Cooling Chip (T.E.C.) to improve the stability of the Heat Pipe Performance Test Instrument},
  booktitle = {2010 5th International Microsystems Packaging Assembly and Circuits Technology Conference},
  year      = {2010},
  pages     = {1-4},
  month     = {Oct},
  abstract  = {Heat pipe is a device of high heat-conduction. It mainly uses inside fluid to carry heat energy while the phase is changing. It's a tool which can transmit a large amount of heat energy in operating temperature while phase is changing. Therefore, heat pipe also named the superconductor. The major purpose of this study is to analyze the affect of the condenser parameters to Heat Pipe Performance. A T.E.C. controller (Thermoelectric Cooling Chip Controller) to measure the condenser section of HPPTI (Heat Pipe Performance Test Instrument) is developed in this study, which can exactly control the temperature in adiabatic section and condenser section very accurately. The experimental results show the maximum heat loading controlled by T.E.C. is the same as that of controlled by water cooling, but the test time is reduce from 7 hours to 3.5 hour, and the final target for test time we expected will be achieved within 20 minutes.},
  doi       = {10.1109/IMPACT.2010.5699661},
  issn      = {2150-5934},
  keywords  = {cooling;heat conduction;heat losses;heat pipes;thermoelectric devices;condenser parameters;heat energy;heat pipe performance test instrument;heat-conduction;stability;thermoelectric cooling chip;Heat Pipe;Maximum Heat Loading;Thermoelectric Chip;heat loss},
}

@InProceedings{Han2015,
  author    = {S. Han and G. Park and G. Lyu and Y. Lee and H. Kim},
  title     = {Performance test and analysis of infrared gas sensors and a combustible gas detector},
  booktitle = {2015 15th International Conference on Control, Automation and Systems (ICCAS)},
  year      = {2015},
  pages     = {1413-1416},
  month     = {Oct},
  abstract  = {Recently, we can find news about toxic and combustible gas accident. So, we have to develop gas detector that can measure gas safely at dangerous area and be possible to monitor gas detection at remote area. In this paper, we analyze and estimate gas sensor modules and combustible gas detectors that is already developed, by using standard gas sample manufactured Korea Gas Safety. We apply result analyzed data from experience for developing next generation combustible gas detector.},
  doi       = {10.1109/ICCAS.2015.7364862},
  issn      = {2093-7121},
  keywords  = {combustion;gas sensors;infrared detectors;Korea Gas Safety;combustible gas detector;gas measurement;infrared gas sensor module;toxic;Detectors;Gas detectors;Least squares approximations;Standards;Testing;Combustible;Detector;Gas;Infrared;Sensor},
}

@InProceedings{Qiu2011,
  author    = {Q. Qiu and L. Zhu and T. Zhao and Z. Liang and X. Yang},
  title     = {A Distributed Storage Performance Test System: Design, Implementation, and Experience},
  booktitle = {2011 Fourth International Joint Conference on Computational Sciences and Optimization},
  year      = {2011},
  pages     = {783-786},
  month     = {April},
  abstract  = {With the rapid development of storage technology, many kinds of storage products and systems have been released, but these products and systems always have some problems such as the performance is not credible, the reliability is not high and so on. In order to better test and evaluate the performance of storage products and systems, we design and implement a distributed Storage Performance Test System called SPTS, which can test the IO performance of file system and disk array. The experience of testing disk array's IOPS and data transfer rate shows that SPTS can provide certain value when customers purchase and use storage products or storage systems.},
  doi       = {10.1109/CSO.2011.28},
  keywords  = {RAID;performance evaluation;storage management;data transfer rate;disk array;distributed storage performance test system;file system;reliability;storage products;storage technology;Arrays;Bandwidth;Benchmark testing;File systems;Monitoring;Throughput;IO performance;IOPS;data rate;disk array;file system;storage test},
}

@InProceedings{Hackenberg2013,
  author    = {D. Hackenberg and R. Oldenburg and D. Molka and R. Schöne},
  title     = {Introducing FIRESTARTER: A processor stress test utility},
  booktitle = {2013 International Green Computing Conference Proceedings},
  year      = {2013},
  pages     = {1-9},
  month     = {June},
  abstract  = {Processor stress test utilities are important tools for a number of different use cases. In particular, cooling systems need to be tested at maximum load in order to ensure that they fulfill their specifications. Additionally, a test system characterization in terms of idle and maximum power consumption is often a prerequisite for energy efficiency research. This creates the need for a simple yet versatile tool that generates near-peak power consumption of compute nodes. While in different research areas tools such as LINPACK and Prime95 are commonly used, these tools are just highly optimized and compute intense routines that solve specific computational problems. As stress test utilities they are unnecessarily hard to use and in many cases unreliable in terms of power consumption maximization. We propose FIRESTARTER, an Open Source tool that is specifically designed to create near-peak power consumption. Our experiments show that this task cannot be achieved with generic high-level language code. We therefore use highly optimized assembly routines that take the specific properties of a given processor microarchitecture into account. A study on four compute nodes with current or last generation x86_64 processors shows that we reliably exceed the power consumption of other stress tests and create very steady power consumption patterns.},
  doi       = {10.1109/IGCC.2013.6604507},
  keywords  = {microprocessor chips;performance evaluation;power aware computing;Firestarter open source tool;assembly routines;cooling systems;energy efficiency research;high-level language code;near-peak power consumption;power consumption patterns;processor stress test utility;test system characterization;x86_64 processors;Bridges;Microarchitecture;Out of order;Ports (Computers);Power demand;Registers;Stress;FIRESTARTER;LINPACK;Prime95},
}

@Article{Foote1992,
  author   = {S. A. Foote and D. B. Grindeland},
  title    = {Model QA3000 Q-Flex accelerometer high performance test results},
  journal  = {IEEE Aerospace and Electronic Systems Magazine},
  year     = {1992},
  volume   = {7},
  number   = {6},
  pages    = {59-67},
  month    = {June},
  issn     = {0885-8985},
  abstract = {Q-Flex quartz flexure suspension technology has evolved to produce a world class accelerometer with thousands of units delivered in 1991. The Sundstrand Model QA3000 Q-Flex design achieves a new level of inertial grade performance while maintaining a competitive market price. The specification for the QA3000, supported by actual performance data, depicts performance characteristics superior in both bias and scale factor. Long term measurements display bias and scale factor repeatability obtained across temperature over a period of three years. These data exhibit improved thermal behavior with reduced errors. Reaction time and radiation data highlight the performance of the hybrid position detector circuit.<>},
  doi      = {10.1109/62.145120},
  keywords = {accelerometers;aerospace instrumentation;aircraft instrumentation;Q-Flex quartz flexure suspension technology;Sundstrand Model QA3000;accelerometer;bias;errors;hybrid position detector circuit;performance characteristics;quartz flexure;radiation data;radiation tolerance;reaction time;scale factor;seismic environment;thermal behavior;time stability;Acceleration;Accelerometers;Aircraft navigation;Automatic testing;Coils;Extraterrestrial measurements;Magnetic levitation;Magnetic sensors;Temperature;Voltage},
}

@InProceedings{Huey-Der2010,
  author    = {C. Huey-Der and J. F. Yang},
  title     = {The Lesson Learned of a System's Performance Test},
  booktitle = {2010 Second World Congress on Software Engineering},
  year      = {2010},
  volume    = {2},
  pages     = {270-276},
  month     = {Dec},
  abstract  = {This paper, by mirroring the performance testing of a given company's merchandising distribution information system, has attempted to resolve the demands in function testing without the aid of any market-sold automated testing tools, to decipher a system's loading response time in an effort to help improve the system functions.},
  doi       = {10.1109/WCSE.2010.153},
  keywords  = {management information systems;performance evaluation;resource allocation;company merchandising distribution information system;performance testing;system loading response time;Databases;Load modeling;Loading;Servers;Software;Testing;Time factors;Client/Server;Loading;Performance Testing},
}

@InProceedings{Hosseinizadeh2009,
  author    = {P. Hosseinizadeh and A. Guergachi},
  title     = {Using heavy-tailed distributions to stress-test kernel methods for segregating the firms that are likely to survive},
  booktitle = {2009 IEEE International Conference on Systems, Man and Cybernetics},
  year      = {2009},
  pages     = {1464-1469},
  month     = {Oct},
  abstract  = {While kernel-based learning methods have emerged during the last two decades as major tools to effectively manage uncertainty, heavy-tailed distributions remain a major challenge for modelers who aim to predict the future behavior of complex systems. In this article, Weibull distribution has been used to stress-test kernel-based methods and study more specifically the impact of heavy-tailed distributions on the performance of Fisher kernels in identifying the potential for collapse of an enterprise based on its stock price.},
  doi       = {10.1109/ICSMC.2009.5346298},
  issn      = {1062-922X},
  keywords  = {Weibull distribution;corporate modelling;learning (artificial intelligence);Fisher kernels;Weibull distribution;complex systems;enterprise;heavy-tailed distributions;kernel-based learning;stock price;stress-test kernel methods;Computational modeling;Gaussian distribution;Kernel;Learning systems;Mathematical model;Predictive models;Probability distribution;Statistical learning;Uncertainty;Weibull distribution;Fisher kernel;Weibull distribution;financial time series;heavy-tailed distributions;modelling;prediction},
}

@InProceedings{Xiaoqin2011,
  author    = {Zhang Xiaoqin and Li Zhihong and Wang Baoliang and Wang Lianchuan},
  title     = {Performance test and data acquisition of voltage regulator for automotive alternator},
  booktitle = {Proceedings 2011 International Conference on Transportation, Mechanical, and Electrical Engineering (TMEE)},
  year      = {2011},
  pages     = {707-710},
  month     = {Dec},
  abstract  = {The dynamic testing system of voltage regulator must be assembled with the automotive alternator, so it's large, expensive, power consumption and operation complexity. A static testing system was developed by using electronic analog generator in place of automotive alternator sets. The system communicated with the computer can carry out performance test and data acquisition, in turn to analysis performance for large quantities of products. The paper described the methods of static testing and the principles of data acquisition. By comparison, it's proved that the static testing system is simple, reliable, easy to operate, cheap and accurate. Its accuracy came to 0.1 relative to dynamic testing system.},
  doi       = {10.1109/TMEE.2011.6199300},
  keywords  = {alternators;automotive electronics;data acquisition;dynamic testing;voltage regulators;automotive alternator sets;data acquisition;dynamic testing system;electronic analog generator;operation complexity;power consumption;static testing system;voltage regulator;Alternators;Data acquisition;Regulators;Testing;Vehicle dynamics;Voltage control;automotive alternator;data acquisition;electrical performance;static test;voltage regulator},
}

@InProceedings{Liao2011,
  author    = {Huaiwei Liao and M. Ilic},
  title     = {Stress test model of cascading failures in power grids},
  booktitle = {2011 North American Power Symposium},
  year      = {2011},
  pages     = {1-5},
  month     = {Aug},
  abstract  = {Cascading failures in electric power systems are one of the major causes of large power blackouts. The operators in control centers of electric power systems need an online tool to monitor the risk of cascading failures when transferring large quantities of power over long distances. In this paper, we propose a two-stage stress test model of cascading failures. The stress test model is intended to emulate the effect of security-constrained economic dispatch (SCED) in support of the required power transfer level, and at the same time, to account for relay actions in response to a given set of severe disturbances, called maximum credible disturbances. The model includes an inner stage, which simulates cascading outages due to relay actions in the system at a given state under disturbances, and an outer stage, which moves the operating point of the system as the power transfer increases as a result of SCED. We use the stress test model to simulate cascading failures in a real 3000-bus power system when increasing its power transfer level in different directions.},
  doi       = {10.1109/NAPS.2011.6025200},
  keywords  = {failure analysis;load dispatching;power grids;power system security;power transmission control;power transmission economics;power transmission reliability;risk analysis;SCED;cascading failures;cascading outages;electric power system control;power blackouts;power grids;power transfer level;risk analysis;security-constrained economic dispatch;stress test model;Load modeling;Power system faults;Power system protection;Protective relaying;Stress},
}

@Article{Lin2017,
  author   = {Y. D. Lin and Y. K. Lai and C. Y. Wang and Y. C. Lai},
  title    = {OFBench: Performance Test Suite on OpenFlow Switches},
  journal  = {IEEE Systems Journal},
  year     = {2017},
  pages    = {1-11},
  issn     = {1932-8184},
  abstract = {Performance issues of OpenFlow switches are attracting a lot of attention owing to the potential large-scale deployment of software-defined devices. This paper presents the OFBench which is an automatic test suite for evaluating the performance of OpenFlow switches. The design, as part of the Automation Control Test System (ACTS) development, is based on a controller-agent architecture which allows the development of test cases that are written in a high-level script language. In addition to the end-to-end measurement methodology, novel methods are proposed to further profile the internal performance metrics, which are difficult to get due to the black-box nature of the device under test. The prototype of this suite currently comprises five test cases to evaluate five performance metrics, which are action time, pipeline time, buffer size, pipeline efficiency, and timeout accuracy. OpenFlow switches are evaluated and three issues are observed associated with switches during the testing. First, some switches may not be well implemented in the design of apply-action instructions. Second, some switches suffer from random crashes with a high volume of bursty packet-in traffic. Finally, the timer of idle-timeout is often not reset properly with matching flow entry.},
  doi      = {10.1109/JSYST.2017.2720758},
  keywords = {Control systems;Performance evaluation;Pipelines;Process control;Protocols;Testing;Computer networks;openflow protocol;performance evaluation;software-defined networks;system performance;testing},
}

@InProceedings{Yujie2011,
  author    = {Zhang Yujie and Zhang Yuanyuan},
  title     = {Design and implementation of OLED optical performance test system},
  booktitle = {IEEE 2011 10th International Conference on Electronic Measurement Instruments},
  year      = {2011},
  volume    = {2},
  pages     = {38-41},
  month     = {Aug},
  abstract  = {For the defects of the manual measurement of OLED optical performance by using discrete devices, this paper presented a platform which can measure the optical and electrical property of the light-emitting device of the OLED at the same time. It drew the real-time curve via the host computer to monitor and compare the performance data. It implemented a rapid, accurate and reliable automatic measurement system. And it improved the measure efficiency and accuracy greatly. It plays an important role in the study of the optical carriers transport properties, luminescence properties, luminous efficiency of OELD devices.},
  doi       = {10.1109/ICEMI.2011.6037760},
  keywords  = {automatic test equipment;luminescence;optical properties;organic light emitting diodes;OLED;automatic measurement system;discrete devices;electrical property;luminescence properties;luminous efficiency;optical carriers transport properties;optical performance test system;real time curve;Computers;Integrated optics;Optical sensors;Optical switches;Optical variables measurement;OLED;optical properties;test simultaneously},
}

@InProceedings{Dong2015,
  author    = {Y. Dong and J. Huang and M. Ding and H. Li and S. Zhang},
  title     = {Performance test and evaluation of photovoltaic system},
  booktitle = {International Conference on Renewable Power Generation (RPG 2015)},
  year      = {2015},
  pages     = {1-4},
  month     = {Oct},
  abstract  = {In this paper, the performance ratio (PR) of PV system is evaluated by field testing. The sampling strategy of efficiency chain for PV system is determined by analyzing long-term operation monitoring data of PV system. The efficiency parameters of components are extracted. The efficiency model of components in PV system is established in PVsyst software. Combining efficiency models, geographic information and the long time weather information, the PR of PV system and the yield over the next twenty-five years can be evaluated.},
  doi       = {10.1049/cp.2015.0500},
  keywords  = {photovoltaic power systems;PV system;PVsyst software;efficiency models;geographic information;long time weather information;long-term operation monitoring data;performance ratio;photovoltaic system;sampling strategy;PV inverter efficiency;PV system;PV system power generation;Performance ratio (PR)},
}

@InProceedings{Yeom2008,
  author    = {Hankil Yeom and Seung Woo Lee},
  title     = {Performance test of gas by-pass type thermal error controller},
  booktitle = {2008 International Conference on Control, Automation and Systems},
  year      = {2008},
  pages     = {1471-1474},
  month     = {Oct},
  abstract  = {In accordance with the trend for high-speed and multi-axes of machine tools, thermal deformation has become an important factor in the accuracy of machine tools. It was analyzed that thermal deformation error accounts for about 70% of all errors made with machine tools. For precise temperature control, both cooling and heating should be done. A hot gas by-pass type of cooling method has a simplified structure and temperature control accuracy to with in plusmn0.1 degC. In this study, the operational characteristics of the thermal error controller, including temperature controllability according to hot gas flow and preset temperature sustainability according to heat load, were tested. It is expected that this study will contribute to the development and performance assessment of thermal error controllers, which could minimize thermal errors and improve the quality of semiconductor equipment, precision injection molds, and precision machine tools.},
  doi       = {10.1109/ICCAS.2008.4694374},
  keywords  = {cooling;heating;machine tools;temperature control;cooling;gas by-pass type thermal error controller;heating;machine tools;temperature control;temperature sustainability;thermal deformation;Controllability;Cooling;Error correction;Fluid flow;Heating;Machine tools;Temperature control;Testing;Thermal factors;Thermal loading;cooling cycle;hot gas by-pass;thermal error controller},
}

@InProceedings{Kato2016,
  author    = {Y. Kato and M. Koike and K. Kurabe and K. Jinno and K. Yamashita and K. Tatsuno},
  title     = {Task performance test on grasping the bolt by a power distribution line maintenance experimental robot system},
  booktitle = {2016 International Symposium on Micro-NanoMechatronics and Human Science (MHS)},
  year      = {2016},
  pages     = {1-7},
  month     = {Nov},
  abstract  = {We have been developing a power distribution line maintenance robot system. This system will autonomously carry out basic tasks in the maintenance work. For examples, “Grasping a bolt”, “Inserting a bolt”, “Tightening a nut” and so on. We perform a task performance test “Grasp the bolt on the tool box”. The system grasps the bolt on tool box under visual feedback from the hand-eye camera. Applied visual feedback control does not require camera calibration and arm calibration because this visual feedback adjusts the bolt and the gripper in one image plane using the hand-eye camera.},
  doi       = {10.1109/MHS.2016.7824232},
  keywords  = {calibration;fasteners;maintenance engineering;power distribution lines;robots;arm calibration;bolt grasping;camera calibration;hand-eye camera;image plane;power distribution line maintenance experimental robot system;task performance test;visual feedback control;Cameras;Fasteners;Grippers;Manipulators;Robot sensing systems;Visualization},
}

@InProceedings{Si2016,
  author    = {Chaogang Si and Changmin Teng and Li Wang},
  title     = {Design and performance test in an interconnected TD-LTE train-ground communication for urban rail transit system},
  booktitle = {2016 IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)},
  year      = {2016},
  pages     = {1734-1737},
  month     = {Oct},
  abstract  = {In existing urban rail transit system, because of long construction period, train-ground communication system for different rail lines may use equipment from different manufacturer, that will bring challenges for management of metro company, even, it may result in emergency brake of train or traffic safety when a train is going across different lines. In this paper, we first study relevant demands of TD-LTE train-ground communication interconnection, an interconnected TD-LTE train-ground communication system for the urban rail transit system is designed next, in order to test the interconnected TD-LTE based train-ground communication system performance, an indoor testing environment is set up. The programmable attenuators and EIT-Monitor are used to simulate the real urban rail transit environment and monitor signal from different network equipment. Final test results prove that the designed interconnected TD-LTE train-ground communication can be applied to current train control system, which completely satisfies the demand of subway operation in urban rail transit system.},
  doi       = {10.1109/IMCEC.2016.7867515},
  keywords  = {Long Term Evolution;electric impedance imaging;rail traffic control;railway communication;railway safety;EIT-monitor;interconnected TD-LTE train-ground communication system;metro company management;programmable attenuators;signal monitoring;subway operation;traffic safety;train control system;train emergency brake;urban rail transit system;Attenuators;Chaotic communication;Coaxial cables;Long Term Evolution;Monitoring;Power dividers;Rails;TD-LTE;interconnection;test;train-ground communication system},
}

@InProceedings{Shengbing2015,
  author    = {Shi Shengbing and Song Chunyan and Wu Yanlin},
  title     = {CAN bus performance test technology},
  booktitle = {2015 12th IEEE International Conference on Electronic Measurement Instruments (ICEMI)},
  year      = {2015},
  volume    = {03},
  pages     = {1395-1399},
  month     = {July},
  abstract  = {With the development of high and new technology, the degree of weapon equipments' integration, digitization and information became more and more higher. CAN bus technology is also used more and more widely. The self-performance of CAN bus effects weapon equipments' information interaction such as instructs convey, default detection and so on. It also has vital influence on weapon equipments to carry out fight tasks. In this paper, through analyzing CAN bus architecture of certain weapon and data transmission characteristic on CAN bus, analyses several problems on CAN bus performance test, including test system structure, test data capacity analysis and data processing. Through constructing one test environment, proves this method is scientific and logical, lays the technological foundation of implementing CAN bus performance test.},
  doi       = {10.1109/ICEMI.2015.7494507},
  keywords  = {Computers;Constitution;Data processing;Monitoring;Weapons;CAN bus;performance test;weapon equipments},
}

@InProceedings{Yao2007,
  author    = {N. Yao and F. Gao and S. Cai and W. Yao},
  title     = {A New Method of Performance Test for Network Storage},
  booktitle = {Second International Multi-Symposiums on Computer and Computational Sciences (IMSCCS 2007)},
  year      = {2007},
  pages     = {416-420},
  month     = {Aug},
  abstract  = {Network storages are used widely in many fields of our society. But their testing performances are not as expected. Most of the tools being used to test the performance of network storage comes from the tools used to test the traditional storage system because the storage devices connected to the net act as the local storage devices. So these tools inevitably miss the effects exerted by the networks which connect the hosts to the storage devices. For example, these tools can hardly generate requests which exceed the maximum loading of storage devices. In this paper, we propose one new method to test the performance of network storage which can easily generate requests that exceed the maximum loading of storage devices. In this method, the test program sends the requests by fixed frequency and the initiator will not be restrained by the targeter when the quantity of requests is close to the maximum load. The load simulated by the new method is more like the load in the real world, especially when the load is very high.},
  doi       = {10.1109/IMSCCS.2007.36},
  keywords  = {program testing;software performance evaluation;storage management;network storage;performance test;storage system;testing performance;Computer networks;Data warehouses;Educational institutions;Frequency;Internet;Network servers;Performance evaluation;Protocols;System testing;Web server},
}

@Article{Dougherty1981,
  author   = {J. W. Dougherty and S. H. Minnich},
  title    = {Finite Element Modeling of Large Turbine Generators; Calculations Versus Load Test Data},
  journal  = {IEEE Power Engineering Review},
  year     = {1981},
  volume   = {PER-1},
  number   = {8},
  pages    = {50-50},
  month    = {Aug},
  issn     = {0272-1724},
  abstract = {Summary form only given, as follows.},
  doi      = {10.1109/MPER.1981.5511784},
  keywords = {Finite element methods;Particle measurements;Power system interconnection;Power system stability;Power system transients;Reactive power;Turbines},
}

@InProceedings{Lumyong2000,
  author    = {Pichit Lumyong and Chaiwut Chat-Uthai},
  title     = {Power minimization technique for induction motor load test},
  booktitle = {Proceedings IPEMC 2000. Third International Power Electronics and Motion Control Conference (IEEE Cat. No.00EX435)},
  year      = {2000},
  volume    = {2},
  pages     = {570-573 vol.2},
  abstract  = {This paper presents the technique of how to minimize power from the supply when a three-phase induction motor is under the load test. The load test enables the determination of the value of load power, current and power factor of the induction motor. In practice, a DC generator or eddy current brake is applied for the mechanical test. The objective of this paper is to propose a load test method using two pulleys for changing speed of an induction motor. The second induction machine is controlled to operate as an induction generator in order to transfer the energy to the supply, therefore the power required during the test is obviously reduced. The study of how to control the induction motor operated as generator will be the useful information for developing the induction generator system (IG) to work with variable speed and load, and to make it work as a stand alone generator},
  doi       = {10.1109/IPEMC.2000.884551},
  keywords  = {asynchronous generators;induction motors;machine testing;power factor;DC generator;eddy current brake;energy transfer;induction generator;induction motor load test;load power;load test method;mechanical test;power factor;power minimization technique;pulleys;three-phase induction motor;variable load;variable speed;Control systems;DC generators;Eddy current testing;Eddy currents;Induction generators;Induction machines;Induction motors;Power supplies;Pulleys;Reactive power},
}

@InProceedings{Chu2007,
  author    = {L. Chu and J. Gu and M. Liu and J. Li and Y. Gao and M. Ehsani},
  title     = {Study on CAN Communication of EBS and Braking Performance Test for Commercial Vehicle},
  booktitle = {2007 IEEE Vehicle Power and Propulsion Conference},
  year      = {2007},
  pages     = {849-852},
  month     = {Sept},
  abstract  = {EBS (electronic brake system) can effectively control and adjust braking force acting on every wheel, reduce braking response time and braking distance, and make vehicle achieve much more braking stability. It is featured with CAN (Controller Area Network) communication by which the sensor signals and control command signals can be transmitted and received. In the braking performance test of EBS, conventional test methods have some inconvenience in existence. For example, the fixing of pressure sensors and wheel speed sensors is restrained by the installation position, and the precision of measuring is prone to be affected by the environment conditions. But based on CAN communication technology, the special testing instrument can be connected with CAN bus, monitoring and recording signals on the bus. Thus signals representing braking performance can be acquired through CAN bus.},
  doi       = {10.1109/VPPC.2007.4544242},
  issn      = {1938-8756},
  keywords  = {braking;controller area networks;pressure sensors;road vehicles;test equipment;CAN communication;EBS;braking distance;braking force;braking performance;braking stability;commercial vehicle;control command signals;controller area network communication;electronic brake system;pressure sensors;sensor signals;wheel speed sensors;Communication system control;Control systems;Delay;Force control;Force sensors;Position measurement;Stability;Testing;Vehicles;Wheels;CAN;Electronic Brake System (EBS)},
}

@InProceedings{Li2013c,
  author    = {T. Li and X. Liu and Y. Tan and G. Huang and K. Zheng},
  title     = {Design of EBS performance test system based on LabVIEW},
  booktitle = {2013 Chinese Automation Congress},
  year      = {2013},
  pages     = {637-642},
  month     = {Nov},
  abstract  = {In the past, EBS performance test was conducted with traditional instruments, which was tedious and costly. This study is made on the system of EBS performance test developed based on LabVIEW. This system, which is easy to operate and quite practicable, can achieve simultaneous monitoring, recording and display of analog signal, digital signal and GPS communication signals. Experiment showed that the good stability and reliability of the system was very helpful for the operators to evaluate and analyse EBS performance.},
  doi       = {10.1109/CAC.2013.6775813},
  keywords  = {Global Positioning System;braking;signal processing;traffic engineering computing;virtual instrumentation;EBS performance test system design;GPS communication signals;LabVIEW;analog signal;digital signal;electronic braking system;system reliability;system stability;Decision support systems;Erbium;Brake System;EBS;GPS;LabVIEW},
}

@InProceedings{Bozoki2008,
  author    = {F. Bozoki and T. Csondes},
  title     = {Scheduling in Performance Test environment},
  booktitle = {2008 16th International Conference on Software, Telecommunications and Computer Networks},
  year      = {2008},
  pages     = {404-408},
  month     = {Sept},
  abstract  = {Nowadays automatic testing is getting more and more important in the telecommunication world. The sooner a fault is discovered the cheaper it is to correct it. If a fault is discovered during the development process the cost of the correction is significantly smaller. There are different test strategies, with different approaches like, conformance test, system test and performance test. The system test takes place after a successful conformance test. Performance test is analyzing the load characteristics of the system under test (SUT). In this article we describe the main attributes of performance testing, where the main challenge is to generate the expected load without having as complex hardware as the SUT is itself. Most of the papers, presented in this subject are focusing on the characteristics of the generated load, but not the way how to achieve it. These papers usually have the assumption that the load can be generated by deploying more hardware resources. Other papers propose new extensions for test description languages such SDL or TTCN-3. In this article we intend to describe a finite state machine (FSM) based model and an algorithm which improves the efficiency of scheduling in this performance test environment. We present an architecture based on the so called virtual threads, an algorithm to optimize the scheduling between these threads, and an example to demonstrate the algorithm.},
  doi       = {10.1109/SOFTCOM.2008.4669519},
  keywords  = {finite state machines;multi-threading;program testing;scheduling;SDL;SUT;TTCN-3;automatic testing;conformance test;development process;fault discovery;finite state machine based model;hardware resource;load test;performance test environment;scheduling optimization algorithm;system under test;telecommunication world;test description language;test strategy;virtual thread;Automata;Automatic testing;Character generation;Costs;Hardware;Operating systems;Performance analysis;Scheduling algorithm;System testing;Yarn},
}

@InProceedings{Qiao2011,
  author    = {J. Qiao},
  title     = {The acceleration stress test of the brake system on an airplane},
  booktitle = {The Proceedings of 2011 9th International Conference on Reliability, Maintainability and Safety},
  year      = {2011},
  pages     = {1067-1072},
  month     = {June},
  abstract  = {The test method is discussed which increases the environment stress and the working stress to stimulate failures in products without damage, besides, the method which converts the acceleration stress test time to working time is put forward to evaluate the MTBF and first overhaul period of the product. In order to stimulate potential failures, the technology of colligating reliability test and life test is studied in the brake system of a certain aircraft, in which the environment stress is not statistical stress but its kind and magnitude are established in allusion to the weak links. Rated working stress which corresponds to antiskid brake rule is brought into the test profile and the contamination tolerance test of hydraulic system is conducted. As a result, latent failures of the break system are activated in a short time; the test which needs 5200 working hours to finish is ended in 200 hours; reliability growth rate achieves 0.65; the MTBF of the brake system increases to 848h from 28h in the beginning, and the first overhaul period of new developed products in the break system attains 1250 takeoff-landing times.},
  doi       = {10.1109/ICRMS.2011.5979426},
  keywords  = {aerospace engineering;aircraft;braking;hydraulic systems;internal stresses;mechanical testing;reliability;acceleration stress test;airplane;brake system;contamination tolerance test;environment stress;hydraulic system;life test;mean time between failure;rated working stress;reliability test;Acceleration;Pollution measurement;Reliability;Servomotors;Stress;Temperature measurement;Valves;design improvement of products;failure excitation;life evaluation;reliability evaluation;reliability growth;test method improvement},
}

@InProceedings{Bennett2010,
  author    = {P. M. Bennett and L. L. Brown},
  title     = {Recent Successes and Changes of the HPCMP Sustained Systems Performance Test},
  booktitle = {2010 DoD High Performance Computing Modernization Program Users Group Conference},
  year      = {2010},
  pages     = {453-462},
  month     = {June},
  abstract  = {The sustained systems performance (SSP) test has been implemented on certain High Performance Computing Modernization Program (HPCMP) HPC systems in order to quantitatively evaluate updates to system software, hardware repairs, job queuing policy modifications, and revisions to the job scheduler as necessary. The test employs codes used in the system acquisition cycle with proven migration capability to HPCMP HPC systems and non-empirical tests for numerical accuracy. Metrics such as compilation time, queue wait time, benchmark execution time, and total test throughput time are gathered and compared against metric data from previous tests to monitor the systems under test while minimizing impact to the users. Jobs failing to execute properly or in anomalously short or long times are investigated, and the results are reported to system administrators and center directors at each center for appropriate actions. During the past year, the SSP test has been instrumental in surfacing configuration issues with the PBS scheduler and performance issues on several HPC systems. Additionally, the frequency of the SSP test on systems procured in Technology Insertion 2009 (TI-09) and thereafter has increased, with attendant changes in the test cases comprising the test. The SSP test continues to play an important role in monitoring the quality of service delivering HPC to HPCMP users at the system, DoD Supercomputing Resource Center, and vendor levels.},
  doi       = {10.1109/HPCMP-UGC.2010.46},
  keywords  = {mainframes;military computing;performance evaluation;processor scheduling;program testing;systems analysis;systems software;DoD supercomputing resource center;HPC system;HPCMP sustained systems performance test;hardware repairs;high performance computing modernization program;job queuing policy modification;job scheduler;system acquisition cycle;system administrator;system software updates;Benchmark testing;Computational modeling;Libraries;Memory management;Oceans;Throughput;US Department of Defense},
}

@InProceedings{Belloni2017,
  author    = {F. Belloni and R. Chiumeo and C. Gandolfi and A. Villa},
  title     = {Performance test of a PQ universal compensator through Control Hardware in the Loop simulation},
  booktitle = {2017 6th International Conference on Clean Electrical Power (ICCEP)},
  year      = {2017},
  pages     = {502-508},
  month     = {June},
  abstract  = {Distributed Energy Resources (DER) connected to distribution grids through static power converters may have major impacts on Power Quality (PQ). For this reason, power converters used as Universal Compensators (UC) are gaining more and more interest. This paper describes the design, modeling and study of a shunt static compensator for Low Voltage distribution grids. The proposed device can be used for interfacing Distributed Generators (DG) or Energy Storage Systems (ESS) to the grid and can be connected close to disturbing loads. This device can compensate harmonic currents, reactive power and unbalances of disturbing loads, and it can also supply sensitive loads in island operation. Performances of the proposed device, with different control schemes and with different harmonic compensation strategies, are assessed through Control Hardware in the Loop (CHIL) Real Time simulations.},
  doi       = {10.1109/ICCEP.2017.8004734},
  keywords  = {compensation;energy resources;power convertors;power grids;power supply quality;reactive power;CHIL;DER;PQ universal compensator;UC;control hardware in the loop real time simulations;distributed energy resources;disturbing loads;harmonic compensation strategies;harmonic currents;island operation;low voltage distribution grids;performance test;power quality;reactive power;static power converters;Hardware;Harmonic analysis;Integrated circuit modeling;Power harmonic filters;Real-time systems;Voltage control;Voltage measurement;Digital Real Time simulations (DRTS);Distributed Generator;Hardware in the loop (HIL);Power Quality;Universal Compensator},
}

@InProceedings{Gara2016,
  author    = {F. Gara and V. Nicoletti and D. Roia and L. Dezi and A. Dall'Asta},
  title     = {Dynamic monitoring of an isolated steel arch bridge during static load test},
  booktitle = {2016 IEEE Workshop on Environmental, Energy, and Structural Monitoring Systems (EESMS)},
  year      = {2016},
  pages     = {1-6},
  month     = {June},
  abstract  = {This paper describes the dynamic monitoring carried out by means of vibration measurements during the standard static load test of a half-through steel arch bridge on the Potenza river. The structural design of the bridge is characterized by some notable aspects: the river crossing is obtained by two coupled steel arches, having a span length around 115 m, and a steel-concrete composite deck sustained by thirty couples of steel hangers; the approaching spans are realized with continuous girders on intermediate supports, having cross section with variable height; the arches are supported on rubber bearing seismic isolators. The vibration measurements were nearly continuously acquired during the loading tests to detect the occurrence of anomalies in the structural behavior. In particular, the global dynamic characteristics of the structure, in terms of modal parameters, were determined using the data set of measurements at specific phases of the load test: first on the unloaded configuration, then on two different loaded configurations and finally after the bridge unloading. Measurements of vibrations due both to the ambient and to the impulse produced by a fully loaded truck passing over a bump, were carried out. The experimental results, in terms of modal parameters of the bridge, are in agreement with the theoretical results obtained with the predictive finite element model developed for design purposes and opportunely modified to account for the real conditions of the bridge during the tests.},
  doi       = {10.1109/EESMS.2016.7504823},
  keywords  = {bridges (structures);condition monitoring;design engineering;dynamic testing;finite element analysis;modal analysis;seismology;steel;structural engineering;vibration measurement;Potenza river;bridge unloading;continuous girders;coupled steel arches;dynamic monitoring;fully-loaded truck;global dynamic characteristics;half-through steel arch bridge;intermediate supports;isolated steel arch bridge;loaded configurations;modal parameters;predictive finite element model;rubber bearing seismic isolators;standard static load test;steel hangers;steel-concrete composite deck;structural behavior;structural design;unloaded configuration;variable height;vibration measurement;Accelerometers;Bridges;Monitoring;Shape;Steel;Structural beams;Vibration measurement;dynamic testing;modal identification;monitoring;operational modal analysis;steel arch bridge;vibration measurement},
}

@InProceedings{Zhang2016,
  author    = {H. Zhang and J. Nie},
  title     = {Performance test of Taurus HPC system},
  booktitle = {2016 IEEE International Conference of Online Analysis and Computing Science (ICOACS)},
  year      = {2016},
  pages     = {185-188},
  month     = {May},
  abstract  = {High performance computing system has become the strong support of scientific research due to the good cost performance ratio and scalability after pure science and experimental science, the performance tests help to find out the performance bottlenecks of HPC systems. How to evaluate the performance of a HPC system is the main purpose of this paper. A high-performance computing system with 16 CPU+GPU compute nodes has been constructed. HPL benchmark was used to evaluate the performance of CPU, GPU under different matrix scale Ns, computational nodes, block size NB of matrix etc, and an empirical formula of Ns value calculation was presented through lots of testings. A comprehensive storage I/O performance was tested with IOZone which is a professional file system's standard testing tool. The performance of CPU cluster reaches 93.5% of the system theoretical value and GPU cluster gets 80% of the theoretical value.},
  doi       = {10.1109/ICOACS.2016.7563076},
  keywords  = {graphics processing units;microprocessor chips;parallel processing;CPU;GPU;IOZone;Taurus HPC system;cost performance ratio;high performance computing system;performance test;professional file systems;standard testing tool;storage I/O performance;Decision support systems;Graphics processing units;Servers;CPU;GPU;HPC;IOZone;Linpack},
}

@Article{Avritzer1995,
  author   = {A. Avritzer and E. R. Weyuker},
  title    = {The automatic generation of load test suites and the assessment of the resulting software},
  journal  = {IEEE Transactions on Software Engineering},
  year     = {1995},
  volume   = {21},
  number   = {9},
  pages    = {705-716},
  month    = {Sep},
  issn     = {0098-5589},
  abstract = {Three automatic test case generation algorithms intended to test the resource allocation mechanisms of telecommunications software systems are introduced. Although these techniques were specifically designed for testing telecommunications software, they can be used to generate test cases for any software system that is modelable by a Markov chain provided operational profile data can either be collected or estimated. These algorithms have been used successfully to perform load testing for several real industrial software systems. Experience generating test suites for five such systems is presented. Early experience with the algorithms indicate that they are highly effective at detecting subtle faults that would have been likely to be missed if load testing had been done in the more traditional way, using hand-crafted test cases. A domain-based reliability measure is applied to systems after the load testing algorithms have been used to generate test data. Data are presented for the same five industrial telecommunications systems in order to track the reliability as a function of the degree of system degradation experienced},
  doi      = {10.1109/32.464549},
  keywords = {Markov processes;automatic test software;program testing;resource allocation;software reliability;telecommunication computing;Markov chain;automatic test case generation algorithms;domain-based reliability measure;fault detection;industrial software systems;load test suites;load testing;reliability;resource allocation mechanisms;software testing;system degradation;telecommunications software;Automatic testing;Communication industry;Computer industry;Fault detection;Performance evaluation;Resource management;Software algorithms;Software systems;Software testing;System testing},
}

@InProceedings{Feng2007,
  author    = {Li Feng and Sheng Zhuang},
  title     = {Action-driven automation test framework for Graphical User Interface (GUI) software testing},
  booktitle = {2007 IEEE Autotestcon},
  year      = {2007},
  pages     = {22-27},
  month     = {Sept},
  abstract  = {In this paper we describe the design and implementation of an action-driven automation test framework especially for GUI software testing. The idea of action-driven automation test framework comes from the core concept of "quality assurance (QA)". Better quality can be ensured by increasing the coverage of test cases on the software but the process of creating large number of test cases has to be optimized. With this goal the framework was designed to primarily increase the efficiency and flexibility in composing test cases and simplify the process of learning the test cases. This paper describes the background, features, and implementation details of the framework.},
  doi       = {10.1109/AUTEST.2007.4374197},
  issn      = {1088-7725},
  keywords  = {automatic test software;graphical user interfaces;program testing;GUI;action driven automation test framework;graphical user interface software testing;quality assurance;Automatic testing;Data mining;Design automation;Engines;Filling;Graphical user interfaces;Logic testing;Quality assurance;Software quality;Software testing},
}

@InProceedings{Krejcar2010,
  author    = {O. Krejcar and M. Penhaker and D. Janckulik and L. Motalova},
  title     = {Performance test of multiplatform real time processing of biomedical signals},
  booktitle = {2010 8th IEEE International Conference on Industrial Informatics},
  year      = {2010},
  pages     = {825-830},
  month     = {July},
  abstract  = {The paper deal with a problem of a data collecting and visualization of several biomedical signals from patients by mobile embedded monitoring stations. Measurement devices were used in real tests. Due to a problem of real time processing a 12 channels ECG from ECG device by Bluetooth to mobile stations, packet parsing as the one problem part of data processing chain, is presented and solved by two possible solutions. Mobile embedded monitoring stations are based on Microsoft Windows Mobile operating system. The whole system is based on the architecture of .NET Framework, .NET Compact Framework, .NET Micro Framework and Microsoft SQL Server.},
  doi       = {10.1109/INDIN.2010.5549635},
  issn      = {1935-4576},
  keywords  = {data visualisation;electrocardiography;medical signal processing;real-time systems;ECG;Microsoft Windows mobile operating system;NET Micro Framework;NET compact framework;biomedical signals;data collection;data processing chain;data visualization;embedded monitoring stations;measurement devices;microsoft SQL server;mobile stations;multiplatform real time processing;packet parsing;Biomedical measurements;Biomedical monitoring;Bluetooth;Data processing;Data visualization;Electrocardiography;Operating systems;Patient monitoring;Signal processing;Testing;ECG;biotelemetry;mobile;processing},
}

@InProceedings{Li2012,
  author    = {L. Li and L. L. Zhu and H. Zhai and D. Liu and H. F. Wang},
  title     = {Study on Performance Test of Storage Structure Base on State Scene Performance},
  booktitle = {2012 International Conference on Computer Science and Service System},
  year      = {2012},
  pages     = {570-573},
  month     = {Aug},
  abstract  = {This paper is an introduction to software performance automated testing and theory. It introduces the features of Open Xml storage and SQL Server storage. Then this paper sets three state scenes and chooses different test automated tools respectively. Finally, it uses tools to monitor software performance index from these two data storage systems. Results are then analyzed, comparing the quality performance of different storage systems to the same state scene.},
  doi       = {10.1109/CSSS.2012.148},
  keywords  = {SQL;XML;program testing;software performance evaluation;storage management;SQL server storage;data storage systems;open XML storage;performance test;software performance automated testing;software performance index monitoring;software performance theory;state scene performance;storage structure;Indexes;Monitoring;Servers;Software;Testing;Time factors;Automated Testing;Open Xml;SQL Server},
}

@InProceedings{Srinivasan2007,
  author    = {G. Srinivasan and A. Chatterjee},
  title     = {Fourier Spectrum-Based Signature Test: A Genetic CAD Toolbox for Reliable RF Testing Using Low-Performance Test Resources},
  booktitle = {16th Asian Test Symposium (ATS 2007)},
  year      = {2007},
  pages     = {139-142},
  month     = {Oct},
  abstract  = {At the present time, coordinated EDA tools for RF/mixed-signal pin test do not exist. In this paper, a CAD tool for efficient production testing of high- performance RF systems using low-cost baseband ATE is presented The CAD tool consists of a custom developed genetic ATPG for spectral (Fourier spectrum) signature-based alternate (to full specification-based tests) test of RF systems and involves co-simulation of scalable behavioral-level models of the RF System-Under-Test, baseband ATE test instrumentation, loadboard resources, and DfT resources for fast test vector optimization/generation. The CAD tool also enables the evaluation of various low-cost ATE architectures on the impact of the generated tests to provide a cost-effective solution.},
  doi       = {10.1109/ATS.2007.98},
  issn      = {1081-7735},
  keywords  = {automatic test equipment;automatic test pattern generation;circuit CAD;integrated circuit testing;radiofrequency integrated circuits;ATE;ATPG;Fourier spectrum;RF system under test;genetic CAD toolbox;loadboard resources;low performance test resources;reliable RF testing;signature test;test instrumentation;Automatic test pattern generation;Baseband;Circuit testing;Costs;Electronic design automation and methodology;Genetics;Instruments;Radio frequency;Sequential analysis;System testing},
}

@InProceedings{Hong2007,
  author    = {S. B. Hong and S. H. Han and C. E. Chung},
  title     = {Performance test of an environmental radiation monitoring system},
  booktitle = {2007 IEEE Nuclear Science Symposium Conference Record},
  year      = {2007},
  volume    = {1},
  pages     = {754-755},
  month     = {Oct},
  abstract  = {A Portable environmental radiation monitoring system which is able to monitor both a scintillation detector and a high pressure ion chamber was developed. We applied Mourich's spectrum-dose rate conversion(G(E) method) for measurement of dose rate and Beck's energy band for natural radiation dose rate of Nal(Tl) Detector. Also man-made radiation dos rate against nuclear power plant such as Cs-137, Mn-54, C0- 58, Co-60, Ir-192 was measured.},
  doi       = {10.1109/NSSMIC.2007.4436438},
  issn      = {1082-3654},
  keywords  = {dosimetry;ionisation chambers;radiation monitoring;solid scintillation detectors;Beck energy band;Co-58;Co-60;Cs-137;G(E) method;Ir-192;Mn-54;Mourich spectrum-dose rate conversion;NaI(Tl) detector;environmental radiation monitoring system;high pressure ion chamber;man-made radiation dose rate;natural radiation dose rate;nuclear power plant;scintillation detector;Connectors;Detectors;Energy measurement;Power generation;Pressure measurement;Radiation monitoring;Scintillation counters;Spectroscopy;System testing;Universal Serial Bus},
}

@InProceedings{Tan2012,
  author    = {Y. Tan and C. Yu},
  title     = {New Device Design and Performance Test on Gas Generator in Automobile Airbag},
  booktitle = {2012 International Conference on Control Engineering and Communication Technology},
  year      = {2012},
  pages     = {484-487},
  month     = {Dec},
  abstract  = {An new test device to test gas generator performance in automobile airbag is built. It is made up of inflator jar, sliding track, lifting device and data acquisition system. This system can produce an analog signal which is similar to the impact signal of automobile crash. For get suitable data of acceleration and the duration of impact, lots of experiments have been done. When lifting height of inflator jar is 280mm, acceleration peak value is from 80.5g to 90.2g and dash duration is from 6ms to 8ms. They can meet require to detonate gas generator. There were five groups gas generators from SHANXI Jinheng auto-parts Co., LTD was tested and changing track of pressure and acceleration can be known clearly. Then forty-four gas generators contrast test were done separately in China and in USA. Test results from our designed device were very similar to USA device. It was confirmed that the device designed to test gas generator performance by ourselves was successful.},
  doi       = {10.1109/ICCECT.2012.77},
  keywords  = {acceleration;automotive components;automotive engineering;data acquisition;design engineering;impact (mechanical);pressure;signal processing;test equipment;China;USA;United States of America;acceleration track;analog signal;automobile airbag;automobile crash impact signal;data acquisition system;gas generator;gas generator contrast test;impact acceleration;impact duration;inflator jar;lifting device;performance test;pressure track;sliding track;test device design;Acceleration;Automobiles;Generators;Performance evaluation;Safety;Tracking;USA Councils;airbag;automobile;gas generator;mechanical design;pressure test},
}

@InProceedings{Lazzaroni2015,
  author    = {M. Lazzaroni and M. Citterio and S. Latorre},
  title     = {Points of Load: Performance test in high-B environment},
  booktitle = {2015 IEEE International Instrumentation and Measurement Technology Conference (I2MTC) Proceedings},
  year      = {2015},
  pages     = {1320-1325},
  month     = {May},
  abstract  = {The performance in magnetic field (B-field) of a DC-DC converter ad hoc designed for LHC operation has been evaluated. The tests have been carried out at the Laboratorio Acceleratori e Superconduttività Applicata (LASA), in Milan (Italy), in the first months of 2014 and the experimental results are here presented and discussed. The ability to operate in hostile environment of the tested DC-DC converter is very interesting in particular when used in measuring system for physics experiments. In this case, in fact, the presence of radiation and strong magnetic field make electronic devices challenged to function. In particular, in this paper the operation in high B-field environment has been investigated and discussed.},
  doi       = {10.1109/I2MTC.2015.7151464},
  issn      = {1091-5281},
  keywords  = {DC-DC power convertors;cyclic accelerators;magnetic field effects;testing;DC-DC converter;LASA;LHC operation;Laboratorio Acceleratori e Superconduttività Applicata;Milan;high-B environment;magnetic field performance;performance test;points of load;Current measurement;Detectors;Instruments;Large Hadron Collider;Magnetic field measurement;Magnetic fields;Physics;Dependability;High-B tolerance;Hostile environment;LHC;Measurement;Points of Load;Reliability},
}

@InProceedings{Mu-qing2010,
  author    = {C. Mu-qing and L. R. Xu Jiang-ning and L. Ping},
  title     = {Fiber-optic gyrocompass performance test and combined dead reckoning (DR) navigation scheme design},
  booktitle = {2010 2nd International Conference on Signal Processing Systems},
  year      = {2010},
  volume    = {3},
  pages     = {V3-594-V3-596},
  month     = {July},
  abstract  = {Different test schemes are designed in the paper, which fully aware of the characteristics and important indicators of fiber-optic gyro compass OCTANS. After analysis the towed system working environment, this paper propose the towed system to use part of OCTANS heave compensation outputs for combined DR navigation system.},
  doi       = {10.1109/ICSPS.2010.5555842},
  keywords  = {compasses;compensation;fibre optic gyroscopes;inertial navigation;DR navigation system;OCTANS;dead reckoning;fiber-optic gyro compass;heave compensation;performance test;Accuracy;Convergence;Navigation;Optical fiber filters;Signal processing;Surges;Three dimensional displays;combined navigation system;heave compensation;towd system},
}

@InProceedings{Peng2011,
  author    = {X. Peng and Q. Ge and F. Xiong},
  title     = {Stress test and finite element analysis of a 10 #x00D7;104 m3 crude oil tank},
  booktitle = {2011 International Conference on Multimedia Technology},
  year      = {2011},
  pages     = {1734-1737},
  month     = {July},
  abstract  = {The large crude oil storage tank with a capacity of 10×104 m3 has been widely used in China currently. In order to obtain the stress distribution in the wall board, bottom board, big fillet weld and manhole, and to verify the rationality of tank design, a stress test which combining the method of static resistance strain test (SRST) and optical fiber strain test (OFST) is conducted during water filling test for the tank. Software ANSYS is employed to construct a three-dimensional (3d) space finite element model under hydraulic test loading. And then theoretically calculated and measured values are compared and a good agreement between them is achieved.},
  doi       = {10.1109/ICMT.2011.6003255},
  keywords  = {crude oil;finite element analysis;fuel storage;internal stresses;mechanical testing;optical fibres;stress analysis;tanks (containers);walls;welding;3D space finite element model;China;big fillet weld;bottom board;crude oil tank;finite element analysis;hydraulic test loading;large crude oil storage tank;manhole;optical fiber strain test;software ANSYS;static resistance strain test;stress distribution;stress test;tank design;wall board;water filling test;Finite element methods;Floors;Fuel storage;Solid modeling;Strain;Stress;Welding;finite element analysis (FEA);oil tank;stress test},
}

@InProceedings{Palacios1990,
  author    = {H. Palacios and D. Rodriguez and J. Castro and V. Gomez and J. Jorquera and T. Magdhal},
  title     = {Signal averaging in stress test and Holter systems},
  booktitle = {Proceedings of the 1990 IEEE Colloquium in South America},
  year      = {1990},
  pages     = {16-21},
  abstract  = {A signal averaging technique is presented as a high quality alternative for filtering and cleaning ECG signals. A basic mathematical approach is first presented, with emphasis on the bandwidth reduction due to imperfect synchronism, when the QRS complex and R wave peak are used for synchronizing and alignment. A very reliable method is presented, especially designed for noisy ECG signals; in this method several thresholds are generated, based on the history of the successive cycles; thresholds for the amplitude of high pass filtered ECG signals and their first derivatives are generated in an adaptive and stable way. Finally, results are shown for several typical cases, including static averaging and dynamic real-time averaging},
  doi       = {10.1109/COLLOQ.1990.152786},
  keywords  = {electrocardiography;patient monitoring;signal processing;Holter systems;QRS complex;R wave peak;amplitude thresholds;bandwidth reduction;cleaning ECG signals;dynamic real-time averaging;electrocardiograms;imperfect synchronism;noisy ECG signals;signal averaging technique;static averaging;stress test;Bandwidth;Cleaning;Electrocardiography;Filtering;Noise generators;Noise level;Signal design;Signal generators;Stress;System testing},
}

@Article{Dougherty1981a,
  author   = {J. W. Dougherty and S. H. Minnich},
  title    = {Finite Element Modeling of Large Turbine Generators; Calculations Versus Load Test Data},
  journal  = {IEEE Transactions on Power Apparatus and Systems},
  year     = {1981},
  volume   = {PAS-100},
  number   = {8},
  pages    = {3921-3929},
  month    = {Aug},
  issn     = {0018-9510},
  abstract = {In support of EPRI Program 1288-1, Improvement in Accuracy of Prediction of Electrical Machine Constants, generator parameters at load have been calculated by the finite element method, in two dimensions. These calculated parameters are compared with test data obtained under EPRI Program RP 997-2, Determination of Synchronous Machine Stability Study Constants. An iterative procedure was used to match the calculated terminal voltage with the test value, for a given armature current and power factor. The test/calculated values for field current, the various angles, and Xq are then compared. Good agreement in all the above parameters is obtained for six diverse load points. Reactances are also compared. Considerable saturation effect is found, and is confirmed by test data in the case of X4. The results of this systematic comparison are judged to be a confirmation of the power of the finite element method.},
  doi      = {10.1109/TPAS.1981.316987},
  keywords = {Accuracy;Finite element methods;Personnel;Power measurement;Reactive power;Stability;Synchronous machines;System testing;Turbines;Voltage},
}

@InProceedings{Vlastaras2015,
  author    = {D. Vlastaras and S. Malkowsky and F. Tufvesson},
  title     = {Stress Test of Vehicular Communication Transceivers Using Software Defined Radio},
  booktitle = {2015 IEEE 81st Vehicular Technology Conference (VTC Spring)},
  year      = {2015},
  pages     = {1-4},
  month     = {May},
  abstract  = {Wireless vehicular communication is, in contrast to other terrestrial types of wireless communications, more dynamic in nature. Both the transmitter and the receiver are moving at high speeds relative to each other, which generates highly dynamic wireless channels. Such channels are characterized by short stationarity regions and large Doppler spreads. Modem manufacturers face a challenge when designing and implementing equipment for such environments. Similarly, for testing and evaluation real-life measurements with vehicles are required, which often is an expensive and slow process. This paper tackles this problem by proposing a method for stress testing transceivers based on the design and implementation of a real-time wireless channel emulator for wireless vehicular communications using a software defined radio (SDR). The emulator together with the proposed test methodology enable quick on-bench evaluation of wireless modems. In the paper we also apply the test on two different IEEE 802.11p modem implementations and characterize the packet error rate performance for different Doppler-delay combinations.},
  doi       = {10.1109/VTCSpring.2015.7146111},
  issn      = {1550-2252},
  keywords  = {modems;software radio;transceivers;wireless LAN;wireless channels;Doppler-delay combinations;IEEE 802.11p modem implementations;packet error rate performance;real-time wireless channel emulator;software defined radio;stress testing transceivers;vehicular communication transceivers;wireless modems;wireless vehicular communications;Ad hoc networks;Delays;Doppler shift;Error analysis;Modems;Stress;Wireless communication},
}

@InProceedings{Kennel2002,
  author    = {R. Kennel and G. Nicastro and R. Roesner and R. Rohlfing},
  title     = {High performance test equipment for 12 V and 42 V automotive components},
  booktitle = {IEEE 2002 28th Annual Conference of the Industrial Electronics Society. IECON 02},
  year      = {2002},
  volume    = {3},
  pages     = {1746-1751 vol.3},
  month     = {Nov},
  abstract  = {Many industrial branches refer to officially defined standards or recommendations concerning their products. Companies of automotive industry, however, define their own technical requirements. As a consequence technical issues like quality of voltage in vehicle power supply systems are different between the companies. A test generator coping with the requirements of most automotive companies at the same time is not available in the market so far. Consequently automotive suppliers use different test equipment depending on the respective customer. A power function generator for testing of 12 V and 42 V components was developed as a co-operation project between university and industry. The generator is able to feed supply currents of 30 A. The output voltage shape can be defined with a high degree of freedom and is repeated cyclically. Voltage rise times of 3 μs and short time voltage drops and/or voltage interrupts can be produced. Of course, slow rise and decrease of the voltage can be realized as well. Additional oscillations of 100 kHz can be superposed to the output voltage. These features make the "voltage ripple generator" superior to commercial products available on market today.},
  doi       = {10.1109/IECON.2002.1185234},
  keywords  = {automotive electronics;electromagnetic compatibility;electronic equipment testing;immunity testing;power supplies to apparatus;test equipment;100 kHz;12 V;3 mus;30 A;42 V;EMC testing;automotive companies;automotive components;automotive industry;co-operation project;high performance test equipment;power function generator;short time voltage drops;supply currents;technical issues;technical requirements;test generator;vehicle power supply systems;voltage interrupts;voltage quality;voltage ripple generator;voltage rise times;Automotive components;Automotive engineering;Electricity supply industry;Feeds;Power supplies;Signal generators;Test equipment;Testing;Vehicles;Voltage},
}

@InProceedings{Yun2009,
  author    = {S. Yun and S. Sung and Y. J. Lee},
  title     = {Design and performance test of relative navigation of a low cost inertial SLAM},
  booktitle = {2009 ICCAS-SICE},
  year      = {2009},
  pages     = {4217-4221},
  month     = {Aug},
  abstract  = {Despite its precise positioning performance, a GPS based navigation system may require the reference or augmentation station in close boundaries and is liable to be affected by satellite observation environments. Thus, this paper presents an INS/vision sensor integrated system, which in principle uses purely unknown feature points in previous epochs in order to cope with the limited GPS/INS integration environment. For the implementation of three-dimensional navigation using feature points, the presented system takes advantage of a robust image extraction and tracking algorithm, data association, and inertial SLAM filter algorithm. Finally, experimental results verified the performance of integrated navigation system, through which the performance enhancement in estimating relative position of the vehicle is demonstrated effectively.},
  keywords  = {SLAM (robots);feature extraction;helicopters;inertial navigation;mobile robots;particle filtering (numerical methods);path planning;remotely operated vehicles;robot vision;sensor fusion;INS-vision sensor integrated system;UAV;data association;distributed particle filter;image extraction;inertial SLAM filter algorithm;integrated navigation system;relative navigation;three-dimensional navigation;tracking algorithm;vision-based inertial system;Costs;Data mining;Filters;Global Positioning System;Machine vision;Robustness;Satellite navigation systems;Sensor systems;Simultaneous localization and mapping;Testing;GPS/INS;SLAM;integrated navigation;positioning;vision sensor},
}

@InProceedings{Chen2016,
  author    = {Q. Chen and Run Hu and Bin Xie and Xingjian Yu and Jingjing Cheng and X. Luo},
  title     = {Effect study of silicone amount on the lumen maintenance of high power LED under accelerated stress test},
  booktitle = {2016 15th IEEE Intersociety Conference on Thermal and Thermomechanical Phenomena in Electronic Systems (ITherm)},
  year      = {2016},
  pages     = {836-840},
  month     = {May},
  abstract  = {In our previous study, we investigated the effects of different packaging materials (silicone and phosphor layer) on the reliability of high power light-emitting diodes (HPLEDs) by highly accelerated stress test (HAST). The experimental results showed that the LED samples' lumen maintenance property might have dependence on the silicone amount in the package. In this paper, we further studied the effect of silicone amount on the lumen maintenance under HAST. Five categories of LED specimens specified by silicone amount were prepared and subjected to an isothermal chamber whose temperature was set at 125 °C. An online testing system was used to monitor and record the light outputs in real time during the experimental process. After 400 hours of aging, the largest attenuating range reached 6.17% and different groups display different degradation behaviors. An exponential decay model was adopted to calculate the decay rate of each lumen maintenance curve. The decay rate differs as the silicone amount inside the package modules changes. This phenomenon is well explained and Monte Carlo ray-tracing simulations are carried out to validate the explanation. The interaction effect of both silicone amount and temperature is also found and more researches need to be done for further study.},
  doi       = {10.1109/ITHERM.2016.7517633},
  issn      = {1087-9870},
  keywords  = {Monte Carlo methods;life testing;light emitting diodes;maintenance engineering;ray tracing;silicones;HAST;HPLED reliability;Monte Carlo ray tracing simulation;high power LED lumen maintenance;high power light emitting diode reliability;highly accelerated stress test;isothermal chamber;online testing system;package module;silicone amount effect;Aging;Degradation;Light emitting diodes;Maintenance engineering;Reliability;Temperature measurement;Testing;Light-emitting diode (LED);Online testing system;Reliability;Silicone amount},
}

@InProceedings{Eom2015,
  author    = {D. Y. Eom and S. L. Hong and C. H. Kim and S. J. Roh and J. D. Kong and K. R. Park},
  title     = {The power characteristic results according to the superconducting magnet coil load test of the motor generator system},
  booktitle = {2015 IEEE 26th Symposium on Fusion Engineering (SOFE)},
  year      = {2015},
  pages     = {1-5},
  month     = {May},
  abstract  = {When the poloidal field (PF) magnet power supplies (MPS) of 11 units are operated, max power of 200 MVA is required to achieve long pulse operation of Korea Superconducting Tokamak Advanced Research (KSTAR). Motor Generator (MG) system was installed to resolve power shortage because the available grid power is only 100 MVA at the National Fusion Research Institute (NFRI) site. MG system is composed of mechanical devices (stator, rotor, bearings, etc.), power control devices (VVVF, exciter), power facilities (transformers, switchboard, UPS, filter, dynamic brake, etc.), utilities (cooling water pump, heat exchangers, cooling fans, oil circulation pump, mechanical brake, etc.) and control system. MG system supplies power to the PF MPS of 11 units. And we configure the Reactive Power Compensator (RPC) & Harmonic Filter (HF) system to stabilize the MG power system. After installing the MG system, individual tests and dummy coil tests were conducted to determine the safety and performance of MG system. And we completed the commissioning of the MG system by carrying out the superconducting magnet coil load test for 2014 KSTAR experiment. MG system was operated up to 150 MVA of PF MPS with RPC & HF system. And the maximum operating duration was about 100 seconds. In this paper, we discuss about the power characteristic results of the MG system according to the superconducting magnet coil load test.},
  doi       = {10.1109/SOFE.2015.7482394},
  keywords  = {Tokamak devices;plasma toroidal confinement;superconducting coils;superconducting magnets;2014 KSTAR experiment;Korea Superconducting Tokamak Advanced Research;NFRI;National Fusion Research Institute;RPC;control system;dummy coil tests;grid power;harmonic filter system;mechanical devices;motor generator system;poloidal field magnet power supplies;power control devices;power facilities;reactive power compensator;superconducting magnet coil load test;Fluctuations;Generators;Power system stability;Reactive power;Superconducting magnets;Voltage control;Voltage measurement;KSTAR;motor generator system;power system},
}

@InProceedings{Yueksel2015,
  author    = {M. Yüksel and S. Losch and S. Kroffke and M. Rohn and F. Kirchner},
  title     = {BLDC wheel hub motor and motor controller performance test of a concept electric robotic vehicle in HIL according to real driving characteristics},
  booktitle = {2015 9th International Conference on Electrical and Electronics Engineering (ELECO)},
  year      = {2015},
  pages     = {613-617},
  month     = {Nov},
  abstract  = {In this paper we are presenting a method, which is developed as a part of our framework for designing complex robotic vehicle systems, to test a power train of a robotic concept car according to the real driving characteristic from telemetry data gathered from a subset of a pilot electric vehicle fleet in northern Germany in Hardware-in-the-Loop. Our aim is to investigate the driving performance of our modified BLDC wheel hub motor and its motorcontroller under urban area traffic conditions.},
  doi       = {10.1109/ELECO.2015.7394578},
  keywords  = {automobiles;brushless DC motors;control engineering computing;electric vehicles;machine control;mechanical engineering computing;mechanical testing;mobile robots;power transmission (mechanical);telemetry;vehicle dynamics;BLDC wheel hub motor;HIL;complex robotic vehicle systems;concept electric robotic vehicle;hardware-in-the-loop;motor controller performance test;northern Germany;power train test;telemetry data;urban area traffic conditions;Brushless DC motors;Robots;Torque;Vehicles;Wheels},
}

@InProceedings{Moghadam2015,
  author    = {M. Moghadam and M. H. Moradi},
  title     = {Systolic and diastolic blood pressure estimation during exercise stress test using GK-MARS fuzzy function approach},
  booktitle = {2015 23rd Iranian Conference on Electrical Engineering},
  year      = {2015},
  pages     = {109-114},
  month     = {May},
  abstract  = {Exercise test is a screening test which is used to investigate and diagnosis cardiovascular disease. Measuring Blood Pressure (BP) during exercise test is an important issue. Because an individual experiences a great amount of physical stress and the vital signs should be carefully monitored. Using cuff and barometer leads to low accuracy of measuring BP. Moreover, vessel crush encounters the continuous measurements with crucial limitations. Hence, measuring systolic and diastolic BP values with desired accuracy in a cuff-less approach is of challenges in this context. This could be achieved by using features extracted from ECG and PPG signals. BP is highly correlated with parameters such as PTT and HR, but not necessarily linear. The correlation could be nonlinear, multimode and vague. Therefore, using intelligent approaches could be very effective in such modeling issue. In this context, using Fuzzy Function (FF) technique is proposed in this paper. Gustafson-Kessel (GK) clustering method instead of the FCM, because of considering correlation between data points, and MARS, due to its great ability in multimode and nonlinear modeling, are used to produce the antecedent and consequence of the rules respectively. GK-MARS structure, especially in cases with limited datasets as this study, could be very effective. In order to evaluation, the performance of this structure in BP estimation is compared with other intelligent methods including GRNN, fuzzy systems based on GD and RLS training methods and other structures of FF. Results indicate better performance of FF with GK-MARS structure in satisfying AAMI (SP10) standard in systolic and diastolic BP estimation of all stages.},
  doi       = {10.1109/IranianCEE.2015.7146192},
  issn      = {2164-7054},
  keywords  = {blood pressure measurement;cardiovascular system;diseases;electrocardiography;fuzzy set theory;AAMI(SP10) standard;ECG signals;GD training methods;GK-MARS fuzzy function approach;GK-MARS structure;GRNN fuzzy systems;Gustafson-Kessel clustering method;PPG signals;RLS training methods;barometer;cardiovascular disease;diastolic blood pressure estimation;fuzzy function technique;intelligent methods;multimode nonlinear modeling;Conferences;Decision support systems;Electrical engineering;Phase shift keying;MAR S;blood pressure;estimation;exercise test;fuzzy function},
}

@InProceedings{Takahashi2002,
  author    = {N. Takahashi},
  title     = {IP traffic performance test for video system/43.5Gbps BERT system},
  booktitle = {Workshop on High Performance Switching and Routing, Merging Optical and IP Technologie},
  year      = {2002},
  pages     = {343-343},
  abstract  = {Not Available},
  doi       = {10.1109/HPSR.2002.1024625},
  keywords  = {Analytical models;Bit error rate;IP networks;Instruments;Marketing and sales;Monitoring;Performance evaluation;System testing;Telecommunication traffic;Traffic control},
}

@Article{Qian2010,
  author   = {J. Qian and P. Weng and J. Luo and Z. Chen and Y. Wu},
  title    = {Measurement System in Large-Scale Superconducting Magnet Performance Test},
  journal  = {IEEE Transactions on Applied Superconductivity},
  year     = {2010},
  volume   = {20},
  number   = {5},
  pages    = {2312-2316},
  month    = {Oct},
  issn     = {1051-8223},
  abstract = {A cryogenic test facility for a superconducting magnet has been constructed at the Institute of Plasma Physics, Chinese Academy of Science. A measurement system was set up to obtain quench signals and parameters in the test program, such as cryogenic hydraulic performances and electromagnetic characteristics. Thirty superconducting magnets in the Experimental Advanced Superconducting Tokamak device and a number of other magnets have been tested in the test system successfully. The design of the measurement system is introduced from the point of view of engineering practice. The measurement method of some parameters is also discussed in detail. The highlight lies in type selection installation techniques and instrumentation of sensors.},
  doi      = {10.1109/TASC.2010.2053925},
  keywords = {cryogenics;displacement measurement;installation;measurement systems;sensors;superconducting magnets;advanced superconducting tokamak device;cryogenic hydraulic performances;cryogenic test facility;displacement measurement;electromagnetic characteristics;large-scale superconducting magnet;measurement system;quench signals;sensor instrumentation;type selection installation techniques;Cryogenics;Electromagnetic measurements;Large-scale systems;Nuclear and plasma sciences;Plasma devices;Plasma measurements;Plasma properties;Superconducting magnets;System testing;Test facilities;Data monitoring system;instrumentation;large-scale cryogenic test facility},
}

@InProceedings{Ruther2003,
  author    = {R. Ruther and G. Tamizh-Mani and J. del Cueto and J. Adelstein and A. A. Montenegro and B. von Roedern},
  title     = {Performance test of amorphous silicon modules in different climates: higher minimum operating temperatures lead to higher performance levels},
  booktitle = {3rd World Conference onPhotovoltaic Energy Conversion, 2003. Proceedings of},
  year      = {2003},
  volume    = {2},
  pages     = {2011-2014 Vol.2},
  month     = {May},
  abstract  = {To assess the performance of thin-film amorphous silicon (a-Si) devices operating in different climatic conditions, three identical sets of commercially available a-Si PV modules from five different manufacturers were simultaneously deployed outdoors in three sites with distinct climates (Arizona-USA, Colorado-USA and Florianopolis-Brazil) in a round robin exposure experiment. The four-year experiment aims to determine the light-induced degradation and stabilization characteristics of a-Si regarding specific history of exposure, and to monitor and compare degradation rates in different climates. We present results from the first year of measurements, showing that modules deployed at the site with the highest minimum operating temperature experienced the highest stabilized output level.},
  keywords  = {Staebler-Wronski effect;amorphous semiconductors;elemental semiconductors;modules;photovoltaic power systems;semiconductor thin films;silicon;solar power stations;thin film devices;Arizona;Brazil;Colorado;Florianopolis;Si;Staebler-Wronski effect;USA;amorphous silicon modules;climatic condition;degradation rate;light induced degradation;minimum operating temperatures;photovoltaic modules;round robin exposure experiment;solar power stations;stabilization properties;thin film amorphous silicon devices},
}

@InProceedings{Nho2004,
  author    = {Eui-Cheol Nho and In-Dong Kim and Tae-Won Chun and Heung-Geun Kim},
  title     = {Cost-effective power quality disturbance generator for the performance test of custom power devices},
  booktitle = {30th Annual Conference of IEEE Industrial Electronics Society, 2004. IECON 2004},
  year      = {2004},
  volume    = {2},
  pages     = {1606-1610 Vol. 2},
  month     = {Nov},
  abstract  = {This paper describes a new sag-swell generator for the test of custom power devices such as UPS, DVR, DSTATCOM, SSTS, etc. The proposed scheme has good features of simple structure, high reliability, wide range of voltage sag and swell variation, and easy control. Outage, harmonic distortion, notches, and voltage unbalance also can be generated. The operation principle of the proposed scheme is described and the characteristics are analyzed through simulation. The usefulness of the scheme is verified through experiments.},
  doi       = {10.1109/IECON.2004.1431821},
  keywords  = {harmonic distortion;power generation faults;power generation reliability;power supply quality;static VAr compensators;cost-effective power quality disturbance generator;custom power devices;harmonic distortion;performance test;sag-swell generator;voltage unbalance;Analytical models;Power generation;Power quality;Power system harmonics;Power system simulation;Power transformers;Testing;Uninterruptible power systems;Voltage control;Voltage fluctuations},
}

@InProceedings{Kim2017,
  author    = {Y. D. Kim and S. H. Jung and D. Y. Gu and H. K. Kim and C. H. Song},
  title     = {IoT Sensor Based Mobility Performance Test-Bed for Disaster Response Robots},
  booktitle = {2017 6th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)},
  year      = {2017},
  pages     = {990-991},
  month     = {July},
  abstract  = {Recently, thanks to development of advanced IoT technology, the disaster prevention service that helps to search and rescue survivors in the disaster site using robots and special equipment is greatly increased. The introduction of these advanced equipments will help to improve rescue operations within golden time and also ensure the safety of firefighters. However, the disaster environment is still very difficult to approach and pass through it due to collapses, obstacles and dangerous materials. In this paper, we design and implement a mobility performance evaluation test-bed which can overcome various risk situations where a robot and special equipment may encounter while driving and passing them. In addition, the test-bed adopts various Internet of Things (IoT) sensors in order to quantitatively evaluate the performance. The test-bed is consists of gaps, continuous ramp, crossing ramp, inclined planes, stairs, vertical climbing, narrow passage, pipe passage, water passage and etc. The level of difficulty for each track can be adjusted to provide a basis for the performance rating of the target robots.},
  doi       = {10.1109/IIAI-AAI.2017.32},
  keywords  = {Internet of Things;emergency management;emergency services;rescue robots;sensors;Internet;Internet of Things;IoT sensor based mobility performance evaluation test-bed;advanced IoT technology;dangerous materials;disaster environment;disaster prevention service;disaster response robots;performance rating;Fires;Rescue robots;Robot sensing systems;Standards;Wheels;Disaster Simulation;IoT sensors;Mobility Performance;Test-bed},
}

@Article{Okada1985,
  author   = {T. Okada and T. Nitta and T. Shintani},
  title    = {On-load test of the 20kVA superconducting generator},
  journal  = {IEEE Transactions on Magnetics},
  year     = {1985},
  volume   = {21},
  number   = {2},
  pages    = {668-671},
  month    = {Mar},
  issn     = {0018-9464},
  abstract = {The on-load tests are carried out on an experimental power system, where the 20 kVA superconducting synchronous generator is connected to the regional power system through reactors (artificial transmission lines). The cooling characteristics of the rotor, especially, the cold damper, are obtained. On the on-load tests, active power vs. reactive power, active power vs. load angle, field current vs. active power characteristics at the constant terminal voltage, and so on are obtained. The transient behavior of the generator for a small variation of the input power is obtained. A transient analysis for the above test was carried out. Good agreement between the measured and calculated values is confirmed. From the results, the characteristics of superconducting generators are compared with those of the conventional ones and discussed.},
  doi      = {10.1109/TMAG.1985.1063807},
  keywords = {Rotating machine testing;Superconducting rotating machines;Synchronous generators;Cooling;Inductors;Power system transients;Power systems;Power transmission lines;Reactive power;Rotors;Superconducting transmission lines;Synchronous generators;System testing},
}

@InProceedings{Akin2004,
  author    = {B. Akin and U. Orguner and A. Ersak},
  title     = {An experimental performance test of a derivative-free non-linear state observer designed for sensorless AC drives},
  booktitle = {Mechatronics, 2004. ICM '04. Proceedings of the IEEE International Conference on},
  year      = {2004},
  pages     = {432-438},
  month     = {June},
  abstract  = {In this paper, a new Kalman filtering technique, unscented Kalman filter (UKF) is utilized both experimentally and theoretically as a state estimation tool in field-oriented control (FOC) of sensorless AC drives. Using the advantages of this recent derivative-free nonlinear estimation tool, rotor speed and dq-axis fluxes of an induction motor are estimated only with the sensed stator currents and voltages information. In a previous study, simulations has shown that, UKF, whose several intrinsic properties suggest its use over EKF in highly nonlinear systems, has highly satisfactory rotor speed and flux estimates, which are the most critical states for FOC. In this new work, those simulation results are supported with experimental results.},
  doi       = {10.1109/ICMECH.2004.1364478},
  keywords  = {AC motor drives;Kalman filters;induction motors;machine vector control;nonlinear control systems;observers;Kalman filtering technique;experimental performance test;field-oriented control;induction motor;nonlinear state observer;nonlinear systems;sensed stator currents;sensorless AC drives;state estimation;unscented Kalman filter;Filtering;Induction motors;Kalman filters;Observers;Rotors;Sensorless control;State estimation;Stators;Testing;Voltage},
}

@InProceedings{Wang2013,
  author    = {Z. Wang and Z. Tong},
  title     = {The performance test of heat exchanger under low-temperature frosting conditions},
  booktitle = {Proceedings of the 2013 International Conference on Advanced Mechatronic Systems},
  year      = {2013},
  pages     = {286-289},
  month     = {Sept},
  abstract  = {The heat exchanger performance test bench under the frosting condition has been designed and structured, and the various parameters measuring instrument and sensor have been installed. The test bench consists of refrigeration cycle and air duct cycle which can simulate low temperature condition. With the assistance of C# programming language and .NET Framework, a multi-function remote measurement and control system is developed, which can be used for environmental simulation, data acquisition, display and data processing, real-time curve and video display. The performance test of heat exchanger under different conditions could be completed by the test system. The influence of external environment factors on the heat exchanger under frosting condition can be studied. This test system could provide more experimental reference and calculation basis for the study of heat exchanger under frosting condition at low temperature.},
  doi       = {10.1109/ICAMechS.2013.6681795},
  issn      = {2325-0682},
  keywords  = {C language;air conditioning;heat exchangers;ice;mechanical engineering computing;refrigeration;.NET Framework;C# programming language;air duct cycle;control system;data acquisition;data processing;environmental simulation;external environment factors;heat exchanger performance test;low-temperature frosting conditions;multifunction remote measurement;real-time curve display;refrigeration cycle;video display;Data models;Educational institutions;Heating;Temperature distribution;Temperature measurement;Heat exchanger;Low-temperature frosting;Performance test},
}

@InProceedings{Xiao2009,
  author    = {J. Xiao and H. Jiang and C. Tang and Y. Mo and J. Xie},
  title     = {Research on Dry Resistance Load Test of Diesel Locomotive for Energy Saving},
  booktitle = {2009 Asia-Pacific Power and Energy Engineering Conference},
  year      = {2009},
  pages     = {1-4},
  month     = {March},
  abstract  = {A method of dry resistance load test of diesel locomotive is introduced. The electric power generated by a dynamotor, which is driven by the diesel, is converted to DC and consumed on the dry resistances. As the heat dissipation of the resistances is about several thousand kilowatts, DC motor fans are used for air cooling the resistances. In order to save energy, the energy for driven the motor fans is come from the electric power of the DC power. A constant current speed regulating system for the motor fans is presented, which bases on a kind of high-power switch component (IGBT). The experimental results are discussed.},
  doi       = {10.1109/APPEEC.2009.4918682},
  issn      = {2157-4839},
  keywords  = {DC motors;cooling;diesel-electric locomotives;fans;DC motor fans;air cooling;constant current speed regulating system;diesel locomotive;dry resistance load test;dynamotor;energy saving;heat dissipation;high-power switch component;Cooling;DC generators;DC motors;Electric resistance;Fans;Insulated gate bipolar transistors;Power generation;Resistance heating;Switches;Testing},
}

@InProceedings{Dixon2016,
  author    = {J. Dixon and V. Rajamani and C. Bunting},
  title     = {Performance test of unmanned aerial systems communication links in a severe multipath environment},
  booktitle = {2016 IEEE International Symposium on Electromagnetic Compatibility (EMC)},
  year      = {2016},
  pages     = {862-867},
  month     = {July},
  abstract  = {This paper discusses the results of exploratory research in analyzing the electromagnetic compatibility (EMC) of commercially available radio frequency transceivers co-located within the chassis of an Unmanned Air System (UAS). Tests were performed on a UAS with multiple communication systems onboard encompassing frequency bands with center frequencies of 915 MHz, 2.4 GHz, and 5.8 GHz. These tests were performed in a normal operational environment a.k.a free space and also inside a multipath environment where the UAS was subjected to performance evaluation i.e. the status of the communication systems of the UAS were monitored while there is no external EM threat and also while applying an external EM field.},
  doi       = {10.1109/ISEMC.2016.7571763},
  keywords  = {aircraft communication;autonomous aerial vehicles;electromagnetic compatibility;radio links;radio transceivers;EMC;UAS;electromagnetic compatibility;external EM field;frequency 2.4 GHz;frequency 5.8 GHz;frequency 915 MHz;multipath environment;multiple communication systems;performance evaluation;performance test;radiofrequency transceivers;unmanned aerial system communication links;Decision support systems;Drones;Electromagnetic Compatibility (EMC);Electromagnetic Interference (EMI);Unmanned Air System (UAS);Unmanned Air Vehicle (UAV)},
}

@InProceedings{Lin2011,
  author    = {Z. Lin and Y. Liu and Y. Jia and Y. Zhang and T. Xia and Y. Liu and F. Wen},
  title     = {Dynamic performance test of single-phase phasor measurement units},
  booktitle = {2011 IEEE Power and Energy Society General Meeting},
  year      = {2011},
  pages     = {1-7},
  month     = {July},
  abstract  = {Wide area measurements are becoming the norm of power system monitoring, protection and control. Frequency monitoring network (FNET) is a low-cost, easily deployable system at 120V distribution level. The frequency disturbance recorder (FDR) is actually a single-phase phasor measurement unit (PMU) in the sense that it measures the voltage phase angle, amplitude, and frequency from a single-phase voltage source. This paper discussed a calibrating and dynamic testing procedure developed for assuring the quality and accuracy of FDRs. Voltage magnitude and angle are calibrated, and two types of dynamic performance test, step and ramp, are performed for verifying the dynamic performance of FDRs. A detailed FDR calibrating and testing case is given. The test results demonstrate that the quality and accuracy of FDRs can satisfy the requirement of wide area measurement system.},
  doi       = {10.1109/PES.2011.6039495},
  issn      = {1932-5517},
  keywords  = {calibration;phase measurement;power system control;power system measurement;power system protection;FDR;calibration;dynamic performance test;frequency disturbance recorder;frequency monitoring network;phasor measurement units;power system control;power system monitoring;power system protection;voltage 120 V;voltage magnitude;voltage source;wide area measurement system;Accuracy;Calibration;Frequency measurement;Phasor measurement units;Power system dynamics;Testing;Voltage measurement;Power system measurement;calibration;dynamic performance;frequency disturbance recorder;phasor measurement unit;wide area measurement system},
}

@InProceedings{Bondi2009,
  author    = {A. B. Bondi and J. P. Ros},
  title     = {Experience with Training a Remotely Located Performance Test Team in a Quasi-agile Global Environment},
  booktitle = {2009 Fourth IEEE International Conference on Global Software Engineering},
  year      = {2009},
  pages     = {254-261},
  month     = {July},
  abstract  = {We describe our experience of training a remotely located team of developers and testers to prepare and execute performance tests. The team is located in India. The lead performance engineer and the test project manager are based in New Jersey. The team members had little or no prior experience of performance testing. We describe how we overcame cultural differences and a large time difference to develop a performance testing team that is now functioning well with far less supervision than was required at its inception. Cultural differences included contrasting views on adherence to strict laboratory procedures and assumptions about the prior knowledge, experience, and expectations of working habits of the India-based and New Jersey-based teams. We show how these differences and organizational challenges were overcome with intensive on-site training, the use of twice-daily scrum meetings, the careful designation of team leaders and role players at the remote testing site, and, eventually, the development intensive use of automated tools to execute performance tests and track the results.},
  doi       = {10.1109/ICGSE.2009.34},
  issn      = {2329-6305},
  keywords  = {groupware;social aspects of automation;testing;training;cultural differences;laboratory procedures;on-site training;organizational challenges;performance testing team;quasi-agile global environment;remote testing site;time difference;Automatic testing;Bonding;Cultural differences;Engineering management;Management training;Performance analysis;Project management;Software engineering;Software testing;System testing;Agile;Scrum;global software development;performance testing;training},
}

@InProceedings{Yun2010,
  author    = {S. Yun and B. J. Lee and Y. J. Lee and S. Sung},
  title     = {Real-time performance test of an vision-based inertial SLAM},
  booktitle = {ICCAS 2010},
  year      = {2010},
  pages     = {2423-2426},
  month     = {Oct},
  abstract  = {Despite its precise positioning performance, a GPS based navigation system may require the reference or augmentation station in close boundaries and is liable to be affected by satellite observation environments. Thus, this paper presents a vision-based inertial SLAM navigation system which can operate in a real-time manner and uses purely unknown feature points in order to cope with the limited GPS/INS integration environment. And real-time performance of the presented system is verified via indoor test.},
  doi       = {10.1109/ICCAS.2010.5670282},
  keywords  = {Global Positioning System;SLAM (robots);aerospace robotics;inertial navigation;real-time systems;robot vision;GPS based navigation system;GPS/INS integration environment;augmentation station;indoor test;positioning performance;real-time manner;real-time performance test;reference station;satellite observation environments;vision-based inertial SLAM navigation system;Estimation;Machine vision;Navigation;Real time systems;Simultaneous localization and mapping;Heterogeneous sensor integration;IMU;Real-Time;Relative positioning;Vision sensor},
}

@InProceedings{Mainardi1994,
  author    = {L. T. Mainardi and E. Petrucci and A. M. Bianchi and V. Balian and M. Bertinelli and M. Mainardi and S. Cerutti},
  title     = {Time-variant spectral analysis for the studying of transient ischemia during dipyridamole stress test},
  booktitle = {Computers in Cardiology 1994},
  year      = {1994},
  pages     = {13-16},
  month     = {Sep},
  abstract  = {The effects of dipyridamole and dipyridamole induced ischemia on the traditional spectral parameters of heart rate variability (HRV) were investigated in normal and coronary artery disease (CAD) patients, who underwent a dipyridamole echocardiography test (DET). The relevant spectral parameters (LF and NF powers, LF/HF ratio) were monitored on a beat-to-beat basis and their variations were linked to the different test epochs and the different pathological events as detected by echocardiographic and electrocardiographic changes. A recursive least square (RLS) identification algorithm was used to this purpose, which is able to track the dynamical changes in nonstationary signals. Spectral parameters were obtained by means of a pole-tracking algorithm which fulfils an efficient extraction of these parameters on a beat-to-beat basis. The estimated parameters allow one, to achieve more information on the autonomic nervous system (ANS) status during drug infusion and the correspondence with the induced ischemia},
  doi       = {10.1109/CIC.1994.470261},
  keywords  = {echocardiography;electrocardiography;medical signal processing;neurophysiology;spectral analysis;HRV;LF powers;LF/HF ratio;NF powers;autonomic nervous system;beat-to-beat basis;coronary artery disease;dipyridamole echocardiography test;dipyridamole induced ischemia;dipyridamole stress test;drug infusion;dynamical changes;electrocardiographic changes;heart rate variability;nonstationary signals;normal patients;pathological events;pole-tracking algorithm;recursive least square identification algorithm;spectral parameters;time-variant spectral analysis;transient ischemia;Coronary arteriosclerosis;Echocardiography;Hafnium;Heart rate variability;Ischemic pain;Noise measurement;Patient monitoring;Spectral analysis;Testing;Transient analysis},
}

@InProceedings{Shankar2011,
  author    = {S. S. Shankar and J. S. Shankar},
  title     = {Synthesizable verification IP to stress test system-on-chip emulation and prototyping platforms},
  booktitle = {2011 International Symposium on Integrated Circuits},
  year      = {2011},
  pages     = {609-612},
  month     = {Dec},
  abstract  = {One of the biggest challenges today with Pre-silicon System-on-Chip verification is to stress out the SoC to uncover as many corner case design issues by injecting heavy real time data traffic into the system. The inherent efficiency and the performance of the Emulation and FPGA prototyping systems make them the ideal platforms to run these tests. A typical solution is to inject data traffic through protocol exercisers with proprietary hardware (vendor specific slow down solutions) which can bridge the emulated DUT with a real time device or use software API's with transaction based SCE-MI communication infrastructure. The need for a complex input output interface makes the former difficult to be used with all emulators / FPGA prototyping systems while SCE-MI communication infrastructure being protocol specific is a disadvantage. So, a synthesizable verification architecture compliant with SCE-MI 2.0 infrastructure through which the protocol specific traffic is injected through industry standard interfaces. i.e. PIPE (PCIe), UTMI (USB), MII (Ethernet) based on user configured stimuli has been designed and implemented. Being synthesizable, the verification environment can run in both emulation and prototyping platforms effectively stress testing the complete system.},
  doi       = {10.1109/ISICir.2011.6131936},
  issn      = {2325-0631},
  keywords  = {field programmable gate arrays;formal verification;industrial property;peripheral interfaces;system-on-chip;DUT;FPGA prototyping systems;PIPE;SCE-MI 2.0 infrastructure;SCE-MI communication infrastructure;UTMI;data traffic;device under test;pre-silicon system-on-chip verification;protocol exercisers;stress test;synthesizable verification IP;verification architecture compliant;verification environment;Computer architecture;Emulation;Hardware;Protocols;Software;Stress;System-on-a-chip;PIPE;SCE-MI;Stress Testing;UTMI},
}

@InProceedings{Yan2017,
  author        = {B. Yan and D. Teng and L. Liu and G. Wang},
  title         = {The degradation behaviors of white LEDs under highly accelerated stress testing (HAST)},
  booktitle     = {2017 18th International Conference on Electronic Packaging Technology (ICEPT)},
  year          = {2017},
  pages         = {759-763},
  month         = {Aug},
  __markedentry = {[Jonnathan:]},
  abstract      = {Reliability of GaN-based LEDs is attracting researchers to engage in actively. At present, evaluating the lifetime of GaN-based LEDs in a short testing duration is still open question. Thermal and humidity stresses are two main environmental stresses that LED products will suffer infield applications. At the level of devices, LEDs are non-sensitive to vibration. In order to evaluate the reliabilities (including the lifetime and failure rate)of white LED devices in a short period, highly accelerated stress testing (HAST) method is attempted boldly in the present paper. A series of HAST conditions are designing through different combinations of thermal, electrical and humidity stresses. The temperatures fixed at 120°C, the biased currents vary between 20mA-350mA, and the humidities vary between 65%RH-95%RH, which imply the pressure inside the furnace is high than 1atm. The forward voltage and light intensity are monitored in-situ with a time step of 1min. Preliminary results indicate that the white LED devices' lifetime of L70 obeys Gaussian distribution under HAST humidity conditions, while the L70 lifetime obeys Inverse power distribution with the injection current density variation. Based on the Arrhenius equation, Inverse power law equation and Gauss equation, the copula acceleration model equation is established with respect to thermal, electrical and humidity stresses. As an example, under the condition of 20mA&85%RH&120°C the accelerating factor is estimated as 118.0 and 109.2. The general lifetime of L70 for white LED devices are estimated as 16926.9h and 5722.5h, respectively.},
  doi           = {10.1109/ICEPT.2017.8046559},
  keywords      = {Gaussian distribution;III-V semiconductors;LED displays;gallium compounds;life testing;thermal stresses;wide band gap semiconductors;Arrhenius equation;GaN;Gauss equation;Gaussian distribution;HAST conditions;L70 lifetime;copula acceleration model equation;degradation behaviors;environmental stresses;failure rate;highly accelerated stress testing;humidity conditions;humidity stresses;injection current density variation;inverse power distribution;inverse power law equation;lifetime rate;temperature 120 degC;thermal stresses;white LED;Gallium;Humidity measurement;Ions;RNA;Stress;Urban areas;Vibrations;Accelerating factor;Copula acceleration model;HAST},
}

@InProceedings{Fahmi2017,
  author        = {F. Z. Fahmi and M. Abdurohman},
  title         = {Performance testing of M2M middleware platform},
  booktitle     = {2017 3rd International Conference on Science in Information Technology (ICSITech)},
  year          = {2017},
  pages         = {378-382},
  month         = {Oct},
  __markedentry = {[Jonnathan:]},
  abstract      = {Machine to Machine Communication (M2M) is an enabler of Internet of Things (IoT) ecosystem. One of representative implemetation of M2M middleware platform is OpenMTC based on 3gpp standard. OpenMTC is horisontal M2M Platform that connect sensors and devices to user application. It support scalability by providing gateway capability layer for connecting to sensors and devices and network capability layar for supporting user application. This platform will handle large data from hundreds to thousands of sensors and devices and send the data to the suitable application. This paper has tested OpenMTC platform performance regarding its capability to handle large data. Utility and response time are measured parameters of middleware server performance. The result shows that server utilization increases when the number of nodes is less than 30. The utilization of the server shows a constant value of 70% when the number of nodes over 30. Response time to increase in line with the increase of node number. Response time is still on target while the number of nodes is less than 30.},
  doi           = {10.1109/ICSITech.2017.8257142},
  keywords      = {3G mobile communication;Internet of Things;machine-to-machine communication;middleware;mobile computing;3gpp standard;Internet of Things ecosystem;IoT ecosystem;M2M middleware platform;OpenMTC platform performance;gateway capability layer;machine to machine communication;middleware server performance;network capability layar;response time;Machine-to-machine communications;Monitoring;Sensors;Servers;Stability criteria;Stress;Testing;M2M;middleware;openMTC;performance test;stability},
}

@InBook{Chan2001,
  pages         = {372-},
  title         = {Production AST with Computers Using the Taguchi Method - Reprinted from Environmental Stress Testing Experiment Using the Taguchi Method, IEEE Transactions on Components, Packaging, and Manufacturing Technology, Part A, Vol. 18, No.1, pp. 39, with permission from the author and the IEEE, 1995.},
  publisher     = {Wiley-IEEE Press},
  year          = {2001},
  author        = {H. Anthony Chan},
  isbn          = {9780470544051},
  __markedentry = {[Jonnathan:]},
  abstract      = {
Manufacturing process improvements which increase productivity, decrease test process time, and improve customer satisfaction are highly desirable in today's marketplace. The application of environmental stress screening (ESS), i.e, Production AST, is a method of achieving these improvements. ESS is the application of stresses applied beyond product specification limits in order to find latent product defects. Utilizing ESS achieves increased robustness and lowers infant mortality.

An experiment was performed to identify the significance or relevancy of the selected stresses for application in the printed wiring assembly (PWA) production process by using a statistically significant controlled method. The design of experiments statistical approach (analysis of variance) is applied, combined with the Taguchi two-level, seven-factor design method.

This experiment concentrated on three stresses?-?temperature cycling, random vibration, and power cyling?-?and two diagnostic levels?-?a prom-based (programmable memory chip), power-on self test (POST), and a functional diagnostic test suite, contained on disk storage.

This was not an optimization experiment. Once the significance to the production process is identified, future optimizing of temperature cycling, power cycling, and vibration screens will be conducted. Also, voltage margining was not included to reduce the complexity of the experiment-treatment factors and interactions. Experimental results and conclusions on the effectiveness of different stress regimens are presented in this chapter.

Introduction

Objectives

Stress Overview

Stress Screen Designs

Experiment Overview

The Taguchi Method

Response Variable Results and Conclusions of the Taguchi Experiment

< LI>
Intra-Experiment Summary

Taguchi Method Conclusion

Terms

Acknowledgments

References

},
  booktitle     = {Accelerated Stress Testing Handbook:Guide for Achieving Quality Products},
  doi           = {10.1109/9780470544051.ch15},
  url           = {https://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5270481},
}

@InBook{Chan2001a,
  pages         = {372-},
  title         = {Manufacturing AST with Telecommunication Products - Reprinted from Quality Improvement Using Environmental Stress Testing, in the AT T Technical Journal, pp. 1023, with permission from the authors and the AT T Technical Journal 1992.},
  publisher     = {Wiley-IEEE Press},
  year          = {2001},
  author        = {H. Anthony Chan},
  isbn          = {9780470544051},
  __markedentry = {[Jonnathan:]},
  abstract      = {
AT&T and other leading manufacturers have developed techniques that use environmental stress testing to enhance the quality and reliability of electronics assemblies. These techniques consist primarily of applying thermal, vibration, and voltage stresses to components or assemblies during design and manufacturing. Environmental stress testing is a tool that is used to accelerate the detection of product weaknesses. When coupled with corrective-action programs, this tool also enhances product quality and reliability. This chapter discusses applications of environmental stress testing in the electronics industry. It also reviews the results of environmental stress testing at AT&T's Little Rock Operations Center in Arkansas as applied primarily to the manufacture of circuit-card assemblies.

Introduction

EST During Product Design (Design AST)

Production EST (AST)

Production EST (AST) Studies at AT&T

Results of the Thermal Cycling Studies

Acknowledgments

References

},
  booktitle     = {Accelerated Stress Testing Handbook:Guide for Achieving Quality Products},
  doi           = {10.1109/9780470544051.ch20},
  url           = {https://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5270486},
}

@Article{Wayman2013,
  author        = {J. L. Wayman and A. Possolo and A. J. Mansfield},
  title         = {Modern statistical and philosophical framework for uncertainty assessment in biometric performance testing},
  journal       = {IET Biometrics},
  year          = {2013},
  volume        = {2},
  number        = {3},
  pages         = {85-96},
  month         = {September},
  issn          = {2047-4938},
  __markedentry = {[Jonnathan:]},
  abstract      = {The question of estimating uncertainty in measurement is fundamental to all scientific fields. In the field of automated human recognition, lack of repeatability and reproducibility of measurements has been noted since at least the 1970s. This study discusses current approaches to estimation of measurement uncertainty within the broader context of scientific philosophy and measurement science. The authors discuss the Duhem-Quine thesis on testing holism and international standards on estimating and reporting uncertainty in laboratory measurements, then apply these concepts to the estimation of uncertainty in technology, scenario and operational testing in biometrics. The authors advocate for moving beyond the calculation of `coverage' intervals as defined in the ISO/IEC `guidelines for the expression of uncertainty in measurement' to full application of the concepts of uncertainty assessment.},
  doi           = {10.1049/iet-bmt.2013.0009},
  keywords      = {IEC standards;ISO standards;biometrics (access control);computerised instrumentation;measurement standards;measurement uncertainty;philosophical aspects;statistical analysis;Duhem-Quine thesis;ISO-IEC guidelines;biometric performance testing;coverage intervals;international standards;laboratory measurements;measurement science;measurement uncertainty estimation;operational testing;philosophical framework;scenario testing;scientific philosophy;statistical framework;technology testing},
}

@InProceedings{Honari2008,
  author        = {B. Honari and J. Donovan and T. Joyce and S. Wilson},
  title         = {Application of generalized linear models for optimizing production stress testing},
  booktitle     = {2008 Annual Reliability and Maintainability Symposium},
  year          = {2008},
  pages         = {267-271},
  month         = {Jan},
  __markedentry = {[Jonnathan:]},
  abstract      = {Accelerated environmental stress tests (EST) are applied during the manufacturing process to improve reliability by precipitating and detecting latent defects. This test represents an in-process manufacturing screen and the objective of performing it is to avoid early field failures that reduce the customer satisfaction level and increase warranty and compensation costs. Temperature cycling during EST is one of the most commonly used test procedures. Although it is an expensive and energy intensive procedure, usually a lengthy test is initially recommended for a new product. Based on the product test performance or a possible manufacturing process modification, the test duration and regime may be changed after some period. Even if the number of test cycles is reduced, EST continues to be an expensive test and a major process bottleneck. This paper uses generalized linear modeling (GLM) to investigate the effects of the production and EST test variables on the population under test. Both the number of units rejected and the time to failure can be modeled as a regression function of covariates representative of the test environment. The field reliability function is written as a product of the unconditional reliability in each segment of the test profile such as dwell, ramp, etc. The next step is to apply the result of the temperature cycle EST GLM to a mathematical cost model. This cost model includes both the test cost and the warranty and compensation costs of the early field failures. The optimum test regime and number of cycles, which minimizes the total cost is determined by combining the GLM and the cost model. In this way the production test regime can be optimized in terms of field reliability/test cost trade-off.},
  doi           = {10.1109/RAMS.2008.4925806},
  issn          = {0149-144X},
  keywords      = {costing;flaw detection;life testing;manufacturing processes;production testing;regression analysis;reliability;accelerated environmental stress tests;compensation cost;generalized linear model;latent defect detection;manufacturing process;mathematical cost model;product test performance;production stress testing;regression analysis;reliability;warranty cost;Cost function;Customer satisfaction;Life estimation;Manufacturing processes;Performance evaluation;Production;Stress;Temperature;Testing;Warranties;Environmental Stress Testing;Generalized Linear Models;Test Optimization},
}

@Article{Parker1992b,
  author        = {T. P. Parker and G. L. Harrison},
  title         = {Quality improvement using environmental stress testing},
  journal       = {AT T Technical Journal},
  year          = {1992},
  volume        = {71},
  number        = {4},
  pages         = {10-23},
  month         = {July},
  issn          = {8756-2324},
  __markedentry = {[Jonnathan:]},
  abstract      = {AT&T and other leading manufacturers have developed techniques that use environmental stress testing to enhance the quality and reliability of electronics assemblies. These techniques consist primarily of applying thermal, vibration, and voltage stresses to components or assemblies during design and manufacturing. Environmental stress testing is a tool that is used to accelerate the detection of product weaknesses. When coupled with corrective-action programs, this tool also enhances product quality and reliability. This paper discusses applications of environmental stress testing in the electronics industry. It also reviews the results of environmental stress testing at AT&T's Little Rock Operations Center in Arkansas as applied primarily to the manufacture of circuit-card assemblies.},
  doi           = {10.1002/j.1538-7305.1992.tb00169.x},
}

@InProceedings{Schinstock1996,
  author        = {D. E. Schinstock and T. A. Haskew},
  title         = {Dynamic load testing of roller screw EMAs},
  booktitle     = {IECEC 96. Proceedings of the 31st Intersociety Energy Conversion Engineering Conference},
  year          = {1996},
  volume        = {1},
  pages         = {221-226 vol.1},
  month         = {Aug},
  __markedentry = {[Jonnathan:]},
  abstract      = {In the electromechanical actuators (EMA) laboratory at The University of Alabama, USA, a dynamic load test stand has been designed and built. This test stand uses large load, high bandwidth and hydraulic actuation to generate load profiles under force control. The test stand can accommodate EMAs up to six feet in length. It can generate dynamic loads of up to 100,000 lb at fundamental frequencies of up to 12 Hz against a stiff environment. This test stand has been used to generate severe loading conditions on a large roller screw in an attempt to qualify the effects of large, high frequency loads on roller screw. During the tests performed in the EMA laboratory the screw was fixed at one end and axial loads were applied to the roller nut at the other. Since the end opposite the nut was fixed, only a small amount of relative rotation between the nut and screw was achieved. This rotation was the result of elastic deformation (wind up) of the screw along the length between the fixed end and the nut. This simulates a severe, but likely, application of the roller screw. The results of the tests performed demonstrate that roller screws may be damaged by dynamic loading with load magnitudes that are well within the static load rating of the screw. While the damage that was observed is not catastrophic, it would be expected to substantially decrease the life of the screw},
  doi           = {10.1109/IECEC.1996.552874},
  issn          = {1089-3547},
  keywords      = {electric actuators;machine testing;mechanical testing;test equipment;test facilities;12 Hz;USA;dynamic load test stand;dynamic load testing;dynamic loading;elastic deformation;electromechanical actuators;roller screw actuators;static load rating;test laboratory;Bandwidth;Electric shock;Fasteners;Force control;Frequency;Hydraulic actuators;Laboratories;Lubrication;Performance evaluation;Testing},
}

@InProceedings{Kruseman2007,
  author        = {B. Kruseman and A. Majhi and G. Gronthoud},
  title         = {On Performance Testing with Path Delay Patterns},
  booktitle     = {25th IEEE VLSI Test Symposium (VTS'07)},
  year          = {2007},
  pages         = {29-34},
  month         = {May},
  __markedentry = {[Jonnathan:]},
  abstract      = {Application specific ICs are typically designed to meet a given performance specification. For these ICs a higher performance does not add value and less performance makes the IC useless. This class of ICs is designed based on worst-case corner analysis. It is expected that this will become area costly in more advanced technologies. An alternative is to use statistical design techniques but this implies that the performance needs to be tested with, for example, path delay testing. Our experiments in 65 nm show that the actual delay depends on the global activity within an IC as well as effects in the local neighbourhood of the path. These global and local effects can independently cause about 15% of additional delay. Hence, their impact needs to be included during test and thr authors propose to create (close to) worst-case delay patterns. Individually, the patterns have an enhanced sensitivity for the most important local effects and combined they provide coverage for global effects. This makes them better suited as speed indicators than conventional path delay patterns.},
  doi           = {10.1109/VTS.2007.45},
  issn          = {1093-0167},
  keywords      = {application specific integrated circuits;delays;integrated circuit testing;65 nm;application specific integrated circuits;path delay testing;performance testing;worst-case corner analysis;Added delay;Consumer electronics;Costs;Delay effects;Electronic equipment testing;Frequency;Libraries;Performance analysis;Ring oscillators;Test pattern generators},
}

@InProceedings{Heukelman2017,
  author        = {D. Heukelman},
  title         = {Measuring e-readiness: A case study: Self-assessment vs performance testing},
  booktitle     = {2017 1st International Conference on Next Generation Computing Applications (NextComp)},
  year          = {2017},
  pages         = {215-219},
  month         = {July},
  __markedentry = {[Jonnathan:]},
  abstract      = {Measuring the impact of an ICT-skills intervention can be done in different ways. Typically, one would measure before an intervention and again after the intervention. In this paper the use of self-assessment questionnaires, as opposed to performance testing, is investigated and reported on. A self-assessment questionnaire was administered to 345 first year students entering Higher Education for the first time. Students were assessed before commencing the program: 25 questions, requiring participants to assess their own level of skill, to determine their e-readiness. A subgroup of 55 of these students were subsequently given 3 tasks to perform in a computer laboratory, to assess their e-readiness skills level. The efficiency, accuracy and reliability of the two methods were compared. It was concluded that, based on the efficiency, accuracy and depth of knowledge gained, self-assessment is a valuable tool.},
  doi           = {10.1109/NEXTCOMP.2017.8016201},
  keywords      = {computer literacy;further education;ICT-skills intervention;computer laboratory;e-readiness measurement;e-readiness skills level;higher education;performance testing;self-assessment questionnaire;Atmospheric measurements;Economics;Extraterrestrial measurements;Instruments;Particle measurements;Reliability;Testing;ICT;Skills Measurement;e-Readiness},
}

@InProceedings{Maalej2013,
  author        = {A. J. Maâlej and M. Hamza and M. Krichen},
  title         = {WSCLT: A Tool for WS-BPEL Compositions Load Testing},
  booktitle     = {2013 Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises},
  year          = {2013},
  pages         = {272-277},
  month         = {June},
  __markedentry = {[Jonnathan:]},
  abstract      = {This paper addresses the load testing of WS-BPEL compositions. For that, we developed WSCLT tool, which takes as input a specification of the composition under test, expressed as a Timed Automaton, and considers various parameters such as the number of requests to handle simultaneously. Our WSCLT tool injects this load in the application and monitors the sequence of requests, invocations and responses between the components. This log is then analyzed by the tool to separate the actions corresponding to each instance and to check that they follow legitimate paths. A global report is then issued regarding all concurrent instances. We illustrate how to use our prototype tool by means of a case study.},
  doi           = {10.1109/WETICE.2013.71},
  issn          = {1524-4547},
  keywords      = {Web services;automata theory;program testing;WS-BPEL compositions;WSCLT;load testing;timed automaton;Atmospheric modeling;Automata;Delays;Load modeling;Queueing analysis;Testing;Web services;Timed Automaton;WS-BPEL compositions;load testing;log analysis},
}

@InProceedings{Eros2008,
  author        = {L. Eros and T. Csondes},
  title         = {Test component assignment in a performance testing environment},
  booktitle     = {2008 16th International Conference on Software, Telecommunications and Computer Networks},
  year          = {2008},
  pages         = {399-403},
  month         = {Sept},
  __markedentry = {[Jonnathan:6]},
  abstract      = {In this paper we are going to introduce the problem of assigning test components to hosts of a performance (or load) testing environment, and its two novel solutions. When testing the performance of a device (system under test-SUT), the test environment simulates the latter real-life environment of the SUT. The number of hosts in the test environment is however way less than the number of hosts the SUT will have to serve in its real-life environment. Thus, real-life hosts are simulated by software entities, the so-called test components that have to be optimally assigned and then executed on the hosts of the test environment (testing hosts). Our goal is to emulate all the test components by as few testing hosts as possible, that is, to maximize the load on the testing hosts. The problem to be solved is a special case of the task assignment problem for which many solutions have been developed. Our solutions presented in this paper are, however, optimized for distributing load testing traffic. Thus the possibilities and restrictions we had to take into account are very different from those of the classical task assignment case. One of the solutions we present extends existing bin packing heuristics, while the other one solves a series of integer linear programs to make the assignments. Our simulations have shown that by applying our solutions, the average load level on testing hosts can be significantly increased.},
  doi           = {10.1109/SOFTCOM.2008.4669518},
  keywords      = {automatic test software;bin packing;digital simulation;integer programming;linear programming;SUT;bin packing heuristic;integer linear program;load testing traffic distribution;performance testing environment;real-life host simulation;software entity;system under test;test component assignment;Emulation;Environmental economics;Heuristic algorithms;Informatics;Software testing;Stress;System testing;Telecommunication traffic;Traffic control},
}

@InProceedings{Liu2017,
  author        = {R. S. Liu and Y. S. Chang and C. W. Hung},
  title         = {VST: A virtual stress testing framework for discovering bugs in SSD flash-translation layers},
  booktitle     = {2017 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)},
  year          = {2017},
  pages         = {283-290},
  month         = {Nov},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Flash translation layers (FTLs) are the core embedded software (also known as firmware) of NAND flash-based solid-state drives (SSDs). The relentless pursuit of high-performance SSDs renders FTLs increasingly complex and intricate. Therefore, testing and validating FTLs are crucial and challenging tasks. Directly testing and validating FTLs on SSD hardware are common practices though, they are time-consuming and cumbersome because 1) the testing speed is limited by the hardware speed of SSDs and 2) just reproducing bugs can be challenging, let alone locating and root causing the bugs. This work presents virtual stress testing (VST), a simulation framework to enable executing SSD FTLs on PCs or servers against virtual SRAM, DRAM, and flash emulated by host-side main memory. FTL function calls, such as moving data from flash to DRAM, are served by the VST framework. Therefore, VST can test FTLs without SSD hardware requirements nor SSD speed limitations, and root causing bugs becomes manageable tasks. We apply VST to representative SSD design, OpenSSD, which is actively utilized and maintained by SSD and FTL communities. Experimental results show that VST can test FTLs at a speed up to 375 GB/s, which is several hundred times faster than directly testing FTLs on SSD hardware. Moreover, we successfully discover seven new FTL bugs in the OpenSSD design using VST, which is a solid evidence of VST's bug-discovering effectiveness.},
  doi           = {10.1109/ICCAD.2017.8203790},
  keywords      = {DRAM chips;NAND circuits;SRAM chips;embedded systems;flash memories;DRAM;FTL bugs;NAND flash-based solid-state drives;SSD FTLs;SSD flash-translation layers;VST framework;byte rate 375.0 GByte/s;core embedded software;firmware;flash translation layers;hardware speed;high-performance SSD;host-side main memory;representative SSD design;simulation framework;testing speed;virtual SRAM;virtual stress testing;Computer bugs;Hardware;Random access memory;Servers;Software;Stress;Testing;Embedded software;data storage systems;disk drives;flash memories;software debugging;software testing;systems simulation},
}

@InProceedings{Haarmann2018,
  author        = {B. Haarmann and C. Martens and H. Petzka and G. Napolitano},
  title         = {A Mighty Dataset for Stress-Testing Question Answering Systems},
  booktitle     = {2018 IEEE 12th International Conference on Semantic Computing (ICSC)},
  year          = {2018},
  pages         = {278-281},
  month         = {Jan},
  __markedentry = {[Jonnathan:6]},
  abstract      = {The general goal of semantic question answering systems is to provide correct answers to natural language queries, given a number of structured datasets. The increasing broad deployment of question answering (QA) systems in everyday life requires a comparable and reliable rating of how well QA systems perform and how scalable they are. In order to achieve this, we developed a massive dataset of more than 2 million natural language questions and their SPARQL queries for the DBpedia dataset. We combined natural language processing and linked open data to automatically generate this large amount of valid question-query pairs. Our aim is to assist the benchmarking or scoring of QA systems in terms of answering questions in a range of languages, retrieving answers from heterogeneous sources or answering massive amounts of questions within a limited time. This dataset represents an ideal choice for stress-testing systems' scalability, speed and correctness. As such it has already been included into the Large-scale QA task of the Question Answering Over Linked Data (QALD) Challenge and the HOBBIT project Question Answering Benchmark.},
  doi           = {10.1109/ICSC.2018.00054},
  keywords      = {Linked Data;natural language processing;query processing;question answering (information retrieval);DBpedia dataset;HOBBIT project Question Answering Benchmark;QA systems;SPARQL queries;combined natural language processing;natural language questions;semantic question answering systems;stress-testing Question Answering systems;stress-testing systems;valid question-query pairs;Benchmark testing;Knowledge discovery;Linked data;Natural languages;Resource description framework;Standards;Task analysis;Benchmark;DBpedia;Question-Answering;Semantics},
}

@InProceedings{Ma2010,
  author        = {B. Ma and B. Chen and X. Bai and J. Huang},
  title         = {Design of BDI Agent for Adaptive Performance Testing of Web Services},
  booktitle     = {2010 10th International Conference on Quality Software},
  year          = {2010},
  pages         = {435-440},
  month         = {July},
  __markedentry = {[Jonnathan:6]},
  abstract      = {As services are dynamic discovered and bound in the open Internet environment, testing has to be exercised continuously and online to verify and validate the continuous changes and to ensure the quality of the integrated service-based system. During this process, testing strategies have to be adapted in accordance to the changes in the environment and target systems. Software agents are characterized by context awareness, autonomous decision making and social collaboration capabilities. The paper introduces the design of BDI (Believe-Decision-Intention) agents to facilitate adaptive performance testing of Web Services. The BDI model specifies the necessary test knowledge, test goal and action plan to carry out test and adaptive schedule. Performance testing is defined as a scheduling problem to select the workload and test cases in order to achieve the goal of performance abnormal detection. A two-level control architecture is built. At the TR (Test Runner) level, the BDI agents control the workload of concurrent requests. At the TC (Test Coordinator) level, the BDI agents control the complexity of test cases. Agents communicate and collaborate with each other to share knowledge and test plan. The paper introduces the design of the BDI model, the adaptation rules and the control architecture. Case study is exercised to illustrate the adaptive testing process based on the design of BDI agents.},
  doi           = {10.1109/QSIC.2010.69},
  issn          = {1550-6002},
  keywords      = {Adaptation model;Collaboration;Complexity theory;Computer architecture;Load modeling;Testing;Time factors;BDI agent;Web Services;adaptive testing;performance testing},
}

@InProceedings{Yang2012,
  author        = {X. Yang and Z. Chen},
  title         = {An improved wavelet denoising method used in electrical throttle performance testing},
  booktitle     = {2012 International Conference on Image Analysis and Signal Processing},
  year          = {2012},
  pages         = {1-4},
  month         = {Nov},
  __markedentry = {[Jonnathan:6]},
  abstract      = {In this paper, an electrical throttle performance test system is designed mainly focusing on its potentiometer and function tests. An improved denoising algorithm based upon the wavelet transform is proposed in non-stationary testing environment. In the experiment, the virtual instrument is used to call the denoising module and processes the acquiring signals. It is proved that its effect is obviously more excellent than conventional algorithms. This test system is then used in actual assembly line. Good parts can be sorted out efficiently and the quality of assembly line is improved.},
  doi           = {10.1109/IASP.2012.6425016},
  issn          = {2156-0110},
  keywords      = {assembling;automotive engineering;fuel systems;mechanical testing;signal denoising;wavelet transforms;assembly line;electrical throttle performance testing;nonstationary testing environment;virtual instrument;wavelet denoising;wavelet transform;Algorithm design and analysis;Educational institutions;Noise;Noise reduction;Testing;Wavelet transforms;electrical throttle;performance test;wavelet denoising},
}

@InProceedings{Shen2016,
  author        = {A. Shen and M. Kuzlu and M. Pipattanasomporn and S. Rahman and L. Chen},
  title         = {A performance testing method for embedded software platforms},
  booktitle     = {2016 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)},
  year          = {2016},
  pages         = {135-140},
  month         = {June},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Performance testing is an important process in the embedded software development. It can detect bugs, help improve software quality and test the system reliability. The objective of this paper is to propose a performance testing method for embedded software platforms. A case study to evaluate the applicability of the proposed method is discussed. Performance tests are performed on three different platforms and test results are compared.},
  doi           = {10.1109/CYBER.2016.7574810},
  keywords      = {embedded systems;program debugging;program testing;software performance evaluation;software quality;software reliability;bug detection;embedded software development;embedded software platforms;performance testing;software quality;system reliability;Embedded software;Hardware;Monitoring;Software performance;Testing;Thermostats;Performance testing;embedded software;multi-agent;open source},
}

@InProceedings{Arnold2015,
  author        = {T. Arnold and A. C. Adewole and R. Tzoneva},
  title         = {Performance testing and assessment of multi-vendor protection schemes using proprietary protocols and the IEC 61850 standard},
  booktitle     = {2015 International Conference on the Industrial and Commercial Use of Energy (ICUE)},
  year          = {2015},
  pages         = {284-290},
  month         = {Aug},
  __markedentry = {[Jonnathan:6]},
  abstract      = {The International Electrotechnical Commission (IEC) developed a global standard for power system communication permitting Intelligent Electronic Devices (IEDs) to interoperate within the smart grid environment. However, in order for electric power utility companies to adopt IEC 61850 standard-based devices with confidence, it is necessary to carry out performance tests and evaluations to allay their fears. This paper presents an evaluation of the performance of IEC 61850 standard-based devices with respect to their speed, security, and dependability of operation. The study was implemented using multi-vendor IEDs configured for a Permissive Overreaching Transfer Trip (POTT) communication scheme with conventional proprietary protocols and the IEC 61850 Generic Object Oriented Substation Events (GOOSE) messages based on hardware-in-the-loop simulations with the Real-Time Digital Simulator (RTDS). RSCAD software was used in the modelling of a typical power system network protected by two multi-vendor distance protection IEDs using a lab-scale testbed designed and implemented for the investigations relating to this paper. Real-time simulations for various fault locations and fault resistances were carried out. The results obtained demonstrated the dependability and security of the operation of the IEC 61850-based POTT communication scheme with faster operating times compared with the conventional POTT communication scheme based on vendor-specific proprietary protocols. This paper could serve as a reference to electric power utility companies as they adopt IEC 61850 standard-based devices in their networks.},
  doi           = {10.1109/ICUE.2015.7280280},
  issn          = {2166-0581},
  keywords      = {IEC standards;electricity supply industry;fault location;power engineering computing;power system faults;protocols;smart power grids;substation automation;substation protection;GOOSE messages;IEC 61850 generic object oriented substation events;IEC 61850 standard-based devices;International Electrotechnical Commission;POTT communication scheme;RSCAD software;RTDS;electric power utility companies;fault locations;fault resistances;hardware-in-the-loop simulations;intelligent electronic devices;multïvendor distance protection IED;multivendor IED;multivendor protection schemes;permissive overreaching transfer trip;power system communication;power system network;real-time digital simulator;smart grid environment;vendor-specific proprietary protocols;Delays;IEC Standards;Impedance;Protocols;Distance protection;GOOSE;IEC 61850;Intelligent Electronic Devices;POTT;real-time digital simulation},
}

@InProceedings{Miljkovic2012,
  author        = {Đ. Miljković and S. Bojić and M. Đukić and M. Jovanović},
  title         = {Automation testing of Graphical User Interface},
  booktitle     = {2012 20th Telecommunications Forum (TELFOR)},
  year          = {2012},
  pages         = {1609-1612},
  month         = {Nov},
  __markedentry = {[Jonnathan:6]},
  abstract      = {In this paper is explained one solution for automation of testing Graphical User Interface. The paper gives a description of the problem, the concept of a solution and a description of the implementation of such a solution in order to confirm the above concept. Validation of the implementation was carried out on graphical tool for the development of software for audio target platform.},
  doi           = {10.1109/TELFOR.2012.6419531},
  keywords      = {graphical user interfaces;program testing;software engineering;audio target platform;automation testing;graphical tool;graphical user interface;software development;Automation;Browsers;Electronic mail;Graphical user interfaces;Manuals;Testing;XML;GUI;GUIPlayer;Lua;XML;ispitivanje},
}

@InProceedings{Meyer2017,
  author        = {G. Meyer},
  title         = {Enhanced Power Electronics System for High-Performance Testing of Motor Control Units in a Power HIL Environment},
  booktitle     = {PCIM Asia 2017; International Exhibition and Conference for Power Electronics, Intelligent Motion, Renewable Energy and Energy Management},
  year          = {2017},
  pages         = {1-8},
  month         = {June},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Hardware-in-the-loop (HIL) simulation is an established test method for analyzing motor control units (MCUs). For highly integrated drive controllers, the controller and the power electronics must be tested at the electric power level (emulation). Using this method requires specific power electronics for emulation. This paper introduces a special hardware solution that is based on an interleaved switching, three-level neutral-point-clamped (NPC) inverter and a sophisticated model-predictive control algorithm to establish a high-bandwidth electronic load for testing electronic power systems.},
}

@InProceedings{Shang2017,
  author        = {D. Shang and X. Zhang and J. Han and X. Xu},
  title         = {MultiModal-database-XJTU: An available database for biometrics recognition with its performance testing},
  booktitle     = {2017 IEEE 3rd Information Technology and Mechatronics Engineering Conference (ITOEC)},
  year          = {2017},
  pages         = {521-526},
  month         = {Oct},
  __markedentry = {[Jonnathan:6]},
  abstract      = {The current need for large multimodal databases to evaluate automatic biometrics recognition systems has motivated the development of the XJTU multimodal database. The main purpose has been to consider a large scale population, with statistical significance, in a real multimodal procedure, and including several sources of variability that can be found in real environments. The acquisition process, contents and availability of the single-session baseline corpus are fully described. Some experiments showing consistency of data through the different acquisition sites and assessing data quality are also presented. MultiModal-Database-XJTU, a new multimodal database, is presented. The database consists of fingerprint images acquired with sensor, frontal face images from a camera, iris images from a Cannon scanner, and voice utterances acquired with a microphone. The MultiModal-Database-XJTU includes real multimodal data from 102 individuals. In this contribution, the acquisition setup and protocol are outlined, and the contents of the database are described. The database will be publicly available for research purposes.},
  doi           = {10.1109/ITOEC.2017.8122351},
  keywords      = {biometrics (access control);feature extraction;fingerprint identification;MultiModal-database-XJTU;XJTU multimodal database;automatic biometrics recognition systems;data quality;multimodal data;multimodal procedure;Authentication;Databases;Face;Feature extraction;Fingerprint recognition;Fingers;Multi-focus image fusion;Perfect reconstruction;Quantum particle swarm optimization;Superior speed},
}

@InProceedings{Jo2010,
  author        = {H. J. Jo and J. G. Hwang and K. M. Lee},
  title         = {Proposal of automated performance testing tool for vital software in train control system},
  booktitle     = {ICCAS 2010},
  year          = {2010},
  pages         = {1151-1155},
  month         = {Oct},
  __markedentry = {[Jonnathan:6]},
  abstract      = {In accordance with the development of recent computer technology, the dependency of train control system on the computer software is being increased further, and accordingly, the testing for the safety and reliability of train control system software became more important. Hence, the safety assurance of the vital software running on the train control system is very critical task and yet, not many works have been done. While much efforts have been reported to improve electronic hardware's safety, not so much systematic approaches to evaluate software's safety. In this paper, we suggested an automated tool for performance testing in train control system, and presented its result of implementation. The testing items in the implemented tool had referred to the international standards in relation to the software for train control system, such as IEC 61508 and IEC 62279. In these international standards, 'performance testing' for train control system S/W has to be recommended highly.},
  doi           = {10.1109/ICCAS.2010.5669732},
  keywords      = {IEC standards;program testing;railway engineering;railway safety;IEC 61508;IEC 62279;automated performance testing tool;computer software;electronic hardware safety;international standard;performance testing;reliability testing;safety assurance;safety testing;train control system;Control systems;Monitoring;Rail transportation;Safety;Software;Standards;Testing;Performance testing;Software safety;Train control system},
}

@InProceedings{Amelot2011,
  author        = {J. Amelot and Y. S. Li-Baboud and C. Vasseur and J. Fletcher and D. Anand and J. Moyne},
  title         = {An IEEE 1588 Performance Testing Dashboard for Power Industry requirements},
  booktitle     = {2011 IEEE International Symposium on Precision Clock Synchronization for Measurement, Control and Communication},
  year          = {2011},
  pages         = {132-137},
  month         = {Sept},
  __markedentry = {[Jonnathan:6]},
  abstract      = {The numerous time synchronization performance requirements in the Smart Grid necessitates a set of common metrics and test methods. The test methods help to verify the ability of the network system and its components to meet the power industry's accuracy, reliability and interoperability criteria for next-generation substations. In order to develop viable metrics and test methods, an IEEE 1588 Testbed for the power industry has been established. To ease the challenges of testing, monitoring and analysis of the results, a software-based testing dashboard was designed and implemented. The dashboard streamlines the performance testing process by converging multiple tests for accuracy, reliability and interoperability into a centralized interface. The dashboard enables real-time visualization and analysis of the results. The paper details the design and implementation of the IEEE 1588 Power Industry Performance Testing Dashboard as well as an update of the preliminary findings from the testbed.},
  doi           = {10.1109/ISPCS.2011.6070157},
  issn          = {1949-0305},
  keywords      = {open systems;power engineering computing;power generation reliability;smart power grids;substations;synchronisation;IEEE 1588;dashboard streamlines;interoperability;next-generation substations;power industry performance testing dashboard;reliability;smart grid;software-based testing dashboard;time synchronization;Frequency synchronization;Power industry;Robustness;Switches;Synchronization;Time frequency analysis;IEEE 1588;PMU;conformance testing;test methods;time synchronization},
}

@InProceedings{Niederstrasser1999,
  author        = {C. G. Niederstrasser and C. A. Kitts and M. A. Swartwout},
  title         = {Design and performance testing of a satellite health beacon receiving station},
  booktitle     = {1999 IEEE Aerospace Conference. Proceedings (Cat. No.99TH8403)},
  year          = {1999},
  volume        = {5},
  pages         = {241-251 vol.5},
  __markedentry = {[Jonnathan:6]},
  abstract      = {As part of its space operations research program, Stanford University's Space Systems Development Laboratory (SSDL) is implementing an automated state of health assessment and notification system for spacecraft. Onboard the spacecraft, this system consists of software that filters telemetry to derive a health assessment and a periodic beacon that broadcasts this assessment to the ground. Throughout the world, a network of low-cost receiving stations receives the beacon signal and relays it to a central mission control center via the Internet. This paper addresses the design and development of a beacon receiving station. Each station is designed to be approximately an order of magnitude lower in price than a conventional two-way ground station. Emphasis is placed on making sure the station is highly autonomous, requiring little or no assistance from the host site. The stations are made up of only three separate components-an antenna, a receiver, and a personal computer},
  doi           = {10.1109/AERO.1999.790205},
  keywords      = {aerospace test facilities;automatic test equipment;automatic testing;computerised monitoring;ground support systems;receiving antennas;satellite ground stations;signal processing;telecommunication computing;Stanford University;antenna;beacon signal;central mission control center;cost;health assessment;performance testing;periodic beacon;personal computer;satellite health beacon receiving station;telemetry;two-way ground station;Information filtering;Information filters;Laboratories;Operations research;Relays;Satellite broadcasting;Software systems;Space vehicles;Telemetry;Testing},
}

@Article{Angrisani2003,
  author        = {L. Angrisani and A. Baccigalupi and G. D'Angiolo},
  title         = {A frame-level measurement apparatus for performance testing of ATM equipment},
  journal       = {IEEE Transactions on Instrumentation and Measurement},
  year          = {2003},
  volume        = {52},
  number        = {1},
  pages         = {20-26},
  month         = {Feb},
  issn          = {0018-9456},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Performance testing of asynchronous transfer mode (ATM) equipment is dealt with here. The attention is principally paid to frame-level metrics, recently proposed by the ATM Forum because of their suitability to reflect user-perceived performance better than traditional cell-level metrics. Following the suggestions of the ATM Forum, more and more network engineers and production managers are interested today in these metrics, thus increasing the need of instruments and measurement solutions appropriate to their estimation. Trying to satisfy this exigency, a new VME extension for instrumentation (VXI) based measurement apparatus is proposed in the paper. The apparatus features a suitable software, developed by the authors, which allows the evaluation of the aforementioned metrics by simply making use of common ATM analyzers; only two VXI line interfaces, capable of managing the physical and ATM layers, are, in fact, adopted. Some details concerning ATM technology and its hierarchical structure, as well as the main differences between frames, specific to the ATM adaptation layer, and cells, characterizing the underlying ATM layer, are first given. Both the hardware and software solutions of the measurement apparatus are then described in detail, paying particular attention to the measurement procedures implemented. In the end, the performance of a new ATM device is assessed through the proposed apparatus.},
  doi           = {10.1109/TIM.2003.809063},
  keywords      = {asynchronous transfer mode;automatic test equipment;telecommunication computing;telecommunication equipment testing;ATM equipment;VME extension;VXI instrumentation;frame-level metric;measurement apparatus;performance testing;Asynchronous transfer mode;B-ISDN;Delay;Instruments;Laboratories;Manufacturing;Particle measurements;Quality of service;Software measurement;Testing},
}

@InProceedings{Jin2010,
  author        = {Ni Jin and Wang Mingming and Wang Jiangqing},
  title         = {Realization on intelligent GUI automation testing based-on .NET},
  booktitle     = {2010 3rd International Conference on Computer Science and Information Technology},
  year          = {2010},
  volume        = {1},
  pages         = {14-17},
  month         = {July},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Points out the obvious deficiencies in capture/playback mechanism at present, aiming at difficulties of maintenance and extension in constantly altered GUI elements, presents a new GUI automation testing solution - Building AUILibrary. It can search, identify all the controls, trigger all kinds of mouse and keyboard events, execute data driving verification roundly and accurately, trace and record execution process and save the locale when exception occurs, implement flexible and effective GUI automation testing indeed.},
  doi           = {10.1109/ICCSIT.2010.5563862},
  keywords      = {graphical user interfaces;program testing;software tools;user interface management systems;.NET framework;AUILibrary;capture mechanism;data driving verification;intelligent GUI automation testing;playback mechanism;Automation;Computers;Graphical user interfaces;Indexes;Software;GUI;Software testing;automation},
}

@InProceedings{Li2010,
  author        = {G. Li and N. Tan},
  title         = {Design and Implementation of Remote Monitoring and Control System for Freight Train Load Testing},
  booktitle     = {2010 Third International Conference on Information and Computing},
  year          = {2010},
  volume        = {1},
  pages         = {117-120},
  month         = {June},
  __markedentry = {[Jonnathan:6]},
  abstract      = {The key technology of the fatigue reliability design and test evaluation of freight train is to establish freight train load spectrum based on operating conditions. Design a set of remote monitoring and control system for the establishment of loading spectrum's actual needs. The system uses GPS technology for vehicle location, speed and other information, through the GPRS technology to build car-side with the ground control center of the interaction channel. Using the ARM7 microprocessors, transplant embedded μC/OS-II operating system, realized the hardware management and task scheduling. The system can achieve vehicle-side with the ground control center data exchange. Through the ground control center monitoring software running real-time get the vehicles and the test equipment status, timely adjustment of test equipment. At the same time enables automatic vehicle equipment. The system basically meet the needs of the overloaded train load test research requirements can be a steady, accurate and complete remote monitoring and control functions.},
  doi           = {10.1109/ICIC.2010.36},
  issn          = {2160-7443},
  keywords      = {Global Positioning System;automatic test equipment;computerised monitoring;microprocessor chips;operating systems (computers);packet radio networks;rail traffic;scheduling;traffic engineering computing;ARM7 microprocessors;GPRS technology;GPS technology;automatic vehicle equipment;data exchange;embedded μC/OS-II operating system;fatigue reliability design;freight train load spectrum;freight train load testing;ground control center;hardware management;remote monitoring;task scheduling;train car-side;Automatic control;Control systems;Fatigue;Global Positioning System;Land vehicles;Loading;Remote monitoring;Road vehicles;System testing;Test equipment;#NAME?},
}

@Article{Hempel2015,
  author        = {M. Hempel and J. W. Tomm and D. Venables and V. Rossin and E. Zucker and T. Elsaesser},
  title         = {Long-Term Aging and Quick Stress Testing of 980-nm Single-Spatial Mode Lasers},
  journal       = {Journal of Lightwave Technology},
  year          = {2015},
  volume        = {33},
  number        = {21},
  pages         = {4450-4456},
  month         = {Nov},
  issn          = {0733-8724},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Single-spatial mode lasers emitting at 980 nm are studied during continuous-wave long-term operation and ultra-high power short-term operation (stress-test) up to 13.5 W. We find that both tests eventually activate the same degradation mechanism, namely internal catastrophic optical damage. In the case of ultra-high power operation, we show that the mechanism that initializes this effect is a lateral widening of the optical mode, resulting in increased absorption outside the waveguide. Defects formed during long-term aging may eventually lead to the same effect. Stress testing allows for activation of several degradation mechanisms in a device one after the other and for distinguishing between mechanisms induced by aging and independent ones. Stress tests could pave the way toward more time-efficient testing, e.g., for comparison of different technology variants in development.},
  doi           = {10.1109/JLT.2015.2475605},
  keywords      = {Aging;Cameras;Cavity resonators;Degradation;Monitoring;Optical pulses;Temperature measurement;Semiconductor device measurements;reliability;semiconductor diodes;semiconductor lasers},
}

@InProceedings{Brcic2015,
  author        = {P. Brčić},
  title         = {Performance testing of EMC xtremio all-flash storage system},
  booktitle     = {2015 23rd Telecommunications Forum Telfor (TELFOR)},
  year          = {2015},
  pages         = {1020-1023},
  month         = {Nov},
  __markedentry = {[Jonnathan:6]},
  abstract      = {EMC XtremIO is one of the most advanced all-Flash data storage systems which is becoming an integral part of medim and enterprise data centers. The paper represents implementation of EMC XtremIO storage system for VDI, and adopted, implemented and validated methodology for testing performance of storage systems. There were generated and released three groups of different intense load tests, during which the data was collected, created tables and graphs. Finally was generated detailed analysis of the results.},
  doi           = {10.1109/TELFOR.2015.7377639},
  keywords      = {flash memories;program testing;EMC XtremIO all-flash storage system;load tests;storage system testing performance;Electromagnetic compatibility;Monitoring;Optical fiber testing;Servers;Synthetic aperture sonar;Virtual machining;All-Flash;XtremIO;data centri;performanse;sistem za skladi¿¿tenje podataka},
}

@InProceedings{Tang2010,
  author        = {J. l. Tang and Y. j. Liu and F. s. Wu},
  title         = {Virtual experiment system for metal creep performance testing based on VRML},
  booktitle     = {2010 2nd International Conference on Advanced Computer Control},
  year          = {2010},
  volume        = {4},
  pages         = {140-143},
  month         = {March},
  __markedentry = {[Jonnathan:6]},
  abstract      = {A virtual experiment system for metal creep performance testing is built by virtual reality modeling language (VRML). The structure, function and design principles of the system are described and its implementation procedure is also discussed. The key development process, including object modeling, 3D scene building, VRML connecting to the real-time database, design of interactive virtual 3D scene and complex virtual interaction, is illustrated in this paper. In addition, the following key problems have been solved during the system realization: virtual models building and geometrical transforming, database designing and optimizing, 3D virtual experimental scenes combining dynamically, the realization of database accessing and the communication of virtual entities.},
  doi           = {10.1109/ICACC.2010.5486954},
  keywords      = {computer testing;database management systems;human computer interaction;virtual reality languages;3D scene building;complex virtual interaction;geometrical transforming;interactive virtual 3D scene;metal creep performance testing;object modeling;real time database;virtual entities;virtual experiment system;virtual reality modeling language;Buildings;Communication system control;Computer simulation;Creep;Instruments;Layout;Spatial databases;System testing;Virtual environment;Virtual reality;VRML;creep performance test;metal;virtual experiment},
}

@Article{Helmy2005,
  author        = {A. Helmy and S. Gupta},
  title         = {FOTG: fault-oriented stress testing of IP multicast},
  journal       = {IEEE Communications Letters},
  year          = {2005},
  volume        = {9},
  number        = {4},
  pages         = {375-377},
  month         = {April},
  issn          = {1089-7798},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Network simulators provide a useful tool, for protocol evaluation. However, the results depend heavily on the simulated scenarios, especially for complex protocols such as multicast. There has been little work on scenario generation. In this work we present a fault-oriented test generation (FOTG) algorithm for automated stress testing of multicast protocols. FOTG processes an extended FSM model and uses a mix of forward and backward search techniques. Unlike traditional verification approaches, instead of starting from initial states, FOTG starts from a fault and uses cause-effect relations for automatic topology synthesis then uses backward implication to generate tests. Using FOTG we test various mechanisms commonly employed by multicast routing and validate our results through simulation.},
  doi           = {10.1109/LCOMM.2005.1413639},
  keywords      = {IP networks;multicast protocols;routing protocols;search problems;telecommunication network topology;FOTG algorithm;FSM model;IP multicast routing;automated stress testing;backward search technique;fault-oriented test generation;forward search technique;network simulator;protocol evaluation;topology synthesis;traditional verification approach;Automatic testing;Engines;Multicast algorithms;Multicast protocols;Robustness;Routing protocols;Stress;System testing;Topology;Very large scale integration},
}

@InProceedings{Dinh2016,
  author        = {A. Dinh and F. M. Bui and T. Nguyen},
  title         = {An accelerometer based system to measure myocardial performance index during stress testing},
  booktitle     = {2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
  year          = {2016},
  pages         = {4877-4880},
  month         = {Aug},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Stress testing is used to measure the performance of the heart in an elevated stress state, in order to monitor or diagnose certain heart problems. Many measurements can be used to determine the performance of the heart, with the Tei index being the measurement of interest in this work. The Tei index has been used as a reliable method to evaluate systolic and diastolic performance, as it overcomes some limitations of the classical echocardiographic indices. It is calculated based on the time intervals derived from echocardiography. This paper presents an exploratory study, which uses an accelerometer to record mechanical events occurring in each cardiac cycle, also known as the seismocardiogram (SCG). From timing measurements corresponding to various events in the heart, a metric for myocardial performance is calculated based on the Tei index. The use of SCG in addition to ECG has the potential to provide further insights about the heart during stress testing, since the SCG quantifies mechanical actions of the heart.},
  doi           = {10.1109/EMBC.2016.7591820},
  issn          = {1557-170X},
  keywords      = {accelerometers;biomedical equipment;electrocardiography;ECG;Tei index;accelerometer based system;cardiac cycle;diastolic performance;heart problem diagnosis;mechanical events;myocardial performance index measurements;seismocardiogram;stress state;stress testing;systolic performance;timing measurements;Accelerometers;Electrocardiography;Heart;Indexes;Sensors;Stress;Valves;Accelerometry;Diastole;Echocardiography;Exercise Test;Female;Heart;Heart Function Tests;Humans;Male;Systole;Wireless Technology},
}

@InProceedings{Gao2016,
  author        = {R. Gao and Z. M. Jiang and C. Barna and M. Litoiu},
  title         = {A Framework to Evaluate the Effectiveness of Different Load Testing Analysis Techniques},
  booktitle     = {2016 IEEE International Conference on Software Testing, Verification and Validation (ICST)},
  year          = {2016},
  pages         = {22-32},
  month         = {April},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Large-scale software systems like Amazon and eBay must be load tested to ensure they can handle hundreds and millions of current requests in the field. Load testing usually lasts for a few hours or even days and generates large volumes of system behavior data (execution logs and counters). This data must be properly analyzed to check whether there are any performance problems in a load test. However, the sheer size of the data prevents effective manual analysis. In addition, unlike functional tests, there is usually no test oracle associated with a load test. To cope with these challenges, there have been many analysis techniques proposed to automatically detect problems in a load test by comparing the behavior of the current test against previous test(s). Unfortunately, none of these techniques compare their performance against each other. In this paper, we have proposed a framework, which evaluates and compares the effectiveness of different test analysis techniques. We have evaluated a total of 23 test analysis techniques using load testing data from three open source systems. Based on our experiments, we have found that all the test analysis techniques can effectively build performance models using data from both buggy or non-buggy tests and flag the performance deviations between them. It is more cost-effective to compare the current test against two recent previous test(s), while using testing data collected under longer sampling intervals (≥180 seconds). Among all the test analysis techniques, Control Chart, Descriptive Statistics and Regression Tree yield the best performance. Our evaluation framework and findings can be very useful for load testing practitioners and researchers. To encourage further research on this topic, we have made our testing data publicity available to download.},
  doi           = {10.1109/ICST.2016.9},
  keywords      = {control charts;large-scale systems;program testing;public domain software;regression analysis;statistics;trees (mathematics);Amazon;control chart;descriptive statistics;eBay;large-scale software systems;load testing analysis;open source systems;regression tree;Data mining;Data models;Load modeling;Queueing analysis;Radiation detectors;Testing;Topology},
}

@InProceedings{Chan1994,
  author        = {H. A. Chan},
  title         = {A formulation to optimize stress testing},
  booktitle     = {1994 Proceedings. 44th Electronic Components and Technology Conference},
  year          = {1994},
  pages         = {1020-1027},
  month         = {May},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Although hard-defects may be detectable in factory tests, weak products may exhibit failures or degrade only under certain stress conditions. Without stress testing, these weak products may often be shipped to customers causing early failures in the field. A candidate product for stress testing needs to get more business benefits to more than pay off the cost of stress testing. A business measure of the success of the stress testing program is the net benefit, which is the total benefit minus the total cost of the program. The optimum stress testing program maximizes this net benefit. A given unit of a product has a probability of encountering a maximum stress X during its product life. It also has a probability of possessing a product yield strength Y, which is the maximum stress the unit can survive without failure. While the strength distribution depends on the design and manufacture processes, the distribution of the maximum stress is determined by the customers' environment. A convenient picture is to construct the contour map of the joint probability distribution of X and Y. In this contour map, a unit falling in the Y<X region will fail during its product life, whereas one falling in the Y>X region will not result in field failure. The effects of stress testing at a given maximum stress level, XST, are shown by a dividing line on the product strength into stress test failure and stress test pass. The units in the contour map are then divided into four regions by the Y=X line and the XST line. The cost and benefits may now be evaluated for each region. Now the value of XST is a free parameter that determines the relative size of each region. The second free parameter is the fraction of units going through stress testing. These two parameters may be adjusted to maximize the net benefit of the stress testing program},
  doi           = {10.1109/ECTC.1994.367502},
  keywords      = {circuit optimisation;environmental stress screening;environmental testing;failure analysis;integrated circuit yield;life testing;probability;production testing;contour map;early failures;factory tests;joint probability distribution;maximum stress;net benefit;product life;product yield strength;stress conditions;stress test failure;stress test pass;stress testing;Circuit testing;Costs;Degradation;Electronic equipment testing;Manufacturing processes;Probability distribution;Process design;Production facilities;Stress measurement;System testing},
}

@InProceedings{Angrisani2001,
  author        = {L. Angrisani and A. Baccigalupi and G. D'Angiolo},
  title         = {A frame-level measurement apparatus for performance testing of ATM equipment},
  booktitle     = {IMTC 2001. Proceedings of the 18th IEEE Instrumentation and Measurement Technology Conference. Rediscovering Measurement in the Age of Informatics (Cat. No.01CH 37188)},
  year          = {2001},
  volume        = {3},
  pages         = {1630-1635 vol.3},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Performance testing of ATM equipment is here dealt with. In particular, the attention is paid to frame-level metrics, recently proposed by the ATM forum because of their suitability to reflect user-perceived performance better than traditional cell-level metrics. Following the suggestions of the ATM forum, more and more network engineers and production managers are nowadays interested in these metrics, thus increasing the need of instruments and measurement solutions appropriate to their estimation. Trying to satisfy this exigency, a new VXI-based measurement apparatus is proposed in the paper. The apparatus features a suitable software, developed by the authors, which allows the evaluation of the aforementioned metrics by making simply use of common ATM analyzers; only two VXI line interfaces, capable of managing both the physical and ATM layer, are, in fact, adopted. At first, some details about the hierarchical structure of the ATM technology as used as the main differences between frames, peculiar to the ATM adaptation layer, and cells characterizing the lower ATM layer are given. Then, both the hardware and software solutions of the measurement apparatus are described in detail with a particular attention to the measurement procedures implemented. At the end the performance of a new ATM device, developed by Ericsson, is assessed in terms of frame-level metrics by means of the proposed apparatus},
  doi           = {10.1109/IMTC.2001.929479},
  issn          = {1091-5281},
  keywords      = {asynchronous transfer mode;automatic test equipment;performance evaluation;peripheral interfaces;telecommunication equipment testing;ATM adaptation layer;ATM equipment;Ericsson;VXI line interfaces;VXI-based measurement apparatus;common ATM analyzers;frame-level measurement;frame-level metrics;hardware;hierarchical structure;performance testing;software;user-perceived performance;3G mobile communication;Asynchronous transfer mode;B-ISDN;Communication switching;GSM;Particle measurements;Quality of service;Software measurement;Telecommunication switching;Testing},
}

@InProceedings{Bertolino2008,
  author        = {A. Bertolino and G. De Angelis and A. Sabetta},
  title         = {VCR: Virtual Capture and Replay for Performance Testing},
  booktitle     = {2008 23rd IEEE/ACM International Conference on Automated Software Engineering},
  year          = {2008},
  pages         = {399-402},
  month         = {Sept},
  __markedentry = {[Jonnathan:6]},
  abstract      = {This paper proposes a novel approach to performance testing, called virtual capture and replay (VCR), that couples capture and replay techniques with the checkpointing capabilities provided by the latest virtualization technologies. VCR enables software performance testers to automatically take a snapshot of a running system when certain critical conditions are verified, and to later replay the scenario that led to those conditions. Several in-depth analyses can be separately carried out in the laboratory just by rewinding the captured scenario and replaying it using different probes and analysis tools.},
  doi           = {10.1109/ASE.2008.58},
  issn          = {1938-4300},
  keywords      = {program testing;virtual reality;VCR;checkpointing capabilities;software performance testing;virtual capture;virtual replay;virtualization technologies;Automatic testing;Checkpointing;Monitoring;Paper technology;Performance analysis;Software performance;Software testing;Space technology;System testing;Video recording},
}

@InProceedings{Xinfeng2011,
  author        = {Zhang Xinfeng and Shen Yong and SongGe},
  title         = {Stress testing on car remote monitoring system},
  booktitle     = {2011 International Conference on Electric Information and Control Engineering},
  year          = {2011},
  pages         = {1715-1718},
  month         = {April},
  __markedentry = {[Jonnathan:6]},
  abstract      = {A virtual on-board concurrent user based remote monitoring system stress testing method is proposed. First, the scenario of maximum concurrent users is obtained through system analysis and the method is proposed. Second, the virtual on-board concurrent users are realized by computer data generation and coding according to package protocol. Finally, a case study of stress testing is done. It is turned out that the remote monitoring system's performance can be effectively evaluated by such test method, and the maximum number of concurrent users also can be predicted.},
  doi           = {10.1109/ICEICE.2011.5777983},
  keywords      = {automobile industry;automotive engineering;computerised monitoring;mechanical engineering computing;stress analysis;car remote monitoring system;computer data coding;computer data generation;package protocol;stress testing method;system analysis;virtual on-board concurrent user;Real time systems;Remote monitoring;Servers;Software;Stress;Testing;New energy Car;Remote monitoring system;Stress Test;virtual on-board terminal},
}

@InProceedings{Schurig1997,
  author        = {H. H. Schurig and M. A. Kruer and M. N. Levesque and E. M. Gaddy and W. J. Andiario},
  title         = {Performance testing of the 5 kW EOS AM-1 flexible solar array blanket},
  booktitle     = {IECEC-97 Proceedings of the Thirty-Second Intersociety Energy Conversion Engineering Conference (Cat. No.97CH6203)},
  year          = {1997},
  volume        = {1},
  pages         = {550-555 vol.1},
  month         = {Jul},
  __markedentry = {[Jonnathan:6]},
  abstract      = {A GaAs/Ge flexible solar array blanket has been developed for use on the NASA/GSFC remote sensing EOS AM-1 spacecraft. This single wing array has been designed to provide 5 kW of power after five years in a low Earth polar orbit. The blanket configuration includes design features such as thin GaAs/Ge cell stacks mounted on a large flexible, hinged substrate, parallel connected solar cell strings providing high voltage output, a printed circuit harness, and a multi-layer jumper bus providing electrical continuity between the cell strings and the printed circuit harness. This work was contracted to TRW Space and Electronics Group in 1993 by Lockheed Martin Missiles & Space (LMMS). This paper presents the essential design of the EOS AM-1 solar array blanket, and summarizes the results of a qualification test program designed to demonstrate adequate design margins and to assess the performance of the mechanical and electrical components after exposure to a simulated mission space environment. It also reviews the complexities of performing electrical output testing on a 8.9 m×5.0 m deployed solar array blanket under AM0 conditions},
  doi           = {10.1109/IECEC.1997.659249},
  keywords      = {III-V semiconductors;aerospace testing;artificial satellites;elemental semiconductors;gallium arsenide;germanium;photovoltaic power systems;semiconductor device testing;solar cell arrays;space vehicle power plants;5 kW;5 m;8.9 m;AM0 conditions;EOS AM-1 spacecraft;GaAs-Ge;design features;flexible solar array blanket;low Earth polar orbit;mission space environment;performance testing;qualification test program;single wing array;Earth Observing System;Flexible printed circuits;Gallium arsenide;Missiles;NASA;Photovoltaic cells;Remote sensing;Space vehicles;Testing;Voltage},
}

@InProceedings{Yan2011,
  author        = {X. Yan and F. Wen and C. Fan and X. Wang},
  title         = {Performance Testing of Open Laboratory Management System Based on LoadRunner},
  booktitle     = {2011 First International Conference on Instrumentation, Measurement, Computer, Communication and Control},
  year          = {2011},
  pages         = {164-167},
  month         = {Oct},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Open Laboratory Management System provides an open virtual experiment environment for students, so that its system performance immediately impacts the quality of students learning. According to analyze the performance requirements of Open Laboratory Management System, the author discovers performance testing points, implements automated performance testing for performance testing points of the system based on Load Runner. In this paper, taking the students login for example, it elaborates testing process and provides the reference for system optimization.},
  doi           = {10.1109/IMCCC.2011.50},
  keywords      = {computer aided instruction;laboratories;program testing;virtual reality;LoadRunner;open laboratory management system;student learning;student login;testing process;virtual experiment environment;Educational institutions;Laboratories;Monitoring;Protocols;Time factors;LoadRunner;Open Laboratory Management System;performance testing},
}

@InProceedings{Leonard1997,
  author        = {D. C. Leonard},
  title         = {Simplifying motor performance testing in the production environment},
  booktitle     = {Proceedings: Electrical Insulation Conference and Electrical Manufacturing and Coil Winding Conference},
  year          = {1997},
  pages         = {185-190},
  month         = {Sep},
  __markedentry = {[Jonnathan:6]},
  abstract      = {The objective of this paper is to illustrate how performance test systems on the factory floor can be enhanced by utilizing the power and speed of integral computer hardware and software to automate and simplify tasks typically performed in the production environment. The first part of this paper discusses why the test system is needed to perform additional tasks. The second section defines the relationships between various departments within the organization, and the test system. The third section discusses the benefits of integrating additional functions into the test system. The final sections of the paper discusses incorporating artificial intelligence and networking to simplify tasks associated with the production environment},
  doi           = {10.1109/EEIC.1997.651034},
  issn          = {0362-2479},
  keywords      = {artificial intelligence;automatic testing;computer networks;electric motors;machine testing;power engineering computing;production testing;additional functions integration;artificial intelligenc;integral computer hardware;integral computer software;motor performance testing;networking;production environment;test system},
}

@InProceedings{Rangaraj2013,
  author        = {S. Rangaraj and D. Kwon and M. Pei and J. Hicks and G. Leatherman and A. Lucero and T. Wilson and S. Streit and J. He},
  title         = {Accelerated stress testing methodology to risk assess silicon-package thermomechanical failure modes resulting from moisture exposure under use condition},
  booktitle     = {2013 IEEE International Reliability Physics Symposium (IRPS)},
  year          = {2013},
  pages         = {5C.3.1-5C.3.5},
  month         = {April},
  __markedentry = {[Jonnathan:6]},
  abstract      = {IC components are exposed to moisture and thermal cycles during chip-package-board assembly and in their end use conditions. Moisture exposure influences the mechanical integrity of silicon backend dielectrics, assembly/packaging materials and packages. Reliability performance under accelerated stresses that simulate use conditions are often a critical factor in choice of materials, processing options and design rules. A complete assessment of the cumulative environmental exposure from chip-package assembly, shipment/storage, board system assembly, through end-customer use is required to guarantee product performance and reliability. This paper will detail these end user environments and use failure mode/mechanism specific acceleration models to develop accurate accelerated life testing plans and requirements. These requirements will then be compared to JEDEC standards based requirements and a need for re-calibration of these standards to more appropriate temperatures and stress durations will be highlighted.},
  doi           = {10.1109/IRPS.2013.6532032},
  issn          = {1541-7026},
  keywords      = {assembling;failure analysis;integrated circuit packaging;integrated circuit reliability;integrated circuit testing;life testing;risk management;stress analysis;IC components;JEDEC standards;accelerated life testing plans;accelerated stress testing methodology;assembly-packaging materials;board system assembly;chip-package-board assembly;cumulative environmental exposure;design rules;end user environments;failure mode-mechanism specific acceleration models;mechanical integrity;moisture cycle;moisture exposure;processing options;product performance;reliability performance;risk assessment;silicon backend dielectrics;silicon-package thermomechanical failure modes;standard re-calibration;stress durations;thermal cycle;through end-customer use;Acceleration;Materials;Mathematical model;Moisture;Reliability;Standards;Stress;HAST;JEDEC standard;acceleration model;moisture;thermal cyclin;use conditions},
}

@InProceedings{Capelli2017,
  author        = {L. Capelli and S. Sironi},
  title         = {Monitoring odour emisssions from an oil gas plant: Electronic nose performance testing in the field},
  booktitle     = {2017 ISOCS/IEEE International Symposium on Olfaction and Electronic Nose (ISOEN)},
  year          = {2017},
  pages         = {1-3},
  month         = {May},
  __markedentry = {[Jonnathan:6]},
  abstract      = {This paper focuses on performance testing of electronic noses for environmental odour monitoring in terms of their capability of correctly classifying odours at low odour concentrations. The studied case concerns the realization of an electronic nose network for the continuous monitoring of odour emissions from a crude oil extraction and separation plant. The novelty of the work consists in the fact that performance testing, which is typically carried out in laboratory before installation in the field for environmental odour monitoring outside the plant boundaries, in this case was carried out after installation with the aim of testing the instruments performances in the effective working conditions. This involved the necessity to develop a specific and repeatable procedure to obtain samples at known quality and concentration in the field. Electronic nose performance was evaluated in terms of classification accuracy, which produced satisfactory results towards the considered olfactory classes.},
  doi           = {10.1109/ISOEN.2017.7968862},
  keywords      = {chemical variables measurement;crude oil;electronic noses;gas industry;crude oil extraction;electronic nose network;environmental odour emisssion monitoring;gas plant;oil plant;olfactory class;performance testing;separation plant;Earth Observing System;Electronic noses;Instruments;Liquids;Monitoring;Oils;Testing;continuous odour monitoring;electronic nose;odour concentration;performance testing;sample preparation},
}

@InProceedings{Bisgrove1997,
  author        = {J. Bisgrove and R. Dayao and B. Houser and T. Jones and J. C. Mayes and M. McGinnis and M. Schmidt and G. Skyles and B. K. Tan},
  title         = {Integrated test facility (ITF)-automation testing to support Intel's manufacturing output},
  booktitle     = {1997 IEEE International Symposium on Semiconductor Manufacturing Conference Proceedings (Cat. No.97CH36023)},
  year          = {1997},
  pages         = {D17-D21},
  month         = {Oct},
  __markedentry = {[Jonnathan:6]},
  abstract      = {To meet the challenges of increasing automation and the potential for downtime, the current Virtual Factory Joint Automation Managers (JAM) worked with Components Automation Systems (CAS), the central engineering group responsible for the automation system, to create an Integrated Test Facility (ITF). ITF's mission is to conduct volume integrated testing of the automation suite prior to production release and to ensure that the automation suite does not hinge factory ramp. The ITF is a complete factory automation system running simulated production wafers. Established in January 1996, the ITF tests new automation product changes integrated into a complete factory manufacturing automation system and certifies that they can run in high volume. Integrated with CAS automation processes, the ITF is a key part of a process that delivers quality software},
  doi           = {10.1109/ISSM.1997.664526},
  keywords      = {factory automation;production engineering computing;production testing;test facilities;automation testing;factory manufacturing automation system;factory ramp;integrated test facility;manufacturing output;production release;quality software;simulated production wafers;volume integrated testing;Automatic testing;Content addressable storage;Engineering management;Fasteners;Manufacturing automation;Production facilities;Production systems;System testing;Test facilities;Virtual manufacturing},
}

@InProceedings{Barna2011,
  author        = {C. Barna and M. Litoiu and H. Ghanbari},
  title         = {Model-based performance testing: NIER track},
  booktitle     = {2011 33rd International Conference on Software Engineering (ICSE)},
  year          = {2011},
  pages         = {872-875},
  month         = {May},
  __markedentry = {[Jonnathan:6]},
  abstract      = {In this paper, we present a method for performance testing of transactional systems. The methods models the system under test, finds the software and hardware bottlenecks and generate the workloads that saturate them. The framework is adaptive, the model and workloads are determined during the performance test execution by measuring the system performance, fitting a performance model and by analytically computing the number and mix of users that will saturate the bottlenecks. We model the software system using a two layers queuing model and use analytical techniques to find the workload mixes that change the bottlenecks in the system. Those workload mixes become stress vectors and initial starting points for the stress test cases. The rest of test cases are generated based on a feedback loop that drives the software system towards the worst case behaviour.},
  doi           = {10.1145/1985793.1985930},
  issn          = {0270-5257},
  keywords      = {program control structures;program testing;queueing theory;feedback loop;model-based performance testing NIER track;performance test execution;queuing model;stress test cases;stress vectors;system under test;transactional systems;Adaptation models;Computational modeling;Hardware;Software;Stress;Testing;Time factors;adaptive system;performance models;performance testing;stress testing},
}

@InProceedings{Lo2017,
  author        = {C. Y. Lo and Y. W. Hua and W. C. Yu and Y. M. Chuang},
  title         = {Functional verification and performance testing for OpenAirinterface (OAI) eNodeB},
  booktitle     = {2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)},
  year          = {2017},
  pages         = {1456-1459},
  month         = {Dec},
  __markedentry = {[Jonnathan:6]},
  abstract      = {In this paper we develop and build an open air interface(OAI) eNodeB test platform for system developers to implement the network function verification and system performance evaluation for LTE network. In this test platform it also includes commercially available instruments such as EXFO EPC Simulator, Cobham TM UE Emulator and Cobham Data Generator to make this test platform performing the basic LTE network functions. The performances of this developed OAIeNodeB platform have been compared with the commercial LTE small cell eNodeB system, which is considered as the bench mark system based on Gemteck eNodeB, for proposed system parameters and various test cases .},
  doi           = {10.1109/APSIPA.2017.8282262},
  keywords      = {Long Term Evolution;performance evaluation;Cobham Data Generator;Cobham TM UE Emulator;EXFO EPC Simulator;Gemteck eNodeB;LTE network functions;developed OAIeNodeB platform;network function verification;open air interface eNodeB test platform;system performance evaluation;5G;B4G;EPC Emulator;OAI (Openairinterface);Open Source;UE Emulator;Verification Platform;eNodeB Emulator},
}

@Article{Johnson2007,
  author        = {M. J. Johnson and C. W. Ho and E. M. Maximilien and L. Williams},
  title         = {Incorporating Performance Testing in Test-Driven Development},
  journal       = {IEEE Software},
  year          = {2007},
  volume        = {24},
  number        = {3},
  pages         = {67-73},
  month         = {May},
  issn          = {0740-7459},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Our performance-testing approach required manually inspecting the performance logs. During the project's development, JUnit-based performance testing tools, such as JUnitPerf, weren't available. Such tools provide better visibility of performance problems than manual inspection of performance logs. Although we believe manual inspection of performance trends is necessary, specifying the bottom-line performance in assert-based test cases can complement the use of performance log files, making the TFP testing results more visible to the developers. We're investigating the design of assert-based performance testing to improve the TFP process. Another direction of future work is automatic performance test generation. In this project, we relied on the performance architect's experience to identify the execution paths and measurement points for performance testing. We can derive this crucial information for performance testing from the performance requirements and system design. We plan to find guidelines for specifications of performance requirements and system design to make the automation possible},
  doi           = {10.1109/MS.2007.77},
  keywords      = {formal specification;formal verification;program testing;software performance evaluation;systems analysis;JUnit-based performance testing tool;assert-based test case;automatic performance test generation;performance requirement specification;system design;test-driven development;Delay;Java;Printers;Process design;Software performance;Software testing;Switches;System software;System testing;Throughput;performance measures;test execution;testing strategies},
}

@InProceedings{Helmy1998,
  author        = {A. Helmy and D. Estrin},
  title         = {Simulation-based `STRESS' testing case study: a multicast routing protocol},
  booktitle     = {Proceedings. Sixth International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems (Cat. No.98TB100247)},
  year          = {1998},
  pages         = {36-43},
  month         = {Jul},
  __markedentry = {[Jonnathan:6]},
  abstract      = {We propose a method for using simulation to analyze the robustness of multiparty (multicast-based) protocols in a systematic fashion. We call our method Systematic Testing of Robustness by Examination of Selected Scenarios (STRESS). STRESS aims to cut the time and effort needed to explore pathological cases of a protocol during its design. This paper has two goals: (1) to describe the method, and (2) to serve as a case study of robustness analysis of multicast routing protocols. We aim to offer design tools similar to those used in CAD and VLSI design, and demonstrate how effective systematic simulation can be in studying protocol robustness},
  doi           = {10.1109/MASCOT.1998.693672},
  keywords      = {digital simulation;local area networks;multicast communication;performance evaluation;telecommunication computing;telecommunication network routing;transport protocols;CAD;LAN;VLSI design;design tools;multicast routing protocols;multiparty protocols;pathological cases;robustness analysis;scenario generation;simulation-based STRESS testing;systematic robustness testing;systematic simulation;Analytical models;Computational modeling;Computer aided software engineering;Computer science;Multicast protocols;Network topology;Routing protocols;Stress;System testing;Unicast},
}

@InProceedings{Baiquan2014,
  author        = {X. Baiquan},
  title         = {Design of Platform for Performance Testing Based on JADE},
  booktitle     = {2014 Sixth International Conference on Measuring Technology and Mechatronics Automation},
  year          = {2014},
  pages         = {251-254},
  month         = {Jan},
  __markedentry = {[Jonnathan:6]},
  abstract      = {For solving the problems presently such as coordination of the virtual users' act and the real-time acquisition of information, based on agent and JADE, this paper brings forward an architecture model of the platform for performance testing. JADE is multi-agent development environment which supports the management and communications control for agents. The principle of JADE is described and the basic method to design a platform for performance testing based on JADE is introduced, and offers a technology approach to realize the platform for performance testing.},
  doi           = {10.1109/ICMTMA.2014.63},
  issn          = {2157-1473},
  keywords      = {Java;multi-agent systems;program testing;software performance evaluation;JADE;Java Agent Development Framework;multiagent development environment;open source software;performance testing platform design;real-time information acquisition;virtual users act coordination;Automation;Mechatronics;Agent;JADE;Platform for performance testing},
}

@InProceedings{Kadam2016,
  author        = {A. H. Kadam and R. Menon and S. S. Williamson},
  title         = {Traction inverter performance testing using mathematical and real-time controller-in-the-loop Permanent Magnet Synchronous Motor emulator},
  booktitle     = {IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society},
  year          = {2016},
  pages         = {6651-6656},
  month         = {Oct},
  __markedentry = {[Jonnathan:6]},
  abstract      = {In the development stage of electric vehicle drive, simulation plays a vital role. It's a powerful tool which allows the developer to investigate various control strategies and test hardware systems in harmless work environment. The software simulations platform does have constraints. In that the complex mathematical operations take longer time to solve and eventually increases the overall simulation time and cannot perform the real-time operation. This simulation further needs to be converted to the target processor's language, either assembly or C- language, which will operate in the drive system. However, if a real-time simulation environment could be comprehended, then the real processor used in the system could be incorporated in the simulation. This eventually will eliminate the chance of introducing error during code translation as well as reduce simulation time. Also, the target controller could be tested within the simulation before introducing it the actual system. This paper discuss a concept of controller-in-loop simulation, which can be used to simulate the entire system in real-time. A simple dynamic model of Permanent Magnet Synchronous Motor is simulated with MATLAB/Simulink as well as on a TMS320F28069 digital signal processor from Texas Instruments Inc. Comparative study of simulation results of both the platforms, demonstrate that although MATLAB/Simulink provides excellent GUI and functionality, it fails to performs real-time simulation which can be accomplished with controller-in-simulation.},
  doi           = {10.1109/IECON.2016.7793156},
  keywords      = {digital signal processing chips;invertors;machine control;microcontrollers;permanent magnet motors;synchronous motors;GUI;MATLAB;Simulink;TMS320F28069 digital signal processor;controller-in-the-loop permanent magnet synchronous motor emulator;traction inverter performance testing;Digital signal processing;Frequency control;Integrated circuits;MATLAB;Mathematical model;Real-time systems;Stators;Control systems;electric machines;emulation;modeling;motor drives;power electronics},
}

@InProceedings{Subtirelu2016,
  author        = {G. E. Subtirelu and M. Dobriceanu and M. Linca},
  title         = {Virtual instrumentation for no-load testing of induction motor},
  booktitle     = {2016 IEEE International Power Electronics and Motion Control Conference (PEMC)},
  year          = {2016},
  pages         = {854-859},
  month         = {Sept},
  __markedentry = {[Jonnathan:6]},
  abstract      = {The main objective of this paper is to solve a practical and current problem, by taking advantage of the virtual instrumentation in testing electrical machines. The abilities of virtual instrumentation are used to data acquisition, measurement and analyze the values of no-load testing's parameters for three-phase induction motor. The virtual measurement system bench is designed and consist from two principal components: the hardware components (six LEM transducers for measuring three voltages and three currents; elements for signal conditioning and power transducers; USB multifunction Input / Output module; a personal computer) and the software components (operating system for the computer; drivers for the acquisition and manipulation of data; virtual instrument for calculation and graphical presentation of results). The LabVIEW graphical programming environment is used for designing virtual instrument. This virtual measurement system bench is an easy to use device which can be used in engineering education laboratories from universities or in electrical machines testing workbenches; it is capable of data acquisition, storage or memorization on different media, visualization of different graphs or analysis on-line or off-line of the results obtained. The virtual measurement system described in the paper can work independently (in the Simulation mode or Real time Acquisition mode) or integrated as part of a future complex virtual system for measurement and analysis in the domain of electrical machines testing workbenches.},
  doi           = {10.1109/EPEPEMC.2016.7752106},
  keywords      = {data acquisition;graph theory;induction motors;machine testing;virtual instrumentation;LEM transducers;LabVIEW graphical programming environment;USB multifunction input-output module;data acquisition;electrical machines testing;engineering education laboratories;no-load testing;personal computer;power transducers;signal conditioning;three-phase induction motor;virtual instrumentation;virtual measurement system;Artificial intelligence;Current measurement;Data acquisition;Induction motors;Instruments;Testing;Voltage measurement},
}

@InProceedings{Fan2013,
  author        = {Haojie Fan and Yongmin Mu},
  title         = {A performance testing and optimization tool for system developed by Python language},
  booktitle     = {International Conference on Cyberspace Technology (CCT 2013)},
  year          = {2013},
  pages         = {24-27},
  month         = {Nov},
  __markedentry = {[Jonnathan:6]},
  abstract      = {With a wide range of Python language in developing programs, More and more programmers choose to use the Python language for systems development, it gradually becomes scientific computing, web and games' Choice Awards. However, the performance of python is always a headache for developers. For reasonable selection of functions in base library, the usage of third-party plug-ins' functions and methods, and the design of custom functions, the problem whether they are the best choices for general developers is difficult to make a positive answer. After the system's performance bottleneck occurs, it is particularly important to determine where to tune and how to tune. Through the analysis and dynamic tracking of source code, with the built-in method in Python, we can get information about the system to be optimized, included: functions, grammatical structures, running time of each function, the relationship between function calls etc. This information provides an effective basis for further optimization of the system. Experimental results show that the system optimized by the tool has a significantly improvement.},
  doi           = {10.1049/cp.2013.2086},
  keywords      = {Performance testing;Python;System Optimization},
}

@InProceedings{Krickovic2015,
  author        = {J. Kričković and Đ. Miljković and M. Đukić},
  title         = {Automation testing of Bootloader for target DSP platform},
  booktitle     = {2015 23rd Telecommunications Forum Telfor (TELFOR)},
  year          = {2015},
  pages         = {1016-1019},
  month         = {Nov},
  __markedentry = {[Jonnathan:6]},
  abstract      = {In this paper is given the implementation of solutions for automated testing of Bootloader on the target DSP platform. Existing tools for manual testing do not meet the challenges of developing modern products, and its necessity for higher percentages of automation. The aim is to save time testing, reducing the occurrence of errors during testing due to human factors, and the ability that testing may execute a person who has no previous knowledge of a given field.},
  doi           = {10.1109/TELFOR.2015.7377638},
  keywords      = {digital signal processing chips;human factors;program testing;Bootloader;automation testing;human factor;software testing;target DSP platform;Automation;Digital signal processing;Electronic mail;Field programmable gate arrays;Hardware design languages;Linux;Testing;Bootloader;Python;TeraTerm;ispitivanje},
}

@InProceedings{Fang-ying2011,
  author        = {Y. Fang-ying},
  title         = {The credit risk macro stress testing of the Chinese banking system},
  booktitle     = {2011 Chinese Control and Decision Conference (CCDC)},
  year          = {2011},
  pages         = {1198-1203},
  month         = {May},
  __markedentry = {[Jonnathan:6]},
  abstract      = {In order to test the overall credit risk of loans of China's banking system, a macroeconomic credit risk model is designed, including a multiple linear regression model describing default probability, and a set of regression models describing macroeconomic environment. Studies show that bank loan default rates and key macroeconomic factors are related. Then stress tests are implemented one by one according to different shocks. The results showed that most banks continue to profit even at 90% confidence level when estimated risk of loss, reflecting a moderate credit risk in the banking system. However, if confidence level rises to 99% when estimated risk of loss, the banking system will face significant losses. The results show that it is necessary to prevent the credit risk of real estate loans and government debt.},
  doi           = {10.1109/CCDC.2011.5968369},
  issn          = {1948-9439},
  keywords      = {banking;credit transactions;macroeconomics;probability;profitability;regression analysis;risk management;Chinese banking system;bank loan;confidence level;credit risk macrostress testing;default probability;default rate;government debt;linear regression model;macroeconomic credit risk model;macroeconomic environment;profit;real estate loan;Banking;Economic indicators;Electric shock;Equations;Macroeconomics;Mathematical model;Stress},
}

@InProceedings{Xing2007,
  author        = {C. Xing and G. Zhang and M. Chen},
  title         = {Research on universal network performance testing model},
  booktitle     = {2007 International Symposium on Communications and Information Technologies},
  year          = {2007},
  pages         = {780-784},
  month         = {Oct},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Network performance testing is one of the key components in optimizing network resource configuration and improving network performance. Existing performance testing tools usually focus on single performance parameters, and lack of the ability to satisfy integrated testing demands of network administrators. In this paper, a universal network performance testing model based on policy scheduling is proposed, which integrates many kinds of performance testing tools into a single system, and provides a uniform testing interface to network administrators. Universal Probe (UP) is the key component of such a model, thus a detailed study is given on UP, which includes UP architecture, policy-based UP cooperation, mobility, and UP deployment under resource constraints. At last, a practical Network Monitor and Measurement System that designed based on the discussed concepts is presented.},
  doi           = {10.1109/ISCIT.2007.4392122},
  keywords      = {computer network management;computer network reliability;monitoring;optimisation;scheduling;network monitor-measurement system;network resource configuration optimization;policy scheduling;uniform testing interface;universal network performance testing model;universal probe;Information technology;Testing},
}

@InProceedings{Hadfield1990,
  author        = {J. A. Hadfield},
  title         = {Development of an economical, software-controlled battery load testing system},
  booktitle     = {12th International Conference on Telecommunications Energy},
  year          = {1990},
  pages         = {553-555},
  month         = {Oct},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Battery discharge capacity tests have traditionally been performed manually, although several mechanized systems are commercially available. A need was identified at the Manitoba Telephone System (MTS) to accurately and economically load test batteries in the field, to verify the capacity of new installations as well as to assist determining the true end-of-life of existing strings. The development of an economical, software-controlled system for testing -48 volt battery strings in the telephone environment is discussed.<>},
  doi           = {10.1109/INTLEC.1990.171303},
  keywords      = {automatic test equipment;battery testers;power supplies to apparatus;secondary cells;telephone equipment;-48 V;Canada;automatic testing;battery testers;development;discharge capacity;end-of-life;load testing;software;telephone equipment;Automatic testing;Batteries;Electronic equipment testing;Environmental economics;Prototypes;Software standards;Software testing;System testing;Telephony;Voltage},
}

@InProceedings{Meng2011,
  author        = {X. Meng},
  title         = {Designing approach analysis on small-scale software performance testing tools},
  booktitle     = {Proceedings of 2011 International Conference on Electronic Mechanical Engineering and Information Technology},
  year          = {2011},
  volume        = {8},
  pages         = {4254-4257},
  month         = {Aug},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Currently, most software performance testing tools in the market are large ones designated for enterprises. Aiming at the demand of small-sized and individual customers' conduction of software performance testing, the paper proposes an approach for designing and realizing a small tool for testing. Core design refers to simulating multi-user concurrent operation by simultaneous execution of multithreading and measuring performance of the system tested through whether each threading responses in a correct manner as well as testing data such as period of responding. Testing tool, which is realized by Java language, consists of three modules of case management, test implementation and test report. Multiple designing modes are utilized in a combined manner during designing, which makes the designing scheme a simple one with high efficiency and easy to expand. The market of performance testing is developing in a rapid manner and researching software performance test is gaining increasingly significance.},
  doi           = {10.1109/EMEIT.2011.6023983},
  keywords      = {Java;automatic test software;concurrency control;multi-threading;program testing;software performance evaluation;software tools;Java language;case management;multithreading;multiuser concurrent operation;small-scale software performance testing tool design;test implementation;test report;Databases;Educational institutions;Instruction sets;Presses;Servers;Software performance;Testing;designing approach;designing mode;small-scaled testing tool;software performance test},
}

@Article{Suryanarayana1997,
  author        = {T. Suryanarayana and J. L. Bhattacharya and K. S. N. Raju and K. A. Durga Prasad},
  title         = {Development and performance testing of a 200 kVA damperless superconducting generator},
  journal       = {IEEE Transactions on Energy Conversion},
  year          = {1997},
  volume        = {12},
  number        = {4},
  pages         = {330-336},
  month         = {Dec},
  issn          = {0885-8969},
  __markedentry = {[Jonnathan:6]},
  abstract      = {A 200 kVA, 3000 RPM superconducting generator has been developed and tested. The rotor has been wound with superconducting wire of Nb-Ti alloy. A closed-circuit liquid helium system has been designed and installed for cooling the superconducting windings. The stator carries the air-gap type armature windings and a laminated-iron flux-shield. A new concept in the design of superconducting generators with high short-circuit ratio (more than 5) has been introduced. This eliminates the requirement of an electromagnetic damper and quick response excitation system. The generator has been comprehensively tested in the superconducting state. Open-circuit and sustained short-circuit tests, three-phase sudden short-circuit tests, synchronization with the grid and parallel operation with power systems have been conducted. The synchronous machine was operated up to its rated kVA in the four quadrants-as a generator and as a condenser with leading and lagging power factors. A few special tests on superconducting generators, which were not reported earlier, such as direct-online starting of a 20 hp squirrel-cage induction motor and negative phase sequence tests have also been performed successfully. Test results and conclusions are given},
  doi           = {10.1109/60.638869},
  keywords      = {electric generators;machine testing;rotors;stators;superconducting machines;superconducting magnets;20 hp;200 kVA;NbTi;air-gap type armature windings;closed-circuit liquid helium system;damperless superconducting generator;laminated-iron flux-shield;open-circuit tests;performance testing;short-circuit ratio;short-circuit tests;stator;superconducting windings cooling;superconducting wire rotor;Air gaps;Cooling;Helium;Induction generators;Rotors;Stators;Superconducting filaments and wires;Superconducting transmission lines;System testing;Wounds},
}

@InProceedings{Gao2013,
  author        = {Q. Gao and W. Wang and G. Wu and X. Li and J. Wei and H. Zhong},
  title         = {Migrating Load Testing to the Cloud: A Case Study},
  booktitle     = {2013 IEEE Seventh International Symposium on Service-Oriented System Engineering},
  year          = {2013},
  pages         = {429-434},
  month         = {March},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Cloud computing has emerged as a new paradigm for the delivery of computing resources. It brings great opportunities to software testing, especially to load testing. In this paper, we focus on migrating conventional load testing tools to the cloud, for which the two significant issues are about multi-tenancy and load simulating resource management. We propose a four layer model for cloud-based load testing, along with the approach of test request admission control and scheduling to solve these issues. We carried out a concrete case study on our proposed approach and made the efficiency of cloud-based load testing shown successfully by two contrast experiments.},
  doi           = {10.1109/SOSE.2013.59},
  keywords      = {cloud computing;program testing;resource allocation;scheduling;cloud computing;cloud-based load testing;computing resource delivery;four layer model;load simulating resource management;load testing migration;multitenancy;scheduling;software testing;test request admission control;Admission control;Databases;Load modeling;Monitoring;Resource management;Software;Testing;cloud computing;load testing;migrating},
}

@InProceedings{Pan2007,
  author        = {L. Pan and L. M. Batten},
  title         = {A Lower Bound on Effective Performance Testing for Digital Forensic Tools},
  booktitle     = {Systematic Approaches to Digital Forensic Engineering, 2007. SADFE 2007. Second International Workshop on},
  year          = {2007},
  pages         = {117-130},
  month         = {April},
  __markedentry = {[Jonnathan:6]},
  abstract      = {The increasing complexity and number of digital forensic tasks required in criminal investigations demand the development of an effective and efficient testing methodology, enabling tools of similar functionalities to be compared based on their performance. Assuming that the tool tester is familiar with the underlying testing platform and has the ability to use the tools correctly, we provide a numerical solution for the lower bound on the number of testing cases needed to determine comparative capabilities of any set of digital forensic tools. We also present a case study on the performance testing of password cracking tools, which allows us to confirm that the lower bound on the number of testing runs needed is closely related to the row size of certain orthogonal arrays. We show how to reduce the number of test runs by using knowledge of the underlying system},
  doi           = {10.1109/SADFE.2007.2},
  keywords      = {computer crime;digital forensic tools;password cracking tools;performance testing;Blindness;Digital forensics;High performance computing;Home computing;Information technology;Kernel;Linux;Software performance;Software testing;System testing;Abstraction Layer Model;Orthogonal Arrays;Partition Testing;SADFE;Software Performance.},
}

@InProceedings{Finnigan2013,
  author        = {J. Finnigan},
  title         = {Radiation Belt Storm Probes (RBSP) Flight Software stress testing: Case study and lessons learned},
  booktitle     = {2013 IEEE Aerospace Conference},
  year          = {2013},
  pages         = {1-12},
  month         = {March},
  __markedentry = {[Jonnathan:6]},
  abstract      = {This paper presents a case study of the Radiation Belt Storm Probes (RBSP) mission Command and Data Handling (C&DH) Flight Software stress testing program. Background information on the motivation for stress testing embedded software, and the general principles and goals of a stress test are provided as an introduction. Details of the stress test program that was implemented for the RBSP C&DH Flight Software are presented and discussed. This discussion includes the design and development of a test framework that was implemented to incrementally build the test scenarios, increase the productivity of the RBSP stress test team, and facilitate reuse for regression testing. Results of the RBSP stress test program are summarized, and lessons learned that may be useful for future embedded software test programs are documented.},
  doi           = {10.1109/AERO.2013.6496814},
  issn          = {1095-323X},
  keywords      = {aerospace computing;aerospace testing;embedded systems;probes;program testing;radiation belts;regression analysis;software reusability;team working;C&DH flight software stress testing program;RBSP flight software stress testing;RBSP stress test team productivity;command and data handling flight software stress testing program;embedded software test programs;radiation belt storm probes;regression testing reusability;test framework design;test framework development;Computer architecture;Loading;Planning;Software;Space vehicles;Stress;Testing},
}

@InProceedings{Wang2009,
  author        = {G. Wang and S. Jiao and H. Song},
  title         = {Mine Pump Comprehensive Performance Testing System Based on Labview},
  booktitle     = {2009 International Conference on Measuring Technology and Mechatronics Automation},
  year          = {2009},
  volume        = {1},
  pages         = {300-303},
  month         = {April},
  __markedentry = {[Jonnathan:6]},
  abstract      = {The pump is one of the key equipments for the safety production of coal mine. It bears the important task to discharge all the underground water. However, the performance efficiency of the water pump will be declined, in the long run. Therefore, in order to ensure the safety production, users should check and test the pump performance regularly ,to test if every target pump has live up to the ldquoCoal Mine Safety Regulationsrdquo. The ultimate goal in finding the fault in time, eliminating hidden dangers, reducing accidents,and saving maintenance costs can be attained. Virtual instrument is the production of modern computer and instrument technology combined in-depth, and is an important technology of computer-assisted testing area. The core idea is "software replacing hardware". The paper introduces the virtual instrument technology into the field of pump performance testing, and designs the mine pump comprehensive performance testing system based on Labview. The system takes software development environment-LabVIEW as platform and based on personal computer, and realizes the function that pumppsilas import and export of water pressure, flow, speed, power, and other signals measured in real-time and dynamic displayed. It uses the polynomial fitting module of LabVIEW to fit the performance curve,and shows the performance curve by the waveform display. At the same time,it uses the Web Publishing Tool of LabVIEW to release the testing interface to the internet,and realizes its network communication function. Compared with traditional instruments,the pump performance testing system which based on Virtual instrument run stably, have strongly data analytical and processing functions, beautiful interface, easy operation, strongly visual function, highly testing precision.},
  doi           = {10.1109/ICMTMA.2009.179},
  issn          = {2157-1473},
  keywords      = {mining;mining equipment;polynomial approximation;pumps;safety;virtual instrumentation;LabVIEW;coal mine safety production;coal mine safety regulations;computer-assisted testing;mine pump comprehensive performance testing system;network communication function;polynomial fitting module;virtual instrument technology;Costs;Hardware;Instruments;Microcomputers;Paper technology;Product safety;Production;Programming;Safety devices;System testing;labview;pump;testing system},
}

@InProceedings{Zhang2016a,
  author        = {Y. Zhang and D. Meisner and J. Mars and L. Tang},
  title         = {Treadmill: Attributing the Source of Tail Latency through Precise Load Testing and Statistical Inference},
  booktitle     = {2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)},
  year          = {2016},
  pages         = {456-468},
  month         = {June},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Managing tail latency of requests has become one of the primary challenges for large-scale Internet services. Data centers are quickly evolving and service operators frequently desire to make changes to the deployed software and production hardware configurations. Such changes demand a confident understanding of the impact on one's service, in particular its effect on tail latency (e.g., 95th-or 99th-percentile response latency of the service). Evaluating the impact on the tail is challenging because of its inherent variability. Existing tools and methodologies for measuring these effects suffer from a number of deficiencies including poor load tester design, statistically inaccurate aggregation, and improper attribution of effects. As shown in the paper, these pitfalls can often result in misleading conclusions. In this paper, we develop a methodology for statistically rigorous performance evaluation and performance factor attribution for server workloads. First, we find that careful design of the server load tester can ensure high quality performance evaluation, and empirically demonstrate the inaccuracy of load testers in previous work. Learning from the design flaws in prior work, we design and develop a modular load tester platform, Treadmill, that overcomes pitfalls of existing tools. Next, utilizing Treadmill, we construct measurement and analysis procedures that can properly attribute performance factors. We rely on statistically-sound performance evaluation and quantile regression, extending it to accommodate the idiosyncrasies of server systems. Finally, we use our augmented methodology to evaluate the impact of common server hardware features with Facebook production workloads on production hardware. We decompose the effects of these features on request tail latency and demonstrate that our evaluation methodology provides superior results, particularly in capturing complicated and counter-intuitive performance behaviors. By tuning the hardware features - s suggested by the attribution, we reduce the 99th-percentile latency by 43% and its variance by 93%.},
  doi           = {10.1109/ISCA.2016.47},
  issn          = {1063-6897},
  keywords      = {Internet;computer centres;computer network performance evaluation;regression analysis;Facebook production workloads;Treadmill;counter-intuitive performance behaviors;data centers;large-scale Internet services;modular load tester platform;performance evaluation;performance factor attribution;precise load testing;production hardware configurations;quantile regression;request tail latency management;server hardware features;server load tester;server systems;server workloads;service operators;software hardware configurations;statistical inference;statistically-sound performance evaluation;Hardware;Histograms;Production;Servers;Testing;Web and internet services;data center;load testing;tail latency},
}

@InProceedings{Zhou2016,
  author        = {C. Zhou and D. Du and Z. Cao and Y. Wang and X. Yang},
  title         = {Assets overlapping networks and stress testing on stability of financial systems},
  booktitle     = {2016 35th Chinese Control Conference (CCC)},
  year          = {2016},
  pages         = {10385-10389},
  month         = {July},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Financial networks, creating potential propagation channels for shocks in crises, are widely viewed as a key factor to systemic stability. In this paper, we develop a dynamic model of deleveraging in an overlapping network of assets. We study the deleveraging spirals driven by the interaction between fire sales and confidence effects, and show how distress is amplified and propagated throughout the network. Using the regulatory data from the Peoples Bank of China (PBC), we construct the assets overlapping network and then apply the model to the system. The result suggests that: (1) the mutually reinforcing effects of fire sales and confidence can contribute to contagion significantly; (2) The vulnerability of the system are largely dependant on the distribution of large illiquid assets. Our model provides a ready-to-use yet powerful stress testing tool for macro-prudential regulation.},
  doi           = {10.1109/ChiCC.2016.7555000},
  keywords      = {asset management;finance;PBC;Peoples Bank of China;assets overlapping networks;confidence effects;deleveraging dynamic model;deleveraging spirals;financial systems stability;fire sales;illiquid assets;macroprudential regulation;stress testing;Electric shock;Heuristic algorithms;Investment;Portfolios;Stability analysis;Stress;Testing;Confidence Effects;Deleveraging;Financial Networks;Stress Testing;Systemic Risk},
}

@InProceedings{Iversen2009,
  author        = {P. O. Iversen and K. Rutkowski and S. Issartel and L. Foged and A. Scannavini},
  title         = {Radiated performance testing of diversity and MIMO enabled terminals},
  booktitle     = {2009 3rd European Conference on Antennas and Propagation},
  year          = {2009},
  pages         = {1069-1071},
  month         = {March},
  __markedentry = {[Jonnathan:6]},
  abstract      = {This paper discuss general methods available for test and design engineers for testing radiated performances of multi-antenna enabled terminals in a controlled environment such as anechoic chambers. Methods for testing SIMO (Single-input Multi-Output), and MIMO (Multi-Input Multi-Output) performances in both passive and active way are highlighted. Information such as user defined propagation channel characteristic can be taking into account in passive measurements and is currently being investigated for the active testing.},
  issn          = {2164-3342},
  keywords      = {MIMO communication;antenna arrays;antenna radiation patterns;diversity reception;wireless channels;MIMO enabled terminals;diversity testing;multiantenna enabled terminals;passive measurements;propagation channel characteristics;radiated performance testing;Anechoic chambers;Antenna arrays;Antenna radiation patterns;Antennas and propagation;Current measurement;Design engineering;MIMO;Performance evaluation;Polarization;System testing},
}

@InProceedings{Nieminen2009,
  author        = {M. Nieminen and T. Raty and J. Palokangas},
  title         = {Stress Testing the Logical Decision Making Server of a Surveillance System},
  booktitle     = {2009 First International Conference on Advances in System Testing and Validation Lifecycle},
  year          = {2009},
  pages         = {98-103},
  month         = {Sept},
  __markedentry = {[Jonnathan:6]},
  abstract      = {The current generation of distributed and automated physical location surveillance systems faces high demands for robustness and reliability. We present and evaluate the design of the Logical Decision Making Server (LDMS), a rule-based automated decision making component used in the Single Location Surveillance Point (SLSP) system. To validate the robustness of the LDMS design for operation in the SLSP environment, we design and conduct a stress test experiment in which large load of TCP/IP input messages is sent instantaneously to the LDMS prototype implementation using the Nethawk EAST software. The stress test results are compared to measurements obtained during a real-life scenario. The LDMS is observed to withstand a significant amount of load without crashing, and its performance is can be considered sufficient for the SLSP system needs. A detailed analysis of results however shows an increase in the latency resulting from an extreme temporal load. We identify potential areas in the design to be improved if demands for higher response rates arise. The research is based on the construction of the related publications and technologies, and the results are established from the testing and validation of the implemented LDMS within the SLSP system.},
  doi           = {10.1109/VALID.2009.16},
  keywords      = {decision support systems;digital simulation;logic design;network servers;performance evaluation;transport protocols;video surveillance;Nethawk EAST software;TCP/IP input messages;automated decision making;environment for automated systems testing;logical decision making server;rule-based component;stress testing;surveillance system;Decision making;Logic testing;Robustness;Software prototyping;Software testing;Stress;Surveillance;System testing;TCPIP;Vehicle crash testing;decision making;stress testing;surveillance},
}

@InProceedings{Liu2006,
  author        = {L. Liu and J. Lin and Z. Li and J. Li},
  title         = {State Machine Based CDMA Stress Testing Service System},
  booktitle     = {2006 IEEE Asia-Pacific Conference on Services Computing (APSCC'06)},
  year          = {2006},
  pages         = {625-628},
  month         = {Dec},
  __markedentry = {[Jonnathan:6]},
  abstract      = {This paper introduces a system model of CDMA stress testing service platform based on state machine technology. This system provides an efficient service oriented solution on protocol and stress testing of CDMA system, with high performance and automatic capability. The concurrent multitask mechanism and the state machine framework enable the high performance and automatic capability of this system. And the scalable distributed architecture offers the maximum flexibility of deployment},
  doi           = {10.1109/APSCC.2006.93},
  keywords      = {code division multiple access;computer architecture;finite state machines;protocols;stress analysis;CDMA stress testing service system;concurrent multitask mechanism;protocol;scalable distributed architecture;state machine;Communication system control;Computer architecture;Electronic equipment testing;Hardware;Mobile communication;Multiaccess communication;Protocols;Software testing;Stress;System testing;Service;State Machine;Stress Testing},
}

@InProceedings{Chan2004,
  author        = {H. A. Chan},
  title         = {Accelerated stress testing for both hardware and software},
  booktitle     = {Annual Symposium Reliability and Maintainability, 2004 - RAMS},
  year          = {2004},
  pages         = {346-351},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Accelerated stress testing (AST) has been used in electronic, electromechanical, and mechanical systems to achieve robustness with high reliability primarily for hardware. For software products, the reliability program is often conducted separate from any hardware accelerated stress testing. Yet, many systems are consist of concurrent software and hardware issues. In addition, the stress testing processes were primarily adopted by those responsible to develop and manufacture hardware. For example, the stresses usually include temperature extremes, thermal cycles, vibrations, etc. These stresses are effective in accelerating latent hardware defects from degradable, marginal, or intermittent failures to hard failures so that root cause analyses and corrective actions may be made. Although experiments had indicated that software faults and hardware defects are related, the available formulation of the fundamental principles was still based on hardware systems. AST for software and for operating systems have been discussed in [M. Werner, et al., "Improving Customer Satisfaction via Accelerated Stress Testing of General Purpose Computer Operating Systems"] and [M. Werner, et al., 2002], but a fundamental understanding of AST for software is lacking. In order to generalize the fundamentals of accelerated stress testing to address both software and hardware, we need to define accelerated stress testing for software and to address whether they are needed, i.e., whether there are effective methods to achieve high software reliability. The basic reliability concepts categorize systems into different categories according to the presence of defects and faults and whether these weaknesses are explicit enough. The concepts for both hardware and software reliability separate the notion of defects and faults from failures. It further conceptually separates the notion of stressing and the notion of detection. The fundamental concept is that all failures except the explicit ones must be manifested under certain stress conditions. There is then a threshold stress level beyond which a system fails. The cumulative effect of stresses is included by defining time as one type of stress. Both hardware and software systems have marginal weakness, and degradable weakness. The process o- f recovery and repair are also examined for both hardware and software events. The basic reliability principles in accelerated stress testing for both software and hardware systems are combined and explained in this paper. While [M. Werner, et al., "Improving Customer Satisfaction via Accelerated Stress Testing of General Purpose Computer Operating Systems"] and [M. Werner, et al., 2002] also address the needs and advantages of AST for software, an effective software AST program requires efficient tools yet to be developed. The benefits should justify the needed further research and development in this area.},
  doi           = {10.1109/RAMS.2004.1285473},
  keywords      = {conformance testing;life testing;software reliability;stress analysis;accelerated stress testing;corrective actions;hardware defects;hardware reliability;reliability program;root cause analysis;software faults;software reliability;Customer satisfaction;Hardware;Life estimation;Operating systems;Software reliability;Software systems;Software testing;Software tools;System testing;Thermal stresses},
}

@InProceedings{Singer1989,
  author        = {P. A. Singer},
  title         = {Trends in VLF/LF modem performance testing},
  booktitle     = {Military Communications Conference, 1989. MILCOM '89. Conference Record. Bridging the Gap. Interoperability, Survivability, Security., 1989 IEEE},
  year          = {1989},
  pages         = {581-584 vol.2},
  month         = {Oct},
  __markedentry = {[Jonnathan:6]},
  abstract      = {The author reviews the historical development of digital VLF/LF modem testing. He discusses the introduction of test equipment in the following four major functional areas: (a) transmit simulation, (b) channel simulation, (c) noise and interference generation, and (d) reception characterization. He demonstrates two major trends: (1) the use of general-purpose hardware and off-line software replacing special-purpose hardware; (2) Gaussian noise, atmospheric laboratory test environments being replaced by tailored simulated electromagnetic interference and atmospheric noise},
  doi           = {10.1109/MILCOM.1989.103992},
  keywords      = {automatic test equipment;digital simulation;electronic equipment testing;modems;performance evaluation;Gaussian noise;LF;VLF;atmospheric laboratory test environments;atmospheric noise;channel simulation;digital modem;electromagnetic interference;general-purpose hardware;interference generation;modem performance testing;noise generation;off-line software;reception characterization;test equipment;transmit simulation;Atmospheric modeling;Electromagnetic interference;Gaussian noise;Hardware;Low-frequency noise;Modems;Noise generators;Test equipment;Testing;Working environment noise},
}

@InProceedings{Chapuis2017,
  author        = {B. Chapuis and B. Garbinato},
  title         = {Scaling and Load Testing Location-Based Publish and Subscribe},
  booktitle     = {2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)},
  year          = {2017},
  pages         = {2543-2546},
  month         = {June},
  __markedentry = {[Jonnathan:6]},
  abstract      = {The rise of the Internet of things (IoT) poses massive scalability issues for location-based services. More particularly, location-aware publish and subscribe services are struggling to scale out the computation of matches between publications and subscriptions that continuously update their location. In this demonstration paper, we propose a novel distributed and horizontally scalable architecture for location-aware publish and subscribe. Our middleware architecture relies on a multi-step routing mechanism based on consistent hashing and range partitioning. To demonstrate its scalability, we present a traffic data generator, which, in contrast to existing generators, can be used to perform real-time load tests. Finally, we show that our architecture can be deployed on a small 10-node cluster and can process up to 80,000 location updates per second producing 25,000 matches per seconds.},
  doi           = {10.1109/ICDCS.2017.234},
  issn          = {1063-6927},
  keywords      = {Internet of Things;message passing;middleware;Internet of Things;location-aware publish and subscribe services;location-based services;middleware architecture;multi-step routing mechanism;traffic data generator;Computer architecture;Generators;Middleware;Real-time systems;Roads;Routing;Scalability},
}

@InProceedings{Wu2012,
  author        = {J. Wu},
  title         = {Stress testing software to determine fault tolerance for hardware failure and anomalies},
  booktitle     = {2012 IEEE AUTOTESTCON Proceedings},
  year          = {2012},
  pages         = {294-298},
  month         = {Sept},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Today's military systems rely for their performance on combinations of hardware and software. While testing of hardware performance during design, development and operation is well understood, the testing of software is less mature. In particular, the effect of hardware failures in the field on software performance, and therefore systems performance, is all-too-often overlooked or is tested in a far less rigorous manner that that applied to Hardware failures alone. Numerous examples exist of major system failures driven by software anomalies but triggered by Hardware failures, with consequences that range from degraded mission performance to weapons system destruction and operator fatalities. Measuring software development quality and fault tolerance is a challenging task. Many software test methods focus on source-code only approach (unit tests, modular test) and neglect the impacts caused by hardware anomalies or failures. Such missing test coverage can and will result in potential degraded software performance quality, thereby adding to project cost and delaying schedule. It can also result in far more disastrous consequences for the warfighters. This paper will discuss the general nature of the hardware-failure-software anomaly - system failure flow-down. It will then describe techniques that exist for system software testing and will highlight extensions of these techniques to focus on an effective and comprehensive software testing that includes performance prediction and hardware failure fault tolerance. The end result is a suite of test methods that, when properly applied, offer a systematic and comprehensive analysis of prime software behaviors under a range of hardware field failure conditions.},
  doi           = {10.1109/AUTEST.2012.6334582},
  issn          = {1088-7725},
  keywords      = {fault tolerant computing;military computing;missiles;program testing;software metrics;software performance evaluation;software quality;delaying schedule;fault tolerance measurement;hardware anomalies;hardware failure fault tolerance;hardware field failure conditions;hardware performance testing;missing test coverage;mission performance degradation;operator fatalities;performance prediction;project cost;software anomalies;software behavior comprehensive analysis;software development quality measurement;software performance;software testing;source code;stress testing software;system failure flow-down;warfighters;weapon system destruction;Embedded systems;Fault detection;Hardware;Monitoring;Real-time systems;Voltage control},
}

@InProceedings{Zhang2011,
  author        = {Li Zhang and Yinghui Chen and Fan Tang and Xiong Ao},
  title         = {Design and implementation of cloud-based performance testing system for web services},
  booktitle     = {2011 6th International ICST Conference on Communications and Networking in China (CHINACOM)},
  year          = {2011},
  pages         = {875-880},
  month         = {Aug},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Nowadays testing plays an important role in software development process. While software testing is expensive and time-consuming, sufficient testing is hard, especially for a distributed system using web services technique in the real circumstance. The development of cloud computing provides us new ideas to solve these testing problems. To address these issues, we propose a framework which integrates cloud computing and performance testing technologies. In this paper, first we present the architecture of the cloud-based performance testing system for web services (CPTS), which is a portable, extensible and easy-to-use framework for generating and submitting test workloads to computing clouds. Then, we show the process how to use CPTS to run a performance test and present the concept of dynamic migration in CPTS. Finally, we present our experiences with CPTS in Amazon EC2. We found that the CPTS allows a user to easily set up and test a web services system on the cloud and improve test effectively.},
  doi           = {10.1109/ChinaCom.2011.6158278},
  keywords      = {Web services;cloud computing;program testing;software performance evaluation;Amazon EC2;CPTS;Web services;cloud computing;cloud-based performance testing system;distributed system;dynamic migration;software development process;software testing;Cloud computing;Dispatching;Dynamic scheduling;Monitoring;Servers;Testing;cloud computing;dynamic migration;performance testing;virtual machine;web services},
}

@InProceedings{Zhizhong2011,
  author        = {L. Zhizhong and W. Sen and X. Jun and N. Bo and J. Hongliang and X. Hua},
  title         = {Performance testing and comprehensive evaluation on large grounding connection},
  booktitle     = {2011 7th Asia-Pacific International Conference on Lightning},
  year          = {2011},
  pages         = {983-989},
  month         = {Nov},
  __markedentry = {[Jonnathan:6]},
  abstract      = {To comprehensively evaluate the safety of large grounding connection, testing and action principle of the main factors that impact the safe operation of grounding connection, were analyzed and studied, and the following conclusions were drew by theoretical analysis and simulation research. While evaluating step voltage and touch voltage, it's inadvisable to consider seasonal factors during the selection of soil resistivity; the testing direction of step voltage and touch voltage should be selected based on simulation computation for getting reliable data; eligibility criterion on electric integrity of grounding connection should not be 200mΩ but appropriately lowered; corrosion evaluation of grounding connection can be get rudely by analogized ways, which need the adding appropriate monitoring point in the corner of the grounding grid. Finally, the grading criterion and reference methods of weight value for the testing results of safe operation factors of grounding connection is proposed for establishing a quantified evaluation system of grading grounding connection, detailing the state evaluation system of large grounding connection.},
  doi           = {10.1109/APL.2011.6111055},
  keywords      = {earthing;power grids;grounding connection;grounding grid;soil resistivity;step voltage;touch voltage;Corrosion;Electric potential;Grounding;Immune system;Resistance;Testing;Thermal stability;Grounding connection;comprehensive evaluation;grading criterion;grounding grid;integrity of grounding connection;quantified evaluation},
}

@Article{Kyle1965,
  author        = {H. C. Kyle},
  title         = {Compatibility and Performance Testing of Communications Systems},
  journal       = {IEEE Transactions on Aerospace},
  year          = {1965},
  volume        = {AS-3},
  number        = {2},
  pages         = {139-143},
  month         = {June},
  issn          = {0536-1516},
  __markedentry = {[Jonnathan:6]},
  abstract      = {During the normal progress of design, fabrication, and integration of communications subsystems for spacecraft and for ground installations, every effort is made to assure that the equipment meets certain specifications relating to performance, environment, reliability, and interface capability. These specifications are based on the best available definition of requirements and interface characteristics of complementing subsystems. Frequently, in the field of manned spaceflight, the spacecraft subsystems, the launch vehicle subsystems, and the ground systems must be designed and constructed concurrently. This means that the operating and interface characteristics of one subsystem are not available for use by the engineers in the design of the other subsystems. Close technical liaison among the various engineering groups is essential in the accomplishment of overall systems' integrity. Component and subsystem testing has been developed to a high degree, but the results of these are necessarily limited. They cannot validate the overall systems' performance and compatibility. It is considered mandatory that the interfacing subsystems be mated to form a complete system in a controlled test environment as early as practicable in any program, especially in one involving communications systems as new and as complex as those for Apollo. This must be accomplished at such a phase in the program that corrective engineering details can be fed back to the cognizant design, fabrication, or integration groups involved in time for necessary modifications prior to the beginning of the flight phase.},
  doi           = {10.1109/TA.1965.4319794},
  keywords      = {Aerospace engineering;Automotive engineering;Communication system control;Control systems;Design engineering;Fabrication;Land vehicles;Road vehicles;Space vehicles;System testing},
}

@InProceedings{Wunderle2016,
  author        = {B. Wunderle and T. Onken and J. Heilmann and D. Silbernagl and J. Arnold and T. Bieniek and R. Pufall},
  title         = {Reliability of sputtered thin aluminium films under accelerated stress testing by vibration loading and modeling},
  booktitle     = {2016 6th Electronic System-Integration Technology Conference (ESTC)},
  year          = {2016},
  pages         = {1-14},
  month         = {Sept},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Aluminium is still one of the most important contact metallisations for power electronic chips like MOSFETs or IGBTs. With a large difference in thermal expansion coefficients (CTEs) between aluminium and silicon and the temperatures generated in hot-spots during high power transients, these layers are prone to failure due to thermo-mechanical fatigue. Usually lifetime assessment is done by subjecting dedicated test specimens to standardised stress tests as e.g. active or passive thermal cycling. This paper proposes a novel method for accelerated stress testing and lifetime modelling of thin aluminium films in the high-cycle fatigue regime by isothermal mechanical loading. The proposed novel test method is suggested to complement or replace resource-demanding thermal cycling tests and allow simple in-situ monitoring of failure.},
  doi           = {10.1109/ESTC.2016.7764458},
  keywords      = {semiconductor device reliability;thermal expansion;vibrations;CTE;IGBT;MOSFET;accelerated stress testing;active thermal cycling;high power transients;high-cycle fatigue regime;hot-spots;isothermal mechanical loading;lifetime modelling;passive thermal cycling;power electronic chips;sputtered thin aluminium films reliability;thermal expansion coefficients;thermomechanical fatigue;thin aluminium films;vibration loading;vibration modeling;Aluminum;Fatigue;Life estimation;Silicon;Stress;Testing},
}

@InProceedings{Querbach2013,
  author        = {B. Querbach and S. Puligundla and D. Becerra and Z. T. Schoenborn and P. Chiang},
  title         = {Comparison of hardware based and software based stress testing of memory IO interface},
  booktitle     = {2013 IEEE 56th International Midwest Symposium on Circuits and Systems (MWSCAS)},
  year          = {2013},
  pages         = {637-640},
  month         = {Aug},
  __markedentry = {[Jonnathan:6]},
  abstract      = {In post-silicon testing and validation of circuit functionality, an effective IO stress pattern can identify bugs quickly and provide adequate test coverage. A lot of work has been done to identify the right stress patterns specific to each IO interface. While some patterns can be generic enough to apply to all IOs, other patterns are interface topology specific. In addition to identifying the worst-case pattern, tradeoffs between test-time and test coverage must be made depending on the test goals. Pseudo Random Bit Stream (PRBS) generators are commonly used to generate test patterns because of the adequate frequency content in the PRBS patterns, the ease of implementation, and minimal gate count. This paper introduces an Advanced Pattern Generator and Checker (APGC) based on PRBS that retains all the aforementioned advantages. The APGC was implemented for a DDR memory interface where different LFSRs beat against each other spatially on neighboring IO lanes while rotating this form of aggressor-victim pattern in time. The results of the APGC stress patterns are compared to a form of advanced software-based learning algorithm based patterns that exhaustively search this complete parameter space. The comparison of APGC to software showed that the measured bit error rate (BER) plotted on a Q-scale of both methods is similar for the Receiver side. On the Transmitter side, APGC showed less eye opening than the software. In addition to the margin comparison, on the test execution side, APGC can speed up the test and validation execution time compared to the software by 32 to 2048 times depending on aggressor victim lane width of 8 to 64 lanes.},
  doi           = {10.1109/MWSCAS.2013.6674729},
  issn          = {1548-3746},
  keywords      = {automatic test pattern generation;electronic engineering computing;error statistics;integrated circuit testing;learning (artificial intelligence);peripheral interfaces;random number generation;semiconductor storage;APGC stress pattern;BER;DDR memory interface;IO stress pattern;LFSR;PRBS generators;Q-scale;advanced pattern generator and checker;aggressor-victim pattern;bit error rate;bug identification;circuit functionality validation;gate count;hardware based stress testing;interface topology;memory IO interface;post-silicon testing;pseudorandom bit stream generators;software based stress testing;software-based learning algorithm;test coverage;test execution;test pattern generation;test time;worst-case pattern},
}

@InProceedings{Mingqiu2011,
  author        = {Ren Mingqiu and Cai Jinyan and Zhu Yuanqing and Han Zhuangzhi},
  title         = {Design of radar ECCM performance testing system and its semi-physical simulation experiment},
  booktitle     = {Proceedings of 2011 IEEE CIE International Conference on Radar},
  year          = {2011},
  volume        = {2},
  pages         = {1058-1062},
  month         = {Oct},
  __markedentry = {[Jonnathan:6]},
  abstract      = {This paper describes the theory, design, implementation, simulation and testing of a radar ECCM performance testing system capable of generating target echo, clutter and jamming signal for radar ECM/ECCM experiment. With the help of the proposed testing system, the jamming styles and parameters can be smartly intercalated with a variety of simulation scenarios. The rubs are resolved such as radar states data acquisition, echo real time simulation and display & control terminals setup of signal environment. Then a radar ECM semi-physical simulation experiment is applied to measure six typical ECCM performance indexes in the signal environment generated by the testing system. Experiment and data processing results show the testing platform is valid and practical. The testing system can be used to solve problems such as radar ECCM performance evaluation, radar advanced design and ECCM strategies when the equipment is relatively small in tracking and guidance phase.},
  doi           = {10.1109/CIE-Radar.2011.6159734},
  issn          = {1097-5764},
  keywords      = {electronic countermeasures;jamming;radar clutter;radar tracking;target tracking;testing;data processing;echo real time simulation;guidance phase;jamming signal;radar ECCM performance testing system;radar clutter;radar states data acquisition;semiphysical simulation experiment;target echo;tracking phase;Electronic countermeasures;Jamming;Radar antennas;Radar tracking;Target tracking;Testing;Radar ECCM;active jamming;evaluation index;semi-physical simulation experiment;testing system},
}

@InProceedings{Kim2012b,
  author        = {Y. Kim and L. K. John and S. Pant and S. Manne and M. Schulte and W. L. Bircher and M. S. S. Govindan},
  title         = {AUDIT: Stress Testing the Automatic Way},
  booktitle     = {2012 45th Annual IEEE/ACM International Symposium on Microarchitecture},
  year          = {2012},
  pages         = {212-223},
  month         = {Dec},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Sudden variations in current (large di/dt) can lead to significant power supply voltage droops and timing errors in modern microprocessors. Several papers discuss the complexity involved with developing test programs, also known as stress marks, to stress the system. Authors of these papers produced tools and methodologies to generate stress marks automatically using techniques such as integer linear programming or genetic algorithms. However, nearly all of the previous work took place in the context of single-core systems, and results were collected and analyzed using cycle-level simulators. In this paper, we measure and analyze di/dt issues on state-of-the-art multi-core x86 systems using real hardware rather than simulators. We build on an existing single-core stress mark generation tool to develop an Automated DI/dT stress mark generation framework, referred to as AUDIT, to generate di/dt stress marks quickly and effectively for multicore systems. We showcase AUDIT's capabilities to adjust to micro architectural and architectural changes. We also present a dithering algorithm to address thread alignment issues on multi-core processors. We compare standard benchmarks, existing di/dt stress marks, and AUDIT-generated stress marks executing on multi-threaded, multi-core systems with complex out-of-order pipelines. Finally, we show how stress analysis using simulators may lead to flawed insights about di/dt issues.},
  doi           = {10.1109/MICRO.2012.28},
  issn          = {1072-4451},
  keywords      = {integrated circuit testing;microprocessor chips;multiprocessing systems;stress analysis;AUDIT capabilities;AUDIT-generated stress marks;automated DI-dT stress mark generation framework;cycle-level simulators;dithering algorithm;genetic algorithms;integer linear programming;microarchitectural changes;microprocessors;multicore processors;multithreaded multicore systems;out-of-order pipelines;power supply voltage droops;single-core stress mark generation tool;single-core systems;stress analysis;stress testing;test programs;thread alignment issues;timing errors;di/dt;genetic algorithm;hardware measurement;inductive noise;low power;power distribution network;stressmark generation;voltage droop},
}

@InProceedings{Samoylenko2017,
  author        = {A. P. Samoylenko and A. I. Panychev and S. A. Panychev},
  title         = {Evaluation of telecommunication system reliability via stress testing},
  booktitle     = {2017 International Siberian Conference on Control and Communications (SIBCON)},
  year          = {2017},
  pages         = {1-5},
  month         = {June},
  __markedentry = {[Jonnathan:6]},
  abstract      = {The problem of evaluating reliability of telecommunication systems in general, and their components is considered. The method of forecasting the reliability of a telecommunications system designed according to the results of stress testing is proposed. The essence of the proposed method is to use the emissions of a random process as a diagnostic parameter that displays the trajectory of a monitored quantity values. As a quantitative measure of reliability used system average uptime. The simulation for normal distribution law of a random parameters with different correlation functions is carried out. The estimation of the average uptime for various sizes of tolerance range of parameters is calculated. It is shown that the theory of random processes emissions is an adequate mathematical apparatus for the formalization of the results of stress testing.},
  doi           = {10.1109/SIBCON.2017.7998430},
  keywords      = {mathematical analysis;telecommunication network reliability;diagnostic parameter;different correlation functions;mathematical apparatus;monitored quantity values;normal distribution law;random parameters;random process emissions;stress testing;system average uptime;telecommunication system reliability;Monitoring;Random processes;Reliability;Stress;Telecommunications;Testing;Trajectory;average uptime;emissions of a random process;forced testing;reliability;stress test;survivability;telecommunication system;the trajectory of a random parameter;tolerance domain},
}

@InProceedings{Tangadpalliwar2011,
  author        = {S. Tangadpalliwar and K. Sandrasegaran and M. Raymond and A. Moitra and F. Madani},
  title         = {Benchmarking Embedded Devices for Broadband Performance Testing},
  booktitle     = {2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing},
  year          = {2011},
  pages         = {321-327},
  month         = {Dec},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Real time monitoring of broadband performance parameters is critical for estimating the user experience of new broadband services like VoIP, IPTV, Gaming and Video. This information is of interest to service providers themselves for efficient network design and maintenance and government regulatory bodies for analyzing ISPs, regions and national benchmarking. A web-based system TRUEE (Tool for Real-time User Experience Estimation) is a distributed system that incorporates independent modules such as standalone measurement devices installed at customer premises, data centers, test servers and web-clients for remote monitoring and management of the system. The focus of this paper is to discuss the process of benchmarking three commercial embedded devices with PC as reference device representing an end user system for accessing broadband services. This work is part of the ongoing development process of TRUEE. This benchmarking process is of significant importance for making an informed decision on the suitability of an embedded device capable of providing desired accuracy and consistency in estimation of the broadband performance parameters. Based on literature review, online forum reviews and cost analysis three devices based on ARM viz. SheevaPlug, Texas Instrument's BeagleBoard-xM and Gumstix Overo are selected for benchmarking. Results show that Marvell's SheevaPlug outperforms the other two devices in accurately measuring the broadband parameters on its network interface.},
  doi           = {10.1109/DASC.2011.71},
  keywords      = {Internet;benchmark testing;broadband networks;embedded systems;performance evaluation;ARM based device;Gumstix Overo;ISP analysis;Marvell SheevaPlug;TRUEE;Texas Instrument's BeagleBoard-xM;Web-based system;Web-clients;benchmarking embedded device;broadband performance parameter;broadband performance testing;broadband service;customer premises;data center;distributed system;end user system;government regulatory body;national benchmarking;network interface;real time monitoring;region benchmarking;remote monitoring;service provider;test servers;tool for real-time user experience estimation;Bandwidth;Benchmark testing;Broadband communication;Jitter;Linux;Performance evaluation;Throughput;Benchmarking;Broadband;Embedded device;Network Monitoring;Performance Testing},
}

@InProceedings{Jiang2015,
  author        = {Z. M. J. Jiang},
  title         = {Load Testing Large-Scale Software Systems},
  booktitle     = {2015 IEEE/ACM 37th IEEE International Conference on Software Engineering},
  year          = {2015},
  volume        = {2},
  pages         = {955-956},
  month         = {May},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Large-scale software systems (e.g., Amazon and Dropbox) must be load tested to ensure that they can service thousands or millions of concurrent requests every day. In this technical briefing, we will describe the state of research and practices in the area of load testing. We will focus on the techniques used in the three phases of a load test: (1) designing a load test, (2) executing a load test, and (3) analyzing the results of a load test. This technical briefing is targeted at load testing practitioners and software engineering researchers interested in testing and analyzing the behavior of large-scale software systems.},
  doi           = {10.1109/ICSE.2015.304},
  issn          = {0270-5257},
  keywords      = {program testing;Amazon;Dropbox;large-scale software system load testing;Computer science;Conferences;Monitoring;Software engineering;Software systems;Testing;load testing;performance;scalability;software testing},
}

@InProceedings{Liang2009,
  author        = {Z. Liang and L. Jianhua and W. Ruofei and G. Xiaobin},
  title         = {Design of Performance Testing System for Train Air Conditioning},
  booktitle     = {2009 International Conference on Energy and Environment Technology},
  year          = {2009},
  volume        = {1},
  pages         = {85-89},
  month         = {Oct},
  __markedentry = {[Jonnathan:6]},
  abstract      = {The design of performance testing system for train air conditioning was done according to the NATIONAL STANDARD TB/T 1804-2003. The cooling capacity was measured by means of air enthalpy difference method. The hardware part of the test system consists of data collection unit and test instrument, while the software is programmed with Visual Basic 6.0, accompanied with the Microsoft Access database. The PLC unit and the touch screen are employed for local control of the system to achieve precise adjustment to the temperature and humidity of environmental chamber, the speed and flow of air. In view of the system characteristics of complex nonlinearity and being difficult to control exactly, test system adopts a fuzzy PID control based on plc to control experimental parameters such as temperature and humidity.},
  doi           = {10.1109/ICEET.2009.27},
  keywords      = {Visual BASIC;air conditioning;computerised instrumentation;fuzzy control;programmable controllers;test equipment;three-term control;touch sensitive screens;visual programming;Microsoft Access database;National Standard TB/T 1804-2003;PLC unit;Visual Basic 6.0;air enthalpy difference method;cooling capacity;data collection unit;environmental chamber humidity;fuzzy PID control;performance testing system;programmable logic controller;test instrument;touch screen;train air conditioning;Air conditioning;Control systems;Cooling;Hardware;Humidity control;Nonlinear control systems;Programmable control;Software testing;System testing;Temperature control;data acquisition;fuzzy control;performance test system;train air conditioning},
}

@Article{Baxter1979,
  author        = {P. D. Baxter and V. Lang and A. Anouchi},
  title         = {A Microprocessor-Based Positive Displacement Measurement System for Diesel Pump and Injector Performance Testing},
  journal       = {IEEE Transactions on Instrumentation and Measurement},
  year          = {1979},
  volume        = {28},
  number        = {4},
  pages         = {317-320},
  month         = {Dec},
  issn          = {0018-9456},
  __markedentry = {[Jonnathan:6]},
  abstract      = {New stringent emissions and economy requirements for the burgeoning diesel engine market have resulted in development of a new entirely digital microprocessor-based fuel delivery measurement system. The system uses a unique inherently digital transducer and a microprocessor for measurement and control.},
  doi           = {10.1109/TIM.1979.4314840},
  keywords      = {Diesel engines;Displacement measurement;Engine cylinders;Fluid flow measurement;Fuels;Maintenance;Pressure measurement;System testing;Transducers;Velocity measurement},
}

@InProceedings{Hwang2014,
  author        = {G. H. Hwang and C. Wu-Lee and Y. H. Tung and C. J. Chuang and S. F. Wu},
  title         = {Implementing TaaS-based stress testing by MapReduce computing model},
  booktitle     = {2014 IEEE 5th International Conference on Software Engineering and Service Science},
  year          = {2014},
  pages         = {137-140},
  month         = {June},
  __markedentry = {[Jonnathan:6]},
  abstract      = {In this paper we propose to employ the MapReduce computing model to implement a Testing as a Service (TaaS) for stress testing. We focus on stress testing for heavy-weight network transactions. The computation power of MapReduce computing system is used to simulate concurrent network transactions issued by a lot of users. The user first describes the testing scenario which he wants to be simulate in a testing script. The TaaS platform analyzes the testing script and then automatically distributes required testing data including details of transactions and files into a MapReduce computing system. We propose three different schemes to distribute testing data and measure their performances. We compare them with the popular stress testing tool JMeter and find out that our scheme can always have the tested system deliver higher error rate during the stress testing.},
  doi           = {10.1109/ICSESS.2014.6933530},
  issn          = {2327-0586},
  keywords      = {distributed programming;program testing;JMeter;MapReduce computing model;TaaS-based stress testing;testing as a service;Computational modeling;Computer crashes;Error analysis;Instruction sets;Servers;Stress;Hadoop;MapReduce;Stress testing},
}

@InProceedings{Wienke2018,
  author        = {J. Wienke and D. Wigand and N. Koster and S. Wrede},
  title         = {Model-Based Performance Testing for Robotics Software Components},
  booktitle     = {2018 Second IEEE International Conference on Robotic Computing (IRC)},
  year          = {2018},
  pages         = {25-32},
  month         = {Jan},
  __markedentry = {[Jonnathan:6]},
  abstract      = {In complex technical systems like robotics platforms, a manifold of issues can impair their dependability. While common testing and simulation methods largely focus on functional aspects, the utilization of resources like CPU, network bandwidth, or memory is only rarely tested systematically. With this contribution we propose a novel Domain-Specific Language (DSL) for modeling performance tests for individual robotics components with the aim to establish a systematic testing process for detecting regressions regarding the resource utilization. This DSL builds upon a testing framework from previous research and aims to significantly reduce the effort and complexity for creating performance tests. The DSL is built using the MPS language workbench and provides a feature-rich editor with modern editing aids. An evaluation indicates that developing performance tests requires only one third of the work in comparison to the original Java-based API.},
  doi           = {10.1109/IRC.2018.00013},
  keywords      = {C language;control engineering computing;embedded systems;formal specification;object-oriented programming;product development;program diagnostics;public domain software;robots;specification languages;DSL;Domain-Specific Language;MPS language workbench;complex technical systems;editing aids;feature-rich editor;model-based performance tests;performance testing;resource utilization;robotics platforms;robotics software components;simulation methods;systematic testing process;DSL;Resource management;Robots;Software;Testing;Tools;Unified modeling language;CBSE;DSL;MPS;performance;performance testing;resource awareness;testing},
}

@InProceedings{Le1994,
  author        = {D. Le and I. Karolik and R. Smith and A. J. Mcgovern and C. Curette and J. Ulbin and M. Zarubaiko and C. Henry and L. Stevens},
  title         = {Environmental Stress Testing with Boundary-Scan},
  booktitle     = {Proceedings., International Test Conference},
  year          = {1994},
  pages         = {307-313},
  month         = {Oct},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Environmental Stress Testing (EST) enhances product quality and reliability by detecting latent or marginal defects in a product. For EST to be effective, testing of a product must achieve a high fault coverage so that as many EST-induced defects can be detected. By utilizing Boundary-Scan (IEEE Std 1149.1-1990), EST can achieve a high fault coverage and at the same time, minimize test cost. The paper describes a complete infrastructure, both software and hardware, for using Boundary-Scan (B-S) in EST. In addition, the paper shows a simplified control mechanism to select individual circuit packs for Boundary-Scan testing. This control mechanism minimizes the number of wires required to drive the control interface and thus, the number of wires in the cable that connects a tester to the backplane of a system under test and across which Boundary-Scan tests are executed. Finally, the paper presents and discusses some study results for evaluating the effectiveness of monitored EST},
  doi           = {10.1109/TEST.1994.527964},
  issn          = {1089-3539},
  keywords      = {IEEE standards;automatic testing;boundary scan testing;environmental stress screening;production testing;IEEE Std 1149.1;boundary scan testing;control;control interface;effectiveness;environmental stress testing;fault coverage;latent defects;marginal defects;product quality;reliability;test cost;Circuit faults;Circuit testing;Control systems;Costs;Electrical fault detection;Fault detection;Hardware;Stress;System testing;Wires},
}

@InProceedings{Jodice1994,
  author        = {J. A. Jodice and S. Harpham},
  title         = {`End-to-end transient simulation for protection system performance testing'},
  booktitle     = {Developments in the Use of Global Positioning Systems},
  year          = {1994},
  pages         = {6/1-6/5},
  month         = {Feb},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Formatted according to the new IEEE Standard C37.111, 1992 (COMTRADE), digital information describing power system disturbances controls a test system which produces transient simulation signals for analyzing protective relay performance. Global positioning system (GPS) satellite timing signals are used to synchronize two remotely located test systems for performing transient end-to-end simulation tests. DFR records of actual events and Electromagnetic Transient Program (EMTP) simulations of multiple fault events, played back through satellite-synchronized end-to-end test systems have proven comprehensive analytical tools-virtually eliminating the need for costly and dangerous staged fault tests generally performed at a limited number of locations},
  keywords      = {digital simulation;electrical faults;power system analysis computing;power system protection;radionavigation;relay protection;satellite relay systems;software packages;synchronisation;Electromagnetic Transient Program;GPS;Global Positioning System;IEEE Standard C37.111;digital fault recorders;digital simulation;end-to-end simulation;multiple fault events;performance testing;power system disturbances;protective relay performance;satellite timing signals;synchronisation;transient simulation signals},
}

@InProceedings{Xu2011,
  author        = {W. Xu and C. Lv},
  title         = {Research of virtual reality in industrial design manufacture and performance testing},
  booktitle     = {2011 2nd International Conference on Intelligent Control and Information Processing},
  year          = {2011},
  volume        = {1},
  pages         = {403-405},
  month         = {July},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Virtual reality (VR) is a new method of visual operating and interacting of complex data can be realized by computers, in which one would have an immersed sense to observe and operate objects in three dimensions timely and unboundedly. VR is a new developing technique and a complex simulation tool for industry, it builds a simulated environment in which researchers can do many things such as driving, operating, designing and performance test in a unaffected way. Performance test plays an important role in vehicle design. Most of interactive processing in virtual vehicle manufacturing is perfect, but many deep interactive functions are under emphasis such as performance test after manufacturing, variation and recording of performance parameters. Research of VRML combining with JavaScript is presented in this paper, and vehicle designing and manufacturing, testing system are built based on it, in which we can real-time and dynamic control the car through keyboard and mouse, and get the real-time performance parameters.},
  doi           = {10.1109/ICICIP.2011.6008274},
  keywords      = {Java;automatic test software;automobile manufacture;performance evaluation;production engineering computing;virtual manufacturing;virtual reality languages;JavaScript;VRML;industrial design manufacture;interactive processing;performance testing;simulation tool;vehicle design;virtual reality;virtual vehicle manufacturing;visual interaction;Computational modeling;Shape},
}

@InProceedings{Guo2010,
  author        = {Xiao-yang Guo and Ying-hui Chen and Xue-song Qiu and Fan Tang},
  title         = {Design and implementation of performance testing model for Web Services},
  booktitle     = {2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics (CAR 2010)},
  year          = {2010},
  volume        = {1},
  pages         = {353-356},
  month         = {March},
  __markedentry = {[Jonnathan:6]},
  abstract      = {The performance testing model for Web Services is proposed. Aiming to enhance testing efficiency and automation, the model provides a multi-machine joint testing model and strategy model. The former is used to share the heavy load to multiple units, which could also be called load balance model, and the latter is used to simulate a realistic Web Services running environment. The model has been applied to an original web services testing software, and proved to be a feasible way for performance testing for web services.},
  doi           = {10.1109/CAR.2010.5456825},
  issn          = {1948-3414},
  keywords      = {Web services;program testing;resource allocation;software performance evaluation;heavy load share;load balance model;multi-machine joint testing model;realistic Web services running environment;software performance testing model;Asia;Automatic control;Automatic testing;Informatics;Laboratories;Load modeling;Robotics and automation;Service oriented architecture;Software testing;Web services;load balance;multi-machine testing;performance testing;strategy model;web services},
}

@Article{Ghosh1999,
  author        = {P. K. Ghosh and L. G. Durante},
  title         = {Measurement performance testing for nonsinusoidal environments},
  journal       = {IEEE Transactions on Power Systems},
  year          = {1999},
  volume        = {14},
  number        = {4},
  pages         = {1526-1532},
  month         = {Nov},
  issn          = {0885-8950},
  __markedentry = {[Jonnathan:6]},
  abstract      = {A comparative study of the measurement accuracy capabilities of solid state watthour meters and other commercially available measurement instruments was performed. This study proposes a set of mathematically designed "waveforms" that could be used as a standard for the uniform, meaningful and reproducible evaluation testing of solid state watthour meters designed for use in nonsinusoidal environments. The test waveforms were theoretically developed based on an extensive database of field captured distorted waveforms that, in most cases, were monitored and recorded during power quality investigations over the last five years. Experimentation was performed using both the theoretically developed waveforms and the field captured waveforms.},
  doi           = {10.1109/59.801951},
  keywords      = {calibration;harmonic distortion;power measurement;power supply quality;power system harmonics;watthour meters;measurement accuracy;measurement instruments;measurement performance testing;nonsinusoidal supply environments;power quality;solid state watthour meters;Electric variables measurement;Guidelines;Harmonic distortion;Laboratories;Power system harmonics;Power systems;Semiconductor materials;Solid state circuits;Testing;Watthour meters},
}

@Article{Lee1983,
  author        = {R. E. Lee and M. T. Bishop},
  title         = {Performance Testing of the Ratio Ground Relay on a Four-Wire Distribution Feeder},
  journal       = {IEEE Transactions on Power Apparatus and Systems},
  year          = {1983},
  volume        = {PAS-102},
  number        = {9},
  pages         = {2943-2949},
  month         = {Sept},
  issn          = {0018-9510},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Digital fault investigations on six Pennsylvania Power and Light 12 kV distribution feeders led to the development of a prototype Ratio Ground Relay to theoretically provide better detection of broken conductor faults. Further assessment of the relay's performance was provided through analog computer tests followed by staged fault testing on an operating distribution feeder. Performance tests are described and documented. These positive test results provided the incentive to monitor the performance of the Ratio Ground Relay on several PP&L distribution feeders.},
  doi           = {10.1109/TPAS.1983.318145},
  keywords      = {Analog computers;Circuit faults;Circuit testing;Conductors;Digital relays;Fault detection;Impedance;Performance evaluation;Power system relaying;Prototypes},
}

@InProceedings{Li2014,
  author        = {J. Li and Q. Li and T. Bi and H. Liu and K. Xu and F. Sun},
  title         = {PMUs performance testing and evaluation in China},
  booktitle     = {2014 IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC)},
  year          = {2014},
  pages         = {1-6},
  month         = {Dec},
  __markedentry = {[Jonnathan:6]},
  abstract      = {Phasor measurement units (PMU) are taking an increasingly important role in power system dynamic security monitoring and control. However, traditional Discrete Fourier Transforms (DFT) used by PMUs cannot obtain accurate phasor measurements during frequency excursion and transient events, being limited by its static phasor model. Therefore, the performance of PMUs under both static and dynamic conditions is fundamental. In this paper, the averaging effect of DFT is explored, which results in the measurement errors of PMUs under dynamic conditions. Then, a PMU testing system is introduced. With that, a centralized test aiming to improve the performance of M-class PMUs in China is accomplished by evaluating the PMUs from seven manufactures in China under static and dynamic conditions. The testing results show that the PMUs under test can satisfy most requirements in the standard by improving their algorithms. The testing data is analyzed to demonstrate the correctness of the theoretical derivation of the averaging effect of DFT.},
  doi           = {10.1109/APPEEC.2014.7066184},
  issn          = {2157-4839},
  keywords      = {discrete Fourier transforms;phasor measurement;power system control;power system security;China;DFT;M-class PMU measurement error;PMU performance evaluation;discrete Fourier transform;frequency excursion;phasor measurement unit performance testing;power system dynamic control;power system dynamic security monitoring;static phasor model;Discrete Fourier transforms;Frequency measurement;Phasor measurement units;Power system dynamics;Standards;Testing;Time measurement;Discrete Fourier transforms (DFT);dynamic phasor algorithm;phasor measurement units (PMU);power system measurements;power system transients},
}

@InProceedings{Bot2014,
  author        = {P. Bot and C. Vatamanu and D. Gavrilut and R. M. Benchea},
  title         = {Performance testing framework: Evaluating the impact on the system speed},
  booktitle     = {2014 Second Workshop on Anti-malware Testing Research (WATeR)},
  year          = {2014},
  pages         = {1-6},
  month         = {Oct},
  __markedentry = {[Jonnathan:6]},
  abstract      = {The world we live in now is defined by the word “speed” and any device, technology, or system that doesn't keep up is rejected or replaced immediately. Because of this, one of the biggest concerns today is “optimization”. Its purpose is to reduce the impact on the user's device. The Anti-Virus industry is also confronting with this challenge. Although the first concern is to keep the user safe, providing a flawless protection, it is crucial to reduce the impact brought on the user's system, preventing him to disable or uninstall the AV solution and thus remaining unprotected. The increased number of malware types/families as well as their complexity generated the need for complicated detection methods, which means a constant evaluation is needed. Because of these reasons, our antimalware laboratory has developed a generic framework for measuring the impact that the AV solutions have on the system they are installed on. This system was designed to be easily configurable, managing the big number of changes that occur every day and fast so that every update released to the users can be tested. Also, this framework is used to test and develop new technologies that improve the performance of our AV product.},
  doi           = {10.1109/WATeR.2014.7015753},
  keywords      = {DP industry;data protection;invasive software;program testing;software performance evaluation;AV solution;antivirus industry;flawless protection;malware type;performance testing framework;system speed impact;Computers;Databases;Gold;Laboratories;Operating systems;Servers;generic framework;impact;performance;user interaction},
}

@Article{Pendurkar2001,
  author        = {R. Pendurkar and A. Chatterjee and Y. Zorian},
  title         = {Switching activity generation with automated BIST synthesis for performance testing of interconnects},
  journal       = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  year          = {2001},
  volume        = {20},
  number        = {9},
  pages         = {1143-1158},
  month         = {Sep},
  issn          = {0278-0070},
  __markedentry = {[Jonnathan:6]},
  abstract      = {A novel scheme of synthesizing nonlinear feedback shift register structures that can be superimposed on the boundary of the component of a system under test to generate interconnect switching activities that resemble real life interconnect switching profiles is proposed. The goal is to perform at-speed interconnect test while simultaneously capturing the dynamic switching effects such as crosstalk and ground bounce, as accurately as possible during interconnect built-in self-test. A library of nonlinear feedback shift register structures called precharacterized test pattern generators (P-TPGs) is constructed. Components of P-TPGs can be modeled using Markov chain and can be interconnected together in specific ways to recreate the switching activity profile of the interconnections being tested. The unique advantage of this scheme is that there is no simulation overhead since P-TPG components are precharacterized by solving Markov equations analytically. An integrated genetic algorithm-based search and optimization technique for finding the best P-TPG component among various possible implementations and matching its activity profiles with those of the interconnections under test has been designed and implemented synthesis for testability allows generation of the worst case interconnect switching activities. Experimental results confirm the validity of our approach},
  doi           = {10.1109/43.945309},
  keywords      = {Markov processes;automatic testing;built-in self test;crosstalk;design for testability;genetic algorithms;integrated circuit interconnections;integrated circuit testing;shift registers;Markov chain;automated BIST synthesis;crosstalk;design for testability;genetic algorithm;ground bounce;interconnect performance testing;nonlinear feedback shift register;precharacterized test pattern generator;search optimization;switching activity;Automatic testing;Built-in self-test;Crosstalk;Feedback;Libraries;Life testing;Nonlinear dynamical systems;Performance evaluation;Shift registers;System testing},
}

@InProceedings{Xie2017,
  author    = {Q. Xie},
  title     = {A new method for SSD black-box performance test},
  booktitle = {2017 Progress In Electromagnetics Research Symposium - Spring (PIERS)},
  year      = {2017},
  pages     = {1116-1122},
  month     = {May},
  abstract  = {In the past decade, NAND Flash has stood out from numerous non-volatile storage mediums. The NAND Flash based Solid State Disk (SSD) has been widely used in many storing required fields such as embedded applications and data center. A new and efficient SSD black-box performance test method is revising in this paper. The designed test system contains time parameter getter, excitation signal generator, buffer unit, write/read controller and SSD. With the application of the proposed method, not only the influence of TRIM mechanism could been analyzed, but also the test precision is increased significantly. To verify the validity and performance of our test system, the IOPS, response time and write/read bandwidth of the universal testing software (IOMETER, HDTUNE, etc.) and SATA protocol analyzer are presented and compared with our method in detail.},
  doi       = {10.1109/PIERS.2017.8261912},
  keywords  = {NAND circuits;flash memories;integrated circuit testing;HDTUNE;IOMETER;IOPS;NAND flash;SATA protocol analyzer;TRIM mechanism;data center;designed test system;efficient SSD black-box performance test method;embedded applications;excitation signal generator;nonvolatile storage mediums;solid state disk;test precision;universal testing software;write-read controller;Electromagnetics;Flash memories;Generators;Software;Springs;Testing;Tools},
}

@InProceedings{Schubert2007,
  author    = {L. Schubert and M. Kuttner and B. Frankenstein and D. Hentschel},
  title     = {Structural Health Monitoring of a rotor blade during statical load test},
  booktitle = {18th International Workshop on Database and Expert Systems Applications (DEXA 2007)},
  year      = {2007},
  pages     = {297-301},
  month     = {Sept},
  abstract  = {The paper describes a structural health monitoring concept based on the evaluation of acoustic Lamb waves. Using a suitable damage indicator like the correlation coefficient it is possible to detect and localize defects in the observed structure. The functional capability was shown in statical test of a part of a rotor blade.},
  doi       = {10.1109/DEXA.2007.151},
  issn      = {1529-4188},
  keywords  = {blades;condition monitoring;correlation methods;fault diagnosis;rotors;statistical testing;surface acoustic waves;acoustic Lamb waves;correlation coefficient;damage indicator;defect detection;defect localization;rotor blade;statical load test;structural health monitoring;Acoustic emission;Acoustic sensors;Acoustic signal detection;Acoustic testing;Acoustic waves;Blades;Electronic mail;Monitoring;Sensor systems;Wind energy;acoustic signature;acousto ultrasonics;correlation coefficient;rotor blade;statical load test;structural health monitoring},
}

@InProceedings{Shan2009,
  author    = {M. Shan and X. Wang and L. Zhao and L. Guo},
  title     = {Using TTCN-3 in Performance Test for Service Application},
  booktitle = {2009 Seventh ACIS International Conference on Software Engineering Research, Management and Applications},
  year      = {2009},
  pages     = {253-258},
  month     = {Dec},
  abstract  = {Service applications are applicable to provide services for requests of users from network. Due to the fact that they have to endure a big number of concurrent requests, the performance of service applications running under specific arrival rate of requests should be assessed. To measure the performance of a service application, multi-party testing context is needed to simulate a number of concurrent requests and collect the responses. TTCN-3 is a test description language; it provides basic language elements for multi-party testing context that can be used in performance tests. This paper proposes a general approach of using TTCN-3 in multi-party performance testing service application. To this aim, a model of service application is presented, and performance testing framework for service applications is discussed. This testing framework is realized for a typical application by developing a reusable TTCN-3 abstract test suite.},
  doi       = {10.1109/SERA.2009.18},
  keywords  = {program testing;TTCN-3 test description language;concurrent request;language element;multiparty testing;performance test;service application;Application software;Conference management;Engineering management;IEC standards;ISO standards;Neural networks;Quality of service;Software engineering;Software testing;System testing;TTCN-3;peformance test;service application},
}

@Article{Demirkaya2007,
  author   = {O. Demirkaya and R. Al Mazrou},
  title    = {Performance Test Data Analysis of Scintillation Cameras},
  journal  = {IEEE Transactions on Nuclear Science},
  year     = {2007},
  volume   = {54},
  number   = {5},
  pages    = {1506-1515},
  month    = {Oct},
  issn     = {0018-9499},
  abstract = {In this paper, we present a set of image analysis tools to calculate the performance parameters of gamma camera systems from test data acquired according to the National Electrical Manufacturers Association NU 1-2001 guidelines. The calculation methods are either completely automated or require minimal user interaction; minimizing potential human errors. The developed methods are robust with respect to varying conditions under which these tests may be performed. The core algorithms have been validated for accuracy. They have been extensively tested on images acquired by the gamma cameras from different vendors. All the algorithms are incorporated into a graphical user interface that provides a convenient way to process the data and report the results. The entire application has been developed in MATLAB programming environment and is compiled to run as a stand-alone program. The developed image analysis tools provide an automated, convenient and accurate means to calculate the performance parameters of gamma cameras and SPECT systems. The developed application is available upon request for personal or non-commercial uses. The results of this study have been partially presented in Society of Nuclear Medicine Annual meeting as an InfoSNM presentation.},
  doi      = {10.1109/TNS.2007.906162},
  keywords = {cameras;gamma-ray apparatus;scintillation counters;single photon emission computed tomography;MATLAB programming;SPECT systems;gamma camera systems;graphical user interface;image analysis;scintillation cameras;Cameras;Data analysis;Graphical user interfaces;Guidelines;Humans;Image analysis;Performance evaluation;Pulp manufacturing;Robustness;System testing;Acceptance testing;SPECT;gamma cameras;performance measurement},
}

@InProceedings{Li2013,
  author    = {P. Li and D. Shi and J. Li},
  title     = {Performance test and bottle analysis based on scientific research management platform},
  booktitle = {2013 10th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)},
  year      = {2013},
  pages     = {218-221},
  month     = {Dec},
  abstract  = {The performance and service quality of a Web system become more and more important along with the development of Web application technology and popularization of Web application rapidly. There are many particularities and difficulties in the testing of web applications as to traditional application, especially in performance testing, such as unpredictable load, reality of designing scenario and veracity of analysis bottleneck. This paper which based on traditional Web system performance testing theory and used the testing tool named LoadRunner to analyze how to detect the shortage of Web system performance precisely. The method has been implemented in System of scientific research management platform, and has been obtained anticipative result. This paper has divide the web system method into six processes based on the Web system performance testing: Making performance testing plan, build performance testing environment, record and develop testing script, foundation testing scene, play the monitor scene and analysis testing result. And also gives Web performance test the general step.},
  doi       = {10.1109/ICCWAMTIP.2013.6716635},
  keywords  = {Web services;program testing;scientific information systems;software performance evaluation;software tools;LoadRunner;Web application popularization;Web application technology development;Web applications testing;Web system performance testing tool;bottleneck analysis;foundation testing scene;performance testing environment;performance testing plan;performance testing script;scene monitoring;scientific research management;service quality;Generators;Monitoring;Software systems;System performance;Testing;Throughput;Time factors;Bottleneck analysis;LoadRunner;Scientific Research Management Platform;Web Performance Testing},
}

@InProceedings{Lee2006,
  author    = {Jongyoung Lee and Naesoo Kim},
  title     = {Performance Test Tool for RFID Middleware: Parameters, Design, Implementation, and Features},
  booktitle = {2006 8th International Conference Advanced Communication Technology},
  year      = {2006},
  volume    = {1},
  pages     = {149-152},
  month     = {Feb},
  abstract  = {Recently, major software vendors (such as Sun, IBM, Oracle) introduced a RFID middleware product which process RFID tag data causing extended RFID related technology and application. RFID middleware which receives tag data from reader, internally processing received data, and transmit the results to the application acts as a key role of applying RFID technology to the application. In this paper, we define parameters for RFID middleware performance and introduce the design of a performance test tool of RFID middleware},
  doi       = {10.1109/ICACT.2006.205940},
  keywords  = {middleware;radiofrequency identification;software performance evaluation;telecommunication computing;IBM;Oracle;RFID middleware;RFID tag data processing;Sun;performance test tool;software vendors;Application software;Delay;Middleware;RFID tags;Radiofrequency identification;Software performance;Software testing;Stress;Sun;Throughput;Middleware;Performance;RFID;Software Testing},
}

@InProceedings{He2016,
  author    = {H. He and E. Wang and T. Pang},
  title     = {Research and analysis of GNSS performance test methods},
  booktitle = {2016 IEEE 11th Conference on Industrial Electronics and Applications (ICIEA)},
  year      = {2016},
  pages     = {2096-2100},
  month     = {June},
  abstract  = {GNSS performance test is necessary at various stages such as initial design, full operational capability and system modernization, and is also the important guarantee of GNSS continuous and reliable operation. At present, China's BeiDou navigation satellite system (BDS) is in the construction stage of developing from the regional navigation system to the global navigation system, which is quite vital to carry out the study on relevant performance test methods. Firstly, this paper systematically studies the GNSS performance test projects carried out in the different stages of development in view of GPS, Galileo and some augmentation systems including WAAS, GBAS, EGNOS. And the test purpose, test content, test method, the experimental reference and test results are analyzed in detailed. Then, based on the status of China's BeiDou navigation satellite system, the related suggestions for performance test methods of BDS are put forward. The study is of great reference value to establishing BDS performance test environment and developing test methods.},
  doi       = {10.1109/ICIEA.2016.7603935},
  keywords  = {Global Positioning System;telecommunication equipment testing;BDS;BeiDou navigation satellite system;China;EGNOS;GBAS;GNSS performance test method;GPS;Galileo;WAAS;augmentation system;global navigation system;regional navigation system;system modernization;Aerospace electronics;Global Positioning System;Military aircraft;Receivers;Satellite broadcasting;Satellites;BeiDou navigation satellite system (BDS);Global Positioning System (GPS);global navigation satellite system (GNSS);performance test;test methods},
}

@InProceedings{Chunqiu2011,
  author    = {Tang Chunqiu and Mo Yimin and Zhou Wen},
  title     = {Application of fuzzy and binary algorithm to regulation of load in locomotive load test},
  booktitle = {2011 Second International Conference on Mechanic Automation and Control Engineering},
  year      = {2011},
  pages     = {96-99},
  month     = {July},
  abstract  = {The purpose of locomotive load test is to examine and adjust the capability of locomotive often in its non-driving state, and it is a kind of important standard and means to estimate the quality of repairing locomotive in railway locomotive depot. There are two ways of load test at present. One is the water-resistor load test, the other is the dry resistor load test. Because the dry resistor-load test means does not pollute the environment and needs area less, its developing foreground is immense. To solve the difficulty that the current cannot be freely regulated continuously, for the first time, the model of weightier resistor network in digital circuit is applied to the locomotive dry resistor-load test system, which solves the problem of dry resistor-load test theoretically. It is proved by theory and test that the precision of dry resistor means can meet the request of locomotives constant power load test and reach the standard of water-resistor, so it can serve the application of the dry resistor-load test system. During the locomotive load test, the load of locomotive may be regulated so that the locomotive can be adapted run on all kinds of actual work state. According to the characteristic of weightier resistor, the control arithmetic, which is made up of fuzzy algorithm and binary algorithm, realizes the fast and exact regulation on locomotive load. This paper introduces how to apply fuzzy and binary algorithm to regulate the dry resistor-load and explains the realization of the fuzzy and binary algorithm.},
  doi       = {10.1109/MACE.2011.5986866},
  keywords  = {digital circuits;electric locomotives;fuzzy set theory;load regulation;mechanical testing;railways;resistors;binary algorithm;digital circuit;dry resistor load test;fuzzy algorithm;load regulation;locomotive constant power load test;nondriving state;railway locomotive depot;resistor network;water-resistor load test;Digital circuits;Fuzzy control;Generators;Insulated gate bipolar transistors;Niobium;Resistors;Water pollution;dry resistor-load;fuzzy and binary algorithm;regulation;weightier resistor},
}

@InProceedings{Qi2011,
  author    = {X. Qi and X. Wei and G. Qimin and X. Huigang},
  title     = {Design of Comprehensive Performance Test System for Residual Current Fire Monitoring Detector Based on Virtual Instrument Technology},
  booktitle = {2011 Third International Conference on Measuring Technology and Mechatronics Automation},
  year      = {2011},
  volume    = {1},
  pages     = {950-953},
  month     = {Jan},
  abstract  = {Aiming at the need of detecting the residual current fire monitoring detector, an intelligent test system based on virtual instrument technology was designed. This system was composed of industrial computer, data acquisition card, signal conditioning circuit, three-phase great current generator and pneumatic fixture, etc. Using Lab VIEW virtual instrument technology platform, the related test and data processing program codes were developed, and its high speed data acquisition and data processing satisfied the needs of ex-factory comprehensive performance test for residual current fire monitoring detector. The hardware design was given and the working principles of this generator were introduced, the module design of system software was also introduced in detail. Practical application shows that the intelligent test system features with stable and reliable, easy to operate and maintain, high precision and can improve the design and performance of products, which can be widely used.},
  doi       = {10.1109/ICMTMA.2011.238},
  issn      = {2157-1473},
  keywords  = {data acquisition;residual current devices;signal conditioning circuits;virtual instrumentation;Lab VIEW;data acquisition card;data processing;fire monitoring detector;high speed data acquisition;industrial computer;intelligent test system;performance test system;residual current;signal conditioning circuit;three-phase great current generator;virtual instrument technology;Current measurement;Detectors;Fires;Instruments;Monitoring;Voltage measurement;Comprehensive performance;Residual current fire monitoring detector;Virtual instrument technology;intelligent test},
}

@InProceedings{Badarinath2016,
  author    = {Badarinath R and Abhilash MT},
  title     = {GP-GPU based high-performance test equipment for debugging radar digital units},
  booktitle = {2016 International Conference on Data Mining and Advanced Computing (SAPIENCE)},
  year      = {2016},
  pages     = {387-391},
  month     = {March},
  abstract  = {Modern active phased array radars are made to optimize the size, weight and power without compromising its capability to combat with advanced electronic warfare. To accomplish this task, the signal is digitized at element level or at sub-array level and processed with the help of advanced digital signal processor. Proving the capabilities of this firmware at bench level helps to reduce the overall development time. Hence, it is necessary to have a built-in test unit or test vector generator to verify the optimal performance of digital modules. The best way to accomplish this goal is to use a high speed baseband I & Q radar data generator which helps in testing, identifying and segregating the problems at various stages. In this paper we have explored the capability of latest general purpose graphical processing unit (GP-GPU) as software defined built in test vector generator with high throughput for active array radar applications.},
  doi       = {10.1109/SAPIENCE.2016.7684173},
  keywords  = {firmware;graphics processing units;phased array radar;program debugging;radar computing;radar signal processing;test equipment;GP-GPU based high-performance test equipment;advanced digital signal processor;advanced electronic warfare;bench level;built-in test unit;digital module optimal performance;element level;general purpose graphical processing unit;high-speed baseband I & Q radar data generator;modern active phased array radars;overall development time;radar digital unit debugging;sub-array level;test vector generator;Array signal processing;Arrays;Generators;Graphics processing units;Hardware;Radar;Radar signal processing;Built-in test;CPU;Digital beamforming;GP-GPU;Radar signal processing},
}

@InProceedings{Kim2012,
  author    = {H. Kim and Y. Lee and E. Lim},
  title     = {Fabrication and performance test of a compact-type magasonic waveguide for nano-particle cleaning},
  booktitle = {2012 12th IEEE International Conference on Nanotechnology (IEEE-NANO)},
  year      = {2012},
  pages     = {1-4},
  month     = {Aug},
  abstract  = {In this work, a compact-type megasonic cleaning system for semiconductor manufacturing was developed and its performance was verified. To design this megasonic system, firstly, an impedance analysis for a quartz megasonic waveguide with the piezoelectric actuator was performed with finite element method (FEM) software ANSYS. The obtained peak value of the anti-resonance frequency was 983 kHz, which showed good agreement with the design value of 982 kHz. In addition, acoustic pressures of the developed system was assessed by measuring acoustic pressures and comparing standard deviation values of them with a conventional megasonic system to evaluate the system performance. The analysis results showed that the standard deviation of the developed system was decreased by 38% compared to the commercial system. For another evaluation, the particle removal efficiency (PRE) test was performed with 80 nm particles. The experimental result revealed that the system has PRE of 91%. Based on the results, the developed megasonic system is regarded as an improved cleaning system which can irradiate more uniform acoustic pressures. As a consequence, it is thought to have higher energy efficiency and save the consumption of chemical and ultra pure water (UPW) in nano-particle cleaning.},
  doi       = {10.1109/NANO.2012.6321990},
  issn      = {1944-9399},
  keywords  = {acoustic intensity;acoustic waveguides;finite element analysis;nanoparticles;semiconductor technology;ultrasonic applications;ultrasonic waves;ANSYS FEM software;PRE test;antiresonance frequency;cleaning system;compact type megasonic waveguide;finite element method;frequency 938 kHz;frequency 982 kHz;impedance analysis;megasonic waveguide fabrication;megasonic waveguide performance test;nanoparticle cleaning;particle removal efficiency;piezoelectric actuator;quartz megasonic waveguide;semiconductor manufacturing;standard deviation;uniform acoustic pressure;Atmospheric measurements;Generators;Particle measurements;Megasonic;Nano-particle cleaning;Waveguide},
}

@InProceedings{Gao2008,
  author    = {Jianqiang Gao and Xiaoying Fan and Junyou Zhao},
  title     = {Online performance test software and its application for Large Capacity Combined-cycle Units},
  booktitle = {2008 International Conference on Condition Monitoring and Diagnosis},
  year      = {2008},
  pages     = {192-195},
  month     = {April},
  abstract  = {The paper introduces an online performance test software for large capacity combined-cycle units. The software is composed of four parts, i.e. the integrated modular modeling software (IMMS), real time database software, client browser software and communication software. The results of the model are displayed in B/S mode on the userpsilas terminals. With IMMS, on-line performance calculating model is developed by means of modular modeling method, which follows the guidelines of ldquoPerformance Test Code on Overall Plant Performancerdquo (PTC46-1996). All the primary parameters used for model calculation are from DCS of the unit. The software has been successfully applied to a 395 MW combined-cycle power unit for a year. It runs stably and reliably. It can provide the economic indicator on line, such as gross equipment power output and gross equipment heat rate etc., so as to help operators monitoring and adjusting the operation of unit more efficiently.},
  doi       = {10.1109/CMD.2008.4580261},
  keywords  = {combined cycle power stations;condition monitoring;power engineering computing;power generation reliability;power system stability;testing;client browser software;communication software;integrated modular modeling software;large capacity combined-cycle unit;online performance test software;real time database software;Application software;Cogeneration;Databases;Distributed control;Economic indicators;Guidelines;Monitoring;Performance evaluation;Software performance;Software testing;combined-cycle;condition monitoring;modeling;online;power generation testing;programming},
}

@InProceedings{Kudomi2002,
  author    = {N. Kudomi and Eunjoo Choi and S. Yamamoto and H. Watabe and Kyeong-Min Kim and T. Hayashi and M. Ogawa and N. Teramoto and E. Sakamoto and H. Iida},
  title     = {Performance test and application of GSO detector assembly for a continuous blood sampling system},
  booktitle = {2002 IEEE Nuclear Science Symposium Conference Record},
  year      = {2002},
  volume    = {3},
  pages     = {1648-1651 vol.3},
  month     = {Nov},
  abstract  = {A new input function monitoring system has been developed using a GSO detector for both PET and SPECT quantitative studies. The paired assembly of crystals provided an absolute sensitivity of approximately 7% for PET tracers and 70% for 99mTc and 201Tl (SPECT tracers). This system was applied to clinical use and animal study such as monkey and rat. This study demonstrates that the present system can he of use in both clinical and small animal studies using SPECT and PET tracers.},
  doi       = {10.1109/NSSMIC.2002.1239640},
  keywords  = {haemodynamics;positron emission tomography;single photon emission computed tomography;solid scintillation detectors;201Tl;99mTc;GSO detector;Gd-Si-O;PET;SPECT;Tc;Tl;blood sampling system;monkey;rat;sensitivity;Animals;Assembly systems;Blood;Detectors;Monitoring;Photonic crystals;Positron emission tomography;Sampling methods;Single photon emission computed tomography;System testing},
}

@InProceedings{Jang2006,
  author    = {S. h. Jang and J. w. Kim and S. k. Shin},
  title     = {API Automation Test with API Relation Diagram},
  booktitle = {2006 International Conference on Hybrid Information Technology},
  year      = {2006},
  volume    = {2},
  pages     = {175-177},
  month     = {Nov},
  abstract  = {The automation test is a useful method for test the standard platform that is equipped with APIs (application program interface) that observe the standard. But their test case codes use APIs that is the test target. And that is the reason that test of APIs can not be realized more efficient and more trust than now. We suggest API relation diagram that shows the dependency of the result of APIs execution. That prevents the incorrect decisions from the bad APIs in test cases and the code of test case is simpler because consideration about the bed API exception is needless. Keyword: API, Automation test.},
  doi       = {10.1109/ICHIT.2006.253608},
  keywords  = {Automatic testing;Automation;Embedded software;Embedded system;Life testing;Microprogramming;Monitoring;Software testing;System testing;Telecommunication standards},
}

@InProceedings{Gondokaryono2011,
  author    = {Y. S. Gondokaryono and Y. Bandung and J. A. Wibowo and A. A. Nugraha and B. Yonathan and D. Ramadhianto},
  title     = {Performance evaluation of audio-video streaming service in Keerom, Papua using integrated audio-video performance test tool},
  booktitle = {2011 6th International Conference on Telecommunication Systems, Services, and Applications (TSSA)},
  year      = {2011},
  pages     = {145-148},
  month     = {Oct},
  abstract  = {This study compared some video codec, audio codec, audio bit rate, video bit rate to determine the quality of the audio-video streaming service on the network Keerom, Papua. Average capacity in this network is 1.5Mbps. Mpeg audio and ac3 are choosen because of its characteristic, while the video codec is mpeg4 and H.264. Audio bit rate used 64 and 128kbps, while the video bit rate 64, 128 and 256kbps. The experiments result show the quality of the audio-video streaming service was better when the audio codec used mpeg audio 64kbps-mpeg4 256kbps. The test results will be used as a reference implementation of audio-video streaming service later in the network Keerom, Papua.},
  doi       = {10.1109/TSSA.2011.6095423},
  keywords  = {audio coding;audio streaming;video codecs;video coding;video streaming;AC3;H.264;Mpeg audio;Mpeg4;audio bit rate;audio codec;audio-video streaming service;bit rate 1.5 Mbit/s;bit rate 128 kbit/s;bit rate 256 kbit/s;bit rate 64 kbit/s;integrated audio-video performance test tool;performance evaluation;video bit rate;video codec;Bit rate;MPEG 4 Standard;PSNR;Streaming media;Transform coding;Video codecs;PESQ;PSNR;performance;streaming;test tool},
}

@InProceedings{Fan2015,
  author    = {J. Fan and W. He and C. Hendricks and M. Pecht and K. C. Yung},
  title     = {A practical design of reliability and performance test for portable lithium-ion batteries},
  booktitle = {2015 IEEE International Conference on Information and Automation},
  year      = {2015},
  pages     = {142-147},
  month     = {Aug},
  abstract  = {Lithium-ion batteries are increasingly used in industry as an energy storage system for applications ranging from portable electronics to high-energy electric vehicle systems. Their reliability and performance in the field can be affected by variations in environmental and loading conditions. Performance characterization testing provides health and performance features that can be used to assess a battery's performance and reliability under a variety of field environments and usage conditions. This paper presents and discusses the performance characterization tests for lithium-ion batteries in portable electronic applications. A case study is also presented where beginning, operational, and end-of-life characterization tests are performed.},
  doi       = {10.1109/ICInfA.2015.7279274},
  keywords  = {electric vehicles;reliability;secondary cells;end-of-life characterization test;energy storage system;high-energy electric vehicle system;portable electronic;portable lithium-ion battery reliability;Batteries;Degradation;Discharges (electric);Impedance;Resistance;Temperature measurement;Testing;Lithium-ion;performance testing;reliability;state of charge},
}

@InProceedings{Cai2004,
  author    = {Yuhong Cai and J. Grundy and J. Hosking},
  title     = {Experiences integrating and scaling a performance test bed generator with an open source CASE tool},
  booktitle = {Proceedings. 19th International Conference on Automated Software Engineering, 2004.},
  year      = {2004},
  pages     = {36-45},
  month     = {Sept},
  abstract  = {We report on our experiences developing a performance test-bed generator for industrial usage by extending an open-source UML CASE tool. This tool generates client and server code, database configuration and deployment scripts from a high-level software architecture description. It automates the code generation, compilation, deployment and performance metric result collection processes. We identify a range of problems that arose from our previous research on performance test-bed generation that needed to be addressed to scale this automated software engineering technique. We describe a range of approaches we used to solve these problems in our new tool. We then report on industrial deployment and evaluation of our new tool and discuss the effectiveness of these solutions},
  doi       = {10.1109/ASE.2004.1342722},
  issn      = {1938-4300},
  keywords  = {Unified Modeling Language;client-server systems;computer aided software engineering;program compilers;program testing;public domain software;software architecture;software tools;UML CASE tool;architecture analysis;automated software engineering;client-and-server code;code compilation;code deployment;code generation;database configuration;deployment scripts;high-level software architecture description;industrial deployment;industrial evaluation;industrial usage;open source CASE tool;performance metric result collection;performance test bed generator;software performance testing;software tool extension;Application software;Automatic testing;Computer aided software engineering;Computer architecture;Open source software;Software architecture;Software engineering;Software performance;Software prototyping;Software testing},
}

@InProceedings{Malik2010,
  author    = {H. Malik},
  title     = {A methodology to support load test analysis},
  booktitle = {2010 ACM/IEEE 32nd International Conference on Software Engineering},
  year      = {2010},
  volume    = {2},
  pages     = {421-424},
  month     = {May},
  abstract  = {Performance analysts rely heavily on load testing to measure the performance of their applications under a given load. During the load test, analyst strictly monitor and record thousands of performance counters to measure the run time system properties such as CPU utilization, Disk I/O, memory consumption, network traffic etc. The most frustrating problem faced by analysts is the time spent and complexity involved in analysing these huge counter logs and finding relevant information distributed across thousands of counters. We present our methodology to help analysts by automatically identifying important performance counters for load test and comparing them across tests to find performance gain/loss. Further, our methodology help analysts to understand the root cause of a load test failure by finding previously solved problems in test repositories. A case study on load test data of a large enterprise application shows that our methodology can effectively guide performance analysts to identify and compare top performance counters across tests in limited time thereby archiving 88% counter data reduction.},
  doi       = {10.1145/1810295.1810408},
  issn      = {0270-5257},
  keywords  = {business data processing;program testing;software performance evaluation;automatic performance counter identification;large enterprise application;load test analysis support;load test failure;performance analysts;performance gain;performance loss;relevant information search;run time system properties;test repositories;Conferences;Electronic mail;Monitoring;Principal component analysis;Radiation detectors;Servers;Testing;automation;counters;load test;performance counters;principal component analysis},
}

@InProceedings{Wang2010,
  author    = {Z. Wang and L. Xu and Z. Wang and H. Zhao and R. Song and W. Lou},
  title     = {Framework of MEMS high accelerated stress test},
  booktitle = {2010 IEEE 5th International Conference on Nano/Micro Engineered and Molecular Systems},
  year      = {2010},
  pages     = {280-283},
  month     = {Jan},
  abstract  = {Given the reliability principles and failure mechanism of MEMS, this paper discussed the accelerated test from three aspects as follows: the connotation of the test including concept and meaning; the scope of application concerned with product levels for applicants in types of stress; test process includes the test objective determination, test stressing selection, the test profile designing, the implementation scheme determining, analysis and improvement measures.},
  doi       = {10.1109/NEMS.2010.5592211},
  keywords  = {failure analysis;micromechanical devices;reliability;stress analysis;MEMS;failure mechanism;reliability principle;test objective determination;test profile designing;test stressing selection;HAST;MEMS;reliability},
}

@InProceedings{Liu2014,
  author    = {Z. Liu},
  title     = {Research of performance test technology for big data applications},
  booktitle = {2014 IEEE International Conference on Information and Automation (ICIA)},
  year      = {2014},
  pages     = {53-58},
  month     = {July},
  abstract  = {This paper studies the performance test in big data application. The existing performance testing technology is not suitable for the big data application. The paper proposed test technology for performance testing. The technology provided test goal analysis, test design, load design for big data application. The character for different application could be supported to consider specific multiple test data design method under this framework. The performance technology is used to test some applications and proved effective.},
  doi       = {10.1109/ICInfA.2014.6932625},
  keywords  = {Big Data;program testing;software performance evaluation;big data application;load design;multiple test data design method;performance testing technology;test goal analysis;Big data;Business;Data models;Monitoring;Servers;Testing;Time factors;Big Data;Performance Test;Software Test},
}

@InProceedings{Du2011,
  author    = {Y. Du and Z. Xiao},
  title     = {Management information system for shock absorber performance test},
  booktitle = {2011 International Conference on Electronics, Communications and Control (ICECC)},
  year      = {2011},
  pages     = {2123-2126},
  month     = {Sept},
  abstract  = {Management information system for shock absorber performance test consolidates isolated islands of information separated in different application systems. It integrates such functions as product, manufacture process and quality control information management, remote monitoring, data statistics and reporting, and centralized data management. Combined B/S and C/S structure are realized in the system. Detail information and UIs of web service, damp tester, real-time monitoring and reporting sub-systems are given. The application of such a system can greatly improve the quality and productivity, thus enhance the competitiveness of shock absorber manufacturers.},
  doi       = {10.1109/ICECC.2011.6067637},
  keywords  = {Web services;management information systems;process monitoring;production engineering computing;production testing;quality control;shock absorbers;statistics;Web service;centralized data management;damp tester;data statistics;management information system;manufacture process;quality control information management;real time monitoring;remote monitoring;shock absorber manufacturers;shock absorber performance test;Educational institutions;Helium;Industrial control;Information systems;Motorcycles;Shock absorbers;Testing;management information system;performance testing;shock absorber},
}

@Article{Wen2009,
  author   = {H. Wen and W. Bailey and K. Goddard and M. Al-Mosawi and C. Beduz and Y. Yang},
  title    = {Performance Test of a 100 kW HTS Generator Operating at 67 K #x2013;77 K},
  journal  = {IEEE Transactions on Applied Superconductivity},
  year     = {2009},
  volume   = {19},
  number   = {3},
  pages    = {1652-1655},
  month    = {June},
  issn     = {1051-8223},
  abstract = {A systematic test program is in progress to fully characterize a 100 kW HTS synchronous generator which was successfully constructed in 2004. The machine was one of the first HTS synchronous generator/motors to operate at liquid nitrogen temperatures while achieving a power rating relevant to practical application. It has a conventional 3-phase stator and a cold rotor with a magnetic core and a superconducting winding consisting of 10 HTS Bi2223 pancake coils separated by magnetic flux diverters. The test program includes a series of tests at various speeds, field currents and temperatures (65 K-77 K) with the machine in open circuit to determine the critical currents of the HTS rotor, the waveform and harmonic characteristics of generated voltage at different levels of iron saturation. Stationary measurements of the rotor critical current are carried out using dc current in the stator windings to quantify the influence of stator field on the performance of the superconducting winding. The voltages and temperatures of the rotor are measured using a radio frequency telemetry system.},
  doi      = {10.1109/TASC.2009.2017832},
  keywords = {bismuth compounds;high-temperature superconductors;machine windings;superconducting machines;synchronous generators;Bi2223 pancake coils;BiSr2CanCun+1O2n+6-d;cold rotor;high-temperature superconducting generator;magnetic core;magnetic flux diverter;power 100 kW;superconducting winding consisting;synchronous generator;temperature 67 K to 77 K;three phase stator;BSCCO coils;HTS motor;high temperature superconducting generator;rotating superconducting machine},
}

@InProceedings{Chunye2017,
  author    = {D. Chunye and S. Wei and W. Jianhua},
  title     = {Based on the analysis of mobile terminal application software performance test},
  booktitle = {2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)},
  year      = {2017},
  pages     = {391-395},
  month     = {June},
  abstract  = {With the rapid development of mobile terminal, mobile applications are gradually penetrated into all aspects of people's life and work. Mobile games, mobile streaming media, location services, mobile Internet news, instant messaging, mobile music and other rich and colorful information era are changing the social life. In view of this, we propose the application software performance test based on the mobile terminal, and analyze the performance test technology and method of the mobile application. Experimental results show that the performance test of the application system can predict the pressure in real environment, the system will be applied in the problems exposed, through the analysis of the data of the test, it will provide help for performance optimization of application system.},
  doi       = {10.1109/SNPD.2017.8022751},
  keywords  = {mobile computing;program testing;information era;instant messaging;location services;mobile Internet news;mobile games;mobile music;mobile streaming media;mobile terminal application software;software performance test;LoadRunner;Mobile application;Mobile terminal;Performance test;Test method;Test technology},
}

@InProceedings{Sucar1989,
  author    = {H. Sucar and S. J. Chandra and D. J. Wharton},
  title     = {High performance test generation for accurate defect models in CMOS gate array technology},
  booktitle = {1989 IEEE International Conference on Computer-Aided Design. Digest of Technical Papers},
  year      = {1989},
  pages     = {166-169},
  month     = {Nov},
  abstract  = {A brief description is given of the CrossCheck test technology which provides the fundamental basis for this work. The authors present a practical analysis of transistor-level defects which result in accurate defect models in comparison to conventional fault models. The embedded test technology and accurate defect models are combined to form a high-quality test environment which is used to implement a high-performance test generation system. The authors present results on five ISCAS sequential benchmark circuits and two real designs. These results indicate that, in the presence of the embedded test electronics, test generation and fault simulation are considerably faster and test quality is substantially improved.<>},
  doi       = {10.1109/ICCAD.1989.76928},
  keywords  = {CMOS integrated circuits;automatic testing;fault location;logic arrays;logic testing;sequential circuits;CMOS gate array technology;CrossCheck test technology;ISCAS sequential benchmark circuits;defect models;embedded test technology;fault simulation;test generation;transistor-level defects;Application specific integrated circuits;Automatic testing;CMOS technology;Circuit faults;Circuit testing;Computational modeling;Costs;Electronic equipment testing;Semiconductor device modeling;System testing},
}

@InProceedings{Chengqing2007,
  author    = {Y. Chengqing and W. Yinglong and W. Jizhi},
  title     = {A IPv6 Network Performance Test System using Multi-Agent},
  booktitle = {2007 8th International Conference on Electronic Measurement and Instruments},
  year      = {2007},
  pages     = {2-113-2-118},
  month     = {Aug},
  abstract  = {The Internet Engineering Task Force (IETF) has introduced IPv6 with a mission to meet the growing demands of the future Internet. IPv6 is more and more emphasized and moving from the pilot phase to the practical application. In the process of deploying IPv6, performance is one of the key issues to be considered. Test is an effective method to understand IPv6 network performance. We need scalable and available tools to measure IPv6 network performance, but the few existing network performance test software support IPv6. So through the introduction of multi-agent technology, a distributed IPv6 network performance test model integrated with centralized control is proposed. We describe architecture and workflow of the model thoroughly, and a IPv6 network performance test system is designed and implemented based on the model. Finally, using our system, we measure IPv6 performance metrics on CERNET2 which is the largest pure IPv6 network in the world presently. The final experiments show that it is necessary to implement a IPv6 network performance test system and that our system is scalable and available for IPv6 network performance test.},
  doi       = {10.1109/ICEMI.2007.4350633},
  keywords  = {IP networks;multi-agent systems;performance evaluation;CERNET2;IPv6 network performance;IPv6 performance metrics;Internet Engineering Task Force;multiagent;software support;Application software;Electronic equipment testing;IP networks;Instruments;Internet;Measurement;Performance analysis;Protocols;System testing;Throughput;IPv6;agent;multi-agent;network performance test},
}

@InProceedings{Sakamoto2002,
  author    = {M. Sakamoto and L. Brisson and A. Katsuno and A. Inoue and Y. Kimura},
  title     = {Reverse Tracer: a software tool for generating realistic performance test programs},
  booktitle = {Proceedings Eighth International Symposium on High Performance Computer Architecture},
  year      = {2002},
  pages     = {81-91},
  month     = {Feb},
  abstract  = {During the development of high-performance processors, software performance models are used to obtain performance estimates. These models are not cycle-accurate, so their results can have significant errors, leading to performance surprises after the hardware is built. Some performance tests can run directly on the logic simulators, to get more accurate results, but those simulators cannot run large interactive workloads with I/O and much operating system code. So the accurate performance estimates from logic simulators are only available for application code, and are not adequate for the evaluation of powerful server systems that are primarily intended to run large interactive workloads. We discuss a software tool system, the "Reverse Tracer", that generates executable performance tests from an instruction trace of the workload. The generated performance tests retain the essential performance characteristics of multi-user I/O-intensive workloads without doing any real I/O, so they can run in logic simulation to measure performance accurately before the hardware is built.},
  doi       = {10.1109/HPCA.2002.995700},
  issn      = {1530-0897},
  keywords  = {application generators;automatic test software;input-output programs;logic simulation;performance evaluation;software tools;virtual machines;Reverse Tracer;accurate performance measurement;application code;errors;executable performance tests;high-performance processors;instruction trace;large interactive workloads;logic simulators;multi-user I/O-intensive workloads;noncycle-accurate models;operating system code;performance estimates;realistic-performance test program generation;server systems;software performance models;software tool;Computer architecture;Software testing;Software tools},
}

@InProceedings{Malik2010a,
  author    = {H. Malik and B. Adams and A. E. Hassan},
  title     = {Pinpointing the Subsystems Responsible for the Performance Deviations in a Load Test},
  booktitle = {2010 IEEE 21st International Symposium on Software Reliability Engineering},
  year      = {2010},
  pages     = {201-210},
  month     = {Nov},
  abstract  = {Large scale systems (LSS) contain multiple subsystems that interact across multiple nodes in sometimes unforeseen and complicated ways. As a result, pinpointing the subsystems that are the source of performance degradation for a load test in LSS can be frustrating, and might take several hours or even days. This is due to the large volume of performance counter data collected such as CPU utilization, Disk I/O, memory consumption and network traffic, the limited operational knowledge of analysts about all subsystems of an LSS and the unavailability of up-to-date documentation in a LSS. We have developed a methodology that automatically ranks the subsystems according to the deviation of their performance in a load test. Our methodology uses performance counter data of a load test to craft performance signatures for the LSS subsystems. Pair-wise correlations among the performance signatures of subsystems within a load test are compared with the corresponding correlations in a baseline test to pinpoint the subsystems responsible for the performance violations. Case studies on load test data obtained from a large telecom system and that of an open source benchmark application show that our approach provides an accuracy of 79% and do not require any instrumentation or domain knowledge to operate.},
  doi       = {10.1109/ISSRE.2010.43},
  issn      = {1071-9458},
  keywords  = {large-scale systems;performance evaluation;program testing;craft performance signature;domain knowledge;large scale system;load test;open source benchmark;operational knowledge;pair wise correlation;performance deviation;user performance counter data;Correlation;Databases;Generators;Principal component analysis;Radiation detectors;Servers;Testing;Load Testing;Performance Counters;Pinpointing},
}

@InProceedings{Jiang2011,
  author    = {D. Jiang and M. Fei and H. Wang and T. Li},
  title     = {Wireless network performance test in hybrid wired/wireless network system},
  booktitle = {2011 9th World Congress on Intelligent Control and Automation},
  year      = {2011},
  pages     = {1029-1034},
  month     = {June},
  abstract  = {Recently, considerable researches on wireless networks have been carried in industrial automation. A great deal of wireless control and monitoring systems are introduced in certain problematic parts of the process industry to improve the productivity and efficiency. However, the control and monitor application requires high standard performances, such as reliability, real-timing and accuracy. Therefore a comprehensive performance assessment is needed to test the property of the wireless network so as to optimize the network protocol and improve the network communication quality. This paper studies the wireless network in the integrated wired/wireless fieldbus system and proposes a method to acquire a set of key indicators of wireless networks. Then, a test device is designed to acquire the performance indicators of the system. The wireless protocols are analysed according to the performance indicators. The results show that the test for the performance of wireless networks can be realized by the method mentioned.},
  doi       = {10.1109/WCICA.2011.5970672},
  keywords  = {field buses;performance evaluation;protocols;radio networks;hybrid wired/wireless network system;network communication quality;network protocol;performance assessment;process industry;productivity improvement;wireless control system;wireless network performance test;wireless protocol;Computers;Control systems;Performance evaluation;Protocols;Real time systems;Wireless networks;IEEE802.15.4A;Performance indicators;Protocol conversion;hybrid Wired/wireless networks},
}

@InProceedings{Xu2010,
  author    = {Wei Xu and Huigang Xu and Qi Xie and Yunfei Yang and Mei Dai},
  title     = {Design of automatic performance test system for CPS},
  booktitle = {2010 International Conference on Computer, Mechatronics, Control and Electronic Engineering},
  year      = {2010},
  volume    = {4},
  pages     = {206-209},
  month     = {Aug},
  abstract  = {In order to satisfy the needs of comprehensive and accurate performance test for CPS (Control and Protective Switching), an automatic performance test system was studied in this paper. The hardware structure and software was introduced in detail; the hardware system was made up of the industrial control computer, the three-phase current generator, adjustable single-phase power, pneumatic fixture, and so on. The test system software developed by LabVIEW was mainly used to achieve the functions of data acquisition, data processing and data display. The designed system is able to automatically test all functions of different types of CPS, including measurement function, communication function, multiple protection function, and so on. Practical application shows that the test system has following properties: high precision, low cost, strong anti-interference and convenient maintenance.},
  doi       = {10.1109/CMCE.2010.5610188},
  issn      = {2159-6026},
  keywords  = {automatic test software;virtual instrumentation;CPS;LabVIEW;adjustable single-phase power;automatic performance test system f;communication function;control and protective switching;data acquisition;data display;data processing;industrial control computer;measurement function;multiple protection function;pneumatic fixture;three-phase current generator;Educational institutions;Fixtures;Generators;Instruments;Software;Software reliability;CPS;LabVIEW;automatic test system;performance test},
}

@InProceedings{Plitschka1989,
  author    = {R. Plitschka},
  title     = {How to treat transmission line effects when testing high speed devices with a high performance test system},
  booktitle = {[1989] Proceedings of the 1st European Test Conference},
  year      = {1989},
  pages     = {78-85},
  month     = {Apr},
  abstract  = {State-of-the-art digital ASICs have even faster clock rates and signal transition times; testing these devices may cause problems regarding delivering the signals to the device under test (DUT) and precisely measuring the response of the DUT. Transmission-line techniques have to be applied to the tester-to-DUT interconnection in order to maintain signal fidelity. The author illustrates how to implement this critical signal path in a high-speed test system to get high-precision timing and level measurements, particularly for CMOS devices. The solution suggested to embed a CMOS device in a transmission-line environment is the resistive divider. The operating principle of the resistive divider is to apply a definable DC load to the DUT. This maintains signal fidelity, as the signal is fed into a parallel terminated system. Therefore no reflections occur},
  doi       = {10.1109/ETC.1989.36223},
  keywords  = {CMOS integrated circuits;application specific integrated circuits;automatic test equipment;automatic testing;digital integrated circuits;integrated circuit testing;CMOS devices;DC load;DUT;critical signal path;digital ASIC;digital ASICs;high performance test system;high speed devices;high-precision timing;high-speed test system;resistive divider;response;transmission line effects;Circuit testing;Coaxial components;Delay effects;Electronic equipment testing;Impedance;Integrated circuit interconnections;Low pass filters;Microstrip;System testing;Transmission lines},
}

@InProceedings{Xie2016,
  author    = {X. Xie and Z. Yang and J. Yu and W. Zhang},
  title     = {Design and implementation of bank financial business automation testing framework based on QTP},
  booktitle = {2016 5th International Conference on Computer Science and Network Technology (ICCSNT)},
  year      = {2016},
  pages     = {143-147},
  month     = {Dec},
  abstract  = {The current software testing in the aspects of industrial benefits gradually causes the attention of the domestic financial bank. The innovation of software technology, the increase of software scale and the shortened developing period make the traditional manual testing meeting enormous challenges, while the development of automated testing technology has promoted the progress of the software testing industry. Because of the particularity of financial and banking services, the bank is under an obligation to ensure the quality and reliability of software. Therefore it's vital to test the software. In specific practice, although the powerful third-party testing tools can be used as a solution, it is hard to rely on certain tool to implement automated testing, hence a framework of automated test is required to be introduced for testing, which intends to handle high efficiency and high-quality testing for software automation. This paper proposes a kind of software automation testing framework based on QTP, mainly targeting on the core of the bank, credit, online banking to test the function of the three major operations. The framework is a secondary development based on QTP and mainly for regression testing of software, which integrates techniques including object recognition, data-driven, and keyword-driven technology, checkpoint technology, to proceed business-level testing. The paper expatiated on four issues, which were the test system design, the test standardization, the testing framework design and the testing of the implementation. The practical application shows that the framework can improve the operational efficiency, reduce the test cost, and guarantee the smooth progress of the software automation testing.},
  doi       = {10.1109/ICCSNT.2016.8070136},
  keywords  = {bank data processing;object recognition;program testing;software quality;software reliability;QTP;automated testing technology;bank financial business automation testing framework;banking service;business-level testing;domestic financial bank;financial services;keyword-driven technology;object recognition;online banking;regression testing;software automation testing;software quality;software reliability;software scale;software technology;software testing industry;test cost;test standardization;test system design;testing framework design;third-party testing tools;Automation;Libraries;Object recognition;Software;Standardization;Testing;Tools;QTP automated testing tool;software testing;test automation framework},
}

@InProceedings{Roberts1997,
  author    = {D. C. Roberts and D. A. Grossman and O. Frieder and R. Bernstein and E. Bisfiop},
  title     = {Performance testing of communication protocols for three-tier computing: results for ICA and X window protocols},
  booktitle = {Proceedings of Sixth International Conference on Computer Communications and Networks},
  year      = {1997},
  pages     = {450-455},
  month     = {Sep},
  abstract  = {We present the results of performance tests to compare two protocols for three-tier computing using the Windows NT operating system. Three-tier computing features a data server for stored databases (Tier 1), an application server that runs applications (Tier 2), and a simple client program that runs on desktop machines that presents the user interface (Tier 3). Three protocols are available to communicate between Tier 2 and 3: intelligence computer architecture (ICA) with and without data compression, and X Window. We measured the performance of the three protocols in a multi-user environment in which we simulated the workload imposed by typical users. We found that, for Microsoft Office 97 and Lotus Notes applications, the X Window protocol uses approximately twice the network bandwidth of ICA, without compression. We also found that compressed ICA generates roughly one third less network traffic than uncompressed ICA at a cost of 20% of additional processor utilization},
  doi       = {10.1109/ICCCN.1997.623350},
  issn      = {1095-2055},
  keywords  = {client-server systems;computer architecture;data compression;network servers;performance evaluation;program testing;protocols;testing;ICA protocols;Lotus Notes applications;Microsoft Office 97;Tier 1;Tier 2;Tier 3;Windows NT operating system;X window protocols;application server;client program;communication protocols;data compression;data server;desktop machines;intelligence computer architecture;multi-user environment;network bandwidth;network traffic;performance testing;stored databases;three-tier computing;user interface;Application software;Computer architecture;Computer interfaces;Independent component analysis;Machine intelligence;Operating systems;Protocols;Spatial databases;System testing;User interfaces},
}

@InProceedings{Kiran2015,
  author    = {S. Kiran and A. Mohapatra and R. Swamy},
  title     = {Experiences in performance testing of web applications with Unified Authentication platform using Jmeter},
  booktitle = {2015 International Symposium on Technology Management and Emerging Technologies (ISTMET)},
  year      = {2015},
  pages     = {74-78},
  month     = {Aug},
  abstract  = {Unified Authentication platform is a Single sign-on (SSO) mechanism which is integrated into Web applications to remove the necessity for multiple application-specific login credentials. Unified Authentication platform (UAP) is a unique platform developed by MIMOS with capability to support multiple authentication mechanism and can be integrated to any Web application to provide Single Sign On (SSO) solution. Performance testing of such web applications using UAP poses some unique challenges because the Jmeter script does not capture all the dynamic values, such as SAML Request, Relay State, Signature Algorithm, Authorization State, Cookie Time, Persistent ID (PID), JSession ID and Shibboleth, generated using single sign-on mechanism of Unified Authentication Platform. This paper explains some of the challenges & experiences to identify an appropriate solution for conducting performance testing on such web application.},
  doi       = {10.1109/ISTMET.2015.7359004},
  keywords  = {Internet;authorisation;program testing;software performance evaluation;Jmeter script;MIMOS;SSO mechanism;UAP;Web applications;performance testing;single sign-on mechanism;unified authentication platform;Authentication;Browsers;Computer architecture;Generators;MIMO;Servers;Testing;Jmeter;Performance Testing;Single Sign-On;Unified Authentication Platform},
}

@InProceedings{Draheim2006,
  author    = {D. Draheim and J. Grundy and J. Hosking and C. Lutteroth and G. Weber},
  title     = {Realistic load testing of Web applications},
  booktitle = {Conference on Software Maintenance and Reengineering (CSMR'06)},
  year      = {2006},
  pages     = {11 pp.-70},
  month     = {March},
  abstract  = {We present a new approach for performing load testing of Web applications by simulating realistic user behaviour with stochastic form-oriented analysis models. Realism in the simulation of user behaviour is necessary in order to achieve valid testing results. In contrast to many other user models, Web site navigation and time delay are modelled stochastically. The models can be constructed from sample data and can take into account effects of session history on user behaviour and the existence of different categories of users. The approach is implemented in an existing architecture modelling and performance evaluation tool and is integrated with existing methods for forward and reverse engineering},
  doi       = {10.1109/CSMR.2006.43},
  issn      = {1534-5351},
  keywords  = {Web sites;delays;human factors;resource allocation;reverse engineering;software architecture;software performance evaluation;stochastic processes;Web application;Web site navigation;architecture modelling;forward engineering;load testing;performance evaluation tool;reverse engineering;stochastic form-oriented analysis models;time delay;user behaviour;Analytical models;Application software;Computational modeling;Computer science;Delay effects;Navigation;Performance evaluation;Software testing;Software tools;Stochastic processes},
}

@InProceedings{Kamra2012,
  author    = {M. Kamra and R. Manna},
  title     = {Performance of Cloud-Based Scalability and Load with an Automation Testing Tool in Virtual World},
  booktitle = {2012 IEEE Eighth World Congress on Services},
  year      = {2012},
  pages     = {57-64},
  month     = {June},
  abstract  = {The development in cloud computing provides limitless capacity which provides opportunity to evaluate an application performance based on its nature to scale. This paper aims at the analysis of Performance using the Google App Engine(cloud computing paradigm). Virtual Office application is chosen as example to perform experiment of testing the scalability in turn maintaining the performance. An Automation Testing Tool - Test Harness has been used to perform the scale testing of the application while being deployed on the cloud. Results have seen shown in the form of request type and response times(Average time taken/request). Taken into account the consideration that when the application load goes up the Google Cloud expands(increases instance hours) without affecting the running application.},
  doi       = {10.1109/SERVICES.2012.54},
  issn      = {2378-3818},
  keywords  = {Web sites;cloud computing;program testing;software performance evaluation;Google App Engine;application performance;automation testing tool;cloud computing;cloud-based scalability;scale testing;test harness;virtual office application;virtual world;Automation;Cloud computing;Google;Scalability;Servers;Teleworking;Testing;API;CPU;GAE;QPS},
}

@InProceedings{Tang2008,
  author    = {Jingfan Tang and Xiaohua Cao and A. Ma},
  title     = {Towards adaptive framework of keyword driven automation testing},
  booktitle = {2008 IEEE International Conference on Automation and Logistics},
  year      = {2008},
  pages     = {1631-1636},
  month     = {Sept},
  abstract  = {This paper presents an adaptive framework of keyword-driven automation testing to support the conversion of the keyword-based test cases into different kinds of test scripts automatically to be executed by different test applications under different test environments (such as GUI environment, database environment, etc.). XML is used to describe the keyword-based commands for the test case. An engine is provided in this framework to parse the XML file and dispatch the command sequences to the different test drivers according to the driver type pre-defined in the command. The test driver is responsible for dispatching the commands to the corresponding test applications to generate the test scripts automatically according to the keywords in the commands. The test scripts will be executed by the test applications on the system-under-test under different test environments. All the test results will be recorded into a log repository for generating all kinds of the test reports.},
  doi       = {10.1109/ICAL.2008.4636415},
  issn      = {2161-8151},
  keywords  = {XML;program compilers;program testing;XML file parsing;adaptive framework;automation engine layer;keyword driven automation testing;keyword-based command sequence;keyword-based test case conversion;log repository;test driver layer;test execution layer;test report;test script;Application software;Automatic testing;Databases;Educational institutions;Graphical user interfaces;Logistics;Robotics and automation;Software testing;System testing;XML;Keyword Driven;adaptive;automation testing},
}

@InProceedings{Jayasinghe2012,
  author    = {D. Jayasinghe and G. Swint and S. Malkowski and J. Li and Q. Wang and J. Park and C. Pu},
  title     = {Expertus: A Generator Approach to Automate Performance Testing in IaaS Clouds},
  booktitle = {2012 IEEE Fifth International Conference on Cloud Computing},
  year      = {2012},
  pages     = {115-122},
  month     = {June},
  abstract  = {Cloud computing is an emerging technology paradigm that revolutionizes the computing landscape by providing on-demand delivery of software, platform, and infrastructure over the Internet. Yet, architecting, deploying, and configuring enterprise applications to run well on modern clouds remains a challenge due to associated complexities and non-trivial implications. The natural and presumably unbiased approach to these questions is thorough testing before moving applications to production settings. However, thorough testing of enterprise applications on modern clouds is cumbersome and error-prone due to a large number of relevant scenarios and difficulties in testing process. We address some of these challenges through Expertus---a flexible code generation framework for automated performance testing of distributed applications in Infrastructure as a Service (IaaS) clouds. Expertus uses a multi-pass compiler approach and leverages template-driven code generation to modularly incorporate different software applications on IaaS clouds. Expertus automatically handles complex configuration dependencies of software applications and significantly reduces human errors associated with manual approaches for software configuration and testing. To date, Expertus has been used to study three distributed applications on five IaaS clouds with over 10,000 different hardware, software, and virtualization configurations. The flexibility and extensibility of Expertus and our own experience on using it shows that new clouds, applications, and software packages can easily be incorporated.},
  doi       = {10.1109/CLOUD.2012.98},
  issn      = {2159-6182},
  keywords  = {cloud computing;program compilers;program testing;software packages;Expertus;IaaS clouds;Infrastructure as a Service;Internet;automated performance testing;cloud computing;distributed applications;enterprise applications;generator approach;multipass compiler approach;software packages;template-driven code generation;Automation;Cloud computing;Clouds;Testing;Weaving;XML;Aspect;Automation;Clouds;Code Generation;Datacenter;EC2;Emulab;IaaS;Multi-Tier;Open Cirrus;Performance;Scalability;Template;Testing},
}

@InProceedings{Putri2017,
  author    = {M. A. Putri and H. N. Hadi and F. Ramdani},
  title     = {Performance testing analysis on web application: Study case student admission web system},
  booktitle = {2017 International Conference on Sustainable Information Engineering and Technology (SIET)},
  year      = {2017},
  pages     = {1-5},
  month     = {Nov},
  abstract  = {Websites usage for universities selection entrance (admission) are most visited websites in daily activity, thus its performance is critical. The ability of web applications either to control or to process users' requests determines its reliability. Furthermore, those websites which process students admission in Universitas Brawijaya and Politeknik Negeri Malang certainly engage massive volume of data and information that requires the highest level of reliability. Therefore, there is absolutely needed appropriate testing performances to measure the level of a certain application based on reliability rate. This measurement is used to determine responses, throughput, capability, and system scalability upon workload given. This research has a contribution to present testing performance concepts, goals, targets, types, and tools of Apache JMeter which is engaged for web assessment including detects mistake and error that relates to application performance and helps to improve the level of application performance as expected.},
  doi       = {10.1109/SIET.2017.8304099},
  keywords  = {Internet;Web services;Web sites;educational institutions;Politeknik Negeri Malang;Universitas Brawijaya;application performance;appropriate testing performances;daily activity;performance testing analysis;process students admission;reliability rate;student admission web system;system scalability;testing performance concepts;universities selection entrance;users;web application;websites usage;Computer science;Reliability;Servers;Software;Stress;Testing;Tools;jmeter;performance testing;testing;website},
}

@InProceedings{Abbas2017,
  author    = {R. Abbas and Z. Sultan and S. N. Bhatti},
  title     = {Comparative analysis of automated load testing tools: Apache JMeter, Microsoft Visual Studio (TFS), LoadRunner, Siege},
  booktitle = {2017 International Conference on Communication Technologies (ComTech)},
  year      = {2017},
  pages     = {39-44},
  month     = {April},
  abstract  = {Software testing is the process of testing, verifying and validating the user's requirements. During whole software development, testing is an ongoing process. Black Box, White Box testing and grey box testing are the three main types of software testing. In Black box testing, user doesn't know intrinsic logics and design of system. In white box testing, Tester knows the intrinsic logic of code. In Grey box testing, Tester has little bit knowledge about the internal structure, code and working of the system. It is commonly used in case of Integration testing. Load testing is the type of testing which helps us to analyze the performance of the system under heavy load or under Zero load. With the help of a automated load Testing Tools, we can do it in better way. The intention for writing this research is to carry out a comparison of four automated load testing tools i.e. Apache JMeter, HP LoadRunner, Microsoft Visual Studio (TFS), Siege based on certain criteria i.e. test scripts generation, plug-in support, result reports, application support and cost. The main focus is to study and analyze these load testing tools and identify which tool is best and more efficient [10]. We assume this comparative analysis can help in selecting the most appropriate tool and motivates the use of open source load testing tools.},
  doi       = {10.1109/COMTECH.2017.8065747},
  keywords  = {program testing;public domain software;software tools;Black box testing;Integration testing;LoadRunner;Microsoft Visual Studio;Siege;TFS;Zero load;apache JMeter;application support;automated load testing tools;comparative analysis;grey box testing;heavy load;intrinsic logic;open source load testing tools;plug-in support;result reports;software testing;test scripts generation;white box testing;Automation;Manuals;Software;Software testing;Tools;Visualization;Testing;automated testing;load testing;manual testing;stress test;testing tools},
}

@InProceedings{Duttagupta2011,
  author    = {S. Duttagupta and R. Mansharamani},
  title     = {Extrapolation tool for load testing results},
  booktitle = {2011 International Symposium on Performance Evaluation of Computer Telecommunication Systems},
  year      = {2011},
  pages     = {69-76},
  month     = {June},
  abstract  = {Load testing of IT applications is fraught with the challenges of time to market, quality of results, high cost of commercial tools, and accurately representing production like scenarios. It would help IT projects to be able to test with a small number of users and extrapolate to scenarios with much larger number of users. This in turn will cut down cycle times and costs and allow for a variety of extrapolations closer to production. We present a simple extrapolation technique based on statistical empirical modeling, which we have found to be more than 90% accurate across a range of applications running across a number of hardware servers. The technique has currently been validated for scenarios where the hardware is the bottleneck and is extensible to a wider range of scenarios as well.},
  keywords  = {extrapolation;program testing;statistical analysis;IT applications;IT projects;extrapolation tool;load testing results;statistical empirical modeling;Extrapolation;Linear regression;Load modeling;Servers;Testing;Throughput;Time factors;Extrapolation;S-Curves;load testing;regression},
}

@InProceedings{Underbrink2012,
  author    = {A. Underbrink and A. Potter and H. Jaenisch and D. J. Reifer},
  title     = {Application stress testing Achieving cyber security by testing cyber attacks},
  booktitle = {2012 IEEE Conference on Technologies for Homeland Security (HST)},
  year      = {2012},
  pages     = {556-561},
  month     = {Nov},
  abstract  = {Application stress testing applies the concept of computer network penetration testing to software applications. Since software applications may be attacked - from inside or outside a protected network boundary - they are threatened by actions and conditions which cause delays, disruptions, or failures. Stress testing exposes software systems to simulated cyber attacks, revealing potential weaknesses and vulnerabilities in their implementation. By using such testing, these internal weaknesses and vulnerabilities can be discovered earlier in the software development life cycle, corrected prior to deployment, and lead to improved software quality. Application stress testing is a process and software prototype for verifying the quality of software applications under severe operating conditions. Since stress testing is rarely - if at all - performed today, the possibility of deploying critical software systems that have been stress tested provides a much stronger indication of their ability to withstand cyber attacks. Many possible attack vectors against critical software can be verified as true threats and mitigated prior to deployment. This improves software quality and serves as a tremendous risk reduction for critical software systems used in government and commercial enterprises. The software prototype models and verifies failure conditions of a system under test (SUT). The SUT is first executed in a virtual environment and its normal operational modes are observed. A normal behavior model is generated in order to predict failure conditions based on attack models and external SUT interfaces. Using off-the-shelf software tools, the predictions are verified in the virtual environment by stressing the executing SUT with attacks against the SUT. Results are presented to testers and system developers for dispensation or mitigation.},
  doi       = {10.1109/THS.2012.6459909},
  keywords  = {computer network security;program testing;program verification;risk analysis;safety-critical software;software prototyping;software quality;software tools;virtual reality;SUT;application stress testing;commercial enterprises;computer network penetration testing;critical software system;cyber attack testing;cyber security;delay;failure analysis;formal verification;government enterprises;off-the-shelf software tools;potential weaknesses revealing;protected network boundary;risk reduction;software application;software development life cycle;software prototype model;software quality;software systems;software vulnerability;system under test;virtual environment;Databases;Monitoring;Prototypes;Software systems;Stress;Testing;application testing;attack;penetration testing;softwaer quality;software assurance},
}

@InProceedings{Parker1992,
  author    = {T. P. Parker and C. W. Webb},
  title     = {A study of failures identified during board level environmental stress testing},
  booktitle = {1992 Proceedings 42nd Electronic Components Technology Conference},
  year      = {1992},
  pages     = {177-184},
  month     = {May},
  abstract  = {AT&T has investigated and implemented environmental stress testing (EST) in the production of a variety of circuit board designs as a means of reducing the incidence of early life failures. EST techniques include thermal cycling, random vibration, and others. These techniques have proven more effective than traditional burn-in techniques. In addition, studies have revealed that functional monitoring during thermal stressing of circuit cards more than doubles the effectiveness of EST. Outgoing quality audits and customer first month failure rates have improved by factors of two to four since the implementation of EST},
  doi       = {10.1109/ECTC.1992.204204},
  keywords  = {environmental testing;failure analysis;life testing;printed circuit testing;production testing;EST techniques;board level environmental stress testing;circuit board designs;early life failures;first month failure rates;functional monitoring;random vibration;thermal cycling;Application software;Assembly;Circuit testing;Failure analysis;Life testing;Manufacturing processes;Printed circuits;Production;Thermal stresses;Total quality management},
}

@InProceedings{Chen2015,
  author    = {Xi Chen and Hao Guo and P. Crossley},
  title     = {Performance testing of IEC 61850 based architecture for UK National Grid standardised Substation automation solutions},
  booktitle = {2015 IEEE Power Energy Society General Meeting},
  year      = {2015},
  pages     = {1-5},
  month     = {July},
  abstract  = {Traditional protection and control systems in many UK National Grid Substations are reaching the end of their asset design life. This provides an opportunity to investigate whether new architecture that deploys Intelligent Electronic Device (IED) technology can deliver a reliable solution that is economically appropriate and delivers long life. The application of IEDs that utilize the IEC61850 based process bus reduces the life-time cost of the secondary systems and improves flexibility and functionality by accommodating high-speed peer-to-peer communications. The interconnectivity of devices on a single network offers significant benefits including a plug and play approach to future system changes. However, it requires interoperability among multi-vendor protection relays and control devices over an operating life of many decades. The realisation of this requires significant and detailed testing to help National Grid gain confidence in the use of these technologies. In this paper the substation architecture and the associated Power Networks are modelled in RTDS with faults applied at different locations on the transmission lines. The paper presents the results of interoperability tests involving multi-vendor Merging Unit (MU) and IED devices, which are then used to evaluate the functional performance of distance protection schemes.},
  doi       = {10.1109/PESGM.2015.7286553},
  issn      = {1932-5517},
  keywords  = {open systems;power grids;relay protection;substation automation;substation protection;IEC61850 based process bus;IED technology;RTDS;UK National Grid Standardised Substation automation solutions;asset design life;control devices;distance protection schemes;high-speed peer-to-peer communications;intelligent electronic device technology;interoperability tests;lifetime cost;multi-vendor merging unit;multi-vendor protection relays;plug and play approach;power networks;secondary systems;transmission lines;Circuit faults;IEC Standards;Interoperability;Merging;Substations;Tagging;IEC61850;Interoperability;Power System Reliability;Substation Automation;Substation Protection},
}

@InProceedings{Mahmoudi1997,
  author    = {R. Mahmoudi and J. L. Tauritz},
  title     = {Performance testing of the North American CDMA system, using an envelope simulator},
  booktitle = {Proceedings of 1997 Wireless Communications Conference},
  year      = {1997},
  pages     = {84-88},
  month     = {Aug},
  abstract  = {The growing use of spread spectrum techniques for personal communications (PCS) in Japan and USA is proving to be an enormous stimulus for the study of system impact on component design. New and innovative techniques are required to translate system criteria into component specifications. In this paper we have studied the performance of the “North American Digital Cellular IS-95” system proposed by QUALCOMM, under the influence of spurious signals using the new “Circuit Envelope Simulator” in HP-EESOF's Microwave Design System, MDS. The implemented functional blocks facilitate the generation of proper (noisy) CDMA (reverse and forward) signals, which are then used to program an arbitrary wave generator in order to create actual test signals. Additionally, these functional blocks can be replaced with equivalent circuits, consisting of passive and active elements, etc. For illustrative purposes, we discuss the application of these signals to two real amplifiers, one linear and one nonlinear. The measured results are critically compared with the simulation results},
  doi       = {10.1109/WCC.1997.622253},
  keywords  = {cellular radio;code division multiple access;digital radio;digital simulation;personal communication networks;spread spectrum communication;telecommunication equipment testing;Circuit Envelope Simulator;HP-EESOF's Microwave Design System;North American CDMA system;North American Digital Cellular IS-95;QUALCOMM;equivalent circuits;functional blocks;linear amplifiers;nonlinear amplifier;performance testing;personal communications;spread spectrum techniques;Circuit noise;Circuit simulation;Circuit testing;Multiaccess communication;Noise generators;Personal communication networks;Signal design;Signal generators;Spread spectrum communication;System testing},
}

@InProceedings{Yan2012,
  author    = {M. Yan and H. Sun and X. Wang and X. Liu},
  title     = {Building a TaaS Platform for Web Service Load Testing},
  booktitle = {2012 IEEE International Conference on Cluster Computing},
  year      = {2012},
  pages     = {576-579},
  month     = {Sept},
  abstract  = {Web services are widely known as the building blocks of typical service oriented applications. The performance of such an application system is mainly dependent on that of component web services. Thus the effective load testing of web services is of great importance to understand and improve the performance of a service oriented system. However, existing Web Service load testing tools ignore the real characteristics of the practical running environment of a web service, which leads to inaccurate test results. In this work, we present WS-TaaS, a load testing platform for web services, which enables load testing process to be as close as possible to the real running scenarios. In this way, we aim at providing testers with more accurate performance testing results than existing tools. WS-TaaS is developed on the basis of our existing Cloud PaaS platform: Service4All. First, we provide detailed analysis of the requirements of Web Service load testing and present the conceptual architecture and design of key components. Then we present the implementation details of WS-TaaS on the basis of Service4All. Finally, we perform a set of experiments based on the testing of real web services, and the experiments illustrate that WS-TaaS can efficiently facilitate the whole process of Web Service load testing.},
  doi       = {10.1109/CLUSTER.2012.20},
  issn      = {1552-5244},
  keywords  = {Web services;cloud computing;program testing;software tools;Cloud PaaS platform;Service4All;TaaS platform;WS-TaaS;Web service load testing tools;load testing platform;service oriented system;typical service oriented applications;Cloud computing;Computer architecture;Monitoring;Testing;cloud computing;load testing;testing as a service;web services},
}

@InProceedings{Xu2010b,
  author    = {L. Xu and W. Zhang and L. Chen},
  title     = {Modeling Users' Visiting Behaviors for Web Load Testing by Continuous Time Markov Chain},
  booktitle = {2010 Seventh Web Information Systems and Applications Conference},
  year      = {2010},
  pages     = {59-64},
  month     = {Aug},
  abstract  = {Virtual users with high quality are the preconditions to ensure the effect of load testing for Web applications. The existed tools for load testing usually generate virtual users with randomly choosing user sessions, manually generating user sessions or mining Log files, which causing such problems as non-real workload, subjectivity or difficult to update. Therefore we set each virtual user with a corresponding configure file, and these files determine the visiting paths, visiting moments and stay time of virtual users based on the Continuous Time Markov Chain. So we firstly finish the pretreatment for Log files, then construct the user visiting model, and next generate the virtual users, lastly carry out the load testing. In this way, we can obtain more reliable results for Web application load testing than the existed methods.},
  doi       = {10.1109/WISA.2010.47},
  keywords  = {Markov processes;Web services;data mining;program testing;virtual reality;Web load testing;continuous time Markov chain;log files mining;user visiting model;virtual users;Electromagnetic compatibility;Load modeling;Markov processes;Testing;Time factors;Web pages;Continuous Time Markov Chain;load testing;virtual user},
}

@InProceedings{Nagowah2012,
  author    = {L. Nagowah and G. Sowamber},
  title     = {A novel approach of automation testing on mobile devices},
  booktitle = {2012 International Conference on Computer Information Science (ICCIS)},
  year      = {2012},
  volume    = {2},
  pages     = {924-930},
  month     = {June},
  abstract  = {Mobile phones and mobile applications have now become an integral part of our everyday life. Mobile application testing plays a pivotal role in making the mobile applications more reliable and defect free. Existing test automation tools have been tailored to perform mobile test automation through mobile emulators. Other tools require the mobile device where the application is installed, to be connected to a computer so that the tests can be run. Obviously, the results obtained from emulators often differ from those obtained on actual mobile devices. To our best knowledge only a few solutions for creating automated tests of mobile applications exist and their functionality is very limited. In this paper, we introduce the idea of implementing a mobile test automation framework MobTAF which performs mobile test automation on the mobile device where connection to a computer is not required. The framework moves the testing infrastructure to the phone, to support test situations that cannot easily be replicated with an emulator. A prototype application was then implemented to test the mobile automation framework, MobTAF. The results prove that MobTAF framework is an efficient way of performing mobile application tests directly on the mobile devices.},
  doi       = {10.1109/ICCISci.2012.6297158},
  keywords  = {mobile computing;mobile handsets;program testing;MobTAF framework;automated tests;automation testing;defect free;mobile application testing;mobile devices;mobile emulators;mobile phones;mobile test automation framework;prototype application;test automation tools;testing infrastructure;Automation;Generators;Layout;Mobile communication;Robustness;Testing;XML;mobile application testing;mobile device test automation;mobile test automation framework;mobile testing;software testing},
}

@InProceedings{Krizanic2010,
  author    = {J. Križanić and A. Grgurić and M. Mošmondor and P. Lazarevski},
  title     = {Load testing and performance monitoring tools in use with AJAX based web applications},
  booktitle = {The 33rd International Convention MIPRO},
  year      = {2010},
  pages     = {428-434},
  month     = {May},
  abstract  = {In order to deliver quality assured software and avoid potential costs caused by unstable software, software testing is essential in software lifecycle. Load testing is one of the testing types with high importance. It is usually accompanied by performance monitoring of the hosting environment. In the case of web applications which are today widely used, one fact is obvious: most of web applications are public and used by vast number of users, which are making a considerable traffic load on hosting environments and web applications. Load testing and performance monitoring become facilitated with existing tools aimed for load testing and performance monitoring. In the paper we analyze and compare several existing tools which facilitate load testing and performance monitoring, in order to find the most appropriate tools by criteria such as ease of use, supported features, and license. Selected tools were put in action in the real environment, through several web applications. For the case study one of the web applications is used in order to introduce different capabilities of tools, including distributed testing, assembling of test scenario from previously recorded usage scenarios, security support, results analysis, monitoring of key parameters, and reporting and alerting about changes of these parameters.},
  keywords  = {Application software;Assembly;Costs;Licenses;Monitoring;Performance analysis;Security;Software quality;Software testing;Telecommunication traffic;AJAX;load testing;performance monitoring;web applications},
}

@InProceedings{Amirante2016,
  author    = {A. Amirante and T. Castaldi and L. Miniero and S. P. Romano},
  title     = {Jattack: a WebRTC load testing tool},
  booktitle = {2016 Principles, Systems and Applications of IP Telecommunications (IPTComm)},
  year      = {2016},
  pages     = {1-6},
  month     = {Oct},
  abstract  = {We present Jattack, an automated stressing tool for the analysis of the performance of WebRTC-enabled server-side components. Jattack has been initially conceived with the primary objective of performing a thorough scalability analysis of the well-known Janus WebRTC gateway. As such, it re-uses most of the Janus core stack components in order to reliably emulate the behavior of a dynamically adjustable number of WebRTC clients. The specific testing .scenario can indeed be programmatically reproduced by writing a small "controller" component, which takes on the responsibility of properly orchestrating the scenario itself. The general-purpose nature of the tool, together with its flexibility deriving from the controller-based programmable approach, makes Jattack also suitable for stress-testing other WebRTC-enabled servers.},
  keywords  = {Internet;program testing;Jattack;WebRTC load testing tool;WebRTC-enabled server-side components;automated stressing tool;stress-testing;Browsers;Media;Scalability;Servers;Stress;Testing;WebRTC},
}

@InProceedings{Malik2013,
  author    = {H. Malik and H. Hemmati and A. E. Hassan},
  title     = {Automatic detection of performance deviations in the load testing of Large Scale Systems},
  booktitle = {2013 35th International Conference on Software Engineering (ICSE)},
  year      = {2013},
  pages     = {1012-1021},
  month     = {May},
  abstract  = {Load testing is one of the means for evaluating the performance of Large Scale Systems (LSS). At the end of a load test, performance analysts must analyze thousands of performance counters from hundreds of machines under test. These performance counters are measures of run-time system properties such as CPU utilization, Disk I/O, memory consumption, and network traffic. Analysts observe counters to find out if the system is meeting its Service Level Agreements (SLAs). In this paper, we present and evaluate one supervised and three unsupervised approaches to help performance analysts to 1) more effectively compare load tests in order to detect performance deviations which may lead to SLA violations, and 2) to provide them with a smaller and manageable set of important performance counters to assist in root-cause analysis of the detected deviations. Our case study is based on load test data obtained from both a large scale industrial system and an open source benchmark application. The case study shows, that our wrapper-based supervised approach, which uses a search-based technique to find the best subset of performance counters and a logistic regression model for deviation prediction, can provide up to 89% reduction in the set of performance counters while detecting performance deviations with few false positives (i.e., 95% average precision). The study also shows that the supervised approach is more stable and effective than the unsupervised approaches but it has more overhead due to its semi-automated training phase.},
  doi       = {10.1109/ICSE.2013.6606651},
  issn      = {0270-5257},
  keywords  = {input-output programs;program testing;public domain software;regression analysis;software performance evaluation;unsupervised learning;CPU utilization;LSS;SLA violations;automatic performance deviation detection;deviation prediction;disk I-O;large scale systems;load testing;logistic regression model;machine learning;memory consumption;network traffic;open source benchmark application;performance counters;root-cause analysis;run-time system properties;search-based technique;service level agreements;wrapper-based supervised approach;Control charts;Large-scale systems;Logistics;Monitoring;Principal component analysis;Radiation detectors;Testing;Machine Learning;Performance;Signature},
}

@InProceedings{Barros2007,
  author    = {M. D. Barros and J. Shiau and C. Shang and K. Gidewall and H. Shi and J. Forsmann},
  title     = {Web Services Wind Tunnel: On Performance Testing Large-Scale Stateful Web Services},
  booktitle = {37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)},
  year      = {2007},
  pages     = {612-617},
  month     = {June},
  abstract  = {New versions of existing large-scale web services such as Passport.comcopy have to go through rigorous performance evaluations in order to ensure a high degree of availability. Performance testing (such as benchmarking, scalability, and capacity tests) of large-scale stateful systems in managed test environments has many different challenges, mainly related to the reproducibility of production conditions in live data centers. One of these challenges is creating a dataset in a test environment that mimics the actual dataset in production. Other challenges involve the characterization of load patterns in production based on log analysis and proper load simulation via reutilization of data from the existing dataset. The intent of this paper is to describe practical approaches to address some of the aforementioned challenges through the use of various novel techniques. For example, this paper discusses data sanitization, which is the alteration of large datasets in a controlled manner to obfuscate sensitive information, preserving data integrity, relationships, and data equivalence classes. This paper also provides techniques for load pattern characterization via the application of Markov chains to custom and generic logs, as well as general guidelines for the development of cache-based load simulation tools tailored for the performance evaluation of stateful systems.},
  doi       = {10.1109/DSN.2007.102},
  issn      = {1530-0889},
  keywords  = {Web services;program testing;security of data;software performance evaluation;Markov chains;Web services wind tunnel;cache-based load simulation tools;data integrity;data sanitization;log analysis;performance testing;Availability;Benchmark testing;Environmental management;Large-scale systems;Pattern analysis;Production systems;Reproducibility of results;Scalability;System testing;Web services},
}

@InProceedings{Rodrigues2015,
  author    = {E. Rodrigues and M. Bernardino and L. Costa and A. Zorzo and F. Oliveira},
  title     = {PLeTsPerf - A Model-Based Performance Testing Tool},
  booktitle = {2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)},
  year      = {2015},
  pages     = {1-8},
  month     = {April},
  abstract  = {Performance testing is a highly specialized task, since it requires that a performance engineer knows the application to be tested, its usage profile, and the infrastructure where it will execute. Moreover, it requires that testing teams expend a considerable effort and time on its automation. In this paper, we present the PLeTsPerf, a model-based performance testing tool to support the automatic generation of scenarios and scripts from application models. PLetsPerf is a mature tool, developed in collaboration with an IT company, which has been used in several works, experimental studies and pilot studies. We present an example of use to demonstrate the process of generating test scripts and scenarios from UML models to test a Web application. We also present the lessons learned and discuss our conclusions about the use of the tool.},
  doi       = {10.1109/ICST.2015.7102628},
  issn      = {2159-4848},
  keywords  = {Internet;program testing;PLeTsPerf tool;UML model;Unified Modeling Language;Web application;model-based performance testing tool;scenario generation;script generation;Companies;Generators;Load modeling;Software;Testing;Unified modeling language;Visualization},
}

@InProceedings{Mercer2011,
  author    = {A. J. Mercer and R. K. James and G. Bennett and P. Patel and C. Johnston and J. Cai},
  title     = {Performance testing of RFID systems with RF-harsh materials},
  booktitle = {2011 IEEE International Conference on RFID-Technologies and Applications},
  year      = {2011},
  pages     = {537-543},
  month     = {Sept},
  abstract  = {Radio Frequency Identification (RFID) has been adopted to track items in supply chain, healthcare, and manufacturing applications. Hospitals and factories, however, are difficult environments for radiowave propagation. Cinder block walls with steel rebar, metal obstructions, and RF noise present significant obstacles to RFID system performance. Tagging lossy materials in these environments, such as metals and liquids, can also degrade the performance of RFID systems. In a previous paper [1] we simulated the RF-harsh conditions prevalent in these environments to evaluate UHF RFID system performance. In this paper, we utilize the same laboratory environment to measure RFID system performance when RF-harsh materials are tagged. These tests serve to examine the effect of water and plastic car parts on RFID system performance in an RF harsh environment. We show that the problems posed when tagging RF-harsh materials can be mitigated with either the strategic placement of tags on the item, or the careful choice of tags. While UHF RFID systems can be used in the presence of RF-harsh circumstances, the system architecture must be carefully tested in order to minimize the effects of performance-hindering RF obstacles.},
  doi       = {10.1109/RFID-TA.2011.6068597},
  keywords  = {radiofrequency identification;radiowave propagation;RF-harsh materials;UHF RFID system;performance testing;radio frequency identification;radiowave propagation;Antennas;Belts;Materials;Metals;Radio frequency;Radiofrequency identification;RFID;UHF (Ultra High Frequency);automotive materials;liquids;manufacturing;materials testing;multipath;performance evaluation;radio;radiowave propagation},
}

@InProceedings{Sidhu2011,
  author    = {T. Sidhu and M. Kanabar and P. Parikh},
  title     = {Configuration and performance testing of IEC 61850 GOOSE},
  booktitle = {2011 International Conference on Advanced Power System Automation and Protection},
  year      = {2011},
  volume    = {2},
  pages     = {1384-1389},
  month     = {Oct},
  abstract  = {The IEC 61850 standard part 8-1 proposes Generic Object Oriented Substation Event (GOOSE) message for time critical applications over the Ethernet network. In order to cover the wide range of applications and achieve flexibility in implementation, GOOSE messages are kept generic in the standard. However, this flexibility leads to configuration problem achieving multi-vendor interoperability. Therefore, some efforts have been carried out in this work to present a systematic GOOSE configuration approach, as well as, verification and performance testing of the GOOSE. First part of this paper configuration of Ethernet switched network, including IEEE 1588 based time synchronization, Rapid Spanning Tree Protocol (RSTP), and IEEE 802.1Q based Quality of Services (QoS). In the second part, the paper leads to step-by-step configuration process comprising IEC 61850 data modeling, datasets of GOOSE within individual IEDs, and system integration of GOOSE. Finally, the verification of configured GOOSE messages is presented using network analyzer tools, and performance testing time delay) over the network is carried out for various network scenarios.},
  doi       = {10.1109/APAP.2011.6180593},
  keywords  = {local area networks;object-oriented methods;open systems;power engineering computing;quality of service;substation automation;synchronisation;Ethernet switched network;IEC 61850 GOOSE performance testing;IEC 61850 data modeling;IEEE 1588 based time synchronization;IEEE 802.1Q based quality of services;QoS;RSTP;generic object oriented substation event message;multivendor interoperability;network analyzer tools;rapid spanning tree protocol;substation automation systems;systematic GOOSE configuration approach;Automation;Bridges;Data models;IEC standards;Power systems;Switches;Testing;Ethernet switched networks;GOOSE;IEC 61850;substation automation systems},
}

@InProceedings{Yao2012,
  author    = {Y. Yao and X. Wang},
  title     = {A distributed, cross-platform automation testing framework for GUI-driven applications},
  booktitle = {Proceedings of 2012 2nd International Conference on Computer Science and Network Technology},
  year      = {2012},
  pages     = {723-726},
  month     = {Dec},
  abstract  = {With the rapid development of computer technology, nowadays GUIs have been widely used in desktop applications and web applications. GUI-driven application testing is an emergent approach to software testing and plays a key role to assure software quality. This paper first discusses the various methods for testing GUI-driven applications, and then defines a GUI model and formally defines the test case and the test suite. Finally, it proposes a novel automated, distributed and cross-platform testing framework for GUI. Experiments conducted showed that the proposed testing architecture managed to use parallel cross-platform clusters to test heterogeneous applications whose technologies were incompatible with the testing framework.},
  doi       = {10.1109/ICCSNT.2012.6526035},
  keywords  = {Internet;graphical user interfaces;program testing;software architecture;software quality;GUI model;GUI-driven application testing;Web applications;computer technology;cross-platform automation testing framework;desktop applications;distributed automation testing framework;graphical user interfaces;parallel cross-platform clusters;software quality assurance;software testing;test case;test suite;testing architecture;GUI-driven applications;automation testing;cross-platform testing;distributed testing framework},
}

@InProceedings{Naheman2013,
  author    = {W. Naheman and Jianxin Wei},
  title     = {Review of NoSQL databases and performance testing on HBase},
  booktitle = {Proceedings 2013 International Conference on Mechatronic Sciences, Electric Engineering and Computer (MEC)},
  year      = {2013},
  pages     = {2304-2309},
  month     = {Dec},
  abstract  = {NoSQL (Not Only SQL) is the generic term of a kind of non-relational database products. This paper, firstly, lists the disadvantages of traditional relational databases, introduces NoSQL databases including their advantages, disadvantages and their application status. Then, a comparison is made between NoSQL databases and SQL database, also another comparison between different NoSQL products. Finally, we introduce the architecture and data model of HBase database, which is a representative of NoSQL databases, and did some performance tests on HBase database, including the column family test, the sort test, the random read/write test and the query test. Test results show that written and query speed of HBase is slow under a single machine environment, but can be significantly improved in multimachine cluster environment.},
  doi       = {10.1109/MEC.2013.6885425},
  keywords  = {SQL;data models;relational databases;software performance evaluation;HBase database;HBase performance testing;NoSQL databases;Not Only SQL database;SQL database;column family test;data model;machine cluster environment;nonrelational database products;query test;random read-write test;single machine environment;sort test;Availability;Blogs;Computer architecture;Distributed databases;Manuals;HBase;NoSQL databases;performance testing;relational database},
}

@InProceedings{Kreit2010,
  author    = {F. Kreit and G. Barberio and C. Subramanian and I. Kostanic and J. P. Pinelli},
  title     = {Performance Testing of the Wireless Sensor Network System for Hurricane Monitoring},
  booktitle = {2010 First International Conference on Sensor Device Technologies and Applications},
  year      = {2010},
  pages     = {63-72},
  month     = {July},
  abstract  = {A wireless pressure monitoring system was developed by Florida Institute of Technology to measure wind induced pressure on low-rise structures during hurricanes. This study presents tests made to evaluate the performance of the sensors and their ability to measure accurate pressure variations. To test the reliability of the pressure sensors, a series of tests were designed. The resulting measurements were then compared to secondary references. The measurements were also compared to the basic Bernoulli theory. Further, the wind tunnel measurement allowed for the development of the first comparative computational fluid dynamics simulation and experimental results. Due to the components packaging in the remote, the sensor case cannot be completely streamlined. The resulting shape caused some aerodynamic disturbances. In order to study the sensor shape's influence on the pressure measurements, different experiments were set up. Specifically, by using a roof shaped ramp model mounted on a van, a highway test was performed, allowing examination of the error caused by the sensor's shape. Another test was performed at the University of Florida Hurricane Simulator to study the gust (unsteady) effects. This test revealed that the sensors were sensitive to mechanical vibrations. The paper addresses the sensor network systems topic of the conference.},
  doi       = {10.1109/SENSORDEVICES.2010.19},
  keywords  = {atmospheric measuring apparatus;atmospheric pressure;computational fluid dynamics;geophysical fluid dynamics;pressure measurement;pressure sensors;storms;wind;wireless sensor networks;Bernoulli theory;Florida Institute of Technology;University of Florida Hurricane Simulator;comparative CFD simulation;computational fluid dynamics;hurricane monitoring;low rise structures;pressure variation measurement;roof shaped ramp model;sensor case shape;sensor performance;wind induced pressure;wind tunnel measurement;wireless pressure monitoring system;wireless sensor network performance testing;Atmospheric measurements;Electron tubes;Fluid flow measurement;Pressure measurement;Sea measurements;Semiconductor device measurement;Wind speed;Multi-sensors;Performance testing;Wireless network},
}

@InProceedings{Habul2008,
  author    = {A. Habul and E. Kurtovic},
  title     = {Load testing an AJAX application},
  booktitle = {ITI 2008 - 30th International Conference on Information Technology Interfaces},
  year      = {2008},
  pages     = {729-732},
  month     = {June},
  abstract  = {This paper presents a methodology for load testing an Ajax application. WebLOAD, an open source tool for performance testing, is used to simulate a huge number of client requests to the server. The load testing is used to evaluate and compare different scenarios on the system performance. In order to avoid misleading results, load testing of Ajax applications should incorporate not only server-side but also client-side code, because it can have a significant impact in determining the generated load.},
  doi       = {10.1109/ITI.2008.4588501},
  issn      = {1330-1012},
  keywords  = {Java;XML;performance evaluation;program testing;public domain software;AJAX;WebLOAD;client- side code;load testing;open source tool;performance testing;server-side code;Databases;Delay;Frequency;HTML;Java;Load modeling;Network servers;System performance;System testing;XML;Ajax;load testing;workload model},
}

@Article{Parker1992a,
  author   = {T. P. Parker and C. W. Webb},
  title    = {A study of failures identified during board level environmental stress testing},
  journal  = {IEEE Transactions on Components, Hybrids, and Manufacturing Technology},
  year     = {1992},
  volume   = {15},
  number   = {6},
  pages    = {1086-1092},
  month    = {Dec},
  issn     = {0148-6411},
  abstract = {AT&T has investigated and implemented environmental stress testing (EST) in the production of a variety of circuit board designs as a means of reducing the incidence of early life failures. EST techniques include thermal cycling (TC), random vibration, etc. These techniques have proven more effective than traditional burn-in techniques. In addition, studies have revealed that functional monitoring during thermal stressing of circuit cards more than doubles the effectiveness of EST. Outgoing quality audits and customer first month failure rates have improved by factors of two to four since the implementation of EST},
  doi      = {10.1109/33.206935},
  keywords = {environmental testing;failure analysis;life testing;printed circuit testing;quality control;AT&T;EST;board level environmental stress testing;burn-in techniques;circuit board designs;customer first month failure rates;early life failures;environmental stress testing;functional monitoring;outgoing quality audits;random vibration;study of failures;temperature cycling;thermal cycling;thermal stressing;Application software;Assembly;Circuit testing;Failure analysis;Human factors;Life testing;Manufacturing processes;Production;Thermal stresses;Total quality management},
}

@InProceedings{Gao2010,
  author    = {T. Gao and Y. Ge and G. Wu and J. Ni},
  title     = {A Reactivity-based Framework of Automated Performance Testing for Web Applications},
  booktitle = {2010 Ninth International Symposium on Distributed Computing and Applications to Business, Engineering and Science},
  year      = {2010},
  pages     = {593-597},
  month     = {Aug},
  abstract  = {To improve the reliability and feasibility of web applications, performance testing is very important for satisfying users. For reducing the cost and improve the efficiency of performance testing, we propose a new reactivity-based performance testing framework in this paper. We also provide a complete approach to generate test cases automatically from original web logs. First our approach retrieves user patterns through logs at the server side. Then, metrics derived from users' perspective are applied and usage pattern from client side are gained. At last test case can be generated automatically by solving an optimization problem through an evolutionary algorithm.},
  doi       = {10.1109/DCABES.2010.127},
  keywords  = {Internet;automatic test pattern generation;client-server systems;evolutionary computation;performance evaluation;Web application;Web logs;automated reactivity-based performance testing framework;evolutionary algorithm;optimization problem;test case generation;user pattern retrieval;Load modeling;Measurement;Servers;Software;Testing;Time factors;Unified modeling language;automated test case generation;performance testing;testing framework;web applications},
}

@InProceedings{Stankovic2006,
  author    = {N. Stankovic},
  title     = {Patterns and Tools for Performance Testing},
  booktitle = {2006 IEEE International Conference on Electro/Information Technology},
  year      = {2006},
  pages     = {152-157},
  month     = {May},
  abstract  = {The growth of software applications in size and complexity is being followed by a number of specific nonfunctional requirements such as portability, interoperability, and availability on various platforms. Most often, these have been addressed by middleware or programming environment. In addition, easy customizability, adaptability, and sharing of components facilitates the development cycle. These should be understood and applied in a broader sense, i.e. to byproducts created during the development process such as programs for functional and performance testing. Much time is spent on developing test programs but their quality and quality of thus obtained results varies largely if the process is not standardized and automated. In this paper we present our experience with performance testing of a large scale suite of gateways that are used for the seamless integration of heterogeneous communication networks. We analyze the commercial and public domain tools for load generation and motivate our decision to define an in-house framework and build a distributed tool for performance, testing that is also not restricted by licensing issues and is readily available to everyone involved. Our tool is built on Visper, the object-oriented distributed programming middleware. The suitability and adaptability of the Visper model for rapid application development and the quality of produced result have proven our decision correct},
  doi       = {10.1109/EIT.2006.252109},
  issn      = {2154-0357},
  keywords  = {distributed programming;middleware;object-oriented programming;program testing;software prototyping;Visper;distributed tool;heterogeneous communication networks;large scale gateways suite;load generation;nonfunctional requirements;object-oriented distributed programming middleware;software applications;software engineering;software testing;software tools;test programs;Application software;Automatic testing;Availability;Communication networks;Large scale integration;Licenses;Middleware;Object oriented programming;Performance analysis;Programming environments;Software testing;software engineering;software tools},
}

@Article{Dhote2013,
  author   = {M. R. Dhote and G. G. Sarate},
  title    = {Performance Testing Complexity Analysis on Ajax-Based Web Applications},
  journal  = {IEEE Software},
  year     = {2013},
  volume   = {30},
  number   = {6},
  pages    = {70-74},
  month    = {Nov},
  issn     = {0740-7459},
  abstract = {The Ajax model of Web applications development has rapidly gained popularity because it promises to bring the richness and responsiveness of desktop applications to the Web. Ajax implementations differ fundamentally from other Web implementations - mainly in making asynchronous requests for parts of a Webpage. Techniques routinely used for performance testing traditional Web applications must be modified and enhanced to suit the needs of Ajax-based applications. Using a general example, the authors of this article examine the unique challenges of carrying out performance testing for Ajax-based applications and offer approaches and tools for overcoming them.},
  doi      = {10.1109/MS.2012.132},
  keywords = {Internet;program testing;software metrics;Ajax-based Web applications;Webpage;performance testing complexity analysis;Browsers;Complexity theory;Internet;Servers;Software measurement;Statistical analysis;Testing;Ajax;performance testing;performance testing and tools;software quality and testing;stress testing},
}

@InProceedings{Dong2016,
  author    = {L. Dong and X. Jing and Y. Chunhui},
  title     = {Study of Performance Testing of Information System Based on Domestic CPU and OS},
  booktitle = {2016 Third International Conference on Trustworthy Systems and their Applications (TSA)},
  year      = {2016},
  pages     = {112-116},
  month     = {Sept},
  abstract  = {In order to evaluate the performance of of information system based on domestic CPU and OS, through the introduction of the background of basic hardware and software based on domestic, we expound the domestic information system performance testing principle and method, according to the testing results of existing mature commercial performance testing tool LoadRunner can not reflect the user experience of time, and can not be directly used for testing the information system which based on domestic CPU/OS, this paper put forward the two kinds of testing schemes that base on user experience of LoadRunner and JMeter domestic information system performance test, and test two kinds of improved schemes, through the comparison of the test data and the user experience time of the two schemes, the variance of the test scheme based on JMeter is smaller than LoadRunner test scheme 70.49%. The results show that the test results of the JMeter scheme are more close to the user experience than LoadRunner.},
  doi       = {10.1109/TSA.2016.27},
  keywords  = {information systems;microprocessor chips;operating systems (computers);performance evaluation;JMeter domestic information system performance test;LoadRunner domestic information system performance test;OS;domestic CPU;domestic information system performance testing method;domestic information system performance testing principle;performance evaluation;Browsers;Hardware;Information systems;Operating systems;Rendering (computer graphics);Servers;Testing;JMeter test tool;LoadRunner test tool;domestic CPU;domestic infrastructure software;domistic Operating System(OS);information system;performance test},
}

@InProceedings{Yan2012a,
  author    = {M. Yan and H. Sun and X. Wang and X. Liu},
  title     = {WS-TaaS: A Testing as a Service Platform for Web Service Load Testing},
  booktitle = {2012 IEEE 18th International Conference on Parallel and Distributed Systems},
  year      = {2012},
  pages     = {456-463},
  month     = {Dec},
  abstract  = {Web services are widely known as the building blocks of typical service oriented applications. The performance of such an application system is mainly dependent on that of component web services. Thus the effective load testing of web services is of great importance to understand and improve the performance of a service oriented system. However, existing Web Service load testing tools ignore the real characteristics of the practical running environment of a web service, which leads to inaccurate test results. In this work, we present WS-TaaS, a load testing platform for web services, which enables load testing process to be as close as possible to the real running scenarios. In this way, we aim at providing testers with more accurate performance testing results than existing tools. WS-TaaS is developed on the basis of our existing Cloud PaaS platform: Service4All. First, we briefly introduce the functionalities and main components of Service4All. Second, we provide detailed analysis of the requirements of Web Service load testing and present the conceptual architecture and design of key components. Third, we present the implementation details of WS-TaaS on the basis of Service4All. Finally, we perform a set of experiments based on the testing of real web services, and the experiments illustrate that WS-TaaS can efficiently facilitate the whole process of Web Service load testing. Especially, comparing with existing testing tools, WS-TaaS can obtain more effective and accurate test results.},
  doi       = {10.1109/ICPADS.2012.69},
  issn      = {1521-9097},
  keywords  = {Web services;cloud computing;performance evaluation;program testing;service-oriented architecture;Service4All;WS-TaaS;Web service load testing tools;building blocks;cloud PaaS platform;component Web services;service oriented applications;service oriented system performance;testing as a service platform;Cloud computing;Monitoring;Runtime;Testing;cloud computing;load testing;testing as a service;web services},
}

@Article{Fang2018,
  author   = {P. Fang and X. Ma and X. Li and X. Qiu and R. Gerhard and X. Zhang and G. Li},
  title    = {Fabrication, Structure Characterization, and Performance Testing of Piezoelectret-Film Sensors for Recording Body Motion},
  journal  = {IEEE Sensors Journal},
  year     = {2018},
  volume   = {18},
  number   = {1},
  pages    = {401-412},
  month    = {Jan},
  issn     = {1530-437X},
  abstract = {During muscle contractions, radial-force distributions are generated on muscle surfaces due to muscle-volume changes, from which the corresponding body motions can be recorded by means of so-called force myography (FMG). Piezo-or ferroelectrets are flexible piezoelectric materials with attractive materials and sensing properties. In addition to several other applications, they are suitable for detecting force variations by means of wearable devices. In this paper, we prepared piezoelectrets from cellular polypropylene films by optimizing the fabrication procedures, and developed an FMG-recording system based on piezoelectret sensors. Different hand and wrist movements were successfully detected on able-bodied subjects with the FMG system. The FMG patterns were evaluated and identified by means of linear discriminant analysis and artificial neural network algorithms, and average motion-classification accuracies of 96.1% and 94.8%, respectively, were obtained. This paper demonstrates the feasibility of using piezoelectret-film sensors for FMG and may thus lead to alternative methods for detecting body motion and to related applications, e.g., in biomedical engineering or structural-health monitoring.},
  doi      = {10.1109/JSEN.2017.2766663},
  keywords = {biomedical measurement;biomedical transducers;cellular biophysics;computerised instrumentation;electrets;force measurement;force sensors;medical computing;motion measurement;muscle;neural nets;piezoelectric thin films;piezoelectric transducers;polymer films;polymer foams;recorders;thin film sensors;FMG-recording system;artificial neural network algorithm;biomedical engineering;body motion detection;body motion recording;cellular polypropylene film;ferroelectret;force myography;force sensor;linear discriminant analysis;muscle contraction;muscle surface generation;performance testing;piezoelectret-film sensor;piezoelectric material;radial-force distribution;structural-health monitoring;structure characterization;wearable device;Accelerometers;Dynamics;Electrodes;Films;Force;Muscles;Sensors;Forcemyography;film sensor;motion registration;piezoelectret;wearable},
}

@InProceedings{Knauss2012,
  author    = {J. P. H. Knauss and C. Warren and D. Kearns},
  title     = {An innovative approach to smart automation testing at National Grid},
  booktitle = {PES T D 2012},
  year      = {2012},
  pages     = {1-8},
  month     = {May},
  abstract  = {Upon completion of a successful Distribution Automation (DA) Pilot Project centered in National Grid's upstate New York service territory, it was determined that the reliability improvements delivered by the pilot demonstration justified a much more comprehensive effort to further evaluate additional Smart Grid technologies. The vision was to conduct experiments with a full suite of Smart Grid technologies including: AMI; Home Area Network and energy management systems; Automatic Fault Isolation & System Restoration; advanced feeder monitoring; distribution transformer monitoring; single pole tripping and Pulse Closing technology on distribution line reclosers; advanced capacitor control with independent pole operation; faulted circuit indicators with 2-way communication capability; and distribution fault locating capability. This vision came to be known as National Grid's Smart Grid Pilot proposal. Many challenges exist with such a comprehensive approach from public and personnel safety, to ensuring interoperability between devices and systems of different manufacture. In order to determine which technologies would provide the most benefit to National Grid's customer base, a means was needed to prequalify the various types of products available before large scale deployments were initiated. Looking at the large number of Smart Grid device suppliers, architectures and products available, we realized that the optimum solution would be to build a facility wherein a wide range of Smart Grid technologies could be installed and systematically put through their paces; i.e. actually tested in as near a real-world atmosphere as practical. Thus was born the National Grid “Smart Technology Centre” or STC. Soon thereafter, National Grid's Utility of the Future engineering team designed, engineered, and constructed a truly innovative test fixture that enabled system level testing on complex distribution networks to ensure process safety during field de- loyment. One of only a few known organizations in the U.S., National Grid has in-house capability to truly test and evaluate an end-to-end Smart distribution system architecture where systems such as automated fault isolation and system restoration can be evaluated. This paper will discuss interoperability testing that National Grid embarked upon to prepare for its proposed Smart Grid Pilot demonstration and will detail the lengths that were taken in creating a test site where medium voltage Smart Grid technologies could be fully evaluated to ensure that the various applications would play well with each other prior to actually being deployed in the field. Furthermore, this paper will focus on providing an overview of the system level testing and technical evaluation of distribution protection and control equipment with automated fault isolation and system restoration capabilities. It will also detail a number of lessons learned from this effort and discuss future plans for smart technology evaluation as a basis for an educational platform and workforce training tool.},
  doi       = {10.1109/TDC.2012.6281507},
  issn      = {2160-8555},
  keywords  = {automatic testing;control equipment;electrical safety;fault location;open systems;power distribution control;power distribution protection;power distribution reliability;power engineering computing;power system restoration;smart power grids;2-way communication capability;AMI;DA Pilot Project;National Grid;New York service territory;STC;Smart Technology Centre;advanced capacitor control;advanced feeder monitoring;automatic fault isolation;automatic system restoration;complex distribution network testing;control equipment;distribution automation;distribution fault locating capability;distribution line reclosers;distribution protection;distribution transformer monitoring;educational platform;end-to-end smart distribution system architecture;energy management systems;faulty circuit indicators;home area network;interoperability;large scale deployments;medium voltage smart grid technologies;personnel safety;process safety;public safety;pulse closing technology;reliability improvements;single pole tripping;smart automation testing;smart grid device suppliers;smart grid pilot demonstration;smart technology evaluation;system level testing;workforce training tool;Automation;Circuit faults;Control systems;Monitoring;Safety;Smart grids;Testing},
}

@InProceedings{Liu2010,
  author    = {Y. Liu and B. Du and S. Wang and H. Yang and X. Wang},
  title     = {Design and Implementation of Performance Testing Utility for RTSP Streaming Media Server},
  booktitle = {2010 First International Conference on Pervasive Computing, Signal Processing and Applications},
  year      = {2010},
  pages     = {193-196},
  month     = {Sept},
  abstract  = {RTSP has been widely used in a variety of streaming media applications and streaming service providers hope to choose a high-performance streaming media server to meet their needs, so it is an important research topic about how to evaluate the serving performance of RTSP streaming media server. This paper analyzes the performance metric of streaming media applications comprehensively, and proposes an approach to design and implement a Performance Testing Utility for RTSP Streaming Server. According to different stress test, the utility mainly evaluates a streaming server's performance in the case of delivering a large number of concurrent streams and quantifies the statistics of various performance metrics. The tool utilizes multi-thread mechanism to create multiple pseudo-terminal instances to simulate a certain number of concurrent users for sending RTSP signals, receives media flow by a special IP address, analyzes RTP packets, and counts the related performance metrics value of the server. Experiments validate the efficiency and accuracy of the tool.},
  doi       = {10.1109/PCSPA.2010.55},
  keywords  = {media streaming;multi-threading;multimedia servers;performance evaluation;protocols;IP address;RTP packets;RTSP streaming media server;multiple pseudo-terminal instances;multithread mechanism;performance metric;performance testing utility;real-time streaming protocol;streaming server performance evaluation;streaming service providers;Measurement;Media;Protocols;Real time systems;Servers;Streaming media;Testing;Concurrent streams;Media flow;Performance metrics;Streaming media server;Testing utility},
}

@InProceedings{Schloegl2016,
  author    = {F. Schloegl and M. Buescher and K. Diwold and S. Lehnhoff and L. Fischer and F. Zeilinger and T. Gawron-Deutsch},
  title     = {Performance testing Smart Grid applications using a distributed co-simulation approach},
  booktitle = {IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society},
  year      = {2016},
  pages     = {6305-6310},
  month     = {Oct},
  abstract  = {Co-simulation is an established approach for Smart Grid simulations as it allows to break down the very complex system into sub-systems. The modularity of co-simulation environments makes easy to distribute it across different sites. One reason for such a distribution may be, that this way confidential software can stay within its secure domain. However the transmission of data between the sites is time consuming. This paper demonstrates how Smart Grid applications can be tested using a co-simulation approach. It investigates the costs of such an approach by measuring the time required for data transmission in a case study.},
  doi       = {10.1109/IECON.2016.7793853},
  keywords  = {data communication;power system security;smart power grids;data transmission;distributed cosimulation;smart grid;Computational modeling;Data models;Hardware;Load modeling;Smart grids;Software;Topology},
}

@InProceedings{Zhou2014,
  author    = {J. Zhou and B. Zhou and S. Li},
  title     = {LTF: A Model-Based Load Testing Framework for Web Applications},
  booktitle = {2014 14th International Conference on Quality Software},
  year      = {2014},
  pages     = {154-163},
  month     = {Oct},
  abstract  = {Performance evaluation is an important approach for various systems to guarantee the quality of their services. However, most performance evaluation tasks face a problem: how to model the system workload? Traditional workload models have limitations when it comes to modeling different workloads. In this paper, we propose a workload model for characterizing and generating synthetic web workloads. First, we introduce a Context-based Sequential Action Model to describe users that exhibit similar access patterns. Next, we present a Workload Parameter Specification Language to describe workload parameters for workload generation. Then, we introduce our load-testing framework based on the proposed model. The representativeness and features of our model are demonstrated by comparing it to other models. Experiments show that our framework can generate accurate and stable synthetic workloads.},
  doi       = {10.1109/QSIC.2014.53},
  issn      = {1550-6002},
  keywords  = {Internet;software performance evaluation;specification languages;LTF;Web applications;context-based sequential action model;model-based load testing framework;performance evaluation;synthetic Web workloads;workload generation;workload model;workload parameter specification language;Computational modeling;Context;Context modeling;Load modeling;Testing;Unified modeling language;load testing;model;performance;workload characterization},
}

@InProceedings{Roy1995,
  author    = {K. Roy and R. K. Roy and A. Chatterjee},
  title     = {Stress testing of combinational VLSI circuits using existing test sets},
  booktitle = {1995 International Symposium on VLSI Technology, Systems, and Applications. Proceedings of Technical Papers},
  year      = {1995},
  pages     = {93-98},
  month     = {May},
  abstract  = {We present a stress testing method which can provide an attractive low-cost alternative to burn-in. The technique is based on reordering of test vectors such that a desired circuit activity or electrical stress is generated across the VLSI chip while achieving a high coverage for stuck-at defects. The test methodology can also be used to generate localized electrical or thermal stress in a circuit. Such testing procedure can be important for weeding out circuits with infant mortality problems. Experimental results on benchmark circuits show that the stress requirements can be changed by more than a factor of 4 by reordering the stuck-at test vectors},
  doi       = {10.1109/VTSA.1995.524640},
  issn      = {1524-766X},
  keywords  = {CMOS logic circuits;VLSI;combinational circuits;integrated circuit testing;integrated logic circuits;logic testing;combinational VLSI circuits;infant mortality problems;localized electrical stress;localized thermal stress;stress testing method;stuck-at defects;test vectors reordering;Circuit faults;Circuit testing;Costs;Current density;Monitoring;National electric code;Ovens;Temperature;Thermal stresses;Very large scale integration},
}

@InProceedings{Shojaee2015,
  author    = {A. Shojaee and N. Agheli and B. Hosseini},
  title     = {Cloud-based load testing method for web services with VMs management},
  booktitle = {2015 2nd International Conference on Knowledge-Based Engineering and Innovation (KBEI)},
  year      = {2015},
  pages     = {170-176},
  month     = {Nov},
  abstract  = {Due to the increased loading the large number of users connected to pervasive web services during the past decade, their load testing and providing the needed resources in low time and cost, requires more attention. In this context cloud computing technology offers new ideas to solve such problems and has reduced the concern of large and complex testing systems. In this research in order to improve the quality and performance of web applications load testing, we proposed a method for web applications load testing based on cloud computing. The proposed method uses the existing facilities in the cloud including pool of computing resources without initial cost, unlimited data storage and cloud computing managerial procedures, containing the actual load generating and multi-user concurrency testing, that lead to improved load testing flexibility, time and operational costs. Moreover, in this load testing method, in order to manage resources and virtual machines, significant improvement is achieved by use of appropriate allocation, reducing performance and unnecessary migration avoiding methods. Through evaluation section of the proposed method through a simulated test environment, it is shown that cloud-based load testing in comparison with traditional methods of load testing, improves factors such as effort, cost and time.},
  doi       = {10.1109/KBEI.2015.7436040},
  keywords  = {Web services;cloud computing;program testing;resource allocation;ubiquitous computing;virtual machines;VM management;Web applications load testing performance;Web applications load testing quality;cloud computing technology;cloud-based load testing method;computing resources pool;load generation;multiuser concurrency testing;pervasive Web services;resource management;virtual machines;Cloud computing;Decision support systems;Handheld computers;Systems architecture;Testing;Virtual machining;Cloud Computing;Load Testing;VMs;Web Service},
}

@InProceedings{Kim2009,
  author    = {H. Kim and B. Choi and W. E. Wong},
  title     = {Performance Testing of Mobile Applications at the Unit Test Level},
  booktitle = {2009 Third IEEE International Conference on Secure Software Integration and Reliability Improvement},
  year      = {2009},
  pages     = {171-180},
  month     = {July},
  abstract  = {With the rapid growth of the wireless market and the development of various mobile devices, innovative methods and technologies to produce high-quality mobile applications and reduce time to market have been emerging. Mobile applications are often characterized by an array of limitations such as the short development lifecycle to gain a competitive advantage and difficulties to update once released. Hence, rigorous testing on the applications is required before distribution to the market, including structural white-box, functional black-box, integration and system testing. Although recently performance testing at the system test level has become crucial given its direct connection with the product quality improvement, most such tests are confined to the areas of load, usability, and stress testing. Moreover, the implementation itself is insufficient due to the limitations of the development environment. This paper proposes a method to support performance testing utilizing a database established through benchmark testing in emulator-based test environment at the unit test level. It also presents the tool that supports the proposed method of performance testing and verifies the reliability of performance test results through experiments.},
  doi       = {10.1109/SSIRI.2009.28},
  keywords  = {integrated software;program testing;emulator-based test environment;functional black-box;integration;mobile applications;performance testing;structural white-box;system testing;unit test level;wireless market;Application software;Benchmark testing;Computer science;Databases;Mobile computing;Process control;Software performance;Software testing;Stress;System testing;emulator-based test;mobile application;performance test;unit test},
}

@InProceedings{Yakovyna2007,
  author    = {V. Yakovyna and D. Fedasyuk and M. Seniv and O. Bilas},
  title     = {The Performance Testing of RSA Algorithm Software Realization},
  booktitle = {2007 9th International Conference - The Experience of Designing and Applications of CAD Systems in Microelectronics},
  year      = {2007},
  pages     = {390-392},
  month     = {Feb},
  abstract  = {The software realization of RSA public key encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested. The present paper shows, that the encryption rate is 306.4 plusmn 0.6 kbytes/sec, while the coefficient of encryption time increasing with file size increasing is 3.299. It is concluded that the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.},
  doi       = {10.1109/CADSM.2007.4297593},
  keywords  = {application program interfaces;network operating systems;public key cryptography;.NET platform;CryptoAPI;RSA algorithm software realization;RSA public key encryption algorithm;coefficient-of-encryption time;cryptographic software;encryption rate;flexible architecture independent tool;public-key cryptography;secure implementation;Algorithm design and analysis;Application software;Costs;Hardware;Public key;Public key cryptography;Software algorithms;Software performance;Software quality;Software testing;.NET;Operation performance;Public-key cryptography;RSA algorithm;Software realization},
}

@InProceedings{Yakovyna2007a,
  author    = {V. Yakovyna and D. Fedasyuk and M. Seniv},
  title     = {Software Realization and Performance Testing of DES Cryptographic Algorithm on the .NET Platform},
  booktitle = {2007 9th International Conference - The Experience of Designing and Applications of CAD Systems in Microelectronics},
  year      = {2007},
  pages     = {386-388},
  month     = {Feb},
  abstract  = {The software realization of DES symmetric encryption algorithm using CryptoAPI on .NET platform has been analyzed. The processing performance of the software implementation has been tested and it was shown, that the encryption rate is 11.1 Mb/sec on the Intel Celeron D 351 3.2 GHz processor, while the development environment is a flexible architecture independent tool and meets all the requirements to the secure implementation of cryptographic software.},
  doi       = {10.1109/CADSM.2007.4297591},
  keywords  = {computer software;cryptography;.NET platform;DES symmetric encryption algorithm;Intel Celeron D 351 3.2 GHz processor;data encryption standard;software implementation;software realization;Algorithm design and analysis;Application software;Cryptography;Hardware;Protection;Software algorithms;Software performance;Software quality;Software testing;Software tools;.NET;CryptoAPI;DES algorithm;Software realization;Symmetric cryptography},
}

@InProceedings{Gavrila2016,
  author    = {C. Gavrilă and C. Z. Kertész},
  title     = {Automated performance testing of end-to-end streaming solutions over HbbTV architecture},
  booktitle = {2016 International Conference on Development and Application Systems (DAS)},
  year      = {2016},
  pages     = {135-138},
  month     = {May},
  abstract  = {This paper presents an automated test execution environment designed to analyze the accessibility, reliability and streaming performance of an end-to-end Hybrid broadcast broadband TV (HbbTV) solution. Its purpose is to provide the means for the TV providers to test their HbbTV solution by simulating real-world scenarios and online functioning in a local, offline environment, before making it available for the end users. This way, common problems like server overload, poor streaming quality and HbbTV incorrect functionality can be foreseen and corrected.},
  doi       = {10.1109/DAAS.2016.7492562},
  keywords  = {Computer architecture;Digital TV;Measurement;Servers;Simple object access protocol;Testing;Automated testing;HbbTV;Network conditions simulation;Streaming media;Web services},
}

@InProceedings{Chen1994,
  author    = {Chih-Ang Chen and S. K. Gupta},
  title     = {BIST/DFT for performance testing of bare dies and MCMs},
  booktitle = {Electro/94 International. Conference Proceedings. Combined Volumes.},
  year      = {1994},
  pages     = {803-812},
  month     = {May},
  abstract  = {High emphasis on performance and high cost of MCM repairs necessitates a frame work for performance testing of dies, substrates, and final MCMs. Application of performance tests to bare dies is very expensive due to the need for small and high speed probes and ATE, BIST, scan, and boundary scan can provide a framework to accomplish performance testing in a cost effective manner. It has been shown that traditional BIST, scan, and boundary scan techniques do not provide the framework for performance testing. Special BIST and scan design techniques that can be employed to guarantee high coverage of delay faults are described. Typically, these techniques produce BIST test pattern generators and scan chain designs that require slightly increased hardware overhead over conventional BIST/scan. However, they can drastically decrease the complexity of bare die performance testing. Furthermore, when used in combination with the proposed enhanced boundary scan design, they provide a framework for detection and diagnosis of dynamic failures},
  doi       = {10.1109/ELECTR.1994.472644},
  keywords  = {built-in self test;fault diagnosis;multichip modules;substrates;BIST;MCMs;bare dies;boundary scan;delay faults;dynamic failures;performance testing;scan;Built-in self-test;Circuit faults;Costs;Delay;Economic forecasting;Integrated circuit interconnections;Logic testing;Parasitic capacitance;Probes;System testing},
}

@InProceedings{Kao2013,
  author    = {C. H. Kao and C. C. Lin and J. N. Chen},
  title     = {Performance Testing Framework for REST-Based Web Applications},
  booktitle = {2013 13th International Conference on Quality Software},
  year      = {2013},
  pages     = {349-354},
  month     = {July},
  abstract  = {Recently, enterprises, organizations, and software companies are building more and more web applications to provide their services over the Internet. In order to fulfill various requirements, the complexity of web applications nowadays is increasing dramatically. As a result, the performance characteristics of web applications, including response time, throughput, etc, become more critical than before and should be taken into careful consideration. If the response time of a web application is poor, users may lose their interests even the function of the web application is correct. Therefore, how to execute performance testing on a complex web application systematically and efficiently will be an important issue. In this paper, a performance testing framework for REST-based web applications is introduced. The performance testing framework aims to provide software testers with an integrated process from test cases design, test scripts generation, to test execution. Based on the test cases designed by software testers and the appropriate software artifacts preserved by the framework (e.g., API document), the framework generates the corresponding performance test scripts, which can be executed by specific performance test tools. This helps software testers to focus more in the design of performance test cases. In addition, effort needed to understand the design and implementation of the application and to learn the operation of testing tools decrease. Thus, the efficiency of performance testing can be highly facilitated.},
  doi       = {10.1109/QSIC.2013.32},
  issn      = {1550-6002},
  keywords  = {Internet;program testing;Internet;REST-based Web applications;performance test scripts;performance test tools;performance testing framework;representational state transfer;software artifacts;software companies;software testers;test cases design;test execution;test scripts generation;Complexity theory;Computer architecture;Engines;Software;Testing;Time factors;XML;Performance testing;software testing;web application},
}

@InProceedings{Lee2014,
  author    = {S. Lee and J. Y. Jo and Y. Kim},
  title     = {Performance testing of web-based data visualization},
  booktitle = {2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  year      = {2014},
  pages     = {1648-1653},
  month     = {Oct},
  abstract  = {Many scientific applications generate massive data that requires visualization. For example, the Nevada Solar Energy-Water-Environmental Nexus project has been generating a large amount of environmental monitoring data in textual format. As the data is available on the web, a web-based visualization tool is desirable for the project rather than a standalone tool. This research analyzes the processing mechanisms of four popular web-based data visualization tools, that is, Google Charts, Flex, OFC, D3, and compares their performances. A standalone visualization tool, JfreeChart, have been also used for comparison. The processing times have been divided into three segments, layout time, data transformation time, and rendering time, and separately measured. The actual temperature data from the Nevada Nexus project has been used for testing in different scales ranging from 100 to 100,000 data points. The result shows that each visualization tool has its own ideal environment.},
  doi       = {10.1109/SMC.2014.6974152},
  issn      = {1062-922X},
  keywords  = {Internet;data visualisation;environmental monitoring (geophysics);rendering (computer graphics);scientific information systems;D3;Flex;Google Charts;JfreeChart;Nevada Solar Energy-Water-Environmental Nexus project;OFC;Web-based data visualization tools;data transformation time;environmental monitoring data;layout time;performance testing;rendering time;scientific applications;standalone visualization tool;textual format;Browsers;Data visualization;Flexible printed circuits;Google;Libraries;Rendering (computer graphics);Servers;D3.js;Data Visualization;Flex;Google Charts;JFreeChart;Open Flash Chart;Sensor Data},
}

@InProceedings{Chen2008,
  author    = {S. Chen and D. Moreland and S. Nepal and J. Zic},
  title     = {Yet Another Performance Testing Framework},
  booktitle = {19th Australian Conference on Software Engineering (aswec 2008)},
  year      = {2008},
  pages     = {170-179},
  month     = {March},
  abstract  = {Performance testing is one of the vital activities spanning the whole life cycle of software engineering. While there are a considerable number of performance testing products and open source tools available, they are either too expensive and complicated for small projects, or too specific and simple for diverse performance tests. This paper presents a general-purpose testing framework for both simple and small, and complicated and large-scale performance testing. Our framework proposes an abstraction to facilitate performance testing by separating the application logic from the common performance testing functionalities. This leads to a set of general-purpose data models and components, which form the core of the framework. The framework has been prototyped on both .NET and Java platforms and was used for a number of performance-related projects.},
  doi       = {10.1109/ASWEC.2008.4483205},
  issn      = {1530-0803},
  keywords  = {Java;program testing;software performance evaluation;.NET platform;Java platform;general-purpose data model;general-purpose testing framework;performance testing framework;performance testing product;software engineering;Australia;Automatic testing;Data models;Grinding machines;Java;Life testing;Logic testing;Prototypes;Software engineering;Software testing},
}

@InProceedings{Lim2006,
  author    = {B. H. Lim and J. R. Kim and K. H. Shim},
  title     = {Hierarchical Load Testing Architecture using Large Scale Virtual Clients},
  booktitle = {2006 IEEE International Conference on Multimedia and Expo},
  year      = {2006},
  pages     = {581-584},
  month     = {July},
  abstract  = {In this work, we develop a hierarchical load testing architecture using large scale virtual clients to reduce the testing time and ensure the stability of the server for distributed applications. It explicitly secures the stability of the servers for networked virtual environment and at the same time, it elaborately generates actual loads for testing the performance of the servers. Our agent based load testing architecture provides variety of interactions of virtual entities in the virtual worlds to perform realistic simulations. Simulation results illustrate that our proposed architecture ensures the stability and capacity of the servers for both massively multiplayer online games and peer-to-peer network games},
  doi       = {10.1109/ICME.2006.262475},
  issn      = {1945-7871},
  keywords  = {client-server systems;computer games;peer-to-peer computing;performance evaluation;software agents;distributed application;hierarchical agent based load testing architecture;large scale networked virtual client-server environment;multiplayer online games;peer-to-peer network games;Computational modeling;Computer architecture;Computer industry;Electronic equipment testing;Large-scale systems;Network servers;Pervasive computing;Stability;System testing;Virtual environment},
}

@InProceedings{Zhou2014a,
  author    = {J. Zhou and B. Zhou and S. Li},
  title     = {Automated Model-Based Performance Testing for PaaS Cloud Services},
  booktitle = {2014 IEEE 38th International Computer Software and Applications Conference Workshops},
  year      = {2014},
  pages     = {644-649},
  month     = {July},
  abstract  = {Recently, cloud computing has become popular for its unique advantages. Many applications have been migrated to cloud as web services. However, evaluating the performance of cloud services is non-trivial. Performance testing is one of the dominant techniques for evaluating system performance. In this paper, we present a model and template-based approach that automatically generates test scripts and test cases to measure service performance in an enterprise private cloud. We describe how load is generated automatically from our tool. Our empirical study shows the proposed approach can significantly decrease the cost of performance testing and help reveal potential performance issues.},
  doi       = {10.1109/COMPSACW.2014.108},
  keywords  = {Web services;cloud computing;program testing;software performance evaluation;PaaS cloud services;Web services;automated model;cloud computing;enterprise private cloud;performance testing;Automation;Cloud computing;Computational modeling;Context;Load modeling;Testing;automated;cloud;performance testing;web service},
}

@InProceedings{Xie2008,
  author    = {J. Xie and X. Ye and B. Li and F. Xie},
  title     = {A Configurable Web Service Performance Testing Framework},
  booktitle = {2008 10th IEEE International Conference on High Performance Computing and Communications},
  year      = {2008},
  pages     = {312-319},
  month     = {Sept},
  abstract  = {More and more softwares based on web service technologies are developed. Before their releases on the Internet, it is necessary to evaluate these systems' performance, especially their response time under different workload pressures. However, existing performance testing benchmarks and tools for web service applications are difficult to adapt to various user-specific testing purposes. This paper proposes a configurable web service performance testing framework which contains client module, application server module and database module. Client module, by using the network cooperation method that one central client drives several other clients, adapts to a great number of concurrent customers to request web services. Application server module contains web services under testing and external supporting web services, each of which is configured as a plug-in. The process to realize mixed ratio of web service interactions is similar to dealing cards and adapts to different commercial application characteristics. In database module, the data model including table and attribute dependence can be customized, and the data scale initialization can be resized according to the topology of above dependence. As such, this framework allows testers to dynamically define their data model, customize their scale of database, configure their transaction characteristics, deploy their application strategies and confirm their performance metrics..},
  doi       = {10.1109/HPCC.2008.53},
  keywords  = {Web services;client-server systems;data models;program testing;Internet;attribute dependence;client-server module;configurable Web service performance testing;data model;database module;table dependence;user-specific testing purpose;Application software;Benchmark testing;Data models;Delay;Internet;Measurement;Network servers;Topology;Transaction databases;Web services;benchmark;framework;performance testing;web service},
}

@InProceedings{Masud2006,
  author    = {M. Z. Mas'ud and A. H. Yaacob and N. M. Ahmad},
  title     = {Network performance testing on VM based autonomous web server},
  booktitle = {2006 International Conference on Computing Informatics},
  year      = {2006},
  pages     = {1-6},
  month     = {June},
  abstract  = {As online services increasingly play vital roles in modern society, the possibilities and opportunities offered are limitless, unfortunately, so too are the risks and chances of malicious intrusions. Intrusion detection systems (IDSs) has been widely used as an important component in protecting online service towards Web attacks and evasions. Yet, today's architectures for intrusion detection force the IDS designer to make a difficult choice to place IDS, so that it can protect itself from a direct attack. To address these challenges, this paper introduces a novel framework to safeguard IDS from a direct attack. Simply called zero administrative server (ZAS), the system incorporates IDS in a virtual machine (VM) environment. VM offers strong isolation for IDS from the monitored services and provides significant resistance to malicious attacks. Moreover, this VM based WWW server has the ability to monitor the network traffic to the running services; analyse the information obtained and detect the intrusion; alienate the intruder from the services; and reconstruct the corrupted data or damaged files caused by the evasion. In this paper, we demonstrate ZAS by exposing it to several attacking tools as well as to show the effects it takes on the network performance in terms of TCP throughput and application-to-application round trip time.},
  doi       = {10.1109/ICOCI.2006.5276470},
  issn      = {2166-5710},
  keywords  = {Web services;security of data;virtual machines;VM based autonomous Web server;Web attacks;intrusion detection systems;malicious attacks;network performance testing;online services;virtual machine;zero administrative server;File servers;Intrusion detection;Network servers;Protection;Testing;Virtual machine monitors;Virtual machining;Virtual manufacturing;Web server;World Wide Web;Checksum;Intrusion Detection System;Virtual Machine;WWW Server},
}

@InProceedings{Kanstren2015,
  author    = {T. Kanstrén and P. Aho and A. Lämsä and H. Martin and J. Liikka and M. Seppänen},
  title     = {Robot-assisted smartphone performance testing},
  booktitle = {2015 IEEE International Conference on Technologies for Practical Robot Applications (TePRA)},
  year      = {2015},
  pages     = {1-6},
  month     = {May},
  abstract  = {This paper describes experiences and lessons learned in applying an approach of using a physical robot for testing overall smartphone device performance based on user profiles. The process consists of capturing user actions, abstracting them to usage profiles, transforming these into test models, and generating test cases from the models. The goal is to support performance testing of touch screen devices and applications in a realistic test environment. To achieve this, the tests are based on real-world generated user profiles and executed using a real physical robot, simulating the actual user. Our performance testing targets different attributes of performance such as response times, power and resource usage, and software/hardware aging. Use of different hardware and software configurations in the test scenarios is considered. This work has been performed in close collaboration with industry partners in robotics provider and user industries.},
  doi       = {10.1109/TePRA.2015.7219669},
  issn      = {2325-0526},
  keywords  = {program testing;robots;smart phones;software maintenance;software performance evaluation;hardware aging;hardware configuration;overall smartphone device performance testing;physical robot;power usage;resource usage;response times;robot-assisted smartphone performance testing;software aging;software configuration;touch screen devices;user profiles;Electronic mail;Markov processes;Performance evaluation;Robot kinematics;Service robots;Testing},
}

@Article{Pachucki1995,
  author   = {D. E. Pachucki},
  title    = {Environmental stress testing experiment using the Taguchi method},
  journal  = {IEEE Transactions on Components, Packaging, and Manufacturing Technology: Part A},
  year     = {1995},
  volume   = {18},
  number   = {1},
  pages    = {3-9},
  month    = {Mar},
  issn     = {1070-9886},
  abstract = {Manufacturing process improvements which increase productivity, decrease test process time, and improve customer satisfaction are highly desirable in today's marketplace. The application of environmental stress screening (ESS) is a method of achieving these improvements. ESS is the application of stresses applied beyond product specification limits in order to find latent product defects. Utilizing ESS achieves increased robustness and lower infant mortality. An experiment was performed to identify the significance or relevancy of the selected stresses for application in the printed wiring board (PWA) production process by using a statistically significant controlled method. The design of experiments statistical approach (analysis of variance), is applied, combined with the Taguchi two-level, seven-factor design method. This experiment concentrated on three stresses (temperature cycling, random vibration, and power cycling) and two diagnostic levels: a prom-based (programmable memory chip), power-on self test (POST), and a functional diagnostic test suite, contained on disk storage. Note that this was not an optimization experiment. Once the significance to the production process is identified, future optimizing of temperature cycling, power cycling, and vibration screens, will be conducted. Also, voltage margining was not included so as to reduce the complexity of the experiment-treatment factors and interactions. Experimental results and conclusions on the effectiveness of different stress regimens are presented in this paper},
  doi      = {10.1109/95.370727},
  keywords = {automatic testing;covariance analysis;design of experiments;dynamic testing;environmental stress screening;environmental testing;human resource management;life testing;printed circuit manufacture;printed circuit testing;production testing;Taguchi method;analysis of variance;customer satisfaction;design of experiments;diagnostic levels;environmental stress testing;functional diagnostic test suite;infant mortality;latent product defects;power cycling;power-on self test;printed wiring board production;productivity;prom-based diagnostics;random vibration;robustness;statistically significant controlled method;stress regimens;temperature cycling;test process time;Automatic testing;Customer satisfaction;Design methodology;Electronic switching systems;Manufacturing processes;Production;Productivity;Robustness;Stress;Temperature},
}

@InProceedings{Chen1999,
  author    = {Qingxin Chen and V. Sorokine},
  title     = {A fast simulation technique for performance testing of the RF/IF chain of CDMA receivers},
  booktitle = {1999 IEEE MTT-S International Topical Symposium on Technologies for Wireless Applications (Cat. No. 99TH8390)},
  year      = {1999},
  pages     = {23-28},
  month     = {Feb},
  abstract  = {We propose an improved approach to the simulation of the CDMA forward link. The simulator achieves its computational efficiency by adopting a simplified CDMA system model without compromising much of its practicality. Additional reduction in the computational complexity is obtained by implementing bit level operations for certain receiver tasks. Improved processing algorithms are also introduced, which further facilitates the simulation process. The rationale behind the development of the simulator as well as many techniques involved could prove beneficial to a CDMA receiver designer in terms of shortening the design cycle and reducing the computational power requirements.},
  doi       = {10.1109/MTTTWA.1999.755123},
  keywords  = {code division multiple access;computational complexity;digital simulation;land mobile radio;radio receivers;signal processing;telecommunication equipment testing;CDMA forward link;CDMA receivers;RF/IF chain;bit level operations;computational complexity reduction;computational efficiency;computational power requirements reduction;design cycle;fast simulation technique;mobile radio;performance testing;processing algorithms;system model;Additive white noise;Computational modeling;Context modeling;Fading;Multiaccess communication;Power system modeling;Radio frequency;Signal generators;Space technology;Testing},
}

@InProceedings{Gois2017,
  author    = {N. Gois and P. Porfírio and A. Coelho},
  title     = {A Multi-objective Metaheuristic Approach to Search-Based Stress Testing},
  booktitle = {2017 IEEE International Conference on Computer and Information Technology (CIT)},
  year      = {2017},
  pages     = {55-62},
  month     = {Aug},
  abstract  = {Nowadays applications need to deal with a large number of concurrent requests. These systems must be stress tested to ensure that they can function correctly under a load. In this context, a research field called Search-based Software Testing has become increasingly important. Most of the search-based test methods are based on single objective optimization. In the case of multi-objective optimization of tests, usually researchers assign different weight values to different objectives and combine them as a single objective. This research paper verifies the use of a multi-objective algorithm in search-based stress testing. The NSGA-II algorithm was implemented in the IAdapter tool using the jMetal framework. IAdapter is a JMeter plugin used for performing search-based stress tests. jMetal is an object-oriented Java-based framework for multi-objective optimization with metaheuristics. One experiment was conducted to validate the proposed approach.},
  doi       = {10.1109/CIT.2017.19},
  keywords  = {Java;Pareto optimisation;concurrency control;genetic algorithms;program testing;search problems;IAdapter tool;JMeter plugin;NSGA-II algorithm;Software Testing;concurrent requests;jMetal framework;multiobjective algorithm;multiobjective metaheuristic approach;multiobjective optimization;object-oriented Java-based framework;search-based stress testing;search-based test methods;single objective optimization;weight values;Genetic algorithms;Load modeling;Search problems;Software;Stress;Testing;Time factors;Multi-Objective Metaheuristic;Pareto Frontier;Search-Based Stress Test},
}

@InProceedings{Kaulbars2015,
  author    = {D. Kaulbars and F. Schweikowski and C. Wietfeld},
  title     = {Spatially Distributed Traffic Generation for Stress Testing the Robustness of Mission-Critical Smart Grid Communication},
  booktitle = {2015 IEEE Globecom Workshops (GC Wkshps)},
  year      = {2015},
  pages     = {1-6},
  month     = {Dec},
  abstract  = {Resilient Smart Grids require very robust communication infrastructures, which allow to support the control of the Smart Grid even and especially in critical situations. Current network quality assurance processes, such as drive tests in wireless systems, typically focus on cell coverage and quality of service parameters (e.g., max. data rate) at a specific geographical position, without considering the impact of overload situations. Therefore, this paper introduces a methodology for stress testing a communication infrastructure for Smart Grids by synchronized, distributed so-called Smart Traffic Generators (STGs). Due to their low cost, the STGs become a permanent part of the infrastructure and enable a network operator independent, continuous network quality monitoring. A case study leveraging a LTE deployment demonstrates how the proposed approach can prove the fulfillment of Quality of Service (QoS) requirements of time critical Smart Grid applications, even in stress situations with high cell load. Although, the proposed approach has been introduced for Smart Grids, it can also be used for ensuring the communication resilience for other critical infrastructures, e.g., public safety networks.},
  doi       = {10.1109/GLOCOMW.2015.7414168},
  keywords  = {Long Term Evolution;carrier transmission on power lines;quality of service;smart power grids;telecommunication traffic;mission-critical smart grid communication;network quality monitoring;quality of service;spatially distributed traffic generation;stress testing;Generators;Long Term Evolution;Mobile communication;Mobile computing;Quality of service;Smart grids;Stress},
}

@InProceedings{Wang2010b,
  author    = {X. Wang and B. Zhou and W. Li},
  title     = {Model Based Load Testing of Web Applications},
  booktitle = {International Symposium on Parallel and Distributed Processing with Applications},
  year      = {2010},
  pages     = {483-490},
  month     = {Sept},
  abstract  = {In this paper, a usage model is proposed to simulate users' behaviors realistically in load testing of web applications, and another relevant workload model is proposed to help generate realistic load for load testing. It also demonstrates an eclipse-based load testing tool “Load Testing Automation Framework (LTAF)” which is based on these two models and can perform load testing of web applications easily and automatically. Furthermore, these models and tools were successfully applied into a representative web-based system from a big Corporation.},
  doi       = {10.1109/ISPA.2010.24},
  issn      = {2158-9178},
  keywords  = {Internet;program testing;Load Testing Automation Framework;Web applications;Web-based system;eclipse-based load testing tool;model based load testing;usage model;user behaviors;File systems;Load modeling;Markov processes;Navigation;Servers;Testing;Unified modeling language;Load Model;Load Testing;Markov Chains;Performance Engineering;Usage Model},
}

@InProceedings{Young2007,
  author    = {A. Young and T. Holt and M. Elsayed and A. Neuber and M. Kristiansen and L. L. Altgilbers and A. H. Stults},
  title     = {Fuse and load testing with mid-sized, high energy density flux compression generators},
  booktitle = {2007 16th IEEE International Pulsed Power Conference},
  year      = {2007},
  volume    = {2},
  pages     = {1165-1168},
  month     = {June},
  abstract  = {Compact Pulsed Power Systems (CPPSs) require power sources that are small in size yet can produce the necessary electrical energy required to drive a given load. Helical Flux Compression Generators (HFCGs) are attractive for single shot applications due to their rapid conversion of chemical energy to electrical energy. Mid-sized generators occupy little total volume (∼4,000-cm3 total with a compressible volume of ∼300-cm3 in the present generator design), while the high explosives used in an HFCG provide an energy density of ∼8,000 MJ/m3. Consistent output current and energy gain from shot to shot are key variables in the ability of an HFCG to drive CPPSs effectively. An investigation into the practicality of using mid-sized HFCGs as the driver for single shot CPPSs is presented. Data and waveforms from generators fired into 3 μH inductive loads are shown, with results measuring the generator’s performance as a driver for an inductive energy storage (IES) system. Results are also shown from adding a power conditioning system to the output of the HFCG, where the measurements demonstrate the ability of an HFCG to drive high impedance loads. The effectiveness of a mid-sized HFCG as drivers for these systems will be evaluated.},
  doi       = {10.1109/PPPS.2007.4652394},
  issn      = {2158-4915},
  keywords  = {Chemicals;Energy measurement;Energy storage;Explosives;Fuses;Impedance measurement;Power conditioning;Power measurement;Pulse power systems;Testing},
}

@InProceedings{Khan2016,
  author    = {R. Khan and M. Amjad},
  title     = {Web application's performance testing using HP LoadRunner and CA Wily introscope tools},
  booktitle = {2016 International Conference on Computing, Communication and Automation (ICCCA)},
  year      = {2016},
  pages     = {802-806},
  month     = {April},
  abstract  = {This paper cover the importance of performance testing of the web application. The performance of any web application has been depend on the some different type of the testing process like load testing, soak testing, smoke testing and stress testing etc. In this paper we applied smoke testing on a web application. This web application has been developed for the customer before delivering the software to the customer it is duty of tester to test all the aspects of the software and deliver error free and reliable software to the customer. Reliability has its own most important role in the software industry. In this paper performance testing has been performed using HP LoadRunner and CA Wily Introscope tools.},
  doi       = {10.1109/CCAA.2016.7813849},
  keywords  = {DP industry;Internet;program testing;software performance evaluation;software reliability;software tools;CA Wily Introscope tool;HP LoadRunner;Web application performance testing;smoke testing;software industry;software reliability;Business;Scalability;Servers;Software;Testing;Throughput;Uniform resource locators;HP LoadRunner;Load Testng;Perforamance Testing;Software Testing;Wily Introscope Tools},
}

@InProceedings{Mukherjee2014,
  author    = {J. Mukherjee and M. Wang and D. Krishnamurthy},
  title     = {Performance Testing Web Applications on the Cloud},
  booktitle = {2014 IEEE Seventh International Conference on Software Testing, Verification and Validation Workshops},
  year      = {2014},
  pages     = {363-369},
  month     = {March},
  abstract  = {Web applications are increasingly resorting to public cloud platforms such as the Amazon Web Services (AWS) Elastic Compute Cloud (EC2). However, previous studies have shown that the virtualized infrastructures used in a cloud environment can introduce performance issues. Hence, it is crucial to test the performance of the cloud to support Web applications. This is challenging because the performance effect of the cloud platform cannot be easily isolated from other extraneous factors. In this paper, we present a systematic experimental process to address this challenge. Following our proposed process, we test the performance of Web applications running on different types of AWS EC2 instances. Results suggest that Web server response times can fluctuate up to 1000% for the same workload under certain circumstances such as instance type, time-of-the-day, and day-of-the-week.},
  doi       = {10.1109/ICSTW.2014.57},
  keywords  = {Web services;cloud computing;software performance evaluation;virtualisation;AWS EC2 instances;Amazon Web Services Elastic Compute Cloud;Web application performance testing;Web server response time;cloud environment;instance type;performance issues;public cloud platform;virtualized infrastructure;Bandwidth;Generators;Testing;Time factors;Web servers},
}

@InProceedings{Young2007a,
  author    = {A. J. Young and T. A. Holt and M. A. Elsayed and A. A. Neuber and M. Kristiansen and L. L. Altgilbers and A. H. Stults},
  title     = {Fuse and Load Testing with Mid-Sized, High Energy Density Flux Compression Generators},
  booktitle = {2007 IEEE 34th International Conference on Plasma Science (ICOPS)},
  year      = {2007},
  pages     = {719-719},
  month     = {June},
  abstract  = {Compact pulsed power systems require power sources that are small in size yet can produce the necessary electrical energy required to drive the system. Helical magnetic flux compression generators (HFCGs) are attractive for single shot applications due to their rapid conversion of chemical energy to electrical energy. The small total volume of a generator coupled with the energy density of the fast-reacting high explosives makes mid-sized HFCGs an appealing option as sources in single shot compact pulsed power systems. Consistent output current and energy gain from shot to shot are key variables in the ability of an HFCG to drive compact pulsed power systems efficiently.},
  doi       = {10.1109/PPPS.2007.4346025},
  issn      = {0730-9244},
  keywords  = {electric fuses;pulse generators;pulsed power supplies;compact pulsed power systems;fuse testing;helical magnetic flux compression generators;high energy density flux compression generators;load testing;Electronic equipment testing;Explosives;Fuses;Impedance;Power generation;Pulse compression methods;Pulse generation;Pulse power systems;Pulse shaping methods;Switches},
}

@InProceedings{Wunderle2017,
  author    = {B. Wunderle and J. Heilmann and D. May and J. Arnold and J. Hirscheider and J. Bauer and R. Schacht and J. Vogel and M. A. Ras},
  title     = {Modelling and characterisation of a grease pump-out test stand and its use for accelerated stress testing of thermal greases},
  booktitle = {2017 23rd International Workshop on Thermal Investigations of ICs and Systems (THERMINIC)},
  year      = {2017},
  pages     = {1-6},
  month     = {Sept},
  abstract  = {Thermal greases allow a low stress bond at low bond line thicknesses (BLT) at medium thermal conductivities and simple application, all of which make it an alternative to solders, thermal adhesives or pads. It is widely used in power and microprocessor applications, most of which involve large areas to be used for heat transfer. However, for years thermal overload failure of power modules and chips has been a pressing problem due to pump-out of thermal grease as die or module thermal interface material (TIM): Most thermal greases are Bingham fluids and thus no solids, so they can be squeezed out from in between the gap, driven by thermo-mechanical action of the adjacent layers as e.g. DCB substrate or silicon chip with the heat sink. Today, thermal greases have to be qualified in lengthy stress tests in a product relevant environment which consumes substantial resources as often a system test is required. Therefore, a fast test is necessary which accelerates testing and thus allows a fast screening of market-available greases on one hand, and guidelines for material development on the other. For that purpose this paper addresses this topic in a combined simulative and experimental manner, where at the same time a novel test procedure is proposed for accelerated grease pump-out testing (GPOT) in the framework of a completely new approach, combining loading with in-situ failure analytical techniques and decoupling thermal from mechanical loading.},
  doi       = {10.1109/THERMINIC.2017.8233806},
  keywords  = {adhesion;adhesives;failure analysis;greases;heat sinks;integrated circuit packaging;integrated circuit reliability;life testing;microprocessor chips;thermal conductivity;thermal management (packaging);thermal resistance;thermal stresses;accelerated grease pump-out;accelerated stress testing;grease pump-out test;stress tests;thermal adhesives;thermal conductivities;thermal grease;thermal interface material module;thermal overload failure;Conductivity;Life estimation;Loading;Stress;Testing;Thermal conductivity;Thermal stresses},
}

@InProceedings{Banerjee2013,
  author    = {A. Banerjee and S. Chattopadhyay and A. Roychoudhury},
  title     = {Static Analysis Driven Cache Performance Testing},
  booktitle = {2013 IEEE 34th Real-Time Systems Symposium},
  year      = {2013},
  pages     = {319-329},
  month     = {Dec},
  abstract  = {Real-time, embedded software are constrained by several non-functional requirements, such as timing. With the ever increasing performance gap between the processor and the main memory, the performance of memory subsystems often pose a significant bottleneck in achieving the desired performance for a real-time, embedded software. Cache memory plays a key role in reducing the performance gap between a processor and main memory. Therefore, analyzing the cache behaviour of a program is critical for validating the performance of an embedded software. In this paper, we propose a novel approach to automatically generate test inputs that expose the cache performance issues to the developer. Each such test scenario points to the specific parts of a program that exhibit anomalous cache behaviour along with a set of test inputs that lead to such undesirable cache behaviour. We build a framework that leverages the concepts of both static cache analysis and dynamic test generation to systematically compute the cache-performance stressing test inputs. Our framework computes a test-suite which does not contain any false positives. This means that each element in the test-suite points to a real cache performance issue. Moreover, our test generation framework provides an assurance of the test coverage via a well-formed coverage metric. We have implemented our entire framework using Chronos worst case execution time (WCET) analyzer and LLVM compiler infrastructure. Several experiments suggest that our test generation framework quickly converges towards generating cache-performance stressing test cases. We also show the application of our generated test-suite in design space exploration and cache performance optimization.},
  doi       = {10.1109/RTSS.2013.39},
  issn      = {1052-8725},
  keywords  = {cache storage;embedded systems;program compilers;program diagnostics;software performance evaluation;Chronos worst case execution time;LLVM compiler infrastructure;WCET analyzer;anomalous cache behaviour;cache performance optimization;cache-performance stressing test cases;coverage metric;design space exploration;dynamic test generation;real-time embedded software;static cache analysis;test coverage;test-suite;Abstracts;Cache memory;Embedded software;Instruments;Performance analysis;Testing;Cache performance;Performance testing;Test generation},
}

@InProceedings{Sueker1997,
  author    = {K. H. Sueker},
  title     = {A static dynamometer for load testing large variable frequency motor drives},
  booktitle = {1997 IEEE International Electric Machines and Drives Conference Record},
  year      = {1997},
  pages     = {WB1/9.1-WB1/9.3},
  month     = {May},
  abstract  = {The static dynamometer, an apparent oxymoron, is a system which allows full load testing of variable frequency motor drives with no rotating equipment and only minimal demand from the power line. By inserting a reactor between the drive output and the line from which it is powered, the drive can be made to appear as a synchronous generator. This arrangement offers a practical alternative to the motor-generator sets usually employed for load testing. The required equipment consists of a set of power reactors approximating 10% of the drive rating, a contactor and a phase locked loop circuit for regulating the drive phase relative to the line. The static dynamometer is in production use on variable speed drives from 20 to 5000 hp and 480 to 4160 V. There are no intrinsic limits to either power or voltage for its application},
  doi       = {10.1109/IEMDC.1997.604303},
  keywords  = {dynamometers;machine testing;motor drives;variable speed drives;20 to 5000 hp;480 to 4160 V;drive rating;load testing;motor-generator sets;phase locked loop circuit;power reactors;production experience;static dynamometer;synchronous generator;variable frequency motor drives;variable speed drives;Circuit testing;Frequency;Inductors;Motor drives;Phase locked loops;Production;Synchronous generators;System testing;Variable speed drives;Voltage},
}

@InProceedings{Mansharamani2010,
  author    = {R. Mansharamani and A. Khanapurkar and B. Mathew and R. Subramanyan},
  title     = {Performance Testing: Far from Steady State},
  booktitle = {2010 IEEE 34th Annual Computer Software and Applications Conference Workshops},
  year      = {2010},
  pages     = {341-346},
  month     = {July},
  abstract  = {The dot com era ushered in a number of industry standard load testing tools. While there is no doubt that these tools have helped improve the quality of IT systems, performance testing in the IT industry is far from steady state. There are still severe gaps between performance test results and production systems performance in IT projects. This paper proposes a number of areas where performance testing needs to improve radically, several of which can be incorporated in to load testing tools. Examples are also provided of simple analytics during single user performance testing to demonstrate the effectiveness of this extra but necessary step in the testing process.},
  doi       = {10.1109/COMPSACW.2010.66},
  keywords  = {DP industry;Internet;electronic commerce;performance evaluation;testing;IT system quality;industry standard load testing tools;production systems;single user performance testing;Databases;Extrapolation;Industries;Testing;Throughput;Time factors;Tuning;load testing tools;performance emulation;performance testing;think time variability},
}

@InProceedings{Meira2012,
  author    = {J. A. Meira and E. C. d. Almeida and Y. Le Traon and G. Sunye},
  title     = {Peer-to-Peer Load Testing},
  booktitle = {2012 IEEE Fifth International Conference on Software Testing, Verification and Validation},
  year      = {2012},
  pages     = {642-647},
  month     = {April},
  abstract  = {Nowadays the large-scale systems are common-place in any kind of applications. The popularity of the web created a new environment in which the applications need to be highly scalable due to the data tsunami generated by a huge load of requests (i.e., connections and business operations). In this context, the main question is to validate how far the web applications can deal with the load generated by the clients. Load testing is a technique to analyze the behavior of the system under test upon normal and heavy load conditions. In this work we present a peer-to-peer load testing approach to isolate bottleneck problems related to centralized testing drivers and to scale up the load. Our approach was tested in a DBMS as study case and presents satisfactory results.},
  doi       = {10.1109/ICST.2012.153},
  issn      = {2159-4848},
  keywords  = {Internet;peer-to-peer computing;program testing;Web applications;centralized testing drivers;large-scale systems;peer-to-peer load testing;system under test;Cloud computing;Computer architecture;Databases;Large-scale systems;Peer to peer computing;Scalability;Testing;large-scale systems;load testing;peer-to-peer},
}

@Article{Jiang2016,
  author   = {B. Jiang and P. Chen and W. K. Chan and X. Zhang},
  title    = {To What Extent is Stress Testing of Android TV Applications Automated in Industrial Environments?},
  journal  = {IEEE Transactions on Reliability},
  year     = {2016},
  volume   = {65},
  number   = {3},
  pages    = {1223-1239},
  month    = {Sept},
  issn     = {0018-9529},
  abstract = {An Android-based smart television (TV) must reliably run its applications in an embedded program environment under diverse hardware resource conditions. Owing to the diverse hardware components used to build numerous TV models, TV simulators are usually not sufficiently high in fidelity to simulate various TV models and thus are only regarded as unreliable alternatives when stress testing such applications. Therefore, even though stress testing on real TV sets is tedious, it is the de facto approach to ensure the reliability of these applications in the industry. In this paper, we study to what extent stress testing of smart TV applications can be fully automated in the industrial environments. To the best of our knowledge, no previous work has addressed this important question. We summarize the findings collected from ten industrial test engineers who have tested 20 such TV applications in a real production environment. Our study shows that the industry required test automation supports on high-level GUI object controls and status checking, setup of resource conditions, and the interplay between the two. With such supports, 87% of the industrial test specifications of one TV model can be fully automated, and 71.4% of them were found to be fully reusable to test a subsequent TV model with major upgrades of hardware, operating system, and application. It represents a significant improvement with margins of 28% and 38%, respectively, compared with stress testing without such supports.},
  doi      = {10.1109/TR.2015.2481601},
  keywords = {Android (operating system);automatic testing;digital television;graphical user interfaces;production engineering computing;program testing;reliability;Android-based smart TV;Android-based smart television;TV simulators;hardware resource conditions;high-level GUI object controls;industrial environments;industrial test specifications;operating system;reliability;status checking;stress testing;test automation;Androids;Automation;Humanoid robots;Smart phones;Stress;TV;Testing;Android;TV;automated testing;reliability;software reuse;stress testing;test case creation},
}

@InProceedings{Wandan2009,
  author    = {Z. Wandan and J. Ningkang and Z. Xubo},
  title     = {Design and Implementation of a Web Application Automation Testing Framework},
  booktitle = {2009 Ninth International Conference on Hybrid Intelligent Systems},
  year      = {2009},
  volume    = {2},
  pages     = {316-318},
  month     = {Aug},
  abstract  = {In this paper the problems in the automation testing of GUI based Web applications are discussed. A new automation testing framework based on the concept of object feature set and dynamic searching policy is proposed. The design and implementation of it are both given. The framework working using result shows that it makes the testing more convenient and efficient with less resources and time cost but higher testing coverage.The ability of maintenance and stability are both improved.},
  doi       = {10.1109/HIS.2009.175},
  keywords  = {Internet;graphical user interfaces;program testing;GUI;Internet technology;Web application automation testing framework;Web application maintenance;dynamic searching policy;object feature set;software development cycle;Application software;Automatic control;Automatic testing;Costs;Design automation;Graphical user interfaces;Java;Programming;Software testing;System testing;Web application testing;automation testing framework;dynamic searching technology},
}

@InProceedings{Shu2007,
  author    = {X. Shu and F. Maurer},
  title     = {A Tool for Automated Performance Testing of Java3D Applications in Agile Environments},
  booktitle = {International Conference on Software Engineering Advances (ICSEA 2007)},
  year      = {2007},
  pages     = {35-35},
  month     = {Aug},
  abstract  = {Following the agile philosophy that all core features of a system need an automated test harness, performance requirements also need such a check when they are essential for the success of a project. The purpose of this paper is to describe a tool, J3DPerfUnit, which supports automated performance testing for Java3D applications in agile environments. We elicited tool requirements from domain experts through a survey and evaluated J3DPerfUnit using code from our partner's bioinformatics project and Java3D official tutorials. The evaluation pointed out that the tool is effective in detecting performance problems and in identifying where they come from when loading/unloading a 3D object.},
  doi       = {10.1109/ICSEA.2007.11},
  keywords  = {Java;program testing;rendering (computer graphics);software metrics;Java3D application;agile environment;automated performance testing;graphics rendering;software metrics;Application software;Automatic testing;Availability;Bioinformatics;Computer science;Engines;Java;Layout;System testing;Tree graphs},
}

@InProceedings{Motalova2010,
  author    = {L. Motalova and O. Krejcar},
  title     = {Stress Testing Data Access via a Web Service for Determination of Adequate Server Hardware for Developed Software Solution},
  booktitle = {2010 Second International Conference on Computer Engineering and Applications},
  year      = {2010},
  volume    = {1},
  pages     = {329-333},
  month     = {March},
  abstract  = {The aim of this project is stress testing of the system for data management and planning of the operations developed for home care agencies which has to be upgrading of the current system based on the older database of Microsoft Access product. The part of the system is a mobile application that allows employees to edit the records of patients directly in the terrain. The whole system, including applications developed for the stress testing is based on Microsoft technology .NET. Our Stress Testing application allows testing a selected problem areas to find any limitations before the tested developing solution will be set up at customer. By the help of our test application, the hardware solution for the server was selected on the base of selected home care agency needs.},
  doi       = {10.1109/ICCEA.2010.72},
  keywords  = {Web services;file servers;information retrieval;program testing;software tools;Microsoft access product database;Microsoft technology .NET;Web service;adequate server hardware;data management system;home care agency;stress testing data access;Databases;Displays;Hardware;Random number generation;Software testing;Stress;System testing;Time factors;Time measurement;Web services;data access;software;stress testing;web services},
}

@InProceedings{Canfora2013,
  author    = {G. Canfora and F. Mercaldo and C. A. Visaggio and M. DAngelo and A. Furno and C. Manganelli},
  title     = {A Case Study of Automating User Experience-Oriented Performance Testing on Smartphones},
  booktitle = {2013 IEEE Sixth International Conference on Software Testing, Verification and Validation},
  year      = {2013},
  pages     = {66-69},
  month     = {March},
  abstract  = {We have developed a platform named Advanced Test Environment (ATE) for supporting the design and the automatic execution of UX tests for applications running on Android smartphones. The platform collects objective metrics used to estimate the UX. In this paper, we investigate the extent that the metrics captured by ATE are able to approximate the results that are obtained from UX testing with real human users. Our findings suggest that ATE produces UX estimations that are comparable to those reported by human users. We have also compared ATE with three widespread benchmark tools that are commonly used in the industry, and the results show that ATE outperforms these tools.},
  doi       = {10.1109/ICST.2013.16},
  issn      = {2159-4848},
  keywords  = {Linux;automatic testing;program testing;smart phones;software performance evaluation;ATE;Android smartphones;UX estimations;UX test design;UX testing;advanced test environment;automatic UX test execution;objective metrics;user experience-oriented performance testing automation;Conferences;Software testing;android;mobile applications;smartphone;software testing;usability;user experience},
}

@InProceedings{Grossman1994,
  author    = {D. Grossman and C. J. Staton and B. Bailey and M. C. McCabe and A. Latts and O. Frieder and C. Bock and D. Roberts},
  title     = {A prototype-driven approach to application-level performance testing: a case study of a large finance application},
  booktitle = {Proceedings of 3rd Symposium on Assessments of Quality Software Development Tools},
  year      = {1994},
  pages     = {125-135},
  month     = {Jun},
  abstract  = {We present an approach to application-level performance testing. This uses a popular test tool, TPNS (Teleprocessing Network Simulator) to simulate performance of an application. Our approach hinges upon a simple prototype to verify that the system performance falls within acceptable bounds. Once the initial prototype is developed, detailed tuning may take place. We present a case study in which we tested the performance of a large finance application. This approach led to critical performance tuning improvement. Due to this improvement, the average user response time in our simulations was reduced from 30 seconds to under 1.5 seconds. This simulation has been verified by actual system usage during the first two months of live operation in which the average response time has indeed been under 1.5 seconds},
  doi       = {10.1109/AQSDT.1994.315756},
  keywords  = {accounts data processing;performance evaluation;program testing;software prototyping;TPNS;Teleprocessing Network Simulator;application-level performance testing;large finance application;prototype-driven approach;system performance;test tool;user response time;Computer aided software engineering;Computer bugs;Database systems;Finance;Financial management;Information technology;Operating systems;Prototypes;System testing;Technology management},
}

@InProceedings{Jiang2008,
  author    = {Z. M. Jiang and A. E. Hassan and G. Hamann and P. Flora},
  title     = {Automatic identification of load testing problems},
  booktitle = {2008 IEEE International Conference on Software Maintenance},
  year      = {2008},
  pages     = {307-316},
  month     = {Sept},
  abstract  = {Many software applications must provide services to hundreds or thousands of users concurrently. These applications must be load tested to ensure that they can function correctly under high load. Problems in load testing are due to problems in the load environment, the load generators, and the application under test. It is important to identify and address these problems to ensure that load testing results are correct and these problems are resolved. It is difficult to detect problems in a load test due to the large amount of data which must be examined. Current industrial practice mainly involves time-consuming manual checks which, for example, grep the logs of the application for error messages. In this paper, we present an approach which mines the execution logs of an application to uncover the dominant behavior (i.e., execution sequences) for the application and flags anomalies (i.e., deviations) from the dominant behavior. Using a case study of two open source and two large enterprise software applications, we show that our approach can automatically identify problems in a load test. Our approach flags < 0.01% of the log lines for closer analysis by domain experts. The flagged lines indicate load testing problems with a relatively small number of false alarms. Our approach scales well for large applications and is currently used daily in practice.},
  doi       = {10.1109/ICSM.2008.4658079},
  issn      = {1063-6773},
  keywords  = {program testing;public domain software;software engineering;automatic identification;enterprise software;load testing;open source software;Catalogs;Computer bugs;Databases;Generators;Monitoring;Software;Testing},
}

@InProceedings{Ibhar2017,
  author    = {N. Ibhar and W. Flores and R. León},
  title     = {Design of a low-cost teleoperated robotic arm: Assembly and performance testing},
  booktitle = {2017 IEEE 37th Central America and Panama Convention (CONCAPAN XXXVII)},
  year      = {2017},
  pages     = {1-5},
  month     = {Nov},
  abstract  = {At present, robots are widely used in various tasks, whether for industrial or even domestic uses. Thus, for certain tasks it has become necessary to operate the robot in an intuitive and safe way. The vast majority of current robotic hands do not completely replace the functionality of a hand and can not be used in environments which are designed for the use of a human hand. Thus, this document shows the design of a hybrid system with robotic hand and prosthesis applications. The design of a biomechanically controlled, functional and anthropomorphic robotic arm is shown, which demonstrates that it is feasible to design a real-time, low-cost, robotic arm.},
  doi       = {10.1109/CONCAPAN.2017.8278490},
  keywords  = {biomechanics;human-robot interaction;manipulator dynamics;prosthetics;robot dynamics;telerobotics;anthropomorphic robotic arm;biomechanically controlled arm;domestic uses;functional arm;human hand;hybrid system design;industrial uses;low-cost teleoperated robotic arm;performance testing;prosthesis;robotic hand;robotic hands;robots;Manipulators;Service robots;Silicon compounds;Task analysis;Testing;Torque;Human-robot interaction;Humanoid robots;Robot control;Telerobotics},
}

@InProceedings{l.liu2007,
  author    = {l. liu and w. wei and j. li},
  title     = {Wireless Communication System Automation Testing Framework},
  booktitle = {2007 International Conference on Wireless Communications, Networking and Mobile Computing},
  year      = {2007},
  pages     = {2981-2984},
  month     = {Sept},
  abstract  = {This article intends to introduce a leading next generation wireless protocol oriented automation testing framework - WiCAT system. This framework supports multiple protocol messaging testing by simulating the wireless equipments and implementing the telecommunication system logic. WiCAT provides high-efficiency and low-cost performance basing on a distributed, expandable and extensible architecture.},
  doi       = {10.1109/WICOM.2007.740},
  issn      = {2161-9646},
  keywords  = {automatic test software;electronic messaging;mobile radio;protocols;telecommunication computing;telecommunication equipment testing;WiCAT system;multiple protocol messaging testing;next generation wireless protocol;telecommunication system logic;wireless communication system automation testing;Automatic testing;Automation;Computer architecture;Graphical user interfaces;Local area networks;System testing;User interfaces;Utility programs;Wireless application protocol;Wireless communication},
}

@InProceedings{Nie2010,
  author    = {N. Nie and J. Guo and J. Fu and Z. Feng},
  title     = {Reliability and Performance Testing Model of Web-Based User Login and Access Control},
  booktitle = {2010 2nd International Workshop on Database Technology and Applications},
  year      = {2010},
  pages     = {1-4},
  month     = {Nov},
  abstract  = {In order to test the performance, reliability and security of Web-based system, the paper generates the test scripts template and establishes testing model of system login and access control. Then some Web-based systems are tested by automation test tools. The performance, reliability and security problems of Web login process can be traced and diagnosed. The test result shows that Web-based system can be verified and improved by the test script template of multi-users secure login and resources access control.},
  doi       = {10.1109/DBTA.2010.5658927},
  issn      = {2167-1923},
  keywords  = {Internet;authorisation;computer network security;performance evaluation;Web based user login;access control;multiuser secure login;performance testing model;reliability testing model;test script template;Access control;Correlation;Driver circuits;Software reliability;Testing},
}

@InProceedings{Angmo2014,
  author    = {R. Angmo and M. Sharma},
  title     = {Performance evaluation of web based automation testing tools},
  booktitle = {2014 5th International Conference - Confluence The Next Generation Information Technology Summit (Confluence)},
  year      = {2014},
  pages     = {731-735},
  month     = {Sept},
  abstract  = {In today's 21st century era countless software applications are written as a web based application which runs in a web browsers. With new technologies and commercialization of I.T. sector, the web based system has undergoes frequent and rapid changes. Today Softwares are coded as a web based application, which help to access data from any part of the globe. Even the economic relevance of web based enhances the control and quality of software. The quality assurance of any system depends on its test. But to do manually testing in most of the cases is time consuming, expensive and hectic. For the better business purpose and to save time and money automation testing is required. There are variety of tools are available in the market for this. One of the best known tool is selenium suite which is a combination of different automation testing tool. In this paper we will discuss about the selenium suite. It provides testers with different framework for different test cases. The main objective of this paper is to find the best tool in selenium suite and then compare it with some other tool for same task. For this purpose, performance evaluation is done on the basis of some criteria.},
  doi       = {10.1109/CONFLUENCE.2014.6949287},
  keywords  = {Internet;program testing;software performance evaluation;software quality;software tools;Web based application;Web based automation testing tools;Web browsers;performance evaluation;selenium suite;software applications;software quality;Automation;Browsers;Information technology;Performance evaluation;Software;Software testing;Automation testing;Performance;Selenium;Test case;Watir-webdriver;Web applications},
}

@InProceedings{Kapoh2016,
  author    = {H. Kapoh and E. S. Lumunon and N. A. E. Sajangbati},
  title     = {Design model material requirement of coconut flour production and performance testing based multi user in North Sulawesi},
  booktitle = {2016 International Conference on Knowledge Creation and Intelligent Computing (KCIC)},
  year      = {2016},
  pages     = {1-7},
  month     = {Nov},
  abstract  = {There has been many previous studies that discuss the control for the production of coconut flour and raw material inventory. But a system or a computer-based model for coconut flour industry in North Sulawesi has not or does not exist. For that reason, coconut flour industries also require tools on in running the business as developed in this study. The problem in this research is how to make the design of the model material production requirement of coconut flour-based multi-user to control the production of industrial centers in North Sulawesi coconut flour and how to test the model. The model generated in this study have been through a survey in the industrial district of coconut flour to get the data that will be used analysis, so that a complete picture processing system coconut flour and can describe the problem also the solution clearly in order to get the system needs a model along the test by using a test black box the program and the respondents used for the performance test in order to know the program's ability to interact with users. The collected data is then analyzed and designed using some design method that is data flow diagrams, use case diagram, entity relationship diagrams and material requirements planning methods. Results of the test will indicate that all functions on the system works well and test the respondent for 30 and 60 minutes resulting in a 60% and 63% of respondents were taken as many as 30 answered easily using the model application.},
  doi       = {10.1109/KCIC.2016.7883617},
  keywords  = {design engineering;food processing industry;materials requirements planning;production engineering computing;raw materials inventory;North Sulawesi;coconut flour industry;coconut flour production;computer-based model;data flow diagrams;design model material requirement;entity relationship diagrams;industrial centers;material requirements planning methods;model material production requirement;performance testing based multiuser;picture processing system;raw material inventory;use case diagram;Companies;Computational modeling;Industries;Planning;Production;Raw materials;Testing;coconut flour;design;model;multi-user;production;testing},
}

@InProceedings{Pu2009,
  author    = {Y. Pu and M. Xu},
  title     = {Load Testing for Web Applications},
  booktitle = {2009 First International Conference on Information Science and Engineering},
  year      = {2009},
  pages     = {2954-2957},
  month     = {Dec},
  abstract  = {The performance testing criteria was analyzed, including response time, concurrency users, throughout and performance counter. Performance testing is necessary for the system reliability. Load testing can be used for software troubleshooting and optimizing. With the LoadRunner and TestDirector testing tools, a load testing scheme based on an online examination system was designed.},
  doi       = {10.1109/ICISE.2009.720},
  issn      = {2160-1283},
  keywords  = {Internet;program testing;software performance evaluation;LoadRunner testing tools;TestDirector testing tools;Web application;concurrency users;load testing;online examination system;performance counter;performance testing criteria;response time;software troubleshooting;system reliability;Application software;Automatic testing;Computer bugs;Concurrent computing;Delay;Reliability engineering;Software performance;Software testing;System performance;System testing},
}

@InProceedings{Wu2010a,
  author    = {Q. Wu and Y. Wang},
  title     = {Performance Testing and Optimization of J2EE-Based Web Applications},
  booktitle = {2010 Second International Workshop on Education Technology and Computer Science},
  year      = {2010},
  volume    = {2},
  pages     = {681-683},
  month     = {March},
  abstract  = {J2EE-based Web applications are becoming increasingly ubiquitous and with their increasing adoption, the performance is the attention focus and the most important factor of evaluating the system by users. In this paper, we present a systematic solution for performance testing and optimization of J2EE-based Web applications. The solution helps to identify and eliminate bottlenecks in the application design and ensures that systems are designed to meet their quality of service requirements. This paper firstly analyses the architecture of J2EE-based Web applications and performance testing principle, and then improves the JMeter testing framework for meeting the more concurrent users. Lastly, performance testing for J2EE-based Web applications is done; it finds performance bottlenecks and puts forward optimum measures, and compares the performance with the former one.},
  doi       = {10.1109/ETCS.2010.583},
  keywords  = {Internet;Java;program testing;software performance evaluation;J2EE-based Web applications optimization;JMeter testing framework;concurrent users;performance testing;quality of service requirements;systematic solution;Application software;Business;Delay;Educational institutions;Nonhomogeneous media;Performance analysis;Scalability;Service oriented architecture;System performance;System testing;JMeter;Web applications;distributed;optimization;performance},
}

@InProceedings{Hamed2009,
  author    = {O. Hamed and N. Kafri},
  title     = {Performance testing for web based application architectures (.NET vs. Java EE)},
  booktitle = {2009 First International Conference on Networked Digital Technologies},
  year      = {2009},
  pages     = {218-224},
  month     = {July},
  abstract  = {Having an efficient web application is a challenge that we need to achieve when architecting web applications in the development process. This research follows a performance modeling approach that aims to utilize load testing tools to give ideas about performance issues early in the development life cycle for applications implemented using Java Enterprise Edition (Java EE) or .NET platform. Thus, it helps system architects to choose between competitive frameworks. To achieve this, the applications are subjected to artificial workload. Direct measurements are obtained on the specified application scenarios using different tools. Parasoft WebKing and Hewlett-Packard LoadRunner were used for this purpose. Later on, the obtained results indicate that, Java EE performs better than .NET. by means of response time and memory utilization.},
  doi       = {10.1109/NDT.2009.5272178},
  issn      = {2155-8728},
  keywords  = {Java;program testing;software architecture;software performance evaluation;Hewlett-Packard LoadRunner;Java Enterprise Edition;Parasoft WebKing;Web based application architectures;artificial workload;development life cycle;load testing tools;performance testing;Analytical models;Application software;Automatic testing;Computational modeling;Delay;Java;Performance analysis;Scalability;Service oriented architecture;System testing},
}

@InBook{Baura2002,
  pages     = {0-},
  title     = {Pharmacologic Stress Testing Using Closed-Loop Drug Delivery},
  publisher = {Wiley-IEEE Press},
  year      = {2002},
  author    = {Gail D. Baura},
  isbn      = {9780471683179},
  abstract  = {
This chapter contains sections titled:

Pharmacokinetics and Pharmacodynamics

Control Theory

Problem Significance

Closed-Loop Drug Infusion in Pharmacological Stress Tests

Summary

References

Peripheral Insulin Kinetics Exercises

},
  booktitle = {System Theory and Practical Applications of Biomedical Signals},
  doi       = {10.1109/9780471683179.ch14},
  keywords  = {Absorption;Biomedical monitoring;Blood flow;Drug delivery},
  url       = {https://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5444092},
}

@Article{Omidshafiei2016,
  author   = {S. Omidshafiei and A. A. Agha-Mohammadi and Y. F. Chen and N. K. Ure and S. Y. Liu and B. T. Lopez and R. Surati and J. P. How and J. Vian},
  title    = {Measurable Augmented Reality for Prototyping Cyberphysical Systems: A Robotics Platform to Aid the Hardware Prototyping and Performance Testing of Algorithms},
  journal  = {IEEE Control Systems},
  year     = {2016},
  volume   = {36},
  number   = {6},
  pages    = {65-87},
  month    = {Dec},
  issn     = {1066-033X},
  abstract = {Planning, control, perception, and learning are current research challenges in multirobot systems. The transition dynamics of the robots may be unknown or stochastic, making it difficult to select the best action each robot must take at a given time. The observation model, a function of the robots' sensor systems, may be noisy or partial, meaning that deterministic knowledge of the team's state is often impossible to attain. Moreover, the actions each robot can take may have an associated success rate and/or a probabilistic completion time. Robots designed for real-world applications require careful consideration of such sources of uncertainty, regardless of the control scheme or planning or learning algorithms used for a specific problem. Understanding the underlying mechanisms of planning algorithms can be challenging due to the latent variables they often operate on. When performance testing such algorithms on hardware, the simultaneous use of the debugging and visualization tools available on a workstation can be difficult. This transition from experimentation to implementation becomes especially challenging when the experiments need to replicate some feature of the software tool set in hardware, such as simulation of visually complex environments. This article details a robotics prototyping platform, called measurable augmented reality for prototyping cyberphysical systems (MAR-CPS), that directly addresses this problem, allowing for the real-time visualization of latent state information to aid hardware prototyping and performance testing of algorithms.},
  doi      = {10.1109/MCS.2016.2602090},
  keywords = {augmented reality;control engineering computing;cyber-physical systems;data visualisation;mobile robots;path planning;robot vision;software prototyping;software tools;MAR-CPS;hardware prototyping;latent state information;measurable augmented reality for prototyping cyberphysical systems;performance testing;planning algorithm;real-time visualization;robot sensor system;robotic platform;software tool set;Algorithm design and analysis;Augmented reality;Central Processing Unit;Cyber-physical systems;Planning;Robot sensing systems;Robots},
}

@InProceedings{Gold2004,
  author    = {K. Gold and A. Brown},
  title     = {Architecture and performance testing of a software GPS receiver for space-based applications},
  booktitle = {2004 IEEE Aerospace Conference Proceedings (IEEE Cat. No.04TH8720)},
  year      = {2004},
  volume    = {4},
  pages     = {2404-2416 Vol.4},
  month     = {March},
  abstract  = {Space-based GPS technology presents significant challenges over Earth-based systems. These include visibility issues for rotating platforms and tracking of GPS satellites from spacecraft that are in higher orbits than the GPS, realtime resolution of carrier phase ambiguities, and different dynamics during various mission phases. NAVSYS has developed a software GPS receiver that makes use of 3-dimensional digital beam steering technology and inertial aiding to address these issues. This approach offers several advantages including all round visibility for spinning satellites, tracking of weak GPS signals, reduction of multipath, and reprogrammability to accommodate different mission phases. Additionally, a suite of simulation tools based on the NAVSYS Matlab Toolbox and Advanced GPS Hybrid simulation products have been built to allow testing for simulated space environments. The receiver architecture and test tools are described in this paper.},
  doi       = {10.1109/AERO.2004.1368035},
  issn      = {1095-323X},
  keywords  = {Global Positioning System;aerospace computing;artificial satellites;beam steering;hybrid simulation;radio receivers;real-time systems;satellite tracking;software radio;telecommunication equipment testing;3-dimensional digital beam steering technology;Earth based systems;GPS hybrid simulation products;GPS satellite tracking;GPS signal tracking;Matlab toolbox;NAVSYS;carrier phase ambiguity;multipath reduction;realtime resolution;receiver architecture;rotating platforms;simulated space environment;software GPS receiver;space based applications;spinning satellites;Application software;Beam steering;Computer architecture;Global Positioning System;Orbits;Satellites;Software performance;Software testing;Space technology;Space vehicles},
}

@Article{Kalita2011,
  author   = {M. Kalita and T. Bezboruah},
  title    = {Investigation on performance testing and evaluation of PReWebD: a .NET technique for implementing web application},
  journal  = {IET Software},
  year     = {2011},
  volume   = {5},
  number   = {4},
  pages    = {357-365},
  month    = {August},
  issn     = {1751-8806},
  abstract = {A prototype research web application based on Visual Studio platform is developed with .NET as framework, Internet Information Server (IIS) (Version: 5.1) as web server and Microsoft Standard Query Language (SQL) Server (Version: 2005) as database server to study the performance and evaluation of the .NET technique used for developing the web application. The authors call it the PReWebD. As the performance is one of the most important features of a web application, to evaluate the performance, testing of PReWebD has been carried out using Mercury LoadRunner (Version 8.0) for validation and to study some other attributes like scalability, reliability etc. The performance depends on parameters such as hits/s, response time, throughput, errors/s etc. These parameters for PReWebD are tested with different stress levels. The statistical testing and analysis is done to assure the stability, reliability and quality of the application. Here the authors report in details the architecture, testing procedure, result of performance testing as well as the results of statistical analysis on recorded data of PReWebD.},
  doi      = {10.1049/iet-sen.2010.0139},
  keywords = {Internet;SQL;network operating systems;program testing;software architecture;software performance evaluation;statistical testing;.NET technique;Internet Information Server;Mercury LoadRunner;Microsoft Standard Query Language;PReWebD;SQL server;Visual Studio platform;Web application;Web server;architecture;database server;performance evaluation;performance testing;statistical analysis;statistical testing;stress level},
}

@Article{Pakin2007,
  author   = {S. Pakin},
  title    = {The Design and Implementation of a Domain-Specific Language for Network Performance Testing},
  journal  = {IEEE Transactions on Parallel and Distributed Systems},
  year     = {2007},
  volume   = {18},
  number   = {10},
  pages    = {1436-1449},
  month    = {Oct},
  issn     = {1045-9219},
  abstract = {CONCEPTUAL is a toolset designed specifically to help measure the performance of high-speed interconnection networks such as those used in workstation clusters and parallel computers. It centers around a high-level domain-specific language, which makes it easy for a programmer to express, measure, and report the performance of complex communication patterns. The primary challenge in implementing a compiler for such a language is that the generated code must be extremely efficient so as not to misattribute overhead costs to the messaging library. At the same time, the language itself must not sacrifice expressiveness for compiler efficiency, or there would be little point in using a high-level language for performance testing. This paper describes the CONCEPTUAL language and the CONCEPTUAL compiler's novel code-generation framework. The language provides primitives for a wide variety of idioms needed for performance testing and emphasizes a readable syntax. The core code-generation technique, based on unrolling CONCEPTUAL programs into sequences of communication events, is simple yet enables the efficient implementation of a variety of high-level constructs. The paper further explains how CONCEPTUAL implements time-bounded loops - even those that comprise blocking communication - in the absence of a time-out mechanism as this is a somewhat unique language/implementation feature.},
  doi      = {10.1109/TPDS.2007.1065},
  keywords = {computational linguistics;high level languages;message passing;program compilers;program control structures;program testing;software performance evaluation;specification languages;CONCEPTUAL language;blocking communication;code generation;domain-specific language;high-level language;high-speed interconnection networks;messaging library;network performance testing;parallel computers;program compiler;readable syntax;time-bounded loops;time-out mechanism;workstation clusters;Computer networks;Concurrent computing;Costs;Domain specific languages;High performance computing;Libraries;Multiprocessor interconnection networks;Programming profession;Testing;Workstations;Interprocessor communications;Measurement techniques;Specialized application languages},
}

@InProceedings{Netto2011,
  author    = {M. A. S. Netto and S. Menon and H. V. Vieira and L. T. Costa and F. M. de Oliveira and R. Saad and A. Zorzo},
  title     = {Evaluating Load Generation in Virtualized Environments for Software Performance Testing},
  booktitle = {2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum},
  year      = {2011},
  pages     = {993-1000},
  month     = {May},
  abstract  = {Before placing a software system into production, it is necessary to guarantee it provides users with a certain level of Quality-of-Service. Intensive performance testing is then necessary to achieve such a level and the tests require an isolated computing environment. Virtualization can therefore play an important role for saving energy costs by reducing the number of servers required to run performance tests and for allowing performance isolation when executing multiple tests in the same computing infrastructure. Load generation is an important component in performance testing as it simulates users interacting with the target application. This paper presents our experience in using a virtualized environment for load generation aimed at performance testing. We measured several performance metrics and varied system load, number of virtual machines per physical resource, and the CPU pinning schema for comparison of virtual and physical machines. The two main findings from our experiments are that physical machines produced steadier and faster response times under heavy load and that the pinning schema is an important aspect when setting up a virtualized environment for load generation.},
  doi       = {10.1109/IPDPS.2011.244},
  issn      = {1530-2075},
  keywords  = {program testing;software metrics;software performance evaluation;virtual machines;virtualisation;isolated computing environment;load generation;performance metrics;quality-of-service;software performance testing;virtual machines;virtualization;virtualized environment;Generators;Measurement;Servers;Testing;Throughput;Time factors;Virtual machining},
}

@InProceedings{Siivola2016,
  author    = {E. Siivola and S. Sierla and H. Niemistö and T. Karhela and V. Vyatkin},
  title     = {Requirement verification in simulation-based automation testing},
  booktitle = {2016 IEEE 14th International Conference on Industrial Informatics (INDIN)},
  year      = {2016},
  pages     = {740-743},
  month     = {July},
  abstract  = {The emergence of the Industrial Internet results in an increasing number of complicated temporal interdependencies between automation systems and the processes to be controlled. There is a need for verification methods that scale better than formal verification methods and which are more exact than testing. Simulation-based runtime verification is proposed as such a method, and an application of Metric temporal logic is presented as a contribution. The practical scalability of the proposed approach is validated against a production process designed by an industrial partner, resulting in the discovery of requirement violations.},
  doi       = {10.1109/INDIN.2016.7819257},
  keywords  = {Internet;automation;digital simulation;formal verification;production engineering computing;temporal logic;testing;formal verification;industrial Internet emergence;metric temporal logic;production process;requirement verification;simulation-based automation testing;simulation-based runtime verification;Automation;Leaching;Metals;Monitoring;Runtime;Slurries;Testing},
}

@InProceedings{Seth2017,
  author    = {P. Seth and N. Rane and A. Wagh and A. Katade and S. Sahu and N. Malhotra},
  title     = {Uberisation of mobile automation testing},
  booktitle = {2017 International Conference on Intelligent Computing and Control Systems (ICICCS)},
  year      = {2017},
  pages     = {181-183},
  month     = {June},
  abstract  = {Mobile phones and mobile applications have now become an essential part of everyday life. To make Mobile applications more reliable and error free, mobile application testing is important. Currently only a few techniques exist for creating automate tests of mobile applications and their functionality is very limited. In this paper, we introduce the new way of implementing a mobile test automation platform which performs mobile test automation from mobile devices itself. The main aim of automating the testing process is to develop a high quality and optimized applications to deliver efficient results to the customer.},
  doi       = {10.1109/ICCONS.2017.8250706},
  keywords  = {mobile computing;mobile handsets;program testing;Mobile phones;mobile application testing;mobile automation testing;mobile devices;mobile test automation platform;Androids;Automation;Mobile applications;Mobile communication;Mobile handsets;Testing;Tools;Device automation;Mobile app testing;Software Engineering;Software quality;Test Automation;Wireless testing},
}

@InProceedings{Lim2006a,
  author    = {Bum Hyun Lim and Jin Ryong Kim and Kwang Hyun Shim},
  title     = {A load testing architecture for networked virtual environment},
  booktitle = {2006 8th International Conference Advanced Communication Technology},
  year      = {2006},
  volume    = {1},
  pages     = {5 pp.-848},
  month     = {Feb},
  abstract  = {In this work, we develop a load testing architecture for networked virtual environment to reduce the testing time and ensure the stability of the server for distributed applications. It explicitly secures the stability of the server for networked virtual environment and at the same time, it elaborately generates actual loads for testing the performance of the server. Our agent based load testing architecture provides variety of interactions of virtual entities in the virtual worlds to perform realistic simulations. Simulation results show that our proposed architecture ensures the stability and capacity of the servers},
  doi       = {10.1109/ICACT.2006.206095},
  keywords  = {client-server systems;resource allocation;distributed applications;load testing architecture;networked virtual environment;server stability;virtual client;Analytical models;Databases;Discrete event simulation;Environmental management;Large-scale systems;Libraries;Network servers;Protocols;Testing;Virtual environment;Load test;beta test;game simulator;networked virtual environment;stress test;virtual client},
}

@InProceedings{Hao2010,
  author    = {D. Hao and Y. Chen and F. Tang and F. Qi},
  title     = {Distributed agent-based performance testing framework on Web Services},
  booktitle = {2010 IEEE International Conference on Software Engineering and Service Sciences},
  year      = {2010},
  pages     = {90-94},
  month     = {July},
  abstract  = {Web Services are applied widely in the field of information technology, and performance testing for Web Services applications has become an important problem. This paper introduces the method of performance testing, and proposes a framework of agent-based performance testing on Web Services, which includes TestFlow Generator, Scenario Creator, Test Manager, Load Generation Agent and Test Analyzer. And the implementation of kernel modules in the framework is introduced especially. To realize the load allocation to distributed Load Generation Agents from Test Manager, a queue-based allocation strategy is given.},
  doi       = {10.1109/ICSESS.2010.5552290},
  issn      = {2327-0586},
  keywords  = {Load modeling;Monitoring;Resource management;Schedules;Testing;Web services;Web Services;allocation strategy;load generation;performance testing},
}

@Article{Avritzer2004,
  author   = {A. Avritzer and E. J. Weyuker},
  title    = {The role of modeling in the performance testing of e-commerce applications},
  journal  = {IEEE Transactions on Software Engineering},
  year     = {2004},
  volume   = {30},
  number   = {12},
  pages    = {1072-1083},
  month    = {Dec},
  issn     = {0098-5589},
  abstract = {An e-commerce scalability case study is presented in which both traditional performance testing and performance modeling were used to help tune the application for high performance. This involved the creation of a system simulation model as well as the development of an approach for test case generation and execution. We describe our experience using a simulation model to help diagnose production system problems, and discuss ways that the effectiveness of performance testing efforts was improved by its use.},
  doi      = {10.1109/TSE.2004.107},
  keywords = {Java;electronic commerce;program testing;resource allocation;software performance evaluation;e-commerce;production system diagnosis;software performance modeling;software performance testing;test case generation;workload characterization;Aerospace testing;Computer architecture;Databases;Helium;Java;Monitoring;Production systems;Scalability;Software testing;System testing},
}

@InProceedings{Williamette2012,
  author    = {C. Williamette and E. Hansen},
  title     = {Development of electrical performance testing standards for the acceptance of solar photovoltaic projects based on field experience and observation},
  booktitle = {2012 38th IEEE Photovoltaic Specialists Conference},
  year      = {2012},
  pages     = {000554-000559},
  month     = {June},
  abstract  = {As-built performance requirements are becoming more common in Interconnection Applications (IAs) and Power Purchase Agreements (PPAs). Often overlooked as, “just the last step in the commissioning process,” it is important to understand the scope of the testing requirements before committing to the agreement. The worst case scenario is when your project has design flaws that prevent it from meeting requirements. By the time the system is discovered to be failing, it can be too late and too costly to fix. Understanding standards for performance testing can help guide project design to ensure better success meeting those requirements later on.},
  doi       = {10.1109/PVSC.2012.6317675},
  issn      = {0160-8371},
  keywords  = {commissioning;interconnections;photovoltaic power systems;solar power stations;standards;PPA;commissioning process;electrical performance testing standards;field experience;interconnection applications;power purchase agreements;solar PV systems;solar photovoltaic projects;Indexes;Inverters;Irrigation;Monitoring;Soil;Wiring;Current-voltage characteristics;Performance Analysis;Soil measurements;Solar energy;System analysis and design;Thermal analysis},
}

@InProceedings{Kim2009a,
  author    = {G. h. Kim and H. c. Moon and G. P. Song and S. K. Shin},
  title     = {Software Performance Testing Scheme Using Virtualization Technology},
  booktitle = {Proceedings of the 4th International Conference on Ubiquitous Information Technologies Applications},
  year      = {2009},
  pages     = {1-5},
  month     = {Dec},
  abstract  = {In this paper, we propose software performance testing scheme using virtualization technology. Generally, people have used software performance testing tool such as load runner and silk performer. However, people should perform software performance testing manually in case of the situation that people cannot use testing tool. It needs a lot of resources such as human resource and computing resource. Therefore, we propose software performance testing scheme using virtualization technology to reduce resource consumption. Proposed scheme can reduce computer resource consumption because virtualization technology can make a number of virtual computers with a small number of physical computers. Also proposed scheme can reduce human resource consumption because, in proposed scheme, management computer can control keyboard and mouse of virtual computers automatically. Simulation result shows that proposed scheme has possibility to be used for software performance testing.},
  doi       = {10.1109/ICUT.2009.5405721},
  issn      = {1976-0035},
  keywords  = {software performance evaluation;virtual machines;computer management;computing resource;human resource;software performance testing;virtual computers;virtualization technology;Automatic control;Computational modeling;Human resource management;Keyboards;Mice;Performance evaluation;Physics computing;Resource virtualization;Software performance;Software testing},
}

@Article{Krishnamurthy2006,
  author   = {D. Krishnamurthy and J. A. Rolia and S. Majumdar},
  title    = {A Synthetic Workload Generation Technique for Stress Testing Session-Based Systems},
  journal  = {IEEE Transactions on Software Engineering},
  year     = {2006},
  volume   = {32},
  number   = {11},
  pages    = {868-882},
  month    = {Nov},
  issn     = {0098-5589},
  abstract = {Enterprise applications are often business critical but lack effective synthetic workload generation techniques to evaluate performance. These workloads are characterized by sessions of interdependent requests that often cause and exploit dynamically generated responses. Interrequest dependencies must be reflected in synthetic workloads for these systems to exercise application functions correctly. This poses significant challenges for automating the construction of representative synthetic workloads and manipulating workload characteristics for sensitivity analyses. This paper presents a technique to overcome these problems. Given request logs for a system under study, the technique automatically creates a synthetic workload that has specified characteristics and maintains the correct interrequest dependencies. The technique is demonstrated through a case study involving a TPC-W e-commerce system. Results show that incorrect performance results can be obtained by neglecting interrequest dependencies, thereby highlighting the value of our technique. The study also exploits our technique to investigate the impact of several workload characteristics on system performance. Results establish that high variability in the distributions of session length, session idle times, and request service times can cause increased contention among sessions, leading to poor system responsiveness. To the best of our knowledge, these are the first results of this kind for a session-based system. We believe our technique is of value for studies where fine control over workload is essential},
  doi      = {10.1109/TSE.2006.106},
  keywords = {electronic commerce;performance evaluation;program testing;TPC-W e-commerce system;e-commerce system;enterprise application;performance evaluation;sensitivity analyses;stress testing session-based system;synthetic workload generation technique;Application software;Character generation;Computer Society;Delay;Occupational stress;Sensitivity analysis;Stress control;System performance;System testing;Web server;Internet applications;Performance of systems;Web servers.;electronic commerce;measurement techniques;modeling techniques;software engineering;testing tools},
}

@InProceedings{Ali2015,
  author    = {A. Ali and N. Badr},
  title     = {Performance testing as a service for web applications},
  booktitle = {2015 IEEE Seventh International Conference on Intelligent Computing and Information Systems (ICICIS)},
  year      = {2015},
  pages     = {356-361},
  month     = {Dec},
  abstract  = {Software testing is a vital activity that is undertaken during software engineering life cycle to ensure software quality and reliability. Performance testing is a type of software testing that is done to shows how web application behaves under a certain workload. Cloud computing as an emerging technology can be used in the field of software engineering to provide cloud testing in order to overcome all deficiencies of conventional testing by leveraging cloud computing resources. As a result, testing-as-a-service (TaaS) is introduced as a service model that performs all testing activities in fully automated manner, on demand with a pay-for use basis. Moreover, TaaS increases testing efficiency and reduces time and cost required for testing. In this paper, performance TaaS framework for web applications is introduced which provides all performance testing activities including automatic test case generation and test execution. In addition, the proposed framework addresses many issues as: maximize resource utilization and continuous monitoring to ensure system reliability.},
  doi       = {10.1109/IntelCIS.2015.7397245},
  keywords  = {Web services;program testing;software performance evaluation;software quality;Web applications;automatic test case generation;cloud computing resources;cloud testing;continuous monitoring;performance testing;software engineering life cycle;software quality;software reliability;software testing;system reliability;testing-as-a-service;Fault tolerance;Fault tolerant systems;Software;Testing;Virtualization;Cloud Computing;JMeter;Performance Testing;TaaS;web Application Testing},
}

@InProceedings{Habash2011,
  author    = {R. W. Y. Habash and V. Groza and Y. Yang and C. Blouin and P. Guillemette},
  title     = {Performance Testing and Control of a Small Wind Energy Converter},
  booktitle = {2011 Sixth IEEE International Symposium on Electronic Design, Test and Application},
  year      = {2011},
  pages     = {263-268},
  month     = {Jan},
  abstract  = {Responding to more demand in coming years, the task of the small wind energy industry requires progress on several fronts-from public policy initiatives, to technology development, to market growth. Enhanced technologies such as contra-rotating blades, transmission systems, lubrication, airfoils, generators, and power electronics will lower cost and increase energy production. This paper mainly considers two key technological points of a small wind energy converter (SWEC) namely, the performance of the rotor system and induction generator. Small-scale prototypes have been built to experimentally verify the performance of the SWEC. Wind tunnel tests of the power output, power coefficient, and turbine speed were carried out to ascertain the aerodynamic power conversion and the operation capability at lower wind speeds. The results demonstrated a significant increase in performance compared to a single-rotor system of the same type. Another aspect of development and test is to present a comparative performance evaluation between a standard induction generator and an efficient but with modified design (TRIAS Generator) as a realistic solution of clean power for grid-connected SWECs. The paper also discusses issues related to control and monitoring of SWEC.},
  doi       = {10.1109/DELTA.2011.55},
  keywords  = {aerodynamics;asynchronous generators;power convertors;power generation control;power grids;power markets;rotors;wind power plants;wind tunnels;wind turbines;aerodynamic power conversion;grid connected SWEC;induction generator;market growth;performance testing;public policy;rotor system;small scale prototype;small wind energy converter control;technology development;wind energy industry;wind tunnel;Blades;Generators;Induction motors;Rotors;Wind energy;Wind speed;Wind turbines;Small wind generator;contra-rotating system;induction generator},
}

@Article{Grossman1996,
  author   = {D. Grossman and M. C. McCabe and C. Staton and B. Bailey and O. Frieder and D. C. Roberts},
  title    = {Performance testing a large finance application},
  journal  = {IEEE Software},
  year     = {1996},
  volume   = {13},
  number   = {5},
  pages    = {50-54},
  month    = {Sep},
  issn     = {0740-7459},
  abstract = {The case study presented in the paper shows how a simple prototype can be used to verify, before production, that a system will perform at an acceptable level under realistic conditions. The study involves the first implementation of American Management System's Federal Financial System (FFS), a financial accounting application, in a customer information control system (CICS) DB2 environment running on a large IBM mainframe},
  doi      = {10.1109/52.536458},
  keywords = {accounts data processing;financial data processing;program testing;program verification;relational databases;software performance evaluation;American Management System;DB2 environment;Federal Financial System;IBM mainframe;case study;customer information control system;financial accounting application;large finance application;performance testing;program verification;relational database;simple prototype;Control systems;Database systems;Delay;Environmental management;Finance;Financial management;Information technology;Operating systems;Performance evaluation;Production systems;Prototypes;Stress;System testing;Technology management;Testing},
}

@InProceedings{Duttagupta2011a,
  author    = {S. Duttagupta and M. Nambiar},
  title     = {Performance Extrapolation for Load Testing Results of Mixture of Applications},
  booktitle = {2011 UKSim 5th European Symposium on Computer Modeling and Simulation},
  year      = {2011},
  pages     = {424-429},
  month     = {Nov},
  abstract  = {Load testing of IT applications faces the challenge of providing high quality test results that would represent the performance in production like scenarios, without incurring high cost of commercial load testing tools. It would help IT projects to be able to test with a small number of users and extrapolate to scenarios with much larger number of users. Such an extrapolation strategy when applied to mixture of application workloads running on a shared server environment must take into consideration application characteristics (CPU/IO intensive, memory bound) as well the server capabilities. The goal is to predict the performance of mixture workload, the maximum throughput offered by the application mix and the maximum number of users supported by the system before the throughput starts degrading. In this paper, we propose an extrapolation strategy that analyses a system workload mix based on its service demand on various resources and extrapolates its performance using simple empirical modeling techniques. Moreover, its ability to extrapolate throughput of an application mixture even if there is a change in the mixture, can help in capacity planning of the system.},
  doi       = {10.1109/EMS.2011.56},
  keywords  = {extrapolation;program testing;IT application;application mixture;empirical modeling technique;extrapolation strategy;information technology;load testing;Extrapolation;Load modeling;Production;Servers;Telecommunications;Testing;Throughput;Extrapolation;S-curve;load Testing;mixture of applications;multi-classes of job},
}

@InProceedings{Singh2012,
  author    = {M. Singh and R. Singh},
  title     = {Load Testing of web frameworks},
  booktitle = {2012 2nd IEEE International Conference on Parallel, Distributed and Grid Computing},
  year      = {2012},
  pages     = {592-596},
  month     = {Dec},
  abstract  = {This document deals with a comparative analysis on the web frame works namely Spring3.0 MVC, Struts 2.0, JSF 1.2x and Wickets. A detailed study is given on the behavior of the frameworks when they are utilized in the front end and at the backend JPA is used to make communication with the database. The Database utilized is Oracle 10g. Load Testing of all the applications is done using J-meter.},
  doi       = {10.1109/PDGC.2012.6449887},
  keywords  = {Internet;database management systems;online front-ends;program testing;J-meter;JSF 1.2x;Oracle 10g;Spring3.0 MVC;Struts 2.0;Web frameworks;Wickets;backend JPA;database;front end;load testing;Bandwidth;Color;Information filters;Process control;Springs;Throughput;JSF 1.2x;Spring3.0 MVC;Struts 2.0;Wickets and JPA},
}

@InProceedings{Freitas2014,
  author    = {A. Freitas and R. Vieira},
  title     = {An Ontology for Guiding Performance Testing},
  booktitle = {2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)},
  year      = {2014},
  volume    = {1},
  pages     = {400-407},
  month     = {Aug},
  abstract  = {Software test is a technique to obtain information about software systems quality. Performance test is a type of software test that aims at evaluating software performance at a given load scenario, but it requires specialized knowledge about tools, activities and metrics of the domain. Since ontology is a promising knowledge representation technique, this paper presents a literature review to identify trends and compare researches of ontologies in the fields of software testing and software performance. Also, to investigate this issue from a practical perspective, it was developed an ontology for representing the core knowledge of performance testing. This paper presents the ontology and compare it with related ones. Then, semantic technologies are explored to demonstrate the practical feasibility of developing ontology-based applications for assisting testers with performance test planning and management.},
  doi       = {10.1109/WI-IAT.2014.62},
  keywords  = {ontologies (artificial intelligence);program testing;software management;software performance evaluation;software quality;knowledge representation technique;ontology;performance test management;performance test planning;performance testing guidance;semantic technologies;software performance evaluation;software systems quality;software testing;Measurement;OWL;Ontologies;Software performance;Software testing},
}

@InProceedings{Khandelwal2017,
  author    = {H. Khandelwal and P. Mankodi and R. Prajapati},
  title     = {Enhancement of automation testing system using Yocto project},
  booktitle = {2017 International conference of Electronics, Communication and Aerospace Technology (ICECA)},
  year      = {2017},
  volume    = {1},
  pages     = {697-700},
  month     = {April},
  abstract  = {Nowadays, in industries, Testing has become one of the important tasks. Testing is necessary for an effective performance of product and software applications. When companies having a mass production of hardware boards, it is necessary to do testing of each and every module of hardware like SPI, UART, GPIO, PWM, ADC, USB, Ethernet. If we do testing manually then it will significantly take more time, which we can be reduced by automation testing. But the solution is not an automation testing because automation testing also requires the same amount of system, for example for 300 boards 300 system is required. The only difference in manual and automation testing is that in automation testing it will require less human effort. Now we are focusing more on developing a solution in which many tests can be done on one single system i.e. for 300 boards only one system is required for testing hence this problem can be solved by Yocto Project. Yocto project have build the tool named Bitbake which is written in Python language, which works on multithreading and scheduling so that simultaneously you can test more boards on a single system. In this paper we did automation testing of GPIO pins using Yocto project.},
  doi       = {10.1109/ICECA.2017.8203630},
  keywords  = {automatic test software;Bitbake tool;GPIO pins;Python language;Yocto Project;automation testing system;multithreading;scheduling;Automation;Hardware;Licenses;Pins;Software;Testing;Tools;Automation;Bitbake;Open embedded;Yocto project},
}

@InProceedings{Subraya2000,
  author    = {B. M. Subraya and S. V. Subrahmanya},
  title     = {Object driven performance testing of Web applications},
  booktitle = {Proceedings First Asia-Pacific Conference on Quality Software},
  year      = {2000},
  pages     = {17-26},
  abstract  = {Performance of many Web sites depends on the load on the site at peak time under varying conditions. Performance testing is normally conducted in reasonably simulated environment with the help of performance testing tools. However, performance of a Web site depends on various parameters and each parameter must be tested under varying stress levels. It is not possible to draw a common denominator for performance parameters to test the Web site due to complexity of Web sites. Different parts of the Web site must be tested with different parameters under varying condition and stress level. In such circumstances, it is necessary to decompose the Web site into many components, which represents the behavior of various business components. These business components are mapped to various objects that truly represent the behavior and structure of the part of the web site. These objects are subjected to performance testing with different parameters and stress levels. This paper addresses the new testing process, which uses the concept of decomposing the behavior of the Web site into testable components, which are mapped onto testable objects. These testable objects are subjected to performance testing under varied performance parameters and stress levels},
  doi       = {10.1109/APAQ.2000.883774},
  keywords  = {computational complexity;information resources;program testing;programming environments;software performance evaluation;Web applications;Web sites;complexity;object driven performance testing;performance parameters;simulated environment;Acoustic testing;Application software;Cities and towns;Consumer electronics;Electronic commerce;Life testing;Software testing;Stress;System testing;Time to market},
}

@InProceedings{Baltas2012,
  author    = {N. Baltas and T. Field},
  title     = {Continuous Performance Testing in Virtual Time},
  booktitle = {2012 Ninth International Conference on Quantitative Evaluation of Systems},
  year      = {2012},
  pages     = {13-22},
  month     = {Sept},
  abstract  = {In this paper we show how program code and performance models can be made to cooperate seamlessly to support continuous software performance testing throughout the development lifecycle. We achieve this by extending our existing VEX tool for executing programs in virtual time so that events that occur during normal execution and those that occur during the simulation of a performance model can be scheduled on a single global virtual time line. The execution time of an incomplete component of an application is thus estimated by a performance model, whilst that of existing code is measured by instrumentation that is added dynamically at program load time. A key challenge is to be able to map some or all of the resources in a performance model to the real resources of the host platform on which the application is running. We outline a continuous performance engineering methodology that exploits our unified framework and illustrate the principles involved byway of a simple Java application development case study.},
  doi       = {10.1109/QEST.2012.26},
  keywords  = {Java;program testing;software performance evaluation;software tools;Java application development;VEX tool;continuous performance engineering methodology;continuous software performance testing;development lifecycle;performance model;program code;program execution;program load time;virtual time;Computational modeling;Instruction sets;Java;Predictive models;Real-time systems;Resumes;Schedules;Modelling Queueing networks;Software Performance;Virtual execution},
}

@Comment{jabref-meta: databaseType:bibtex;}
